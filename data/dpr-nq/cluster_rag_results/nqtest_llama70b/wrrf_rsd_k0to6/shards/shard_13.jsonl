{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 2122.3368644714355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Molly", "latency_ms": 1256.4527988433838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2135.9896659851074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2309.4234466552734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2151.3118743896484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2178.9276599884033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3166}, "6": {"k": 6, "answer": "Geraldine Somerville", "latency_ms": 2731.3339710235596, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3755}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 2719.9783325195312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 2165.727138519287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 2133.5036754608154, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 3652.4062156677246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1946}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 2587.739944458008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2568}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 2946.7997550964355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3241}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 2772.101640701294, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3873}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwest desert regions", "latency_ms": 2756.230592727661, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4868.396043777466, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "arid lowland or mountainous shrubland", "latency_ms": 5764.675140380859, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "arid lowland or mountainous shrubland", "latency_ms": 5500.555992126465, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 5314.719438552856, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2582}, "5": {"k": 5, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 4067.7387714385986, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3217}, "6": {"k": 6, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 6377.0081996917725, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3887}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 3210.3192806243896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dr. Rajendra Prasad", "latency_ms": 2763.141393661499, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 743}, "2": {"k": 2, "answer": "Dr. Rajendra Prasad", "latency_ms": 2729.5258045196533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1429}, "3": {"k": 3, "answer": "Dr. Rajendra Prasad", "latency_ms": 3046.8406677246094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2127}, "4": {"k": 4, "answer": "Dr. Rajendra Prasad", "latency_ms": 4504.996538162231, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2812}, "5": {"k": 5, "answer": "Sachchidananda Sinha", "latency_ms": 4185.858726501465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3414}, "6": {"k": 6, "answer": "Sachchidananda Sinha", "latency_ms": 3362.542152404785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4113}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1919.3971157073975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2142.476797103882, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2181.189775466919, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "10pm (Eastern)", "latency_ms": 2757.54451751709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1955}, "4": {"k": 4, "answer": "September 22, 2014", "latency_ms": 3892.223358154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1503.5829544067383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3263}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2339.482545852661, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3828}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "June 22, 2001", "latency_ms": 2663.186550140381, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2001", "latency_ms": 1863.0197048187256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "2001", "latency_ms": 1435.2247714996338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1265}, "3": {"k": 3, "answer": "2001", "latency_ms": 1516.815185546875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "2001", "latency_ms": 2373.112678527832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2528}, "5": {"k": 5, "answer": "2001", "latency_ms": 2033.5173606872559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3161}, "6": {"k": 6, "answer": "2001", "latency_ms": 1766.908884048462, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3803}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2406.871557235718, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 4445.245742797852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 2860.4557514190674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 3164.8364067077637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 2811.821222305298, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2666}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 4692.732334136963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3372}, "6": {"k": 6, "answer": "September 27, 2017", "latency_ms": 3233.4272861480713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4119}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3", "latency_ms": 1690.2644634246826, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sectionals", "latency_ms": 1030.477523803711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Sectionals", "latency_ms": 1229.4049263000488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "Sectionals", "latency_ms": 1965.6989574432373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Sectionals", "latency_ms": 1470.7667827606201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2430}, "5": {"k": 5, "answer": "In \"Sectionals\"", "latency_ms": 3181.7786693573, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3019}, "6": {"k": 6, "answer": "In \"Sectionals\"", "latency_ms": 3105.717658996582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3642}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1649.8961448669434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2245.086669921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2016.117811203003, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2180.1066398620605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2404.827833175659, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1696.6557502746582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3087}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2697.9598999023438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3792}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 1206.4509391784668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "the harbor", "latency_ms": 1041.167974472046, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Havana Harbor, Cuba", "latency_ms": 2402.0347595214844, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Havana Harbor", "latency_ms": 1470.9722995758057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "Havana Harbor, Cuba", "latency_ms": 1987.1039390563965, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Havana Harbor, Cuba", "latency_ms": 2996.6630935668945, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3051}, "6": {"k": 6, "answer": "Havana Harbor, Cuba", "latency_ms": 3507.338285446167, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3692}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 1207.4482440948486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2829.04314994812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2265.562057495117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "No specific god mentioned", "latency_ms": 1696.3424682617188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1935}, "4": {"k": 4, "answer": "None mentioned", "latency_ms": 1854.59303855896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Lord Vishnu and Lord Shiva and Ganesha", "latency_ms": 4442.836046218872, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3225}, "6": {"k": 6, "answer": "Lord Vishnu and Lord Shiva", "latency_ms": 4182.045698165894, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 4933.169364929199, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "All of them", "latency_ms": 2516.153335571289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Honduras, Nicaragua", "latency_ms": 3243.373155593872, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1356}, "3": {"k": 3, "answer": "Costa Rica, El Salvador, Nicaragua, Panama", "latency_ms": 4873.46339225769, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2020}, "4": {"k": 4, "answer": "Costa Rica, El Salvador, Nicaragua, Panama", "latency_ms": 5103.4228801727295, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2639}, "5": {"k": 5, "answer": "Costa Rica, Nicaragua, Panama, El Salvador, Guatemala, Honduras, Belize", "latency_ms": 6954.742193222046, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3298}, "6": {"k": 6, "answer": "Costa Rica, Nicaragua, Panama, El Salvador, Honduras, Guatemala, Belize", "latency_ms": 7252.559423446655, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3983}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence.", "latency_ms": 1864.5853996276855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 1562.7093315124512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Complex sentence", "latency_ms": 2052.4346828460693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Complex sentence", "latency_ms": 993.7577247619629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1977}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 1878.1380653381348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2683}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 1439.1591548919678, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3371}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 1993.3669567108154, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4097}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and trade.", "latency_ms": 2720.4630374908447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 4313.738822937012, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3934.586763381958, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "the Nature and Causes of the Wealth of Nations", "latency_ms": 4235.090494155884, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 4207.3729038238525, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 2533}, "5": {"k": 5, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3980.027675628662, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "the nature and causes of the wealth of nations", "latency_ms": 2937.312364578247, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3840}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 4119.3249225616455, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "August 28, 2018", "latency_ms": 2372.4570274353027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "August 28, 2018", "latency_ms": 3657.0329666137695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 3361.2442016601562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 3323.505163192749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 4190.036773681641, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 4332.603693008423, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere", "latency_ms": 2968.675374984741, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northern Territory", "latency_ms": 1738.931655883789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "Northern Territory of Australia", "latency_ms": 2446.4473724365234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1370}, "3": {"k": 3, "answer": "Northern Territory of Australia, Western Australia, Queensland", "latency_ms": 3501.9876956939697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2036}, "4": {"k": 4, "answer": "Northern Territory of Australia", "latency_ms": 2142.7533626556396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2664}, "5": {"k": 5, "answer": "Northern Territory and Western Australia", "latency_ms": 2492.6629066467285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3373}, "6": {"k": 6, "answer": "Southern part of Northern Territory and southwest corner of Western Australia", "latency_ms": 3839.738607406616, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4026}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Leia Organa", "latency_ms": 2211.270332336426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2149.5580673217773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "her", "latency_ms": 962.8283977508545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "her", "latency_ms": 634.4118118286133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1831}, "4": {"k": 4, "answer": "her", "latency_ms": 1197.3719596862793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2436}, "5": {"k": 5, "answer": "Her", "latency_ms": 1129.1251182556152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2972}, "6": {"k": 6, "answer": "her", "latency_ms": 1203.61328125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3543}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 1809.577465057373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Barry Cryer", "latency_ms": 2112.0212078094482, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 548}, "2": {"k": 2, "answer": "Barry Cryer", "latency_ms": 1861.8581295013428, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1196}, "3": {"k": 3, "answer": "Barry Cryer", "latency_ms": 2360.6162071228027, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1779}, "4": {"k": 4, "answer": "Barry Cryer", "latency_ms": 2701.3440132141113, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2329}, "5": {"k": 5, "answer": "Barry Cryer", "latency_ms": 2429.224967956543, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2924}, "6": {"k": 6, "answer": "Barry Cryer", "latency_ms": 2772.2835540771484, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3540}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 1496.4134693145752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chloroplast", "latency_ms": 1922.133445739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Chloroplast and Mitochondrion", "latency_ms": 4225.782632827759, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1366}, "3": {"k": 3, "answer": "Chloroplast, Mitochondrion", "latency_ms": 3046.4401245117188, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2058}, "4": {"k": 4, "answer": "Mitochondrion and Chloroplast", "latency_ms": 3477.5264263153076, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2715}, "5": {"k": 5, "answer": "Mitochondria and Chloroplasts", "latency_ms": 3810.994863510132, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3366}, "6": {"k": 6, "answer": "Mitochondria and Chloroplasts", "latency_ms": 3346.9676971435547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4042}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Backup.", "latency_ms": 6596.738338470459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2573.7271308898926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2873.171806335449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1400}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2923.048496246338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2155}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1587.9416465759277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2794}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3128.110647201538, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3477}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2407.010793685913, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4139}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3172.374725341797, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenny Rogers and Dottie West", "latency_ms": 4159.226894378662, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 590}, "2": {"k": 2, "answer": "Kenny Rogers and Dottie West", "latency_ms": 4212.459564208984, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3974.5051860809326, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "Kenny Rogers and Dottie West", "latency_ms": 4245.647430419922, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2446}, "5": {"k": 5, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3782.484531402588, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3047}, "6": {"k": 6, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3971.8925952911377, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3665}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 1611.109972000122, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "36 months", "latency_ms": 2076.3092041015625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 601}, "2": {"k": 2, "answer": "36 months", "latency_ms": 781.2900543212891, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "36 months", "latency_ms": 2524.799585342407, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1911}, "4": {"k": 4, "answer": "36 months old", "latency_ms": 2546.0410118103027, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "36 months old", "latency_ms": 2215.362071990967, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3091}, "6": {"k": 6, "answer": "36 months", "latency_ms": 1438.0173683166504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3669}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 1461.7745876312256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Three-part", "latency_ms": 1802.63352394104, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 652}, "2": {"k": 2, "answer": "Three-part", "latency_ms": 2122.330904006958, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Three", "latency_ms": 895.500659942627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Three", "latency_ms": 1717.9999351501465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2580}, "5": {"k": 5, "answer": "Three", "latency_ms": 1228.7249565124512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "Three", "latency_ms": 928.6315441131592, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3881}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 7874.3133544921875, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elijah Wood", "latency_ms": 2386.0721588134766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Elijah Wood", "latency_ms": 2097.541332244873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1301}, "3": {"k": 3, "answer": "Elijah Wood", "latency_ms": 1606.7945957183838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1967}, "4": {"k": 4, "answer": "Elijah Wood, Ian Holm", "latency_ms": 3742.8677082061768, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Elijah Wood, Ian Holm", "latency_ms": 3109.9746227264404, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3159}, "6": {"k": 6, "answer": "Elijah Wood", "latency_ms": 1903.3465385437012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3812}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party", "latency_ms": 2189.3248558044434, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume.", "latency_ms": 1570.981740951538, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "Costume", "latency_ms": 2000.1749992370605, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1200}, "3": {"k": 3, "answer": "Costume", "latency_ms": 2053.7993907928467, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Costume", "latency_ms": 2059.3416690826416, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2533}, "5": {"k": 5, "answer": "Costume", "latency_ms": 1518.1212425231934, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3102}, "6": {"k": 6, "answer": "Costume party", "latency_ms": 2355.175495147705, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3774}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 737.4022006988525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3233.3011627197266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 686}, "2": {"k": 2, "answer": "One", "latency_ms": 1996.9277381896973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "One", "latency_ms": 1493.8209056854248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1990}, "4": {"k": 4, "answer": "One", "latency_ms": 1024.277687072754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2590}, "5": {"k": 5, "answer": "1", "latency_ms": 1659.2907905578613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3222}, "6": {"k": 6, "answer": "1", "latency_ms": 1080.3947448730469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3848}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "He promised Fantine", "latency_ms": 1774.468183517456, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fantine's debts", "latency_ms": 2396.044969558716, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "Fantine's debts", "latency_ms": 3270.4317569732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Fantine's request", "latency_ms": 1664.3824577331543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "Fantine's debts", "latency_ms": 1415.6663417816162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "Fantine's debts", "latency_ms": 2663.6645793914795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3087}, "6": {"k": 6, "answer": "Fantine's request", "latency_ms": 2591.524124145508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3699}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, and South Korea.", "latency_ms": 2873.711347579956, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenya", "latency_ms": 1576.4250755310059, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "Kenya", "latency_ms": 1423.9718914031982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1382}, "3": {"k": 3, "answer": "Kenya and India", "latency_ms": 2418.283224105835, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Kenya, India, Russia", "latency_ms": 2541.5658950805664, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2794}, "5": {"k": 5, "answer": "Kenya, India, Russia, United Kingdom", "latency_ms": 4282.5024127960205, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3513}, "6": {"k": 6, "answer": "Kenya, India, Russia, United Kingdom, Canada", "latency_ms": 5331.196308135986, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 4240}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and control.", "latency_ms": 2311.3558292388916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to consolidate Bantu education", "latency_ms": 2684.8111152648926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 714}, "2": {"k": 2, "answer": "to consolidate Bantu education", "latency_ms": 3085.2530002593994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1413}, "3": {"k": 3, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7518.905878067017, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7368.260145187378, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7971.224546432495, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7472.362279891968, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4119}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 1855.2229404449463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 3239.7406101226807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 2483.701467514038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Huge and powerful snake", "latency_ms": 2702.3086547851562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1759}, "4": {"k": 4, "answer": "Python", "latency_ms": 1151.6125202178955, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2384}, "5": {"k": 5, "answer": "Python", "latency_ms": 1715.022087097168, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "Python", "latency_ms": 960.7429504394531, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3616}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 1363.6047840118408, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ice", "latency_ms": 1444.4677829742432, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "water-ice", "latency_ms": 2338.1946086883545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "water-ice", "latency_ms": 2322.442054748535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "water-ice", "latency_ms": 2382.3561668395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2422}, "5": {"k": 5, "answer": "water-ice", "latency_ms": 2238.511562347412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3037}, "6": {"k": 6, "answer": "water-ice", "latency_ms": 1747.5800514221191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3686}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22", "latency_ms": 3749.101161956787, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Not in season 2.", "latency_ms": 3592.587471008301, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "The Departed episode", "latency_ms": 2655.869483947754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "The Departed episode", "latency_ms": 2776.1902809143066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "The Departed episode", "latency_ms": 2682.7704906463623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2403}, "5": {"k": 5, "answer": "Season 3 finale", "latency_ms": 2464.801788330078, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2999}, "6": {"k": 6, "answer": "Season 3 finale", "latency_ms": 2083.554267883301, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3599}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "Home team", "latency_ms": 2012.7222537994385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2963.001012802124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "Premier League clubs", "latency_ms": 3265.072822570801, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1184}, "3": {"k": 3, "answer": "Premier League clubs", "latency_ms": 2415.990114212036, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1765}, "4": {"k": 4, "answer": "The team named first", "latency_ms": 2176.168441772461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2352}, "5": {"k": 5, "answer": "Premier League clubs", "latency_ms": 2099.4880199432373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2942}, "6": {"k": 6, "answer": "Premier League clubs", "latency_ms": 2355.2780151367188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3561}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw neighborhood", "latency_ms": 2580.7976722717285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northwest", "latency_ms": 2461.5654945373535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "Northwest", "latency_ms": 2086.751699447632, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Northwest", "latency_ms": 1800.5907535552979, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "Northwest Washington, DC", "latency_ms": 2742.3839569091797, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2831}, "5": {"k": 5, "answer": "Northwest Washington, DC", "latency_ms": 3226.939916610718, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3491}, "6": {"k": 6, "answer": "Northwest Washington, DC", "latency_ms": 2747.176170349121, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 4153}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 2505.6111812591553, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3029.6473503112793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Mosaic covenant", "latency_ms": 2415.618419647217, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Noahic", "latency_ms": 2969.2068099975586, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1878}, "4": {"k": 4, "answer": "Noahic", "latency_ms": 2188.746452331543, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Noahic", "latency_ms": 2421.656608581543, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3188}, "6": {"k": 6, "answer": "Noahic", "latency_ms": 2137.240171432495, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3744}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 2365.4255867004395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3083.6751461029053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3113.9745712280273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1164}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2911.064386367798, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1761}, "4": {"k": 4, "answer": "a singer", "latency_ms": 1822.932243347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2334}, "5": {"k": 5, "answer": "a singer", "latency_ms": 1733.9696884155273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2914}, "6": {"k": 6, "answer": "a singer", "latency_ms": 1587.1717929840088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3512}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2544.6393489837646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rudy Vallée", "latency_ms": 2129.063606262207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "Rudy Vallée", "latency_ms": 2452.2652626037598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "Rudy Vallée", "latency_ms": 2397.557497024536, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1793}, "4": {"k": 4, "answer": "Rudy Vallée", "latency_ms": 3302.0858764648438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2437}, "5": {"k": 5, "answer": "Rudy Vallée", "latency_ms": 2040.5704975128174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3088}, "6": {"k": 6, "answer": "Rudy Vallée", "latency_ms": 2153.258800506592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3682}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 1579.836368560791, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 1514.93239402771, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 1760.371208190918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 1794.4791316986084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 1404.6835899353027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 1487.6577854156494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3176}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 2066.1356449127197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3827}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "Second", "latency_ms": 701.3254165649414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "50 million", "latency_ms": 1805.3851127624512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 713}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2398.7245559692383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1332}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2743.995189666748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2866.5761947631836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2648.972749710083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3466.388702392578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 1873.368501663208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mahatma Gandhi", "latency_ms": 2906.363010406494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 706}, "2": {"k": 2, "answer": "Sonia Gandhi", "latency_ms": 2294.1813468933105, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1380}, "3": {"k": 3, "answer": "Sonia Gandhi", "latency_ms": 3157.841682434082, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2102}, "4": {"k": 4, "answer": "Sonia Gandhi", "latency_ms": 2104.3007373809814, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2798}, "5": {"k": 5, "answer": "Jawaharlal Nehru", "latency_ms": 3474.0607738494873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3473}, "6": {"k": 6, "answer": "Jawaharlal Nehru", "latency_ms": 4150.491237640381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4183}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenae Anderson", "latency_ms": 1680.1502704620361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bobby Flay", "latency_ms": 2666.593551635742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Bobby Flay", "latency_ms": 2363.5878562927246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "Bobby Flay", "latency_ms": 2435.7199668884277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Bobby Flay", "latency_ms": 2701.5113830566406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2536}, "5": {"k": 5, "answer": "Bobby Flay", "latency_ms": 2650.007486343384, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3144}, "6": {"k": 6, "answer": "Bobby Flay", "latency_ms": 2472.7261066436768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 936.4748001098633, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 1723.6194610595703, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": ".java", "latency_ms": 1699.641466140747, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": ".java", "latency_ms": 1160.2208614349365, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": ".java", "latency_ms": 1379.103183746338, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": ".java", "latency_ms": 966.7243957519531, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": ".java", "latency_ms": 1950.1996040344238, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3815}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 1521.9988822937012, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Polish Cipher Bureau", "latency_ms": 3222.6431369781494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Polish Cipher Bureau", "latency_ms": 3013.430595397949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Poland", "latency_ms": 1935.6811046600342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "Poland, Britain, and France", "latency_ms": 3638.7860774993896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2669}, "5": {"k": 5, "answer": "Poland, Britain, and France", "latency_ms": 4053.3783435821533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3396}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 1270.8544731140137, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4068}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline", "latency_ms": 2568.373918533325, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to offer promotion or threaten demotion", "latency_ms": 3852.51522064209, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "ensure members adhere to party policies", "latency_ms": 3803.9698600769043, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "ensure members adhere to party policies", "latency_ms": 3034.2371463775635, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "ensure members adhere to party policies", "latency_ms": 3387.221097946167, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 2586}, "5": {"k": 5, "answer": "ensure members adhere to party policies", "latency_ms": 2754.0085315704346, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 3310}, "6": {"k": 6, "answer": "ensure members adhere to party policies", "latency_ms": 3133.9356899261475, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 4003}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 2101.012706756592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3404.658555984497, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "1978", "latency_ms": 1803.2093048095703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "1973", "latency_ms": 2069.244384765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1773}, "4": {"k": 4, "answer": "1973", "latency_ms": 1505.3808689117432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "1973", "latency_ms": 1029.5920372009277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "1973", "latency_ms": 1329.0464878082275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3801}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the​ right but not the​ obligation to buy foreign​ currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 2272.1028327941895, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 1755.028247833252, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 2278.022289276123, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 2050.4379272460938, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "FX option", "latency_ms": 2285.6669425964355, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2671}, "5": {"k": 5, "answer": "Call option", "latency_ms": 2067.343235015869, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "FX option", "latency_ms": 2298.201084136963, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3889}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 535.2277755737305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 1540.2791500091553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360 members", "latency_ms": 2011.5301609039307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1380}, "3": {"k": 3, "answer": "360", "latency_ms": 1371.7968463897705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2035}, "4": {"k": 4, "answer": "360 members", "latency_ms": 1544.7287559509277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "360 members", "latency_ms": 1524.4238376617432, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3315}, "6": {"k": 6, "answer": "360", "latency_ms": 1659.3594551086426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4009}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 1721.9631671905518, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 2316.282033920288, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 2845.3876972198486, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 2226.386547088623, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 2469.752550125122, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 2018.8777446746826, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3224}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 3146.43931388855, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3892}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gormé"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 2793.1108474731445, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eydie Gormé", "latency_ms": 3049.156427383423, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 580}, "2": {"k": 2, "answer": "Eydie Gormé", "latency_ms": 2671.5054512023926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1156}, "3": {"k": 3, "answer": "Eydie Gormé", "latency_ms": 3022.8638648986816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1733}, "4": {"k": 4, "answer": "Eydie Gormé", "latency_ms": 2757.542610168457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2334}, "5": {"k": 5, "answer": "Eydie Gormé", "latency_ms": 2486.2723350524902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2899}, "6": {"k": 6, "answer": "Eydie Gormé", "latency_ms": 2204.615354537964, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3505}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1769.5717811584473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "H.L. Dattu", "latency_ms": 3433.7315559387207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "H.L. Dattu", "latency_ms": 3783.708333969116, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "H.L. Dattu", "latency_ms": 3532.5422286987305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1746}, "4": {"k": 4, "answer": "K. M. Joseph", "latency_ms": 3602.418899536133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2303}, "5": {"k": 5, "answer": "K. M. Joseph", "latency_ms": 2518.2838439941406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2867}, "6": {"k": 6, "answer": "K. M. Joseph", "latency_ms": 3450.6258964538574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3435}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 3489.0670776367188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nadal", "latency_ms": 2586.360216140747, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 576}, "2": {"k": 2, "answer": "Rafael Nadal", "latency_ms": 2293.135166168213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "Rafael Nadal", "latency_ms": 2530.8549404144287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "Rafael Nadal", "latency_ms": 3473.679304122925, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2490}, "5": {"k": 5, "answer": "Rafael Nadal", "latency_ms": 3671.110153198242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3076}, "6": {"k": 6, "answer": "Rafael Nadal", "latency_ms": 2833.6527347564697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3697}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 1472.951889038086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 1814.4595623016357, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 1215.2488231658936, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1215}, "3": {"k": 3, "answer": "1", "latency_ms": 1195.211410522461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "1", "latency_ms": 1434.399127960205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2442}, "5": {"k": 5, "answer": "1", "latency_ms": 1468.8220024108887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3025}, "6": {"k": 6, "answer": "1", "latency_ms": 1928.5967350006104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3624}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 1241.758108139038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2010", "latency_ms": 1538.4790897369385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "2010", "latency_ms": 1244.6894645690918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1304}, "3": {"k": 3, "answer": "2010", "latency_ms": 1488.0409240722656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "2010", "latency_ms": 1024.6176719665527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2522}, "5": {"k": 5, "answer": "2010", "latency_ms": 1217.0145511627197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3047}, "6": {"k": 6, "answer": "2010", "latency_ms": 1796.9205379486084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3736}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 1239.7141456604004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2638.5393142700195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "17", "latency_ms": 1700.5982398986816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "17", "latency_ms": 1176.2959957122803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "37", "latency_ms": 1020.6007957458496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "37", "latency_ms": 2055.147886276245, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "37", "latency_ms": 566.8485164642334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3818}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 3361.086368560791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 2749.799966812134, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 3222.843647003174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 3349.3261337280273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 2213.4721279144287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2502}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 3203.4170627593994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 3651.8306732177734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3804}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 4770.391941070557, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 2099.818229675293, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "Corey, Cory", "latency_ms": 2849.285364151001, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1192}, "3": {"k": 3, "answer": "Corey, Cory", "latency_ms": 2385.1776123046875, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "Corey, Cory", "latency_ms": 2588.352918624878, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2429}, "5": {"k": 5, "answer": "Corey, Cory", "latency_ms": 2632.4052810668945, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3018}, "6": {"k": 6, "answer": "Corey, Cory", "latency_ms": 2468.7628746032715, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3649}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 2038.6695861816406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Randy Houser", "latency_ms": 2843.6858654022217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2487.6060485839844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1203}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2931.8580627441406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3703.327417373657, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2934.443473815918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3069}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2641.343593597412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3781}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 1465.087890625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 946.6147422790527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "159", "latency_ms": 1184.4372749328613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "159", "latency_ms": 1966.6643142700195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "159", "latency_ms": 1347.0771312713623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2738}, "5": {"k": 5, "answer": "159", "latency_ms": 1396.7702388763428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3443}, "6": {"k": 6, "answer": "159", "latency_ms": 1725.9554862976074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4092}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 2222.5329875946045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2658.1320762634277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "Egan", "latency_ms": 1776.9694328308105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "Egan", "latency_ms": 2042.2959327697754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1797}, "4": {"k": 4, "answer": "Egan", "latency_ms": 1817.5408840179443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2433}, "5": {"k": 5, "answer": "Egan", "latency_ms": 2062.7663135528564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3107}, "6": {"k": 6, "answer": "Egan", "latency_ms": 2037.2052192687988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3720}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 1706.3140869140625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wilt Chamberlain", "latency_ms": 2083.808660507202, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Wilt Chamberlain", "latency_ms": 2362.764835357666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1184}, "3": {"k": 3, "answer": "Wilt Chamberlain", "latency_ms": 2632.791042327881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1782}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2079.3468952178955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2375}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2680.067777633667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3043}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2238.5263442993164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3625}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 1931.5516948699951, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Right hand", "latency_ms": 943.4463977813721, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 1384.9296569824219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1185}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 1426.1388778686523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1739}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 1345.5827236175537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2303}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 1422.055959701538, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2911}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 1593.1224822998047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3525}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 2199.7199058532715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Donald Duck", "latency_ms": 1579.3139934539795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Donald Duck", "latency_ms": 1519.975185394287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Donald Duck", "latency_ms": 2334.3241214752197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1945}, "4": {"k": 4, "answer": "Donald Duck", "latency_ms": 783.8397026062012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2560}, "5": {"k": 5, "answer": "Donald Duck", "latency_ms": 2298.7022399902344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3212}, "6": {"k": 6, "answer": "Donald Duck", "latency_ms": 2070.1208114624023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3839}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 2190.1965141296387, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1907.646656036377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "Bernard Mayes", "latency_ms": 2732.290744781494, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2729.724645614624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Bernard Mayes", "latency_ms": 2434.701681137085, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Bernard Mayes", "latency_ms": 3593.977212905884, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "Bernard Mayes", "latency_ms": 2001.8954277038574, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3721}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2019", "latency_ms": 3811.5901947021484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2018", "latency_ms": 2809.2658519744873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 3584.818124771118, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 4909.012794494629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 4151.187896728516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2414}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 3947.2146034240723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3044}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 1868.4651851654053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3640}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 1695.8081722259521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2441.650390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2430.09877204895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2396.390914916992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2498.25382232666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1930.3677082061768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1913.1147861480713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3868}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 1272.907018661499, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2515.2878761291504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "Claire Holt", "latency_ms": 2820.5556869506836, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1251}, "3": {"k": 3, "answer": "Claire Holt", "latency_ms": 1639.406681060791, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Claire Holt", "latency_ms": 2428.184747695923, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Claire Holt", "latency_ms": 2196.645975112915, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3150}, "6": {"k": 6, "answer": "Claire Holt", "latency_ms": 1850.1918315887451, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3764}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living things", "latency_ms": 1845.2515602111816, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in wood or soil", "latency_ms": 2469.3143367767334, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 705}, "2": {"k": 2, "answer": "in wood, soil, plants, and living organisms", "latency_ms": 4889.817476272583, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "in wood, soil, plants, and animals", "latency_ms": 4843.119144439697, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "in plants, soil, and organisms", "latency_ms": 4154.005289077759, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2760}, "5": {"k": 5, "answer": "in plants, soil, and organisms", "latency_ms": 3898.0982303619385, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3383}, "6": {"k": 6, "answer": "in plants, soil, and organisms", "latency_ms": 4580.941915512085, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 4085}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1733.5278987884521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chandan Shetty", "latency_ms": 2757.7924728393555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "Chandan Shetty", "latency_ms": 2480.449914932251, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Chandan Shetty", "latency_ms": 2810.4782104492188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "Chandan Shetty", "latency_ms": 2987.431049346924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2509}, "5": {"k": 5, "answer": "Chandan Shetty", "latency_ms": 2685.488700866699, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3122}, "6": {"k": 6, "answer": "Chandan Shetty", "latency_ms": 1869.7795867919922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3723}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 2630.7554244995117, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2592.787027359009, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1694.9043273925781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2600.368022918701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2606.9462299346924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2493}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2186.896562576294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3126}, "6": {"k": 6, "answer": "Lake Powell", "latency_ms": 1502.0673274993896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3779}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 2101.5772819519043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jesper Klein", "latency_ms": 870.8007335662842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1346.2138175964355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3095.3900814056396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1875}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2118.3526515960693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2666.944742202759, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3225}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2872.84255027771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3855}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Lake Winnipeg", "latency_ms": 2238.73233795166, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 3218.855619430542, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Rocky Mountains to Lake Winnipeg", "latency_ms": 4176.930665969849, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 3043.4789657592773, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 3074.312925338745, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2698}, "5": {"k": 5, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 3979.212760925293, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3345}, "6": {"k": 6, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 2591.6426181793213, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3989}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 1557.2013854980469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 2175.8952140808105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome", "latency_ms": 1256.1259269714355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Rome, Italy", "latency_ms": 2687.47615814209, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1893}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 2548.9587783813477, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2522}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 2178.6582469940186, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3096}, "6": {"k": 6, "answer": "Rome", "latency_ms": 1725.921392440796, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3697}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "Measurement mark", "latency_ms": 1501.718521118164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "manufacturing company or site", "latency_ms": 3190.4447078704834, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "the manufacturing company or site", "latency_ms": 3034.534215927124, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1255}, "3": {"k": 3, "answer": "manufacturing company or site", "latency_ms": 2523.493528366089, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "the manufacturing company or site", "latency_ms": 2967.6170349121094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2500}, "5": {"k": 5, "answer": "the manufacturing company or site", "latency_ms": 3237.2336387634277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3104}, "6": {"k": 6, "answer": "the manufacturing company or site", "latency_ms": 3265.8185958862305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3725}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia", "latency_ms": 1854.4421195983887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 3749.5436668395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 3857.394218444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1352}, "3": {"k": 3, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 4744.799375534058, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1952}, "4": {"k": 4, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 4849.24578666687, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2562}, "5": {"k": 5, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 5259.572267532349, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3175}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 3836.824655532837, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3848}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Boy Meets Girl", "latency_ms": 2097.2626209259033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 2262.0999813079834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "1988", "latency_ms": 1741.0695552825928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "1988", "latency_ms": 1718.684196472168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1785}, "4": {"k": 4, "answer": "1988", "latency_ms": 2031.0912132263184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2388}, "5": {"k": 5, "answer": "1988", "latency_ms": 2021.623134613037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3045}, "6": {"k": 6, "answer": "1988", "latency_ms": 1575.1070976257324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3669}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 1722.3215103149414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tute", "latency_ms": 1774.9738693237305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "Tute", "latency_ms": 1758.5945129394531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1155}, "3": {"k": 3, "answer": "Truco", "latency_ms": 2020.0366973876953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1754}, "4": {"k": 4, "answer": "Truco", "latency_ms": 1501.0981559753418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2355}, "5": {"k": 5, "answer": "Truco", "latency_ms": 1758.9738368988037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3018}, "6": {"k": 6, "answer": "Truco", "latency_ms": 1717.9522514343262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3591}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 2927.532434463501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Five percent", "latency_ms": 1824.7582912445068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "2% to 16%", "latency_ms": 3263.2524967193604, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "2% to 16%", "latency_ms": 2769.592046737671, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 3531.432867050171, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2533}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 1886.4853382110596, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3238}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 2677.2711277008057, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3867}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 1986.727237701416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1975", "latency_ms": 1733.7665557861328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "1975", "latency_ms": 1235.5718612670898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1185}, "3": {"k": 3, "answer": "1975", "latency_ms": 2012.0213031768799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1790}, "4": {"k": 4, "answer": "1975", "latency_ms": 1419.3081855773926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2368}, "5": {"k": 5, "answer": "1975", "latency_ms": 1405.383586883545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3067}, "6": {"k": 6, "answer": "1975", "latency_ms": 1743.6397075653076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3648}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 1481.215476989746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2882.7385902404785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2102.1478176116943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Lionel Richie", "latency_ms": 2916.0728454589844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 2799.799680709839, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 2220.1151847839355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3084}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 3412.480592727661, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3678}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert", "latency_ms": 1494.107723236084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Leonard Calvert", "latency_ms": 2636.1396312713623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 688}, "2": {"k": 2, "answer": "Leonard Calvert", "latency_ms": 3189.810276031494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1339}, "3": {"k": 3, "answer": "Cecilius Calvert", "latency_ms": 3745.988607406616, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1949}, "4": {"k": 4, "answer": "Lord Baltimore's first settlers and his younger brother Leonard Calvert", "latency_ms": 5342.4413204193115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "Lord Baltimore's first settlers, including Leonard Calvert", "latency_ms": 3999.734878540039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "Lord Baltimore and his brother Leonard Calvert", "latency_ms": 3905.92098236084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3951}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 1545.4695224761963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiger Woods", "latency_ms": 1889.0626430511475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Tiger Woods", "latency_ms": 2302.5028705596924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Tiger Woods", "latency_ms": 1535.6807708740234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1929}, "4": {"k": 4, "answer": "Tiger Woods", "latency_ms": 1732.1910858154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2540}, "5": {"k": 5, "answer": "Tiger Woods", "latency_ms": 2015.3281688690186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "Tiger Woods", "latency_ms": 1493.8697814941406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3891}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 1972.1722602844238, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2393.503427505493, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "200 to 500 mg", "latency_ms": 2944.666862487793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg", "latency_ms": 2438.185930252075, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "200 to 500 mg", "latency_ms": 2689.2290115356445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2466}, "5": {"k": 5, "answer": "200 to 500 mg", "latency_ms": 2464.946985244751, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3126}, "6": {"k": 6, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 3788.2256507873535, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3753}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 3048.31600189209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham", "latency_ms": 2096.7514514923096, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 2091.398000717163, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1166}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 1581.2363624572754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1758}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 1593.6877727508545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2277}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 2038.4471416473389, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2837}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 2613.7514114379883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3435}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 1849.8485088348389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hotel beverage rooms", "latency_ms": 2459.5112800598145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 685}, "2": {"k": 2, "answer": "hotel beverage rooms", "latency_ms": 2532.078742980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1360}, "3": {"k": 3, "answer": "hotel beverage rooms", "latency_ms": 1784.4665050506592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2081}, "4": {"k": 4, "answer": "hotel beverage rooms", "latency_ms": 2125.383138656616, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2799}, "5": {"k": 5, "answer": "hotel beverage rooms", "latency_ms": 2566.67160987854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3421}, "6": {"k": 6, "answer": "hotel beverage rooms", "latency_ms": 3058.147668838501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4097}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh", "latency_ms": 1759.5200538635254, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 3126.9054412841797, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 2912.895679473877, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1372}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 2434.6871376037598, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2057}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 2429.455280303955, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 2414.865255355835, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3433}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 2426.1491298675537, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4062}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 1571.1030960083008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2465.4319286346436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "Bray Wyatt", "latency_ms": 1839.0014171600342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "Bray Wyatt", "latency_ms": 2118.163824081421, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "Bray Wyatt", "latency_ms": 1512.199878692627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Bray Wyatt", "latency_ms": 1547.2137928009033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3274}, "6": {"k": 6, "answer": "Bray Wyatt", "latency_ms": 1288.0949974060059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3935}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 2333.601713180542, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Southport, North Carolina", "latency_ms": 2174.5474338531494, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Southport, North Carolina.", "latency_ms": 2796.0476875305176, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Southport, North Carolina.", "latency_ms": 4038.7654304504395, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Southport, North Carolina.", "latency_ms": 3547.2469329833984, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "Southport, North Carolina", "latency_ms": 2787.672519683838, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3074}, "6": {"k": 6, "answer": "Southport, North Carolina", "latency_ms": 2407.2229862213135, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3695}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 2185.253858566284, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sylvia F. Porter", "latency_ms": 3795.4800128936768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "Sylvia F. Porter", "latency_ms": 2333.5111141204834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Sylvia F. Porter", "latency_ms": 3563.356399536133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1979}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 3743.594169616699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2617}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 3251.3644695281982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3298}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 3156.7840576171875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3907}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 1803.917646408081, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 1438.279390335083, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 704}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 1825.5691528320312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1441}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 3088.0630016326904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2157}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 2456.5699100494385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2828}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 2439.1345977783203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3536}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 1865.7054901123047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4209}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 528.1205177307129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 1756.7756175994873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "Max", "latency_ms": 1146.4519500732422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Max", "latency_ms": 1208.2526683807373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1875}, "4": {"k": 4, "answer": "Max", "latency_ms": 2239.8271560668945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Max", "latency_ms": 693.6755180358887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Max", "latency_ms": 2480.0539016723633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 2483.107805252075, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2924.729347229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1935.9395503997803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Megan Follows", "latency_ms": 2176.8646240234375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Megan Follows", "latency_ms": 1841.7963981628418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "Megan Follows", "latency_ms": 2700.1609802246094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "Megan Follows", "latency_ms": 2371.854543685913, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3695}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "World's Fair in Paris.", "latency_ms": 3876.574754714966, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Exposition Universelle", "latency_ms": 1899.479627609253, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 703}, "2": {"k": 2, "answer": "Exposition Universelle", "latency_ms": 2941.986560821533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "Exposition Universelle", "latency_ms": 2404.948949813843, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Exposition Universelle", "latency_ms": 3013.376474380493, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2560}, "5": {"k": 5, "answer": "Exposition Universelle", "latency_ms": 2422.2326278686523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "Exposition Universelle", "latency_ms": 2972.9244709014893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3845}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 1645.7159519195557, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Brisbane Roar's theme song", "latency_ms": 3474.964141845703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 2740.96417427063, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Empowerment", "latency_ms": 1343.7485694885254, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Empowerment", "latency_ms": 3306.9169521331787, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2580}, "5": {"k": 5, "answer": "Empowerment", "latency_ms": 2148.219585418701, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3162}, "6": {"k": 6, "answer": "Empowerment", "latency_ms": 2581.2976360321045, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3787}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 1714.3669128417969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "National Football League franchises", "latency_ms": 2898.3795642852783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "National Football League franchises", "latency_ms": 1841.8066501617432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "National Football League franchises", "latency_ms": 2383.2290172576904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1849}, "4": {"k": 4, "answer": "National Football League franchises", "latency_ms": 3368.319511413574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2481}, "5": {"k": 5, "answer": "National Football League franchises", "latency_ms": 3109.4892024993896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "National Football League franchises", "latency_ms": 2300.2829551696777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3673}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 2680.7520389556885, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2478.0752658843994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1916.0828590393066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1992.1016693115234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2864.100217819214, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2551}, "5": {"k": 5, "answer": "James Marshall", "latency_ms": 1000.6296634674072, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "James Marshall", "latency_ms": 2452.2836208343506, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3792}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 1348.06227684021, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 2374.238967895508, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 1907.8927040100098, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 1512.8061771392822, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 1501.9607543945312, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 2529.205560684204, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 2341.604471206665, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2985.2445125579834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2177.7257919311523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1872.0929622650146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1933.7317943572998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "All five ski jumping gold medals.", "latency_ms": 3618.4511184692383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "All five ski jumping gold medals.", "latency_ms": 3473.4978675842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3078}, "6": {"k": 6, "answer": "All five ski jumping gold medals.", "latency_ms": 3202.394485473633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3765}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3194.255590438843, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4347.2795486450195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4702.7223110198975, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4587.129354476929, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 5988.702774047852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2596}, "5": {"k": 5, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 5751.706838607788, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3271}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4171.855211257935, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3942}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 1773.6930847167969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central Germany", "latency_ms": 1850.7099151611328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Central Germany", "latency_ms": 1627.4452209472656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Central Germany", "latency_ms": 2034.7378253936768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Central Germany", "latency_ms": 1246.563196182251, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2634}, "5": {"k": 5, "answer": "Central European", "latency_ms": 2045.9487438201904, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3279}, "6": {"k": 6, "answer": "Central European cultures", "latency_ms": 2241.35422706604, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3933}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 1605.255126953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 2343.6381816864014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 1946.3810920715332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 1994.241714477539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "post-medieval era", "latency_ms": 2462.6357555389404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "1648–1651", "latency_ms": 2241.3575649261475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3212}, "6": {"k": 6, "answer": "1648–1651", "latency_ms": 3160.8712673187256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3847}}}
