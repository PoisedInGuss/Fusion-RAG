{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1724.0328788757324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 22, 2018", "latency_ms": 2969.7861671447754, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "June 22, 2018", "latency_ms": 3576.3227939605713, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "June 22, 2018", "latency_ms": 2202.523946762085, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "June 22, 2018", "latency_ms": 3586.06219291687, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 3533.5328578948975, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "June 22, 2018", "latency_ms": 3238.370656967163, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3818}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Freestyle, Nordic Combined, Ski Jumping, Biathlon.", "latency_ms": 8246.028900146484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alpine skiing", "latency_ms": 2078.9387226104736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Alpine, Freestyle", "latency_ms": 2977.5753021240234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Alpine, Freestyle", "latency_ms": 2155.5967330932617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 2963.736057281494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 3139.2195224761963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3268}, "6": {"k": 6, "answer": "Alpine, Freestyle, Cross-country", "latency_ms": 4440.764427185059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3935}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "Arianwen Parkes-Lockwood", "latency_ms": 4359.855175018311, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Aldo Mignone", "latency_ms": 2914.5617485046387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 694}, "2": {"k": 2, "answer": "Aldo Mignone", "latency_ms": 3675.215244293213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Aldo Mignone", "latency_ms": 4096.652984619141, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Aldo Mignone", "latency_ms": 3608.640193939209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2564}, "5": {"k": 5, "answer": "Aldo Mignone", "latency_ms": 3577.7506828308105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3137}, "6": {"k": 6, "answer": "Aldo Mignone", "latency_ms": 2261.3253593444824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3751}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "Bengals, Dolphins, Broncos, Chargers", "latency_ms": 4678.456544876099, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Giants", "latency_ms": 2588.847875595093, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "Chargers", "latency_ms": 2571.5222358703613, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1170}, "3": {"k": 3, "answer": "Miami Dolphins, San Diego Chargers", "latency_ms": 2577.665328979492, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 1819}, "4": {"k": 4, "answer": "Miami Dolphins, San Diego Chargers", "latency_ms": 3116.797924041748, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 2417}, "5": {"k": 5, "answer": "Miami Dolphins, San Diego Chargers", "latency_ms": 2776.6761779785156, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 2970}, "6": {"k": 6, "answer": "Miami Dolphins, San Diego Chargers", "latency_ms": 4372.658014297485, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 3547}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "December 8, 1985", "latency_ms": 3657.5241088867188, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 December 1985", "latency_ms": 3203.401803970337, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 727}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 2889.389753341675, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1447}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 3184.154987335205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2148}, "4": {"k": 4, "answer": "8 December 1985", "latency_ms": 2727.1125316619873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2845}, "5": {"k": 5, "answer": "8 December 1985", "latency_ms": 3595.8898067474365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3541}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 3270.399332046509, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4247}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "Spanish moss", "latency_ms": 2069.4408416748047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spanish moss", "latency_ms": 2300.5475997924805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "Spanish moss", "latency_ms": 1433.837652206421, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Spanish moss", "latency_ms": 2269.150733947754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Spanish moss", "latency_ms": 2263.3273601531982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2678}, "5": {"k": 5, "answer": "Spanish moss", "latency_ms": 1671.6225147247314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3289}, "6": {"k": 6, "answer": "Spanish moss", "latency_ms": 1560.5792999267578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4000}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "I-IV", "latency_ms": 1618.5898780822754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Heart Association Functional Classification", "latency_ms": 2777.5845527648926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 754}, "2": {"k": 2, "answer": "New York Heart Association Functional Classification", "latency_ms": 3032.5863361358643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1453}, "3": {"k": 3, "answer": "New York Heart Association Functional Classification", "latency_ms": 3956.9811820983887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2217}, "4": {"k": 4, "answer": "New York Heart Association Functional Classification", "latency_ms": 2949.390172958374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2949}, "5": {"k": 5, "answer": "New York Heart Association Functional Classification", "latency_ms": 2478.7750244140625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}, "6": {"k": 6, "answer": "New York Heart Association Functional Classification", "latency_ms": 1994.1442012786865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4447}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Mick Hucknall and Neil Moss", "latency_ms": 3479.3317317962646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2218.7857627868652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2660.459041595459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2133.345365524292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2186.412572860718, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2453}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1971.9293117523193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "Eurythmics", "latency_ms": 1998.2810020446777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3680}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 496.8104362487793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 1149.385929107666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "3", "latency_ms": 657.0429801940918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "3", "latency_ms": 1156.665325164795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "3", "latency_ms": 948.3797550201416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2490}, "5": {"k": 5, "answer": "3", "latency_ms": 943.0868625640869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "3", "latency_ms": 1442.5501823425293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3725}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "A cake.", "latency_ms": 1616.7259216308594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Biscuit-sized cakes", "latency_ms": 2180.5849075317383, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "cake", "latency_ms": 683.1672191619873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "cake", "latency_ms": 1468.6880111694336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1764}, "4": {"k": 4, "answer": "A cake", "latency_ms": 1949.420690536499, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "A cake", "latency_ms": 974.7769832611084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3040}, "6": {"k": 6, "answer": "A cake.", "latency_ms": 1851.4482975006104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Seth MacFarlane", "latency_ms": 1650.3729820251465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seth MacFarlane", "latency_ms": 2655.5378437042236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Seth MacFarlane", "latency_ms": 2665.3993129730225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Seth MacFarlane", "latency_ms": 2197.7620124816895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1913}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 2684.9215030670166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2554}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 2162.520408630371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 2903.313398361206, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3844}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "Heroin", "latency_ms": 2013.4389400482178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amphetamines", "latency_ms": 1864.905834197998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Amphetamines", "latency_ms": 1259.6275806427002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1186}, "3": {"k": 3, "answer": "Amphetamines", "latency_ms": 1798.8452911376953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1805}, "4": {"k": 4, "answer": "Amphetamines", "latency_ms": 1913.830041885376, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2447}, "5": {"k": 5, "answer": "Amphetamines", "latency_ms": 2081.6783905029297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3084}, "6": {"k": 6, "answer": "Amphetamines", "latency_ms": 2108.583688735962, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "14 weeks", "latency_ms": 1263.2672786712646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2287.071466445923, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 571}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2135.7741355895996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "Not stated", "latency_ms": 932.1801662445068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1765}, "4": {"k": 4, "answer": "Not specified", "latency_ms": 1768.2418823242188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2320}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2137.7689838409424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2888}, "6": {"k": 6, "answer": "1 week", "latency_ms": 2046.2727546691895, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3456}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "Yushan, China", "latency_ms": 1202.6991844177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haikou, China", "latency_ms": 3105.959415435791, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "Haikou, China", "latency_ms": 2957.0486545562744, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1255}, "3": {"k": 3, "answer": "Haikou, China", "latency_ms": 2699.714183807373, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Yushan, China", "latency_ms": 2041.309118270874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "Yushan, China", "latency_ms": 2788.4960174560547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3085}, "6": {"k": 6, "answer": "Yushan, China", "latency_ms": 2502.2785663604736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3714}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "Thad Luckinbill", "latency_ms": 2963.801860809326, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2356.0895919799805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2245.9466457366943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2225.0523567199707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2473.707914352417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2415.447235107422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3142}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1843.864917755127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3785}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 1788.8245582580566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1983", "latency_ms": 2029.207706451416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "1986", "latency_ms": 1289.93821144104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "1983", "latency_ms": 2031.9514274597168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1922}, "4": {"k": 4, "answer": "1983", "latency_ms": 1245.4547882080078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2597}, "5": {"k": 5, "answer": "1983", "latency_ms": 1858.400821685791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3252}, "6": {"k": 6, "answer": "1983", "latency_ms": 1783.8804721832275, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3909}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "J-Rock", "latency_ms": 1912.3868942260742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alexz Johnson", "latency_ms": 1562.1607303619385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Alexz Johnson", "latency_ms": 2370.601177215576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Alexz Johnson", "latency_ms": 2138.047218322754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Alexz Johnson", "latency_ms": 2388.035535812378, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Alexz Johnson", "latency_ms": 2640.598773956299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3319}, "6": {"k": 6, "answer": "Alexz Johnson", "latency_ms": 2369.840621948242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3980}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "2006", "latency_ms": 1561.6536140441895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 million years ago", "latency_ms": 2866.3148880004883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "June 1995", "latency_ms": 2681.4961433410645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "2.58 million years ago", "latency_ms": 3627.1443367004395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1843}, "4": {"k": 4, "answer": "2.58 million years ago", "latency_ms": 3301.5124797821045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "June 1995", "latency_ms": 2888.580799102783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3114}, "6": {"k": 6, "answer": "June 1995", "latency_ms": 2665.308952331543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3731}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "Master Sergeant", "latency_ms": 1870.3131675720215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Master Sergeant", "latency_ms": 1784.4583988189697, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Master Sergeant", "latency_ms": 1818.8772201538086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1336}, "3": {"k": 3, "answer": "Master Sergeant", "latency_ms": 1221.8492031097412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1903}, "4": {"k": 4, "answer": "Master Sergeant", "latency_ms": 2119.086265563965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2540}, "5": {"k": 5, "answer": "Master Sergeant", "latency_ms": 1484.118938446045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3116}, "6": {"k": 6, "answer": "Master Sergeant", "latency_ms": 1982.203722000122, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3845}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 2717.067003250122, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "GNU project", "latency_ms": 1466.3519859313965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 2061.235189437866, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 2676.4726638793945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 2171.1995601654053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2593}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 2325.826644897461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3276}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 2890.8944129943848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3954}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 3005.9142112731934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2711.151123046875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2640.371799468994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1198}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2945.034980773926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1802}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2350.231885910034, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2401}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2682.1138858795166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3010}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2160.656452178955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3641}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Ed Roland", "latency_ms": 1765.4550075531006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 1523.5376358032227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 2375.0150203704834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 1843.2648181915283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1954}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 2322.3564624786377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2630}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 1270.9553241729736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3316}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 1472.5680351257324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3959}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2931.3180446624756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miami Heat", "latency_ms": 2318.020820617676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 1726.7236709594727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 1614.976406097412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1850}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 2543.2212352752686, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2436}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 2031.2063694000244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3003}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 1885.6778144836426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3602}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1378.5443305969238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Guarani (PYG)", "latency_ms": 4625.377416610718, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "PYG", "latency_ms": 2305.0358295440674, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "PYG", "latency_ms": 2611.440420150757, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "PYG", "latency_ms": 2130.0437450408936, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 2500}, "5": {"k": 5, "answer": "PYG", "latency_ms": 1582.758903503418, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3123}, "6": {"k": 6, "answer": "PYG", "latency_ms": 1353.5456657409668, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3803}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "Midazolam", "latency_ms": 2155.412435531616, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "It is not specified.", "latency_ms": 3027.533531188965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "Benzodiazepines", "latency_ms": 3834.190845489502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Benzodiazepines", "latency_ms": 4170.875310897827, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Benzodiazepines", "latency_ms": 3881.3681602478027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2714}, "5": {"k": 5, "answer": "Benzodiazepines", "latency_ms": 2851.581573486328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3394}, "6": {"k": 6, "answer": "Benzodiazepines", "latency_ms": 4109.368324279785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4040}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 2206.972599029541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "26,000 years", "latency_ms": 2422.881603240967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "26,000 years", "latency_ms": 2422.207832336426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1264}, "3": {"k": 3, "answer": "26,000 years", "latency_ms": 2782.5748920440674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1930}, "4": {"k": 4, "answer": "26,000 years", "latency_ms": 2975.670099258423, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2566}, "5": {"k": 5, "answer": "25,772 years", "latency_ms": 2963.0091190338135, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "25,772 years", "latency_ms": 3150.223970413208, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3819}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 2390.1891708374023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Texas A&M Aggies", "latency_ms": 3208.873748779297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Texas A&M Aggies", "latency_ms": 3599.573850631714, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Texas A&M Aggies", "latency_ms": 2763.669490814209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1946}, "4": {"k": 4, "answer": "Texas A&M Aggies", "latency_ms": 3767.935037612915, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Texas A&M Aggies", "latency_ms": 3017.8465843200684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3187}, "6": {"k": 6, "answer": "Texas A&M Aggies", "latency_ms": 2845.4933166503906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3811}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and Non-Renewable.", "latency_ms": 4237.537384033203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable or non-renewable", "latency_ms": 4162.988662719727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable or non-renewable", "latency_ms": 3631.3350200653076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1447}, "3": {"k": 3, "answer": "renewable or non-renewable", "latency_ms": 3968.925952911377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2207}, "4": {"k": 4, "answer": "renewable or non-renewable", "latency_ms": 4331.554174423218, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2938}, "5": {"k": 5, "answer": "renewable or non-renewable", "latency_ms": 3918.787956237793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3670}, "6": {"k": 6, "answer": "renewable or non-renewable", "latency_ms": 3490.645408630371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4372}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "New life and fertility", "latency_ms": 2428.837537765503, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parental devotion", "latency_ms": 1837.6965522766113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Purity", "latency_ms": 2052.5755882263184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "Purity", "latency_ms": 1945.5337524414062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "Purity", "latency_ms": 1732.4142456054688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2520}, "5": {"k": 5, "answer": "Purity", "latency_ms": 2274.1739749908447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3126}, "6": {"k": 6, "answer": "Purity", "latency_ms": 1513.6752128601074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3769}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Virat Kohli", "latency_ms": 2712.9600048065186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2594.2819118499756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1867.2738075256348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "558", "latency_ms": 1411.3266468048096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1816}, "4": {"k": 4, "answer": "558", "latency_ms": 1534.057855606079, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2421}, "5": {"k": 5, "answer": "558", "latency_ms": 1453.3193111419678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3070}, "6": {"k": 6, "answer": "558", "latency_ms": 1201.0042667388916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "the antimicrobial action of metal ions.", "latency_ms": 2984.7757816314697, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals", "latency_ms": 3104.6578884124756, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "biocidal effect of metals", "latency_ms": 3338.975191116333, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "biocidal effect of metals", "latency_ms": 3459.7537517547607, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2074}, "4": {"k": 4, "answer": "biocidal effect of metals", "latency_ms": 3578.0189037323, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2812}, "5": {"k": 5, "answer": "biocidal effect of metals", "latency_ms": 2564.3856525421143, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3478}, "6": {"k": 6, "answer": "biocidal effect of metals", "latency_ms": 3575.74200630188, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4266}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "Dustin Higgs", "latency_ms": 1962.6142978668213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ted Bundy", "latency_ms": 1827.9032707214355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "Leonard Shockley", "latency_ms": 1927.3154735565186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1201}, "3": {"k": 3, "answer": "Billy Bailey", "latency_ms": 1683.286190032959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1795}, "4": {"k": 4, "answer": "Ted Bundy", "latency_ms": 1746.6340065002441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2422}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2695.690155029297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3027}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2930.086135864258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3641}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the auction.", "latency_ms": 2474.75528717041, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "when they hold two \"touching honors\"", "latency_ms": 4472.704887390137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 580}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 3119.2338466644287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1132}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 3067.9714679718018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1738}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 2694.999933242798, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2310}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 3069.3790912628174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2932}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 2531.4290523529053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3537}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Afghanistan", "latency_ms": 1952.7747631072998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 2586.3099098205566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 699}, "2": {"k": 2, "answer": "Afghanistan", "latency_ms": 1626.2390613555908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Afghanistan", "latency_ms": 2083.5611820220947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2101}, "4": {"k": 4, "answer": "Afghanistan", "latency_ms": 2174.168109893799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2830}, "5": {"k": 5, "answer": "Afghanistan", "latency_ms": 1873.2233047485352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3556}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 1859.3535423278809, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4227}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "Coagulation, Fibrin formation, Clot retraction", "latency_ms": 6142.642498016357, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 5398.512601852417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2518.7885761260986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 6036.244630813599, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2019}, "4": {"k": 4, "answer": "primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 5510.430812835693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2705}, "5": {"k": 5, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 5453.133821487427, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3402}, "6": {"k": 6, "answer": "primary hemostasis, secondary hemostasis, and fibrin cross-linking", "latency_ms": 7560.165643692017, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4123}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "Sebastian Hunsinger", "latency_ms": 3044.3646907806396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shawn Roberts", "latency_ms": 1559.5154762268066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "Shawn Roberts", "latency_ms": 3056.1068058013916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1384}, "3": {"k": 3, "answer": "Sebastian Hedges Thomas", "latency_ms": 2532.3569774627686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2068}, "4": {"k": 4, "answer": "Shawn Roberts", "latency_ms": 3178.197145462036, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2732}, "5": {"k": 5, "answer": "Shawn Roberts", "latency_ms": 1895.20263671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3440}, "6": {"k": 6, "answer": "Shawn Roberts", "latency_ms": 2258.8536739349365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4073}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "20 November 1989", "latency_ms": 2822.885513305664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "20 November 1989", "latency_ms": 2846.0938930511475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 3213.696002960205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1282}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 2921.2512969970703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1877}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 2408.623695373535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2544}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 3226.106882095337, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3211}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 2648.286819458008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3856}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "2016", "latency_ms": 1020.2538967132568, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 2016", "latency_ms": 3370.4757690429688, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "June 2016", "latency_ms": 2146.253824234009, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1346}, "3": {"k": 3, "answer": "June 2016", "latency_ms": 2926.9237518310547, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "June 2016", "latency_ms": 2158.256769180298, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "June 2016", "latency_ms": 2118.126630783081, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "23 June 2016", "latency_ms": 3293.931245803833, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3733}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 2631.6752433776855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Burj Khalifa", "latency_ms": 2682.3832988739014, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 679}, "2": {"k": 2, "answer": "Burj Khalifa", "latency_ms": 2368.813991546631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1360}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 2229.6438217163086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2047}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 1623.0583190917969, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2688}, "5": {"k": 5, "answer": "Burj Khalifa", "latency_ms": 2884.9570751190186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3357}, "6": {"k": 6, "answer": "Burj Khalifa", "latency_ms": 1840.7268524169922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3999}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "Miriam Margolyes", "latency_ms": 2216.0093784332275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2695.897102355957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2496.6673851013184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1735.1233959197998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1979}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2987.6787662506104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2600}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2164.606809616089, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1669.400930404663, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Montesquieu", "latency_ms": 1956.7019939422607, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montesquieu", "latency_ms": 1617.3205375671387, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 1826.4453411102295, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 3008.9111328125, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 2562.188148498535, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2674}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 2400.162935256958, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3375}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 1963.8733863830566, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4002}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Myles Garrett", "latency_ms": 1840.6147956848145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1907.1996212005615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "Myles Garrett", "latency_ms": 2263.9074325561523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Myles Garrett", "latency_ms": 1777.3492336273193, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Myles Garrett", "latency_ms": 2523.6191749572754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2539}, "5": {"k": 5, "answer": "Myles Garrett", "latency_ms": 1767.2545909881592, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3115}, "6": {"k": 6, "answer": "Myles Garrett", "latency_ms": 2162.992477416992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3727}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2063 BS", "latency_ms": 1110.5258464813232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2063 BS", "latency_ms": 1600.8014678955078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1836.8744850158691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1341}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2593.3754444122314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2057}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2749.8903274536133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2693}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1883.821725845337, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3334}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1854.477882385254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4087}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "Captain John Smith", "latency_ms": 2194.2989826202393, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Smith", "latency_ms": 1449.026107788086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 668}, "2": {"k": 2, "answer": "John Smith", "latency_ms": 2026.2832641601562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1301}, "3": {"k": 3, "answer": "John Smith", "latency_ms": 1775.568962097168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1933}, "4": {"k": 4, "answer": "John Smith", "latency_ms": 1288.2792949676514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2561}, "5": {"k": 5, "answer": "John Smith", "latency_ms": 1773.0953693389893, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3211}, "6": {"k": 6, "answer": "John Smith", "latency_ms": 781.0525894165039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3886}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "Parietal cells", "latency_ms": 1363.278865814209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parietal cells", "latency_ms": 1569.8649883270264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 625}, "2": {"k": 2, "answer": "Parietal cells", "latency_ms": 1824.4247436523438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Parietal cells", "latency_ms": 2184.2994689941406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1803}, "4": {"k": 4, "answer": "Parietal cells", "latency_ms": 1888.3004188537598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2404}, "5": {"k": 5, "answer": "Parietal cells", "latency_ms": 3177.8032779693604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3006}, "6": {"k": 6, "answer": "Parietal cells", "latency_ms": 2224.1761684417725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3675}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "Early morning", "latency_ms": 1383.2733631134033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "4 a.m.", "latency_ms": 2597.442388534546, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 2026.756763458252, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "4 a.m.", "latency_ms": 2299.7076511383057, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "4 a.m.", "latency_ms": 2230.3338050842285, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2711}, "5": {"k": 5, "answer": "4 a.m.", "latency_ms": 2909.7909927368164, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3342}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 3178.800582885742, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4006}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 1390.5737400054932, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Idaho", "latency_ms": 957.5042724609375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "Idaho", "latency_ms": 2340.31081199646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Idaho", "latency_ms": 2377.3927688598633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2005}, "4": {"k": 4, "answer": "Idaho", "latency_ms": 1981.7757606506348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2687}, "5": {"k": 5, "answer": "Idaho", "latency_ms": 1493.9799308776855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3311}, "6": {"k": 6, "answer": "Idaho", "latency_ms": 2293.407917022705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3951}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales", "latency_ms": 10415.003299713135, "em": 0.0, "f1": 0.43478260869565216, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2125.822067260742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3101.4997959136963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "2003, 2006, 2007", "latency_ms": 4975.502252578735, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2888.425350189209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2571.9144344329834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2612.462043762207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3853}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 1565.732717514038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "undergone a modulation", "latency_ms": 2242.2831058502197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "modulated", "latency_ms": 1246.1273670196533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "modulated", "latency_ms": 1755.6111812591553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "modulated", "latency_ms": 1278.3474922180176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "modulated", "latency_ms": 2279.0350914001465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3108}, "6": {"k": 6, "answer": "modulated", "latency_ms": 1483.6211204528809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3700}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Male citizens", "latency_ms": 1834.4504833221436, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "full Roman citizens", "latency_ms": 1858.5963249206543, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 637}, "2": {"k": 2, "answer": "Roman citizens", "latency_ms": 1292.6583290100098, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1336}, "3": {"k": 3, "answer": "full Roman citizens", "latency_ms": 1196.4237689971924, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2010}, "4": {"k": 4, "answer": "full Roman citizens", "latency_ms": 2305.2260875701904, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2690}, "5": {"k": 5, "answer": "Roman citizens, patricians and plebeians, adult male citizens.", "latency_ms": 5926.041841506958, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3360}, "6": {"k": 6, "answer": "Roman citizens, including patricians and plebeians, but excluding women, slaves, and children.", "latency_ms": 8034.309148788452, "em": 0.0, "f1": 0.15384615384615385, "containment": 1.0, "context_chars": 4035}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2380.8915615081787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "9 April 2019", "latency_ms": 2989.1326427459717, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "9 April 2019", "latency_ms": 1957.4766159057617, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "9 April 2019", "latency_ms": 2531.830310821533, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "9 April 2019", "latency_ms": 2564.722776412964, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2520}, "5": {"k": 5, "answer": "9 April 2019", "latency_ms": 2524.7013568878174, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "9 April 2019", "latency_ms": 2138.3721828460693, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3804}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "100 parts of blood", "latency_ms": 1946.887493133545, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "volume of blood or mass of blood", "latency_ms": 1797.3332405090332, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "volume of blood or mass of blood", "latency_ms": 3821.8307495117188, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1302}, "3": {"k": 3, "answer": "volume of blood or mass of blood", "latency_ms": 2091.5515422821045, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "volume of blood or mass of blood", "latency_ms": 2856.1112880706787, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "volume of blood or mass of blood", "latency_ms": 2590.310573577881, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3211}, "6": {"k": 6, "answer": "volume of blood or mass of blood", "latency_ms": 1835.3056907653809, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3782}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "Icarus", "latency_ms": 1115.973949432373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Icarus", "latency_ms": 1931.05149269104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "Phaton", "latency_ms": 2135.096311569214, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1365}, "3": {"k": 3, "answer": "Icarus", "latency_ms": 1348.6881256103516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1979}, "4": {"k": 4, "answer": "Icarus", "latency_ms": 1569.7345733642578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2627}, "5": {"k": 5, "answer": "Icarus", "latency_ms": 2140.2862071990967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3199}, "6": {"k": 6, "answer": "Icarus", "latency_ms": 1635.6532573699951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3796}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "September 16, 1979", "latency_ms": 1946.9728469848633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1979", "latency_ms": 1762.6430988311768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "1979", "latency_ms": 778.0523300170898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "1979", "latency_ms": 1830.1477432250977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1875}, "4": {"k": 4, "answer": "1979", "latency_ms": 1555.5245876312256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2443}, "5": {"k": 5, "answer": "1979", "latency_ms": 680.0003051757812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3023}, "6": {"k": 6, "answer": "1979", "latency_ms": 2149.766206741333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3670}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 am", "latency_ms": 1638.6511325836182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2164.9158000946045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "2 April 1986", "latency_ms": 2278.043270111084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "2 April 1986", "latency_ms": 2148.972272872925, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "2 April 1986", "latency_ms": 1518.7923908233643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "2 April 1986", "latency_ms": 2194.422721862793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3251}, "6": {"k": 6, "answer": "2 April 1986", "latency_ms": 2545.9797382354736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3871}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "Tiffany Coyne", "latency_ms": 2693.15505027771, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Carol Merrill", "latency_ms": 1893.0749893188477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Tiffany Coyne", "latency_ms": 2414.216995239258, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 2143.994092941284, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 2386.232852935791, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 1595.5040454864502, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 2568.657636642456, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3701}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "Yankees, Braves, Reds, Giants", "latency_ms": 3559.6437454223633, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5972.584009170532, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5501.817464828491, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5732.19108581543, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1859}, "4": {"k": 4, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5969.857692718506, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2435}, "5": {"k": 5, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5180.196762084961, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3068}, "6": {"k": 6, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 6051.78165435791, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3711}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "2.187 billion dollars", "latency_ms": 2506.654739379883, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$343.4 million", "latency_ms": 2948.4786987304688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "$2 billion", "latency_ms": 2604.046583175659, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "$1.84 billion", "latency_ms": 3614.4278049468994, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "$2 billion", "latency_ms": 2168.9252853393555, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "$2 billion", "latency_ms": 2096.2891578674316, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3208}, "6": {"k": 6, "answer": "$1.84 billion", "latency_ms": 3099.8380184173584, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3814}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2360.6228828430176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2447.2599029541016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2342.913866043091, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "1946", "latency_ms": 1743.067741394043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "1946", "latency_ms": 1996.056318283081, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "1946", "latency_ms": 2119.8949813842773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3131}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1859.3440055847168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3782}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark", "latency_ms": 1855.853796005249, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Norway", "latency_ms": 1530.761957168579, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "Norway", "latency_ms": 1728.855848312378, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Norway", "latency_ms": 2049.7679710388184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1805}, "4": {"k": 4, "answer": "Norway", "latency_ms": 1711.1868858337402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2434}, "5": {"k": 5, "answer": "Norway", "latency_ms": 1763.0627155303955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3035}, "6": {"k": 6, "answer": "Norway", "latency_ms": 1218.4557914733887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3615}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "Prespio", "latency_ms": 1842.8423404693604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Christmas Tree", "latency_ms": 2608.3319187164307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Christmas Tree", "latency_ms": 1832.9243659973145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Christmas Tree", "latency_ms": 1552.3054599761963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Christmas Tree, Nativity scene", "latency_ms": 3453.3517360687256, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Star of Bethlehem", "latency_ms": 1857.4395179748535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3188}, "6": {"k": 6, "answer": "The Star of Bethlehem", "latency_ms": 2208.2979679107666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3810}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "Patrick Swayze", "latency_ms": 1963.2771015167236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Swayze", "latency_ms": 1815.852165222168, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Swayze", "latency_ms": 1814.5241737365723, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Swayze", "latency_ms": 2113.200902938843, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "Swayze", "latency_ms": 2276.954412460327, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Swayze", "latency_ms": 2564.2929077148438, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3181}, "6": {"k": 6, "answer": "Swayze", "latency_ms": 2873.5275268554688, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3787}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Pittsburgh", "latency_ms": 2195.977210998535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3145.066261291504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2416.8355464935303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1314}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2313.326597213745, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1267.6782608032227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3122.563600540161, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3369}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2956.0182094573975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4034}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1704", "latency_ms": 2012.6588344573975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "First Parliament", "latency_ms": 2027.174472808838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "First Parliament", "latency_ms": 1733.1585884094238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "First Parliament", "latency_ms": 2047.8475093841553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2022}, "4": {"k": 4, "answer": "1905", "latency_ms": 1524.5718955993652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2744}, "5": {"k": 5, "answer": "1905", "latency_ms": 1345.1621532440186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3396}, "6": {"k": 6, "answer": "1905", "latency_ms": 1494.816541671753, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4053}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier Fernndez", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Yuzuru Hanyu", "latency_ms": 3705.9905529022217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yuzuru Hanyu", "latency_ms": 4575.079441070557, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Yuzuru Hanyu", "latency_ms": 2521.8255519866943, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Yuzuru Hanyu", "latency_ms": 2745.6791400909424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Yuzuru Hanyu", "latency_ms": 3018.477439880371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2655}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 2640.7294273376465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3335}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 2809.7259998321533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4014}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "Password recovery and cracking.", "latency_ms": 1996.6602325439453, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Password recovery", "latency_ms": 1438.2734298706055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "password recovery", "latency_ms": 1449.1398334503174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1391}, "3": {"k": 3, "answer": "password recovery", "latency_ms": 1734.9281311035156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1996}, "4": {"k": 4, "answer": "Password recovery", "latency_ms": 1786.4704132080078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2581}, "5": {"k": 5, "answer": "Password recovery tool", "latency_ms": 2684.093475341797, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Password recovery tool", "latency_ms": 1840.0287628173828, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3816}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1758.0170631408691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "C. Vidyasagar Rao", "latency_ms": 2874.315023422241, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "C. Vidyasagar Rao", "latency_ms": 2547.858238220215, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 2801.2478351593018, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 2885.420322418213, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "C. Vidyasagar Rao", "latency_ms": 2776.4885425567627, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "C. Vidyasagar Rao", "latency_ms": 2845.219850540161, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3867}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "Channel 15", "latency_ms": 1602.3194789886475, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "15", "latency_ms": 710.1917266845703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 603}, "2": {"k": 2, "answer": "15", "latency_ms": 927.969217300415, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "15", "latency_ms": 1696.4893341064453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1919}, "4": {"k": 4, "answer": "15", "latency_ms": 1502.629280090332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2565}, "5": {"k": 5, "answer": "15", "latency_ms": 1214.6053314208984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3205}, "6": {"k": 6, "answer": "15", "latency_ms": 676.0694980621338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3873}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Claudia Wells", "latency_ms": 1808.2351684570312, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elisabeth Shue", "latency_ms": 2150.040864944458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Claudia Wells", "latency_ms": 2843.125820159912, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "Claudia Wells", "latency_ms": 2374.465227127075, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 2596.082925796509, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2422}, "5": {"k": 5, "answer": "Claudia Wells", "latency_ms": 2416.0397052764893, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "Claudia Wells", "latency_ms": 1713.6216163635254, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3655}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 690.6402111053467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "London, United Kingdom", "latency_ms": 2727.715015411377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 2706.549882888794, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 2788.036823272705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1921}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 2440.826654434204, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2570}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 2483.778476715088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3224}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 2532.8147411346436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3850}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The White House Chef", "latency_ms": 2167.9790019989014, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The White House Executive Chef", "latency_ms": 2965.069532394409, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "The White House Executive Chef", "latency_ms": 3319.181442260742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "The White House Executive Chef", "latency_ms": 2005.0618648529053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2038}, "4": {"k": 4, "answer": "The White House Executive Chef", "latency_ms": 3265.690326690674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2650}, "5": {"k": 5, "answer": "The White House Executive Chef", "latency_ms": 2552.703857421875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "The White House Executive Chef", "latency_ms": 2725.046396255493, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3944}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 1673.1629371643066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2197.6871490478516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2421.5447902679443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Nagendra Singh", "latency_ms": 2710.2651596069336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1876}, "4": {"k": 4, "answer": "B. N. Rao", "latency_ms": 3040.4605865478516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2446}, "5": {"k": 5, "answer": "B. N. Rao", "latency_ms": 2572.726249694824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3070}, "6": {"k": 6, "answer": "B. N. Rao", "latency_ms": 3122.847318649292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3643}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2648.11635017395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "British Columbia", "latency_ms": 2586.120128631592, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "British Columbia", "latency_ms": 1576.8482685089111, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "British Columbia", "latency_ms": 1584.928274154663, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1960}, "4": {"k": 4, "answer": "British Columbia", "latency_ms": 2064.005136489868, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2605}, "5": {"k": 5, "answer": "British Columbia", "latency_ms": 2191.9913291931152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3252}, "6": {"k": 6, "answer": "British Columbia", "latency_ms": 2564.98384475708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3922}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2829.472303390503, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 11, 2018", "latency_ms": 3858.539342880249, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "October 11, 2018", "latency_ms": 3429.7919273376465, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 3131.9739818573, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 3433.373212814331, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2668}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 3170.6113815307617, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3313}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 3077.383041381836, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3934}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Jodie Sweetin", "latency_ms": 2244.4889545440674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jodie Sweetin", "latency_ms": 2428.1797409057617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 652}, "2": {"k": 2, "answer": "Jodie Sweetin", "latency_ms": 2441.3607120513916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Stephanie", "latency_ms": 2285.3341102600098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "Stephanie", "latency_ms": 2601.1064052581787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2553}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2193.140983581543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2384.1445446014404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3762}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "Milennium Tower", "latency_ms": 2190.8369064331055, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Millennium Tower", "latency_ms": 2280.704975128174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 3214.956283569336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1379}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 2247.856378555298, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2031}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 2396.8567848205566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2690}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 2106.6348552703857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3337}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 2344.95210647583, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3994}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 1556.1583042144775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 1806.7073822021484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "2015", "latency_ms": 1219.25950050354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "2015", "latency_ms": 2057.1234226226807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "2015", "latency_ms": 1893.6443328857422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2448}, "5": {"k": 5, "answer": "2015", "latency_ms": 1593.2590961456299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3058}, "6": {"k": 6, "answer": "2015", "latency_ms": 2195.2404975891113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3712}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "John Harlan", "latency_ms": 1143.1198120117188, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Harlan", "latency_ms": 1215.7025337219238, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "Harlan", "latency_ms": 711.646556854248, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Harlan", "latency_ms": 2308.5546493530273, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2074}, "4": {"k": 4, "answer": "Harlan", "latency_ms": 1292.4549579620361, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2772}, "5": {"k": 5, "answer": "Harlan", "latency_ms": 1721.564769744873, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3416}, "6": {"k": 6, "answer": "Harlan", "latency_ms": 2572.360038757324, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 4097}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Tyrann Mathieu", "latency_ms": 2257.1215629577637, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tyrann Mathieu", "latency_ms": 2012.314796447754, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 2494.01593208313, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 2377.6819705963135, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1939}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 4097.352981567383, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2589}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 3649.8780250549316, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3277}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 3037.388563156128, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3916}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "44", "latency_ms": 975.4784107208252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "six", "latency_ms": 2193.7849521636963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "six", "latency_ms": 1724.4045734405518, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Six", "latency_ms": 963.8247489929199, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "six episodes", "latency_ms": 1783.2789421081543, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2698}, "5": {"k": 5, "answer": "Six episodes", "latency_ms": 1508.7809562683105, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3373}, "6": {"k": 6, "answer": "6 episodes", "latency_ms": 2601.2351512908936, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4022}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul Bamer's", "latency_ms": 2262.7999782562256, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Remarque's", "latency_ms": 2602.5216579437256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "German soldiers'", "latency_ms": 2600.924015045166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Erich Maria Remarque", "latency_ms": 3229.0804386138916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1866}, "4": {"k": 4, "answer": "Paul", "latency_ms": 1469.480276107788, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2510}, "5": {"k": 5, "answer": "young soldiers", "latency_ms": 1756.455421447754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "young soldiers", "latency_ms": 1809.5054626464844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3832}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris", "latency_ms": 1962.9406929016113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 5265.680313110352, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 5790.14778137207, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1347}, "3": {"k": 3, "answer": "Frank Morris, John Anglin, Clarence Anglin", "latency_ms": 4990.4351234436035, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1973}, "4": {"k": 4, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 5761.532783508301, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2643}, "5": {"k": 5, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 5924.947261810303, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3265}, "6": {"k": 6, "answer": "Frank Morris, John Anglin, Clarence Anglin", "latency_ms": 6005.065679550171, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3870}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF programs.", "latency_ms": 3261.3816261291504, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF", "latency_ms": 2881.315231323242, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 718}, "2": {"k": 2, "answer": "UNICEF's global programming", "latency_ms": 3853.165864944458, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "UNICEF's global programming", "latency_ms": 4164.162635803223, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2142}, "4": {"k": 4, "answer": "UNICEF's global programming", "latency_ms": 4123.460054397583, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2867}, "5": {"k": 5, "answer": "UNICEF's global programming", "latency_ms": 4088.94944190979, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3525}, "6": {"k": 6, "answer": "UNICEF's global programming", "latency_ms": 2805.0382137298584, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4214}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Tablet", "latency_ms": 1541.287899017334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edge of the coin", "latency_ms": 3089.0331268310547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Edge of the coin", "latency_ms": 1900.9416103363037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1334}, "3": {"k": 3, "answer": "Edge of the coin", "latency_ms": 2553.765296936035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "Not mentioned", "latency_ms": 1456.6011428833008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Not mentioned", "latency_ms": 1488.9671802520752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "on the edge of the coin", "latency_ms": 3185.403347015381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3897}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "Milan-Cortina, Sapporo", "latency_ms": 4546.267509460449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2405.940055847168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "Beijing, China", "latency_ms": 2708.653688430786, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1192}, "3": {"k": 3, "answer": "Beijing, China and not specified", "latency_ms": 3627.5699138641357, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1785}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3382.8558921813965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Beijing, China and unknown", "latency_ms": 3163.32745552063, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3055}, "6": {"k": 6, "answer": "Beijing, China and unknown", "latency_ms": 3576.869010925293, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3676}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "October 22, 1981", "latency_ms": 4183.75825881958, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1997", "latency_ms": 1334.812879562378, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "1997", "latency_ms": 1599.2207527160645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "1997", "latency_ms": 1995.3551292419434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "1997", "latency_ms": 1200.2763748168945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "1997", "latency_ms": 1683.4721565246582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "1997", "latency_ms": 2031.6381454467773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3865}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "Stone Gothic arch bridge", "latency_ms": 1795.2501773834229, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stone Bridge", "latency_ms": 1359.623670578003, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 631}, "2": {"k": 2, "answer": "Historic bridge", "latency_ms": 2571.211338043213, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1332}, "3": {"k": 3, "answer": "Historic Stone Bridge", "latency_ms": 2153.196334838867, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2012}, "4": {"k": 4, "answer": "Historic bridge", "latency_ms": 1801.9380569458008, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2649}, "5": {"k": 5, "answer": "Historic bridge", "latency_ms": 1685.640573501587, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3316}, "6": {"k": 6, "answer": "Historic bridge", "latency_ms": 2690.36602973938, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4013}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The Autocrat", "latency_ms": 2127.254009246826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One person", "latency_ms": 1281.7509174346924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "One person", "latency_ms": 1627.8812885284424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "One person", "latency_ms": 1265.8967971801758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1987}, "4": {"k": 4, "answer": "One person", "latency_ms": 2280.1759243011475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2637}, "5": {"k": 5, "answer": "One person", "latency_ms": 2035.3925228118896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3271}, "6": {"k": 6, "answer": "One person", "latency_ms": 1460.3428840637207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3955}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "Affluence", "latency_ms": 2616.283178329468, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Late Modernism", "latency_ms": 2683.164358139038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Return to domesticity", "latency_ms": 3122.0552921295166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Return to normalcy", "latency_ms": 2511.630058288574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2006}, "4": {"k": 4, "answer": "Return to normalcy", "latency_ms": 1951.19047164917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "Return to domesticity", "latency_ms": 2514.923572540283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3242}, "6": {"k": 6, "answer": "Affluence", "latency_ms": 2286.47780418396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3967}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "Counterclockwise", "latency_ms": 2419.0988540649414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Along its trajectory", "latency_ms": 1508.293867111206, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "Counterclockwise", "latency_ms": 2644.141912460327, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "Counterclockwise", "latency_ms": 3355.9253215789795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1734}, "4": {"k": 4, "answer": "Counterclockwise", "latency_ms": 2357.640266418457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2319}, "5": {"k": 5, "answer": "Counterclockwise", "latency_ms": 2329.690933227539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2889}, "6": {"k": 6, "answer": "Counterclockwise", "latency_ms": 2538.9835834503174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3511}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Statue of Freedom", "latency_ms": 2415.9812927246094, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Statue of Freedom", "latency_ms": 2109.503984451294, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "\"Statue of Freedom\"", "latency_ms": 2587.172746658325, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1305}, "3": {"k": 3, "answer": "an outdoor walkway on top of the Capitol's dome", "latency_ms": 4618.662357330322, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "an outdoor walkway on top of the Capitol's dome", "latency_ms": 4663.171291351318, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "Statue of Freedom", "latency_ms": 2622.114419937134, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3134}, "6": {"k": 6, "answer": "a dome", "latency_ms": 1748.9464282989502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3777}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "Taoyuan Leopards", "latency_ms": 2297.7678775787354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington Wizards", "latency_ms": 1428.0204772949219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "Washington Wizards", "latency_ms": 1993.2363033294678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Washington Wizards", "latency_ms": 1471.3144302368164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "Washington Wizards", "latency_ms": 1565.232276916504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2597}, "5": {"k": 5, "answer": "Washington Wizards", "latency_ms": 2011.9109153747559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Washington Wizards", "latency_ms": 1508.3348751068115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3786}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1956.315517425537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1649.458646774292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Rey Mysterio", "latency_ms": 2477.4391651153564, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Rey Mysterio", "latency_ms": 2655.932664871216, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1810}, "4": {"k": 4, "answer": "Rey Mysterio", "latency_ms": 2755.1066875457764, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2419}, "5": {"k": 5, "answer": "Rey Mysterio", "latency_ms": 2682.4541091918945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3013}, "6": {"k": 6, "answer": "Rey Mysterio", "latency_ms": 2031.7773818969727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3638}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 1579.925537109375, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake of the Ozarks", "latency_ms": 2713.2327556610107, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Lake Oahe", "latency_ms": 2998.647928237915, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Lake Oahe", "latency_ms": 2200.6237506866455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Lake Oahe", "latency_ms": 2374.011754989624, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2518}, "5": {"k": 5, "answer": "Lake Oahe", "latency_ms": 2653.315305709839, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Lake Oahe", "latency_ms": 2671.211004257202, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3743}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Tagore", "latency_ms": 1485.6629371643066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tagore", "latency_ms": 2064.906358718872, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 585}, "2": {"k": 2, "answer": "Tagore", "latency_ms": 2265.5370235443115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tagore", "latency_ms": 865.5192852020264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1860}, "4": {"k": 4, "answer": "Tagore", "latency_ms": 1459.780216217041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2471}, "5": {"k": 5, "answer": "Tagore", "latency_ms": 2254.279136657715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3109}, "6": {"k": 6, "answer": "Tagore", "latency_ms": 1813.6990070343018, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3730}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "George H.W. Bush", "latency_ms": 2232.564687728882, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Geraldine Ferraro", "latency_ms": 2179.8486709594727, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 682}, "2": {"k": 2, "answer": "Geraldine Ferraro, George H. W. Bush", "latency_ms": 4719.449758529663, "em": 0.0, "f1": 0.4444444444444444, "containment": 1.0, "context_chars": 1385}, "3": {"k": 3, "answer": "Geraldine Ferraro, George H. W. Bush", "latency_ms": 6427.98924446106, "em": 0.0, "f1": 0.4444444444444444, "containment": 1.0, "context_chars": 2086}, "4": {"k": 4, "answer": "Geraldine Ferraro, George H. W. Bush", "latency_ms": 6461.603879928589, "em": 0.0, "f1": 0.4444444444444444, "containment": 1.0, "context_chars": 2813}, "5": {"k": 5, "answer": "Geraldine Ferraro, George H. W. Bush", "latency_ms": 5463.186502456665, "em": 0.0, "f1": 0.4444444444444444, "containment": 1.0, "context_chars": 3510}, "6": {"k": 6, "answer": "Geraldine Ferraro, George H. W. Bush", "latency_ms": 5602.581262588501, "em": 0.0, "f1": 0.4444444444444444, "containment": 1.0, "context_chars": 4186}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "American Rock Salt mine, Livingston County, New York", "latency_ms": 4911.227464675903, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Groveland", "latency_ms": 3500.425100326538, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners, Groveland", "latency_ms": 4146.248579025269, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Hampton Corners, Groveland", "latency_ms": 3402.5638103485107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "Hampton Corners, Groveland, New York", "latency_ms": 5911.93699836731, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "Hampton Corners", "latency_ms": 2578.7367820739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3054}, "6": {"k": 6, "answer": "Hampton Corners", "latency_ms": 2457.0071697235107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3783}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 1042.43803024292, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 1228.8098335266113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 1220.1220989227295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1162}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 2625.9753704071045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1729}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 1807.2643280029297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2360}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 946.3584423065186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2959}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 1777.9431343078613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3621}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Meghalaya", "latency_ms": 2686.622142791748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2693.2387351989746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Uttar Dinajpur", "latency_ms": 3436.4752769470215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "Uttar Dinajpur", "latency_ms": 2570.683717727661, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Uttar Dinajpur", "latency_ms": 2667.42205619812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "Uttar Dinajpur", "latency_ms": 3361.428737640381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Uttar Dinajpur", "latency_ms": 3163.8991832733154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3831}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Kanpur", "latency_ms": 2286.0608100891113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ludhiana", "latency_ms": 1879.6720504760742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 565}, "2": {"k": 2, "answer": "Ludhiana", "latency_ms": 1885.1449489593506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Ludhiana", "latency_ms": 2619.199752807617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "Ludhiana", "latency_ms": 2211.639165878296, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "Ludhiana", "latency_ms": 2249.6261596679688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3172}, "6": {"k": 6, "answer": "Ludhiana", "latency_ms": 2015.6185626983643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3791}}}
