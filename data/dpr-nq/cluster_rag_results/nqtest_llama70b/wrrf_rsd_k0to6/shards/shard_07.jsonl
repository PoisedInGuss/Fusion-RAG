{"qid": "5306300389470118812", "question": "what was the religion in persia before islam", "gold_answers": ["the Zoroastrian religion", "Zoroastrian"], "shots": {"0": {"k": 0, "answer": "Zoroastrianism", "latency_ms": 3157.266855239868, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Zoroastrian", "latency_ms": 2170.485019683838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 637}, "2": {"k": 2, "answer": "Zoroastrian", "latency_ms": 2162.9223823547363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Zoroastrian", "latency_ms": 1360.65673828125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1985}, "4": {"k": 4, "answer": "Zoroastrianism", "latency_ms": 1911.7989540100098, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2599}, "5": {"k": 5, "answer": "Zoroastrianism", "latency_ms": 2968.234062194824, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3284}, "6": {"k": 6, "answer": "Zoroastrianism", "latency_ms": 2409.9106788635254, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3945}}}
{"qid": "4492088526674104172", "question": "why does kerosene oil rise up in the wick of lantern", "gold_answers": ["capillary action"], "shots": {"0": {"k": 0, "answer": "Capillary action", "latency_ms": 1802.1738529205322, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2552.6695251464844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Capillary action", "latency_ms": 1598.991870880127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Capillary action", "latency_ms": 1159.1651439666748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1858}, "4": {"k": 4, "answer": "Capillary action", "latency_ms": 1864.2282485961914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2473}, "5": {"k": 5, "answer": "Capillary action", "latency_ms": 1844.6264266967773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3108}, "6": {"k": 6, "answer": "Capillary action", "latency_ms": 2183.056116104126, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3776}}}
{"qid": "-4373262132142058334", "question": "mention the chemical change that proinsulin undergo to be able to act as mature insulin", "gold_answers": ["post translational modification"], "shots": {"0": {"k": 0, "answer": "Proteolytic cleavage", "latency_ms": 2468.430995941162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cleavage of C-peptide", "latency_ms": 2831.9976329803467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Cleavage", "latency_ms": 2378.6637783050537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1349}, "3": {"k": 3, "answer": "Cleavage", "latency_ms": 1890.974760055542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1957}, "4": {"k": 4, "answer": "Cleavage", "latency_ms": 1114.9909496307373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "Cleavage", "latency_ms": 2430.286169052124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "Cleavage of C-peptide", "latency_ms": 2821.1915493011475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3917}}}
{"qid": "-5298560410953979569", "question": "where does the sweetness of fruit come from", "gold_answers": ["Fructose , or fruit sugar", "Fructose"], "shots": {"0": {"k": 0, "answer": "Fructose", "latency_ms": 1280.8318138122559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1898.305892944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 677}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2870.328903198242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1935.4352951049805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1958}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2475.3105640411377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2591}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3429.882764816284, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3247}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2425.534248352051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3865}}}
{"qid": "4344648368832551136", "question": "an object that moves around an external axis is said to be", "gold_answers": ["orbit", "revolution or orbital revolution"], "shots": {"0": {"k": 0, "answer": "rotating", "latency_ms": 2081.1147689819336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "revolving", "latency_ms": 1218.4739112854004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "revolving", "latency_ms": 1445.6696510314941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "in a revolution or orbital revolution", "latency_ms": 2268.4948444366455, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 1844}, "4": {"k": 4, "answer": "revolving", "latency_ms": 2085.860013961792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2504}, "5": {"k": 5, "answer": "revolving", "latency_ms": 1795.6674098968506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3073}, "6": {"k": 6, "answer": "revolving", "latency_ms": 1545.2549457550049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3679}}}
{"qid": "-724426540432437711", "question": "what was the name of the plant on little shop of horrors", "gold_answers": ["Audrey II"], "shots": {"0": {"k": 0, "answer": "Audrey II", "latency_ms": 1332.2882652282715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2423.736333847046, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2198.9526748657227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "Audrey II", "latency_ms": 1828.2394409179688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Audrey II", "latency_ms": 2579.59246635437, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Audrey II", "latency_ms": 2116.5528297424316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3181}, "6": {"k": 6, "answer": "Audrey II", "latency_ms": 2362.483501434326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3783}}}
{"qid": "-5541610970112826260", "question": "who signed the declaration of independence for maryland", "gold_answers": ["Samuel Chase", "Charles Carroll of Carrollton", "Thomas Stone", "William Paca"], "shots": {"0": {"k": 0, "answer": "Samuel Chase", "latency_ms": 1366.8131828308105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 7165.144681930542, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 718}, "2": {"k": 2, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton.", "latency_ms": 7252.443313598633, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 1393}, "3": {"k": 3, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton.", "latency_ms": 8806.436538696289, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 2085}, "4": {"k": 4, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 7215.099573135376, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 2739}, "5": {"k": 5, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton.", "latency_ms": 6853.467226028442, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 3427}, "6": {"k": 6, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton.", "latency_ms": 7127.774000167847, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 4075}}}
{"qid": "-86997217831791339", "question": "when does wonder woman come out on blue ray", "gold_answers": ["September 19 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2261.817216873169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 19, 2017", "latency_ms": 3183.51674079895, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "September 19, 2017", "latency_ms": 1975.9154319763184, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "September 19, 2017", "latency_ms": 3323.5085010528564, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1849}, "4": {"k": 4, "answer": "September 19, 2017", "latency_ms": 4538.411378860474, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "September 19, 2017", "latency_ms": 4072.894811630249, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3129}, "6": {"k": 6, "answer": "September 19, 2017", "latency_ms": 3356.900930404663, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-8062812506672279762", "question": "what nba team did derrick rose play for", "gold_answers": ["New York Knicks", "Minnesota Timberwolves", "Chicago Bulls", "Cleveland Cavaliers"], "shots": {"0": {"k": 0, "answer": "Chicago Bulls", "latency_ms": 1453.0234336853027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chicago Bulls, Minnesota Timberwolves", "latency_ms": 2291.32342338562, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 630}, "2": {"k": 2, "answer": "Minnesota Timberwolves, Chicago Bulls", "latency_ms": 3524.0578651428223, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Minnesota Timberwolves, Chicago Bulls, Cleveland Cavaliers", "latency_ms": 5058.8059425354, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1893}, "4": {"k": 4, "answer": "Minnesota Timberwolves, Chicago Bulls, Cleveland Cavaliers, Boston Celtics", "latency_ms": 5244.238376617432, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2526}, "5": {"k": 5, "answer": "Minnesota Timberwolves, Chicago Bulls, Cleveland Cavaliers, Boston Celtics", "latency_ms": 4730.442047119141, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Minnesota Timberwolves, Chicago Bulls, Cleveland Cavaliers, Memphis Tigers", "latency_ms": 5561.775922775269, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3695}}}
{"qid": "7933002036740390435", "question": "where did the term liberal arts come from", "gold_answers": ["the Roman Empire"], "shots": {"0": {"k": 0, "answer": "Medieval Europe", "latency_ms": 2442.917823791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roman Empire", "latency_ms": 1306.9508075714111, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Roman Empire", "latency_ms": 1798.8684177398682, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Roman Empire", "latency_ms": 1071.6509819030762, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2046}, "4": {"k": 4, "answer": "Roman Empire", "latency_ms": 1524.656057357788, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2760}, "5": {"k": 5, "answer": "Roman Empire", "latency_ms": 2619.9989318847656, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3467}, "6": {"k": 6, "answer": "Roman Empire", "latency_ms": 1815.6437873840332, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4184}}}
{"qid": "-2991400700385487821", "question": "who heads the executive department of west virginia government", "gold_answers": ["the Governor of West Virginia", "the governor of West Virginia", "Jim Justice"], "shots": {"0": {"k": 0, "answer": "The Governor", "latency_ms": 1313.345193862915, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Governor of West Virginia", "latency_ms": 2024.7647762298584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "The Governor of West Virginia", "latency_ms": 2633.847236633301, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "The Governor of West Virginia", "latency_ms": 2666.28360748291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2014}, "4": {"k": 4, "answer": "The Governor of West Virginia", "latency_ms": 2810.455799102783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2616}, "5": {"k": 5, "answer": "The Governor of West Virginia", "latency_ms": 2074.8226642608643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3256}, "6": {"k": 6, "answer": "The Governor of West Virginia", "latency_ms": 2091.357707977295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3899}}}
{"qid": "-9186689755642837558", "question": "how long is the bridge between new brunswick and prince edward island", "gold_answers": ["12.9 - kilometre"], "shots": {"0": {"k": 0, "answer": "13 kilometers", "latency_ms": 999.4077682495117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1209.909200668335, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 686}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2134.979248046875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1373}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1903.70774269104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2045}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1142.7819728851318, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2780}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2186.84720993042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3371}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1975.6896495819092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4094}}}
{"qid": "8029901619424338449", "question": "when did the uk and us become allies", "gold_answers": ["1940", "Since 1940"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1884.9372863769531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "After the end of the Second World War in 1945", "latency_ms": 3880.0370693206787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "After the end of the Second World War in 1945", "latency_ms": 5263.135671615601, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "After the end of the Second World War in 1945", "latency_ms": 3969.2368507385254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "After the end of the Second World War in 1945", "latency_ms": 5266.4148807525635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2450}, "5": {"k": 5, "answer": "After the end of the Second World War in 1945", "latency_ms": 4473.745346069336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "After the end of the Second World War in 1945", "latency_ms": 5613.783597946167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3732}}}
{"qid": "4828649525820722736", "question": "who sang the theme song for the man with the golden gun", "gold_answers": ["Lulu"], "shots": {"0": {"k": 0, "answer": "Lulu", "latency_ms": 1514.350414276123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lulu", "latency_ms": 2317.7554607391357, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 582}, "2": {"k": 2, "answer": "Lulu", "latency_ms": 878.6065578460693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Lulu", "latency_ms": 1516.3116455078125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1818}, "4": {"k": 4, "answer": "Lulu", "latency_ms": 2024.1937637329102, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2431}, "5": {"k": 5, "answer": "Lulu", "latency_ms": 1222.2988605499268, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3088}, "6": {"k": 6, "answer": "Lulu", "latency_ms": 2218.005895614624, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3758}}}
{"qid": "-7924663090486742985", "question": "american horror story freak show girl kidnapped by clown", "gold_answers": ["Bonnie Lipton"], "shots": {"0": {"k": 0, "answer": "Penny", "latency_ms": 1570.361614227295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2142.017364501953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2188.0228519439697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1134.9730491638184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2028}, "4": {"k": 4, "answer": "Ma Petite", "latency_ms": 2307.5640201568604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Twisty", "latency_ms": 1231.1031818389893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3307}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3173.7701892852783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4006}}}
{"qid": "-360675773049242516", "question": "the probability of making a type i error when retaining ho at the .05 level of significance is", "gold_answers": ["5 %"], "shots": {"0": {"k": 0, "answer": "0.05", "latency_ms": 1564.7156238555908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0.05", "latency_ms": 1866.3578033447266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "0.05", "latency_ms": 1806.0567378997803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "0.05", "latency_ms": 1811.4683628082275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1778}, "4": {"k": 4, "answer": "0.05", "latency_ms": 1591.163158416748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2370}, "5": {"k": 5, "answer": "0.05", "latency_ms": 1843.301773071289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2946}, "6": {"k": 6, "answer": "0.05", "latency_ms": 1542.210578918457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3590}}}
{"qid": "5819386267283467034", "question": "what year did the us hockey team won the olympics", "gold_answers": ["1960", "1980", "1960 and 1980"], "shots": {"0": {"k": 0, "answer": "1980", "latency_ms": 1776.6401767730713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1960, 1980", "latency_ms": 3542.673349380493, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "1960, 1980", "latency_ms": 3784.749984741211, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "1960, 1980", "latency_ms": 3057.5177669525146, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1879}, "4": {"k": 4, "answer": "1960, 1980", "latency_ms": 2316.2271976470947, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2485}, "5": {"k": 5, "answer": "1960, 1980", "latency_ms": 3865.7584190368652, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3164}, "6": {"k": 6, "answer": "1960, 1980", "latency_ms": 3573.4047889709473, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3826}}}
{"qid": "3916394566028297311", "question": "who wrote it's a long long way to pasadena", "gold_answers": ["Harry Vanda", "John Young", "David Hemmings", "George Young"], "shots": {"0": {"k": 0, "answer": "Albert E. Brumley", "latency_ms": 3861.783504486084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2223.5758304595947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1872.7638721466064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2228.4185886383057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3032.7062606811523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2469.0685272216797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2718.9016342163086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3838}}}
{"qid": "-2432292250757146771", "question": "who wrote the song i hate you i love you", "gold_answers": ["Angel Benitez", "Olivia O'Brien", "Garrett Nash"], "shots": {"0": {"k": 0, "answer": "Gnash", "latency_ms": 1549.9176979064941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ne-Yo and StarGate", "latency_ms": 3858.5174083709717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2072.0672607421875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3238.2168769836426, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1813}, "4": {"k": 4, "answer": "Gnash", "latency_ms": 2350.489854812622, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3380.8929920196533, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2990}, "6": {"k": 6, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3845.845937728882, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3585}}}
{"qid": "2393389448844632496", "question": "what is loihi and where does it originate from", "gold_answers": ["from the Hawaii hotspot"], "shots": {"0": {"k": 0, "answer": "Loihi, Hawaii", "latency_ms": 2306.532382965088, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Intel's self-learning neuromorphic chip, Hawaiian seamount Loihi", "latency_ms": 5981.140375137329, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 723}, "2": {"k": 2, "answer": "Hawaiian seamount Loihi", "latency_ms": 3489.957332611084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1403}, "3": {"k": 3, "answer": "Hawaiian seamount Loihi", "latency_ms": 4282.206773757935, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2072}, "4": {"k": 4, "answer": "Hawaiian submarine volcano", "latency_ms": 1954.9033641815186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2745}, "5": {"k": 5, "answer": "Hawaiian seamount Loihi", "latency_ms": 3034.7371101379395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3423}, "6": {"k": 6, "answer": "Hawaiian seamount Loihi", "latency_ms": 4382.849454879761, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4043}}}
{"qid": "-6677440871585683891", "question": "who rebuilt the temple after the babylonian captivity", "gold_answers": ["Herod"], "shots": {"0": {"k": 0, "answer": "Zerubbabel", "latency_ms": 2062.5545978546143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the Priest", "latency_ms": 1777.9500484466553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "the Priest", "latency_ms": 2050.2116680145264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "The Priest", "latency_ms": 1205.5230140686035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1910}, "4": {"k": 4, "answer": "The Priest", "latency_ms": 1579.7595977783203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "the Priest", "latency_ms": 1800.635576248169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3126}, "6": {"k": 6, "answer": "the Priest", "latency_ms": 1580.8851718902588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3796}}}
{"qid": "-6750750235985613277", "question": "who was executed for being an american spy during the revolutionary war", "gold_answers": ["Nathan Hale"], "shots": {"0": {"k": 0, "answer": "Nathan Hale", "latency_ms": 1838.4404182434082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nathan Hale", "latency_ms": 2390.514373779297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 593}, "2": {"k": 2, "answer": "Nathan Hale", "latency_ms": 1283.5240364074707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Nathan Hale", "latency_ms": 2135.436773300171, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1856}, "4": {"k": 4, "answer": "Nathan Hale", "latency_ms": 2370.771646499634, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2550}, "5": {"k": 5, "answer": "Nathan Hale", "latency_ms": 1956.5625190734863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Nathan Hale", "latency_ms": 1616.5504455566406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3824}}}
{"qid": "8770209312170080158", "question": "who sang the song suddenly with olivia newton john", "gold_answers": ["Cliff Richard"], "shots": {"0": {"k": 0, "answer": "Cliff Richard", "latency_ms": 1377.7518272399902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cliff Richard", "latency_ms": 1851.8917560577393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "Cliff Richard", "latency_ms": 2344.205856323242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1270}, "3": {"k": 3, "answer": "Cliff Richard", "latency_ms": 1615.6117916107178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Cliff Richard", "latency_ms": 2128.6840438842773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2499}, "5": {"k": 5, "answer": "Cliff Richard", "latency_ms": 2048.8028526306152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3193}, "6": {"k": 6, "answer": "Cliff Richard", "latency_ms": 1822.4191665649414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3826}}}
{"qid": "-180549795106449014", "question": "who is command sergeant major of the army", "gold_answers": ["Daniel A. Dailey"], "shots": {"0": {"k": 0, "answer": "Michael A. Grinston", "latency_ms": 2398.374319076538, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sergeant Major of the Army", "latency_ms": 2465.9297466278076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1371.7560768127441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Sergeant Major of the Army", "latency_ms": 2787.130832672119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Sergeant Major of the Army", "latency_ms": 2872.570514678955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2589}, "5": {"k": 5, "answer": "Sergeant Major of the Army", "latency_ms": 2876.0077953338623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "Sergeant Major of the Army", "latency_ms": 3554.0761947631836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3936}}}
{"qid": "7815138213728640354", "question": "who sings the original windmills of your mind", "gold_answers": ["Noel Harrison"], "shots": {"0": {"k": 0, "answer": "Noel Harrison", "latency_ms": 1652.7554988861084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noel Harrison", "latency_ms": 1296.419382095337, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 603}, "2": {"k": 2, "answer": "No singer mentioned", "latency_ms": 1835.9687328338623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "No singer mentioned", "latency_ms": 1637.2416019439697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Noel Harrison", "latency_ms": 1572.3979473114014, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2554}, "5": {"k": 5, "answer": "Noel Harrison", "latency_ms": 1776.9687175750732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3143}, "6": {"k": 6, "answer": "Noel Harrison", "latency_ms": 1823.181390762329, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3749}}}
{"qid": "2098168902147822379", "question": "where will the next summer and winter olympics be held", "gold_answers": ["Beijing", "Tokyo"], "shots": {"0": {"k": 0, "answer": "Paris 2024 and Milan-Cortina 2026.", "latency_ms": 5696.578025817871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Beijing", "latency_ms": 1752.429485321045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 623}, "2": {"k": 2, "answer": "Tokyo, Beijing", "latency_ms": 2956.5978050231934, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1294}, "3": {"k": 3, "answer": "Tokyo, Beijing", "latency_ms": 3230.8032512664795, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Tokyo, Beijing", "latency_ms": 2648.819923400879, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2494}, "5": {"k": 5, "answer": "Tokyo, Beijing", "latency_ms": 2914.3970012664795, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3086}, "6": {"k": 6, "answer": "Tokyo, Beijing", "latency_ms": 2156.263828277588, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3679}}}
{"qid": "-1458476052377668874", "question": "when did ole miss beat alabama in football", "gold_answers": ["September 19 , 2015", "October 3 , 1970", "October 27 , 1894", "October 13 , 2001", "October 5 , 1968", "October 4 , 2014", "September 11 , 1976", "October 8 , 1988", "October 18 , 2003", "November 5 , 1910"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 1763.2341384887695, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2014", "latency_ms": 2024.5981216430664, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "2003, 2014, 1988", "latency_ms": 4346.670627593994, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "2014, 2015", "latency_ms": 2806.575059890747, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "2003, 2014, 2015", "latency_ms": 4628.767251968384, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2495}, "5": {"k": 5, "answer": "2003, 2014, 2015", "latency_ms": 5663.312196731567, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3108}, "6": {"k": 6, "answer": "2003, 2014, 2015", "latency_ms": 5875.783681869507, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3728}}}
{"qid": "-6861734002351236912", "question": "who sang the song how far is heaven", "gold_answers": ["Los Lonely Boys"], "shots": {"0": {"k": 0, "answer": "Nitty Gritty Dirt Band", "latency_ms": 3697.4167823791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Moore", "latency_ms": 1527.2576808929443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Justin Moore", "latency_ms": 1755.3861141204834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1196}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3106.070041656494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1785}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2212.216854095459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2374}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3073.9781856536865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2987}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1694.9570178985596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3604}}}
{"qid": "-1722216190521937227", "question": "where are the organ mountains in new mexico", "gold_answers": ["southern New Mexico"], "shots": {"0": {"k": 0, "answer": "Las Cruces", "latency_ms": 1740.5381202697754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "southern New Mexico", "latency_ms": 3274.6024131774902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "southern New Mexico", "latency_ms": 1879.2455196380615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1325}, "3": {"k": 3, "answer": "southern New Mexico", "latency_ms": 2917.733907699585, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1982}, "4": {"k": 4, "answer": "southern New Mexico", "latency_ms": 2702.064275741577, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2643}, "5": {"k": 5, "answer": "southern New Mexico", "latency_ms": 2407.505989074707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "southern New Mexico", "latency_ms": 2713.6337757110596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3979}}}
{"qid": "-2717119588239727064", "question": "where are the 10 plagues found in the bible", "gold_answers": ["Book of Exodus", "Exodus"], "shots": {"0": {"k": 0, "answer": "Exodus 7-12", "latency_ms": 2578.7930488586426, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2298.3858585357666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 570}, "2": {"k": 2, "answer": "Book of Exodus", "latency_ms": 2263.2391452789307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1196}, "3": {"k": 3, "answer": "Book of Exodus", "latency_ms": 1840.4812812805176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Book of Exodus", "latency_ms": 2627.5265216827393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2498}, "5": {"k": 5, "answer": "Book of Exodus", "latency_ms": 2070.8932876586914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3146}, "6": {"k": 6, "answer": "The Book of Exodus", "latency_ms": 1964.9648666381836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3856}}}
{"qid": "2988284357714596500", "question": "where are red blood cells made in adults", "gold_answers": ["in the bone marrow"], "shots": {"0": {"k": 0, "answer": "Bone marrow", "latency_ms": 1489.7761344909668, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "bone marrow", "latency_ms": 539.4737720489502, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "bone marrow", "latency_ms": 1800.0140190124512, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "bone marrow", "latency_ms": 1573.2982158660889, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "bone marrow", "latency_ms": 1551.2423515319824, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "bone marrow", "latency_ms": 2047.9707717895508, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "bone marrow", "latency_ms": 1947.5979804992676, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3803}}}
{"qid": "-4616596799374362422", "question": "who was the pinkerton detective agency's first female detective", "gold_answers": ["Kate Warne"], "shots": {"0": {"k": 0, "answer": "Kate Warne", "latency_ms": 1888.3795738220215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kate Warne", "latency_ms": 2352.113962173462, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 681}, "2": {"k": 2, "answer": "Kate Warne", "latency_ms": 993.8251972198486, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Kate Warne", "latency_ms": 1094.677209854126, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Kate Warne", "latency_ms": 2574.4709968566895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2596}, "5": {"k": 5, "answer": "Kate Warne", "latency_ms": 1813.080072402954, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3236}, "6": {"k": 6, "answer": "Kate Warne", "latency_ms": 1383.6586475372314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3900}}}
{"qid": "-3650291155113659146", "question": "how many episodes are there in modern family", "gold_answers": ["232", "201"], "shots": {"0": {"k": 0, "answer": "250 episodes", "latency_ms": 1013.4975910186768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "24", "latency_ms": 962.3486995697021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "24 episodes", "latency_ms": 1762.2287273406982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "24 episodes", "latency_ms": 1050.2955913543701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "24 episodes", "latency_ms": 2236.473560333252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2525}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2410.1996421813965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3181}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1635.3309154510498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3849}}}
{"qid": "3381924381590631417", "question": "who built the first temple for god in jerusalem", "gold_answers": ["Solomon"], "shots": {"0": {"k": 0, "answer": "King Solomon", "latency_ms": 1481.839895248413, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "King Solomon", "latency_ms": 1319.5195198059082, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "King Solomon", "latency_ms": 1351.090908050537, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1278}, "3": {"k": 3, "answer": "King Solomon", "latency_ms": 1449.253797531128, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1900}, "4": {"k": 4, "answer": "King Solomon", "latency_ms": 1514.033555984497, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "King Solomon", "latency_ms": 1282.5593948364258, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3266}, "6": {"k": 6, "answer": "King Solomon", "latency_ms": 1649.648666381836, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3905}}}
{"qid": "-154783694579651082", "question": "what is a dropped pin on google maps for", "gold_answers": ["marks locations", "marks locations in Google Maps"], "shots": {"0": {"k": 0, "answer": "Saving a location", "latency_ms": 1533.8222980499268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "marking locations", "latency_ms": 1128.1206607818604, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "to mark a point on a map", "latency_ms": 2615.2443885803223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "to mark a point on a map", "latency_ms": 3095.266103744507, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "to mark a point on a map", "latency_ms": 2791.086435317993, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "to mark a point on a map", "latency_ms": 3756.0582160949707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3039}, "6": {"k": 6, "answer": "to mark a point on a map", "latency_ms": 3099.4620323181152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3673}}}
{"qid": "6915606477668963399", "question": "what do the 3 dots mean in math", "gold_answers": ["the therefore sign", "therefore sign"], "shots": {"0": {"k": 0, "answer": "Ellipsis", "latency_ms": 1005.9070587158203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2492.666721343994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "∧", "latency_ms": 956.7816257476807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Therefore", "latency_ms": 877.6307106018066, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "Therefore sign", "latency_ms": 1800.2853393554688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2565}, "5": {"k": 5, "answer": "Therefore sign", "latency_ms": 1746.5589046478271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3281}, "6": {"k": 6, "answer": "Therefore sign", "latency_ms": 1479.9003601074219, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3853}}}
{"qid": "-8366545547296627039", "question": "who wrote the song photograph by ringo starr", "gold_answers": ["Richard Starkey", "George Harrison", "Ringo Starr"], "shots": {"0": {"k": 0, "answer": "Ringo Starr and George Harrison", "latency_ms": 3028.252124786377, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ringo Starr and George Harrison", "latency_ms": 1272.4275588989258, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Ringo Starr and George Harrison", "latency_ms": 2886.0857486724854, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Ringo Starr and George Harrison", "latency_ms": 1995.5778121948242, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1985}, "4": {"k": 4, "answer": "Ringo Starr and George Harrison", "latency_ms": 2820.5342292785645, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2640}, "5": {"k": 5, "answer": "Ringo Starr and George Harrison", "latency_ms": 2282.057523727417, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3335}, "6": {"k": 6, "answer": "Ringo Starr and George Harrison", "latency_ms": 2619.0452575683594, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4125}}}
{"qid": "-5004457603684974952", "question": "who is playing the halftime show at super bowl 2016", "gold_answers": ["Beyoncé", "Coldplay", "Bruno Mars"], "shots": {"0": {"k": 0, "answer": "Coldplay", "latency_ms": 1507.0576667785645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 3490.8347129821777, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "Coldplay, Beyoncé, and Bruno Mars.", "latency_ms": 3584.0678215026855, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Coldplay, Beyoncé, and Bruno Mars.", "latency_ms": 5097.558975219727, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1949}, "4": {"k": 4, "answer": "Coldplay, Beyoncé, and Bruno Mars", "latency_ms": 4022.2513675689697, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2609}, "5": {"k": 5, "answer": "Coldplay, Beyoncé, and Bruno Mars", "latency_ms": 3940.9914016723633, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3253}, "6": {"k": 6, "answer": "Coldplay, Beyoncé, and Bruno Mars.", "latency_ms": 4847.943305969238, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3886}}}
{"qid": "7420920477821898435", "question": "to aru kagaku no railgun s episode 3", "gold_answers": ["Project Radio Noise"], "shots": {"0": {"k": 0, "answer": "Episode 3", "latency_ms": 2086.449146270752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1889.2383575439453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2318.505048751831, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2181.2148094177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2467.4134254455566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2505}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2461.609363555908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3169}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2492.288827896118, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3839}}}
{"qid": "7478795216476346339", "question": "who won the 2017 sports personality of the year", "gold_answers": ["Mo Farah"], "shots": {"0": {"k": 0, "answer": "Mo Farah", "latency_ms": 1626.168966293335, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1957.205057144165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2142.6637172698975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Mo Farah", "latency_ms": 2128.0159950256348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1933}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2207.2198390960693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2593}, "5": {"k": 5, "answer": "Mo Farah", "latency_ms": 1553.901195526123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Mo Farah", "latency_ms": 2569.4243907928467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3875}}}
{"qid": "7217222058435937287", "question": "where was the world economic forum held this year", "gold_answers": ["Davos"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2161.721706390381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1884.9611282348633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 669}, "2": {"k": 2, "answer": "Davos", "latency_ms": 2157.7365398406982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1342}, "3": {"k": 3, "answer": "Davos", "latency_ms": 2470.168113708496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2006}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2419.9936389923096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2661}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2193.7177181243896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3359}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2063.9901161193848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4060}}}
{"qid": "-143054837169120955", "question": "where are the giant redwoods located in california", "gold_answers": ["the coast of northern California", "Del Norte County", "Humboldt County"], "shots": {"0": {"k": 0, "answer": "Northern California", "latency_ms": 1024.6644020080566, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 5122.09415435791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 4362.400054931641, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Sierra Nevada", "latency_ms": 1420.1054573059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 6002.659559249878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2536}, "5": {"k": 5, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 5772.774219512939, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3257}, "6": {"k": 6, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 5472.799301147461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3865}}}
{"qid": "4892429640540595424", "question": "who has made the most premier league appearances", "gold_answers": ["Gareth Barry"], "shots": {"0": {"k": 0, "answer": "Gareth Barry", "latency_ms": 1901.0744094848633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mark Schwarzer", "latency_ms": 2063.202381134033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Gareth Barry", "latency_ms": 1641.9808864593506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Gareth Barry", "latency_ms": 1818.8183307647705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1857}, "4": {"k": 4, "answer": "Gareth Barry", "latency_ms": 1622.4169731140137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2477}, "5": {"k": 5, "answer": "Gareth Barry", "latency_ms": 1831.8424224853516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Gareth Barry", "latency_ms": 2113.0454540252686, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3750}}}
{"qid": "5533906981191706877", "question": "who was the first chief minister of west bengal", "gold_answers": ["Prafulla Chandra Ghosh"], "shots": {"0": {"k": 0, "answer": "Prafulla Chandra Ghosh", "latency_ms": 2927.1130561828613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ajoy Mukherjee", "latency_ms": 2234.7588539123535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2491.2784099578857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Ajoy Mukherjee", "latency_ms": 3053.454875946045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2041}, "4": {"k": 4, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3006.3552856445312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2756}, "5": {"k": 5, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3483.9305877685547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3451}, "6": {"k": 6, "answer": "Prafulla Chandra Ghosh", "latency_ms": 4099.070072174072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4115}}}
{"qid": "8823076125131408628", "question": "who sings got my mind set on you", "gold_answers": ["George Harrison", "James Ray"], "shots": {"0": {"k": 0, "answer": "George Harrison", "latency_ms": 1004.2176246643066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2106.3308715820312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2160.51983833313, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1157}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2092.7319526672363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2132.6842308044434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2684.1604709625244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3036}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1865.6728267669678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3647}}}
{"qid": "9168660859139861094", "question": "two main types of research methods used in psychology", "gold_answers": ["Correlational research", "Descriptive research", "quantitative data", "Quantitative psychological research", "qualitative", "quantitative", "Qualitative psychological research", "Experimental research", "qualitative data"], "shots": {"0": {"k": 0, "answer": "Qualitative and Quantitative.", "latency_ms": 3187.392234802246, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Qualitative or quantitative", "latency_ms": 1788.8877391815186, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 745}, "2": {"k": 2, "answer": "Qualitative or quantitative", "latency_ms": 1959.6118927001953, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1482}, "3": {"k": 3, "answer": "Qualitative or quantitative", "latency_ms": 2147.7537155151367, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2291}, "4": {"k": 4, "answer": "Qualitative or quantitative", "latency_ms": 1982.1887016296387, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3033}, "5": {"k": 5, "answer": "Qualitative or quantitative", "latency_ms": 2388.5555267333984, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3717}, "6": {"k": 6, "answer": "Qualitative or quantitative", "latency_ms": 2193.6323642730713, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4483}}}
{"qid": "-7073063191952855764", "question": "who plays peter in what we do in the shadows", "gold_answers": ["Ben Fransham"], "shots": {"0": {"k": 0, "answer": "Mark Proksch", "latency_ms": 2615.0946617126465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3218.0557250976562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2250.433921813965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1251}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2413.2213592529297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1887}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2243.650436401367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3166.5916442871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2978.7676334381104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3825}}}
{"qid": "7901746249864619718", "question": "when does the 14th season of grey's anatomy come out", "gold_answers": ["September 28 , 2017"], "shots": {"0": {"k": 0, "answer": "September 28, 2017", "latency_ms": 3665.369987487793, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 28, 2017", "latency_ms": 2408.707618713379, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 28, 2017", "latency_ms": 3309.4847202301025, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1402}, "3": {"k": 3, "answer": "September 28, 2017", "latency_ms": 3875.072956085205, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 28, 2017", "latency_ms": 3535.677433013916, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2701}, "5": {"k": 5, "answer": "September 28, 2017", "latency_ms": 3405.2326679229736, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3369}, "6": {"k": 6, "answer": "September 28, 2017", "latency_ms": 2996.7408180236816, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4057}}}
{"qid": "-896127746191949637", "question": "when was the first hunger games book published", "gold_answers": ["September 14 , 2008", "2008"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 1835.7465267181396, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 14, 2008", "latency_ms": 3507.9915523529053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "September 14, 2008", "latency_ms": 3109.558582305908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "September 14, 2008", "latency_ms": 2438.80558013916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1939}, "4": {"k": 4, "answer": "September 14, 2008", "latency_ms": 3313.9419555664062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2601}, "5": {"k": 5, "answer": "September 14, 2008", "latency_ms": 3021.2485790252686, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3261}, "6": {"k": 6, "answer": "September 14, 2008", "latency_ms": 2080.446481704712, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "8044909700499569711", "question": "how much is the united states in debt to china", "gold_answers": ["$1.06 trillion", "1,200.5"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2893.090009689331, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "21 percent", "latency_ms": 1456.5434455871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "$1.08 trillion", "latency_ms": 2533.902406692505, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "21 percent", "latency_ms": 1808.321237564087, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "21 percent", "latency_ms": 1840.0912284851074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "$1.26 trillion", "latency_ms": 1942.9256916046143, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "$1.26 trillion", "latency_ms": 2863.1091117858887, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3834}}}
{"qid": "-3123234845590594961", "question": "where did the race in grease take place", "gold_answers": ["Thunder Road"], "shots": {"0": {"k": 0, "answer": "Thunder Road", "latency_ms": 1730.9141159057617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles River", "latency_ms": 1767.2865390777588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Los Angeles River", "latency_ms": 1350.1574993133545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1166}, "3": {"k": 3, "answer": "Los Angeles River", "latency_ms": 2335.181474685669, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "Los Angeles River", "latency_ms": 1847.7332592010498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "Los Angeles River", "latency_ms": 2072.5185871124268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3134}, "6": {"k": 6, "answer": "Los Angeles River", "latency_ms": 2604.6266555786133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3732}}}
{"qid": "4326992806019599297", "question": "what is the maximum data rate for the 802.11a standard select one", "gold_answers": ["54 Mbit / s"], "shots": {"0": {"k": 0, "answer": "54 Mbps", "latency_ms": 812.7219676971436, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "54 Mbit/s", "latency_ms": 1847.0611572265625, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "54 Mbit/s", "latency_ms": 2445.770740509033, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "54 Mbit/s", "latency_ms": 2580.655813217163, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1967}, "4": {"k": 4, "answer": "54 Mbit/s", "latency_ms": 2754.685878753662, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "54 Mbit/s", "latency_ms": 2734.994649887085, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3293}, "6": {"k": 6, "answer": "54 Mbit/s", "latency_ms": 2440.977096557617, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3955}}}
{"qid": "6144099837933283715", "question": "a good that can be used in place of another good", "gold_answers": ["A substitute good", "substitute good"], "shots": {"0": {"k": 0, "answer": "Substitute", "latency_ms": 1282.454252243042, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Substitute", "latency_ms": 1730.24320602417, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Substitute", "latency_ms": 1525.4113674163818, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1332}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1783.9665412902832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2672.3077297210693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "Substitute", "latency_ms": 932.5659275054932, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Pickling salt", "latency_ms": 2872.4677562713623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3687}}}
{"qid": "-4621948696356225060", "question": "where in the bible can i find the lord's prayer", "gold_answers": ["the Gospel of Luke", "the Gospel of Matthew"], "shots": {"0": {"k": 0, "answer": "Matthew 6:9-13, Luke 11:2-4", "latency_ms": 6131.612300872803, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2169.0611839294434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 562}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1865.5803203582764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2434.5550537109375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2164.5138263702393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "Matthew 6:13", "latency_ms": 2699.991464614868, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3093}, "6": {"k": 6, "answer": "Matthew 6:9-13", "latency_ms": 4381.889343261719, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3639}}}
{"qid": "6941993254369956277", "question": "when was the last time nebraska voted democrat", "gold_answers": ["1964"], "shots": {"0": {"k": 0, "answer": "1964", "latency_ms": 1785.6323719024658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1964", "latency_ms": 1783.7650775909424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "1964", "latency_ms": 1320.3604221343994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1327}, "3": {"k": 3, "answer": "1964", "latency_ms": 1044.4705486297607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2024}, "4": {"k": 4, "answer": "1964", "latency_ms": 1826.5538215637207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2726}, "5": {"k": 5, "answer": "1964", "latency_ms": 1752.6452541351318, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3395}, "6": {"k": 6, "answer": "1964", "latency_ms": 1558.924913406372, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4084}}}
{"qid": "-8955197065025093046", "question": "who become the ceo of it wipro company in 2016", "gold_answers": ["Abid Ali Neemuchwala"], "shots": {"0": {"k": 0, "answer": "Abidali Neemuchwala", "latency_ms": 4497.037172317505, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Not specified", "latency_ms": 1778.8264751434326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 682}, "2": {"k": 2, "answer": "Abidali Neemuchwala", "latency_ms": 4948.52352142334, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1310}, "3": {"k": 3, "answer": "Abidali Neemuchwala", "latency_ms": 3874.6914863586426, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1995}, "4": {"k": 4, "answer": "Abidali Neemuchwala", "latency_ms": 3666.992425918579, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2602}, "5": {"k": 5, "answer": "Abidali Neemuchwala", "latency_ms": 4289.957761764526, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3242}, "6": {"k": 6, "answer": "Abidali Neemuchwala", "latency_ms": 4965.461015701294, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3922}}}
{"qid": "-3010425579521817304", "question": "who does eric end up with in gossip girl", "gold_answers": ["Jenny"], "shots": {"0": {"k": 0, "answer": "Vanessa, then Serena, then no one, then Serena again, but ultimately Vanessa then Serena then finally  Serena", "latency_ms": 9390.494585037231, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1880.9449672698975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2133.246898651123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1227}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2684.4019889831543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1458.9183330535889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2460}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2930.6459426879883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3065}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2421.705961227417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3688}}}
{"qid": "7264112453286983469", "question": "who plays unis in she's the man", "gold_answers": ["Emily Perkins"], "shots": {"0": {"k": 0, "answer": "Amanda Bynes", "latency_ms": 1895.5750465393066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2477.114200592041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2998.199939727783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1915.6467914581299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2718.435764312744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2513}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2357.290744781494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2945.181131362915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3825}}}
{"qid": "2627695648792729859", "question": "who played booster in jingle all the way", "gold_answers": ["Curtis Armstrong"], "shots": {"0": {"k": 0, "answer": "Eric Lloyd", "latency_ms": 1039.6442413330078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1847.538948059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2187.196731567383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1294}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2368.3152198791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3153.5825729370117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2663.3877754211426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3297}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2742.215871810913, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3955}}}
{"qid": "-9169976182548289414", "question": "who is recognized as the founder of islam", "gold_answers": ["the Islamic prophet Muhammad", "Muhammad"], "shots": {"0": {"k": 0, "answer": "Muhammad", "latency_ms": 692.7368640899658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Muhammad", "latency_ms": 1573.1725692749023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 636}, "2": {"k": 2, "answer": "Muhammad", "latency_ms": 1328.1581401824951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Muhammad", "latency_ms": 1749.8352527618408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Muhammad", "latency_ms": 1187.436580657959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2600}, "5": {"k": 5, "answer": "Muhammad", "latency_ms": 1373.4374046325684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "Muhammad", "latency_ms": 2039.4222736358643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3877}}}
{"qid": "-6696747560626271522", "question": "who plays emma in air bud world pup", "gold_answers": ["Brittany Paige Bouck"], "shots": {"0": {"k": 0, "answer": "Brittany Paige Bouck", "latency_ms": 3343.6546325683594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2374.837636947632, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1979.2203903198242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "Brittany Paige Bouck", "latency_ms": 3895.6024646759033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "Brittany Paige Bouck", "latency_ms": 2890.6567096710205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2452}, "5": {"k": 5, "answer": "Brittany Paige Bouck", "latency_ms": 3582.6523303985596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3082}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2373.227596282959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3699}}}
{"qid": "5871681964137793716", "question": "how old was sasuke when his clan died", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "7 years old", "latency_ms": 1777.8007984161377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seven", "latency_ms": 1710.641860961914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Seven", "latency_ms": 1189.1953945159912, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1247}, "3": {"k": 3, "answer": "Seven", "latency_ms": 1437.7267360687256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Seven", "latency_ms": 1233.5090637207031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Seven", "latency_ms": 1498.898983001709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3178}, "6": {"k": 6, "answer": "Seven", "latency_ms": 1193.2649612426758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3784}}}
{"qid": "8552176802923865025", "question": "where do some of the natural air pollutants come from", "gold_answers": ["wildfires", "Dust", "Vegetation", "Carbon dioxide", "Volcanic activity"], "shots": {"0": {"k": 0, "answer": "Volcanic eruptions", "latency_ms": 2274.6834754943848, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1840.1663303375244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 718}, "2": {"k": 2, "answer": "Volcanic eruption", "latency_ms": 2263.761043548584, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "forest fires, volcanic eruptions", "latency_ms": 3521.253824234009, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2128}, "4": {"k": 4, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity", "latency_ms": 9563.545227050781, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 2745}, "5": {"k": 5, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity", "latency_ms": 9488.954782485962, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 3349}, "6": {"k": 6, "answer": "Volcanic eruptions, forest fires, wind erosion, pollen dispersal.", "latency_ms": 6329.293489456177, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 4079}}}
{"qid": "-2630525064809360052", "question": "who is the pastor of new birth missionary baptist church now", "gold_answers": ["Stephen A. Davis"], "shots": {"0": {"k": 0, "answer": "Jamal Harrison Bryant", "latency_ms": 2749.4828701019287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pastor Bryant", "latency_ms": 1593.7962532043457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "Pastor Bryant", "latency_ms": 1898.5939025878906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "Jamal Bryant", "latency_ms": 2140.638828277588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2018}, "4": {"k": 4, "answer": "Jamal Bryant", "latency_ms": 2088.254690170288, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2649}, "5": {"k": 5, "answer": "Jamal Bryant", "latency_ms": 1915.7092571258545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3286}, "6": {"k": 6, "answer": "Jamal Bryant", "latency_ms": 2178.6763668060303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3917}}}
{"qid": "6434931911289860123", "question": "who is doing 2018 super bowl half time show", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "Justin Timberlake", "latency_ms": 1800.3871440887451, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1648.9367485046387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "Maroon 5", "latency_ms": 2174.1080284118652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1232}, "3": {"k": 3, "answer": "Justin Timberlake", "latency_ms": 1296.2427139282227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Justin Timberlake", "latency_ms": 2362.8931045532227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2524}, "5": {"k": 5, "answer": "Justin Timberlake", "latency_ms": 1536.0298156738281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3212}, "6": {"k": 6, "answer": "Justin Timberlake", "latency_ms": 1923.2666492462158, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3848}}}
{"qid": "8869318258439148973", "question": "who is playing the halftime show for the superbowl", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1444.8847770690918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 3203.6075592041016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "Coldplay, Beyoncé, and Bruno Mars.", "latency_ms": 3752.54487991333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "Katy Perry", "latency_ms": 2343.282699584961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "Maroon 5", "latency_ms": 1854.060411453247, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "Maroon 5", "latency_ms": 2465.2483463287354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": "Maroon 5", "latency_ms": 2181.9231510162354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3899}}}
{"qid": "-8359866474144720253", "question": "who hosted they think it's all over", "gold_answers": ["Des Lynam", "Lee Mack", "comedian Nick Hancock", "Nick Hancock"], "shots": {"0": {"k": 0, "answer": "Nick Hancock", "latency_ms": 1037.6458168029785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2026.4244079589844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2644.2506313323975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2912.5795364379883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2409.4254970550537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2489}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2488.8553619384766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3145}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1152.4467468261719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3720}}}
{"qid": "-1206653570097564556", "question": "where does the movie proof of life take place", "gold_answers": ["The Republic of Tecala"], "shots": {"0": {"k": 0, "answer": "South America", "latency_ms": 2033.6313247680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "London and Leipzig", "latency_ms": 1550.966739654541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "The Republic of Tecala", "latency_ms": 2205.0225734710693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1268}, "3": {"k": 3, "answer": "The Republic of Tecala", "latency_ms": 3064.0132427215576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1866}, "4": {"k": 4, "answer": "The Republic of Tecala", "latency_ms": 3309.252977371216, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2533}, "5": {"k": 5, "answer": "The Republic of Tecala", "latency_ms": 2489.2020225524902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3200}, "6": {"k": 6, "answer": "The Republic of Tecala", "latency_ms": 3066.441059112549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3800}}}
{"qid": "6144521615402262404", "question": "where does us highway 1 start and end", "gold_answers": ["Fort Kent , Maine", "to Key West , Florida", "Key West , Florida"], "shots": {"0": {"k": 0, "answer": "Fort Kent, Maine to Key West, Florida", "latency_ms": 2714.6992683410645, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2399.155616760254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2066.9105052948, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1712.6076221466064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2654.1671752929688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2169.001579284668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3106}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2512.6633644104004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3750}}}
{"qid": "-8631190913794477985", "question": "who scored the most points in a single game in the nba", "gold_answers": ["Wilt Chamberlain"], "shots": {"0": {"k": 0, "answer": "Wilt Chamberlain", "latency_ms": 1476.3462543487549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2399.7139930725098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "Wilt Chamberlain", "latency_ms": 2163.757562637329, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "Wilt Chamberlain", "latency_ms": 1879.4174194335938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1850}, "4": {"k": 4, "answer": "Wilt Chamberlain", "latency_ms": 2476.3455390930176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2460}, "5": {"k": 5, "answer": "Wilt Chamberlain", "latency_ms": 2692.669153213501, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3106}, "6": {"k": 6, "answer": "Wilt Chamberlain", "latency_ms": 2379.9281120300293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3688}}}
{"qid": "199896377614951764", "question": "where is natural gas found in the us", "gold_answers": ["Texas", "Pennsylvania", "Colorado", "New Mexico", "West Virginia", "Arkansas", "Wyoming", "Louisiana"], "shots": {"0": {"k": 0, "answer": "Various states including Texas, Alaska, and Pennsylvania", "latency_ms": 4474.961996078491, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shale formations", "latency_ms": 2261.894702911377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "Shale formations", "latency_ms": 2346.96364402771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Louisiana, Texas, California, Alaska, shale formations", "latency_ms": 4379.122495651245, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1825}, "4": {"k": 4, "answer": "Louisiana, Texas, California, Alaska", "latency_ms": 2677.9425144195557, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2501}, "5": {"k": 5, "answer": "Louisiana, Texas, California, Alaska", "latency_ms": 4448.79937171936, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Louisiana, Texas, California, Alaska", "latency_ms": 3791.8667793273926, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3847}}}
{"qid": "8986775680996674901", "question": "when were the first general elections held in independent india", "gold_answers": ["1951 -- 52"], "shots": {"0": {"k": 0, "answer": "1951", "latency_ms": 1296.290636062622, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "25 October 1951 – 27 March 1952", "latency_ms": 4476.425647735596, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "25 October 1951 and 27 March 1952", "latency_ms": 5651.8614292144775, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "25 October 1951 and 27 March 1952", "latency_ms": 6005.111217498779, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1974}, "4": {"k": 4, "answer": "1951", "latency_ms": 1018.1219577789307, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2639}, "5": {"k": 5, "answer": "25 October 1951", "latency_ms": 2468.9884185791016, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "1951-1952", "latency_ms": 2794.060707092285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3946}}}
{"qid": "700604097171850168", "question": "what was the tower of london originally used for", "gold_answers": ["as a royal residence", "a royal residence"], "shots": {"0": {"k": 0, "answer": "Royal Palace", "latency_ms": 1225.0118255615234, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2585.270404815674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "incidental role of holding prisoners", "latency_ms": 2819.5180892944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "incidental role as a castle", "latency_ms": 2964.855670928955, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "incidental role of holding prisoners", "latency_ms": 2503.8630962371826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "incidental role of holding prisoners", "latency_ms": 2486.955165863037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3015}, "6": {"k": 6, "answer": "incidental role as a castle", "latency_ms": 2791.62335395813, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3633}}}
{"qid": "6745303307988470742", "question": "what type of fuel goes in a zippo", "gold_answers": ["butane", "lighter fluid"], "shots": {"0": {"k": 0, "answer": "Lighter fluid", "latency_ms": 1069.6320533752441, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Butane", "latency_ms": 953.5064697265625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "Naphtha", "latency_ms": 2434.3533515930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1187}, "3": {"k": 3, "answer": "naphtha", "latency_ms": 1843.1775569915771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1794}, "4": {"k": 4, "answer": "naphtha", "latency_ms": 2124.9091625213623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2422}, "5": {"k": 5, "answer": "light petroleum distillate or naphtha", "latency_ms": 4312.335014343262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2992}, "6": {"k": 6, "answer": "light petroleum distillate or naphtha", "latency_ms": 5319.113492965698, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3631}}}
{"qid": "-2060506905455252030", "question": "first jnanpith award was an autor of which language", "gold_answers": ["Malayalam"], "shots": {"0": {"k": 0, "answer": "Gujarati", "latency_ms": 1933.6888790130615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2162.662982940674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Not mentioned", "latency_ms": 756.8717002868652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1310}, "3": {"k": 3, "answer": "Malayalam", "latency_ms": 2723.480701446533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Malayalam", "latency_ms": 1611.0491752624512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2644}, "5": {"k": 5, "answer": "Malayalam", "latency_ms": 2625.542640686035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3284}, "6": {"k": 6, "answer": "Malayalam", "latency_ms": 1858.8807582855225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3929}}}
{"qid": "4738663028303377024", "question": "who played the mad hatter in the batman tv show", "gold_answers": ["Roddy McDowall", "David Wayne", "Benedict Samuel"], "shots": {"0": {"k": 0, "answer": "David Wayne", "latency_ms": 825.2830505371094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Peter MacNicol", "latency_ms": 2689.728260040283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "Peter MacNicol", "latency_ms": 2468.726634979248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1997.422218322754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3431.328296661377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "Roddy McDowall", "latency_ms": 2733.8719367980957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3249}, "6": {"k": 6, "answer": "Benedict Samuel", "latency_ms": 3452.092409133911, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3887}}}
{"qid": "-1650946015201779846", "question": "how many cracker barrels in the united states", "gold_answers": ["639", "more than 600"], "shots": {"0": {"k": 0, "answer": "645 locations", "latency_ms": 1413.2649898529053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "645 stores in 44 states", "latency_ms": 2958.7600231170654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "645 stores in 44 states", "latency_ms": 3542.653799057007, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "645 stores in 44 states", "latency_ms": 4400.790452957153, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "645 stores in 44 states", "latency_ms": 2444.7522163391113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2581}, "5": {"k": 5, "answer": "645 stores in 44 states", "latency_ms": 2980.027437210083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "645 stores in 44 states", "latency_ms": 3379.7807693481445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3882}}}
{"qid": "-3422350952909582054", "question": "in photosynthesis the carbon in co2 is initially fixed to what molecule", "gold_answers": ["3 - phosphoglycerate"], "shots": {"0": {"k": 0, "answer": "RuBP", "latency_ms": 1035.48002243042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 5354.719161987305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 712}, "2": {"k": 2, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 6094.369173049927, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1391}, "3": {"k": 3, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 4590.235710144043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2092}, "4": {"k": 4, "answer": "Phosphoenolpyruvate (PEP)", "latency_ms": 5818.727254867554, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2818}, "5": {"k": 5, "answer": "Phosphoenolpyruvate (PEP)", "latency_ms": 4167.783498764038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3482}, "6": {"k": 6, "answer": "Phosphoenolpyruvate (PEP)", "latency_ms": 5024.667024612427, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4191}}}
{"qid": "-2704708103393811482", "question": "who voices randy in f is for family", "gold_answers": ["T.J. Miller"], "shots": {"0": {"k": 0, "answer": "Bill Burr", "latency_ms": 1220.2491760253906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2694.277048110962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "Bill Burr", "latency_ms": 734.9250316619873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Bill Burr", "latency_ms": 1513.3326053619385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1941}, "4": {"k": 4, "answer": "Bill Burr", "latency_ms": 749.2475509643555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2506}, "5": {"k": 5, "answer": "Bill Burr", "latency_ms": 2324.3043422698975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3254}, "6": {"k": 6, "answer": "Bill Burr", "latency_ms": 1771.9242572784424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3857}}}
{"qid": "5482012214308896475", "question": "how many countries does cadbury sell its products", "gold_answers": ["more than 50", "more than 50 countries worldwide"], "shots": {"0": {"k": 0, "answer": "160 countries", "latency_ms": 822.0515251159668, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "more than fifty", "latency_ms": 1559.570550918579, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "more than fifty", "latency_ms": 2612.492084503174, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1401}, "3": {"k": 3, "answer": "more than fifty", "latency_ms": 1828.730821609497, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2055}, "4": {"k": 4, "answer": "more than fifty countries", "latency_ms": 1947.3261833190918, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2763}, "5": {"k": 5, "answer": "more than fifty countries", "latency_ms": 2478.5571098327637, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3397}, "6": {"k": 6, "answer": "50", "latency_ms": 1025.829553604126, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4072}}}
{"qid": "-5737509619250561344", "question": "ethiopia flight 961 crashes in to the sea", "gold_answers": ["23 November 1996"], "shots": {"0": {"k": 0, "answer": "November 23, 1996", "latency_ms": 3448.951005935669, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indian Ocean", "latency_ms": 1317.307949066162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Indian Ocean", "latency_ms": 2285.193681716919, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "Indian Ocean", "latency_ms": 1479.4187545776367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2016}, "4": {"k": 4, "answer": "Indian Ocean", "latency_ms": 1553.8663864135742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Indian Ocean", "latency_ms": 1882.737636566162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3314}, "6": {"k": 6, "answer": "Indian Ocean", "latency_ms": 1055.922031402588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3915}}}
{"qid": "-7175456993713717070", "question": "what does istj mean in a personality test", "gold_answers": ["Extroverted Thinking ( Te )", "Extroverted Intuition ( Ne )", "Introverted Feeling ( Fi )", "Introverted Sensing ( Si )"], "shots": {"0": {"k": 0, "answer": "Introverted, Sensing, Thinking, Judging", "latency_ms": 4003.8185119628906, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4826.136589050293, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 724}, "2": {"k": 2, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4425.270080566406, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 3235.551357269287, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2101}, "4": {"k": 4, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 3471.804618835449, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2729}, "5": {"k": 5, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4519.103765487671, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3440}, "6": {"k": 6, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 3459.833860397339, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4140}}}
{"qid": "4437170343606050664", "question": "who does the voice of ash in sing", "gold_answers": ["Scarlett Johansson"], "shots": {"0": {"k": 0, "answer": "Scarlett Johansson", "latency_ms": 2954.258680343628, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1845.5264568328857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2341.4559364318848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1919.1064834594727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Veronica Taylor", "latency_ms": 1635.6873512268066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2415.651321411133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3086}, "6": {"k": 6, "answer": "Ash King", "latency_ms": 2018.8567638397217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3710}}}
{"qid": "-8773010039077552394", "question": "who scored the most points in their nba career", "gold_answers": ["Kareem Abdul - Jabbar"], "shots": {"0": {"k": 0, "answer": "LeBron James", "latency_ms": 2385.661840438843, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2624.666690826416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1893.564224243164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1138}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3079.8611640930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1734}, "4": {"k": 4, "answer": "Kareem Abdul-Jabbar", "latency_ms": 3591.5298461914062, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2339}, "5": {"k": 5, "answer": "Kareem Abdul-Jabbar", "latency_ms": 3745.443105697632, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2902}, "6": {"k": 6, "answer": "Kareem Abdul-Jabbar", "latency_ms": 2305.170774459839, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3493}}}
{"qid": "-3278224144622911032", "question": "with a land area of 54 314 square miles where does wisconsin rank among the 50 states", "gold_answers": ["25"], "shots": {"0": {"k": 0, "answer": "23rd", "latency_ms": 1022.9957103729248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2458.2483768463135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2230.1876544952393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2126.5954971313477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1784}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2938.819408416748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2373}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2935.228109359741, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2985}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2662.107467651367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3615}}}
{"qid": "-3466298422174960041", "question": "who plays charles on have and have nots", "gold_answers": ["Nick Sager", "Nick Sagar"], "shots": {"0": {"k": 0, "answer": "Aaron O'Connell", "latency_ms": 2432.119131088257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1727.271318435669, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1652.0307064056396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1251}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2702.1377086639404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1872}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3197.080135345459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2470}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1860.9569072723389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3208.116054534912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "1803248910342766083", "question": "who wrote the book my country my life", "gold_answers": ["L.K. Advani"], "shots": {"0": {"k": 0, "answer": "L.K. Advani", "latency_ms": 1746.6180324554443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "L. K. Advani", "latency_ms": 3572.305917739868, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "L. K. Advani", "latency_ms": 3063.0240440368652, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1158}, "3": {"k": 3, "answer": "L. K. Advani", "latency_ms": 3265.0814056396484, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1798}, "4": {"k": 4, "answer": "L. K. Advani", "latency_ms": 2872.678279876709, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "L. K. Advani", "latency_ms": 3013.1475925445557, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "L. K. Advani", "latency_ms": 3617.5286769866943, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3798}}}
{"qid": "-1176280233636154422", "question": "when did the east india company take control of india", "gold_answers": ["1757", "1799", "1612", "in 1757"], "shots": {"0": {"k": 0, "answer": "1757", "latency_ms": 1119.9312210083008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1757", "latency_ms": 1739.6571636199951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "1757", "latency_ms": 1447.9105472564697, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "1757", "latency_ms": 995.943546295166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1924}, "4": {"k": 4, "answer": "1757", "latency_ms": 1725.0871658325195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "1757", "latency_ms": 1525.7439613342285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3232}, "6": {"k": 6, "answer": "1757", "latency_ms": 1502.4375915527344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3872}}}
{"qid": "5911119091653953181", "question": "where does the water come from to fill lake eyre", "gold_answers": ["Warburton River"], "shots": {"0": {"k": 0, "answer": "Cooper Creek", "latency_ms": 1048.1421947479248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "inland Queensland", "latency_ms": 1268.953800201416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "the river systems of semi-arid inland Queensland", "latency_ms": 4121.06990814209, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "the river systems of semi-arid inland Queensland", "latency_ms": 4496.001482009888, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1767}, "4": {"k": 4, "answer": "The river systems of semi-arid inland Queensland", "latency_ms": 3015.5229568481445, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2393}, "5": {"k": 5, "answer": "Semi-arid inland Queensland", "latency_ms": 2784.7094535827637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2992}, "6": {"k": 6, "answer": "The river systems of semi-arid inland Queensland", "latency_ms": 3987.531900405884, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3623}}}
{"qid": "5557104327881436095", "question": "who is the founder of google and when was it founded", "gold_answers": ["1998", "Sergey Brin", "Larry Page and Sergey Brin", "Larry Page"], "shots": {"0": {"k": 0, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 4137.169361114502, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2696.233034133911, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Larry Page, Sergey Brin, September 4, 1998", "latency_ms": 5085.267782211304, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1320}, "3": {"k": 3, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 5934.332609176636, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 4882.85493850708, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 2637}, "5": {"k": 5, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 6509.841442108154, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 3261}, "6": {"k": 6, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 5449.173927307129, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 3896}}}
{"qid": "-1333328812971005142", "question": "who did the dominican republic gain its independence from", "gold_answers": ["Haiti"], "shots": {"0": {"k": 0, "answer": "Haiti", "latency_ms": 1350.7916927337646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spain and Haiti", "latency_ms": 2158.4312915802, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 667}, "2": {"k": 2, "answer": "Spain and Haiti", "latency_ms": 1807.7175617218018, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1342}, "3": {"k": 3, "answer": "Haiti and Spain", "latency_ms": 2276.1240005493164, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2056}, "4": {"k": 4, "answer": "Haiti and Spain", "latency_ms": 2989.9346828460693, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2736}, "5": {"k": 5, "answer": "Haiti and Spain", "latency_ms": 2482.325315475464, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3463}, "6": {"k": 6, "answer": "Haiti and Spain", "latency_ms": 2753.035306930542, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4100}}}
{"qid": "1122605495295045742", "question": "how did early humans make use of stones during the prehistoric period", "gold_answers": ["start fires", "hunt", "bury their dead"], "shots": {"0": {"k": 0, "answer": "Tool making", "latency_ms": 2305.666923522949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 5431.042194366455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 5152.285099029541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 5121.88982963562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 5483.096361160278, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 5777.231931686401, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3239}, "6": {"k": 6, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 5759.453296661377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3899}}}
{"qid": "7402184777947527945", "question": "who wrote the text for jeanie with the light brown hair", "gold_answers": ["Stephen Foster"], "shots": {"0": {"k": 0, "answer": "Maud Irving or Robert Burns", "latency_ms": 2984.9507808685303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stephen Foster", "latency_ms": 1016.7386531829834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Stephen Foster", "latency_ms": 2057.527542114258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1222}, "3": {"k": 3, "answer": "Stephen Foster", "latency_ms": 1511.4176273345947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Stephen Foster", "latency_ms": 1461.9929790496826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Stephen Foster", "latency_ms": 1870.671272277832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3133}, "6": {"k": 6, "answer": "Stephen Foster", "latency_ms": 1550.0874519348145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3748}}}
{"qid": "1656745334095178455", "question": "the basic steps of rational decision making include defining goals and", "gold_answers": ["Implementation of plans / policies"], "shots": {"0": {"k": 0, "answer": "identifying alternatives", "latency_ms": 1932.3437213897705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "problem definition", "latency_ms": 988.0111217498779, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 774}, "2": {"k": 2, "answer": "problem definition", "latency_ms": 1789.0052795410156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1428}, "3": {"k": 3, "answer": "problem definition", "latency_ms": 1517.9765224456787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2061}, "4": {"k": 4, "answer": "problem definition", "latency_ms": 1787.4739170074463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2713}, "5": {"k": 5, "answer": "problem definition", "latency_ms": 1208.9474201202393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3369}, "6": {"k": 6, "answer": "problem definition", "latency_ms": 2091.7787551879883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4087}}}
{"qid": "-216657635823030751", "question": "when was the design period known as art deco", "gold_answers": ["1910 -- 1939"], "shots": {"0": {"k": 0, "answer": "1920s to 1940s", "latency_ms": 3164.943218231201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "just before World War I", "latency_ms": 2528.9900302886963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "just before World War I", "latency_ms": 2667.0427322387695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1362}, "3": {"k": 3, "answer": "just before World War I", "latency_ms": 3491.2891387939453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2025}, "4": {"k": 4, "answer": "just before World War I", "latency_ms": 3056.033134460449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "just before World War I", "latency_ms": 2226.961374282837, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3308}, "6": {"k": 6, "answer": "just before World War I", "latency_ms": 1870.7807064056396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4011}}}
{"qid": "250542332339248886", "question": "where does the bob and tom show broadcast from", "gold_answers": ["WFBQ in Indianapolis , Indiana", "Indianapolis , Indiana"], "shots": {"0": {"k": 0, "answer": "Indianapolis", "latency_ms": 1793.4465408325195, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indianapolis, Indiana", "latency_ms": 1692.6584243774414, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Indianapolis, Indiana", "latency_ms": 1669.5826053619385, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "WFBQ in Indianapolis, Indiana", "latency_ms": 2892.001152038574, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "WFBQ in Indianapolis, Indiana", "latency_ms": 3842.200756072998, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2443}, "5": {"k": 5, "answer": "WFBQ, Indianapolis, Indiana", "latency_ms": 3015.838861465454, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3028}, "6": {"k": 6, "answer": "WFBQ, Indianapolis, Indiana", "latency_ms": 4354.2046546936035, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3662}}}
{"qid": "7610758795954724809", "question": "star wars the clone wars season 3 episode 1", "gold_answers": ["Clone Cadets"], "shots": {"0": {"k": 0, "answer": "Clone Cadets", "latency_ms": 1425.7829189300537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2178.774833679199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1820.8343982696533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2589.1058444976807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2013}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2108.8109016418457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2693}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2326.3416290283203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3333}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2581.4037322998047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4014}}}
{"qid": "2997223939033016160", "question": "what part of brain is responsible for complex thinking", "gold_answers": ["the frontal lobe"], "shots": {"0": {"k": 0, "answer": "Cerebrum", "latency_ms": 2248.228073120117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cerebral cortex", "latency_ms": 1870.615005493164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "Cerebral cortex", "latency_ms": 2639.472723007202, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Cerebral cortex", "latency_ms": 2181.398630142212, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2016}, "4": {"k": 4, "answer": "Cerebral cortex", "latency_ms": 1880.6650638580322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2632}, "5": {"k": 5, "answer": "Cerebral cortex", "latency_ms": 1848.879098892212, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3345}, "6": {"k": 6, "answer": "Cerebral cortex", "latency_ms": 1625.3864765167236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4011}}}
{"qid": "2680196226239522881", "question": "who won the champions league final in 2016", "gold_answers": ["Real Madrid"], "shots": {"0": {"k": 0, "answer": "Real Madrid", "latency_ms": 1315.7641887664795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1825.6609439849854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "Real Madrid", "latency_ms": 1433.5429668426514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Real Madrid", "latency_ms": 1243.6904907226562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Real Madrid", "latency_ms": 1734.9181175231934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2523}, "5": {"k": 5, "answer": "Real Madrid", "latency_ms": 1521.3894844055176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Real Madrid", "latency_ms": 1075.2146244049072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3705}}}
{"qid": "-8458006812258546025", "question": "who has the most gold medals in the winter olympics of all time", "gold_answers": ["Norway"], "shots": {"0": {"k": 0, "answer": "Marit Bjoergen", "latency_ms": 2544.5401668548584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canada", "latency_ms": 888.1876468658447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Canada", "latency_ms": 1451.8640041351318, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Norway and Canada and Germany", "latency_ms": 2761.099100112915, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Norway and Canada and Germany", "latency_ms": 3822.0651149749756, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2407}, "5": {"k": 5, "answer": "Marit Bjørgen", "latency_ms": 2559.8506927490234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3030}, "6": {"k": 6, "answer": "Marit Bjørgen", "latency_ms": 2722.235679626465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3641}}}
