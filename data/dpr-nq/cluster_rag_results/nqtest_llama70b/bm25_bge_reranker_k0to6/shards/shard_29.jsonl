{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 356.89592361450195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 22, 2018", "latency_ms": 716.7458534240723, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "June 22, 2018", "latency_ms": 734.379768371582, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "June 22, 2018", "latency_ms": 731.1456203460693, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "June 22, 2018", "latency_ms": 734.4226837158203, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 729.0530204772949, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3106}, "6": {"k": 6, "answer": "June 22, 2018", "latency_ms": 734.2970371246338, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3761}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Freestyle, Nordic Combined, Ski Jumping, Biathlon.", "latency_ms": 1329.7064304351807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Freestyle skiing", "latency_ms": 502.19249725341797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Freestyle, Cross-country", "latency_ms": 776.545524597168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1487}, "3": {"k": 3, "answer": "Freestyle, Cross-country", "latency_ms": 658.9117050170898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2139}, "4": {"k": 4, "answer": "Freestyle, Cross-country, Alpine", "latency_ms": 768.69797706604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2771}, "5": {"k": 5, "answer": "Alpine, Freestyle, Cross-country", "latency_ms": 949.1479396820068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3533}, "6": {"k": 6, "answer": "Alpine, Freestyle, Cross-country", "latency_ms": 795.6063747406006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4196}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "Arianwen Parkes-Lockwood", "latency_ms": 624.7386932373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Aldo Mignone", "latency_ms": 738.6612892150879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Aldo Mignone", "latency_ms": 752.3548603057861, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Aldo Mignone", "latency_ms": 658.266544342041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Aldo Mignone", "latency_ms": 671.5624332427979, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Aldo Mignone", "latency_ms": 731.989860534668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3064}, "6": {"k": 6, "answer": "Aldo Mignone", "latency_ms": 672.0168590545654, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3684}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "Bengals, Dolphins, Broncos, Chargers", "latency_ms": 666.022777557373, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Denver Broncos", "latency_ms": 433.9418411254883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 661}, "2": {"k": 2, "answer": "Broncos, Bengals", "latency_ms": 559.2255592346191, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Broncos, Bengals, Chargers", "latency_ms": 685.0268840789795, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "Broncos, Bengals, Chargers", "latency_ms": 663.4128093719482, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Broncos, Bengals, Chargers, Dolphins", "latency_ms": 810.981273651123, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3162}, "6": {"k": 6, "answer": "Bengals, Broncos, Dolphins, Chargers", "latency_ms": 894.7057723999023, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3790}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "December 8, 1985", "latency_ms": 656.8312644958496, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 December 1985", "latency_ms": 655.2543640136719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 727}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 644.5255279541016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1444}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 615.41748046875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2083}, "4": {"k": 4, "answer": "December 8, 1985", "latency_ms": 737.4646663665771, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 2891}, "5": {"k": 5, "answer": "December 8, 1985", "latency_ms": 744.9989318847656, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 3592}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 624.1142749786377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4298}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "Spanish moss", "latency_ms": 248.0297088623047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ivory-billed woodpecker", "latency_ms": 815.2036666870117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "Spanish moss", "latency_ms": 428.6050796508789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Spanish moss", "latency_ms": 442.35777854919434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Spanish moss", "latency_ms": 429.0196895599365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2605}, "5": {"k": 5, "answer": "Spanish moss", "latency_ms": 447.7977752685547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3206}, "6": {"k": 6, "answer": "Spanish moss", "latency_ms": 433.1045150756836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3839}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "I-IV", "latency_ms": 295.40109634399414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Class II or III", "latency_ms": 556.049108505249, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 730}, "2": {"k": 2, "answer": "Canadian Cardiovascular Society", "latency_ms": 555.4537773132324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1494}, "3": {"k": 3, "answer": "Canadian Cardiovascular Society", "latency_ms": 557.6870441436768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2250}, "4": {"k": 4, "answer": "Canadian Cardiovascular Society", "latency_ms": 549.8178005218506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2897}, "5": {"k": 5, "answer": "Canadian Cardiovascular Society grading", "latency_ms": 609.8508834838867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3686}, "6": {"k": 6, "answer": "Canadian Cardiovascular Society grading", "latency_ms": 601.1669635772705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4395}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Charles and Eddie", "latency_ms": 295.1068878173828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 538.4373664855957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 563.6265277862549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1158}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 596.3377952575684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 591.3565158843994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2462}, "5": {"k": 5, "answer": "Eurythmics", "latency_ms": 629.0326118469238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3079}, "6": {"k": 6, "answer": "Eurythmics", "latency_ms": 656.9569110870361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3723}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 165.56167602539062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 360.7516288757324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "three", "latency_ms": 407.0720672607422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1230}, "3": {"k": 3, "answer": "three", "latency_ms": 365.03052711486816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1860}, "4": {"k": 4, "answer": "three", "latency_ms": 384.6738338470459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2507}, "5": {"k": 5, "answer": "three", "latency_ms": 389.298677444458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3130}, "6": {"k": 6, "answer": "3", "latency_ms": 365.4196262359619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3814}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "A cake", "latency_ms": 235.30125617980957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Biscuit-sized cakes", "latency_ms": 598.9725589752197, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "biscuit-sized cakes", "latency_ms": 656.4614772796631, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "cake", "latency_ms": 373.13032150268555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1764}, "4": {"k": 4, "answer": "A cake.", "latency_ms": 484.56454277038574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "A cake", "latency_ms": 444.64778900146484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3040}, "6": {"k": 6, "answer": "A cake.", "latency_ms": 483.14833641052246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Seth MacFarlane", "latency_ms": 422.78313636779785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seth MacFarlane", "latency_ms": 627.2115707397461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "Seth MacFarlane", "latency_ms": 625.8325576782227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Seth MacFarlane", "latency_ms": 607.5615882873535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 660.6473922729492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2554}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 617.5186634063721, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3178}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 620.8457946777344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3812}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "Heroin", "latency_ms": 252.77400016784668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amphetamines", "latency_ms": 496.3667392730713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Amphetamines", "latency_ms": 492.4886226654053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1289}, "3": {"k": 3, "answer": "Amphetamines", "latency_ms": 483.84547233581543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1866}, "4": {"k": 4, "answer": "Amphetamines", "latency_ms": 497.4076747894287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2506}, "5": {"k": 5, "answer": "Amphetamines", "latency_ms": 504.0311813354492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3114}, "6": {"k": 6, "answer": "Amphetamines", "latency_ms": 504.35900688171387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3719}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "14 weeks", "latency_ms": 280.9457778930664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a week", "latency_ms": 420.89271545410156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 566}, "2": {"k": 2, "answer": "1 week", "latency_ms": 438.86375427246094, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1169}, "3": {"k": 3, "answer": "1 week", "latency_ms": 467.30828285217285, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1781}, "4": {"k": 4, "answer": "1 week", "latency_ms": 417.90223121643066, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2400}, "5": {"k": 5, "answer": "1 week", "latency_ms": 440.1218891143799, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2973}, "6": {"k": 6, "answer": "1 week", "latency_ms": 427.1211624145508, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3528}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "Yushan, China", "latency_ms": 420.14217376708984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sheffield, England", "latency_ms": 554.3322563171387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Yushan, China", "latency_ms": 653.1815528869629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "Yushan, China.", "latency_ms": 666.0799980163574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Yushan, China.", "latency_ms": 720.4265594482422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "Yushan, China.", "latency_ms": 666.0058498382568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3143}, "6": {"k": 6, "answer": "Yushan, China.", "latency_ms": 660.0658893585205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3752}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "Thad Luckinbill", "latency_ms": 410.52699089050293, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 546.9009876251221, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 590.6131267547607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 563.8144016265869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 566.2529468536377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2623}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 555.419921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 574.2275714874268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3906}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 301.43260955810547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1983", "latency_ms": 508.5914134979248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "1983", "latency_ms": 485.3520393371582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1308}, "3": {"k": 3, "answer": "1983", "latency_ms": 488.8145923614502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1922}, "4": {"k": 4, "answer": "1983", "latency_ms": 440.13404846191406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2597}, "5": {"k": 5, "answer": "1983", "latency_ms": 414.8411750793457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3254}, "6": {"k": 6, "answer": "1983", "latency_ms": 432.82532691955566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3893}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "J-Rock", "latency_ms": 288.8929843902588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alexz Johnson", "latency_ms": 471.1127281188965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Alexz Johnson", "latency_ms": 488.6474609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Alexz Johnson", "latency_ms": 459.23447608947754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Alexz Johnson", "latency_ms": 492.9080009460449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Alexz Johnson", "latency_ms": 523.0367183685303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3289}, "6": {"k": 6, "answer": "Alexz Johnson", "latency_ms": 492.80738830566406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3936}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "2006", "latency_ms": 219.31147575378418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2002", "latency_ms": 771.4076042175293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 629}, "2": {"k": 2, "answer": "March 15, 2002", "latency_ms": 848.6676216125488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "March 15, 2002", "latency_ms": 765.3532028198242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "March 15, 2002", "latency_ms": 873.9135265350342, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2557}, "5": {"k": 5, "answer": "March 15, 2002", "latency_ms": 767.0869827270508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "March 15, 2002", "latency_ms": 744.3079948425293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3847}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "Master Sergeant", "latency_ms": 235.02755165100098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Master sergeant", "latency_ms": 431.4532279968262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 718}, "2": {"k": 2, "answer": "Master sergeant", "latency_ms": 504.9467086791992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Master Sergeant", "latency_ms": 487.03980445861816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1858}, "4": {"k": 4, "answer": "Master Sergeant", "latency_ms": 420.2091693878174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Master Sergeant", "latency_ms": 424.9289035797119, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3052}, "6": {"k": 6, "answer": "Master Sergeant", "latency_ms": 419.2326068878174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3721}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 293.8060760498047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Richard Stallman", "latency_ms": 480.67498207092285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 697}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 488.5976314544678, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1378}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 501.6345977783203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2056}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 491.9006824493408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2701}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 497.77960777282715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3340}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 496.05631828308105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3970}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 372.84350395202637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 603.8155555725098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 601.4440059661865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 569.8075294494629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 614.4676208496094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Heena Sidhu", "latency_ms": 655.4510593414307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3058}, "6": {"k": 6, "answer": "Heena Sidhu", "latency_ms": 608.1545352935791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3706}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Ed Roland", "latency_ms": 245.21756172180176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 454.45895195007324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 442.7165985107422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 445.3165531158447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 461.8988037109375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2582}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 466.94493293762207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3242}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 458.59432220458984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3880}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 377.6063919067383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miami Heat", "latency_ms": 454.5161724090576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 631}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 447.7124214172363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 435.2729320526123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1849}, "4": {"k": 4, "answer": "Chicago Bulls", "latency_ms": 449.8915672302246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 458.38284492492676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3059}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 474.31254386901855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3656}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 388.9966011047363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Guarani (PYG)", "latency_ms": 827.5096416473389, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "PYG", "latency_ms": 503.8905143737793, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "PYG", "latency_ms": 496.44994735717773, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "PYG", "latency_ms": 490.28658866882324, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 2431}, "5": {"k": 5, "answer": "PYG", "latency_ms": 448.26555252075195, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3069}, "6": {"k": 6, "answer": "PYG", "latency_ms": 448.6980438232422, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3701}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "Midazolam", "latency_ms": 363.8415336608887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Benzodiazepines", "latency_ms": 688.6758804321289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 678}, "2": {"k": 2, "answer": "Midazolam", "latency_ms": 577.4340629577637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1362}, "3": {"k": 3, "answer": "Midazolam", "latency_ms": 585.4806900024414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2076}, "4": {"k": 4, "answer": "Midazolam", "latency_ms": 568.2096481323242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2758}, "5": {"k": 5, "answer": "Midazolam", "latency_ms": 566.5125846862793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3473}, "6": {"k": 6, "answer": "Midazolam", "latency_ms": 592.7164554595947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4153}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 358.9015007019043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "25,772 years", "latency_ms": 554.2490482330322, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "25,772 years", "latency_ms": 560.4703426361084, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1302}, "3": {"k": 3, "answer": "25,772 years", "latency_ms": 561.6917610168457, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "25,772 years", "latency_ms": 566.6835308074951, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "25,772 years", "latency_ms": 568.892240524292, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3183}, "6": {"k": 6, "answer": "25,772 years", "latency_ms": 569.8421001434326, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3864}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 305.7534694671631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Texas A&M Aggies", "latency_ms": 623.7506866455078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Texas A&M Aggies", "latency_ms": 615.6668663024902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Texas A&M Aggies", "latency_ms": 624.8412132263184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Texas A&M Aggies", "latency_ms": 634.922981262207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2541}, "5": {"k": 5, "answer": "Texas A&M Aggies", "latency_ms": 629.8050880432129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3161}, "6": {"k": 6, "answer": "Texas A&M Aggies", "latency_ms": 620.929479598999, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3878}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and Non-Renewable.", "latency_ms": 736.2010478973389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable or non-renewable", "latency_ms": 823.1542110443115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable or non-renewable", "latency_ms": 813.5602474212646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1428}, "3": {"k": 3, "answer": "renewable or non-renewable", "latency_ms": 802.1843433380127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2178}, "4": {"k": 4, "answer": "renewable or non-renewable", "latency_ms": 888.5724544525146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2910}, "5": {"k": 5, "answer": "renewable or non-renewable", "latency_ms": 904.8411846160889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3588}, "6": {"k": 6, "answer": "renewable or non-renewable", "latency_ms": 805.1626682281494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4288}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "New life and fertility", "latency_ms": 369.47059631347656, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parental devotion", "latency_ms": 510.9422206878662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Parental devotion", "latency_ms": 496.3393211364746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Parental devotion and filial values", "latency_ms": 743.6938285827637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "Purity", "latency_ms": 424.3147373199463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2504}, "5": {"k": 5, "answer": "Purity", "latency_ms": 445.61290740966797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3139}, "6": {"k": 6, "answer": "Purity", "latency_ms": 427.28567123413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Virat Kohli", "latency_ms": 376.422643661499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 598.9923477172852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 556.7116737365723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 566.7848587036133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1887}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 547.0380783081055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 566.1258697509766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 567.5220489501953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3703}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "the antimicrobial action of metal ions.", "latency_ms": 601.992130279541, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals", "latency_ms": 713.263988494873, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "biocidal effect of metals", "latency_ms": 713.7951850891113, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "biocidal effect of metals", "latency_ms": 726.1521816253662, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2103}, "4": {"k": 4, "answer": "biocidal effect of metals", "latency_ms": 680.7501316070557, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2841}, "5": {"k": 5, "answer": "biocidal effect of metals", "latency_ms": 723.4997749328613, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3568}, "6": {"k": 6, "answer": "biocidal effect of metals", "latency_ms": 724.4837284088135, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4258}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "Dustin Higgs", "latency_ms": 358.00886154174805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Coburn", "latency_ms": 495.07999420166016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "James Coburn", "latency_ms": 498.920202255249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1294}, "3": {"k": 3, "answer": "James Coburn", "latency_ms": 544.9934005737305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "Billy Bailey", "latency_ms": 448.64368438720703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 552.5217056274414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 582.3974609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the auction.", "latency_ms": 371.4582920074463, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the conclusion of play", "latency_ms": 613.6763095855713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 550}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 620.8713054656982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1122}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 613.2969856262207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1728}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 601.0549068450928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2310}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 626.6994476318359, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2926}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 601.9446849822998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3511}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Afghanistan", "latency_ms": 292.3309803009033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 499.57823753356934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 694}, "2": {"k": 2, "answer": "Afghanistan", "latency_ms": 498.68297576904297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Afghanistan", "latency_ms": 532.9155921936035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2124}, "4": {"k": 4, "answer": "Afghanistan", "latency_ms": 505.0501823425293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2785}, "5": {"k": 5, "answer": "Afghanistan", "latency_ms": 506.47568702697754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3509}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 523.0343341827393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4243}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "Coagulation, Fibrin formation, Clot retraction", "latency_ms": 1021.5237140655518, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 1132.711410522461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 592.2012329101562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 1118.1018352508545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2082}, "4": {"k": 4, "answer": "primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 1151.4155864715576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2807}, "5": {"k": 5, "answer": "primary hemostasis, secondary hemostasis, and fibrin cross-linking", "latency_ms": 1337.3830318450928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3521}, "6": {"k": 6, "answer": "primary hemostasis, secondary hemostasis, and fibrin cross-linking", "latency_ms": 1316.1475658416748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4173}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "Sebastian Hunsinger", "latency_ms": 500.3161430358887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shawn Roberts", "latency_ms": 546.1299419403076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "Sebastian HÃ¼lk", "latency_ms": 652.6405811309814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1374}, "3": {"k": 3, "answer": "Sebastian Hedges Thomas", "latency_ms": 687.7896785736084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2068}, "4": {"k": 4, "answer": "Presley Smith", "latency_ms": 575.3154754638672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2768}, "5": {"k": 5, "answer": "Presley Smith", "latency_ms": 526.942253112793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3398}, "6": {"k": 6, "answer": "Presley Smith", "latency_ms": 549.5784282684326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4044}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "20 November 1989", "latency_ms": 423.83432388305664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "20 November 1989", "latency_ms": 604.6967506408691, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 609.7328662872314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 608.2236766815186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1890}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 708.7960243225098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2551}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 596.7252254486084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 596.7583656311035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3861}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "2016", "latency_ms": 217.51022338867188, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "23 June 2016", "latency_ms": 589.367151260376, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "23 June 2016", "latency_ms": 590.9979343414307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1348}, "3": {"k": 3, "answer": "23 June 2016", "latency_ms": 591.1235809326172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2020}, "4": {"k": 4, "answer": "23 June 2016", "latency_ms": 601.0375022888184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2685}, "5": {"k": 5, "answer": "23 June 2016", "latency_ms": 605.3204536437988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3299}, "6": {"k": 6, "answer": "23 June 2016", "latency_ms": 613.9578819274902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3971}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 365.34571647644043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Burj Khalifa", "latency_ms": 562.4229907989502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 679}, "2": {"k": 2, "answer": "Burj Khalifa", "latency_ms": 556.7078590393066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1360}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 562.5059604644775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 547.30224609375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2612}, "5": {"k": 5, "answer": "Burj Khalifa", "latency_ms": 547.1503734588623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3253}, "6": {"k": 6, "answer": "Burj Khalifa", "latency_ms": 570.6808567047119, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3944}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "Miranda Hart", "latency_ms": 288.23304176330566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miranda Hart's mother is played by  Marcia Warren", "latency_ms": 1075.6573677062988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Miranda Hart's character's mother is played by  Linda Bassett", "latency_ms": 1222.3777770996094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Miranda Hart's mother is played by  Cherie Lunghi but Chummy's mother is played by:  Miranda Richardson", "latency_ms": 1883.1892013549805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Miranda Hart's mother is played by  Cherie Lunghi", "latency_ms": 1169.4543361663818, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Miranda Hart's mother is played by  Cherie Lunghi", "latency_ms": 1224.843978881836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3101}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 618.2687282562256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3767}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Montesquieu", "latency_ms": 357.88917541503906, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montesquieu", "latency_ms": 543.3440208435059, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 544.1770553588867, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 592.188835144043, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2009}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 572.2453594207764, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2690}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 576.3735771179199, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3328}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 565.4397010803223, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3955}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Myles Garrett", "latency_ms": 316.9221878051758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sam Bradford", "latency_ms": 421.10538482666016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 546.48756980896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Myles Garrett", "latency_ms": 498.1677532196045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Myles Garrett", "latency_ms": 511.2295150756836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2507}, "5": {"k": 5, "answer": "Myles Garrett", "latency_ms": 500.86379051208496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3083}, "6": {"k": 6, "answer": "Myles Garrett", "latency_ms": 512.1352672576904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3743}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2063 BS", "latency_ms": 296.7550754547119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 538.6955738067627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 557.9073429107666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 560.3950023651123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 624.9899864196777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2646}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 598.585844039917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3358}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 579.9999237060547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4016}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "Captain John Smith", "latency_ms": 316.6184425354004, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Smith", "latency_ms": 431.5052032470703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "John Smith", "latency_ms": 441.88904762268066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "John Smith", "latency_ms": 451.0049819946289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1951}, "4": {"k": 4, "answer": "John Smith", "latency_ms": 439.44597244262695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2627}, "5": {"k": 5, "answer": "John Smith", "latency_ms": 429.459810256958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3237}, "6": {"k": 6, "answer": "John Smith", "latency_ms": 429.95643615722656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3921}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "Parietal cells", "latency_ms": 383.0552101135254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parietal cells", "latency_ms": 549.6721267700195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 625}, "2": {"k": 2, "answer": "Parietal cells", "latency_ms": 553.2863140106201, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Parietal cells", "latency_ms": 565.85693359375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1878}, "4": {"k": 4, "answer": "Parietal cells", "latency_ms": 596.2440967559814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2588}, "5": {"k": 5, "answer": "Parietal cells", "latency_ms": 567.286491394043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3257}, "6": {"k": 6, "answer": "Parietal cells", "latency_ms": 606.7159175872803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3912}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "Early morning", "latency_ms": 230.36623001098633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Two hours before waking up", "latency_ms": 605.2346229553223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 709}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 549.2730140686035, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1372}, "3": {"k": 3, "answer": "4 a.m.", "latency_ms": 541.0037040710449, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2012}, "4": {"k": 4, "answer": "4 a.m.", "latency_ms": 547.0693111419678, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2676}, "5": {"k": 5, "answer": "4 a.m.", "latency_ms": 548.7062931060791, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3360}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 542.015790939331, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4081}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 236.54627799987793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Idaho", "latency_ms": 435.7898235321045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 613}, "2": {"k": 2, "answer": "Idaho", "latency_ms": 422.6658344268799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Idaho", "latency_ms": 436.66577339172363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Idaho", "latency_ms": 433.0110549926758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2603}, "5": {"k": 5, "answer": "Idaho", "latency_ms": 444.51117515563965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3262}, "6": {"k": 6, "answer": "Idaho", "latency_ms": 456.1624526977539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales", "latency_ms": 1763.768196105957, "em": 0.0, "f1": 0.43478260869565216, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 586.2481594085693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 582.4780464172363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 531.5241813659668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 583.3139419555664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "Pirates of the Caribbean: The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales", "latency_ms": 2313.5666847229004, "em": 0.0, "f1": 0.3846153846153846, "containment": 1.0, "context_chars": 3306}, "6": {"k": 6, "answer": "1. The Curse of the Black Pearl \n2. At World's End \n3. Dead Men Tell No Tales", "latency_ms": 1753.1118392944336, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3991}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 260.49089431762695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "progressed", "latency_ms": 480.04150390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 691}, "2": {"k": 2, "answer": "modulated", "latency_ms": 440.1674270629883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1303}, "3": {"k": 3, "answer": "modulated", "latency_ms": 437.72387504577637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "modulated", "latency_ms": 463.0241394042969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "modulated", "latency_ms": 471.4372158050537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3201}, "6": {"k": 6, "answer": "modulated", "latency_ms": 457.9598903656006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3846}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Male citizens", "latency_ms": 226.66430473327637, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "all full Roman citizens", "latency_ms": 544.529914855957, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 637}, "2": {"k": 2, "answer": "full Roman citizens", "latency_ms": 488.22522163391113, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1296}, "3": {"k": 3, "answer": "full Roman citizens", "latency_ms": 505.9936046600342, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1941}, "4": {"k": 4, "answer": "full Roman citizens, excluding women, slaves, and originally those outside Rome", "latency_ms": 1177.2043704986572, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Adult male citizens", "latency_ms": 485.9910011291504, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3278}, "6": {"k": 6, "answer": "Adult male citizens", "latency_ms": 476.00531578063965, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3977}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 356.0926914215088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "9 April 2019", "latency_ms": 652.8401374816895, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "9 April 2019", "latency_ms": 601.0098457336426, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "9 April 2019", "latency_ms": 656.1048030853271, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1925}, "4": {"k": 4, "answer": "9 April 2019", "latency_ms": 602.0817756652832, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2611}, "5": {"k": 5, "answer": "9 April 2019", "latency_ms": 624.3467330932617, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3253}, "6": {"k": 6, "answer": "9 April 2019", "latency_ms": 662.8069877624512, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3894}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "100 parts of blood", "latency_ms": 357.4235439300537, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "volume of blood or mass of blood", "latency_ms": 741.4405345916748, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "volume of blood or mass of blood", "latency_ms": 743.8044548034668, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1302}, "3": {"k": 3, "answer": "volume of blood or mass of blood", "latency_ms": 729.9404144287109, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "volume of blood or mass of blood", "latency_ms": 740.1947975158691, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2563}, "5": {"k": 5, "answer": "volume of blood or mass of blood", "latency_ms": 734.7919940948486, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3260}, "6": {"k": 6, "answer": "volume of blood or mass of blood", "latency_ms": 754.4910907745361, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3981}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "Icarus", "latency_ms": 299.0999221801758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Icarus", "latency_ms": 500.31423568725586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 587}, "2": {"k": 2, "answer": "Icarus", "latency_ms": 504.23336029052734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "Icarus", "latency_ms": 493.90363693237305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Icarus", "latency_ms": 489.9735450744629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2411}, "5": {"k": 5, "answer": "Icarus", "latency_ms": 534.4419479370117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3008}, "6": {"k": 6, "answer": "Icarus", "latency_ms": 561.7380142211914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3645}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "September 16, 1979", "latency_ms": 529.6001434326172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 16, 1979", "latency_ms": 731.5397262573242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "September 16, 1979", "latency_ms": 761.5542411804199, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "September 16, 1979", "latency_ms": 741.0182952880859, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1782}, "4": {"k": 4, "answer": "September 16, 1979", "latency_ms": 760.4019641876221, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2363}, "5": {"k": 5, "answer": "September 16, 1979", "latency_ms": 779.3750762939453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2958}, "6": {"k": 6, "answer": "September 16, 1979", "latency_ms": 721.3268280029297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3587}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 am", "latency_ms": 361.6342544555664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2 April 1986", "latency_ms": 601.5143394470215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "2 April 1986", "latency_ms": 596.646785736084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1296}, "3": {"k": 3, "answer": "2 April 1986", "latency_ms": 605.2713394165039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "2 April 1986", "latency_ms": 628.3152103424072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2588}, "5": {"k": 5, "answer": "2 April 1986", "latency_ms": 597.3615646362305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "2 April 1986", "latency_ms": 614.3572330474854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3825}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "Tiffany Coyne", "latency_ms": 349.8561382293701, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiffany Coyne", "latency_ms": 544.8260307312012, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "Tiffany Coyne", "latency_ms": 547.7926731109619, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1160}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 547.2455024719238, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1744}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 540.247917175293, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2372}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 566.7684078216553, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2986}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 605.5653095245361, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3619}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "Yankees, Braves, Reds, Giants", "latency_ms": 675.1301288604736, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 1102.9720306396484, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 1121.3552951812744, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 1109.4071865081787, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1853}, "4": {"k": 4, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 1109.9674701690674, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 1123.2821941375732, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3099}, "6": {"k": 6, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 1196.2089538574219, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3813}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "2.187 billion dollars", "latency_ms": 420.147180557251, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$1.84 billion", "latency_ms": 710.9386920928955, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "$1.84 billion", "latency_ms": 635.0932121276855, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "$1.84 billion", "latency_ms": 633.4617137908936, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "$1.84 billion", "latency_ms": 638.2105350494385, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "$1.84 billion", "latency_ms": 711.0583782196045, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3247}, "6": {"k": 6, "answer": "$1.84 billion", "latency_ms": 678.295373916626, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3890}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 373.31628799438477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Christmas season of 1997", "latency_ms": 681.9875240325928, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 649}, "2": {"k": 2, "answer": "Christmas season of 1997", "latency_ms": 695.4078674316406, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1304}, "3": {"k": 3, "answer": "Christmas season of 1997", "latency_ms": 681.6802024841309, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Christmas season of 1997", "latency_ms": 697.5436210632324, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2519}, "5": {"k": 5, "answer": "Christmas season of 1997", "latency_ms": 675.6322383880615, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3152}, "6": {"k": 6, "answer": "1946", "latency_ms": 479.414701461792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark", "latency_ms": 231.68540000915527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 554.5878410339355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Norway and Denmark", "latency_ms": 596.8458652496338, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 577.171802520752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 595.0658321380615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2559}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 565.420389175415, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "Denmark", "latency_ms": 445.8353519439697, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3813}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "PresÃ©pio", "latency_ms": 281.33487701416016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Christmas tree", "latency_ms": 467.5326347351074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "Christmas Tree", "latency_ms": 419.78979110717773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Christmas Tree", "latency_ms": 442.096471786499, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Christmas Tree", "latency_ms": 441.2498474121094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Christmas Tree", "latency_ms": 440.45019149780273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3193}, "6": {"k": 6, "answer": "Christmas Tree", "latency_ms": 427.5848865509033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3790}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "Patrick Swayze", "latency_ms": 357.086181640625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Swayze", "latency_ms": 500.3669261932373, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Swayze", "latency_ms": 500.05030632019043, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Swayze", "latency_ms": 479.6578884124756, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Swayze", "latency_ms": 505.07283210754395, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Swayze", "latency_ms": 505.77473640441895, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Swayze", "latency_ms": 613.0936145782471, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3767}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Pittsburgh", "latency_ms": 282.62853622436523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 563.2669925689697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 744}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 565.8013820648193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1438}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 595.7410335540771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2130}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 549.9038696289062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2735}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 570.8785057067871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3461}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 554.4471740722656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4132}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1704", "latency_ms": 220.08824348449707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "17th Century", "latency_ms": 497.9133605957031, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "17th Century", "latency_ms": 505.5234432220459, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1314}, "3": {"k": 3, "answer": "17th Century", "latency_ms": 499.89938735961914, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2009}, "4": {"k": 4, "answer": "17th Century", "latency_ms": 482.33580589294434, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2706}, "5": {"k": 5, "answer": "1624", "latency_ms": 427.7911186218262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3428}, "6": {"k": 6, "answer": "17th Century", "latency_ms": 508.20469856262207, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4096}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier FernÃ¡ndez", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Yuzuru Hanyu", "latency_ms": 487.2250556945801, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yuzuru Hanyu", "latency_ms": 686.0151290893555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Yuzuru Hanyu", "latency_ms": 727.5409698486328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Yuzuru Hanyu", "latency_ms": 780.3876399993896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Yuzuru Hanyu", "latency_ms": 741.455078125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2607}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 712.4228477478027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3275}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 717.9832458496094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3956}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "Password recovery and cracking.", "latency_ms": 423.89774322509766, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Password recovery", "latency_ms": 448.9936828613281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "Password recovery", "latency_ms": 444.0805912017822, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1391}, "3": {"k": 3, "answer": "Password recovery", "latency_ms": 440.7839775085449, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Password recovery", "latency_ms": 418.428897857666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2714}, "5": {"k": 5, "answer": "Password recovery", "latency_ms": 417.3610210418701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3379}, "6": {"k": 6, "answer": "Password recovery", "latency_ms": 417.34886169433594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3964}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 350.9705066680908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "C. Vidyasagar Rao", "latency_ms": 734.7862720489502, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "C. Vidyasagar Rao", "latency_ms": 771.4200019836426, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 740.7779693603516, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2058}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 747.5471496582031, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2686}, "5": {"k": 5, "answer": "C. Vidyasagar Rao", "latency_ms": 752.305269241333, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3326}, "6": {"k": 6, "answer": "C. Vidyasagar Rao", "latency_ms": 754.0380954742432, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3955}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "Channel 15", "latency_ms": 283.707857131958, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "15", "latency_ms": 375.40388107299805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 682}, "2": {"k": 2, "answer": "15", "latency_ms": 415.04645347595215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "15", "latency_ms": 355.35407066345215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1884}, "4": {"k": 4, "answer": "15", "latency_ms": 384.000301361084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2486}, "5": {"k": 5, "answer": "15", "latency_ms": 431.0801029205322, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3118}, "6": {"k": 6, "answer": "15", "latency_ms": 426.24855041503906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3738}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Claudia Wells", "latency_ms": 368.72363090515137, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Claudia Wells", "latency_ms": 625.5848407745361, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Claudia Wells", "latency_ms": 544.3906784057617, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1207}, "3": {"k": 3, "answer": "Claudia Wells", "latency_ms": 554.8005104064941, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 575.2708911895752, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2477}, "5": {"k": 5, "answer": "Claudia Wells", "latency_ms": 563.7245178222656, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "Claudia Wells", "latency_ms": 560.3680610656738, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3693}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 237.40315437316895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "London, United Kingdom", "latency_ms": 576.1258602142334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 572.1640586853027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 558.7637424468994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1913}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 610.4693412780762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2585}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 585.7343673706055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 573.1680393218994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3847}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The White House Chef", "latency_ms": 424.0133762359619, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The White House Executive Chef", "latency_ms": 599.4746685028076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "The White House Executive Chef", "latency_ms": 634.0372562408447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "The White House Executive Chef", "latency_ms": 626.5785694122314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2038}, "4": {"k": 4, "answer": "The White House Executive Chef", "latency_ms": 624.4208812713623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2650}, "5": {"k": 5, "answer": "The White House Executive Chef", "latency_ms": 631.3676834106445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3311}, "6": {"k": 6, "answer": "The White House Executive Chef", "latency_ms": 625.5650520324707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3974}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 416.1841869354248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 596.0907936096191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 580.4059505462646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "B. N. Rao", "latency_ms": 678.3754825592041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1818}, "4": {"k": 4, "answer": "B. N. Rao", "latency_ms": 642.9791450500488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "B. N. Rao", "latency_ms": 635.8678340911865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3111}, "6": {"k": 6, "answer": "B. N. Rao", "latency_ms": 675.8112907409668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 368.516206741333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "British Columbia", "latency_ms": 458.04524421691895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "British Columbia", "latency_ms": 488.3151054382324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "British Columbia", "latency_ms": 452.86107063293457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1960}, "4": {"k": 4, "answer": "British Columbia", "latency_ms": 421.46778106689453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "British Columbia", "latency_ms": 445.2555179595947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3229}, "6": {"k": 6, "answer": "British Columbia", "latency_ms": 480.3166389465332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3910}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 367.246150970459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 11, 2018", "latency_ms": 778.095006942749, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "October 11, 2018", "latency_ms": 783.6718559265137, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 789.1342639923096, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 785.7556343078613, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 795.7656383514404, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3267}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 789.6449565887451, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3912}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Jodie Sweetin", "latency_ms": 362.90669441223145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 565.0405883789062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 552.0212650299072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 566.4875507354736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 625.5905628204346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 618.4120178222656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3179}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 585.8213901519775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3852}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "Milennium Tower", "latency_ms": 386.1865997314453, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Millennium Tower", "latency_ms": 596.160888671875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 552.7012348175049, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 567.7402019500732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 571.7384815216064, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2661}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 604.4516563415527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3357}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 569.2949295043945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4043}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 227.9057502746582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 435.5509281158447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "2015", "latency_ms": 471.9982147216797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 550.3451824188232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "2015", "latency_ms": 444.2141056060791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2535}, "5": {"k": 5, "answer": "2015", "latency_ms": 425.10056495666504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "2015", "latency_ms": 445.953369140625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "John Harlan", "latency_ms": 292.9675579071045, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Marshall Harlan", "latency_ms": 576.8659114837646, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Harlan", "latency_ms": 439.6171569824219, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1390}, "3": {"k": 3, "answer": "Harlan", "latency_ms": 434.80920791625977, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2069}, "4": {"k": 4, "answer": "John Marshall Harlan", "latency_ms": 659.1529846191406, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2750}, "5": {"k": 5, "answer": "John Marshall Harlan", "latency_ms": 591.2625789642334, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3453}, "6": {"k": 6, "answer": "John Marshall Harlan", "latency_ms": 614.8769855499268, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4112}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Tyrann Mathieu", "latency_ms": 424.527645111084, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tyrann Mathieu", "latency_ms": 626.258134841919, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 634.4640254974365, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 704.9205303192139, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 610.4686260223389, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2568}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 614.5346164703369, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3181}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 648.4661102294922, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3816}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "44", "latency_ms": 182.1293830871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Six", "latency_ms": 374.19986724853516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "six", "latency_ms": 397.0019817352295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "6 episodes", "latency_ms": 477.01025009155273, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2042}, "4": {"k": 4, "answer": "Six episodes", "latency_ms": 437.33882904052734, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2715}, "5": {"k": 5, "answer": "Six episodes", "latency_ms": 466.8083190917969, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3373}, "6": {"k": 6, "answer": "6 episodes", "latency_ms": 482.59449005126953, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4016}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul BaÃ¼mer's", "latency_ms": 423.7649440765381, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "German", "latency_ms": 367.311954498291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "German perspective", "latency_ms": 429.0437698364258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "German perspective", "latency_ms": 432.4681758880615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "German perspective", "latency_ms": 465.925931930542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "German perspective", "latency_ms": 425.82201957702637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "German perspective", "latency_ms": 440.25516510009766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3798}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris", "latency_ms": 226.06134414672852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 1029.4806957244873, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 1065.9558773040771, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1347}, "3": {"k": 3, "answer": "Frank Morris, John Anglin, Clarence Anglin, John Paul Scott", "latency_ms": 1196.3255405426025, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1986}, "4": {"k": 4, "answer": "Frank Morris, John Anglin, Clarence Anglin, John Paul Scott", "latency_ms": 1214.1380310058594, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Frank Morris, John Anglin, Clarence Anglin, John Paul Scott", "latency_ms": 1214.3971920013428, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3244}, "6": {"k": 6, "answer": "Frank Morris, John Anglin, Clarence Anglin, John Paul Scott", "latency_ms": 1194.5645809173584, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3898}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF programs.", "latency_ms": 421.170711517334, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF's global programming", "latency_ms": 714.7030830383301, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "UNICEF's global programming", "latency_ms": 666.6522026062012, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1350}, "3": {"k": 3, "answer": "UNICEF's global programming", "latency_ms": 715.4507637023926, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2070}, "4": {"k": 4, "answer": "UNICEF's global programming", "latency_ms": 716.7108058929443, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2800}, "5": {"k": 5, "answer": "UNICEF's global programming", "latency_ms": 666.4354801177979, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3488}, "6": {"k": 6, "answer": "UNICEF's global programming", "latency_ms": 686.8183612823486, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4114}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Tablet", "latency_ms": 219.9997901916504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the base", "latency_ms": 477.25415229797363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "at the base", "latency_ms": 480.06296157836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "at the base", "latency_ms": 484.38191413879395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "at the base", "latency_ms": 502.73609161376953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2578}, "5": {"k": 5, "answer": "at the base", "latency_ms": 507.5249671936035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "at the base", "latency_ms": 538.6142730712891, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3899}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "Milan-Cortina, Sapporo", "latency_ms": 671.302318572998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 561.1693859100342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Pyeongchang and Beijing", "latency_ms": 687.9227161407471, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Beijing, China and unknown", "latency_ms": 693.9220428466797, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1823}, "4": {"k": 4, "answer": "Beijing, China and unknown", "latency_ms": 687.8440380096436, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Pyeongchang and Beijing", "latency_ms": 724.7209548950195, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3180}, "6": {"k": 6, "answer": "Beijing, China and unknown", "latency_ms": 729.438304901123, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3852}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "October 22, 1981", "latency_ms": 527.9593467712402, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 558.6001873016357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "1997", "latency_ms": 435.4703426361084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "1997", "latency_ms": 470.2174663543701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "1997", "latency_ms": 440.6695365905762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "1997", "latency_ms": 435.08362770080566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": "1997", "latency_ms": 438.31324577331543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3859}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "Stone Gothic arch bridge", "latency_ms": 366.1165237426758, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rolling bascule bridge", "latency_ms": 690.7033920288086, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "single-leaf, through-truss, rolling bascule bridges", "latency_ms": 1267.0118808746338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1379}, "3": {"k": 3, "answer": "Rolling bascule bridge", "latency_ms": 679.067850112915, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2038}, "4": {"k": 4, "answer": "Stone Bridge", "latency_ms": 580.7657241821289, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2671}, "5": {"k": 5, "answer": "Stone Bridge", "latency_ms": 454.2126655578613, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3308}, "6": {"k": 6, "answer": "Stone Bridge", "latency_ms": 443.0108070373535, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3975}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The Autocrat", "latency_ms": 292.5076484680176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One person", "latency_ms": 428.80868911743164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "One person", "latency_ms": 427.7620315551758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1345}, "3": {"k": 3, "answer": "One person", "latency_ms": 481.0962677001953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2018}, "4": {"k": 4, "answer": "One person", "latency_ms": 438.02952766418457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2672}, "5": {"k": 5, "answer": "One person", "latency_ms": 445.9242820739746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3336}, "6": {"k": 6, "answer": "One person", "latency_ms": 438.4894371032715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4005}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "Affluence", "latency_ms": 292.56439208984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Economic expansion", "latency_ms": 507.80749320983887, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 726}, "2": {"k": 2, "answer": "Pride in new-found affluence", "latency_ms": 813.8163089752197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1399}, "3": {"k": 3, "answer": "other-directedness", "latency_ms": 515.4001712799072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2115}, "4": {"k": 4, "answer": "other-directedness", "latency_ms": 492.4886226654053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2743}, "5": {"k": 5, "answer": "other-directedness", "latency_ms": 505.3086280822754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3483}, "6": {"k": 6, "answer": "other-directedness", "latency_ms": 515.1646137237549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4192}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "Counterclockwise", "latency_ms": 358.94203186035156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Counterclockwise", "latency_ms": 550.1830577850342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "Counterclockwise", "latency_ms": 552.6454448699951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "Counterclockwise", "latency_ms": 543.2040691375732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1770}, "4": {"k": 4, "answer": "Counterclockwise", "latency_ms": 544.0609455108643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2344}, "5": {"k": 5, "answer": "Counterclockwise", "latency_ms": 565.1791095733643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3019}, "6": {"k": 6, "answer": "Counterclockwise", "latency_ms": 547.9621887207031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3590}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Statue of Freedom", "latency_ms": 355.3144931793213, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "an outdoor walkway", "latency_ms": 543.4379577636719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Statue of Freedom", "latency_ms": 540.2333736419678, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1177}, "3": {"k": 3, "answer": "Statue of Freedom", "latency_ms": 581.7275047302246, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "Statue of Freedom", "latency_ms": 609.5259189605713, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2367}, "5": {"k": 5, "answer": "Statue of Freedom", "latency_ms": 541.8965816497803, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3022}, "6": {"k": 6, "answer": "Statue of Freedom", "latency_ms": 549.7047901153564, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3682}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "Taoyuan Leopards", "latency_ms": 487.1020317077637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wizards", "latency_ms": 418.048620223999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "Washington Wizards", "latency_ms": 439.3646717071533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Washington Wizards", "latency_ms": 427.88195610046387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Washington Wizards", "latency_ms": 442.6722526550293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2454}, "5": {"k": 5, "answer": "Washington Wizards", "latency_ms": 445.79315185546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Washington Wizards", "latency_ms": 446.75254821777344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3773}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 367.50125885009766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chris Benoit", "latency_ms": 491.27197265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "Daniel Bryan", "latency_ms": 425.4136085510254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Rey Mysterio", "latency_ms": 622.8137016296387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Daniel Bryan", "latency_ms": 473.7975597381592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2491}, "5": {"k": 5, "answer": "Rey Mysterio", "latency_ms": 632.2877407073975, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Daniel Bryan", "latency_ms": 441.5113925933838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3729}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 289.1848087310791, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake of the Ozarks", "latency_ms": 595.2813625335693, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Lake Oahe", "latency_ms": 560.0361824035645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Lake Oahe", "latency_ms": 547.0921993255615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1810}, "4": {"k": 4, "answer": "Lake Oahe", "latency_ms": 588.9184474945068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2438}, "5": {"k": 5, "answer": "Lake Oahe", "latency_ms": 567.8975582122803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3122}, "6": {"k": 6, "answer": "Lake Oahe", "latency_ms": 544.140100479126, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3705}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Tagore", "latency_ms": 234.9398136138916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tagore", "latency_ms": 488.66796493530273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 585}, "2": {"k": 2, "answer": "Tagore", "latency_ms": 512.2618675231934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tagore", "latency_ms": 506.99877738952637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "Tagore", "latency_ms": 486.8905544281006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Tagore", "latency_ms": 489.06660079956055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3134}, "6": {"k": 6, "answer": "Tagore", "latency_ms": 473.9692211151123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3767}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "George H.W. Bush", "latency_ms": 422.81460762023926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "George H.W. Bush and Geraldine Ferraro", "latency_ms": 998.8856315612793, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 737}, "2": {"k": 2, "answer": "Geraldine Ferraro", "latency_ms": 606.3663959503174, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1452}, "3": {"k": 3, "answer": "Geraldine Ferraro", "latency_ms": 613.9805316925049, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2141}, "4": {"k": 4, "answer": "Geraldine Ferraro", "latency_ms": 613.4440898895264, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2825}, "5": {"k": 5, "answer": "Geraldine Ferraro", "latency_ms": 654.3645858764648, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3549}, "6": {"k": 6, "answer": "Geraldine Ferraro and George H.W. Bush", "latency_ms": 1012.4869346618652, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4311}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "American Rock Salt mine, Livingston County, New York", "latency_ms": 727.5946140289307, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Groveland", "latency_ms": 792.9019927978516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners, Groveland", "latency_ms": 818.6495304107666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1263}, "3": {"k": 3, "answer": "Hampton Corners", "latency_ms": 568.5594081878662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Hampton Corners, Groveland, New York", "latency_ms": 985.5773448944092, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "Hampton Corners", "latency_ms": 565.6683444976807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Goderich, Ontario", "latency_ms": 609.2214584350586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3842}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 235.3801727294922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 429.2128086090088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 440.6468868255615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 427.6123046875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 471.74620628356934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2469}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 424.0283966064453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3106}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 439.4690990447998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3673}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Meghalaya", "latency_ms": 297.0895767211914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Meghalaya", "latency_ms": 486.9039058685303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Meghalaya", "latency_ms": 534.9373817443848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Meghalaya", "latency_ms": 533.1385135650635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1953}, "4": {"k": 4, "answer": "Meghalaya", "latency_ms": 502.8953552246094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2522}, "5": {"k": 5, "answer": "Meghalaya", "latency_ms": 539.1199588775635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3167}, "6": {"k": 6, "answer": "Meghalaya", "latency_ms": 543.7092781066895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3848}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Kanpur", "latency_ms": 294.2996025085449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kanpur", "latency_ms": 501.8303394317627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Kanpur", "latency_ms": 473.30164909362793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Kanpur", "latency_ms": 486.0706329345703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1824}, "4": {"k": 4, "answer": "Kanpur", "latency_ms": 474.32875633239746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2472}, "5": {"k": 5, "answer": "Kanpur", "latency_ms": 487.6129627227783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3053}, "6": {"k": 6, "answer": "Kanpur", "latency_ms": 505.6014060974121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
