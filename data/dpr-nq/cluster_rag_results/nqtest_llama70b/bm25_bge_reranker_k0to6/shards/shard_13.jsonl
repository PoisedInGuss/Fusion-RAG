{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 295.6116199493408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 556.3712120056152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 556.55837059021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 544.7442531585693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1956}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 561.5513324737549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2588}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 563.086748123169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 596.7714786529541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3824}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 358.6163520812988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 607.3143482208252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 601.2794971466064, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 555.3314685821533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 595.0589179992676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2597}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 554.95285987854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3219}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 557.1742057800293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3892}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwest desert regions", "latency_ms": 343.7998294830322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 904.9444198608398, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "arid lowland or mountainous shrubland", "latency_ms": 948.6403465270996, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 965.4934406280518, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 994.8832988739014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 1040.921688079834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 1045.4270839691162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3932}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 480.3352355957031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dr. Rajendra Prasad", "latency_ms": 704.7421932220459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 743}, "2": {"k": 2, "answer": "Dr. Rajendra Prasad", "latency_ms": 680.8292865753174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1429}, "3": {"k": 3, "answer": "Dr. Rajendra Prasad", "latency_ms": 666.8646335601807, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2125}, "4": {"k": 4, "answer": "Dr. Rajendra Prasad", "latency_ms": 745.9056377410889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2814}, "5": {"k": 5, "answer": "Dr. Rajendra Prasad", "latency_ms": 665.184497833252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3509}, "6": {"k": 6, "answer": "Dr. Rajendra Prasad", "latency_ms": 671.7228889465332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4207}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 355.6656837463379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 587.1710777282715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 552.5453090667725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 587.9178047180176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 594.4638252258301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 567.8858757019043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3179}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 564.4080638885498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3861}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "June 22, 2001", "latency_ms": 536.9770526885986, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2001", "latency_ms": 409.2278480529785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "2001", "latency_ms": 440.62018394470215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "2001", "latency_ms": 474.49755668640137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1878}, "4": {"k": 4, "answer": "2001", "latency_ms": 447.3986625671387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2536}, "5": {"k": 5, "answer": "June 22, 2001", "latency_ms": 744.4348335266113, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3180}, "6": {"k": 6, "answer": "June 22, 2001", "latency_ms": 755.8343410491943, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3795}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 364.41659927368164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 768.4140205383301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 771.0649967193604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 744.0707683563232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 777.9359817504883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2705}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 781.3313007354736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3344}, "6": {"k": 6, "answer": "September 27, 2017", "latency_ms": 786.7159843444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4040}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3", "latency_ms": 303.76529693603516, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "February 14, 2013", "latency_ms": 902.0311832427979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "February 14, 2013", "latency_ms": 742.131233215332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "February 14, 2013", "latency_ms": 774.4505405426025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "February 14, 2013", "latency_ms": 744.823694229126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2648}, "5": {"k": 5, "answer": "February 14, 2013", "latency_ms": 747.1907138824463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3314}, "6": {"k": 6, "answer": "February 14, 2013", "latency_ms": 784.3444347381592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3975}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 353.59644889831543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 555.8624267578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 592.1645164489746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 552.9048442840576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 609.8330020904541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 602.2682189941406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3115}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 610.2776527404785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3815}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 422.3010540008545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Havana harbor, Cuba", "latency_ms": 667.884349822998, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "Havana harbor, Cuba", "latency_ms": 620.9607124328613, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Havana harbor, Cuba", "latency_ms": 618.3731555938721, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1910}, "4": {"k": 4, "answer": "Havana harbor, Cuba", "latency_ms": 601.6335487365723, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2533}, "5": {"k": 5, "answer": "Havana harbor, Cuba", "latency_ms": 607.2728633880615, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3164}, "6": {"k": 6, "answer": "Havana Harbor, Cuba", "latency_ms": 608.5216999053955, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3769}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 295.33958435058594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 593.1036472320557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "No specific god mentioned", "latency_ms": 627.0599365234375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1280}, "3": {"k": 3, "answer": "Lord Vasupujya", "latency_ms": 730.668306350708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1942}, "4": {"k": 4, "answer": "Lord Vishnu and Lord Shiva", "latency_ms": 784.5885753631592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Lord Vishnu and Lord Shiva and Lord Vasupujya", "latency_ms": 1157.1335792541504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "Lord Vishnu and Lord Shiva and Lord Ganesha", "latency_ms": 1082.1948051452637, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3870}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 545.8693504333496, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costa Rica, Nicaragua, Panama, Belize, Honduras, Guatemala, El Salvador", "latency_ms": 1299.321174621582, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Costa Rica, Panama", "latency_ms": 627.0956993103027, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1294}, "3": {"k": 3, "answer": "Costa Rica, Panama", "latency_ms": 624.7062683105469, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1901}, "4": {"k": 4, "answer": "Costa Rica, Panama", "latency_ms": 711.2562656402588, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2494}, "5": {"k": 5, "answer": "Panama, Costa Rica, Nicaragua", "latency_ms": 745.1872825622559, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Panama, Nicaragua, Costa Rica", "latency_ms": 763.7639045715332, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3823}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence", "latency_ms": 247.67804145812988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 443.13549995422363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Complex sentence", "latency_ms": 448.09985160827637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1350}, "3": {"k": 3, "answer": "Complex sentence", "latency_ms": 432.4185848236084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2037}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 438.356876373291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2743}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 453.70006561279297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3425}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 437.5929832458496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4084}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and trade.", "latency_ms": 413.9699935913086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 839.3816947937012, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 782.8061580657959, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 793.1075096130371, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 2000}, "4": {"k": 4, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 824.7678279876709, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 2681}, "5": {"k": 5, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 807.0614337921143, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3408}, "6": {"k": 6, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 800.3599643707275, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 4069}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 771.9106674194336, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 10, 2017", "latency_ms": 765.0308609008789, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "October 10, 2017", "latency_ms": 725.7840633392334, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 740.6675815582275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 778.0678272247314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2494}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 744.4562911987305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3109}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 749.7649192810059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere", "latency_ms": 480.1778793334961, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northern Territory", "latency_ms": 399.07073974609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "Northern Territory", "latency_ms": 416.4998531341553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Asia outside of Russia", "latency_ms": 542.8307056427002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1907}, "4": {"k": 4, "answer": "Asia outside of Russia", "latency_ms": 540.2255058288574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "Southern part of the Northern Territory", "latency_ms": 671.8056201934814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3248}, "6": {"k": 6, "answer": "Southern part of the Northern Territory", "latency_ms": 687.889814376831, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3956}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Leia Organa", "latency_ms": 358.40821266174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 540.1005744934082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "Leia", "latency_ms": 419.66819763183594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "Leia", "latency_ms": 435.1522922515869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1785}, "4": {"k": 4, "answer": "Leia", "latency_ms": 440.8140182495117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2382}, "5": {"k": 5, "answer": "Leia, Callista", "latency_ms": 612.7476692199707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2994}, "6": {"k": 6, "answer": "Callista", "latency_ms": 446.9037055969238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3614}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 238.2831573486328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Allen Ludden", "latency_ms": 481.61768913269043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "Allen Ludden", "latency_ms": 489.70603942871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Barry Cryer", "latency_ms": 543.7803268432617, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "Jack Barry", "latency_ms": 464.6108150482178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2471}, "5": {"k": 5, "answer": "Barry Cryer", "latency_ms": 548.6059188842773, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3021}, "6": {"k": 6, "answer": "Barry Cryer", "latency_ms": 546.9164848327637, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3654}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 296.0772514343262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mitochondrion", "latency_ms": 562.6249313354492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 707}, "2": {"k": 2, "answer": "Mitochondrion and Chloroplast", "latency_ms": 745.9568977355957, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1366}, "3": {"k": 3, "answer": "Mitochondrion and Chloroplast", "latency_ms": 802.6759624481201, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2064}, "4": {"k": 4, "answer": "Mitochondria and Chloroplasts", "latency_ms": 761.5869045257568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2715}, "5": {"k": 5, "answer": "Mitochondria and Chloroplasts", "latency_ms": 767.6370143890381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3391}, "6": {"k": 6, "answer": "Mitochondria and Chloroplasts", "latency_ms": 754.6279430389404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4070}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Backup.", "latency_ms": 940.5176639556885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 591.9604301452637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 538.8219356536865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1380}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 559.9710941314697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2097}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 592.8511619567871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2806}, "5": {"k": 5, "answer": "Veriato, Armitage, Metasploit, Spector Pro, Centrify", "latency_ms": 1513.9060020446777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3562}, "6": {"k": 6, "answer": "Armitage, Veriato, Metasploit, Spector Pro, Centrato", "latency_ms": 1500.8132457733154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4251}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 547.7612018585205, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenny Rogers and Dottie West", "latency_ms": 753.5698413848877, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 590}, "2": {"k": 2, "answer": "Kenny Rogers and Dottie West", "latency_ms": 756.1612129211426, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Dottie West and Kenny Rogers", "latency_ms": 689.4187927246094, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Dottie West and Kenny Rogers", "latency_ms": 731.8618297576904, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "Dottie West and Kenny Rogers", "latency_ms": 688.612699508667, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3082}, "6": {"k": 6, "answer": "Dottie West and Kenny Rogers", "latency_ms": 695.8737373352051, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3663}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 300.75860023498535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Two years of age", "latency_ms": 546.2782382965088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 581}, "2": {"k": 2, "answer": "36 months", "latency_ms": 419.1474914550781, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1200}, "3": {"k": 3, "answer": "36 months old", "latency_ms": 484.8911762237549, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "36 months old", "latency_ms": 493.44897270202637, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2526}, "5": {"k": 5, "answer": "36 months old", "latency_ms": 489.87674713134766, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3129}, "6": {"k": 6, "answer": "36 months", "latency_ms": 443.36533546447754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3836}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 179.5828342437744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Three-part", "latency_ms": 415.96508026123047, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Three-part", "latency_ms": 414.68024253845215, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Three", "latency_ms": 377.28118896484375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Three", "latency_ms": 407.75108337402344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2599}, "5": {"k": 5, "answer": "Three", "latency_ms": 382.8859329223633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3264}, "6": {"k": 6, "answer": "Three", "latency_ms": 385.0054740905762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3904}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 1036.2474918365479, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elijah Wood", "latency_ms": 521.8803882598877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "Elijah Wood", "latency_ms": 495.5267906188965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1258}, "3": {"k": 3, "answer": "Elijah Wood", "latency_ms": 502.1653175354004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1919}, "4": {"k": 4, "answer": "Elijah Wood", "latency_ms": 532.7432155609131, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Elijah Wood", "latency_ms": 510.24818420410156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3233}, "6": {"k": 6, "answer": "Elijah Wood", "latency_ms": 553.1468391418457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3862}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party", "latency_ms": 302.69718170166016, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume party", "latency_ms": 486.98949813842773, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "Fancy dress party", "latency_ms": 568.5825347900391, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Fancy dress party", "latency_ms": 816.8582916259766, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1971}, "4": {"k": 4, "answer": "Fancy dress party", "latency_ms": 559.7116947174072, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2647}, "5": {"k": 5, "answer": "Fancy dress party", "latency_ms": 566.1344528198242, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3310}, "6": {"k": 6, "answer": "Fancy dress party", "latency_ms": 562.3085498809814, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3940}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 174.16095733642578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 584.0094089508057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 584.8665237426758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 558.3159923553467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 553.6010265350342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "1", "latency_ms": 406.47435188293457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3225}, "6": {"k": 6, "answer": "1", "latency_ms": 447.5288391113281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3912}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "He promised Fantine", "latency_ms": 499.9046325683594, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fantine's debts", "latency_ms": 745.0509071350098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "Fantine's debts", "latency_ms": 723.42848777771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Because she was Fantine's daughter", "latency_ms": 995.3038692474365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Because she was Fantine's daughter", "latency_ms": 760.6785297393799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Because she was Fantine's daughter", "latency_ms": 805.201530456543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "Because she was Fantine's daughter", "latency_ms": 763.9245986938477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3701}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, and South Korea.", "latency_ms": 611.8757724761963, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenya", "latency_ms": 426.93090438842773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 688}, "2": {"k": 2, "answer": "Kenya", "latency_ms": 418.0607795715332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1382}, "3": {"k": 3, "answer": "Kenya and India", "latency_ms": 569.0329074859619, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Kenya, India", "latency_ms": 610.8477115631104, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2788}, "5": {"k": 5, "answer": "Kenya, India, Norway, Russia", "latency_ms": 942.0688152313232, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3489}, "6": {"k": 6, "answer": "Kenya, India, Norway, Russia", "latency_ms": 984.389066696167, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 4162}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and control.", "latency_ms": 545.954704284668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 1349.3549823760986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 1340.8422470092773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 1337.6972675323486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 1363.2984161376953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 1353.1315326690674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 1349.44748878479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4130}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 297.7433204650879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 628.9901733398438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 623.2092380523682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Indian python", "latency_ms": 463.7026786804199, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1830}, "4": {"k": 4, "answer": "Indian python", "latency_ms": 440.91343879699707, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "Indian python", "latency_ms": 439.4674301147461, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3040}, "6": {"k": 6, "answer": "Indian python", "latency_ms": 437.7117156982422, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3650}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 233.72483253479004, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "water-ice", "latency_ms": 505.06019592285156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "water-ice", "latency_ms": 467.50950813293457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1200}, "3": {"k": 3, "answer": "water-ice", "latency_ms": 470.2563285827637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1776}, "4": {"k": 4, "answer": "water-ice", "latency_ms": 490.7209873199463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2423}, "5": {"k": 5, "answer": "water-ice", "latency_ms": 476.6426086425781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2996}, "6": {"k": 6, "answer": "water-ice", "latency_ms": 481.8413257598877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3644}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 625.584602355957, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Season four premiere", "latency_ms": 487.030029296875, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 594}, "2": {"k": 2, "answer": "Season four premiere", "latency_ms": 484.15637016296387, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1217}, "3": {"k": 3, "answer": "Season 3 finale", "latency_ms": 553.8527965545654, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1818}, "4": {"k": 4, "answer": "Season 3 finale", "latency_ms": 542.9444313049316, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2382}, "5": {"k": 5, "answer": "Season 3 finale", "latency_ms": 554.1119575500488, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2999}, "6": {"k": 6, "answer": "Season 3 finale", "latency_ms": 547.5099086761475, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3599}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "Home team", "latency_ms": 243.12615394592285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 543.1756973266602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "BBC", "latency_ms": 352.0538806915283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1172}, "3": {"k": 3, "answer": "BBC", "latency_ms": 378.30471992492676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1768}, "4": {"k": 4, "answer": "BBC", "latency_ms": 381.5743923187256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2392}, "5": {"k": 5, "answer": "BBC", "latency_ms": 364.1026020050049, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2976}, "6": {"k": 6, "answer": "BBC", "latency_ms": 391.0033702850342, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3568}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw neighborhood", "latency_ms": 294.61050033569336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northwest", "latency_ms": 419.74854469299316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "Northwest Washington", "latency_ms": 485.2921962738037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Northwest", "latency_ms": 446.5656280517578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1995}, "4": {"k": 4, "answer": "Northwest Washington, DC.", "latency_ms": 730.3097248077393, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2687}, "5": {"k": 5, "answer": "Northwest", "latency_ms": 518.4152126312256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3299}, "6": {"k": 6, "answer": "Northwest", "latency_ms": 435.5614185333252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 306.2453269958496, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Covenant of Works", "latency_ms": 542.3092842102051, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "Noahic", "latency_ms": 507.19547271728516, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Covenant of Works", "latency_ms": 546.342134475708, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Covenant of Works", "latency_ms": 552.0114898681641, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2423}, "5": {"k": 5, "answer": "Covenant of Works", "latency_ms": 550.9123802185059, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "Noahic", "latency_ms": 510.73145866394043, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3733}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 358.701229095459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 601.5264987945557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 602.9520034790039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 545.4130172729492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1807}, "4": {"k": 4, "answer": "Jack Jones", "latency_ms": 443.9113140106201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2394}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 592.4501419067383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2969}, "6": {"k": 6, "answer": "Jack Jones", "latency_ms": 597.9769229888916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3572}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 418.61963272094727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ray Henderson", "latency_ms": 437.7315044403076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "Ray Henderson", "latency_ms": 421.7338562011719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Ray Henderson", "latency_ms": 469.8336124420166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Ray Henderson", "latency_ms": 471.64344787597656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "Ray Henderson", "latency_ms": 469.2878723144531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Ray Henderson", "latency_ms": 443.0654048919678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3732}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 293.3027744293213, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 437.3819828033447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 439.0535354614258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 475.3763675689697, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 422.26147651672363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2529}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 483.13236236572266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3176}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 484.9133491516113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3789}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "2nd", "latency_ms": 233.3357334136963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 555.6159019470215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 556.9345951080322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 544.8465347290039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 544.1164970397949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 551.347017288208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3079}, "6": {"k": 6, "answer": "11th largest", "latency_ms": 502.8212070465088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3698}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 415.79318046569824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mahatma Gandhi", "latency_ms": 547.7988719940186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 706}, "2": {"k": 2, "answer": "Mahatma Gandhi", "latency_ms": 558.6111545562744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1429}, "3": {"k": 3, "answer": "Sonia Gandhi", "latency_ms": 485.26835441589355, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2103}, "4": {"k": 4, "answer": "Sonia Gandhi", "latency_ms": 484.10940170288086, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2799}, "5": {"k": 5, "answer": "Mahatma Gandhi", "latency_ms": 557.6009750366211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3509}, "6": {"k": 6, "answer": "Jawaharlal Nehru", "latency_ms": 680.2458763122559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4184}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenifer Lewis", "latency_ms": 364.4709587097168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "La Toya Jackson", "latency_ms": 573.1360912322998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 578.432559967041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1263}, "3": {"k": 3, "answer": "Bobby Flay", "latency_ms": 613.3363246917725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "Bobby Flay", "latency_ms": 558.1953525543213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Bobby Flay", "latency_ms": 585.1712226867676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3086}, "6": {"k": 6, "answer": "Bobby Flay", "latency_ms": 571.4178085327148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3703}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 190.3231143951416, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 363.05785179138184, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": ".java", "latency_ms": 387.6605033874512, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": ".java", "latency_ms": 368.9999580383301, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": ".java", "latency_ms": 427.29997634887695, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": ".java", "latency_ms": 413.07711601257324, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": ".java", "latency_ms": 381.53958320617676, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 255.16605377197266, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alan Turing", "latency_ms": 434.8304271697998, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Alan Turing", "latency_ms": 432.8315258026123, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1289}, "3": {"k": 3, "answer": "Alan Turing", "latency_ms": 451.8930912017822, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 441.65515899658203, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2530}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 458.35351943969727, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3124}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 446.4602470397949, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3756}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline", "latency_ms": 373.13032150268555, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ensure party members adhere to party policies", "latency_ms": 855.7274341583252, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "ensure members adhere to party policies", "latency_ms": 693.8681602478027, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "to ensure members adhere to party policies", "latency_ms": 727.5724411010742, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "to ensure members adhere to party policies", "latency_ms": 716.0825729370117, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "to ensure members adhere to party policies", "latency_ms": 711.1740112304688, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "to gather votes on major issues", "latency_ms": 670.2160835266113, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 3850}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 243.1037425994873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 544.5454120635986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 584.1662883758545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 593.8172340393066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 621.290922164917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 595.900297164917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3311}, "6": {"k": 6, "answer": "1973", "latency_ms": 532.9959392547607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3866}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the right but not the obligation to buy foreign currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 297.5733280181885, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 420.02224922180176, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 428.3111095428467, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 454.4999599456787, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "FX option", "latency_ms": 442.95430183410645, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2700}, "5": {"k": 5, "answer": "FX option", "latency_ms": 448.4131336212158, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3357}, "6": {"k": 6, "answer": "Call option", "latency_ms": 488.83581161499023, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4005}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 234.66730117797852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 473.2625484466553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360", "latency_ms": 392.2688961029053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1376}, "3": {"k": 3, "answer": "360", "latency_ms": 369.6770668029785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2070}, "4": {"k": 4, "answer": "360 members", "latency_ms": 435.23454666137695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2700}, "5": {"k": 5, "answer": "360 members", "latency_ms": 442.2783851623535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3342}, "6": {"k": 6, "answer": "360", "latency_ms": 379.4891834259033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3995}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 379.06670570373535, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 576.9603252410889, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 595.1476097106934, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 559.2751502990723, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 557.4591159820557, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 563.9572143554688, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3183}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 564.7859573364258, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3835}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gorm"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 408.1683158874512, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eydie Gorm", "latency_ms": 595.2358245849609, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 580}, "2": {"k": 2, "answer": "Eydie Gorm", "latency_ms": 660.2673530578613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1156}, "3": {"k": 3, "answer": "Eydie Gorm", "latency_ms": 656.7518711090088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1757}, "4": {"k": 4, "answer": "Eydie Gorm", "latency_ms": 652.0135402679443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2334}, "5": {"k": 5, "answer": "Eydie Gorm", "latency_ms": 656.5709114074707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2965}, "6": {"k": 6, "answer": "Eydie Gorm", "latency_ms": 607.1348190307617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3515}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "Kurian Joseph", "latency_ms": 363.54637145996094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jasti Chelameswar", "latency_ms": 716.1643505096436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Jasti Chelameswar", "latency_ms": 712.719202041626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Jasti Chelameswar", "latency_ms": 726.4120578765869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "Jasti Chelameswar", "latency_ms": 727.3898124694824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2481}, "5": {"k": 5, "answer": "Jasti Chelameswar", "latency_ms": 719.7284698486328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3093}, "6": {"k": 6, "answer": "Jasti Chelameswar", "latency_ms": 729.1264533996582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3657}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 353.1839847564697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roger Federer", "latency_ms": 492.27356910705566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 635}, "2": {"k": 2, "answer": "Roger Federer", "latency_ms": 500.1645088195801, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Roger Federer", "latency_ms": 480.2885055541992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1790}, "4": {"k": 4, "answer": "Roger Federer", "latency_ms": 481.7209243774414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2362}, "5": {"k": 5, "answer": "Roger Federer", "latency_ms": 530.0748348236084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3023}, "6": {"k": 6, "answer": "Margaret Court", "latency_ms": 501.04713439941406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3597}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 174.39532279968262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Once", "latency_ms": 399.6882438659668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "1", "latency_ms": 413.45787048339844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1221}, "3": {"k": 3, "answer": "Once", "latency_ms": 452.1288871765137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1834}, "4": {"k": 4, "answer": "1", "latency_ms": 387.7730369567871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2444}, "5": {"k": 5, "answer": "1", "latency_ms": 389.2548084259033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3051}, "6": {"k": 6, "answer": "1", "latency_ms": 383.56566429138184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3682}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 246.1373805999756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2016", "latency_ms": 478.90686988830566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "2002", "latency_ms": 484.97509956359863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "2010", "latency_ms": 486.79232597351074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1938}, "4": {"k": 4, "answer": "2010", "latency_ms": 474.61700439453125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2619}, "5": {"k": 5, "answer": "2010", "latency_ms": 454.30660247802734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "2016", "latency_ms": 449.2197036743164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3855}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 184.25488471984863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 561.9871616363525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "Not stated.", "latency_ms": 499.194860458374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "37", "latency_ms": 383.32653045654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "37", "latency_ms": 437.15524673461914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "37", "latency_ms": 429.7802448272705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "37", "latency_ms": 413.3884906768799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3896}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 419.7959899902344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 634.4232559204102, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 622.8747367858887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 603.9133071899414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1815}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 652.4419784545898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 603.8596630096436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3082}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 623.25119972229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3712}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 718.2350158691406, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 539.04128074646, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 587}, "2": {"k": 2, "answer": "Corey, Cory", "latency_ms": 528.5613536834717, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1188}, "3": {"k": 3, "answer": "Corey, Cory", "latency_ms": 557.8784942626953, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Corey, Cory", "latency_ms": 557.6043128967285, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2481}, "5": {"k": 5, "answer": "Corey, Cory", "latency_ms": 592.6558971405029, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3134}, "6": {"k": 6, "answer": "Corey, Cory, Gowdy, Goudy", "latency_ms": 1053.5719394683838, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3755}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 303.3175468444824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 597.3899364471436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 599.1494655609131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1374}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 558.4044456481934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 558.5706233978271, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2669}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 599.3607044219971, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3298}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 599.1945266723633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3901}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 207.0024013519287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 375.3645420074463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "159", "latency_ms": 354.33459281921387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "159", "latency_ms": 371.3672161102295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "159", "latency_ms": 359.3151569366455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2732}, "5": {"k": 5, "answer": "159", "latency_ms": 385.49017906188965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3379}, "6": {"k": 6, "answer": "159", "latency_ms": 381.93511962890625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4038}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 363.1434440612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Egan", "latency_ms": 436.98930740356445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 581}, "2": {"k": 2, "answer": "Egan", "latency_ms": 440.16051292419434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Egan", "latency_ms": 448.3838081359863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "Egan", "latency_ms": 474.62010383605957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "Egan", "latency_ms": 483.9658737182617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3081}, "6": {"k": 6, "answer": "Egan", "latency_ms": 488.1143569946289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3737}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 300.14848709106445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pete Maravich", "latency_ms": 654.5023918151855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Pete Maravich", "latency_ms": 605.0889492034912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Pete Maravich", "latency_ms": 727.271318435669, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "Wilt Chamberlain", "latency_ms": 567.8412914276123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2537}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 601.1207103729248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3150}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 575.5653381347656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 357.82814025878906, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Right hand", "latency_ms": 410.9964370727539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 420.72296142578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1154}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 430.9420585632324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1756}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 439.34035301208496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2378}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 447.48425483703613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2972}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 409.5492362976074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3526}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 479.78973388671875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Donald Duck", "latency_ms": 431.5752983093262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Donald Duck", "latency_ms": 501.1262893676758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Donald Duck", "latency_ms": 444.55981254577637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Donald Duck", "latency_ms": 471.6947078704834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Donald Duck", "latency_ms": 446.66385650634766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3205}, "6": {"k": 6, "answer": "Donald Duck", "latency_ms": 496.1838722229004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3857}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 377.79784202575684, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 577.1152973175049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "Bernard Mayes", "latency_ms": 626.5377998352051, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "Bernard Mayes", "latency_ms": 590.0778770446777, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1910}, "4": {"k": 4, "answer": "Bernard Hill", "latency_ms": 612.9703521728516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2563}, "5": {"k": 5, "answer": "Bernard Mayes", "latency_ms": 611.314058303833, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "Bernard Mayes", "latency_ms": 604.5916080474854, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3875}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2019", "latency_ms": 540.576696395874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2018", "latency_ms": 725.121021270752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 744.6088790893555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1217}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 727.4742126464844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1847}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 727.0116806030273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2443}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 731.7755222320557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 730.644702911377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 237.1065616607666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 532.2775840759277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 534.2128276824951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1188}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 552.6320934295654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 567.1041011810303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2500}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 547.0077991485596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3096}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 565.9036636352539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3706}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 296.7982292175293, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Claire Holt", "latency_ms": 476.3772487640381, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Claire Holt", "latency_ms": 478.3368110656738, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "Claire Holt", "latency_ms": 498.10171127319336, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1799}, "4": {"k": 4, "answer": "Claire Holt", "latency_ms": 494.0459728240967, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2435}, "5": {"k": 5, "answer": "Claire Holt", "latency_ms": 483.4282398223877, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3006}, "6": {"k": 6, "answer": "Claire Holt", "latency_ms": 500.37598609924316, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3646}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living things", "latency_ms": 294.50082778930664, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in the biosphere", "latency_ms": 587.8188610076904, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 700}, "2": {"k": 2, "answer": "in all land-living organisms, soils, and plants", "latency_ms": 962.597131729126, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 1350}, "3": {"k": 3, "answer": "in all land-living organisms", "latency_ms": 679.7540187835693, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "in all land-living organisms, soils, and plants", "latency_ms": 966.9597148895264, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 2601}, "5": {"k": 5, "answer": "in all land-living organisms", "latency_ms": 686.561107635498, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3308}, "6": {"k": 6, "answer": "in all land-living organisms, soils, and plants", "latency_ms": 981.5442562103271, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 3961}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 356.9662570953369, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Akul Balaji", "latency_ms": 606.3196659088135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Akul Balaji", "latency_ms": 711.0636234283447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "Akul Balaji", "latency_ms": 553.6174774169922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Akul Balaji", "latency_ms": 569.7329044342041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Akul Balaji", "latency_ms": 612.6279830932617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Akul Balaji", "latency_ms": 616.8820858001709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3797}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 478.2853126525879, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kanab, Utah", "latency_ms": 594.1481590270996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "Kanab, Utah, Lake Powell", "latency_ms": 788.5501384735107, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Kanab, Utah, Lake Powell, Page, Arizona", "latency_ms": 1086.0302448272705, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1929}, "4": {"k": 4, "answer": "Utah, Arizona, Wyoming, Oroville, California, Lake Powell, Kanab, Page", "latency_ms": 1487.8969192504883, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 2574}, "5": {"k": 5, "answer": "Utah, Arizona, Wyoming, Oroville, California, Lake Powell, Page, Arizona, Kanab, Utah", "latency_ms": 1725.5115509033203, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 3201}, "6": {"k": 6, "answer": "Utah, Arizona, Wyoming, Oroville, California, Lake Powell, Page, Arizona, Kanab, Utah", "latency_ms": 1880.6190490722656, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 3819}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 300.54187774658203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kevin Kline", "latency_ms": 493.4408664703369, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Kevin Kline", "latency_ms": 497.66016006469727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1323}, "3": {"k": 3, "answer": "Kevin Kline", "latency_ms": 481.64916038513184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1957}, "4": {"k": 4, "answer": "Kevin Kline", "latency_ms": 530.2314758300781, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "Kevin Kline", "latency_ms": 499.5753765106201, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3241}, "6": {"k": 6, "answer": "Kevin Kline", "latency_ms": 534.1296195983887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3908}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Lake Winnipeg", "latency_ms": 481.29987716674805, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 618.4346675872803, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 708}, "2": {"k": 2, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 620.0683116912842, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1438}, "3": {"k": 3, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 601.35817527771, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2136}, "4": {"k": 4, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 591.2876129150391, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2791}, "5": {"k": 5, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 625.0584125518799, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3435}, "6": {"k": 6, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 615.3228282928467, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4040}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 235.2292537689209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 439.5332336425781, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome, Italy", "latency_ms": 567.3162937164307, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Rome, Italy", "latency_ms": 615.1158809661865, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 551.1503219604492, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 590.6858444213867, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3108}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 583.1165313720703, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3743}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "Measurement mark", "latency_ms": 253.53217124938965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "manufacturing company or site", "latency_ms": 621.4859485626221, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "the manufacturing company or site", "latency_ms": 713.6020660400391, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1255}, "3": {"k": 3, "answer": "manufacturing company or site", "latency_ms": 632.0168972015381, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "the manufacturing company or site", "latency_ms": 610.0835800170898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2406}, "5": {"k": 5, "answer": "the manufacturing company or site", "latency_ms": 613.5842800140381, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2980}, "6": {"k": 6, "answer": "the manufacturing company or site", "latency_ms": 624.5715618133545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3601}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia", "latency_ms": 302.2439479827881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 826.4825344085693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 845.9792137145996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "hydrogen fluoride, ammonia, methanol, DNA, proteins", "latency_ms": 1035.9907150268555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "hydrogen fluoride, ammonia, methanol, DNA, proteins", "latency_ms": 1097.2685813903809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2596}, "5": {"k": 5, "answer": "hydrogen fluoride, ammonia, methanol, DNA, proteins", "latency_ms": 1020.5838680267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol, DNA, proteins", "latency_ms": 1100.1157760620117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3885}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Boy Meets Girl", "latency_ms": 359.46202278137207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 409.9392890930176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "1988", "latency_ms": 460.7527256011963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1196}, "3": {"k": 3, "answer": "1988", "latency_ms": 421.7839241027832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1799}, "4": {"k": 4, "answer": "1988", "latency_ms": 442.26813316345215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2390}, "5": {"k": 5, "answer": "1988", "latency_ms": 526.2947082519531, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3000}, "6": {"k": 6, "answer": "1988", "latency_ms": 496.09971046447754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3619}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 246.58942222595215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Manille", "latency_ms": 421.36454582214355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Manille", "latency_ms": 427.5181293487549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Manille", "latency_ms": 436.3739490509033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1792}, "4": {"k": 4, "answer": "Manille", "latency_ms": 433.5176944732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2373}, "5": {"k": 5, "answer": "Manille", "latency_ms": 421.4613437652588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2944}, "6": {"k": 6, "answer": "Manille", "latency_ms": 426.00250244140625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3530}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 354.724645614624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Five percent", "latency_ms": 404.2396545410156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "2% to 16%", "latency_ms": 645.5810070037842, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "2% to 16%", "latency_ms": 683.89892578125, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 664.0708446502686, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2458}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 681.3726425170898, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3087}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 666.3317680358887, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3775}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 233.38770866394043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1975", "latency_ms": 414.1879081726074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "1975", "latency_ms": 414.9436950683594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1185}, "3": {"k": 3, "answer": "1975", "latency_ms": 435.39881706237793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1763}, "4": {"k": 4, "answer": "1975", "latency_ms": 433.18939208984375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2388}, "5": {"k": 5, "answer": "1975", "latency_ms": 468.982458114624, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3008}, "6": {"k": 6, "answer": "1975", "latency_ms": 439.8798942565918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3593}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 353.9273738861084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 576.0133266448975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Lionel Richie", "latency_ms": 586.190938949585, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1199}, "3": {"k": 3, "answer": "Lionel Richie", "latency_ms": 541.1496162414551, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1806}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 557.5542449951172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2421}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 544.715404510498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3068}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 571.6168880462646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3662}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert", "latency_ms": 430.3317070007324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "George Calvert", "latency_ms": 494.00877952575684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "George Calvert", "latency_ms": 479.80594635009766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Cecil Calvert", "latency_ms": 630.7365894317627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Cecil Calvert", "latency_ms": 628.328800201416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2629}, "5": {"k": 5, "answer": "Cecil Calvert", "latency_ms": 606.9290637969971, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3323}, "6": {"k": 6, "answer": "Cecil Calvert and his brother Leonard Calvert", "latency_ms": 979.142427444458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3953}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 239.15433883666992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiger Woods", "latency_ms": 514.106273651123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Jack Nicklaus", "latency_ms": 511.25335693359375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Jack Nicklaus", "latency_ms": 509.0639591217041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "Jack Nicklaus", "latency_ms": 497.5135326385498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Jack Nicklaus", "latency_ms": 501.88612937927246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3115}, "6": {"k": 6, "answer": "Jack Nicklaus", "latency_ms": 487.63585090637207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3719}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 354.2792797088623, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 555.1674365997314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "200 to 500 mg", "latency_ms": 607.1557998657227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg", "latency_ms": 665.257453918457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1889}, "4": {"k": 4, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 980.1135063171387, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 978.456974029541, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 1040.4822826385498, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3897}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 470.11756896972656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham United", "latency_ms": 471.8911647796631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 586}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 494.21072006225586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 506.15382194519043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1805}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 478.1630039215088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2397}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 486.4485263824463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2916}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 490.73266983032227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3533}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 305.1016330718994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Paris and Spain", "latency_ms": 478.03425788879395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "a friend's house or a nearby park", "latency_ms": 831.8638801574707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "a friend's house or a nearby park", "latency_ms": 829.7097682952881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "a friend's house or a nearby park", "latency_ms": 798.2566356658936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "a friend's house or a nearby park", "latency_ms": 810.2104663848877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3259}, "6": {"k": 6, "answer": "a friend's house or a nearby park", "latency_ms": 834.8038196563721, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh", "latency_ms": 231.1725616455078, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 554.140567779541, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 591.0613536834717, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1372}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 557.0418834686279, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2068}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 543.6720848083496, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 530.6081771850586, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3333}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 556.5934181213379, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3984}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 297.66154289245605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 584.7578048706055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 582.0844173431396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Roman Reigns", "latency_ms": 494.36020851135254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Bray Wyatt", "latency_ms": 481.36258125305176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2609}, "5": {"k": 5, "answer": "Bray Wyatt", "latency_ms": 484.4338893890381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3226}, "6": {"k": 6, "answer": "Bray Wyatt", "latency_ms": 483.170747756958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3897}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 421.3385581970215, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Southport, North Carolina", "latency_ms": 600.287914276123, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Southport, North Carolina.", "latency_ms": 681.3888549804688, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Southport, North Carolina.", "latency_ms": 679.4037818908691, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Southport, North Carolina.", "latency_ms": 657.3569774627686, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Southport, North Carolina.", "latency_ms": 682.7805042266846, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Southport, North Carolina.", "latency_ms": 669.874906539917, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3759}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 301.8908500671387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 558.9711666107178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "Sylvia F. Porter", "latency_ms": 683.1884384155273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Sylvia F. Porter", "latency_ms": 685.0383281707764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 666.3331985473633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 686.9583129882812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3171}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 672.0070838928223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3846}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 298.74253273010254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 472.9588031768799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 714}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 478.1956672668457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1414}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 554.6257495880127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2151}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 504.50778007507324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2897}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 507.14707374572754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3534}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 500.58603286743164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4176}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 168.72429847717285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 372.06029891967773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "Max", "latency_ms": 371.57654762268066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1247}, "3": {"k": 3, "answer": "Max", "latency_ms": 386.0020637512207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Max", "latency_ms": 376.4221668243408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2452}, "5": {"k": 5, "answer": "Max", "latency_ms": 409.1296195983887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Max", "latency_ms": 380.5675506591797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3796}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 354.9838066101074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 572.4918842315674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 578.413724899292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 572.8027820587158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "Megan Follows", "latency_ms": 544.550895690918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Megan Follows", "latency_ms": 535.7787609100342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Megan Follows", "latency_ms": 547.1148490905762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3790}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "Industrialization and imperialism.", "latency_ms": 421.02766036987305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Women starting to serve in limited military roles.", "latency_ms": 861.041784286499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "World War was not, but Exposition Universelle and Paris 1900 chess tournament were.", "latency_ms": 1506.2155723571777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "World Exposition", "latency_ms": 513.6704444885254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "World Exposition", "latency_ms": 553.7412166595459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "World Exposition, Paris 1900 chess tournament, Women starting to serve in military roles.", "latency_ms": 1559.0829849243164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3271}, "6": {"k": 6, "answer": "Exposition Universelle", "latency_ms": 626.427173614502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3863}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 311.71131134033203, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Brisbane Roar's theme song", "latency_ms": 829.125165939331, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 619.819164276123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Empowerment", "latency_ms": 479.50148582458496, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Empowerment", "latency_ms": 526.2289047241211, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2587}, "5": {"k": 5, "answer": "Empowerment", "latency_ms": 553.4322261810303, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "Empowerment", "latency_ms": 507.9317092895508, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3951}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 234.66777801513672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "National Football League (NFL) franchises", "latency_ms": 741.0917282104492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "National Football League franchises", "latency_ms": 564.5952224731445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "National Football League franchises", "latency_ms": 542.914867401123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "National Football League franchises", "latency_ms": 540.36545753479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2513}, "5": {"k": 5, "answer": "National Football League franchises", "latency_ms": 545.8042621612549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "National Football League franchises", "latency_ms": 549.4351387023926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3722}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 355.4418087005615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Marshall", "latency_ms": 424.454927444458, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "James Marshall", "latency_ms": 443.1123733520508, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "James Marshall", "latency_ms": 447.10826873779297, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": "James Marshall", "latency_ms": 427.9444217681885, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "James Marshall", "latency_ms": 454.04934883117676, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3220}, "6": {"k": 6, "answer": "James Marshall", "latency_ms": 426.5248775482178, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3781}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 304.22258377075195, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 549.4346618652344, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 535.4998111724854, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 536.9100570678711, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 544.996976852417, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2505}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 542.2024726867676, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3136}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 546.5841293334961, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 358.00719261169434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 584.6631526947021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 539.6766662597656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 589.3862247467041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 559.3628883361816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2489}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 588.1125926971436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3139}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 744.5814609527588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3745}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 654.2248725891113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart", "latency_ms": 455.2006721496582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 804.1448593139648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1227}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 807.0766925811768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1863}, "4": {"k": 4, "answer": "Charles Hart", "latency_ms": 438.4129047393799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2497}, "5": {"k": 5, "answer": "Charles Hart", "latency_ms": 438.63749504089355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3161}, "6": {"k": 6, "answer": "Charles Hart", "latency_ms": 442.4765110015869, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3836}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 233.306884765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northern Europe and Central European", "latency_ms": 588.895320892334, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "Northern Europe and Central European", "latency_ms": 599.8432636260986, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Northern Europe and Central European cultures.", "latency_ms": 720.7746505737305, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "Northern Europe and Central European cultures.", "latency_ms": 741.9910430908203, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Northern Europe and Central European cultures.", "latency_ms": 718.116044998169, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3406}, "6": {"k": 6, "answer": "Northern Europe and Central Europe", "latency_ms": 627.0933151245117, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4098}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 293.6358451843262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 541.6574478149414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 552.3154735565186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 558.9170455932617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "16481651", "latency_ms": 663.9034748077393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2648}, "5": {"k": 5, "answer": "16481651", "latency_ms": 676.59592628479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3409}, "6": {"k": 6, "answer": "16481651", "latency_ms": 668.9705848693848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4087}}}
