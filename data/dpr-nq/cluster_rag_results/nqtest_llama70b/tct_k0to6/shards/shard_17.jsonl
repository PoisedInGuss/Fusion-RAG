{"qid": "-9197932657152136610", "question": "what are the main sources of economic growth in the us currently", "gold_answers": ["pharmaceuticals", "aircraft", "telecommunications", "heavy machinery"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 578.2601833343506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "investment, new products and services", "latency_ms": 875.2508163452148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "investment, new products and services", "latency_ms": 897.0990180969238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "investment, new products and services", "latency_ms": 870.560884475708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "investment, new products and services, labor, capital, efficiency", "latency_ms": 1699.3038654327393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2611}, "5": {"k": 5, "answer": "increases in labour, increase in capital and increase in efficiency", "latency_ms": 1481.658935546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3381}, "6": {"k": 6, "answer": "increases in labour, increase in capital and increase in efficiency", "latency_ms": 1655.0211906433105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4053}}}
{"qid": "-4566914757117567579", "question": "who played ethel on the doris day show", "gold_answers": ["Carol Worthington"], "shots": {"0": {"k": 0, "answer": "Kay Chanda", "latency_ms": 737.454891204834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 839.7865295410156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 597.0683097839355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 572.3497867584229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 569.328784942627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 574.9938488006592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3130}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 604.7344207763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3742}}}
{"qid": "212435016090205927", "question": "who played g baby in the movie hardball", "gold_answers": ["DeWayne Warren"], "shots": {"0": {"k": 0, "answer": "Keanu Reeves", "latency_ms": 562.669038772583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 774.395227432251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 797.330379486084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 816.7197704315186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1807}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 574.4080543518066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2426}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 605.8545112609863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3073}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 576.3280391693115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3657}}}
{"qid": "-4190633494852415957", "question": "who played john coffey in the movie the green mile", "gold_answers": ["Michael Clarke Duncan"], "shots": {"0": {"k": 0, "answer": "Michael Clarke Duncan", "latency_ms": 312.0589256286621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Clarke Duncan", "latency_ms": 508.18490982055664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Michael Clarke Duncan", "latency_ms": 531.369686126709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1227}, "3": {"k": 3, "answer": "Michael Clarke Duncan", "latency_ms": 711.1637592315674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1866}, "4": {"k": 4, "answer": "Michael Clarke Duncan", "latency_ms": 515.1855945587158, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2532}, "5": {"k": 5, "answer": "Michael Clarke Duncan", "latency_ms": 492.45572090148926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3151}, "6": {"k": 6, "answer": "Michael Clarke Duncan", "latency_ms": 517.2169208526611, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3791}}}
{"qid": "811267239470530686", "question": "who wrote catch 22 (both names)", "gold_answers": ["American author Joseph Heller", "Joseph Heller .", "Joseph Heller"], "shots": {"0": {"k": 0, "answer": "Joseph Heller", "latency_ms": 246.1221218109131, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Joseph Heller", "latency_ms": 444.02050971984863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 630}, "2": {"k": 2, "answer": "Joseph Heller", "latency_ms": 490.71502685546875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Joseph Heller, Tomas Kalnoky", "latency_ms": 993.3600425720215, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Joseph Heller, Tomas Kalnoky", "latency_ms": 759.8865032196045, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Joseph Heller, Tomas Kalnoky", "latency_ms": 795.874834060669, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3200}, "6": {"k": 6, "answer": "Joseph Heller Tomas Kalnoky", "latency_ms": 703.6426067352295, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3863}}}
{"qid": "-1608179127534867277", "question": "where was the world chess tournament 2017 held", "gold_answers": ["Tbilisi , Georgia", "in Tbilisi , Georgia"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 191.26105308532715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 553.0316829681396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 555.6328296661377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1384}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 737.1072769165039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2066}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 741.8835163116455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2706}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 789.1867160797119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3372}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 750.6194114685059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4015}}}
{"qid": "7687115121611301468", "question": "who votes to elect a rajya sabha memmber", "gold_answers": ["state legislatures"], "shots": {"0": {"k": 0, "answer": "Elected members of State Legislative Assembly", "latency_ms": 750.6124973297119, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "MLAs", "latency_ms": 616.877555847168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 574.5882987976074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1160}, "3": {"k": 3, "answer": "MLAs", "latency_ms": 707.5009346008301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1795}, "4": {"k": 4, "answer": "MLA", "latency_ms": 457.28540420532227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2432}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 810.8482360839844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3061}, "6": {"k": 6, "answer": "Elected members of the State Assembly", "latency_ms": 1180.8278560638428, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3695}}}
{"qid": "-5784633834792163973", "question": "when does season 8 of hawaii five o premiere", "gold_answers": ["September 29 , 2017"], "shots": {"0": {"k": 0, "answer": "September 27, 2017", "latency_ms": 798.757791519165, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 29, 2017", "latency_ms": 1051.1150360107422, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "September 29, 2017", "latency_ms": 962.5115394592285, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "September 29, 2017", "latency_ms": 1144.9143886566162, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "September 29, 2017", "latency_ms": 1133.2402229309082, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2477}, "5": {"k": 5, "answer": "September 29, 2017", "latency_ms": 1038.6922359466553, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "September 29, 2017", "latency_ms": 1036.1578464508057, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3801}}}
{"qid": "-5864397450755103545", "question": "paul walkers cars in fast and furious list", "gold_answers": ["1995 Toyota Supra", "2002 Mitsubishi Lancer OZ Rally", "1995 Dodge Stealth", "1995 Mitsubishi Eclipse"], "shots": {"0": {"k": 0, "answer": "Toyota Supra, Nissan Skyline, Mitsubishi Eclipse, Dodge Charger, BMW M5", "latency_ms": 2092.151165008545, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 766.6499614715576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 577.4059295654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 566.8725967407227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 759.9313259124756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2438}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 560.6508255004883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3009}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 748.3811378479004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3642}}}
{"qid": "-8491157534197669091", "question": "who won the oscar for best actor in 1975", "gold_answers": ["Art Carney"], "shots": {"0": {"k": 0, "answer": "Art Carney", "latency_ms": 311.0225200653076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 827.0087242126465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 542.1900749206543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 569.648027420044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 770.7614898681641, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2529}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 557.5525760650635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3165}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 832.2708606719971, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "-8408640804522114136", "question": "when did the first episode of that 70s show air", "gold_answers": ["August 23 , 1998"], "shots": {"0": {"k": 0, "answer": "August 23, 1998", "latency_ms": 556.3850402832031, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1998", "latency_ms": 421.9486713409424, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "1998", "latency_ms": 668.3051586151123, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "1998", "latency_ms": 470.1495170593262, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "1998", "latency_ms": 452.8493881225586, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2479}, "5": {"k": 5, "answer": "1998", "latency_ms": 469.23327445983887, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "1998", "latency_ms": 646.7516422271729, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3672}}}
{"qid": "722920117313579366", "question": "when did the book thief movie come out", "gold_answers": ["November 27 , 2013", "2013"], "shots": {"0": {"k": 0, "answer": "November 8, 2013", "latency_ms": 937.4115467071533, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "November 8, 2013", "latency_ms": 1337.8162384033203, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "November 8, 2013", "latency_ms": 1033.6012840270996, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "November 8, 2013", "latency_ms": 945.3175067901611, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "November 8, 2013", "latency_ms": 942.0664310455322, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2509}, "5": {"k": 5, "answer": "November 8, 2013", "latency_ms": 1197.620153427124, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3152}, "6": {"k": 6, "answer": "November 8, 2013", "latency_ms": 1040.473461151123, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3796}}}
{"qid": "-4427112594024146143", "question": "when did the eagles win the super bowl", "gold_answers": ["2017"], "shots": {"0": {"k": 0, "answer": "Super Bowl LII", "latency_ms": 390.25163650512695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Super Bowl LII", "latency_ms": 752.7835369110107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "2017 season", "latency_ms": 494.45033073425293, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1243}, "3": {"k": 3, "answer": "2018", "latency_ms": 644.0455913543701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1875}, "4": {"k": 4, "answer": "2018", "latency_ms": 424.5014190673828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2479}, "5": {"k": 5, "answer": "2018", "latency_ms": 651.2837409973145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3070}, "6": {"k": 6, "answer": "2018", "latency_ms": 472.34272956848145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3672}}}
{"qid": "7078422108284431587", "question": "who is the biggest selling female group of all time", "gold_answers": ["Spice Girls"], "shots": {"0": {"k": 0, "answer": "The Spice Girls", "latency_ms": 506.32333755493164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spice Girls", "latency_ms": 502.02178955078125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Spice Girls", "latency_ms": 721.8294143676758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Spice Girls", "latency_ms": 537.1706485748291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Spice Girls", "latency_ms": 736.1438274383545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2555}, "5": {"k": 5, "answer": "Spice Girls", "latency_ms": 492.295503616333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3184}, "6": {"k": 6, "answer": "Spice Girls", "latency_ms": 519.8080539703369, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3862}}}
{"qid": "1039102546557940080", "question": "who sang from russia with love james bond", "gold_answers": ["Matt Monro"], "shots": {"0": {"k": 0, "answer": "Matt Monro", "latency_ms": 500.8201599121094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matt Monro", "latency_ms": 682.349443435669, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Matt Monro", "latency_ms": 908.3139896392822, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1284}, "3": {"k": 3, "answer": "Matt Monro", "latency_ms": 736.7939949035645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1913}, "4": {"k": 4, "answer": "Matt Monro", "latency_ms": 699.2909908294678, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2534}, "5": {"k": 5, "answer": "Matt Monro", "latency_ms": 524.3194103240967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3146}, "6": {"k": 6, "answer": "Matt Monro", "latency_ms": 758.1830024719238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3845}}}
{"qid": "-8507438636601119973", "question": "where is urinary bladder located in human body", "gold_answers": ["on the pelvic floor", "pelvic floor"], "shots": {"0": {"k": 0, "answer": "Pelvic cavity", "latency_ms": 531.2597751617432, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the base of the pelvis", "latency_ms": 978.846549987793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "at the base of the pelvis", "latency_ms": 967.4384593963623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "at the base of the pelvis", "latency_ms": 1253.2398700714111, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "At the base of the pelvis", "latency_ms": 756.3071250915527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2455}, "5": {"k": 5, "answer": "At the base of the pelvis", "latency_ms": 1172.2111701965332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3099}, "6": {"k": 6, "answer": "At the base of the pelvis", "latency_ms": 998.4843730926514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3702}}}
{"qid": "-1996951438961136762", "question": "architectural elements forming rib vaults eg wells cathedral", "gold_answers": ["two to three barrel vaults", "an armature of piped masonry", "barrel vaults"], "shots": {"0": {"k": 0, "answer": "Ribs", "latency_ms": 473.92749786376953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ribs", "latency_ms": 644.8984146118164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "Ribs", "latency_ms": 684.5309734344482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "Ribs", "latency_ms": 433.81404876708984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Ribs and barrel vaults", "latency_ms": 1117.3248291015625, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2530}, "5": {"k": 5, "answer": "Ribs and piped masonry", "latency_ms": 978.2395362854004, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3132}, "6": {"k": 6, "answer": "Piped masonry", "latency_ms": 736.1023426055908, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3795}}}
{"qid": "-8490085242981497626", "question": "who sang gonna sit right down and write myself a letter", "gold_answers": ["Fats Waller"], "shots": {"0": {"k": 0, "answer": "Alicia Keys", "latency_ms": 373.3847141265869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fats Waller", "latency_ms": 596.5323448181152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "Fats Waller", "latency_ms": 806.302547454834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Fats Waller", "latency_ms": 609.4272136688232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Fats Waller", "latency_ms": 821.8209743499756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Fats Waller", "latency_ms": 783.2403182983398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3177}, "6": {"k": 6, "answer": "Fats Waller", "latency_ms": 749.265193939209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3801}}}
{"qid": "8783361206191889627", "question": "how many rooms is there in buckingham palace", "gold_answers": ["775 rooms", "775"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 787.2347831726074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "775", "latency_ms": 604.4149398803711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "775", "latency_ms": 345.10278701782227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1222}, "3": {"k": 3, "answer": "775", "latency_ms": 534.614086151123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "775 rooms", "latency_ms": 461.712121963501, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2433}, "5": {"k": 5, "answer": "775 rooms", "latency_ms": 659.5940589904785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3044}, "6": {"k": 6, "answer": "775 rooms", "latency_ms": 626.0793209075928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3650}}}
{"qid": "1172792682698457582", "question": "where did they get the tree for rockefeller center", "gold_answers": ["State College , PA"], "shots": {"0": {"k": 0, "answer": "Wallkill, New York", "latency_ms": 643.906831741333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 1879.3282508850098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 1435.3578090667725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1314}, "3": {"k": 3, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 1632.4472427368164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 1652.6157855987549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2623}, "5": {"k": 5, "answer": "upstate New York and surrounding states, and even Ottawa in Ontario, Canada.", "latency_ms": 1509.5598697662354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3301}, "6": {"k": 6, "answer": "upstate New York and surrounding states, and even Ottawa in Ontario, Canada.", "latency_ms": 1896.2256908416748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3990}}}
{"qid": "-8616225749004085214", "question": "who expanded the territory of china during the qing dynasty", "gold_answers": ["Prince Bao", "the Qianlong Emperor", "Qianlong"], "shots": {"0": {"k": 0, "answer": "Qianlong Emperor", "latency_ms": 563.8878345489502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Russian Empire", "latency_ms": 734.8716259002686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "The Qing dynasty", "latency_ms": 727.5989055633545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "Qing Empire", "latency_ms": 497.11012840270996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Nurhaci", "latency_ms": 829.5741081237793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "Manchu Aisin Gioro clan", "latency_ms": 1293.689489364624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Manchu Aisin Gioro clan", "latency_ms": 1265.9623622894287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3831}}}
{"qid": "-4544825586005995775", "question": "what is the second largest country in asia", "gold_answers": ["China"], "shots": {"0": {"k": 0, "answer": "Kazakhstan", "latency_ms": 549.7305393218994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 555.0391674041748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 749.4645118713379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 727.7154922485352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 763.953447341919, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 801.3029098510742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3144}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 807.3742389678955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3827}}}
{"qid": "2851585794686488659", "question": "when was the last episode of vampire diaries aired", "gold_answers": ["March 10 , 2017"], "shots": {"0": {"k": 0, "answer": "March 10, 2017", "latency_ms": 761.160135269165, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 768.4001922607422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 919.5384979248047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "March 10, 2017", "latency_ms": 1180.6423664093018, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "March 10, 2017", "latency_ms": 967.4293994903564, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2494}, "5": {"k": 5, "answer": "March 10, 2017", "latency_ms": 1029.9742221832275, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3132}, "6": {"k": 6, "answer": "March 10, 2017", "latency_ms": 1212.731122970581, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3804}}}
{"qid": "636692438616046367", "question": "who played ashley on the young and the restless", "gold_answers": ["Shari Shattuck", "Eileen Davidson", "Brenda Epperson"], "shots": {"0": {"k": 0, "answer": "Eileen Davidson", "latency_ms": 496.5939521789551, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eileen Davidson", "latency_ms": 712.6438617706299, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 629}, "2": {"k": 2, "answer": "Eileen Davidson", "latency_ms": 742.3977851867676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Eileen Davidson, Brenda Epperson, Shari Shattuck", "latency_ms": 1219.968557357788, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1868}, "4": {"k": 4, "answer": "Eileen Davidson", "latency_ms": 741.9209480285645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2498}, "5": {"k": 5, "answer": "Eileen Davidson", "latency_ms": 759.6473693847656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3082}, "6": {"k": 6, "answer": "Eileen Davidson", "latency_ms": 759.6344947814941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3692}}}
{"qid": "-2668952310493902320", "question": "who has scored the most points for wales v france", "gold_answers": ["Neil Jenkins"], "shots": {"0": {"k": 0, "answer": "Neil Jenkins", "latency_ms": 428.2710552215576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 744.2667484283447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 764.7030353546143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1159}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 561.6118907928467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1764}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 770.7729339599609, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2366}, "5": {"k": 5, "answer": "Barry John", "latency_ms": 911.8094444274902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2986}, "6": {"k": 6, "answer": "Barry John", "latency_ms": 709.0954780578613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3526}}}
{"qid": "-551363795407275714", "question": "who is pictured on the 5000 dollar bill", "gold_answers": ["James Madison"], "shots": {"0": {"k": 0, "answer": "James Madison", "latency_ms": 446.4306831359863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 758.2471370697021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 837.7010822296143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 781.8639278411865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 847.0261096954346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 755.5575370788574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3199}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 816.1489963531494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3832}}}
{"qid": "-1776638341170409438", "question": "what is the strongest earthquake in the united states", "gold_answers": ["1700 Cascadia earthquake", "1964 Alaska earthquake and tsunami"], "shots": {"0": {"k": 0, "answer": "Great Alaska Earthquake", "latency_ms": 367.60663986206055, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Magnitude 4.5 aftershock", "latency_ms": 1009.2742443084717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Magnitude 4.5", "latency_ms": 855.2336692810059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "5.8 magnitude", "latency_ms": 616.5306568145752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "5.8 magnitude", "latency_ms": 691.9398307800293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "Magnitude 8.5 or higher", "latency_ms": 939.3832683563232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3171}, "6": {"k": 6, "answer": "Magnitude 8.5 or higher", "latency_ms": 989.0248775482178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3861}}}
{"qid": "-3417376069582577712", "question": "who wrote the song balls to the wall", "gold_answers": ["Herman Frank", "Peter Baltes", "Stefan Kaufmann", "Wolf Hoffmann", "Udo Dirkschneider", "Deaffy"], "shots": {"0": {"k": 0, "answer": "Accept", "latency_ms": 183.9301586151123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 749.5644092559814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 561.7854595184326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 830.721378326416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 604.8946380615234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2461}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 828.636884689331, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 755.1274299621582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3664}}}
{"qid": "-5788046732019278353", "question": "who talks for belle in beauty and the beast", "gold_answers": ["Julie Nathanson", "Jodi Benson", "Paige O'Hara"], "shots": {"0": {"k": 0, "answer": "Paige O'Hara", "latency_ms": 683.8376522064209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Paige O'Hara", "latency_ms": 1144.7341442108154, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 689}, "2": {"k": 2, "answer": "Paige O'Hara", "latency_ms": 809.9775314331055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Paige O'Hara", "latency_ms": 612.6110553741455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Paige O'Hara", "latency_ms": 1237.269401550293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2606}, "5": {"k": 5, "answer": "Paige O'Hara", "latency_ms": 1035.6295108795166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3245}, "6": {"k": 6, "answer": "Paige O'Hara", "latency_ms": 876.5316009521484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3918}}}
{"qid": "-819495145099806596", "question": "what is a coherent set of values and beliefs about public policy called", "gold_answers": ["political ideology", "ideology", "a political ideology"], "shots": {"0": {"k": 0, "answer": "Ideology", "latency_ms": 477.6902198791504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 944.3628787994385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 732}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 938.9925003051758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1466}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 780.6260585784912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2200}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 764.7123336791992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2914}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 805.2079677581787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3608}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 749.1641044616699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4313}}}
{"qid": "-467801736331608973", "question": "when do liam and annie get together season 3", "gold_answers": ["Holiday Madness"], "shots": {"0": {"k": 0, "answer": "Episode 9", "latency_ms": 304.08430099487305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Season three", "latency_ms": 633.4812641143799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "Season three", "latency_ms": 625.413179397583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "Season three", "latency_ms": 629.7690868377686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1774}, "4": {"k": 4, "answer": "Season three", "latency_ms": 465.5876159667969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2353}, "5": {"k": 5, "answer": "Season three", "latency_ms": 468.4934616088867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2923}, "6": {"k": 6, "answer": "Season 3", "latency_ms": 690.0203227996826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3532}}}
{"qid": "7210975046317501288", "question": "what breed of cat has spots and stripes", "gold_answers": ["tabby"], "shots": {"0": {"k": 0, "answer": "Ocicat", "latency_ms": 604.3741703033447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 791.0776138305664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Leopard cat", "latency_ms": 673.3498573303223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1176}, "3": {"k": 3, "answer": "Leopard cat", "latency_ms": 742.0196533203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1798}, "4": {"k": 4, "answer": "Fishing cat", "latency_ms": 484.1945171356201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2315}, "5": {"k": 5, "answer": "Fishing cat", "latency_ms": 712.5592231750488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2919}, "6": {"k": 6, "answer": "Fishing cat", "latency_ms": 498.60143661499023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3515}}}
{"qid": "7817340376558760325", "question": "who voiced simba in the lion king 2", "gold_answers": ["Matthew Broderick"], "shots": {"0": {"k": 0, "answer": "Matthew Broderick", "latency_ms": 560.1108074188232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 823.1194019317627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 745.6750869750977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 792.1838760375977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 773.1342315673828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "Matthew Broderick", "latency_ms": 746.5493679046631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3173}, "6": {"k": 6, "answer": "Matthew Broderick", "latency_ms": 591.5048122406006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3826}}}
{"qid": "7584034394038581786", "question": "when did the angel of the north get built", "gold_answers": ["1998", "1994"], "shots": {"0": {"k": 0, "answer": "1998", "latency_ms": 433.7480068206787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 773.726224899292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "1910", "latency_ms": 638.2811069488525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 801.0139465332031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1818}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 740.45729637146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2400}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 755.4328441619873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2999}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 784.8243713378906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3680}}}
{"qid": "1854394640394891866", "question": "when did mcgee became a regular on ncis", "gold_answers": ["in season two", "season two"], "shots": {"0": {"k": 0, "answer": "Season 2", "latency_ms": 547.9960441589355, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Season 2", "latency_ms": 497.3108768463135, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 720.8571434020996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "September 28, 2004", "latency_ms": 1206.0856819152832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "September 28, 2004", "latency_ms": 1062.0996952056885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "September 28, 2004", "latency_ms": 1023.1835842132568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3203}, "6": {"k": 6, "answer": "September 28, 2004", "latency_ms": 1135.7779502868652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3815}}}
{"qid": "2247250807557083996", "question": "when was 1 john 5 7 added to the bible", "gold_answers": ["the 9th century"], "shots": {"0": {"k": 0, "answer": "15th century", "latency_ms": 302.39415168762207, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 778.8186073303223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 547}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 809.3385696411133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1150}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 729.0787696838379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1697}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 784.4681739807129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2293}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 780.9009552001953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2923}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 767.8847312927246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3513}}}
{"qid": "-2049551589682654986", "question": "when was the latest version of chrome released", "gold_answers": ["2018 - 01 - 22"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 834.496259689331, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "May 25, 2010", "latency_ms": 951.2526988983154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 554.9204349517822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 743.3149814605713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 746.6392517089844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 750.7762908935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3118}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 770.5256938934326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "-3534092359651954035", "question": "who is jojo in horton hears a who", "gold_answers": ["Jesse McCartney"], "shots": {"0": {"k": 0, "answer": "JoJo", "latency_ms": 239.79520797729492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1052.7851581573486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "the teenage son of Mayor Ned McDodd", "latency_ms": 818.2942867279053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1201}, "3": {"k": 3, "answer": "the teenage son of Mayor Ned McDodd", "latency_ms": 995.7020282745361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1781}, "4": {"k": 4, "answer": "the Mayor's teenage son", "latency_ms": 1012.47239112854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2370}, "5": {"k": 5, "answer": "the Mayor's teenage son", "latency_ms": 865.2777671813965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3031}, "6": {"k": 6, "answer": "the Mayor's teenage son", "latency_ms": 851.5698909759521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "6504412384445795967", "question": "the part of the cytoskeleton made from the protein actin is called", "gold_answers": ["Microfilaments", "microfilament"], "shots": {"0": {"k": 0, "answer": "Microfilaments", "latency_ms": 526.2107849121094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "actin cytoskeleton", "latency_ms": 642.1825885772705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "actin cytoskeleton", "latency_ms": 835.1607322692871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1339}, "3": {"k": 3, "answer": "microfilament", "latency_ms": 497.1604347229004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2049}, "4": {"k": 4, "answer": "microfilament", "latency_ms": 748.5928535461426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2644}, "5": {"k": 5, "answer": "microfilaments", "latency_ms": 758.765459060669, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3351}, "6": {"k": 6, "answer": "Microfilaments", "latency_ms": 518.7780857086182, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4033}}}
{"qid": "95888218441734902", "question": "who plays jack in battle of the sexes", "gold_answers": ["Bill Pullman", "( Bill Pullman"], "shots": {"0": {"k": 0, "answer": "Steve Carell", "latency_ms": 532.7372550964355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 811.1388683319092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 756.0536861419678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "Robert Harron", "latency_ms": 518.6591148376465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "Robert Harron", "latency_ms": 535.8400344848633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "Robert Harron", "latency_ms": 709.1231346130371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Donald Crisp", "latency_ms": 707.8976631164551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3787}}}
{"qid": "2482202658787537401", "question": "is a network connection device that can build tables that identify addresses on each network", "gold_answers": ["routing table", "a router"], "shots": {"0": {"k": 0, "answer": "Router", "latency_ms": 179.02398109436035, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 938.3077621459961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 753.2534599304199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1360}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 766.5302753448486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2055}, "4": {"k": 4, "answer": "Router", "latency_ms": 374.6929168701172, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2780}, "5": {"k": 5, "answer": "Router", "latency_ms": 351.1843681335449, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3459}, "6": {"k": 6, "answer": "Router", "latency_ms": 372.1189498901367, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4211}}}
{"qid": "8359496728452221378", "question": "when did the royal proclamation of 1763 end", "gold_answers": ["with the American Revolutionary War", "the American Revolutionary War", "1783"], "shots": {"0": {"k": 0, "answer": "1763", "latency_ms": 239.8390769958496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 757.0326328277588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "1768", "latency_ms": 671.2939739227295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1387}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 764.784574508667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2065}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 572.4751949310303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2750}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 765.2747631072998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3400}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 563.7285709381104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4009}}}
{"qid": "-2657014790962135860", "question": "the tenure of the office of the lokayukt of up", "gold_answers": ["8 years", "eight years"], "shots": {"0": {"k": 0, "answer": "8 years", "latency_ms": 460.42752265930176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 589.3862247467041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "5 years", "latency_ms": 712.7799987792969, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 576.7245292663574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Eight years", "latency_ms": 443.6962604522705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2620}, "5": {"k": 5, "answer": "Eight years", "latency_ms": 450.26254653930664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3244}, "6": {"k": 6, "answer": "Eight years", "latency_ms": 485.8694076538086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3922}}}
{"qid": "1827180983934640653", "question": "when did response to state of the union start", "gold_answers": ["1966", "in 1966"], "shots": {"0": {"k": 0, "answer": "1966", "latency_ms": 439.3446445465088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 537.8313064575195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 559.5312118530273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 766.0531997680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1856}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 578.364372253418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2519}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 772.0353603363037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 560.4815483093262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3752}}}
{"qid": "-8006002028754190814", "question": "who had the most governmental power under the articles of confederation", "gold_answers": ["the states"], "shots": {"0": {"k": 0, "answer": "State governments", "latency_ms": 251.19543075561523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Each state", "latency_ms": 607.4626445770264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "The states", "latency_ms": 430.60755729675293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1388}, "3": {"k": 3, "answer": "The states", "latency_ms": 473.3297824859619, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2088}, "4": {"k": 4, "answer": "The states", "latency_ms": 431.7970275878906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2811}, "5": {"k": 5, "answer": "The states", "latency_ms": 631.6001415252686, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3483}, "6": {"k": 6, "answer": "The states", "latency_ms": 454.46085929870605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4174}}}
{"qid": "3406509904702130536", "question": "how many hospitals are there in the united states", "gold_answers": ["5,534 registered hospitals", "5,534"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 373.2905387878418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 792.1020984649658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 749}, "2": {"k": 2, "answer": "5,534", "latency_ms": 493.60013008117676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1474}, "3": {"k": 3, "answer": "5,534", "latency_ms": 499.5152950286865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2154}, "4": {"k": 4, "answer": "5,534", "latency_ms": 563.894510269165, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2838}, "5": {"k": 5, "answer": "5,534", "latency_ms": 706.000566482544, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3584}, "6": {"k": 6, "answer": "5,534", "latency_ms": 726.2420654296875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4298}}}
{"qid": "2435796066046322163", "question": "who donates a christmas tree to trafalgar square", "gold_answers": ["Oslo , Norway"], "shots": {"0": {"k": 0, "answer": "Norway", "latency_ms": 498.4548091888428, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The city of Oslo, Norway", "latency_ms": 902.2157192230225, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "The city of Oslo, Norway", "latency_ms": 1102.6124954223633, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "The city of Oslo, Norway", "latency_ms": 695.476770401001, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1885}, "4": {"k": 4, "answer": "The city of Oslo, Norway", "latency_ms": 1209.3594074249268, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "Norway", "latency_ms": 683.2997798919678, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3139}, "6": {"k": 6, "answer": "The city of Oslo, Norway", "latency_ms": 914.8783683776855, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3783}}}
{"qid": "4926415052497472665", "question": "who starred in the movie on golden pond", "gold_answers": ["William Lanteau", "Dabney Coleman", "Henry Fonda", "Doug McKeon", "Jane Fonda", "Christopher Rydell", "Katharine Hepburn"], "shots": {"0": {"k": 0, "answer": "Henry Fonda", "latency_ms": 522.9096412658691, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Julie Andrews, Christopher Plummer, Glenne Headly", "latency_ms": 1292.2470569610596, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Julie Andrews and Christopher Plummer", "latency_ms": 961.1587524414062, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Henry Fonda, Katharine Hepburn and Jane Fonda", "latency_ms": 1435.858964920044, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Henry Fonda, Katharine Hepburn, Jane Fonda", "latency_ms": 1704.2944431304932, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2510}, "5": {"k": 5, "answer": "Julie Andrews, Christopher Plummer, Katharine Hepburn, Henry Fonda, Jane Fonda", "latency_ms": 2017.5600051879883, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 1319.077491760254, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3737}}}
{"qid": "2142753216627246962", "question": "isdn uses b & d channels. what is d channel use for", "gold_answers": ["carries control and signaling information", "data", "control and signaling information"], "shots": {"0": {"k": 0, "answer": "Signaling", "latency_ms": 250.9605884552002, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "control and signaling information", "latency_ms": 793.870210647583, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "control and signaling information", "latency_ms": 800.3585338592529, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1365}, "3": {"k": 3, "answer": "control and signaling information", "latency_ms": 565.83571434021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2091}, "4": {"k": 4, "answer": "control and signaling information", "latency_ms": 794.2557334899902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2696}, "5": {"k": 5, "answer": "control and signaling information", "latency_ms": 1039.2258167266846, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3420}, "6": {"k": 6, "answer": "control and signaling information", "latency_ms": 759.4544887542725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4084}}}
{"qid": "1547060614805522730", "question": "what is the rate limiting enzyme of kreb's cycle", "gold_answers": ["Isocitrate dehydrogenase"], "shots": {"0": {"k": 0, "answer": "Isocitrate dehydrogenase", "latency_ms": 1097.3572731018066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 733.3133220672607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 746.4065551757812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 749.4692802429199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 768.7616348266602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2484}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 729.1934490203857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3130}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 755.0888061523438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3811}}}
{"qid": "8965198420725510475", "question": "when was the taj mahal built and completed", "gold_answers": ["1632 -- 53"], "shots": {"0": {"k": 0, "answer": "1653", "latency_ms": 274.8091220855713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1196", "latency_ms": 637.209415435791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "1196", "latency_ms": 449.6345520019531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1209}, "3": {"k": 3, "answer": "1643", "latency_ms": 690.2382373809814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "1643, 1653", "latency_ms": 685.859203338623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2492}, "5": {"k": 5, "answer": "1632-1653", "latency_ms": 921.0212230682373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3122}, "6": {"k": 6, "answer": "1632-1653", "latency_ms": 850.9821891784668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3787}}}
{"qid": "-6292760252056275316", "question": "which supreme court judge has surved in international court of justice", "gold_answers": ["Dalveer Bhandari"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 585.888147354126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 545.0806617736816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 772.7031707763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 751.863956451416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1868}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 524.3935585021973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "Dalveer Bhandari", "latency_ms": 1093.149185180664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3133}, "6": {"k": 6, "answer": "Dalveer Bhandari", "latency_ms": 917.7918434143066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3695}}}
{"qid": "8361850218460994084", "question": "who is known as father of green revolution in india", "gold_answers": ["Mankombu Sambasivan Swaminathan"], "shots": {"0": {"k": 0, "answer": "M.S. Swaminathan", "latency_ms": 745.5263137817383, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Norman Borlaug", "latency_ms": 892.0412063598633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 704}, "2": {"k": 2, "answer": "Norman Borlaug", "latency_ms": 620.3393936157227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1438}, "3": {"k": 3, "answer": "Norman Borlaug", "latency_ms": 817.7084922790527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2160}, "4": {"k": 4, "answer": "Norman Borlaug", "latency_ms": 1026.6079902648926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2896}, "5": {"k": 5, "answer": "M. S. Swaminathan", "latency_ms": 759.3386173248291, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3559}, "6": {"k": 6, "answer": "M. S. Swaminathan", "latency_ms": 791.0211086273193, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4226}}}
{"qid": "-5690645328022945594", "question": "who sing say you won't let go", "gold_answers": ["James Arthur"], "shots": {"0": {"k": 0, "answer": "James Arthur", "latency_ms": 455.4307460784912, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 564.8245811462402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 565}, "2": {"k": 2, "answer": "James Arthur", "latency_ms": 445.62435150146484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1151}, "3": {"k": 3, "answer": "James Arthur", "latency_ms": 433.92395973205566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1743}, "4": {"k": 4, "answer": "James Arthur", "latency_ms": 475.5418300628662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "James Arthur", "latency_ms": 653.7981033325195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2969}, "6": {"k": 6, "answer": "James Arthur", "latency_ms": 624.0148544311523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3592}}}
{"qid": "-4292736993227486718", "question": "who monitor the recovery of the location during a disaster", "gold_answers": ["management team"], "shots": {"0": {"k": 0, "answer": "Incident Commander", "latency_ms": 313.9834403991699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Key personnel", "latency_ms": 421.44179344177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 728}, "2": {"k": 2, "answer": "Emergency managers", "latency_ms": 421.65470123291016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1433}, "3": {"k": 3, "answer": "Emergency managers", "latency_ms": 440.77086448669434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2145}, "4": {"k": 4, "answer": "Emergency managers", "latency_ms": 457.66162872314453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2814}, "5": {"k": 5, "answer": "Emergency managers", "latency_ms": 592.7133560180664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3536}, "6": {"k": 6, "answer": "Emergency managers", "latency_ms": 630.8131217956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4304}}}
{"qid": "-4741747756019727470", "question": "where does the synthesis of new dna from existing dna occurs", "gold_answers": ["origins of replication"], "shots": {"0": {"k": 0, "answer": "Replication fork", "latency_ms": 704.0457725524902, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "origins of replication", "latency_ms": 780.2469730377197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "origins of replication", "latency_ms": 785.6574058532715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1305}, "3": {"k": 3, "answer": "In a cell", "latency_ms": 667.5112247467041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2003}, "4": {"k": 4, "answer": "at specific locations, or origins of replication, in the genome", "latency_ms": 1704.2372226715088, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "In a cell", "latency_ms": 671.5898513793945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3312}, "6": {"k": 6, "answer": "In a cell", "latency_ms": 746.6518878936768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3974}}}
{"qid": "4268853195499399258", "question": "who sings gimme shelter with mick jagger", "gold_answers": ["Merry Clayton"], "shots": {"0": {"k": 0, "answer": "Merry Clayton", "latency_ms": 309.87071990966797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Merry Clayton", "latency_ms": 702.0399570465088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "Merry Clayton", "latency_ms": 500.96940994262695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Merry Clayton", "latency_ms": 789.1011238098145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1957}, "4": {"k": 4, "answer": "Merry Clayton", "latency_ms": 701.458215713501, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2614}, "5": {"k": 5, "answer": "Merry Clayton", "latency_ms": 515.6543254852295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "Merry Clayton", "latency_ms": 697.0996856689453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3850}}}
{"qid": "7172420463912356173", "question": "who does tony end up with on skins", "gold_answers": ["Michelle"], "shots": {"0": {"k": 0, "answer": "Michelle Richardson", "latency_ms": 250.89192390441895, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 766.8633460998535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 816.4758682250977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1179}, "3": {"k": 3, "answer": "Michelle", "latency_ms": 368.55292320251465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1743}, "4": {"k": 4, "answer": "Michelle", "latency_ms": 423.6412048339844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2341}, "5": {"k": 5, "answer": "Michelle", "latency_ms": 615.1220798492432, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2966}, "6": {"k": 6, "answer": "Michelle", "latency_ms": 397.5410461425781, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3558}}}
{"qid": "-1400292288904470066", "question": "who sings sugar sugar you are my candy girl", "gold_answers": ["the Archies"], "shots": {"0": {"k": 0, "answer": "The Archies", "latency_ms": 498.14510345458984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 787.9817485809326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 560}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 850.6829738616943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1181}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 979.4571399688721, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "The Archies", "latency_ms": 499.86767768859863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2365}, "5": {"k": 5, "answer": "The Archies", "latency_ms": 668.0011749267578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2966}, "6": {"k": 6, "answer": "The Archies", "latency_ms": 505.2297115325928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3583}}}
{"qid": "-1696720698220253139", "question": "who does tyler end up with in you get me", "gold_answers": ["Ali"], "shots": {"0": {"k": 0, "answer": "Holly.\nor \nAlison.", "latency_ms": 1047.95503616333, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Holly", "latency_ms": 638.4327411651611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "Holly", "latency_ms": 412.8754138946533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1130}, "3": {"k": 3, "answer": "Holly", "latency_ms": 687.9246234893799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1648}, "4": {"k": 4, "answer": "Holly", "latency_ms": 646.7862129211426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2213}, "5": {"k": 5, "answer": "Holly", "latency_ms": 426.5584945678711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2799}, "6": {"k": 6, "answer": "Holly", "latency_ms": 671.9038486480713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3389}}}
{"qid": "-6797239474199900801", "question": "who won the gold for the men's figure skating", "gold_answers": ["Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 360.7456684112549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Todd Eldredge", "latency_ms": 777.2092819213867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 702}, "2": {"k": 2, "answer": "Todd Eldredge", "latency_ms": 764.6856307983398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1391}, "3": {"k": 3, "answer": "Todd Eldredge", "latency_ms": 789.1318798065186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2069}, "4": {"k": 4, "answer": "Todd Eldredge", "latency_ms": 797.8920936584473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2785}, "5": {"k": 5, "answer": "Todd Eldredge", "latency_ms": 778.0921459197998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3497}, "6": {"k": 6, "answer": "Todd Eldredge", "latency_ms": 774.1508483886719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4143}}}
{"qid": "-7819569157752445011", "question": "when did the song holiday road come out", "gold_answers": ["1983", "June 24 , 1983"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 231.09698295593262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 24, 1983", "latency_ms": 1174.6635437011719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 594}, "2": {"k": 2, "answer": "1983", "latency_ms": 717.0240879058838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "1983", "latency_ms": 462.01324462890625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1907}, "4": {"k": 4, "answer": "1983", "latency_ms": 696.0341930389404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "1983", "latency_ms": 634.4189643859863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3200}, "6": {"k": 6, "answer": "1983", "latency_ms": 427.1101951599121, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3775}}}
{"qid": "-8839043176903626071", "question": "when does the mlb season start and finish", "gold_answers": ["October 31 , 2018", "March 29"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 386.80148124694824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 29 to October 1", "latency_ms": 1010.1635456085205, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "March 29 to October 1", "latency_ms": 750.2577304840088, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1260}, "3": {"k": 3, "answer": "March 29 to October 1", "latency_ms": 789.7396087646484, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1868}, "4": {"k": 4, "answer": "March 29 - October 1", "latency_ms": 770.3137397766113, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2487}, "5": {"k": 5, "answer": "March 29 - October 1", "latency_ms": 983.0324649810791, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3081}, "6": {"k": 6, "answer": "March 29 - October 1", "latency_ms": 758.5031986236572, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3724}}}
{"qid": "6356531089429364942", "question": "when did scotland beat england in six nations", "gold_answers": ["8 March 2008", "25 February 2006", "24 February 2018", "2 April 2000"], "shots": {"0": {"k": 0, "answer": "8 February 2020", "latency_ms": 432.89875984191895, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 531.6190719604492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 587.3973369598389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "1938, (and another year not specified in the context)", "latency_ms": 1356.274127960205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1973}, "4": {"k": 4, "answer": "1984, 1994 not mentioned, only 1938", "latency_ms": 1160.0337028503418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "Since 1938, only in 1994 is not mentioned, but  [3] \"Scotland national rugby union team\": \"a disappointment; losing their first three Five Nations matches. However, the tournament ended on a high when Scotland recorded only their second victory over England at Twickenham since 1938.\"", "latency_ms": 4755.738973617554, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3350}, "6": {"k": 6, "answer": "Since 1938, only in [3]", "latency_ms": 1177.3223876953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3982}}}
{"qid": "-3382335563294993978", "question": "when did the rational dress society begin to work", "gold_answers": ["1881"], "shots": {"0": {"k": 0, "answer": "1881", "latency_ms": 255.31864166259766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1881", "latency_ms": 468.8577651977539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "1881", "latency_ms": 450.3366947174072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "1881", "latency_ms": 444.31424140930176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1976}, "4": {"k": 4, "answer": "1881", "latency_ms": 473.43945503234863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2609}, "5": {"k": 5, "answer": "1881", "latency_ms": 435.9300136566162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3236}, "6": {"k": 6, "answer": "1881", "latency_ms": 454.41555976867676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3849}}}
{"qid": "-5630827734073464379", "question": "why is the indian ocean the warmest in the world", "gold_answers": ["human induced greenhouse warming"], "shots": {"0": {"k": 0, "answer": "High sea surface temperatures", "latency_ms": 385.38455963134766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "human induced greenhouse warming", "latency_ms": 739.1581535339355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "Human induced greenhouse warming", "latency_ms": 837.0566368103027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1337}, "3": {"k": 3, "answer": "Long-term ocean temperature records show a rapid, continuous warming", "latency_ms": 1401.4534950256348, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 1996}, "4": {"k": 4, "answer": "Long-term ocean temperature records show a rapid, continuous warming", "latency_ms": 1458.1778049468994, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 2580}, "5": {"k": 5, "answer": "Long-term ocean temperature records show a rapid, continuous warming", "latency_ms": 1372.678279876709, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 3238}, "6": {"k": 6, "answer": "Human induced greenhouse warming", "latency_ms": 773.6358642578125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3834}}}
{"qid": "-3544151584263258729", "question": "where was the film manchester by the sea filmed", "gold_answers": ["Middleton", "Essex", "Gloucester", "Beverly", "Swampscott", "Lynn", "Manchester", "Salem", "Tewksbury"], "shots": {"0": {"k": 0, "answer": "Gloucester, Massachusetts", "latency_ms": 621.0527420043945, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 770.8442211151123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 764.2350196838379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1353}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 567.568302154541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1999}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 779.9348831176758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2677}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 818.476676940918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3272}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 789.9096012115479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3959}}}
{"qid": "-5077733789764986167", "question": "consist of the sum of the fixed and variable costs for any given level of production", "gold_answers": ["total cost ( TC )"], "shots": {"0": {"k": 0, "answer": "Total Costs", "latency_ms": 462.0046615600586, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Total cost", "latency_ms": 420.00436782836914, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "Total cost", "latency_ms": 627.2637844085693, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Total cost", "latency_ms": 629.1694641113281, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Total cost", "latency_ms": 419.65270042419434, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "Total cost", "latency_ms": 452.2073268890381, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3107}, "6": {"k": 6, "answer": "Total cost", "latency_ms": 617.3529624938965, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3799}}}
{"qid": "4892187805447493570", "question": "where was thomas and the magic railroad filmed", "gold_answers": ["Toronto , Ontario , Canada", "Isle of Man", "the Isle of Man"], "shots": {"0": {"k": 0, "answer": "Strasburg Rail Road", "latency_ms": 673.9504337310791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 796.2734699249268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 762.6869678497314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 563.6551380157471, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Strasburg Rail Road", "latency_ms": 838.0954265594482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "Strasburg Rail Road", "latency_ms": 862.3535633087158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3172}, "6": {"k": 6, "answer": "Strasburg Railroad", "latency_ms": 570.1661109924316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-7094533216301278566", "question": "who has access to the presidential daily briefing", "gold_answers": ["Secretaries of State", "the President", "Defense", "National Security Advisor"], "shots": {"0": {"k": 0, "answer": "The President and senior officials.", "latency_ms": 675.2517223358154, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President and top-level US officials", "latency_ms": 957.1983814239502, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "The President of the United States and a small number of top-level US officials.", "latency_ms": 1689.4471645355225, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 1419}, "3": {"k": 3, "answer": "The President of the United States and top-level US officials approved by the President", "latency_ms": 1689.5124912261963, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 2061}, "4": {"k": 4, "answer": "The President of the United States and a small number of top-level US officials", "latency_ms": 1481.8456172943115, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 2699}, "5": {"k": 5, "answer": "The President of the United States and a small number of top-level US officials approved by the President.", "latency_ms": 2153.3775329589844, "em": 0.0, "f1": 0.13333333333333333, "containment": 1.0, "context_chars": 3336}, "6": {"k": 6, "answer": "The President of the United States and a small number of top-level US officials approved by the President", "latency_ms": 1879.2064189910889, "em": 0.0, "f1": 0.13333333333333333, "containment": 1.0, "context_chars": 4011}}}
{"qid": "-243139310037543674", "question": "what tool is available from microsoft as an alternative to the usmt for smaller migrations", "gold_answers": ["Windows Easy Transfer"], "shots": {"0": {"k": 0, "answer": "Easy Transfer", "latency_ms": 279.6201705932617, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Files", "latency_ms": 609.734296798706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Windows Easy Transfer", "latency_ms": 701.7371654510498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Windows Easy Transfer", "latency_ms": 703.2694816589355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Windows Easy Transfer", "latency_ms": 502.7883052825928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2561}, "5": {"k": 5, "answer": "Windows Easy Transfer", "latency_ms": 774.1050720214844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3253}, "6": {"k": 6, "answer": "Windows Easy Transfer", "latency_ms": 745.8117008209229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3892}}}
{"qid": "7079282152145474767", "question": "who appoints the chief election commissioner of india", "gold_answers": ["the president", "President of India"], "shots": {"0": {"k": 0, "answer": "The President of India", "latency_ms": 549.3946075439453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President", "latency_ms": 429.9807548522949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "The President", "latency_ms": 428.5390377044678, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1437}, "3": {"k": 3, "answer": "The President", "latency_ms": 430.79638481140137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2202}, "4": {"k": 4, "answer": "The President", "latency_ms": 630.2757263183594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2874}, "5": {"k": 5, "answer": "The President", "latency_ms": 452.303409576416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3567}, "6": {"k": 6, "answer": "The President", "latency_ms": 610.7850074768066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4272}}}
{"qid": "6303430169473424975", "question": "glycogen and amylopectin are long chains of which simple sugar(s)", "gold_answers": ["glucose"], "shots": {"0": {"k": 0, "answer": "Glucose", "latency_ms": 258.03256034851074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Glucose", "latency_ms": 664.2851829528809, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "glucose", "latency_ms": 473.4690189361572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Glucose", "latency_ms": 674.2496490478516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Glucose", "latency_ms": 771.4576721191406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2630}, "5": {"k": 5, "answer": "Glucose", "latency_ms": 456.9413661956787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3262}, "6": {"k": 6, "answer": "Glucose", "latency_ms": 696.9952583312988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3969}}}
{"qid": "-3240666523350424161", "question": "who was the editor of the journal jugantor published in the time of swadeshi movement", "gold_answers": ["Bhupendranath Dutt"], "shots": {"0": {"k": 0, "answer": "Barindra Kumar Ghosh", "latency_ms": 505.96022605895996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Barindra Kumar Ghosh", "latency_ms": 889.7674083709717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "Barindra Kumar Ghosh", "latency_ms": 903.6204814910889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Barindra Kumar Ghosh", "latency_ms": 1168.1525707244873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2005}, "4": {"k": 4, "answer": "Barindra Kumar Ghosh", "latency_ms": 931.6723346710205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2661}, "5": {"k": 5, "answer": "Barindra Kumar Ghosh", "latency_ms": 908.4556102752686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3352}, "6": {"k": 6, "answer": "Barindra Kumar Ghosh", "latency_ms": 894.8659896850586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3982}}}
{"qid": "1321443496772706078", "question": "when did indoor toilets become common in america", "gold_answers": ["After World War I"], "shots": {"0": {"k": 0, "answer": "Late 19th century", "latency_ms": 416.26882553100586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1890s", "latency_ms": 688.7907981872559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "1890s", "latency_ms": 740.9377098083496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "1890s", "latency_ms": 481.7664623260498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "1890s", "latency_ms": 680.3030967712402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2583}, "5": {"k": 5, "answer": "1890s", "latency_ms": 488.57665061950684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "1890s", "latency_ms": 731.848955154419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3830}}}
{"qid": "6019244948248861067", "question": "who wrote were going on a bear hunt", "gold_answers": ["Michael Rosen"], "shots": {"0": {"k": 0, "answer": "Michael Rosen", "latency_ms": 244.8289394378662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Rosen", "latency_ms": 641.0841941833496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "Michael Rosen", "latency_ms": 452.4660110473633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Michael Rosen", "latency_ms": 423.16579818725586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1802}, "4": {"k": 4, "answer": "Michael Rosen", "latency_ms": 430.8772087097168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2407}, "5": {"k": 5, "answer": "Michael Rosen", "latency_ms": 409.55615043640137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2948}, "6": {"k": 6, "answer": "Michael Rosen", "latency_ms": 636.6469860076904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3550}}}
{"qid": "8753987902863757141", "question": "what is the revolution period of venus in earth years", "gold_answers": ["0.615 198 yr", "224.7 Earth days"], "shots": {"0": {"k": 0, "answer": "0.61519726", "latency_ms": 632.5821876525879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 770.3139781951904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "0.615 Earth years", "latency_ms": 864.893913269043, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "0.62 years", "latency_ms": 554.7044277191162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "0.62 years", "latency_ms": 754.3909549713135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2453}, "5": {"k": 5, "answer": "0.62", "latency_ms": 503.97396087646484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3045}, "6": {"k": 6, "answer": "0.615 Earth years", "latency_ms": 879.7481060028076, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3637}}}
{"qid": "-5904934687784134086", "question": "who has the power to approve or veto legislation constitution", "gold_answers": ["the President"], "shots": {"0": {"k": 0, "answer": "The President", "latency_ms": 253.45683097839355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President of the United States", "latency_ms": 869.4746494293213, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "The President of the United States", "latency_ms": 1104.6547889709473, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1348}, "3": {"k": 3, "answer": "The President of the United States", "latency_ms": 1104.2122840881348, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2019}, "4": {"k": 4, "answer": "The President of the United States", "latency_ms": 925.6999492645264, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2691}, "5": {"k": 5, "answer": "The President of the United States", "latency_ms": 1131.7286491394043, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3370}, "6": {"k": 6, "answer": "The President of the United States", "latency_ms": 956.9118022918701, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3994}}}
{"qid": "-1910743846708408775", "question": "when was the taming ofthe shrew first performed", "gold_answers": ["prior to June 1592"], "shots": {"0": {"k": 0, "answer": "1594", "latency_ms": 493.117094039917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 818.6016082763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 701}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 820.7921981811523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1353}, "3": {"k": 3, "answer": "1768", "latency_ms": 470.9351062774658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2022}, "4": {"k": 4, "answer": "15901591", "latency_ms": 892.021656036377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "15901591", "latency_ms": 854.6922206878662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 819.2429542541504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3940}}}
{"qid": "6521877788261380307", "question": "who is the first prime minister of france", "gold_answers": ["Michel Debr"], "shots": {"0": {"k": 0, "answer": "Adolphe Thiers", "latency_ms": 851.7417907714844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 785.020112991333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 801.9399642944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 831.8607807159424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 721.8310832977295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2627}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 748.0287551879883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1018.8271999359131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3944}}}
{"qid": "-3375621376413612480", "question": "list of strict nature reserve in the philippines", "gold_answers": ["Lake Malimanga", "Palawan", "Calavite and FB Harrison", "Olango Island", "Calauit Safari Park", "Lake Buluan"], "shots": {"0": {"k": 0, "answer": "Verde Island Passage, Mayon Volcano, El Nido Managed Resource Protected Area", "latency_ms": 1762.3059749603271, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 706.3324451446533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 953.5353183746338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 565.4287338256836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 761.5115642547607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2609}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 556.4067363739014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3292}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 792.748212814331, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4066}}}
{"qid": "-7848107192827858958", "question": "where do the events in the story take place geographically", "gold_answers": ["Persia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 582.2222232818604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 538.2990837097168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Setting", "latency_ms": 543.84446144104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "Setting", "latency_ms": 357.38492012023926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "Setting", "latency_ms": 357.62572288513184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2421}, "5": {"k": 5, "answer": "the open countryside", "latency_ms": 699.7928619384766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3104}, "6": {"k": 6, "answer": "Poland", "latency_ms": 416.8851375579834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3756}}}
{"qid": "-5123704261908217758", "question": "how and why were serial novels a phenomenon in the nineteenth century", "gold_answers": ["improved economics of distribution", "the rise of literacy", "technological advances in printing"], "shots": {"0": {"k": 0, "answer": "Cheap printing technology", "latency_ms": 520.44677734375, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Broad audiences and magazine publication.", "latency_ms": 723.0522632598877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "Broad audiences and growth of following", "latency_ms": 1138.6396884918213, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Broad audiences and growing following.", "latency_ms": 928.0440807342529, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Broad audiences and growing literacy rates.", "latency_ms": 1135.282039642334, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "Broad audiences and growing following", "latency_ms": 867.3009872436523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Broad audiences and growing following.", "latency_ms": 681.9243431091309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3853}}}
{"qid": "8893432128322519771", "question": "who eliminated costa rica in world cup 2014", "gold_answers": ["Netherlands"], "shots": {"0": {"k": 0, "answer": "Netherlands", "latency_ms": 453.51314544677734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 748.4993934631348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1071.213960647583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 797.828197479248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 770.6389427185059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 568.7191486358643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 782.3507785797119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3768}}}
{"qid": "-1356405650810931451", "question": "how many countries touches the land boundary of india", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "6", "latency_ms": 391.05987548828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "6", "latency_ms": 376.68871879577637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "6", "latency_ms": 613.2199764251709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1305}, "3": {"k": 3, "answer": "6", "latency_ms": 360.0947856903076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1887}, "4": {"k": 4, "answer": "6", "latency_ms": 580.2233219146729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "6", "latency_ms": 664.8035049438477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3168}, "6": {"k": 6, "answer": "6", "latency_ms": 391.65759086608887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3793}}}
{"qid": "6447777231012695504", "question": "who was the 11th prime minister of canada", "gold_answers": ["R.B. Bennett", "Arthur Meighen"], "shots": {"0": {"k": 0, "answer": "William Lyon Mackenzie King", "latency_ms": 690.2663707733154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 597.6705551147461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 804.1379451751709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1332}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 534.3430042266846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2006}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 782.141923904419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Wilfrid Laurier", "latency_ms": 708.6560726165771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3344}, "6": {"k": 6, "answer": "Wilfrid Laurier", "latency_ms": 851.3915538787842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3975}}}
{"qid": "-5935683210985272192", "question": "when did the steel mills closed in youngstown ohio", "gold_answers": ["September 19 , 1977"], "shots": {"0": {"k": 0, "answer": "1977", "latency_ms": 249.7231960296631, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 19, 1977", "latency_ms": 960.7727527618408, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "1977", "latency_ms": 608.8838577270508, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "September 19, 1977", "latency_ms": 951.7390727996826, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1958}, "4": {"k": 4, "answer": "September 19, 1977", "latency_ms": 753.6029815673828, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "September 19, 1977", "latency_ms": 911.787748336792, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "1977", "latency_ms": 672.8804111480713, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3947}}}
{"qid": "1834961239491311230", "question": "who owns and operates the panama canal today", "gold_answers": ["Panama Canal Authority", "Panama", "Panamanian government"], "shots": {"0": {"k": 0, "answer": "Panama Canal Authority", "latency_ms": 560.1842403411865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kansas City Southern and Mi-Jack Products", "latency_ms": 1251.3599395751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "Panama Canal Authority", "latency_ms": 783.3600044250488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Panama Canal Authority", "latency_ms": 560.2812767028809, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1956}, "4": {"k": 4, "answer": "Panama Canal Authority", "latency_ms": 542.9174900054932, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Panama Canal Authority", "latency_ms": 812.8495216369629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3277}, "6": {"k": 6, "answer": "Panamanian government", "latency_ms": 776.8306732177734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3949}}}
{"qid": "-535648230475805474", "question": "where is a simple gear train used in real life", "gold_answers": ["Automobile drivetrains"], "shots": {"0": {"k": 0, "answer": "Bicycles", "latency_ms": 503.2391548156738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 767.8604125976562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 551.3694286346436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1224}, "3": {"k": 3, "answer": "Automobile manual transmission", "latency_ms": 789.0486717224121, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1842}, "4": {"k": 4, "answer": "Automobile manual transmission", "latency_ms": 746.4289665222168, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Automobile manual transmission", "latency_ms": 573.3487606048584, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3017}, "6": {"k": 6, "answer": "Automobile manual transmission", "latency_ms": 747.6112842559814, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3672}}}
{"qid": "8911390210346559626", "question": "who plays the dad in malcom in the middle", "gold_answers": ["Bryan Cranston"], "shots": {"0": {"k": 0, "answer": "Bryan Cranston", "latency_ms": 550.6036281585693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 787.2631549835205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 955.0111293792725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 766.1161422729492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1844}, "4": {"k": 4, "answer": "Bryan Cranston", "latency_ms": 586.6096019744873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2432}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 760.9682083129883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3044}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 974.8907089233398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3645}}}
{"qid": "-8336776482564898273", "question": "who has won the most world series in baseball", "gold_answers": ["the New York Yankees", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "New York Yankees", "latency_ms": 516.9756412506104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Yankees", "latency_ms": 683.4409236907959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 570}, "2": {"k": 2, "answer": "New York Yankees", "latency_ms": 691.4806365966797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1194}, "3": {"k": 3, "answer": "New York Yankees", "latency_ms": 505.61976432800293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1811}, "4": {"k": 4, "answer": "New York Yankees", "latency_ms": 694.3840980529785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2418}, "5": {"k": 5, "answer": "New York Yankees", "latency_ms": 495.6386089324951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2997}, "6": {"k": 6, "answer": "New York Yankees", "latency_ms": 492.295503616333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3603}}}
{"qid": "-8742089114148260796", "question": "where are the winter olympic games being played", "gold_answers": ["Beijing"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 580.3639888763428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chamonix, France", "latency_ms": 611.1884117126465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "Chamonix, France.", "latency_ms": 665.8675670623779, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "Chamonix, France.", "latency_ms": 900.1946449279785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Chamonix, France.", "latency_ms": 665.794849395752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "Chamonix, France", "latency_ms": 817.6262378692627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3156}, "6": {"k": 6, "answer": "Pyeongchang", "latency_ms": 549.5550632476807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3843}}}
{"qid": "3864930130255054488", "question": "who made the song falling in love with you", "gold_answers": ["Hugo Peretti", "Elvis Presley", "George David Weiss", "Luigi Creatore"], "shots": {"0": {"k": 0, "answer": "UB40", "latency_ms": 249.1157054901123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Randy Owen, Teddy Gentry and Greg Fowler", "latency_ms": 1134.8822116851807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Randy Owen, Teddy Gentry and Greg Fowler", "latency_ms": 1153.4671783447266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Randy Owen, Teddy Gentry and Greg Fowler", "latency_ms": 933.0153465270996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 796.544075012207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2400}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 765.4123306274414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2958}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 806.4391613006592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3565}}}
{"qid": "8076743617384207713", "question": "where did saudi crown prince go to college", "gold_answers": ["King Saud University"], "shots": {"0": {"k": 0, "answer": "King Saud University", "latency_ms": 502.030611038208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 726.3014316558838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 686}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 751.272439956665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1358}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 601.3727188110352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2019}, "4": {"k": 4, "answer": "Princeton University", "latency_ms": 498.2798099517822, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2690}, "5": {"k": 5, "answer": "Princeton University", "latency_ms": 730.1275730133057, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3310}, "6": {"k": 6, "answer": "Princeton University", "latency_ms": 733.9675426483154, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3997}}}
{"qid": "1735766792677422630", "question": "who did the singing in into the woods", "gold_answers": ["the cast", "the cast members"], "shots": {"0": {"k": 0, "answer": "Meryl Streep", "latency_ms": 558.6121082305908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "All join in", "latency_ms": 688.805341720581, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "All join in", "latency_ms": 674.5040416717529, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "All join in", "latency_ms": 705.5599689483643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1941}, "4": {"k": 4, "answer": "All join in", "latency_ms": 502.9256343841553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2586}, "5": {"k": 5, "answer": "the ensemble cast", "latency_ms": 513.5629177093506, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "the ensemble cast", "latency_ms": 709.2828750610352, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3912}}}
{"qid": "5711801828691961426", "question": "who was the viceroy when the simon commission visited india", "gold_answers": ["Lord Irwin"], "shots": {"0": {"k": 0, "answer": "Lord Irwin", "latency_ms": 500.8077621459961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 758.7344646453857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 764.1031742095947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 765.2101516723633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 797.7814674377441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2623}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 563.3077621459961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3285}, "6": {"k": 6, "answer": "Lord Irwin", "latency_ms": 727.0975112915039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3936}}}
{"qid": "9001143341771379731", "question": "who in germany signed the treaty of versailles", "gold_answers": ["colonial minister Johannes Bell", "Foreign minister Hermann Mller", "Gustav Bauer"], "shots": {"0": {"k": 0, "answer": "Ulrich Graf von Brockdorff-Rantzau", "latency_ms": 990.5307292938232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 762.6702785491943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 742.1572208404541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "Germany's new political leadership", "latency_ms": 602.4012565612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "Germany's new political leadership", "latency_ms": 812.0207786560059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2485}, "5": {"k": 5, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 878.1979084014893, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3132}, "6": {"k": 6, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 682.9566955566406, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3794}}}
{"qid": "-4619585332904698754", "question": "who holds the record for most platinum albums", "gold_answers": ["The Beatles", "AC / DC", "Elvis Presley"], "shots": {"0": {"k": 0, "answer": "The Beatles", "latency_ms": 255.79094886779785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elvis Presley", "latency_ms": 818.7732696533203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Elvis Presley", "latency_ms": 836.9224071502686, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Elvis Presley", "latency_ms": 805.0198554992676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Elvis Presley", "latency_ms": 797.673225402832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Elvis Presley", "latency_ms": 789.9165153503418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Elvis Presley", "latency_ms": 756.2642097473145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3859}}}
{"qid": "-720512252272678238", "question": "when did the movie the post begin filming", "gold_answers": ["May 30 , 2017", "May 2017"], "shots": {"0": {"k": 0, "answer": "May 30, 2016", "latency_ms": 773.139238357544, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 748.9078044891357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 748.6650943756104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 754.2345523834229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 847.4831581115723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 837.1162414550781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 849.2190837860107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3808}}}
{"qid": "-3371798557886238687", "question": "who starred in an officer and a gentleman", "gold_answers": ["Louis Gossett Jr .", "David Keith", "Louis Gossett Jr.", "Richard Gere", "Debra Winger", "Phillip J. Salmon"], "shots": {"0": {"k": 0, "answer": "Richard Gere", "latency_ms": 516.0751342773438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 818.413257598877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 1629.5037269592285, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 1713.846206665039, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1851}, "4": {"k": 4, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 1555.0808906555176, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 1826.3332843780518, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3182}, "6": {"k": 6, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 2056.2093257904053, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3771}}}
