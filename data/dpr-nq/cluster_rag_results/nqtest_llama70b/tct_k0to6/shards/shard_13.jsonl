{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 286.4222526550293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Molly", "latency_ms": 405.78579902648926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 531.4772129058838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1189}, "3": {"k": 3, "answer": "Bonnie Wright's mom, Molly, is played by Julie Walters", "latency_ms": 1086.9228839874268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1804}, "4": {"k": 4, "answer": "Bonnie Wright's mom is Molly, but the actress is not specified in the context. \nI cannot answer.", "latency_ms": 2084.9599838256836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "Bonnie Wright's mom is Molly, played by Julie Walters", "latency_ms": 1268.167495727539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3041}, "6": {"k": 6, "answer": "Bonnie Wright", "latency_ms": 720.5390930175781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3687}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 565.2954578399658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 569.9329376220703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 781.7592620849609, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 582.2265148162842, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 801.4912605285645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2422}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 754.4946670532227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2994}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 804.97145652771, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3594}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwest desert regions", "latency_ms": 580.1165103912354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 1324.5444297790527, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 1351.8927097320557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 1549.5035648345947, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1902}, "4": {"k": 4, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 1378.8120746612549, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2546}, "5": {"k": 5, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 1331.9523334503174, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3213}, "6": {"k": 6, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 1596.1344242095947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3866}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 681.6391944885254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Karl Seitz", "latency_ms": 730.7877540588379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Karl Seitz", "latency_ms": 746.9048500061035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Karl Seitz", "latency_ms": 739.54176902771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2011}, "4": {"k": 4, "answer": "Dr. Rajendra Prasad", "latency_ms": 1107.8293323516846, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2756}, "5": {"k": 5, "answer": "Karl Seitz", "latency_ms": 560.7333183288574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3455}, "6": {"k": 6, "answer": "Dr. Rajendra Prasad", "latency_ms": 899.1868495941162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4101}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 587.3641967773438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 732.2053909301758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 785.7942581176758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 803.0390739440918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 807.002067565918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2525}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 586.9410037994385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3215}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 787.543535232544, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3827}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "June 22, 2001", "latency_ms": 791.332483291626, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2001", "latency_ms": 436.34533882141113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "2001", "latency_ms": 678.1570911407471, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "2001", "latency_ms": 432.97719955444336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "2001", "latency_ms": 432.6283931732178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "2001", "latency_ms": 489.0596866607666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3112}, "6": {"k": 6, "answer": "2001", "latency_ms": 677.9096126556396, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3738}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 363.6045455932617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 975.7404327392578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 989.2237186431885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 1007.2221755981445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 973.2475280761719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2653}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 1238.0142211914062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "September 27, 2017", "latency_ms": 976.7498970031738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3894}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3", "latency_ms": 508.9123249053955, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 595.1662063598633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "Yes/No episode", "latency_ms": 990.0081157684326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "Yes/No episode", "latency_ms": 713.6850357055664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1775}, "4": {"k": 4, "answer": "In \"The Power of Madonna\"", "latency_ms": 1196.1755752563477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2338}, "5": {"k": 5, "answer": "In \"The Power of Madonna\"", "latency_ms": 954.8773765563965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2957}, "6": {"k": 6, "answer": "In \"Hell-O\"", "latency_ms": 634.1359615325928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3580}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 368.24679374694824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 769.3948745727539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 797.5289821624756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 796.7989444732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 803.5948276519775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2450}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 811.1650943756104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3058}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 864.1252517700195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3696}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 322.46947288513184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "the harbor", "latency_ms": 428.3266067504883, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "the harbor", "latency_ms": 624.0670680999756, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Havana Harbor", "latency_ms": 702.904224395752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1879}, "4": {"k": 4, "answer": "Havana Harbor", "latency_ms": 673.6047267913818, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2451}, "5": {"k": 5, "answer": "Havana Harbor", "latency_ms": 725.0046730041504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3067}, "6": {"k": 6, "answer": "Havana Harbor", "latency_ms": 695.8668231964111, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3641}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 515.887975692749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 600.9089946746826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 863.0471229553223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 808.6748123168945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "No specific god mentioned", "latency_ms": 633.657693862915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2553}, "5": {"k": 5, "answer": "No specific god mentioned", "latency_ms": 841.156005859375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "No specific god mentioned", "latency_ms": 618.5922622680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3868}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 750.4734992980957, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costa Rica and Panama and also possibly Belize, Honduras, Guatemala, Nicaragua, and El Salvador", "latency_ms": 1904.749870300293, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 555}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 746.3374137878418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1164}, "3": {"k": 3, "answer": "Costa Rica and Panama and Nicaragua", "latency_ms": 971.5588092803955, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 1386.9645595550537, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2447}, "5": {"k": 5, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 963.8876914978027, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3107}, "6": {"k": 6, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 956.6636085510254, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3740}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence.", "latency_ms": 309.0813159942627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 656.623125076294, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 704}, "2": {"k": 2, "answer": "Typical sentence", "latency_ms": 479.57706451416016, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1360}, "3": {"k": 3, "answer": "Typical sentence", "latency_ms": 517.3740386962891, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2042}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 583.4274291992188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2701}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 450.7794380187988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3365}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 423.9954948425293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4053}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and trade.", "latency_ms": 650.4256725311279, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 1094.8338508605957, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Nations' wealth", "latency_ms": 805.5472373962402, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "what builds nations' wealth", "latency_ms": 619.7547912597656, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "The Wealth of Nations", "latency_ms": 600.4359722137451, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "Nations' wealth", "latency_ms": 735.6793880462646, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 1004.8847198486328, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3884}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 991.6424751281738, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 776.5662670135498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "August 28, 2018", "latency_ms": 1044.428825378418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 917.3908233642578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 1124.2907047271729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2414}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 936.3007545471191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3034}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 967.1084880828857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3625}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere", "latency_ms": 687.3595714569092, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 1354.818344116211, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 1780.9298038482666, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1341}, "3": {"k": 3, "answer": "Oceania", "latency_ms": 672.3942756652832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2029}, "4": {"k": 4, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 1596.095323562622, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2753}, "5": {"k": 5, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 1550.408124923706, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3452}, "6": {"k": 6, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 1562.7882480621338, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4028}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Leia Organa", "latency_ms": 592.4317836761475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Leia", "latency_ms": 465.13938903808594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Leia", "latency_ms": 631.1349868774414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "Leia", "latency_ms": 666.3131713867188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "Leia", "latency_ms": 422.1055507659912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2435}, "5": {"k": 5, "answer": "Mara Jade", "latency_ms": 695.7101821899414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3055}, "6": {"k": 6, "answer": "Mara Jade", "latency_ms": 710.2334499359131, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3620}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 239.84742164611816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack Barry", "latency_ms": 629.5063495635986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Barry Cryer", "latency_ms": 751.4791488647461, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1167}, "3": {"k": 3, "answer": "Barry Cryer", "latency_ms": 565.701961517334, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1717}, "4": {"k": 4, "answer": "Barry Cryer", "latency_ms": 766.571044921875, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2312}, "5": {"k": 5, "answer": "Barry Cryer", "latency_ms": 782.4232578277588, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2905}, "6": {"k": 6, "answer": "Barry Cryer", "latency_ms": 772.5121974945068, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3488}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 523.9460468292236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "mitochondria", "latency_ms": 706.589937210083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "mitochondria", "latency_ms": 723.9606380462646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1387}, "3": {"k": 3, "answer": "Mitochondria", "latency_ms": 527.1642208099365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2044}, "4": {"k": 4, "answer": "Mitochondria", "latency_ms": 558.9780807495117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "Mitochondria", "latency_ms": 703.79638671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3429}, "6": {"k": 6, "answer": "Mitochondrion", "latency_ms": 770.2791690826416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4103}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Backup.", "latency_ms": 1514.6560668945312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 742.1495914459229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 753}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 543.6093807220459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1483}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 939.0561580657959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2186}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 781.0049057006836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2895}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 734.3654632568359, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3588}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 781.0080051422119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4332}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 741.8487071990967, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 589.9474620819092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 716.0606384277344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1156}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 917.668342590332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1740}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 737.0343208312988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2320}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 993.6983585357666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2925}, "6": {"k": 6, "answer": "Dottie West and Kenny Rogers", "latency_ms": 702.4147510528564, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3512}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 556.9241046905518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "36 months", "latency_ms": 642.5631046295166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 601}, "2": {"k": 2, "answer": "36 months", "latency_ms": 668.654203414917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "36 months", "latency_ms": 623.9266395568848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1765}, "4": {"k": 4, "answer": "Three years old", "latency_ms": 779.627799987793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2456}, "5": {"k": 5, "answer": "36 months", "latency_ms": 659.8331928253174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3064}, "6": {"k": 6, "answer": "36 months", "latency_ms": 426.0749816894531, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3657}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 204.76913452148438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Three-part", "latency_ms": 454.69212532043457, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 652}, "2": {"k": 2, "answer": "Three-part", "latency_ms": 668.226957321167, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Three-part", "latency_ms": 713.9501571655273, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Three-part", "latency_ms": 460.59608459472656, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2532}, "5": {"k": 5, "answer": "Three-part", "latency_ms": 675.3222942352295, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3179}, "6": {"k": 6, "answer": "Three-part", "latency_ms": 675.3933429718018, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3783}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 1494.3392276763916, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 654.1666984558105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 2640.1429176330566, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 2302.0098209381104, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 1957}, "4": {"k": 4, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 2182.086944580078, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 2623}, "5": {"k": 5, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 2215.8830165863037, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 2287.501573562622, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 3815}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party", "latency_ms": 518.0954933166504, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume", "latency_ms": 666.353702545166, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 775.0699520111084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1180}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 735.2263927459717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1773}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 930.286169052124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2402}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 557.8224658966064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3124}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 754.4567584991455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3753}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 190.54174423217773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 803.2419681549072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 572.8018283843994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 571.5410709381104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1875}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 602.8048992156982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2446}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 576.746940612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3078}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 584.0263366699219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3649}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "He promised Fantine", "latency_ms": 594.7511196136475, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 824.5220184326172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 759.6795558929443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "He pitied her.", "latency_ms": 837.921142578125, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 762.8669738769531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Fantine's letter authorizing him to take Cosette", "latency_ms": 1458.8232040405273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "Fantine's letter authorizing him to take Cosette", "latency_ms": 1637.1850967407227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3717}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, and South Korea.", "latency_ms": 1020.2457904815674, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 986.3598346710205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "Uganda and Rwanda", "latency_ms": 1090.2719497680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1391}, "3": {"k": 3, "answer": "China", "latency_ms": 582.3237895965576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "China", "latency_ms": 600.2757549285889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2779}, "5": {"k": 5, "answer": "China", "latency_ms": 566.4985179901123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3516}, "6": {"k": 6, "answer": "China, Uganda, Rwanda", "latency_ms": 1090.0659561157227, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4217}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and control.", "latency_ms": 680.7620525360107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to consolidate Bantu education", "latency_ms": 977.9999256134033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 714}, "2": {"k": 2, "answer": "to consolidate Bantu education", "latency_ms": 835.1104259490967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1413}, "3": {"k": 3, "answer": "to consolidate Bantu education", "latency_ms": 1011.3935470581055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2090}, "4": {"k": 4, "answer": "to ensure blacks had only enough education to work as unskilled laborers", "latency_ms": 1485.203504562378, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 1943.4075355529785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "to consolidate Bantu education and implement discriminatory practices uniformly", "latency_ms": 1362.3788356781006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4022}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 524.0583419799805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 644.2849636077881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 1015.8572196960449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Python", "latency_ms": 555.0312995910645, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1783}, "4": {"k": 4, "answer": "Python", "latency_ms": 612.1788024902344, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2399}, "5": {"k": 5, "answer": "Python", "latency_ms": 380.1090717315674, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2984}, "6": {"k": 6, "answer": "Python", "latency_ms": 555.5434226989746, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3596}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 430.8640956878662, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "dry ice", "latency_ms": 409.2409610748291, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "dry ice", "latency_ms": 458.9078426361084, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "dry ice", "latency_ms": 452.53849029541016, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Dry ice", "latency_ms": 452.0454406738281, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2481}, "5": {"k": 5, "answer": "Dry ice", "latency_ms": 420.7425117492676, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "Frost or snow mixed with dust", "latency_ms": 726.593017578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3697}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 810.9478950500488, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "End of the second season", "latency_ms": 1049.5109558105469, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "In the hospital.", "latency_ms": 764.0113830566406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "Season 3 finale", "latency_ms": 748.1980323791504, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1814}, "4": {"k": 4, "answer": "Season 3 finale", "latency_ms": 810.85205078125, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2378}, "5": {"k": 5, "answer": "Season 3 finale", "latency_ms": 568.2587623596191, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2940}, "6": {"k": 6, "answer": "Season 3 finale", "latency_ms": 763.7457847595215, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3519}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "Home team", "latency_ms": 244.51828002929688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "None", "latency_ms": 594.5637226104736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "Premier League clubs", "latency_ms": 766.3452625274658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "the team who were away for the first game", "latency_ms": 1275.8984565734863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1789}, "4": {"k": 4, "answer": "the club drawn first", "latency_ms": 809.0076446533203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2360}, "5": {"k": 5, "answer": "The club drawn first", "latency_ms": 768.9807415008545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2964}, "6": {"k": 6, "answer": "the team drawn first", "latency_ms": 811.011791229248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3567}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw neighborhood", "latency_ms": 299.15714263916016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 756.3629150390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "Washington, D.C.", "latency_ms": 826.552152633667, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Washington", "latency_ms": 604.8448085784912, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Northwest Washington, DC", "latency_ms": 613.7239933013916, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2653}, "5": {"k": 5, "answer": "Northwest", "latency_ms": 638.9517784118652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3337}, "6": {"k": 6, "answer": "Northwest", "latency_ms": 410.3848934173584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4073}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 332.75580406188965, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 754.7647953033447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 744.516134262085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 752.2237300872803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 747.9338645935059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2515}, "5": {"k": 5, "answer": "Noahic Covenant", "latency_ms": 766.8476104736328, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "Noahic Covenant", "latency_ms": 796.1630821228027, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3812}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 376.94835662841797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 751.0988712310791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 948.5437870025635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1187}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 756.3126087188721, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1795}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 978.9628982543945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2366}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 587.6688957214355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2945}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 759.6895694732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3548}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 370.8231449127197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 762.8934383392334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 742.3655986785889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1194}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 597.6219177246094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 749.643087387085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2407}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 772.7422714233398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3012}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 557.5790405273438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3625}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 520.0917720794678, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 436.10668182373047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 431.02121353149414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 636.4994049072266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 484.33494567871094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2529}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 653.0296802520752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3149}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 429.5525550842285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3746}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "Second", "latency_ms": 187.69025802612305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Second", "latency_ms": 576.8680572509766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "Second", "latency_ms": 377.1810531616211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Second", "latency_ms": 608.6554527282715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1797}, "4": {"k": 4, "answer": "Second", "latency_ms": 612.0514869689941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2453}, "5": {"k": 5, "answer": "Second", "latency_ms": 620.6538677215576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3117}, "6": {"k": 6, "answer": "Second most populated country", "latency_ms": 580.8300971984863, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3837}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 612.1091842651367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mahatma Gandhi", "latency_ms": 745.2471256256104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 694}, "2": {"k": 2, "answer": "Mahatma Gandhi", "latency_ms": 782.585859298706, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1402}, "3": {"k": 3, "answer": "Mahatma Gandhi", "latency_ms": 750.6532669067383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2058}, "4": {"k": 4, "answer": "Mahatma Gandhi", "latency_ms": 780.2858352661133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2732}, "5": {"k": 5, "answer": "Jawaharlal Nehru", "latency_ms": 941.150426864624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3454}, "6": {"k": 6, "answer": "Jawaharlal Nehru", "latency_ms": 921.3283061981201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4189}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenifer Lewis", "latency_ms": 590.3232097625732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 931.2102794647217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 773.3514308929443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 713.8335704803467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 864.9487495422363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 843.0845737457275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3331}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1108.5643768310547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3918}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 190.81449508666992, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 646.0475921630859, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": ".java", "latency_ms": 650.843620300293, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": ".java", "latency_ms": 375.23770332336426, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": ".java", "latency_ms": 597.2802639007568, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": ".java", "latency_ms": 566.6458606719971, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3152}, "6": {"k": 6, "answer": ".java", "latency_ms": 569.3869590759277, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 435.8558654785156, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Poland", "latency_ms": 847.4431037902832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Poland", "latency_ms": 462.21280097961426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "Poland", "latency_ms": 436.22422218322754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "Poland", "latency_ms": 689.0075206756592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "Poland", "latency_ms": 482.2053909301758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3252}, "6": {"k": 6, "answer": "Polish cryptologists", "latency_ms": 755.690336227417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3947}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline", "latency_ms": 600.8875370025635, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to offer promotion or threaten demotion", "latency_ms": 1232.8593730926514, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "administer the whipping system", "latency_ms": 846.0571765899658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "offer promotion or threaten demotion within the committee system", "latency_ms": 1368.2889938354492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1857}, "4": {"k": 4, "answer": "administer the whipping system", "latency_ms": 603.872537612915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "ensure party discipline", "latency_ms": 474.4124412536621, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3058}, "6": {"k": 6, "answer": "ensure party discipline and behaviour", "latency_ms": 817.8997039794922, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3708}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 249.59635734558105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 748.859167098999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 609}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 606.0194969177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 802.9694557189941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 558.037519454956, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2657}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 597.0211029052734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3347}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 804.7289848327637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3996}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the right but not the obligation to buy foreign currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 262.4402046203613, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 655.0147533416748, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 439.56732749938965, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 722.9363918304443, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "FX option", "latency_ms": 659.7347259521484, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2690}, "5": {"k": 5, "answer": "FX option", "latency_ms": 406.70251846313477, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3343}, "6": {"k": 6, "answer": "FX option", "latency_ms": 676.1138439178467, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3971}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 432.9195022583008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 435.166597366333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360", "latency_ms": 598.9561080932617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1380}, "3": {"k": 3, "answer": "360 members", "latency_ms": 446.02322578430176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2064}, "4": {"k": 4, "answer": "One", "latency_ms": 556.0507774353027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2764}, "5": {"k": 5, "answer": "360 members", "latency_ms": 462.99147605895996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3441}, "6": {"k": 6, "answer": "360 members", "latency_ms": 594.1846370697021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4091}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 580.1935195922852, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 778.4655094146729, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 858.393669128418, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 761.8553638458252, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 564.6708011627197, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2599}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 752.9392242431641, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3278}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 818.4037208557129, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3919}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gorm"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 659.0559482574463, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gorm", "latency_ms": 660.0821018218994, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Eydie Gorm", "latency_ms": 873.2128143310547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1181}, "3": {"k": 3, "answer": "Eydie Gorm", "latency_ms": 666.715145111084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1757}, "4": {"k": 4, "answer": "Eydie Gorm", "latency_ms": 853.4412384033203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2334}, "5": {"k": 5, "answer": "Eydie Gorm", "latency_ms": 694.4534778594971, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2899}, "6": {"k": 6, "answer": "Eydie Gorm", "latency_ms": 612.5264167785645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3496}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 369.3094253540039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "H.L. Dattu", "latency_ms": 690.2992725372314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "H.L. Dattu", "latency_ms": 942.4312114715576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "H.L. Dattu", "latency_ms": 668.5702800750732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "H.L. Dattu", "latency_ms": 1175.7190227508545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2472}, "5": {"k": 5, "answer": "H.L. Dattu", "latency_ms": 698.7524032592773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3151}, "6": {"k": 6, "answer": "H.L. Dattu", "latency_ms": 680.0992488861084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3784}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 831.5057754516602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 747.7610111236572, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Nadal", "latency_ms": 453.7086486816406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Nadal", "latency_ms": 446.17509841918945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Nadal", "latency_ms": 715.3832912445068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2518}, "5": {"k": 5, "answer": "Federer, Nadal, Sampras, Djokovic, Emerson", "latency_ms": 1892.5395011901855, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3137}, "6": {"k": 6, "answer": "Roger Federer", "latency_ms": 714.8985862731934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3711}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 196.97952270507812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 621.4287281036377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 352.5538444519043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1238}, "3": {"k": 3, "answer": "1", "latency_ms": 418.12896728515625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1858}, "4": {"k": 4, "answer": "1", "latency_ms": 576.4472484588623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2433}, "5": {"k": 5, "answer": "1", "latency_ms": 385.44535636901855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3032}, "6": {"k": 6, "answer": "1", "latency_ms": 589.285135269165, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3639}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 249.63879585266113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2010", "latency_ms": 510.15233993530273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "2010", "latency_ms": 648.5497951507568, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "2010", "latency_ms": 418.15853118896484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1883}, "4": {"k": 4, "answer": "2010", "latency_ms": 605.3645610809326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2487}, "5": {"k": 5, "answer": "2010", "latency_ms": 487.4613285064697, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "2010", "latency_ms": 420.4554557800293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3791}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 397.3710536956787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 595.2448844909668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 773.9701271057129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 588.6414051055908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 978.3217906951904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 723.8948345184326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3137}, "6": {"k": 6, "answer": "17", "latency_ms": 545.6199645996094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3766}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 809.9954128265381, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 625.2732276916504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 847.4531173706055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 1057.370662689209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 845.9353446960449, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 1088.9348983764648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3144}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 617.7506446838379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3795}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 934.1397285461426, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 970.6740379333496, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 847.1293449401855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "Corey, Corey-Jackson", "latency_ms": 1054.9561977386475, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Corey, Corey-Jackson, Smithy", "latency_ms": 1105.863332748413, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2482}, "5": {"k": 5, "answer": "Corey, Corey-Jackson, Corey-James", "latency_ms": 1373.9080429077148, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3118}, "6": {"k": 6, "answer": "Corey, Corey-Jackson, Corey Jackson, Smithy", "latency_ms": 1477.750301361084, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3750}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 525.5060195922852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Toby Keith", "latency_ms": 525.6993770599365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Toby Keith", "latency_ms": 701.0965347290039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Toby Keith", "latency_ms": 675.1646995544434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Toby Keith", "latency_ms": 703.1834125518799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2440}, "5": {"k": 5, "answer": "Toby Keith", "latency_ms": 686.9945526123047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3102}, "6": {"k": 6, "answer": "Toby Keith", "latency_ms": 501.71685218811035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3677}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 397.19414710998535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 349.8573303222656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "159", "latency_ms": 546.4708805084229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1239}, "3": {"k": 3, "answer": "159", "latency_ms": 368.33977699279785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1888}, "4": {"k": 4, "answer": "159", "latency_ms": 379.1012763977051, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2618}, "5": {"k": 5, "answer": "159", "latency_ms": 380.63597679138184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3242}, "6": {"k": 6, "answer": "159", "latency_ms": 632.2951316833496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3913}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 612.9343509674072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 582.8275680541992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 726.8116474151611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1118}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 580.0256729125977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1672}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 786.1733436584473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2243}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 593.7168598175049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2838}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 699.3546485900879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3365}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 303.1039237976074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 757.6663494110107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 560.0106716156006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 821.7642307281494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 808.2559108734131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2410}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 997.4246025085449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3004}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1042.914628982544, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3590}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 382.00831413269043, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Left hand fourth finger", "latency_ms": 923.5072135925293, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 415.19641876220703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1137}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 622.8060722351074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1691}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 630.190372467041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2293}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 629.446268081665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2857}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 415.1186943054199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3471}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 713.324785232544, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 999.1312026977539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1108.3199977874756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 764.6157741546631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 808.8035583496094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2470}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 727.7123928070068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3100}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 998.2590675354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3724}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 555.7897090911865, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Philip Stone", "latency_ms": 624.3071556091309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "Philip Stone", "latency_ms": 636.3387107849121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1184}, "3": {"k": 3, "answer": "Bernard Hill", "latency_ms": 717.9646492004395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "Bernard Hill", "latency_ms": 818.5882568359375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2403}, "5": {"k": 5, "answer": "Bernard Hill", "latency_ms": 537.4047756195068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2961}, "6": {"k": 6, "answer": "Bernard Hill", "latency_ms": 744.157075881958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3543}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2019", "latency_ms": 1013.5273933410645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 792.6857471466064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 580.4877281188965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1404}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 763.8680934906006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2021}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 578.700065612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2622}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 807.2569370269775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3249}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 564.671516418457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3863}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 249.42660331726074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 734.3051433563232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 559.9679946899414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1305}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 814.0993118286133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1996}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 556.412935256958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2635}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 793.8787937164307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3260}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 567.495584487915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3875}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 520.0514793395996, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 546.1475849151611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 547}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 550.8086681365967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1146}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 746.7272281646729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1681}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 815.6118392944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2299}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 815.4139518737793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2944}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 614.9919033050537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3588}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "Every living thing", "latency_ms": 502.46405601501465, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "plants, animals, dead plant matter", "latency_ms": 1000.1111030578613, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "plants, soils, animals, organisms", "latency_ms": 976.3927459716797, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "plants, soils, animals, dead plant matter", "latency_ms": 1153.329849243164, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "in plants, animals, and soils", "latency_ms": 768.3632373809814, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2577}, "5": {"k": 5, "answer": "in plants, soils, and organisms", "latency_ms": 956.8536281585693, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3284}, "6": {"k": 6, "answer": "in plants, soils, and organisms", "latency_ms": 955.2435874938965, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 4017}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 373.2726573944092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 583.1143856048584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 785.9375476837158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1187}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 645.1528072357178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1761}, "4": {"k": 4, "answer": "Chandan Shetty", "latency_ms": 867.5210475921631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2373}, "5": {"k": 5, "answer": "Chandan Shetty", "latency_ms": 608.1390380859375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2968}, "6": {"k": 6, "answer": "Chandan Shetty", "latency_ms": 659.9962711334229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3611}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 744.117259979248, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 587.0130062103271, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 593.1117534637451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 964.9338722229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1866}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 571.1181163787842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 769.2158222198486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3126}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 574.6746063232422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3744}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 521.0208892822266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 575.380802154541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 824.5573043823242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1232}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 728.0690670013428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 561.7237091064453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2515}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 783.5671901702881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3048}, "6": {"k": 6, "answer": "Kevin Kline", "latency_ms": 769.2131996154785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3734}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Lake Winnipeg", "latency_ms": 940.3281211853027, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 828.4206390380859, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Rocky Mountains to Lake Winnipeg", "latency_ms": 878.0031204223633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1383}, "3": {"k": 3, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 822.8850364685059, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 632.7369213104248, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2737}, "5": {"k": 5, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 790.9111976623535, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3342}, "6": {"k": 6, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 840.2681350708008, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4010}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 248.44741821289062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 662.726879119873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 649}, "2": {"k": 2, "answer": "Rome", "latency_ms": 433.5451126098633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Rome", "latency_ms": 421.02789878845215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1916}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 800.3106117248535, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2547}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 773.345947265625, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3180}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 574.9068260192871, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3842}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "Measurement mark", "latency_ms": 261.3809108734131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 730.2145957946777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 721.7123508453369, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 756.9935321807861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1831}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 759.0675354003906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2379}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 952.3735046386719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3002}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 542.5481796264648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3580}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia", "latency_ms": 293.55573654174805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 750.586748123169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 1050.1210689544678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Hydrogen fluoride, ammonia, methanol, hydrogen sulfide", "latency_ms": 1508.6297988891602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Hydrogen fluoride, ammonia, methanol, hydrogen sulfide", "latency_ms": 1494.3315982818604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "Hydrogen fluoride, ammonia, methanol, hydrogen sulfide", "latency_ms": 1317.2311782836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 1079.3139934539795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Boy Meets Girl", "latency_ms": 576.2615203857422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "April 1989", "latency_ms": 747.7264404296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "1988", "latency_ms": 403.82838249206543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "1988", "latency_ms": 661.4484786987305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "1988", "latency_ms": 419.45648193359375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2433}, "5": {"k": 5, "answer": "1988", "latency_ms": 635.995626449585, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3031}, "6": {"k": 6, "answer": "1988", "latency_ms": 444.97227668762207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3624}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 263.38863372802734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hombre", "latency_ms": 630.7673454284668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "Hombre", "latency_ms": 406.7072868347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Hombre", "latency_ms": 698.2676982879639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Hombre", "latency_ms": 754.5180320739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Hombre", "latency_ms": 638.9989852905273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2974}, "6": {"k": 6, "answer": "Hombre", "latency_ms": 432.1756362915039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3613}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 646.1911201477051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Five percent", "latency_ms": 625.2367496490479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Five percent", "latency_ms": 415.1597023010254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Five percent", "latency_ms": 660.3522300720215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1957}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 901.5493392944336, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2567}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 882.6780319213867, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 1106.8627834320068, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3794}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 245.68438529968262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 747.4853992462158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "1975", "latency_ms": 415.42673110961914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1178}, "3": {"k": 3, "answer": "1975", "latency_ms": 446.2857246398926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1756}, "4": {"k": 4, "answer": "1975", "latency_ms": 624.5193481445312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2368}, "5": {"k": 5, "answer": "1975", "latency_ms": 474.56932067871094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2949}, "6": {"k": 6, "answer": "1975", "latency_ms": 625.8759498596191, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3539}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 370.2712059020996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lionel Richie", "latency_ms": 736.6712093353271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Lionel Richie", "latency_ms": 746.9072341918945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Lionel Richie", "latency_ms": 555.0656318664551, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 802.1090030670166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 792.2449111938477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3239}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 619.3008422851562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3863}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert", "latency_ms": 464.02454376220703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lord Baltimore", "latency_ms": 630.6765079498291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Lord Baltimore and John Cabot", "latency_ms": 1152.475118637085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Sir George Calvert", "latency_ms": 550.8418083190918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "Jesuit settlers from England", "latency_ms": 1108.3636283874512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "English Catholics", "latency_ms": 482.74970054626465, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3293}, "6": {"k": 6, "answer": "English Catholics", "latency_ms": 609.2252731323242, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3987}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 256.119966506958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 782.0196151733398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1015.1417255401611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Gary Player", "latency_ms": 642.2805786132812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1826}, "4": {"k": 4, "answer": "Gary Player", "latency_ms": 629.9991607666016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2438}, "5": {"k": 5, "answer": "Gary Player", "latency_ms": 662.1992588043213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3088}, "6": {"k": 6, "answer": "Gary Player", "latency_ms": 440.5174255371094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3738}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 368.6504364013672, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 747.9593753814697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "200 to 500 mg", "latency_ms": 1013.6892795562744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg", "latency_ms": 830.181360244751, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1878}, "4": {"k": 4, "answer": "200 to 500 mg", "latency_ms": 829.1807174682617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2503}, "5": {"k": 5, "answer": "200 to 500 mg", "latency_ms": 791.7542457580566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3147}, "6": {"k": 6, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 1305.8421611785889, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3735}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 1078.977346420288, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham", "latency_ms": 681.006908416748, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 530.5435657501221, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1166}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 702.4402618408203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1758}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 538.7752056121826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2394}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 667.7210330963135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2939}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 515.312910079956, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3533}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 503.0169486999512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canada, Mexico, and the Caribbean.", "latency_ms": 1029.7505855560303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 698}, "2": {"k": 2, "answer": "Canada, Mexico, and the Caribbean, or Chicago.", "latency_ms": 1218.5020446777344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1393}, "3": {"k": 3, "answer": "Canada, Mexico, and the Caribbean", "latency_ms": 936.0575675964355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2014}, "4": {"k": 4, "answer": "Canada, Mexico, and the Caribbean.", "latency_ms": 1003.2808780670166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2663}, "5": {"k": 5, "answer": "Canada, Mexico, or the Caribbean", "latency_ms": 965.3172492980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3306}, "6": {"k": 6, "answer": "Canada, Mexico, or the Caribbean.", "latency_ms": 790.4872894287109, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3970}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh", "latency_ms": 456.5567970275879, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 558.5517883300781, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 732.5189113616943, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1379}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 738.642692565918, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2052}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 575.1523971557617, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2718}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 792.0784950256348, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3417}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 587.5139236450195, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4093}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 298.8402843475342, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 800.4007339477539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 706}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 770.371675491333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 718.146562576294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2062}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 758.0327987670898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2736}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 560.5850219726562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3396}, "6": {"k": 6, "answer": "Roman Reigns", "latency_ms": 736.1888885498047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4082}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 437.01672554016113, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Boston", "latency_ms": 642.8060531616211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "Boston", "latency_ms": 383.6698532104492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Southport, North Carolina", "latency_ms": 630.9680938720703, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Southport, North Carolina.", "latency_ms": 1073.8959312438965, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "Southport, North Carolina", "latency_ms": 854.6044826507568, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3045}, "6": {"k": 6, "answer": "Southport, North Carolina", "latency_ms": 1044.5261001586914, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3679}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 524.0647792816162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 550.544023513794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 786.2529754638672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 764.1620635986328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 1183.69722366333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 905.3993225097656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 892.991304397583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3782}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 547.6462841033936, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 484.1420650482178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 669}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 708.7981700897217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 706.2838077545166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2012}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 806.0920238494873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2658}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 706.8860530853271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3374}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 713.2399082183838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4111}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 191.52593612670898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 442.549467086792, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "Max", "latency_ms": 378.92866134643555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Max", "latency_ms": 627.4135112762451, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1967}, "4": {"k": 4, "answer": "Max", "latency_ms": 438.2140636444092, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2615}, "5": {"k": 5, "answer": "Max", "latency_ms": 614.1912937164307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3269}, "6": {"k": 6, "answer": "Max", "latency_ms": 606.8675518035889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3871}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 561.8340969085693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 805.1509857177734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 786.05055809021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Amybeth McNulty", "latency_ms": 579.0834426879883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "Amybeth McNulty", "latency_ms": 994.5797920227051, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2461}, "5": {"k": 5, "answer": "Amybeth McNulty", "latency_ms": 768.115758895874, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3048}, "6": {"k": 6, "answer": "Amybeth McNulty", "latency_ms": 819.9663162231445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3664}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "Industrialization and imperialism.", "latency_ms": 845.1201915740967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 577.406644821167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 784.1930389404297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 770.371675491333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 806.0250282287598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2466}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 802.4582862854004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 862.7471923828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 526.6737937927246, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "self-empowerment", "latency_ms": 677.3922443389893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 855.0107479095459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "self-empowerment", "latency_ms": 850.3339290618896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "self-empowerment", "latency_ms": 896.7845439910889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2540}, "5": {"k": 5, "answer": "self-empowerment", "latency_ms": 1148.094654083252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3170}, "6": {"k": 6, "answer": "self-empowerment", "latency_ms": 885.3929042816162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 246.48070335388184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "NFL owners", "latency_ms": 451.91216468811035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "NFL franchises", "latency_ms": 465.9264087677002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "NFL franchises", "latency_ms": 596.0366725921631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1828}, "4": {"k": 4, "answer": "NFL franchises", "latency_ms": 476.9716262817383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2427}, "5": {"k": 5, "answer": "NFL franchises", "latency_ms": 653.8941860198975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3074}, "6": {"k": 6, "answer": "NFL franchises", "latency_ms": 612.8895282745361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3678}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 581.1612606048584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 746.0880279541016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Marshall", "latency_ms": 475.32081604003906, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Marshall", "latency_ms": 462.1763229370117, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1977}, "4": {"k": 4, "answer": "Marshall", "latency_ms": 623.4498023986816, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2639}, "5": {"k": 5, "answer": "Marshall", "latency_ms": 468.31774711608887, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3324}, "6": {"k": 6, "answer": "Marshall", "latency_ms": 478.2238006591797, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3947}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 308.2289695739746, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 747.9658126831055, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 906.5625667572021, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 763.7622356414795, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 762.2618675231934, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 789.839506149292, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 802.405834197998, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3821}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 617.2873973846436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 759.8416805267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 727.3874282836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1188}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 799.3800640106201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1788}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1020.34592628479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2404}, "5": {"k": 5, "answer": "All five ski jumping gold medals.", "latency_ms": 828.068733215332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3041}, "6": {"k": 6, "answer": "5", "latency_ms": 660.9559059143066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3705}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1013.5324001312256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1216.273307800293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1003.420352935791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1032.7599048614502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1844}, "4": {"k": 4, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1057.152509689331, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2508}, "5": {"k": 5, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1080.0702571868896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3165}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 816.6763782501221, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3840}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 449.0313529968262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "German-speaking world", "latency_ms": 520.9438800811768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 699}, "2": {"k": 2, "answer": "German-speaking world", "latency_ms": 690.8538341522217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1383}, "3": {"k": 3, "answer": "German-speaking world", "latency_ms": 535.2437496185303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2014}, "4": {"k": 4, "answer": "German-speaking world", "latency_ms": 745.1932430267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2662}, "5": {"k": 5, "answer": "German-speaking world", "latency_ms": 498.1715679168701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3308}, "6": {"k": 6, "answer": "German-speaking world", "latency_ms": 486.33432388305664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4054}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 314.35656547546387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 547.6000308990479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 764.0519142150879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 570.9540843963623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "post-medieval era", "latency_ms": 530.8282375335693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "Post-medieval era", "latency_ms": 543.4064865112305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3140}, "6": {"k": 6, "answer": "16481651", "latency_ms": 617.9320812225342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3791}}}
