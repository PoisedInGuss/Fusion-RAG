{"qid": "-9197932657152136610", "question": "what are the main sources of economic growth in the us currently", "gold_answers": ["pharmaceuticals", "aircraft", "telecommunications", "heavy machinery"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 775.5947113037109, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1412.04833984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1211.4243507385254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1440}, "3": {"k": 3, "answer": "New products and services", "latency_ms": 1281.6784381866455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2083}, "4": {"k": 4, "answer": "New products and services", "latency_ms": 1117.5079345703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2789}, "5": {"k": 5, "answer": "New products and services", "latency_ms": 1295.628547668457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3477}, "6": {"k": 6, "answer": "New products and services", "latency_ms": 1113.5828495025635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4126}}}
{"qid": "-4566914757117567579", "question": "who played ethel on the doris day show", "gold_answers": ["Carol Worthington"], "shots": {"0": {"k": 0, "answer": "Kay Chanda", "latency_ms": 805.4313659667969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1327.0087242126465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1096.1346626281738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1166}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1050.3954887390137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1798}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1012.3386383056641, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2420}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1389.5063400268555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3034}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 879.5905113220215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3700}}}
{"qid": "212435016090205927", "question": "who played g baby in the movie hardball", "gold_answers": ["DeWayne Warren"], "shots": {"0": {"k": 0, "answer": "Keanu Reeves", "latency_ms": 1087.3992443084717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "DeWayne Warren", "latency_ms": 966.2327766418457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 644}, "2": {"k": 2, "answer": "DeWayne Warren", "latency_ms": 1050.4591464996338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "DeWayne Warren", "latency_ms": 1192.1906471252441, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1890}, "4": {"k": 4, "answer": "DeWayne Warren", "latency_ms": 1049.7264862060547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2486}, "5": {"k": 5, "answer": "DeWayne Warren", "latency_ms": 584.033727645874, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3158}, "6": {"k": 6, "answer": "DeWayne Warren", "latency_ms": 995.6350326538086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3748}}}
{"qid": "-4190633494852415957", "question": "who played john coffey in the movie the green mile", "gold_answers": ["Michael Clarke Duncan"], "shots": {"0": {"k": 0, "answer": "Michael Clarke Duncan", "latency_ms": 726.917028427124, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Clarke Duncan", "latency_ms": 942.2817230224609, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "Michael Clarke Duncan", "latency_ms": 666.2166118621826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1266}, "3": {"k": 3, "answer": "Michael Clarke Duncan", "latency_ms": 1185.7006549835205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Michael Clarke Duncan", "latency_ms": 961.775541305542, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Michael Clarke Duncan", "latency_ms": 957.3562145233154, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3211}, "6": {"k": 6, "answer": "Michael Clarke Duncan", "latency_ms": 1288.1629467010498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3825}}}
{"qid": "811267239470530686", "question": "who wrote catch 22 (both names)", "gold_answers": ["American author Joseph Heller", "Joseph Heller .", "Joseph Heller"], "shots": {"0": {"k": 0, "answer": "Joseph Heller", "latency_ms": 683.4628582000732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Joseph Heller", "latency_ms": 433.8700771331787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 623}, "2": {"k": 2, "answer": "Joseph Heller", "latency_ms": 1148.60200881958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1255}, "3": {"k": 3, "answer": "Joseph Heller", "latency_ms": 908.2832336425781, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Joseph Heller", "latency_ms": 692.7385330200195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2538}, "5": {"k": 5, "answer": "Joseph Heller", "latency_ms": 1128.711223602295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3136}, "6": {"k": 6, "answer": "Joseph Heller", "latency_ms": 1023.9236354827881, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3800}}}
{"qid": "-1608179127534867277", "question": "where was the world chess tournament 2017 held", "gold_answers": ["Tbilisi , Georgia", "in Tbilisi , Georgia"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 178.85494232177734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tbilisi, Georgia", "latency_ms": 1566.8179988861084, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "Tbilisi, Georgia", "latency_ms": 1600.4540920257568, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Tbilisi, Georgia", "latency_ms": 1754.8458576202393, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Tbilisi, Georgia", "latency_ms": 1006.2975883483887, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Tbilisi, Georgia", "latency_ms": 1311.2823963165283, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3272}, "6": {"k": 6, "answer": "Tbilisi, Georgia", "latency_ms": 1118.1957721710205, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3876}}}
{"qid": "7687115121611301468", "question": "who votes to elect a rajya sabha memmber", "gold_answers": ["state legislatures"], "shots": {"0": {"k": 0, "answer": "Elected members of State Legislative Assembly", "latency_ms": 1799.7689247131348, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Legislative assemblies of the states and the Electoral College of the Union Territories.", "latency_ms": 2630.5999755859375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "Members of the Legislative Assembly (MLAs)", "latency_ms": 1771.9213962554932, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Members of the Legislative Assembly (MLAs)", "latency_ms": 2109.252691268921, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "Members of the Legislative Assembly (MLAs)", "latency_ms": 1460.3984355926514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Members of the Legislative Assembly", "latency_ms": 1395.310401916504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3118}, "6": {"k": 6, "answer": "Members of the Legislative Assembly (MLAs)", "latency_ms": 2080.9617042541504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3678}}}
{"qid": "-5784633834792163973", "question": "when does season 8 of hawaii five o premiere", "gold_answers": ["September 29 , 2017"], "shots": {"0": {"k": 0, "answer": "September 27, 2017", "latency_ms": 972.5720882415771, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 29, 2017", "latency_ms": 1372.0979690551758, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "September 29, 2017", "latency_ms": 1755.1605701446533, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "September 29, 2017", "latency_ms": 2053.0600547790527, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "September 29, 2017", "latency_ms": 1456.0294151306152, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2477}, "5": {"k": 5, "answer": "September 29, 2017", "latency_ms": 1194.1027641296387, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3133}, "6": {"k": 6, "answer": "September 29, 2017", "latency_ms": 1367.3498630523682, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3769}}}
{"qid": "-5864397450755103545", "question": "paul walkers cars in fast and furious list", "gold_answers": ["1995 Toyota Supra", "2002 Mitsubishi Lancer OZ Rally", "1995 Dodge Stealth", "1995 Mitsubishi Eclipse"], "shots": {"0": {"k": 0, "answer": "Toyota Supra, Nissan Skyline, Mitsubishi Eclipse, Dodge Charger, BMW M5", "latency_ms": 3012.479066848755, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1009.6402168273926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1254.404067993164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1207}, "3": {"k": 3, "answer": "Mitsubishi Lancer Evolution, 1972 Ford Gran Torino Sport", "latency_ms": 3046.5731620788574, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 1821}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1262.3107433319092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2438}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 995.6607818603516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3037}, "6": {"k": 6, "answer": "Mitsubishi Lancer Evolution, Mitsubishi Lancer Ralliart edition", "latency_ms": 2940.4361248016357, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3671}}}
{"qid": "-8491157534197669091", "question": "who won the oscar for best actor in 1975", "gold_answers": ["Art Carney"], "shots": {"0": {"k": 0, "answer": "Art Carney", "latency_ms": 973.6599922180176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1272.8424072265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "Peter Finch", "latency_ms": 1221.8947410583496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "Peter Finch", "latency_ms": 752.7012825012207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "Peter Finch", "latency_ms": 1196.7532634735107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2655}, "5": {"k": 5, "answer": "Peter Finch", "latency_ms": 770.5905437469482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3243}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1290.7121181488037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3847}}}
{"qid": "-8408640804522114136", "question": "when did the first episode of that 70s show air", "gold_answers": ["August 23 , 1998"], "shots": {"0": {"k": 0, "answer": "August 23, 1998", "latency_ms": 829.6337127685547, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "16 April 2012", "latency_ms": 1282.8636169433594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "16 April 2012", "latency_ms": 1077.2104263305664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1187}, "3": {"k": 3, "answer": "1998", "latency_ms": 952.6584148406982, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "1998", "latency_ms": 424.42965507507324, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "August 23, 1998", "latency_ms": 1635.8861923217773, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3052}, "6": {"k": 6, "answer": "August 23, 1998", "latency_ms": 1130.6471824645996, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3712}}}
{"qid": "722920117313579366", "question": "when did the book thief movie come out", "gold_answers": ["November 27 , 2013", "2013"], "shots": {"0": {"k": 0, "answer": "November 8, 2013", "latency_ms": 998.0776309967041, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "November 8, 2013", "latency_ms": 1602.902889251709, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 661}, "2": {"k": 2, "answer": "November 8, 2013", "latency_ms": 1421.4293956756592, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1300}, "3": {"k": 3, "answer": "November 8, 2013", "latency_ms": 1486.0148429870605, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1913}, "4": {"k": 4, "answer": "November 8, 2013", "latency_ms": 1844.5773124694824, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2522}, "5": {"k": 5, "answer": "November 8, 2013", "latency_ms": 1499.8295307159424, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3153}, "6": {"k": 6, "answer": "November 8, 2013", "latency_ms": 1569.3612098693848, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3786}}}
{"qid": "-4427112594024146143", "question": "when did the eagles win the super bowl", "gold_answers": ["2017"], "shots": {"0": {"k": 0, "answer": "Super Bowl LII", "latency_ms": 1013.7369632720947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 751.8506050109863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 824.7063159942627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "2018", "latency_ms": 1098.0591773986816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "2018", "latency_ms": 661.0736846923828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2414}, "5": {"k": 5, "answer": "2018", "latency_ms": 659.5292091369629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3056}, "6": {"k": 6, "answer": "2018", "latency_ms": 1134.8726749420166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3647}}}
{"qid": "7078422108284431587", "question": "who is the biggest selling female group of all time", "gold_answers": ["Spice Girls"], "shots": {"0": {"k": 0, "answer": "The Spice Girls", "latency_ms": 754.0192604064941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 942.1195983886719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "Spice Girls", "latency_ms": 754.6241283416748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Spice Girls", "latency_ms": 854.623556137085, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1852}, "4": {"k": 4, "answer": "Spice Girls", "latency_ms": 696.1879730224609, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Spice Girls", "latency_ms": 949.0652084350586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3085}, "6": {"k": 6, "answer": "Spice Girls", "latency_ms": 704.2975425720215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3741}}}
{"qid": "1039102546557940080", "question": "who sang from russia with love james bond", "gold_answers": ["Matt Monro"], "shots": {"0": {"k": 0, "answer": "Matt Monro", "latency_ms": 520.3945636749268, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matt Monro", "latency_ms": 669.7788238525391, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "Matt Monro", "latency_ms": 901.801347732544, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Matt Monro", "latency_ms": 885.4188919067383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1860}, "4": {"k": 4, "answer": "Matt Monro", "latency_ms": 674.2455959320068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Matt Monro", "latency_ms": 1198.927879333496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3053}, "6": {"k": 6, "answer": "Matt Monro", "latency_ms": 668.7920093536377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3701}}}
{"qid": "-8507438636601119973", "question": "where is urinary bladder located in human body", "gold_answers": ["on the pelvic floor", "pelvic floor"], "shots": {"0": {"k": 0, "answer": "Pelvic cavity", "latency_ms": 790.2233600616455, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the base of the pelvis", "latency_ms": 1154.8724174499512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "at the base of the pelvis", "latency_ms": 1586.69114112854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1184}, "3": {"k": 3, "answer": "At the base of the pelvis", "latency_ms": 1400.2685546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1788}, "4": {"k": 4, "answer": "at the base of the pelvis", "latency_ms": 1991.8386936187744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2395}, "5": {"k": 5, "answer": "At the base of the pelvis", "latency_ms": 1202.2879123687744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3024}, "6": {"k": 6, "answer": "at the base of the pelvis", "latency_ms": 1655.0374031066895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3679}}}
{"qid": "-1996951438961136762", "question": "architectural elements forming rib vaults eg wells cathedral", "gold_answers": ["two to three barrel vaults", "an armature of piped masonry", "barrel vaults"], "shots": {"0": {"k": 0, "answer": "Ribs", "latency_ms": 425.7371425628662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ribs in a net-like form", "latency_ms": 1591.5637016296387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 571}, "2": {"k": 2, "answer": "Ribs in a net-like form", "latency_ms": 1347.5172519683838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Stone", "latency_ms": 1072.3145008087158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "Lierne ribs", "latency_ms": 1062.5884532928467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2551}, "5": {"k": 5, "answer": "Lierne ribs", "latency_ms": 1188.9653205871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Lierne ribs", "latency_ms": 1491.072416305542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3896}}}
{"qid": "-8490085242981497626", "question": "who sang gonna sit right down and write myself a letter", "gold_answers": ["Fats Waller"], "shots": {"0": {"k": 0, "answer": "Alicia Keys", "latency_ms": 1041.210651397705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cleo Laine, Uncle Floyd, Madeleine Peyroux, Tony Danza, Paul McCartney", "latency_ms": 3362.159252166748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Cleo Laine, Uncle Floyd, Madeleine Peyroux, Tony Danza, Paul McCartney, Fats Waller", "latency_ms": 3516.0837173461914, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Fats Waller", "latency_ms": 1269.1388130187988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1921}, "4": {"k": 4, "answer": "Fats Waller", "latency_ms": 992.9842948913574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2585}, "5": {"k": 5, "answer": "Fats Waller", "latency_ms": 1033.320665359497, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Fats Waller", "latency_ms": 1523.815393447876, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3811}}}
{"qid": "8783361206191889627", "question": "how many rooms is there in buckingham palace", "gold_answers": ["775 rooms", "775"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1047.4371910095215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "775", "latency_ms": 717.2260284423828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "775", "latency_ms": 830.1281929016113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1197}, "3": {"k": 3, "answer": "775", "latency_ms": 588.0262851715088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1767}, "4": {"k": 4, "answer": "775", "latency_ms": 441.817045211792, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2347}, "5": {"k": 5, "answer": "775", "latency_ms": 631.8075656890869, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2992}, "6": {"k": 6, "answer": "775", "latency_ms": 610.3770732879639, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3613}}}
{"qid": "1172792682698457582", "question": "where did they get the tree for rockefeller center", "gold_answers": ["State College , PA"], "shots": {"0": {"k": 0, "answer": "Wallkill, New York", "latency_ms": 869.4641590118408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 969.5372581481934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1268.5959339141846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Ohio, Killingworth, Connecticut", "latency_ms": 1448.678970336914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1273.636817932129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2583}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1080.6293487548828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3247}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1057.833194732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3925}}}
{"qid": "-8616225749004085214", "question": "who expanded the territory of china during the qing dynasty", "gold_answers": ["Prince Bao", "the Qianlong Emperor", "Qianlong"], "shots": {"0": {"k": 0, "answer": "Qianlong Emperor", "latency_ms": 1065.7556056976318, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "European empires", "latency_ms": 965.6662940979004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "Qianlong Emperor", "latency_ms": 1052.283763885498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1335}, "3": {"k": 3, "answer": "Qianlong Emperor", "latency_ms": 1253.190279006958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2000}, "4": {"k": 4, "answer": "Qianlong Emperor", "latency_ms": 808.9590072631836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Qianlong Emperor", "latency_ms": 810.8727931976318, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3267}, "6": {"k": 6, "answer": "Qianlong Emperor", "latency_ms": 1064.1958713531494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3922}}}
{"qid": "-4544825586005995775", "question": "what is the second largest country in asia", "gold_answers": ["China"], "shots": {"0": {"k": 0, "answer": "Kazakhstan", "latency_ms": 751.0666847229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1169.175624847412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1281.846523284912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1351.1428833007812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1955}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 779.80637550354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 827.5704383850098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3251}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1277.7843475341797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3816}}}
{"qid": "2851585794686488659", "question": "when was the last episode of vampire diaries aired", "gold_answers": ["March 10 , 2017"], "shots": {"0": {"k": 0, "answer": "March 10, 2017", "latency_ms": 1638.3562088012695, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1135.9729766845703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "March 10, 2017", "latency_ms": 1448.2579231262207, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "March 10, 2017", "latency_ms": 1476.4938354492188, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1844}, "4": {"k": 4, "answer": "March 10, 2017", "latency_ms": 1235.2488040924072, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "March 10, 2017", "latency_ms": 1523.5724449157715, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3129}, "6": {"k": 6, "answer": "March 10, 2017", "latency_ms": 1673.302173614502, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3724}}}
{"qid": "636692438616046367", "question": "who played ashley on the young and the restless", "gold_answers": ["Shari Shattuck", "Eileen Davidson", "Brenda Epperson"], "shots": {"0": {"k": 0, "answer": "Eileen Davidson", "latency_ms": 1105.3376197814941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eileen Davidson", "latency_ms": 721.3919162750244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 629}, "2": {"k": 2, "answer": "Eileen Davidson", "latency_ms": 783.583402633667, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Eileen Davidson", "latency_ms": 1035.7744693756104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1855}, "4": {"k": 4, "answer": "Eileen Davidson, Brenda Epperson, Shari Shattuck", "latency_ms": 2018.5325145721436, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2479}, "5": {"k": 5, "answer": "Eileen Davidson, Brenda Epperson, Shari Shattuck", "latency_ms": 2462.268114089966, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3090}, "6": {"k": 6, "answer": "Eileen Davidson, Brenda Epperson, Shari Shattuck", "latency_ms": 2692.2154426574707, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3694}}}
{"qid": "-2668952310493902320", "question": "who has scored the most points for wales v france", "gold_answers": ["Neil Jenkins"], "shots": {"0": {"k": 0, "answer": "Neil Jenkins", "latency_ms": 1141.8354511260986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1201.7390727996826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 886.7967128753662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1181}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1800.8942604064941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "Barry John", "latency_ms": 766.3164138793945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2357}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1064.812183380127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3004}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1308.6590766906738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3616}}}
{"qid": "-551363795407275714", "question": "who is pictured on the 5000 dollar bill", "gold_answers": ["James Madison"], "shots": {"0": {"k": 0, "answer": "James Madison", "latency_ms": 500.16212463378906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 827.9905319213867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1873.2244968414307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1251}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1306.6792488098145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1933}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 750.2825260162354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 771.7165946960449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3244}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1120.091199874878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3882}}}
{"qid": "-1776638341170409438", "question": "what is the strongest earthquake in the united states", "gold_answers": ["1700 Cascadia earthquake", "1964 Alaska earthquake and tsunami"], "shots": {"0": {"k": 0, "answer": "Great Alaska Earthquake", "latency_ms": 1047.6295948028564, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1979 Coyote Lake earthquake", "latency_ms": 1337.928056716919, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1529.2308330535889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "5.8", "latency_ms": 798.7241744995117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "7.9 M", "latency_ms": 1028.8581848144531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "7.9 M", "latency_ms": 1072.730302810669, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3214}, "6": {"k": 6, "answer": "7.9 M", "latency_ms": 1245.0203895568848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3870}}}
{"qid": "-3417376069582577712", "question": "who wrote the song balls to the wall", "gold_answers": ["Herman Frank", "Peter Baltes", "Stefan Kaufmann", "Wolf Hoffmann", "Udo Dirkschneider", "Deaffy"], "shots": {"0": {"k": 0, "answer": "Accept", "latency_ms": 393.2175636291504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 987.4639511108398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1020.9589004516602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1250.049352645874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1272.369384765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1535.9504222869873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3122}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1040.4472351074219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3803}}}
{"qid": "-5788046732019278353", "question": "who talks for belle in beauty and the beast", "gold_answers": ["Julie Nathanson", "Jodi Benson", "Paige O'Hara"], "shots": {"0": {"k": 0, "answer": "Paige O'Hara", "latency_ms": 1114.5288944244385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Emma Watson", "latency_ms": 775.4929065704346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Paige O'Hara", "latency_ms": 1636.0857486724854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1334}, "3": {"k": 3, "answer": "Paige O'Hara", "latency_ms": 883.2645416259766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1985}, "4": {"k": 4, "answer": "Paige O'Hara", "latency_ms": 1337.005615234375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2641}, "5": {"k": 5, "answer": "Paige O'Hara", "latency_ms": 1342.7915573120117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3336}, "6": {"k": 6, "answer": "Paige O'Hara", "latency_ms": 1322.702169418335, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3994}}}
{"qid": "-819495145099806596", "question": "what is a coherent set of values and beliefs about public policy called", "gold_answers": ["political ideology", "ideology", "a political ideology"], "shots": {"0": {"k": 0, "answer": "Ideology", "latency_ms": 663.9173030853271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "doctrine", "latency_ms": 607.0148944854736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Public policy doctrine", "latency_ms": 468.2881832122803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1428}, "3": {"k": 3, "answer": "Public policy doctrine", "latency_ms": 1211.954116821289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2128}, "4": {"k": 4, "answer": "Public policy doctrine", "latency_ms": 776.5018939971924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2727}, "5": {"k": 5, "answer": "Public policy doctrine", "latency_ms": 435.41622161865234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3415}, "6": {"k": 6, "answer": "Public policy doctrine", "latency_ms": 1217.3211574554443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4168}}}
{"qid": "-467801736331608973", "question": "when do liam and annie get together season 3", "gold_answers": ["Holiday Madness"], "shots": {"0": {"k": 0, "answer": "Episode 9", "latency_ms": 726.2523174285889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1033.250331878662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1148.1342315673828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1144}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 985.9120845794678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1749}, "4": {"k": 4, "answer": "Season 3", "latency_ms": 1269.1481113433838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2330}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 530.6062698364258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2907}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1090.6271934509277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3535}}}
{"qid": "7210975046317501288", "question": "what breed of cat has spots and stripes", "gold_answers": ["tabby"], "shots": {"0": {"k": 0, "answer": "Tabby", "latency_ms": 623.9051818847656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bengal cat", "latency_ms": 1540.7884120941162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "Bengal cat", "latency_ms": 1271.9955444335938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1160}, "3": {"k": 3, "answer": "Bengal cat", "latency_ms": 1526.3941287994385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1790}, "4": {"k": 4, "answer": "Bengal cat", "latency_ms": 1182.178020477295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2482}, "5": {"k": 5, "answer": "Bengal cat", "latency_ms": 1310.584545135498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3026}, "6": {"k": 6, "answer": "Bengal cat", "latency_ms": 1365.4015064239502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3634}}}
{"qid": "7817340376558760325", "question": "who voiced simba in the lion king 2", "gold_answers": ["Matthew Broderick"], "shots": {"0": {"k": 0, "answer": "Matthew Broderick", "latency_ms": 839.2550945281982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matthew Broderick", "latency_ms": 1485.304832458496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 649}, "2": {"k": 2, "answer": "Matthew Broderick", "latency_ms": 1284.062385559082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Matthew Broderick", "latency_ms": 1314.5179748535156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1880}, "4": {"k": 4, "answer": "Matthew Broderick", "latency_ms": 1036.6876125335693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2555}, "5": {"k": 5, "answer": "Matthew Broderick", "latency_ms": 1257.800817489624, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Matthew Broderick", "latency_ms": 1216.8338298797607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3811}}}
{"qid": "7584034394038581786", "question": "when did the angel of the north get built", "gold_answers": ["1998", "1994"], "shots": {"0": {"k": 0, "answer": "1998", "latency_ms": 523.8983631134033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 691.7984485626221, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "1994-1998", "latency_ms": 1032.0794582366943, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1201}, "3": {"k": 3, "answer": "1994-1998", "latency_ms": 1603.0383110046387, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1878}, "4": {"k": 4, "answer": "1994-1998", "latency_ms": 1379.31227684021, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2510}, "5": {"k": 5, "answer": "1994-1998", "latency_ms": 1399.7418880462646, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3099}, "6": {"k": 6, "answer": "1994-1998", "latency_ms": 1368.5424327850342, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3712}}}
{"qid": "1854394640394891866", "question": "when did mcgee became a regular on ncis", "gold_answers": ["in season two", "season two"], "shots": {"0": {"k": 0, "answer": "Season 2", "latency_ms": 733.3142757415771, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Season two", "latency_ms": 937.0162487030029, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Season two", "latency_ms": 1228.6102771759033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Season two", "latency_ms": 921.7076301574707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1985}, "4": {"k": 4, "answer": "Season two", "latency_ms": 552.3712635040283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2629}, "5": {"k": 5, "answer": "Season two", "latency_ms": 522.8989124298096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3274}, "6": {"k": 6, "answer": "Season two", "latency_ms": 1248.7199306488037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3896}}}
{"qid": "2247250807557083996", "question": "when was 1 john 5 7 added to the bible", "gold_answers": ["the 9th century"], "shots": {"0": {"k": 0, "answer": "15th century", "latency_ms": 801.6941547393799, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1200.6182670593262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1297.1806526184082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "13th century", "latency_ms": 1699.960708618164, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "13th century", "latency_ms": 1162.4765396118164, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2581}, "5": {"k": 5, "answer": "19th century", "latency_ms": 539.6506786346436, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3130}, "6": {"k": 6, "answer": "19th century", "latency_ms": 1120.8009719848633, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3705}}}
{"qid": "-2049551589682654986", "question": "when was the latest version of chrome released", "gold_answers": ["2018 - 01 - 22"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 774.5089530944824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "20 May 2014", "latency_ms": 1615.4358386993408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 689}, "2": {"k": 2, "answer": "19 May 2015", "latency_ms": 1053.560495376587, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1373}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1094.8095321655273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2052}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1319.394588470459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2737}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1471.8914031982422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3464}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1049.5960712432861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4107}}}
{"qid": "-3534092359651954035", "question": "who is jojo in horton hears a who", "gold_answers": ["Jesse McCartney"], "shots": {"0": {"k": 0, "answer": "JoJo", "latency_ms": 687.7610683441162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a small Who", "latency_ms": 954.4575214385986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "JoJo, the teenage son of Mayor Ned McDodd", "latency_ms": 2080.085515975952, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1157}, "3": {"k": 3, "answer": "JoJo, the Mayor's teenage son", "latency_ms": 2192.9092407226562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1746}, "4": {"k": 4, "answer": "JoJo, the Mayor's teenage son", "latency_ms": 1713.186264038086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "JoJo, the Mayor's teenage son", "latency_ms": 1553.745985031128, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3004}, "6": {"k": 6, "answer": "JoJo, the Mayor's teenage son", "latency_ms": 1755.4066181182861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3646}}}
{"qid": "6504412384445795967", "question": "the part of the cytoskeleton made from the protein actin is called", "gold_answers": ["Microfilaments", "microfilament"], "shots": {"0": {"k": 0, "answer": "Microfilaments", "latency_ms": 296.8626022338867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "actin cytoskeleton", "latency_ms": 1093.8975811004639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "Microfilament", "latency_ms": 780.6963920593262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "microfilaments", "latency_ms": 1190.688133239746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1941}, "4": {"k": 4, "answer": "Microfilaments", "latency_ms": 805.046796798706, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2667}, "5": {"k": 5, "answer": "microfilaments", "latency_ms": 968.4102535247803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3336}, "6": {"k": 6, "answer": "Microfilaments", "latency_ms": 802.7868270874023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4014}}}
{"qid": "95888218441734902", "question": "who plays jack in battle of the sexes", "gold_answers": ["Bill Pullman", "( Bill Pullman"], "shots": {"0": {"k": 0, "answer": "Steve Carell", "latency_ms": 745.4426288604736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Steve Carell", "latency_ms": 705.4135799407959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "Steve Carell", "latency_ms": 1033.9837074279785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Steve Carell", "latency_ms": 1222.790241241455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1887}, "4": {"k": 4, "answer": "Steve Carell", "latency_ms": 743.2446479797363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Emma Stone", "latency_ms": 714.0343189239502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "Emma Stone", "latency_ms": 624.1109371185303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3797}}}
{"qid": "2482202658787537401", "question": "is a network connection device that can build tables that identify addresses on each network", "gold_answers": ["routing table", "a router"], "shots": {"0": {"k": 0, "answer": "Router", "latency_ms": 385.9062194824219, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Router", "latency_ms": 595.8902835845947, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 714}, "2": {"k": 2, "answer": "Router", "latency_ms": 900.9249210357666, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1368}, "3": {"k": 3, "answer": "Router", "latency_ms": 346.9517230987549, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Router", "latency_ms": 876.4526844024658, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2721}, "5": {"k": 5, "answer": "Router", "latency_ms": 639.1415596008301, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3483}, "6": {"k": 6, "answer": "Router", "latency_ms": 568.4661865234375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4182}}}
{"qid": "8359496728452221378", "question": "when did the royal proclamation of 1763 end", "gold_answers": ["with the American Revolutionary War", "the American Revolutionary War", "1783"], "shots": {"0": {"k": 0, "answer": "1763", "latency_ms": 464.2031192779541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "American Revolutionary War", "latency_ms": 986.7720603942871, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "with the American Revolutionary War", "latency_ms": 1514.9848461151123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "with the American Revolutionary War", "latency_ms": 1627.084493637085, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1981}, "4": {"k": 4, "answer": "with the American Revolutionary War", "latency_ms": 1321.6331005096436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2692}, "5": {"k": 5, "answer": "with the American Revolutionary War", "latency_ms": 1097.7263450622559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3351}, "6": {"k": 6, "answer": "with the American Revolutionary War", "latency_ms": 828.488826751709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3976}}}
{"qid": "-2657014790962135860", "question": "the tenure of the office of the lokayukt of up", "gold_answers": ["8 years", "eight years"], "shots": {"0": {"k": 0, "answer": "8 years", "latency_ms": 482.90133476257324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eight years", "latency_ms": 920.7038879394531, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Eight years", "latency_ms": 714.6379947662354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1335}, "3": {"k": 3, "answer": "Eight years", "latency_ms": 879.8224925994873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1959}, "4": {"k": 4, "answer": "Eight years", "latency_ms": 985.08620262146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2621}, "5": {"k": 5, "answer": "Eight years", "latency_ms": 1039.44730758667, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3270}, "6": {"k": 6, "answer": "Eight years", "latency_ms": 1198.9710330963135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3926}}}
{"qid": "1827180983934640653", "question": "when did response to state of the union start", "gold_answers": ["1966", "in 1966"], "shots": {"0": {"k": 0, "answer": "1966", "latency_ms": 240.37981033325195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "January 25, 1984", "latency_ms": 1692.0077800750732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "1970", "latency_ms": 1006.0839653015137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1350}, "3": {"k": 3, "answer": "1970", "latency_ms": 1038.6722087860107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "1970", "latency_ms": 990.1068210601807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2632}, "5": {"k": 5, "answer": "1970", "latency_ms": 437.0601177215576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "1970", "latency_ms": 1104.2811870574951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3924}}}
{"qid": "-8006002028754190814", "question": "who had the most governmental power under the articles of confederation", "gold_answers": ["the states"], "shots": {"0": {"k": 0, "answer": "State governments", "latency_ms": 445.5087184906006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Congress", "latency_ms": 405.1094055175781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "Congress", "latency_ms": 375.34356117248535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1370}, "3": {"k": 3, "answer": "Congress", "latency_ms": 624.9148845672607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1995}, "4": {"k": 4, "answer": "The states", "latency_ms": 463.42015266418457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2689}, "5": {"k": 5, "answer": "The states", "latency_ms": 1148.2231616973877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3352}, "6": {"k": 6, "answer": "The states", "latency_ms": 423.0821132659912, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4075}}}
{"qid": "3406509904702130536", "question": "how many hospitals are there in the united states", "gold_answers": ["5,534 registered hospitals", "5,534"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 577.507734298706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5,534", "latency_ms": 740.1225566864014, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 723}, "2": {"k": 2, "answer": "5,534", "latency_ms": 1113.457441329956, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1403}, "3": {"k": 3, "answer": "5,534", "latency_ms": 1248.6598491668701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2123}, "4": {"k": 4, "answer": "5,534", "latency_ms": 1004.0948390960693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2807}, "5": {"k": 5, "answer": "5,534", "latency_ms": 936.5973472595215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3458}, "6": {"k": 6, "answer": "5,534", "latency_ms": 1007.7164173126221, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4111}}}
{"qid": "2435796066046322163", "question": "who donates a christmas tree to trafalgar square", "gold_answers": ["Oslo , Norway"], "shots": {"0": {"k": 0, "answer": "Norway", "latency_ms": 235.33058166503906, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The city of Oslo, Norway", "latency_ms": 1093.3866500854492, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Norway", "latency_ms": 957.207441329956, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "The city of Oslo, Norway", "latency_ms": 1855.9482097625732, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1929}, "4": {"k": 4, "answer": "The city of Oslo, Norway", "latency_ms": 1137.7286911010742, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2542}, "5": {"k": 5, "answer": "Norway", "latency_ms": 957.4885368347168, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3188}, "6": {"k": 6, "answer": "Norway", "latency_ms": 1030.9782028198242, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3831}}}
{"qid": "4926415052497472665", "question": "who starred in the movie on golden pond", "gold_answers": ["William Lanteau", "Dabney Coleman", "Henry Fonda", "Doug McKeon", "Jane Fonda", "Christopher Rydell", "Katharine Hepburn"], "shots": {"0": {"k": 0, "answer": "Henry Fonda", "latency_ms": 971.9803333282471, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Julie Andrews and Christopher Plummer", "latency_ms": 1448.9667415618896, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 609}, "2": {"k": 2, "answer": "Julie Andrews, Christopher Plummer, Katharine Hepburn, Henry Fonda", "latency_ms": 3457.7066898345947, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Julie Andrews, Christopher Plummer, Katharine Hepburn, Henry Fonda, Jane Fonda", "latency_ms": 3612.379550933838, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Julie Andrews, Christopher Plummer, Katharine Hepburn, Henry Fonda, Jane Fonda", "latency_ms": 3795.9060668945312, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2539}, "5": {"k": 5, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 2011.3935470581055, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3142}, "6": {"k": 6, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 1980.626106262207, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3750}}}
{"qid": "2142753216627246962", "question": "isdn uses b & d channels. what is d channel use for", "gold_answers": ["carries control and signaling information", "data", "control and signaling information"], "shots": {"0": {"k": 0, "answer": "Signaling", "latency_ms": 496.2272644042969, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sending and receiving X.25 data packets", "latency_ms": 2647.413969039917, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "control and signaling information", "latency_ms": 1301.3498783111572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "control and signaling information", "latency_ms": 1011.868953704834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1908}, "4": {"k": 4, "answer": "signaling and control", "latency_ms": 763.9377117156982, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "signaling and control", "latency_ms": 928.9555549621582, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "signaling and control", "latency_ms": 1061.819314956665, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3818}}}
{"qid": "1547060614805522730", "question": "what is the rate limiting enzyme of kreb's cycle", "gold_answers": ["Isocitrate dehydrogenase"], "shots": {"0": {"k": 0, "answer": "Isocitrate dehydrogenase", "latency_ms": 1314.4311904907227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "ALA synthase", "latency_ms": 1000.150203704834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "ALA synthase", "latency_ms": 748.8436698913574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1358}, "3": {"k": 3, "answer": "ALA synthase", "latency_ms": 1370.521068572998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2004}, "4": {"k": 4, "answer": "ALA synthase", "latency_ms": 766.2861347198486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2633}, "5": {"k": 5, "answer": "ALA synthase", "latency_ms": 1053.5130500793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3362}, "6": {"k": 6, "answer": "ALA synthase", "latency_ms": 1093.5420989990234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3998}}}
{"qid": "8965198420725510475", "question": "when was the taj mahal built and completed", "gold_answers": ["1632 -- 53"], "shots": {"0": {"k": 0, "answer": "1653", "latency_ms": 780.5826663970947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1643, 1653", "latency_ms": 2137.8731727600098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "1632-1653", "latency_ms": 1902.674913406372, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "1632-1653", "latency_ms": 1080.984115600586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "1632-1653", "latency_ms": 889.9526596069336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2502}, "5": {"k": 5, "answer": "1632-1653", "latency_ms": 1489.9561405181885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3162}, "6": {"k": 6, "answer": "1632-1653", "latency_ms": 1268.585443496704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "-6292760252056275316", "question": "which supreme court judge has surved in international court of justice", "gold_answers": ["Dalveer Bhandari"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 788.3610725402832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Raghunandan Swarup Pathak", "latency_ms": 1941.7634010314941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Raghunandan Swarup Pathak, Dalveer Bhandari", "latency_ms": 2340.0168418884277, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Raghunandan Swarup Pathak, Dalveer Bhandari", "latency_ms": 2815.913677215576, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1951}, "4": {"k": 4, "answer": "Raghunandan Swarup Pathak", "latency_ms": 2434.5862865448, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "Raghunandan Swarup Pathak, Dalveer Bhandari", "latency_ms": 2571.192979812622, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3195}, "6": {"k": 6, "answer": "R S Pathak, Dalveer Bhandari", "latency_ms": 1993.929147720337, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3800}}}
{"qid": "8361850218460994084", "question": "who is known as father of green revolution in india", "gold_answers": ["Mankombu Sambasivan Swaminathan"], "shots": {"0": {"k": 0, "answer": "M.S. Swaminathan", "latency_ms": 1569.4694519042969, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Prof. M.S. Swaminathan", "latency_ms": 1418.1206226348877, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 719}, "2": {"k": 2, "answer": "M.S. Swaminathan", "latency_ms": 1596.7555046081543, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1382}, "3": {"k": 3, "answer": "M.S. Swaminathan", "latency_ms": 1592.0288562774658, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2049}, "4": {"k": 4, "answer": "M.S. Swaminathan", "latency_ms": 930.6075572967529, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2738}, "5": {"k": 5, "answer": "M.S. Swaminathan", "latency_ms": 1125.4467964172363, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3422}, "6": {"k": 6, "answer": "M.S. Swaminathan", "latency_ms": 895.3688144683838, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4080}}}
{"qid": "-5690645328022945594", "question": "who sing say you won't let go", "gold_answers": ["James Arthur"], "shots": {"0": {"k": 0, "answer": "James Arthur", "latency_ms": 753.7651062011719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Arthur", "latency_ms": 894.9308395385742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "James Arthur", "latency_ms": 415.6026840209961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1176}, "3": {"k": 3, "answer": "James Arthur", "latency_ms": 935.128927230835, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1723}, "4": {"k": 4, "answer": "James Arthur", "latency_ms": 1175.2796173095703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2329}, "5": {"k": 5, "answer": "James Arthur", "latency_ms": 883.8515281677246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2899}, "6": {"k": 6, "answer": "James Arthur", "latency_ms": 432.7065944671631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3505}}}
{"qid": "-4292736993227486718", "question": "who monitor the recovery of the location during a disaster", "gold_answers": ["management team"], "shots": {"0": {"k": 0, "answer": "Incident Commander", "latency_ms": 945.6229209899902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Emergency Responders", "latency_ms": 726.4776229858398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 804}, "2": {"k": 2, "answer": "The management team", "latency_ms": 942.0480728149414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1560}, "3": {"k": 3, "answer": "The management team", "latency_ms": 957.8149318695068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2208}, "4": {"k": 4, "answer": "The management team", "latency_ms": 965.6410217285156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2938}, "5": {"k": 5, "answer": "The management team", "latency_ms": 1009.4423294067383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3675}, "6": {"k": 6, "answer": "The management team", "latency_ms": 1054.4040203094482, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4324}}}
{"qid": "-4741747756019727470", "question": "where does the synthesis of new dna from existing dna occurs", "gold_answers": ["origins of replication"], "shots": {"0": {"k": 0, "answer": "Replication fork", "latency_ms": 815.5298233032227, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "In the cell", "latency_ms": 530.7919979095459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "the nucleus", "latency_ms": 671.318769454956, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "in the nucleus", "latency_ms": 1076.7207145690918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "In the nucleus", "latency_ms": 980.0291061401367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2637}, "5": {"k": 5, "answer": "in the nucleus", "latency_ms": 1270.9388732910156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3330}, "6": {"k": 6, "answer": "in the nucleus", "latency_ms": 686.915397644043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3992}}}
{"qid": "4268853195499399258", "question": "who sings gimme shelter with mick jagger", "gold_answers": ["Merry Clayton"], "shots": {"0": {"k": 0, "answer": "Merry Clayton", "latency_ms": 717.2107696533203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Merry Clayton", "latency_ms": 739.8421764373779, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Merry Clayton", "latency_ms": 1257.7803134918213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Merry Clayton", "latency_ms": 613.0526065826416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1844}, "4": {"k": 4, "answer": "Merry Clayton", "latency_ms": 726.6049385070801, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2520}, "5": {"k": 5, "answer": "Merry Clayton", "latency_ms": 1138.2570266723633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3200}, "6": {"k": 6, "answer": "Merry Clayton", "latency_ms": 981.1794757843018, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3861}}}
{"qid": "7172420463912356173", "question": "who does tony end up with on skins", "gold_answers": ["Michelle"], "shots": {"0": {"k": 0, "answer": "Michelle Richardson", "latency_ms": 1164.557695388794, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michelle Richardson", "latency_ms": 933.1250190734863, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 808.635950088501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Michelle", "latency_ms": 772.3567485809326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Michelle", "latency_ms": 378.2367706298828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2444}, "5": {"k": 5, "answer": "Michelle", "latency_ms": 813.9126300811768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3046}, "6": {"k": 6, "answer": "Michelle", "latency_ms": 344.71583366394043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3631}}}
{"qid": "-1400292288904470066", "question": "who sings sugar sugar you are my candy girl", "gold_answers": ["the Archies"], "shots": {"0": {"k": 0, "answer": "The Archies", "latency_ms": 1031.127691268921, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1044.6069240570068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1011.5337371826172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1159.498691558838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1066.5993690490723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2501}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 867.5756454467773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3132}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1215.7540321350098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-1696720698220253139", "question": "who does tyler end up with in you get me", "gold_answers": ["Ali"], "shots": {"0": {"k": 0, "answer": "Holly.\nor \nAlison.", "latency_ms": 1762.5644207000732, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Holly", "latency_ms": 641.4711475372314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1510.0901126861572, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "Ali", "latency_ms": 820.9106922149658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1761}, "4": {"k": 4, "answer": "Ali", "latency_ms": 344.47455406188965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2363}, "5": {"k": 5, "answer": "Ali", "latency_ms": 620.1748847961426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2959}, "6": {"k": 6, "answer": "Ali", "latency_ms": 586.3330364227295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3584}}}
{"qid": "-6797239474199900801", "question": "who won the gold for the men's figure skating", "gold_answers": ["Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 990.0710582733154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Evgeni Plushenko", "latency_ms": 1667.9761409759521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 736}, "2": {"k": 2, "answer": "Evgeni Plushenko", "latency_ms": 1596.2977409362793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1349}, "3": {"k": 3, "answer": "Dick Button", "latency_ms": 1074.4614601135254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Evan Lysacek", "latency_ms": 1390.631914138794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2652}, "5": {"k": 5, "answer": "Evan Lysacek", "latency_ms": 1434.6656799316406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3318}, "6": {"k": 6, "answer": "Alexei Urmanov", "latency_ms": 1262.4034881591797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3964}}}
{"qid": "-7819569157752445011", "question": "when did the song holiday road come out", "gold_answers": ["1983", "June 24 , 1983"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 574.9015808105469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1983", "latency_ms": 1152.0895957946777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "1983", "latency_ms": 1216.8025970458984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "1983", "latency_ms": 1181.8976402282715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1907}, "4": {"k": 4, "answer": "1983", "latency_ms": 406.51559829711914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "1983", "latency_ms": 911.9572639465332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3169}, "6": {"k": 6, "answer": "1983", "latency_ms": 1094.62308883667, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3792}}}
{"qid": "-8839043176903626071", "question": "when does the mlb season start and finish", "gold_answers": ["October 31 , 2018", "March 29"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1264.033555984497, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 20 - September 29", "latency_ms": 942.7697658538818, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "March 20 to September 29", "latency_ms": 1803.924560546875, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "March 20 to September 29", "latency_ms": 1340.226411819458, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "March 20 to September 29", "latency_ms": 1595.3028202056885, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2459}, "5": {"k": 5, "answer": "March 20 to September 29", "latency_ms": 1356.0419082641602, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3100}, "6": {"k": 6, "answer": "March 20 to September 29", "latency_ms": 1850.6853580474854, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3751}}}
{"qid": "6356531089429364942", "question": "when did scotland beat england in six nations", "gold_answers": ["8 March 2008", "25 February 2006", "24 February 2018", "2 April 2000"], "shots": {"0": {"k": 0, "answer": "8 February 2020", "latency_ms": 608.3195209503174, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1999", "latency_ms": 1129.9986839294434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "1999", "latency_ms": 827.1341323852539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "1999", "latency_ms": 902.2970199584961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1963}, "4": {"k": 4, "answer": "1999", "latency_ms": 690.0877952575684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2651}, "5": {"k": 5, "answer": "1999", "latency_ms": 879.9495697021484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3267}, "6": {"k": 6, "answer": "1999", "latency_ms": 425.2738952636719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3911}}}
{"qid": "-3382335563294993978", "question": "when did the rational dress society begin to work", "gold_answers": ["1881"], "shots": {"0": {"k": 0, "answer": "1881", "latency_ms": 960.0551128387451, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1881", "latency_ms": 866.4083480834961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "1881", "latency_ms": 1018.7737941741943, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "1881", "latency_ms": 446.1963176727295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1939}, "4": {"k": 4, "answer": "1881", "latency_ms": 862.1571063995361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2589}, "5": {"k": 5, "answer": "1881", "latency_ms": 1145.2128887176514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3243}, "6": {"k": 6, "answer": "1881", "latency_ms": 416.6567325592041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3870}}}
{"qid": "-5630827734073464379", "question": "why is the indian ocean the warmest in the world", "gold_answers": ["human induced greenhouse warming"], "shots": {"0": {"k": 0, "answer": "High salt content and low evaporation.", "latency_ms": 1412.8310680389404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "human induced greenhouse warming", "latency_ms": 958.8797092437744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "Long-term ocean temperature records show a rapid, continuous warming", "latency_ms": 1744.6212768554688, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Long-term ocean temperature records show rapid warming", "latency_ms": 1356.1427593231201, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Long-term ocean temperature records show a rapid, continuous warming", "latency_ms": 2107.1505546569824, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 2651}, "5": {"k": 5, "answer": "Long-term ocean temperature records show a rapid, continuous warming", "latency_ms": 1377.8369426727295, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 3358}, "6": {"k": 6, "answer": "Human induced greenhouse warming", "latency_ms": 924.3674278259277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4057}}}
{"qid": "-3544151584263258729", "question": "where was the film manchester by the sea filmed", "gold_answers": ["Middleton", "Essex", "Gloucester", "Beverly", "Swampscott", "Lynn", "Manchester", "Salem", "Tewksbury"], "shots": {"0": {"k": 0, "answer": "Gloucester, Massachusetts", "latency_ms": 1071.833848953247, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Massachusetts, Beverly, Essex, Gloucester, Swampscott, Lynn", "latency_ms": 3050.9657859802246, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 635}, "2": {"k": 2, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 4195.752143859863, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 1334}, "3": {"k": 3, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 4431.750774383545, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 1999}, "4": {"k": 4, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 4060.2102279663086, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 2671}, "5": {"k": 5, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 4256.649494171143, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 3317}, "6": {"k": 6, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 4234.781265258789, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 3945}}}
{"qid": "-5077733789764986167", "question": "consist of the sum of the fixed and variable costs for any given level of production", "gold_answers": ["total cost ( TC )"], "shots": {"0": {"k": 0, "answer": "Total Costs", "latency_ms": 457.5026035308838, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Total cost", "latency_ms": 866.9238090515137, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Total cost", "latency_ms": 644.4199085235596, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Total cost", "latency_ms": 480.97848892211914, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1866}, "4": {"k": 4, "answer": "Total cost", "latency_ms": 1141.9556140899658, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2562}, "5": {"k": 5, "answer": "Total cost", "latency_ms": 914.4899845123291, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3166}, "6": {"k": 6, "answer": "Total cost", "latency_ms": 1055.034875869751, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3771}}}
{"qid": "4892187805447493570", "question": "where was thomas and the magic railroad filmed", "gold_answers": ["Toronto , Ontario , Canada", "Isle of Man", "the Isle of Man"], "shots": {"0": {"k": 0, "answer": "Strasburg Rail Road", "latency_ms": 392.9710388183594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shepperton Studios", "latency_ms": 1204.577922821045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "Toronto and Shepperton Studios", "latency_ms": 1566.2665367126465, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1307}, "3": {"k": 3, "answer": "Strasburg Rail Road, Toronto, Isle of Man", "latency_ms": 1848.3350276947021, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1950}, "4": {"k": 4, "answer": "Shepperton Studios, Toronto, Strasburg Rail Road, Isle of Man", "latency_ms": 1972.8713035583496, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2557}, "5": {"k": 5, "answer": "Strasburg, Pennsylvania, Toronto, Ontario, and the Isle of Man.", "latency_ms": 3234.9658012390137, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "Strasburg, Pennsylvania, Toronto, Ontario, and the Isle of Man.", "latency_ms": 3049.3016242980957, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3849}}}
{"qid": "-7094533216301278566", "question": "who has access to the presidential daily briefing", "gold_answers": ["Secretaries of State", "the President", "Defense", "National Security Advisor"], "shots": {"0": {"k": 0, "answer": "The President and senior officials.", "latency_ms": 460.91604232788086, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President and top-level US officials", "latency_ms": 1635.3061199188232, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "The President of the United States and top-level US officials approved by the President.", "latency_ms": 2791.8519973754883, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 1334}, "3": {"k": 3, "answer": "The President and top-level US officials approved by the President", "latency_ms": 2440.430164337158, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1990}, "4": {"k": 4, "answer": "The President and a small number of top-level US officials", "latency_ms": 1953.4311294555664, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2712}, "5": {"k": 5, "answer": "The President and a small number of top-level US officials", "latency_ms": 2769.5980072021484, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3439}, "6": {"k": 6, "answer": "The President and a small number of top-level US officials", "latency_ms": 2508.3978176116943, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4152}}}
{"qid": "-243139310037543674", "question": "what tool is available from microsoft as an alternative to the usmt for smaller migrations", "gold_answers": ["Windows Easy Transfer"], "shots": {"0": {"k": 0, "answer": "Easy Transfer", "latency_ms": 295.1672077178955, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Files", "latency_ms": 1108.1807613372803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Windows Easy Transfer", "latency_ms": 773.0660438537598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Windows Easy Transfer", "latency_ms": 1203.4287452697754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2036}, "4": {"k": 4, "answer": "Windows Easy Transfer", "latency_ms": 976.8476486206055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2675}, "5": {"k": 5, "answer": "Windows Easy Transfer", "latency_ms": 941.5795803070068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3330}, "6": {"k": 6, "answer": "Windows Easy Transfer", "latency_ms": 1253.6756992340088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3989}}}
{"qid": "7079282152145474767", "question": "who appoints the chief election commissioner of india", "gold_answers": ["the president", "President of India"], "shots": {"0": {"k": 0, "answer": "The President of India", "latency_ms": 803.0803203582764, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1086.1196517944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "The President", "latency_ms": 642.3938274383545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "The President", "latency_ms": 648.8902568817139, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2036}, "4": {"k": 4, "answer": "The President", "latency_ms": 695.655107498169, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2697}, "5": {"k": 5, "answer": "The President", "latency_ms": 1158.0135822296143, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3369}, "6": {"k": 6, "answer": "The President", "latency_ms": 1169.4679260253906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4062}}}
{"qid": "6303430169473424975", "question": "glycogen and amylopectin are long chains of which simple sugar(s)", "gold_answers": ["glucose"], "shots": {"0": {"k": 0, "answer": "Glucose", "latency_ms": 554.375410079956, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "glucose", "latency_ms": 963.2368087768555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 720}, "2": {"k": 2, "answer": "glucose", "latency_ms": 395.57456970214844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1375}, "3": {"k": 3, "answer": "glucose", "latency_ms": 771.7292308807373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2079}, "4": {"k": 4, "answer": "glucose", "latency_ms": 1044.2323684692383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2705}, "5": {"k": 5, "answer": "glucose", "latency_ms": 908.5016250610352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3319}, "6": {"k": 6, "answer": "Glucose", "latency_ms": 687.3970031738281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4011}}}
{"qid": "-3240666523350424161", "question": "who was the editor of the journal jugantor published in the time of swadeshi movement", "gold_answers": ["Bhupendranath Dutt"], "shots": {"0": {"k": 0, "answer": "Barindra Kumar Ghosh", "latency_ms": 695.7085132598877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1009.9601745605469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "Abhinash Bhattacharya, Barindra, Bhupendranath Dutt and Debabrata Basu.", "latency_ms": 4058.85910987854, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1334}, "3": {"k": 3, "answer": "Abhinash Bhattacharya, Barindra, Bhupendranath Dutt and Debabrata Basu.", "latency_ms": 3244.974136352539, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1994}, "4": {"k": 4, "answer": "Abhinash Bhattacharya, Barindra, Bhupendranath Dutt and Debabrata Basu.", "latency_ms": 3292.539358139038, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2603}, "5": {"k": 5, "answer": "Abhinash Bhattacharya, Barindra, Bhupendranath Dutt and Debabrata Basu.", "latency_ms": 3662.484884262085, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3289}, "6": {"k": 6, "answer": "Abhinash Bhattacharya, Barindra, Bhupendranath Dutt and Debabrata Basu.", "latency_ms": 3120.0807094573975, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3888}}}
{"qid": "1321443496772706078", "question": "when did indoor toilets become common in america", "gold_answers": ["After World War I"], "shots": {"0": {"k": 0, "answer": "Late 19th century", "latency_ms": 1490.164041519165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1890s", "latency_ms": 772.5174427032471, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "1890s", "latency_ms": 898.8869190216064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "1890s", "latency_ms": 1148.9784717559814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "1890s", "latency_ms": 968.4360027313232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2533}, "5": {"k": 5, "answer": "1890s", "latency_ms": 713.2115364074707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3135}, "6": {"k": 6, "answer": "1890s", "latency_ms": 965.4648303985596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "6019244948248861067", "question": "who wrote were going on a bear hunt", "gold_answers": ["Michael Rosen"], "shots": {"0": {"k": 0, "answer": "Michael Rosen", "latency_ms": 749.4471073150635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Rosen", "latency_ms": 1106.564998626709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "Michael Rosen", "latency_ms": 441.06101989746094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Michael Rosen", "latency_ms": 934.5462322235107, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Michael Rosen", "latency_ms": 841.7689800262451, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Michael Rosen", "latency_ms": 932.650089263916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3096}, "6": {"k": 6, "answer": "Michael Rosen", "latency_ms": 521.7926502227783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3761}}}
{"qid": "8753987902863757141", "question": "what is the revolution period of venus in earth years", "gold_answers": ["0.615 198 yr", "224.7 Earth days"], "shots": {"0": {"k": 0, "answer": "0.61519726", "latency_ms": 872.15256690979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0.616", "latency_ms": 1228.2679080963135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "0.615", "latency_ms": 1163.728952407837, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "0.615", "latency_ms": 996.6886043548584, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "0.615", "latency_ms": 1032.393217086792, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2494}, "5": {"k": 5, "answer": "0.615 Earth years", "latency_ms": 1201.4667987823486, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3110}, "6": {"k": 6, "answer": "0.615 Earth years", "latency_ms": 1159.89089012146, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3736}}}
{"qid": "-5904934687784134086", "question": "who has the power to approve or veto legislation constitution", "gold_answers": ["the President"], "shots": {"0": {"k": 0, "answer": "The President", "latency_ms": 769.6540355682373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The president", "latency_ms": 504.06599044799805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "President", "latency_ms": 968.4984683990479, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "President", "latency_ms": 590.8701419830322, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "The President", "latency_ms": 618.6704635620117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2549}, "5": {"k": 5, "answer": "The President", "latency_ms": 1111.0353469848633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3218}, "6": {"k": 6, "answer": "The President", "latency_ms": 898.9715576171875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3848}}}
{"qid": "-1910743846708408775", "question": "when was the taming ofthe shrew first performed", "gold_answers": ["prior to June 1592"], "shots": {"0": {"k": 0, "answer": "1593-1594", "latency_ms": 1077.8331756591797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1887", "latency_ms": 949.526309967041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "1768", "latency_ms": 467.35644340515137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1330}, "3": {"k": 3, "answer": "1768", "latency_ms": 962.6328945159912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "1768", "latency_ms": 416.9421195983887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2613}, "5": {"k": 5, "answer": "1768", "latency_ms": 715.012788772583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3237}, "6": {"k": 6, "answer": "11 June 1594", "latency_ms": 1234.034776687622, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3928}}}
{"qid": "6521877788261380307", "question": "who is the first prime minister of france", "gold_answers": ["Michel Debr"], "shots": {"0": {"k": 0, "answer": "Adolphe Thiers", "latency_ms": 1036.677598953247, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michel Debr", "latency_ms": 1054.2683601379395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Michel Debr", "latency_ms": 1136.6603374481201, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1352}, "3": {"k": 3, "answer": "Michel Debr", "latency_ms": 1032.8443050384521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2013}, "4": {"k": 4, "answer": "Michel Debr", "latency_ms": 1039.6618843078613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2717}, "5": {"k": 5, "answer": "Michel Debr", "latency_ms": 800.6076812744141, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3373}, "6": {"k": 6, "answer": "Michel Debr", "latency_ms": 1475.2018451690674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4004}}}
{"qid": "-3375621376413612480", "question": "list of strict nature reserve in the philippines", "gold_answers": ["Lake Malimanga", "Palawan", "Calavite and FB Harrison", "Olango Island", "Calauit Safari Park", "Lake Buluan"], "shots": {"0": {"k": 0, "answer": "Verde Island Passage, Mayon Volcano, El Nido Managed Resource Protected Area", "latency_ms": 2102.7369499206543, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Masungi Rock", "latency_ms": 1223.4764099121094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "Masungi Georeserve", "latency_ms": 1613.560438156128, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "Masungi Georeserve", "latency_ms": 1111.0985279083252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "Masungi Georeserve", "latency_ms": 913.698673248291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2776}, "5": {"k": 5, "answer": "Masungi Georeserve", "latency_ms": 1283.4243774414062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3429}, "6": {"k": 6, "answer": "Masungi Georeserve", "latency_ms": 1334.9754810333252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4147}}}
{"qid": "-7848107192827858958", "question": "where do the events in the story take place geographically", "gold_answers": ["Persia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 977.1678447723389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Peloponnese and Ionian Islands", "latency_ms": 1869.352102279663, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "Peloponnese and Ionian Islands", "latency_ms": 1703.8161754608154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Peloponnese and Ionian Islands", "latency_ms": 1377.622127532959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "Peloponnese, Ionian Islands, Middle-earth, Maine woods, Storybrooke", "latency_ms": 2905.78556060791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2586}, "5": {"k": 5, "answer": "Peloponnese and Ionian Islands", "latency_ms": 1894.6402072906494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3220}, "6": {"k": 6, "answer": "England and Transylvania", "latency_ms": 1043.639898300171, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3870}}}
{"qid": "-5123704261908217758", "question": "how and why were serial novels a phenomenon in the nineteenth century", "gold_answers": ["improved economics of distribution", "the rise of literacy", "technological advances in printing"], "shots": {"0": {"k": 0, "answer": "Cheap printing technology", "latency_ms": 969.2788124084473, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 760.2834701538086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "in periodicals and newspapers.", "latency_ms": 1585.4942798614502, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "in periodicals and newspapers.", "latency_ms": 1713.681697845459, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "published in periodicals and newspapers in serial form", "latency_ms": 1709.887981414795, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 2740}, "5": {"k": 5, "answer": "published in newspapers and periodicals", "latency_ms": 891.4628028869629, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 3375}, "6": {"k": 6, "answer": "published in periodicals and newspapers in serial form", "latency_ms": 1943.3088302612305, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 4046}}}
{"qid": "8893432128322519771", "question": "who eliminated costa rica in world cup 2014", "gold_answers": ["Netherlands"], "shots": {"0": {"k": 0, "answer": "Netherlands", "latency_ms": 1014.5962238311768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1022.2651958465576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "Netherlands", "latency_ms": 836.3139629364014, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Netherlands", "latency_ms": 717.7910804748535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Netherlands", "latency_ms": 490.8299446105957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2498}, "5": {"k": 5, "answer": "Netherlands", "latency_ms": 875.9820461273193, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Netherlands", "latency_ms": 962.6588821411133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3742}}}
{"qid": "-1356405650810931451", "question": "how many countries touches the land boundary of india", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "6", "latency_ms": 172.31154441833496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "6", "latency_ms": 821.8073844909668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "6", "latency_ms": 448.3335018157959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "6", "latency_ms": 1161.4990234375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1990}, "4": {"k": 4, "answer": "6", "latency_ms": 681.0500621795654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2685}, "5": {"k": 5, "answer": "6", "latency_ms": 901.0083675384521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3444}, "6": {"k": 6, "answer": "6", "latency_ms": 410.21084785461426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4188}}}
{"qid": "6447777231012695504", "question": "who was the 11th prime minister of canada", "gold_answers": ["R.B. Bennett", "Arthur Meighen"], "shots": {"0": {"k": 0, "answer": "William Lyon Mackenzie King", "latency_ms": 867.8884506225586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sir Wilfrid Laurier", "latency_ms": 902.9622077941895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "Sir Wilfrid Laurier", "latency_ms": 1037.9142761230469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1339}, "3": {"k": 3, "answer": "R. B. Bennett", "latency_ms": 1021.461009979248, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1980}, "4": {"k": 4, "answer": "R. B. Bennett", "latency_ms": 1533.1499576568604, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2668}, "5": {"k": 5, "answer": "R. B. Bennett", "latency_ms": 853.7352085113525, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3310}, "6": {"k": 6, "answer": "R. B. Bennett", "latency_ms": 1028.9440155029297, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3924}}}
{"qid": "-5935683210985272192", "question": "when did the steel mills closed in youngstown ohio", "gold_answers": ["September 19 , 1977"], "shots": {"0": {"k": 0, "answer": "1977", "latency_ms": 702.9204368591309, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1979", "latency_ms": 712.4290466308594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "Black Monday", "latency_ms": 686.5994930267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1374}, "3": {"k": 3, "answer": "1977", "latency_ms": 426.51867866516113, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "Late 1970s and early 1980s.", "latency_ms": 1368.3719635009766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2742}, "5": {"k": 5, "answer": "Late 1970s and early 1980s.", "latency_ms": 1871.5956211090088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3416}, "6": {"k": 6, "answer": "Late 1970s and early 1980s.", "latency_ms": 1952.6982307434082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4093}}}
{"qid": "1834961239491311230", "question": "who owns and operates the panama canal today", "gold_answers": ["Panama Canal Authority", "Panama", "Panamanian government"], "shots": {"0": {"k": 0, "answer": "The Panama Canal Authority", "latency_ms": 597.3737239837646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kansas City Southern and Mi-Jack Products", "latency_ms": 1581.1100006103516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "Panama Canal Authority", "latency_ms": 1482.2702407836914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Panama Canal Authority", "latency_ms": 785.1989269256592, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Panama Canal Authority", "latency_ms": 1032.1922302246094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2565}, "5": {"k": 5, "answer": "Panama Canal Authority", "latency_ms": 1005.059003829956, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Panama Canal Authority", "latency_ms": 936.0823631286621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3880}}}
{"qid": "-535648230475805474", "question": "where is a simple gear train used in real life", "gold_answers": ["Automobile drivetrains"], "shots": {"0": {"k": 0, "answer": "Bicycles", "latency_ms": 487.57171630859375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "automobile manual transmission", "latency_ms": 939.6307468414307, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "Automobile manual transmission", "latency_ms": 980.4675579071045, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Automobile manual transmission", "latency_ms": 930.5169582366943, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1842}, "4": {"k": 4, "answer": "Automobile manual transmission", "latency_ms": 1027.5907516479492, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "Automobile manual transmission", "latency_ms": 817.5463676452637, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3110}, "6": {"k": 6, "answer": "Automobile manual transmission", "latency_ms": 1251.4855861663818, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3702}}}
{"qid": "8911390210346559626", "question": "who plays the dad in malcom in the middle", "gold_answers": ["Bryan Cranston"], "shots": {"0": {"k": 0, "answer": "Bryan Cranston", "latency_ms": 813.4949207305908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1010.303258895874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 572}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 823.4000205993652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 789.6139621734619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1830}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 808.8932037353516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2537}, "5": {"k": 5, "answer": "Bryan Cranston", "latency_ms": 964.2252922058105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3205}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1007.1907043457031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3812}}}
{"qid": "-8336776482564898273", "question": "who has won the most world series in baseball", "gold_answers": ["the New York Yankees", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "New York Yankees", "latency_ms": 298.8111972808838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1027.8279781341553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "Southern California", "latency_ms": 733.508825302124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Yogi Berra", "latency_ms": 1187.795639038086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1843}, "4": {"k": 4, "answer": "Yogi Berra", "latency_ms": 790.5838489532471, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2469}, "5": {"k": 5, "answer": "Yogi Berra", "latency_ms": 804.8970699310303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3102}, "6": {"k": 6, "answer": "New York Yankees", "latency_ms": 749.910831451416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3719}}}
{"qid": "-8742089114148260796", "question": "where are the winter olympic games being played", "gold_answers": ["Beijing"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1078.6969661712646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pyeongchang", "latency_ms": 1279.3378829956055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "Pyeongchang", "latency_ms": 1353.1367778778076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "Beijing, China", "latency_ms": 997.8663921356201, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1880}, "4": {"k": 4, "answer": "Beijing, China", "latency_ms": 1498.4407424926758, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Beijing, China", "latency_ms": 1249.2704391479492, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3168}, "6": {"k": 6, "answer": "Beijing, China", "latency_ms": 1267.5108909606934, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3789}}}
{"qid": "3864930130255054488", "question": "who made the song falling in love with you", "gold_answers": ["Hugo Peretti", "Elvis Presley", "George David Weiss", "Luigi Creatore"], "shots": {"0": {"k": 0, "answer": "UB40", "latency_ms": 722.1047878265381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 2293.3318614959717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 594}, "2": {"k": 2, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 1959.8784446716309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1188}, "3": {"k": 3, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 2504.415273666382, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1796}, "4": {"k": 4, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 2049.299716949463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2404}, "5": {"k": 5, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 1846.369743347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3033}, "6": {"k": 6, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 2515.7861709594727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3636}}}
{"qid": "8076743617384207713", "question": "where did saudi crown prince go to college", "gold_answers": ["King Saud University"], "shots": {"0": {"k": 0, "answer": "King Saud University", "latency_ms": 559.1721534729004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Georgetown University", "latency_ms": 767.1129703521729, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "Georgetown University", "latency_ms": 1176.4137744903564, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1376}, "3": {"k": 3, "answer": "Georgetown University", "latency_ms": 1208.975076675415, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1973}, "4": {"k": 4, "answer": "Georgetown University", "latency_ms": 516.09206199646, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2632}, "5": {"k": 5, "answer": "Georgetown University", "latency_ms": 1123.211145401001, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3272}, "6": {"k": 6, "answer": "Georgetown University", "latency_ms": 1144.5395946502686, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3892}}}
{"qid": "1735766792677422630", "question": "who did the singing in into the woods", "gold_answers": ["the cast", "the cast members"], "shots": {"0": {"k": 0, "answer": "Anna Kendrick", "latency_ms": 684.2963695526123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Meryl Streep, Emily Blunt, James Corden, Anna Kendrick, Chris Pine, Johnny Depp, Daniel Huttlestone, Lilla Crawford, MacKenzie Mauzy, Tracey Ullman, Christine Baranski, Tammy Blanchard, Lucy Punch", "latency_ms": 6959.529161453247, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 711}, "2": {"k": 2, "answer": "Meryl Streep, Emily Blunt, James Corden, Anna Kendrick, Chris Pine, Johnny Depp, Daniel Huttlestone, Lilla Crawford, MacKenzie Mauzy, Tracey Ullman, Christine Baranski, Tammy Blanchard, Lucy Punch", "latency_ms": 8837.5723361969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1405}, "3": {"k": 3, "answer": "Meryl Streep, Emily Blunt, James Corden, Anna Kendrick, Chris Pine, Johnny Depp, Daniel Huttlestone, Lilla Crawford, MacKenzie Mauzy, Tracey Ullman, Christine Baranski, Tammy Blanchard, and Lucy Punch.", "latency_ms": 8668.05100440979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2076}, "4": {"k": 4, "answer": "Meryl Streep, Emily Blunt, James Corden, Anna Kendrick, Chris Pine, Johnny Depp, Daniel Huttlestone, Lilla Crawford, MacKenzie Mauzy, Tracey Ullman, Christine Baranski, Tammy Blanchard, and Lucy Punch.", "latency_ms": 9191.94769859314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2722}, "5": {"k": 5, "answer": "Meryl Streep, Emily Blunt, James Corden, Anna Kendrick, Chris Pine, Johnny Depp, Daniel Huttlestone, Lilla Crawford, MacKenzie Mauzy, Tracey Ullman, Christine Baranski, Tammy Blanchard, and Lucy Punch.", "latency_ms": 9412.985801696777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3402}, "6": {"k": 6, "answer": "Meryl Streep, Emily Blunt, James Corden, Anna Kendrick, Chris Pine, Johnny Depp", "latency_ms": 4134.668588638306, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4048}}}
{"qid": "5711801828691961426", "question": "who was the viceroy when the simon commission visited india", "gold_answers": ["Lord Irwin"], "shots": {"0": {"k": 0, "answer": "Lord Irwin", "latency_ms": 651.2525081634521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lord Irwin", "latency_ms": 949.7363567352295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "Lord Irwin", "latency_ms": 1103.348970413208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Lord Irwin", "latency_ms": 1125.8571147918701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1928}, "4": {"k": 4, "answer": "Lord Irwin", "latency_ms": 734.2531681060791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "Lord Irwin", "latency_ms": 1205.045461654663, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3241}, "6": {"k": 6, "answer": "Lord Irwin", "latency_ms": 1192.4197673797607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3881}}}
{"qid": "9001143341771379731", "question": "who in germany signed the treaty of versailles", "gold_answers": ["colonial minister Johannes Bell", "Foreign minister Hermann Mller", "Gustav Bauer"], "shots": {"0": {"k": 0, "answer": "Ulrich Graf von Brockdorff-Rantzau", "latency_ms": 2227.8223037719727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gustav Bauer", "latency_ms": 1249.6943473815918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 683}, "2": {"k": 2, "answer": "Gustav Bauer", "latency_ms": 1171.217918395996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Gustav Bauer", "latency_ms": 1178.9283752441406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2001}, "4": {"k": 4, "answer": "Gustav Bauer", "latency_ms": 1193.4788227081299, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2690}, "5": {"k": 5, "answer": "Gustav Bauer", "latency_ms": 1243.3454990386963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3367}, "6": {"k": 6, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 1261.674404144287, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 4014}}}
{"qid": "-4619585332904698754", "question": "who holds the record for most platinum albums", "gold_answers": ["The Beatles", "AC / DC", "Elvis Presley"], "shots": {"0": {"k": 0, "answer": "The Beatles", "latency_ms": 495.0387477874756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elvis Presley", "latency_ms": 1153.8946628570557, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Elvis Presley", "latency_ms": 1030.992031097412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Elvis Presley", "latency_ms": 1247.2140789031982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1919}, "4": {"k": 4, "answer": "Elvis Presley", "latency_ms": 1193.089246749878, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2468}, "5": {"k": 5, "answer": "Elvis Presley", "latency_ms": 1211.5650177001953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3092}, "6": {"k": 6, "answer": "Elvis Presley", "latency_ms": 1082.6220512390137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3795}}}
{"qid": "-720512252272678238", "question": "when did the movie the post begin filming", "gold_answers": ["May 30 , 2017", "May 2017"], "shots": {"0": {"k": 0, "answer": "May 30, 2016", "latency_ms": 1375.4301071166992, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "May 2017", "latency_ms": 1042.5691604614258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "May 2017", "latency_ms": 1475.9554862976074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1324}, "3": {"k": 3, "answer": "May 2017", "latency_ms": 1197.7779865264893, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1966}, "4": {"k": 4, "answer": "May 30, 2017", "latency_ms": 2022.6125717163086, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2630}, "5": {"k": 5, "answer": "May 30, 2017", "latency_ms": 1830.79195022583, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3272}, "6": {"k": 6, "answer": "May 30, 2017", "latency_ms": 1674.342393875122, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3961}}}
{"qid": "-3371798557886238687", "question": "who starred in an officer and a gentleman", "gold_answers": ["Louis Gossett Jr .", "David Keith", "Louis Gossett Jr.", "Richard Gere", "Debra Winger", "Phillip J. Salmon"], "shots": {"0": {"k": 0, "answer": "Richard Gere", "latency_ms": 989.0444278717041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 3271.2972164154053, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 2998.588800430298, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 2691.688299179077, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1850}, "4": {"k": 4, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 1985.1889610290527, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2501}, "5": {"k": 5, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 2833.683490753174, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3168}, "6": {"k": 6, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 2822.6699829101562, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3792}}}
