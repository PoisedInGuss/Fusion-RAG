{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 532.7019691467285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1236.5655899047852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "Helen McCrory", "latency_ms": 1266.3533687591553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1323}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1153.4955501556396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Geraldine Somerville", "latency_ms": 770.7948684692383, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Geraldine Somerville", "latency_ms": 1039.7467613220215, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3219}, "6": {"k": 6, "answer": "Ellie Darcey-Alden", "latency_ms": 1482.7690124511719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 759.1969966888428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 646.6028690338135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 1272.6936340332031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 1044.3131923675537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1950}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 1494.947910308838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 1196.9056129455566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 1264.848232269287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3798}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwest desert regions", "latency_ms": 1067.549467086792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 1972.9266166687012, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "arid lowland or mountainous shrubland", "latency_ms": 2241.9025897979736, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 1881.8888664245605, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 2214.761734008789, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2622}, "5": {"k": 5, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 2498.521566390991, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3248}, "6": {"k": 6, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 1661.2772941589355, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3854}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 1346.1346626281738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rajendra Prasad", "latency_ms": 1653.3558368682861, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Rajendra Prasad", "latency_ms": 993.6597347259521, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 2177.565574645996, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2083}, "4": {"k": 4, "answer": "Rajendra Prasad", "latency_ms": 1041.56494140625, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2757}, "5": {"k": 5, "answer": "Rajendra Prasad", "latency_ms": 1442.692518234253, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3383}, "6": {"k": 6, "answer": "Rajendra Prasad", "latency_ms": 1520.453691482544, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4045}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 529.5791625976562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 6, 2011", "latency_ms": 1853.3921241760254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 689}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1005.7821273803711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1347}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1036.3554954528809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1942}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1068.9804553985596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1273.6084461212158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3240}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1232.801914215088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3895}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "June 22, 2001", "latency_ms": 1206.1102390289307, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1279.320478439331, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1037.0981693267822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "June 22, 2001", "latency_ms": 906.3577651977539, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1935}, "4": {"k": 4, "answer": "June 22, 2001", "latency_ms": 1456.0232162475586, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2565}, "5": {"k": 5, "answer": "June 22, 2001", "latency_ms": 1570.3608989715576, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3152}, "6": {"k": 6, "answer": "June 22, 2001", "latency_ms": 1414.2577648162842, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3769}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 591.0420417785645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 1820.1584815979004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 1454.7162055969238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 1847.9573726654053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 1174.9320030212402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2739}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 1761.0886096954346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3435}, "6": {"k": 6, "answer": "September 27, 2017", "latency_ms": 1395.3757286071777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4141}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3", "latency_ms": 742.7246570587158, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sectionals", "latency_ms": 458.0838680267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Sectionals", "latency_ms": 632.4663162231445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Sectionals", "latency_ms": 1173.3355522155762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Sectionals", "latency_ms": 935.7082843780518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2469}, "5": {"k": 5, "answer": "Sectionals", "latency_ms": 850.4259586334229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "In \"Sectionals\"", "latency_ms": 1070.133924484253, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3705}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 981.4620018005371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 983.5889339447021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1008.4867477416992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1013.911247253418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1288.7322902679443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1498.079776763916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1255.7218074798584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3828}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 1461.2083435058594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "the harbor", "latency_ms": 899.1866111755371, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Havana Harbor, Cuba", "latency_ms": 630.8577060699463, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Havana Harbor, Cuba", "latency_ms": 1505.0287246704102, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Havana Harbor, Cuba", "latency_ms": 1283.4410667419434, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2573}, "5": {"k": 5, "answer": "Havana Harbor, Cuba", "latency_ms": 1692.5606727600098, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3200}, "6": {"k": 6, "answer": "Havana Harbor, Cuba", "latency_ms": 1569.282054901123, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3877}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 1025.0589847564697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1129.1825771331787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1250.5595684051514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Lord Vishnu", "latency_ms": 995.6088066101074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Lord Vasupujya", "latency_ms": 1353.3196449279785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2600}, "5": {"k": 5, "answer": "Lord Vishnu", "latency_ms": 980.7319641113281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3168}, "6": {"k": 6, "answer": "Lord Vishnu", "latency_ms": 922.0833778381348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3811}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 1872.666597366333, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "All of them", "latency_ms": 731.013298034668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Costa Rica, Nicaragua, Panama, Honduras, Guatemala, El Salvador, Belize", "latency_ms": 3011.244297027588, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1322}, "3": {"k": 3, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 1451.3053894042969, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2021}, "4": {"k": 4, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 1155.1322937011719, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2696}, "5": {"k": 5, "answer": "Costa Rica, Nicaragua, Panama, Guatemala, Honduras, El Salvador, Belize", "latency_ms": 3020.808696746826, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3355}, "6": {"k": 6, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 1203.2806873321533, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3983}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence.", "latency_ms": 839.1962051391602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 850.4419326782227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Complex sentence", "latency_ms": 846.3666439056396, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Complex sentence", "latency_ms": 663.5897159576416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2006}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 1115.6322956085205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 664.618730545044, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3361}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 709.0559005737305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4087}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and trade.", "latency_ms": 1530.8473110198975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 1019.0811157226562, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "the Nature and Causes of the Wealth of Nations", "latency_ms": 2123.2776641845703, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "the Nature and Causes of the Wealth of Nations", "latency_ms": 2255.382776260376, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "the Nature and Causes of the Wealth of Nations", "latency_ms": 2252.166748046875, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "the nature and causes of the wealth of nations", "latency_ms": 1797.9943752288818, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "the nature and causes of the wealth of nations", "latency_ms": 1847.8436470031738, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3738}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 1102.0021438598633, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "August 28, 2018", "latency_ms": 1771.7113494873047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "August 28, 2018", "latency_ms": 1420.0849533081055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 1436.715841293335, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1868}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 1331.1996459960938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 1749.5534420013428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3172}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 1412.0829105377197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3841}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere", "latency_ms": 905.6434631347656, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 2371.441602706909, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 1697.9444026947021, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1341}, "3": {"k": 3, "answer": "Oceania", "latency_ms": 762.7813816070557, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2010}, "4": {"k": 4, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 2884.483814239502, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2698}, "5": {"k": 5, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 2448.0502605438232, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3338}, "6": {"k": 6, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 2459.7442150115967, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4067}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Leia Organa", "latency_ms": 776.4029502868652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1208.8487148284912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1194.5393085479736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Mara Jade", "latency_ms": 998.5921382904053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1813}, "4": {"k": 4, "answer": "a woman at Luke's Jedi Academy", "latency_ms": 1685.5943202972412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2349}, "5": {"k": 5, "answer": "her", "latency_ms": 542.7830219268799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2920}, "6": {"k": 6, "answer": "Mara Jade", "latency_ms": 706.3016891479492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3554}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 684.5777034759521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack Barry", "latency_ms": 782.8516960144043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Jack Barry", "latency_ms": 1139.423131942749, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1196}, "3": {"k": 3, "answer": "Allen Ludden", "latency_ms": 883.4567070007324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Jack Barry", "latency_ms": 961.1093997955322, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2405}, "5": {"k": 5, "answer": "Allen Ludden", "latency_ms": 1371.9511032104492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2988}, "6": {"k": 6, "answer": "Barry Cryer", "latency_ms": 956.7914009094238, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3583}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 717.9160118103027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mitochondria", "latency_ms": 1165.18235206604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "Mitochondria", "latency_ms": 743.5142993927002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1365}, "3": {"k": 3, "answer": "Mitochondria", "latency_ms": 971.84157371521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2024}, "4": {"k": 4, "answer": "Mitochondria, Chloroplasts", "latency_ms": 1889.6818161010742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2672}, "5": {"k": 5, "answer": "Mitochondria, Chloroplasts", "latency_ms": 1388.1664276123047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3329}, "6": {"k": 6, "answer": "Mitochondria, Chloroplasts", "latency_ms": 1505.7766437530518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4028}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Backup.", "latency_ms": 1702.6426792144775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1439.8479461669922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 693}, "2": {"k": 2, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 1648.1411457061768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1402}, "3": {"k": 3, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 2277.621030807495, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2089}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1206.6900730133057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2782}, "5": {"k": 5, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 1839.306354522705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3506}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 738.2893562316895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4159}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 1203.1872272491455, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 968.6276912689209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 567}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1001.9221305847168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1136}, "3": {"k": 3, "answer": "Dottie West and Kenny Rogers", "latency_ms": 917.539119720459, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1721}, "4": {"k": 4, "answer": "Dottie West and Kenny Rogers", "latency_ms": 1652.6150703430176, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2308}, "5": {"k": 5, "answer": "Dottie West and Kenny Rogers", "latency_ms": 1764.8093700408936, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2904}, "6": {"k": 6, "answer": "Dottie West and Kenny Rogers", "latency_ms": 1646.841049194336, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3499}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 755.6807994842529, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Three years old", "latency_ms": 650.1402854919434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 689}, "2": {"k": 2, "answer": "36 months old", "latency_ms": 1166.1937236785889, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "36 months old", "latency_ms": 1223.9656448364258, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1927}, "4": {"k": 4, "answer": "36 months old", "latency_ms": 1230.5729389190674, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2546}, "5": {"k": 5, "answer": "36 months old", "latency_ms": 1152.8661251068115, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3151}, "6": {"k": 6, "answer": "36 months old", "latency_ms": 1422.2400188446045, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3851}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 180.74703216552734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 987.2028827667236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "3", "latency_ms": 655.9500694274902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "3", "latency_ms": 608.9751720428467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "3", "latency_ms": 837.1903896331787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Three", "latency_ms": 571.519136428833, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3190}, "6": {"k": 6, "answer": "3", "latency_ms": 894.1841125488281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3842}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 2884.662866592407, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 980.053186416626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "Billy Boyd", "latency_ms": 708.1236839294434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Billy Boyd", "latency_ms": 887.3398303985596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1843}, "4": {"k": 4, "answer": "Billy Boyd", "latency_ms": 892.3304080963135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Billy Boyd", "latency_ms": 938.6396408081055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Elijah Wood, Billy Boyd, Dominic Guard, Simon Chandler, Michael Scholes", "latency_ms": 3202.6216983795166, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3783}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party", "latency_ms": 748.9676475524902, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume party", "latency_ms": 931.2622547149658, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Costume party", "latency_ms": 926.537036895752, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1198}, "3": {"k": 3, "answer": "Costume", "latency_ms": 1105.611801147461, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Costume", "latency_ms": 888.939380645752, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2432}, "5": {"k": 5, "answer": "Costume", "latency_ms": 471.90260887145996, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3067}, "6": {"k": 6, "answer": "Costume", "latency_ms": 1170.8953380584717, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3683}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 402.1434783935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One", "latency_ms": 581.0694694519043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 598}, "2": {"k": 2, "answer": "One", "latency_ms": 921.3345050811768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1204}, "3": {"k": 3, "answer": "One", "latency_ms": 635.2591514587402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1902}, "4": {"k": 4, "answer": "One", "latency_ms": 451.3700008392334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2590}, "5": {"k": 5, "answer": "1", "latency_ms": 1088.646650314331, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3247}, "6": {"k": 6, "answer": "One", "latency_ms": 584.5777988433838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3872}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "He promised Fantine", "latency_ms": 1194.2322254180908, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1167.1485900878906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1061.5758895874023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1178}, "3": {"k": 3, "answer": "Fantine's note", "latency_ms": 995.175838470459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1805}, "4": {"k": 4, "answer": "Fantine's daughter", "latency_ms": 1741.1108016967773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2389}, "5": {"k": 5, "answer": "Fantine's daughter", "latency_ms": 1337.8443717956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2997}, "6": {"k": 6, "answer": "Fantine's request", "latency_ms": 1292.5028800964355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3610}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, and South Korea.", "latency_ms": 1964.8330211639404, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canada", "latency_ms": 1099.4813442230225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 710}, "2": {"k": 2, "answer": "Canada", "latency_ms": 617.7899837493896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1400}, "3": {"k": 3, "answer": "Canada, China, Belgium, Portugal", "latency_ms": 1688.5359287261963, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2096}, "4": {"k": 4, "answer": "Canada, China, Belgium, Portugal", "latency_ms": 1666.8004989624023, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2743}, "5": {"k": 5, "answer": "Canada, China, Belgium, Portugal", "latency_ms": 1798.5849380493164, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3428}, "6": {"k": 6, "answer": "Canada, China, Europeans, Portuguese, Belgians, British", "latency_ms": 2475.3127098083496, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 4109}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and control.", "latency_ms": 1179.004192352295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 3043.1365966796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 2831.2511444091797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 2951.8258571624756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 3169.403314590454, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 2428.7497997283936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3344}, "6": {"k": 6, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 3041.569471359253, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4022}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 1182.1691989898682, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 875.4901885986328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 987.8017902374268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Huge and powerful snake", "latency_ms": 1770.2155113220215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Python", "latency_ms": 895.552396774292, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Python", "latency_ms": 871.4120388031006, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3099}, "6": {"k": 6, "answer": "Python", "latency_ms": 402.7743339538574, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3724}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 701.3089656829834, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ice", "latency_ms": 401.1533260345459, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Ice", "latency_ms": 603.8117408752441, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "water-ice", "latency_ms": 939.7048950195312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "water-ice", "latency_ms": 997.8525638580322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "water-ice", "latency_ms": 953.6306858062744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "water-ice", "latency_ms": 981.9533824920654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3668}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 1500.9090900421143, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Not in season 2.", "latency_ms": 1183.2046508789062, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1239.5405769348145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1185}, "3": {"k": 3, "answer": "The Departed episode", "latency_ms": 1515.5088901519775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "The Departed episode", "latency_ms": 1402.1410942077637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2425}, "5": {"k": 5, "answer": "Season 3", "latency_ms": 1230.9155464172363, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2989}, "6": {"k": 6, "answer": "Season 3, episode 22, \"The Departed\"", "latency_ms": 2208.658218383789, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3630}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "Home team", "latency_ms": 622.7045059204102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 943.1779384613037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1021.0161209106445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 983.3798408508301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 793.6222553253174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2423}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 982.4056625366211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3027}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1059.7145557403564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3655}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw neighborhood", "latency_ms": 749.0742206573486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington, D.C.", "latency_ms": 1042.4730777740479, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 691}, "2": {"k": 2, "answer": "Washington, D.C.", "latency_ms": 1314.0742778778076, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "LeDroit Park", "latency_ms": 974.327564239502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2026}, "4": {"k": 4, "answer": "Northwest Washington", "latency_ms": 720.444917678833, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2709}, "5": {"k": 5, "answer": "Northwest Washington", "latency_ms": 802.04176902771, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3449}, "6": {"k": 6, "answer": "Northwest Washington", "latency_ms": 940.8175945281982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4133}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 781.5096378326416, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noahic", "latency_ms": 1222.2812175750732, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "Noahic", "latency_ms": 650.6862640380859, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Noahic", "latency_ms": 968.0311679840088, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Noahic", "latency_ms": 935.7695579528809, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2577}, "5": {"k": 5, "answer": "Noahic", "latency_ms": 990.8616542816162, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "Noahic", "latency_ms": 562.5321865081787, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3870}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 1002.131462097168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 703.6442756652832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 955.5470943450928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1154}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1058.2771301269531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1034.7537994384766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2344}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 771.4202404022217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2946}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 803.6975860595703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3530}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 560.5731010437012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Anna King", "latency_ms": 918.3647632598877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Anna King", "latency_ms": 1210.3567123413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "Rudy Valle패e, Anna King, Erma Bombeck", "latency_ms": 2229.264736175537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Rudy Valle패e, Anna King, Erma Bombeck", "latency_ms": 2435.3268146514893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2444}, "5": {"k": 5, "answer": "Rudy Valle패e", "latency_ms": 1048.8722324371338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3038}, "6": {"k": 6, "answer": "Rudy Valle패e", "latency_ms": 1562.3416900634766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3686}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 819.25368309021, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 696.796178817749, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 1195.373296737671, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 1025.9490013122559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 448.31395149230957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 883.232593536377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 1130.7578086853027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3801}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "Second", "latency_ms": 209.6548080444336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "17.5% of the world's population", "latency_ms": 1983.2277297973633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "17.5% of the world's population", "latency_ms": 2137.701988220215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1440}, "3": {"k": 3, "answer": "17.5% of the world's population", "latency_ms": 2450.4053592681885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2155}, "4": {"k": 4, "answer": "17.5% of the world's population", "latency_ms": 2069.918394088745, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2822}, "5": {"k": 5, "answer": "17.5% of the world's population", "latency_ms": 1576.9474506378174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3415}, "6": {"k": 6, "answer": "Second most populated country", "latency_ms": 1206.1247825622559, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 4027}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 580.6901454925537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gandhi", "latency_ms": 694.6678161621094, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 689}, "2": {"k": 2, "answer": "Gandhi", "latency_ms": 704.4064998626709, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "Gandhi", "latency_ms": 1215.8145904541016, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2016}, "4": {"k": 4, "answer": "Gandhi", "latency_ms": 679.1903972625732, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Gandhi", "latency_ms": 1153.9363861083984, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3399}, "6": {"k": 6, "answer": "Pattom A. Thanu Pillai", "latency_ms": 1544.5480346679688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4081}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenae Anderson", "latency_ms": 523.5509872436523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bobby Flay", "latency_ms": 854.316234588623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Bobby Flay", "latency_ms": 1015.4082775115967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Bobby Flay", "latency_ms": 975.588321685791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Bobby Flay", "latency_ms": 1267.869234085083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "Bobby Flay", "latency_ms": 1263.1313800811768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "Bobby Flay", "latency_ms": 1478.5716533660889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 661.9746685028076, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "codice_22", "latency_ms": 1066.5786266326904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 687}, "2": {"k": 2, "answer": ".java", "latency_ms": 675.9083271026611, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": ".java", "latency_ms": 622.4424839019775, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2009}, "4": {"k": 4, "answer": ".java", "latency_ms": 782.8431129455566, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2651}, "5": {"k": 5, "answer": ".java", "latency_ms": 884.6936225891113, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3316}, "6": {"k": 6, "answer": ".java", "latency_ms": 862.6852035522461, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3937}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 643.2619094848633, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alan Turing", "latency_ms": 666.7830944061279, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Alan Turing", "latency_ms": 856.3127517700195, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1304}, "3": {"k": 3, "answer": "Alan Turing", "latency_ms": 1203.2172679901123, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 1021.4271545410156, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2627}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 442.2578811645508, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3278}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 767.7867412567139, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3946}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline", "latency_ms": 850.1942157745361, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to offer promotion or threaten demotion", "latency_ms": 2103.0075550079346, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "bargain for votes", "latency_ms": 1578.6421298980713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1383}, "3": {"k": 3, "answer": "manages their party's legislative program", "latency_ms": 1219.4910049438477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "manage their party's legislative program", "latency_ms": 1344.517707824707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2655}, "5": {"k": 5, "answer": "manage their party's legislative program", "latency_ms": 1110.2063655853271, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3318}, "6": {"k": 6, "answer": "manage legislative program", "latency_ms": 999.4807243347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3982}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 480.7605743408203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1237.8342151641846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 700}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1261.4319324493408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1342}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1047.7447509765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1043.5607433319092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2586}, "5": {"k": 5, "answer": "1973", "latency_ms": 708.9989185333252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3141}, "6": {"k": 6, "answer": "1973", "latency_ms": 683.0856800079346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the right but not the obligation to buy foreign currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 673.6409664154053, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 705.38330078125, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 905.3447246551514, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 899.3594646453857, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "FX option", "latency_ms": 870.9523677825928, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2666}, "5": {"k": 5, "answer": "FX option", "latency_ms": 895.6103324890137, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3287}, "6": {"k": 6, "answer": "FX option", "latency_ms": 715.923547744751, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3850}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 477.61988639831543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 687.1871948242188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360 members", "latency_ms": 932.6951503753662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1420}, "3": {"k": 3, "answer": "360", "latency_ms": 874.2334842681885, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2062}, "4": {"k": 4, "answer": "360", "latency_ms": 1206.7418098449707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2717}, "5": {"k": 5, "answer": "360 members", "latency_ms": 954.688310623169, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3347}, "6": {"k": 6, "answer": "360 members", "latency_ms": 1162.2095108032227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3997}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 601.1581420898438, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 1001.1138916015625, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 1195.3914165496826, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 802.5569915771484, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 1265.9108638763428, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 1032.7415466308594, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 869.4074153900146, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3856}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gorm칠"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 1120.8577156066895, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eydie Gorm칠", "latency_ms": 1560.1756572723389, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 580}, "2": {"k": 2, "answer": "Eydie Gorm칠", "latency_ms": 1348.8504886627197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Eydie Gorm칠", "latency_ms": 1285.6180667877197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1787}, "4": {"k": 4, "answer": "Eydie Gorm칠", "latency_ms": 1310.5449676513672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2404}, "5": {"k": 5, "answer": "Eydie Gorm칠", "latency_ms": 1143.4192657470703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3052}, "6": {"k": 6, "answer": "Eydie Gorm칠", "latency_ms": 1348.3705520629883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3653}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 756.9804191589355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ashok Bhushan", "latency_ms": 1241.0736083984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 562}, "2": {"k": 2, "answer": "Ashok Bhushan", "latency_ms": 1255.9945583343506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Ashok Bhushan", "latency_ms": 1429.154872894287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1806}, "4": {"k": 4, "answer": "Ashok Bhushan", "latency_ms": 1273.0896472930908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2408}, "5": {"k": 5, "answer": "Ashok Bhushan", "latency_ms": 844.7539806365967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2929}, "6": {"k": 6, "answer": "Ashok Bhushan", "latency_ms": 1100.0995635986328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3493}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1033.2789421081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Martina Navratilova", "latency_ms": 1377.6702880859375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "Martina Navratilova", "latency_ms": 1356.1351299285889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Martina Navratilova", "latency_ms": 1644.9642181396484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Martina Navratilova", "latency_ms": 841.789722442627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Roger Federer", "latency_ms": 1002.2222995758057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3229}, "6": {"k": 6, "answer": "Roger Federer", "latency_ms": 990.7150268554688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3882}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 980.2584648132324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 367.7358627319336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 600.9671688079834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1215}, "3": {"k": 3, "answer": "1", "latency_ms": 674.4887828826904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "1", "latency_ms": 835.369348526001, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2459}, "5": {"k": 5, "answer": "1", "latency_ms": 588.4003639221191, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3072}, "6": {"k": 6, "answer": "1", "latency_ms": 826.9751071929932, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3655}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 282.69505500793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1954", "latency_ms": 916.8787002563477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "2002", "latency_ms": 843.0981636047363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "2002", "latency_ms": 926.5077114105225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "2000", "latency_ms": 1164.7343635559082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2479}, "5": {"k": 5, "answer": "2002", "latency_ms": 668.7994003295898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "2002", "latency_ms": 1176.0592460632324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3746}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 557.0847988128662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "7", "latency_ms": 426.02992057800293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "2", "latency_ms": 1150.7318019866943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "2", "latency_ms": 430.788516998291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "5", "latency_ms": 1171.7357635498047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2621}, "5": {"k": 5, "answer": "17", "latency_ms": 368.00312995910645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3284}, "6": {"k": 6, "answer": "2", "latency_ms": 938.5483264923096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3886}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 1310.2495670318604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 1303.5752773284912, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 1208.7631225585938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 919.3761348724365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1872}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 1270.2884674072266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2545}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 1327.310562133789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3218}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 1369.0435886383057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3855}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 1590.4483795166016, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 1070.030927658081, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1009.1953277587891, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Corey, Cory", "latency_ms": 1343.627691268921, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1916}, "4": {"k": 4, "answer": "Corey, Cory", "latency_ms": 1327.0587921142578, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Corey, Cory", "latency_ms": 1291.7976379394531, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3106}, "6": {"k": 6, "answer": "Corey, Cory", "latency_ms": 1050.7948398590088, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3691}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 1045.8900928497314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Toby Keith", "latency_ms": 1047.1181869506836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Toby Keith", "latency_ms": 697.7910995483398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Toby Keith", "latency_ms": 941.037654876709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Toby Keith", "latency_ms": 1234.8825931549072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2491}, "5": {"k": 5, "answer": "Toby Keith", "latency_ms": 1235.8176708221436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3102}, "6": {"k": 6, "answer": "Toby Keith", "latency_ms": 952.2278308868408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3737}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 403.9030075073242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 original counties", "latency_ms": 577.8200626373291, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "159", "latency_ms": 1099.5984077453613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1301}, "3": {"k": 3, "answer": "159", "latency_ms": 648.9794254302979, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1933}, "4": {"k": 4, "answer": "159", "latency_ms": 873.4643459320068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2557}, "5": {"k": 5, "answer": "159", "latency_ms": 657.4654579162598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3247}, "6": {"k": 6, "answer": "159", "latency_ms": 834.0356349945068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3920}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 1263.8216018676758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1042.891025543213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "Matt Flinders", "latency_ms": 825.4690170288086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Johnny Curtis", "latency_ms": 1005.9432983398438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "Matt Flinders", "latency_ms": 1228.2097339630127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2443}, "5": {"k": 5, "answer": "Matt Flinders", "latency_ms": 1198.913812637329, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3057}, "6": {"k": 6, "answer": "Matt Flinders", "latency_ms": 1207.099437713623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3640}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 480.7898998260498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1274.8267650604248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 974.661111831665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1177}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 989.4607067108154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1755}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 835.5538845062256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2346}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1216.4688110351562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2998}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1297.2745895385742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3631}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 862.0436191558838, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Right hand", "latency_ms": 858.525276184082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 612.8442287445068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1154}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 904.3314456939697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1718}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 700.8004188537598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2320}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 635.1957321166992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2914}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 786.0815525054932, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3468}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 1164.9994850158691, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Donald Duck", "latency_ms": 977.6675701141357, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Donald Duck", "latency_ms": 478.37281227111816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1293}, "3": {"k": 3, "answer": "Donald Duck", "latency_ms": 1004.7714710235596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1945}, "4": {"k": 4, "answer": "Donald Duck", "latency_ms": 1207.8070640563965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Donald Duck", "latency_ms": 472.66650199890137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3192}, "6": {"k": 6, "answer": "Donald Duck", "latency_ms": 1168.5616970062256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3800}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 587.3491764068604, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bernard Hill", "latency_ms": 955.9197425842285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 590}, "2": {"k": 2, "answer": "Bernard Hill", "latency_ms": 1196.333408355713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1178}, "3": {"k": 3, "answer": "Bernard Hill", "latency_ms": 960.59250831604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1824}, "4": {"k": 4, "answer": "Bernard Hill", "latency_ms": 1233.3834171295166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2422}, "5": {"k": 5, "answer": "Bernard Hill", "latency_ms": 997.8518486022949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3028}, "6": {"k": 6, "answer": "Bernard Hill", "latency_ms": 1246.3011741638184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3691}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2019", "latency_ms": 1042.0799255371094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2018", "latency_ms": 1553.3125400543213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 1631.4024925231934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 1905.6575298309326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1787}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 1421.248197555542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2404}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 1411.726713180542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3055}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 1139.711856842041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3697}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 900.4871845245361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles", "latency_ms": 677.2921085357666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Los Angeles", "latency_ms": 1181.633472442627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Los Angeles", "latency_ms": 934.2801570892334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Los Angeles", "latency_ms": 674.0367412567139, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "Los Angeles", "latency_ms": 1160.0804328918457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Los Angeles", "latency_ms": 615.3614521026611, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3800}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 1176.4607429504395, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Claire Holt", "latency_ms": 933.0921173095703, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Claire Holt", "latency_ms": 1619.6215152740479, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Claire Holt", "latency_ms": 924.8743057250977, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Claire Holt", "latency_ms": 1025.059461593628, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "Claire Holt", "latency_ms": 1217.027187347412, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3110}, "6": {"k": 6, "answer": "Claire Holt", "latency_ms": 1052.3412227630615, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3753}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living things", "latency_ms": 814.4443035125732, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in the biosphere", "latency_ms": 1256.6568851470947, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 700}, "2": {"k": 2, "answer": "the deepest parts of the ocean, and high in the atmosphere, soil and subsurface.", "latency_ms": 2688.1263256073, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 1325}, "3": {"k": 3, "answer": "in all water bodies, soil, and subsurface, and in forests", "latency_ms": 2672.3740100860596, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 2010}, "4": {"k": 4, "answer": "the deepest parts of the ocean, and at least high in the atmosphere", "latency_ms": 2832.817316055298, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2664}, "5": {"k": 5, "answer": "the deepest parts of the ocean, and at least high in the atmosphere", "latency_ms": 2108.8807582855225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3314}, "6": {"k": 6, "answer": "the deepest parts of the ocean, and at least high in the atmosphere", "latency_ms": 2664.020538330078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3937}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 569.878339767456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Vijay Raghavendra", "latency_ms": 1119.3263530731201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "Vijay Raghavendra", "latency_ms": 1613.3689880371094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Vijay Raghavendra", "latency_ms": 1234.8928451538086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Vijay Raghavendra", "latency_ms": 1511.1727714538574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "Vijay Raghavendra", "latency_ms": 1424.386739730835, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Vijay Raghavendra", "latency_ms": 1757.6477527618408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3852}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 886.5208625793457, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kanab, Utah", "latency_ms": 1108.9515686035156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "Kanab, Utah, Lake Powell", "latency_ms": 1434.0620040893555, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Kanab, Utah, Lake Powell", "latency_ms": 1910.7158184051514, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Kanab, Utah, Lake Powell", "latency_ms": 1908.5044860839844, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2523}, "5": {"k": 5, "answer": "Lake Powell, Kanab, Utah", "latency_ms": 1840.1141166687012, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3150}, "6": {"k": 6, "answer": "Lake Powell, Utah, Kanab", "latency_ms": 1726.104974746704, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3775}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 996.5918064117432, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roy Dotrice", "latency_ms": 757.9607963562012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Henry Garrett", "latency_ms": 1183.4042072296143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Roy Dotrice", "latency_ms": 1160.8326435089111, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1502.6493072509766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1487.778902053833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3212}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1077.888011932373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3858}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Lake Winnipeg", "latency_ms": 1111.0146045684814, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Saskatchewan Glacier to Rocky Mountain House", "latency_ms": 1881.8914890289307, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Rocky Mountains to Lake Winnipeg", "latency_ms": 1451.0931968688965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "Rocky Mountains to Lake Winnipeg", "latency_ms": 1581.7244052886963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "Alberta to Lake Winnipeg", "latency_ms": 1386.040210723877, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Alberta to Lake Winnipeg", "latency_ms": 1047.2252368927002, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3354}, "6": {"k": 6, "answer": "Alberta to Lake Winnipeg", "latency_ms": 1531.6972732543945, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4071}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 737.0195388793945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 469.41065788269043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome", "latency_ms": 974.1353988647461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Rome, Italy", "latency_ms": 1036.4933013916016, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 737.4660968780518, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2547}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 1254.5220851898193, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 1196.0346698760986, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3722}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "Measurement mark", "latency_ms": 699.6333599090576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "batch code", "latency_ms": 688.291072845459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "manufacturing company or site", "latency_ms": 1261.1305713653564, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "manufacturing company or site", "latency_ms": 1079.066276550293, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1967}, "4": {"k": 4, "answer": "the manufacturing company or site", "latency_ms": 1572.7956295013428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2574}, "5": {"k": 5, "answer": "the manufacturing company or site", "latency_ms": 1279.8945903778076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3214}, "6": {"k": 6, "answer": "the manufacturing company or site", "latency_ms": 1772.709608078003, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3855}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia", "latency_ms": 411.1442565917969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 1924.588918685913, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 1658.3240032196045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1352}, "3": {"k": 3, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 2375.9663105010986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1952}, "4": {"k": 4, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 1687.6487731933594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 1762.7289295196533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 2208.210229873657, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3766}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Boy Meets Girl", "latency_ms": 887.4363899230957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 1265.261173248291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "1988", "latency_ms": 1152.9147624969482, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1199}, "3": {"k": 3, "answer": "1988", "latency_ms": 437.1953010559082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1815}, "4": {"k": 4, "answer": "1988", "latency_ms": 1015.5730247497559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2417}, "5": {"k": 5, "answer": "1988", "latency_ms": 790.1978492736816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3047}, "6": {"k": 6, "answer": "1988", "latency_ms": 630.7106018066406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3682}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 714.2214775085449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tute", "latency_ms": 674.4480133056641, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "Manille", "latency_ms": 960.8104228973389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1164}, "3": {"k": 3, "answer": "Manille", "latency_ms": 977.1766662597656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1799}, "4": {"k": 4, "answer": "Manille", "latency_ms": 484.6515655517578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2447}, "5": {"k": 5, "answer": "Manille", "latency_ms": 874.5214939117432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "Manille", "latency_ms": 850.269079208374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3654}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 801.9859790802002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1011.1589431762695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1005.7182312011719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "5%", "latency_ms": 910.0258350372314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "5%", "latency_ms": 625.9219646453857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "5%", "latency_ms": 644.0291404724121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3166}, "6": {"k": 6, "answer": "5%", "latency_ms": 714.3874168395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3791}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 967.4222469329834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1975", "latency_ms": 448.0106830596924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "1975", "latency_ms": 712.8286361694336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "1975", "latency_ms": 906.7542552947998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1934}, "4": {"k": 4, "answer": "1975", "latency_ms": 971.4107513427734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2604}, "5": {"k": 5, "answer": "1975", "latency_ms": 886.0993385314941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3272}, "6": {"k": 6, "answer": "1975", "latency_ms": 933.0756664276123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3882}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 654.4754505157471, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lionel Richie", "latency_ms": 1053.8699626922607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Lionel Richie", "latency_ms": 1316.4112567901611, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Lionel Richie", "latency_ms": 1212.916612625122, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 1455.8486938476562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2625}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 1045.3872680664062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3233}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 1528.1784534454346, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3841}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert", "latency_ms": 884.2360973358154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cecil Calvert and Catholic settlers", "latency_ms": 1625.9815692901611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Catholics", "latency_ms": 891.2026882171631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1330}, "3": {"k": 3, "answer": "Cecil Calvert", "latency_ms": 1194.1235065460205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "Cecil Calvert", "latency_ms": 1249.1798400878906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2671}, "5": {"k": 5, "answer": "Cecil Calvert", "latency_ms": 1491.438865661621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3378}, "6": {"k": 6, "answer": "Cecil Calvert", "latency_ms": 879.908561706543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4011}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 743.3350086212158, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gary Player", "latency_ms": 921.4456081390381, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 630}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1005.4562091827393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 952.1350860595703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1175.9836673736572, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1078.4285068511963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3139}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1262.0189189910889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3728}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 1279.209852218628, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "200 to 500 mg", "latency_ms": 1566.5719509124756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 1751.1146068572998, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg", "latency_ms": 1341.4812088012695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1930}, "4": {"k": 4, "answer": "200 to 500 mg", "latency_ms": 1837.831735610962, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2549}, "5": {"k": 5, "answer": "200 to 500 mg", "latency_ms": 1183.640956878662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3248}, "6": {"k": 6, "answer": "200 to 500 mg", "latency_ms": 1835.5295658111572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3949}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 1180.0055503845215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham", "latency_ms": 725.4846096038818, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 579.8108577728271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1097}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 1136.0926628112793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1685}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 1301.091194152832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2245}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 928.7912845611572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2837}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 748.774528503418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3479}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 987.0340824127197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canada", "latency_ms": 812.2353553771973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "Canada", "latency_ms": 851.5865802764893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "Canada", "latency_ms": 1074.2731094360352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2012}, "4": {"k": 4, "answer": "Canada", "latency_ms": 594.3350791931152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Canada", "latency_ms": 905.4548740386963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3367}, "6": {"k": 6, "answer": "Canada", "latency_ms": 906.6751003265381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4000}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh", "latency_ms": 727.7028560638428, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 769.0398693084717, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 714.9777412414551, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1337}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 1251.8887519836426, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2015}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 1307.861089706421, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2687}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 1290.0574207305908, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3365}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 1269.4435119628906, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4050}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 831.6574096679688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1085.7539176940918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 964.2379283905029, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1104.4223308563232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1963}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1272.7487087249756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1258.38041305542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3222}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1273.5307216644287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3921}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 664.9312973022461, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Southport, North Carolina", "latency_ms": 1238.5921478271484, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Southport, North Carolina.", "latency_ms": 1538.766622543335, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1232}, "3": {"k": 3, "answer": "Southport, North Carolina", "latency_ms": 1251.7218589782715, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "Southport, North Carolina", "latency_ms": 1592.106580734253, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2456}, "5": {"k": 5, "answer": "Southport, North Carolina.", "latency_ms": 1163.102388381958, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3102}, "6": {"k": 6, "answer": "Southport, North Carolina.", "latency_ms": 1619.3861961364746, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3707}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 997.7257251739502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1008.436918258667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 705}, "2": {"k": 2, "answer": "Sylvia F. Porter", "latency_ms": 1036.3051891326904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Sylvia F. Porter", "latency_ms": 852.7500629425049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 1576.2059688568115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 1556.347370147705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 1371.480941772461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3904}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 508.9612007141113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 505.91111183166504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 1221.4128971099854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 453.14550399780273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2050}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 905.2956104278564, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2696}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 903.0945301055908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3371}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 1172.2187995910645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4055}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 692.2500133514404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 412.87827491760254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 602}, "2": {"k": 2, "answer": "Max", "latency_ms": 1152.9498100280762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Max", "latency_ms": 353.410005569458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1831}, "4": {"k": 4, "answer": "Max", "latency_ms": 853.6429405212402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2452}, "5": {"k": 5, "answer": "Max", "latency_ms": 402.6670455932617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Max", "latency_ms": 551.3262748718262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3787}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 1017.3132419586182, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amybeth McNulty", "latency_ms": 1502.1255016326904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 677}, "2": {"k": 2, "answer": "Amybeth McNulty", "latency_ms": 1242.3720359802246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Amybeth McNulty", "latency_ms": 973.3188152313232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Amybeth McNulty", "latency_ms": 1180.232286453247, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2563}, "5": {"k": 5, "answer": "Amybeth McNulty", "latency_ms": 932.5582981109619, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3243}, "6": {"k": 6, "answer": "Amybeth McNulty", "latency_ms": 1086.6529941558838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3818}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "Industrialization and imperialism.", "latency_ms": 831.9001197814941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "World's Fair, Rapid Transit Tunnel, Eight Nation Alliance, inventions, and laws.", "latency_ms": 2901.193141937256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "World's Fair, Rapid Transit Tunnel, Eight Nation Alliance invasion, Browning Pistol invention, Nobel Prize invention.", "latency_ms": 4035.0353717803955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "World's Fair, Rapid Transit Tunnel, Eight Nation Alliance invasion, and others.", "latency_ms": 2430.368185043335, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "World's Fair, Rapid Transit Tunnel, Eight Nation Alliance invasion, Nobel Prize invention.", "latency_ms": 2978.2731533050537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "World's Fair, Rapid Transit Tunnel, Eight Nation Alliance invasion, Browning Pistol invention, Nobel Prize invention.", "latency_ms": 3019.7596549987793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3330}, "6": {"k": 6, "answer": "World's Fair, Rapid Transit Tunnel, Eight Nation Alliance invasion, Browning Pistol invention, Nobel Prize invention.", "latency_ms": 3290.066719055176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3996}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 1060.0011348724365, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "self-empowerment", "latency_ms": 1689.8629665374756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 1402.7495384216309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "self-empowerment", "latency_ms": 1525.7558822631836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "self-empowerment", "latency_ms": 1113.9721870422363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2472}, "5": {"k": 5, "answer": "Empowerment", "latency_ms": 1410.3238582611084, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3094}, "6": {"k": 6, "answer": "Empowerment", "latency_ms": 1316.523551940918, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3769}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 842.3893451690674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Teams", "latency_ms": 635.8458995819092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "Teams", "latency_ms": 1042.1006679534912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Teams", "latency_ms": 479.2969226837158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "NFL franchises", "latency_ms": 834.0964317321777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2469}, "5": {"k": 5, "answer": "NFL teams", "latency_ms": 1111.9422912597656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "NFL teams", "latency_ms": 1168.9839363098145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3722}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 1095.339059829712, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1243.027925491333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "James W. Marshall", "latency_ms": 1113.2535934448242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1270}, "3": {"k": 3, "answer": "James W. Marshall", "latency_ms": 1267.2746181488037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "James W. Marshall", "latency_ms": 1090.8606052398682, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2582}, "5": {"k": 5, "answer": "James W. Marshall", "latency_ms": 1024.3968963623047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "James W. Marshall", "latency_ms": 1284.193992614746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3901}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 1061.7196559906006, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 958.3125114440918, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 1285.3178977966309, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 1051.243782043457, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 1016.251802444458, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 742.234468460083, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 1277.2111892700195, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3801}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1059.6768856048584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1301.9952774047852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1408.9715480804443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 824.1865634918213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1872}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1068.7425136566162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1329.1888236999512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1047.8923320770264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3671}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1612.6790046691895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1431.5869808197021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1115.255355834961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1199.9027729034424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1213.1571769714355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2596}, "5": {"k": 5, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1208.2359790802002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3287}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1708.20951461792, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3918}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 444.61894035339355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central German cultural region", "latency_ms": 739.1819953918457, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Central Germany", "latency_ms": 633.5663795471191, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Central Germany", "latency_ms": 871.1779117584229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1946}, "4": {"k": 4, "answer": "Central Germany", "latency_ms": 675.7824420928955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Central Germany", "latency_ms": 871.1903095245361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3288}, "6": {"k": 6, "answer": "Central Europe", "latency_ms": 1113.1231784820557, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3974}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 960.158109664917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "16481651", "latency_ms": 1092.5955772399902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "16481651", "latency_ms": 1086.517333984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "16481651", "latency_ms": 1092.8845405578613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1979}, "4": {"k": 4, "answer": "16481651", "latency_ms": 1485.1512908935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2632}, "5": {"k": 5, "answer": "16481651", "latency_ms": 1244.8759078979492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "16481651", "latency_ms": 1072.697639465332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3966}}}
