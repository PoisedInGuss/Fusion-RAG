{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2971.4925289154053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 22, 2018", "latency_ms": 3463.6948108673096, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "June 22, 2018", "latency_ms": 3123.685121536255, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "June 22, 2018", "latency_ms": 4075.4661560058594, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1885}, "4": {"k": 4, "answer": "June 22, 2018", "latency_ms": 3247.7874755859375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 4099.898099899292, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "June 22, 2018", "latency_ms": 2738.246202468872, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3790}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Freestyle, Nordic Combined, Ski Jumping, Biathlon.", "latency_ms": 9931.545734405518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alpine skiing", "latency_ms": 1874.399185180664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Alpine, Freestyle", "latency_ms": 2885.9238624572754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Alpine, Freestyle", "latency_ms": 3689.30721282959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 4024.461030960083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 4068.013906478882, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3268}, "6": {"k": 6, "answer": "Alpine, Freestyle, Cross-country", "latency_ms": 4151.155471801758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3935}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "Arianwen Parkes-Lockwood", "latency_ms": 3014.8346424102783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Aldo Mignone", "latency_ms": 3823.469638824463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 694}, "2": {"k": 2, "answer": "Aldo Mignone", "latency_ms": 4086.045026779175, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Aldo Mignone", "latency_ms": 2747.0059394836426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Aldo Mignone", "latency_ms": 2920.9630489349365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2564}, "5": {"k": 5, "answer": "Aldo Mignone", "latency_ms": 3137.3181343078613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3137}, "6": {"k": 6, "answer": "Aldo Mignone", "latency_ms": 3217.0369625091553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3751}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "Bengals, Dolphins, Broncos, Chargers", "latency_ms": 5386.376619338989, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Giants and Dan Marino", "latency_ms": 3164.7138595581055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "Miami Dolphins", "latency_ms": 1364.6845817565918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1201}, "3": {"k": 3, "answer": "Miami Dolphins, San Diego Chargers", "latency_ms": 3313.382863998413, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 1819}, "4": {"k": 4, "answer": "Miami Dolphins, San Diego Chargers", "latency_ms": 3260.383367538452, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 2372}, "5": {"k": 5, "answer": "Miami Dolphins, San Diego Chargers", "latency_ms": 3132.0619583129883, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 2970}, "6": {"k": 6, "answer": "Miami Dolphins, San Diego Chargers, Denver Broncos", "latency_ms": 4344.151020050049, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3525}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "December 8, 1985", "latency_ms": 2629.8322677612305, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 December 1985", "latency_ms": 2687.9851818084717, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 727}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 2218.8880443573, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1447}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 2765.4635906219482, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2148}, "4": {"k": 4, "answer": "8 December 1985", "latency_ms": 1966.9389724731445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2845}, "5": {"k": 5, "answer": "8 December 1985", "latency_ms": 1696.0904598236084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3541}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 3729.311943054199, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4247}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "Spanish moss", "latency_ms": 791.5999889373779, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spanish moss", "latency_ms": 1932.7061176300049, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "Spanish moss", "latency_ms": 1550.8828163146973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Spanish moss", "latency_ms": 1991.4546012878418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Spanish moss", "latency_ms": 1053.1084537506104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2678}, "5": {"k": 5, "answer": "Spanish moss", "latency_ms": 2107.3780059814453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3289}, "6": {"k": 6, "answer": "Spanish moss", "latency_ms": 781.0878753662109, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4000}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "I-IV", "latency_ms": 2180.8488368988037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Heart Association Functional Classification", "latency_ms": 2325.122117996216, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 754}, "2": {"k": 2, "answer": "New York Heart Association Functional Classification", "latency_ms": 3031.1572551727295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1453}, "3": {"k": 3, "answer": "New York Heart Association Functional Classification", "latency_ms": 3960.3660106658936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2217}, "4": {"k": 4, "answer": "New York Heart Association Functional Classification", "latency_ms": 2922.187566757202, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2949}, "5": {"k": 5, "answer": "New York Heart Association Functional Classification", "latency_ms": 2684.460401535034, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}, "6": {"k": 6, "answer": "New York Heart Association Functional Classification", "latency_ms": 2962.981700897217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4447}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Charles and Eddie", "latency_ms": 2249.8412132263184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3470.346450805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2965.4605388641357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2794.7158813476562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3260.852813720703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2453}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1956.6333293914795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2969.275951385498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3679}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 964.385986328125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 1450.4358768463135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "3", "latency_ms": 1717.1249389648438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "3", "latency_ms": 1697.1187591552734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "3", "latency_ms": 1303.3745288848877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2490}, "5": {"k": 5, "answer": "3", "latency_ms": 1466.5989875793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "3", "latency_ms": 1246.5109825134277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3725}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "A cake", "latency_ms": 1628.5114288330078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Biscuit-sized cakes", "latency_ms": 2998.1765747070312, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "cake", "latency_ms": 1990.1278018951416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "cake", "latency_ms": 1746.9220161437988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1764}, "4": {"k": 4, "answer": "A cake", "latency_ms": 1448.7769603729248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "A cake", "latency_ms": 2109.5964908599854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3040}, "6": {"k": 6, "answer": "A cake.", "latency_ms": 2563.45534324646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Seth MacFarlane", "latency_ms": 2782.6967239379883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seth MacFarlane", "latency_ms": 2503.5221576690674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Seth MacFarlane", "latency_ms": 3067.352294921875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Seth MacFarlane", "latency_ms": 3121.2103366851807, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1913}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 2801.663398742676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2554}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 3463.5212421417236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 3498.1870651245117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3844}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "Heroin", "latency_ms": 1787.2204780578613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amphetamines", "latency_ms": 2595.3195095062256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Amphetamines", "latency_ms": 2118.704080581665, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1186}, "3": {"k": 3, "answer": "Amphetamines", "latency_ms": 2140.373706817627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1805}, "4": {"k": 4, "answer": "Amphetamines", "latency_ms": 2310.1725578308105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2410}, "5": {"k": 5, "answer": "Amphetamines", "latency_ms": 2056.9000244140625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3052}, "6": {"k": 6, "answer": "Amphetamines", "latency_ms": 2588.5186195373535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "14 weeks", "latency_ms": 1832.4558734893799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2739.250421524048, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 571}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3218.9958095550537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3152.055501937866, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1751}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1924.0326881408691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2401}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2770.9641456604004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2983}, "6": {"k": 6, "answer": "Not specified", "latency_ms": 1792.5775051116943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3586}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "Yushan, China", "latency_ms": 2847.3589420318604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haikou, China", "latency_ms": 2449.924945831299, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "Haikou, China", "latency_ms": 3204.108715057373, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1255}, "3": {"k": 3, "answer": "Haikou, China", "latency_ms": 2773.9133834838867, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Yushan, China", "latency_ms": 2783.3285331726074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "Yushan, China", "latency_ms": 3015.540599822998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3043}, "6": {"k": 6, "answer": "Yushan, China.", "latency_ms": 3332.631826400757, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "Thad Luckinbill", "latency_ms": 1773.8795280456543, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2413.487434387207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2992.542028427124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2643.030881881714, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2201.1828422546387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2482}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2910.661220550537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3142}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2533.3619117736816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3745}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 1038.182020187378, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1983", "latency_ms": 2251.220464706421, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "1983 is not in the context, the answer is: I cannot answer.", "latency_ms": 6745.639324188232, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 1312}, "3": {"k": 3, "answer": "1973", "latency_ms": 1376.2688636779785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "1983", "latency_ms": 2281.6412448883057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2577}, "5": {"k": 5, "answer": "1983", "latency_ms": 2043.057918548584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3252}, "6": {"k": 6, "answer": "1983", "latency_ms": 1739.2046451568604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3909}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "J-Rock", "latency_ms": 1841.0749435424805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alexz Johnson", "latency_ms": 2341.0634994506836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Alexz Johnson", "latency_ms": 1816.9684410095215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Alexz Johnson", "latency_ms": 2478.749990463257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Alexz Johnson", "latency_ms": 2891.7946815490723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Alexz Johnson", "latency_ms": 2894.619941711426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3319}, "6": {"k": 6, "answer": "Alexz Johnson", "latency_ms": 2129.049777984619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4045}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "2006", "latency_ms": 1189.0263557434082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 million years ago", "latency_ms": 2225.6782054901123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "June 1995", "latency_ms": 2919.787645339966, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "2.58 million years ago", "latency_ms": 3253.8211345672607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "June 1995", "latency_ms": 2483.919382095337, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "March 15, 2002", "latency_ms": 3861.4349365234375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3114}, "6": {"k": 6, "answer": "March 15, 2002", "latency_ms": 3241.725444793701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3731}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "Master Sergeant", "latency_ms": 1244.5781230926514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Master Sergeant", "latency_ms": 1779.806137084961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Master Sergeant", "latency_ms": 2355.8549880981445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1336}, "3": {"k": 3, "answer": "Master Sergeant", "latency_ms": 1419.4118976593018, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1903}, "4": {"k": 4, "answer": "Master Sergeant", "latency_ms": 1832.7722549438477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2540}, "5": {"k": 5, "answer": "Master Sergeant", "latency_ms": 1990.506649017334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3116}, "6": {"k": 6, "answer": "Master Sergeant", "latency_ms": 1510.5819702148438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3845}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 1931.9374561309814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "GNU project", "latency_ms": 1540.1248931884766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 1835.9942436218262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 1866.4441108703613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 2563.0311965942383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2593}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 2609.7705364227295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3271}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 1837.7392292022705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3954}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2180.556058883667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2736.7923259735107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2401.6754627227783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1189}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2410.980463027954, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1802}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2163.5096073150635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2411}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2097.3122119903564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3010}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3294.5520877838135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3641}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Ed Roland", "latency_ms": 535.0501537322998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 2317.2667026519775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 2048.9134788513184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 1093.634843826294, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1954}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 1815.7455921173096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2630}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 1555.6867122650146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3316}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 2145.197868347168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3959}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1896.46315574646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miami Heat", "latency_ms": 1579.742193222046, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 1718.583583831787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1217}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 1472.3279476165771, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1850}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 2338.8872146606445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2436}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 1694.953441619873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3003}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 1534.0850353240967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3613}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2279.926300048828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "PYG", "latency_ms": 1804.0940761566162, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "PYG6155", "latency_ms": 1870.276689529419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "PYG", "latency_ms": 1316.657543182373, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "PYG", "latency_ms": 1740.6866550445557, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 2500}, "5": {"k": 5, "answer": "PYG", "latency_ms": 1209.0444564819336, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3069}, "6": {"k": 6, "answer": "PYG", "latency_ms": 2531.771659851074, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3749}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "Midazolam", "latency_ms": 1839.5802974700928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "It is not specified.", "latency_ms": 3441.6465759277344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "Benzodiazepines", "latency_ms": 3007.4210166931152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Benzodiazepines", "latency_ms": 2436.016082763672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Benzodiazepines", "latency_ms": 3746.8481063842773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2714}, "5": {"k": 5, "answer": "Benzodiazepines", "latency_ms": 4029.3376445770264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3394}, "6": {"k": 6, "answer": "Benzodiazepines", "latency_ms": 3857.4912548065186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4040}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 2515.167236328125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "26,000 years", "latency_ms": 2176.8481731414795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "26,000 years", "latency_ms": 3226.9155979156494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "26,000 years", "latency_ms": 3086.7903232574463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1900}, "4": {"k": 4, "answer": "25,772 years", "latency_ms": 2670.1626777648926, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "25,772 years", "latency_ms": 2930.0012588500977, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "25,772 years", "latency_ms": 1965.052604675293, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3770}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 2044.708251953125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Texas A&M Aggies", "latency_ms": 2419.985771179199, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Texas A&M Aggies", "latency_ms": 2887.547016143799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1266}, "3": {"k": 3, "answer": "Texas A&M Aggies", "latency_ms": 1911.5099906921387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "Texas A&M Aggies", "latency_ms": 2745.864152908325, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2551}, "5": {"k": 5, "answer": "Texas A&M Aggies", "latency_ms": 2503.8578510284424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3175}, "6": {"k": 6, "answer": "Texas A&M Aggies", "latency_ms": 3026.5870094299316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3811}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and Non-Renewable.", "latency_ms": 4986.688613891602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable or non-renewable", "latency_ms": 3821.6001987457275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable or non-renewable", "latency_ms": 3546.4725494384766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1447}, "3": {"k": 3, "answer": "renewable or non-renewable", "latency_ms": 4157.352924346924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2207}, "4": {"k": 4, "answer": "renewable or non-renewable", "latency_ms": 4647.874593734741, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2938}, "5": {"k": 5, "answer": "renewable or non-renewable", "latency_ms": 3973.255395889282, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3670}, "6": {"k": 6, "answer": "renewable or non-renewable", "latency_ms": 4005.939483642578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4372}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "New life and fertility", "latency_ms": 2715.3873443603516, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parental devotion", "latency_ms": 1810.1329803466797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Purity", "latency_ms": 1224.8642444610596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "Purity", "latency_ms": 1014.1229629516602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "Purity", "latency_ms": 1549.9248504638672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2520}, "5": {"k": 5, "answer": "Purity", "latency_ms": 2026.8330574035645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "Purity", "latency_ms": 728.4932136535645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3769}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Virat Kohli", "latency_ms": 2375.38743019104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2732.13267326355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2346.204996109009, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "558", "latency_ms": 1472.6252555847168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1816}, "4": {"k": 4, "answer": "558", "latency_ms": 1226.3903617858887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2421}, "5": {"k": 5, "answer": "558", "latency_ms": 1540.3335094451904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3070}, "6": {"k": 6, "answer": "558", "latency_ms": 953.7172317504883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "the antimicrobial action of metal ions.", "latency_ms": 3322.8750228881836, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals", "latency_ms": 2718.952417373657, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "biocidal effect of metals", "latency_ms": 3285.360336303711, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "biocidal effect of metals", "latency_ms": 3003.6299228668213, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2074}, "4": {"k": 4, "answer": "biocidal effect of metals", "latency_ms": 2758.420944213867, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2812}, "5": {"k": 5, "answer": "biocidal effect of metals", "latency_ms": 3632.671117782593, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3478}, "6": {"k": 6, "answer": "biocidal effect of metals", "latency_ms": 2661.4174842834473, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4266}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "Dustin Higgs", "latency_ms": 2389.3463611602783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ted Bundy", "latency_ms": 2042.7937507629395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "Leonard Shockley", "latency_ms": 2701.1308670043945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1201}, "3": {"k": 3, "answer": "Walter LaGrand", "latency_ms": 2454.2152881622314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1806}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1868.880271911621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2400}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2498.3255863189697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3027}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2432.548999786377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3628}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the auction.", "latency_ms": 2458.359956741333, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "when they hold two \"touching honors\"", "latency_ms": 4330.2483558654785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 580}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 3781.581401824951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1132}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 2555.607557296753, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1738}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 2459.7322940826416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2343}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 3547.9397773742676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2965}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 3539.2091274261475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3537}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Afghanistan", "latency_ms": 2372.5483417510986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 2596.667528152466, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 699}, "2": {"k": 2, "answer": "Afghanistan", "latency_ms": 1855.8144569396973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Afghanistan", "latency_ms": 2138.8208866119385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2101}, "4": {"k": 4, "answer": "Afghanistan", "latency_ms": 2557.318925857544, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2830}, "5": {"k": 5, "answer": "Afghanistan", "latency_ms": 2553.8170337677, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3556}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 2293.393135070801, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4227}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "Coagulation, Fibrin formation, Clot retraction", "latency_ms": 6099.743127822876, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 4984.588384628296, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2586.416006088257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 6314.413070678711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2019}, "4": {"k": 4, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 4381.8981647491455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2705}, "5": {"k": 5, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 6211.630344390869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3296}, "6": {"k": 6, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 5592.23747253418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3992}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "Sebastian Hunsinger", "latency_ms": 2755.1958560943604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shawn Roberts", "latency_ms": 1396.6999053955078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "Sebastian HÃ¼lk", "latency_ms": 1953.4263610839844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1374}, "3": {"k": 3, "answer": "Sebastian Hedges Thomas", "latency_ms": 3170.5989837646484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2068}, "4": {"k": 4, "answer": "Shawn Roberts", "latency_ms": 2193.8347816467285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2732}, "5": {"k": 5, "answer": "Shawn Roberts", "latency_ms": 2042.2801971435547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3378}, "6": {"k": 6, "answer": "Shawn Roberts", "latency_ms": 2359.032392501831, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4086}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "20 November 1989", "latency_ms": 1766.052007675171, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "20 November 1989", "latency_ms": 2369.464874267578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 2609.086036682129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1282}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 2649.684429168701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1927}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 2716.3119316101074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2594}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 3005.657196044922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 2021.895408630371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3830}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "2016", "latency_ms": 715.2698040008545, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 2016", "latency_ms": 2329.22625541687, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "June 2016", "latency_ms": 2653.221845626831, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1251}, "3": {"k": 3, "answer": "June 2016", "latency_ms": 1864.9146556854248, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "June 2016", "latency_ms": 2417.511463165283, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "June 2016", "latency_ms": 1608.3252429962158, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "June 2016", "latency_ms": 2179.919958114624, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3756}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 1989.7873401641846, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Burj Khalifa", "latency_ms": 2188.1167888641357, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 679}, "2": {"k": 2, "answer": "Burj Khalifa", "latency_ms": 2404.0868282318115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1360}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 2245.516300201416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2047}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 2239.560127258301, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2688}, "5": {"k": 5, "answer": "Burj Khalifa", "latency_ms": 2154.7348499298096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3330}, "6": {"k": 6, "answer": "Burj Khalifa", "latency_ms": 1893.0950164794922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "Miranda Hart", "latency_ms": 1609.0657711029053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miranda Hart's mother is played by  Marcia Warren", "latency_ms": 5503.476619720459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Miranda Hart's mother is played by  Cherie Lunghi", "latency_ms": 7211.690425872803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2948.3611583709717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2523.8776206970215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2600}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2236.976146697998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2932.0905208587646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3841}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Montesquieu", "latency_ms": 1503.3299922943115, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montesquieu", "latency_ms": 2303.6928176879883, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 2535.181760787964, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 2624.3340969085693, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 2581.2623500823975, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2674}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 2464.1451835632324, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3375}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 2377.537250518799, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4007}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Myles Garrett", "latency_ms": 1691.488265991211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3009.5465183258057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "Myles Garrett", "latency_ms": 2247.1582889556885, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Myles Garrett", "latency_ms": 2254.5063495635986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1868}, "4": {"k": 4, "answer": "Myles Garrett", "latency_ms": 2867.065191268921, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2509}, "5": {"k": 5, "answer": "Myles Garrett", "latency_ms": 3456.148624420166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "Myles Garrett", "latency_ms": 2295.6137657165527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3780}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2063 BS", "latency_ms": 2060.9405040740967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2063 BS", "latency_ms": 1929.1503429412842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2408.6499214172363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1341}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1748.6999034881592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2057}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3446.1729526519775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2698}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3245.7728385925293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3451}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2582.7503204345703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4087}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "Captain John Smith", "latency_ms": 1523.442029953003, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Smith", "latency_ms": 2263.103485107422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 668}, "2": {"k": 2, "answer": "John Smith", "latency_ms": 1565.3727054595947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1301}, "3": {"k": 3, "answer": "John Smith", "latency_ms": 2078.714609146118, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1933}, "4": {"k": 4, "answer": "John Smith", "latency_ms": 1253.3917427062988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2608}, "5": {"k": 5, "answer": "John Smith", "latency_ms": 1724.095344543457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3236}, "6": {"k": 6, "answer": "John Smith", "latency_ms": 2363.16180229187, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3886}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "Parietal cells", "latency_ms": 2234.0800762176514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parietal cells", "latency_ms": 2250.277519226074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 625}, "2": {"k": 2, "answer": "Parietal cells", "latency_ms": 2197.266101837158, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Parietal cells", "latency_ms": 2964.2887115478516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1803}, "4": {"k": 4, "answer": "Parietal cells", "latency_ms": 2176.1200428009033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2404}, "5": {"k": 5, "answer": "Parietal cells", "latency_ms": 2096.980333328247, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3006}, "6": {"k": 6, "answer": "Parietal cells", "latency_ms": 2165.9371852874756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3675}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "Early morning", "latency_ms": 1891.082763671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "4 a.m.", "latency_ms": 1713.1421566009521, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 2439.131736755371, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "4 a.m.", "latency_ms": 2329.270839691162, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "4 a.m.", "latency_ms": 2124.107599258423, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2711}, "5": {"k": 5, "answer": "4 a.m.", "latency_ms": 2431.0660362243652, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3342}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 2426.7630577087402, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4053}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 1084.7434997558594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Idaho", "latency_ms": 1526.643991470337, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "Idaho", "latency_ms": 1274.3115425109863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Idaho", "latency_ms": 2256.443738937378, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2005}, "4": {"k": 4, "answer": "Idaho", "latency_ms": 2111.919641494751, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2629}, "5": {"k": 5, "answer": "Idaho", "latency_ms": 2037.5230312347412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3311}, "6": {"k": 6, "answer": "Idaho", "latency_ms": 1518.7451839447021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3951}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales", "latency_ms": 10005.799770355225, "em": 0.0, "f1": 0.43478260869565216, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3005.6352615356445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2670.7355976104736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2199.5763778686523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1904}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2613.7466430664062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2943.0739879608154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3211}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1918.5066223144531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3853}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 1570.997953414917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "modulate", "latency_ms": 1018.6736583709717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "modulate", "latency_ms": 1808.5963726043701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "modulated", "latency_ms": 1453.5467624664307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "modulated", "latency_ms": 2021.74973487854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "modulated", "latency_ms": 1718.9717292785645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3108}, "6": {"k": 6, "answer": "modulated", "latency_ms": 2042.9141521453857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3720}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Male citizens", "latency_ms": 1537.1341705322266, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "full Roman citizens", "latency_ms": 2367.5832748413086, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 637}, "2": {"k": 2, "answer": "Roman citizens", "latency_ms": 903.0003547668457, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1336}, "3": {"k": 3, "answer": "Roman citizens", "latency_ms": 1964.4877910614014, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2010}, "4": {"k": 4, "answer": "Roman citizens", "latency_ms": 1993.304967880249, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2685}, "5": {"k": 5, "answer": "Full Roman citizens, excluding women, slaves, and originally those outside Rome.", "latency_ms": 5223.198175430298, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 3365}, "6": {"k": 6, "answer": "Adult male citizens", "latency_ms": 1735.5566024780273, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4007}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2906.4040184020996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "9 April 2019", "latency_ms": 3012.9454135894775, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "9 April 2019", "latency_ms": 2744.6417808532715, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "9 April 2019", "latency_ms": 2976.4115810394287, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1878}, "4": {"k": 4, "answer": "9 April 2019", "latency_ms": 2416.8455600738525, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2520}, "5": {"k": 5, "answer": "9 April 2019", "latency_ms": 2496.628999710083, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "9 April 2019", "latency_ms": 3546.8177795410156, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3804}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "100 parts of blood", "latency_ms": 2439.4235610961914, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "volume of blood or mass of blood", "latency_ms": 3224.961757659912, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "volume of blood or mass of blood", "latency_ms": 3837.169885635376, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1302}, "3": {"k": 3, "answer": "volume of blood or mass of blood", "latency_ms": 3890.3415203094482, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "volume of blood or mass of blood", "latency_ms": 3948.2131004333496, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "volume of blood or mass of blood", "latency_ms": 3127.9139518737793, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3085}, "6": {"k": 6, "answer": "volume of blood or mass of blood", "latency_ms": 4173.348665237427, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3782}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "Icarus", "latency_ms": 2304.8160076141357, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Icarus", "latency_ms": 2683.5572719573975, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "Iphigenia is not mentioned, the correct answer is: Icarus", "latency_ms": 6032.129526138306, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "PhaÃ«ton", "latency_ms": 2434.692621231079, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "Icarus", "latency_ms": 2654.9103260040283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Icarus", "latency_ms": 2116.626262664795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Icarus", "latency_ms": 2342.3616886138916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3796}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "September 16, 1979", "latency_ms": 4177.384614944458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1979", "latency_ms": 1781.4288139343262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "1979", "latency_ms": 1656.9886207580566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "1979", "latency_ms": 1803.5564422607422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1875}, "4": {"k": 4, "answer": "September 16, 1979", "latency_ms": 3320.4798698425293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2492}, "5": {"k": 5, "answer": "September 16, 1979", "latency_ms": 4820.187330245972, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3060}, "6": {"k": 6, "answer": "1979", "latency_ms": 2088.0608558654785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3640}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 am", "latency_ms": 2418.1010723114014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2667.7615642547607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "2 April 1986", "latency_ms": 3199.9762058258057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "2 April 1986", "latency_ms": 2674.0481853485107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "2 April 1986", "latency_ms": 2463.9744758605957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "2 April 1986", "latency_ms": 2842.0145511627197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3251}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2948.9388465881348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3889}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "Tiffany Coyne", "latency_ms": 2584.256410598755, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Carol Merrill", "latency_ms": 2263.4031772613525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Tiffany Coyne", "latency_ms": 2599.2958545684814, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 2511.676073074341, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 1937.3829364776611, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 2639.2979621887207, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 1886.6698741912842, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3701}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "Yankees, Braves, Reds, Giants", "latency_ms": 4310.078144073486, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5944.3464279174805, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5263.800621032715, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5619.334697723389, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1859}, "4": {"k": 4, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 4797.239065170288, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2435}, "5": {"k": 5, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5162.386178970337, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3068}, "6": {"k": 6, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5788.538932800293, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3674}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "2.187 billion dollars", "latency_ms": 1872.293472290039, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$343.4 million", "latency_ms": 2656.6457748413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "$2 billion", "latency_ms": 1737.8356456756592, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "$1.84 billion", "latency_ms": 3521.6221809387207, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "$2 billion", "latency_ms": 2489.164113998413, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "$2 billion", "latency_ms": 1619.8146343231201, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3193}, "6": {"k": 6, "answer": "$1.84 billion", "latency_ms": 2233.9296340942383, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3799}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2255.625009536743, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1601.3107299804688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1842.848777770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "1946", "latency_ms": 2064.92018699646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1636.528730392456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "1946", "latency_ms": 1336.609125137329, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3131}, "6": {"k": 6, "answer": "1946", "latency_ms": 1521.1997032165527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3782}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark", "latency_ms": 988.6472225189209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Her parents", "latency_ms": 1524.6248245239258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Norway", "latency_ms": 1485.9874248504639, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Norway", "latency_ms": 1446.3253021240234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1862}, "4": {"k": 4, "answer": "Norway", "latency_ms": 2032.2563648223877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2442}, "5": {"k": 5, "answer": "Norway", "latency_ms": 1539.038896560669, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3014}, "6": {"k": 6, "answer": "Norway", "latency_ms": 1338.8679027557373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3609}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "PresÃ©pio", "latency_ms": 1200.927734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Christmas Tree", "latency_ms": 1556.809425354004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Christmas Tree", "latency_ms": 977.4799346923828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Christmas Tree", "latency_ms": 1709.878921508789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Star of Bethlehem", "latency_ms": 2099.325180053711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3197.185516357422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3188}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1619.661569595337, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3810}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "Patrick Swayze", "latency_ms": 1690.4845237731934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Swayze", "latency_ms": 2131.366729736328, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Swayze", "latency_ms": 1546.8025207519531, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "Swayze", "latency_ms": 2107.1908473968506, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "Swayze", "latency_ms": 2117.41042137146, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Swayze", "latency_ms": 1822.9403495788574, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3260}, "6": {"k": 6, "answer": "Swayze", "latency_ms": 2624.8228549957275, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3875}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Pittsburgh", "latency_ms": 1883.5206031799316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2082.73983001709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2207.5304985046387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1604.8760414123535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2385.03098487854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2559}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1899.5957374572754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3285}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2937.2928142547607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3950}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1704", "latency_ms": 1824.819803237915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "First Parliament", "latency_ms": 1994.5800304412842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "First Parliament", "latency_ms": 1244.07958984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "First Parliament", "latency_ms": 1022.4242210388184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2022}, "4": {"k": 4, "answer": "1905", "latency_ms": 1476.7658710479736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2744}, "5": {"k": 5, "answer": "1905", "latency_ms": 485.56041717529297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3396}, "6": {"k": 6, "answer": "1905", "latency_ms": 1469.5768356323242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4053}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier FernÃ¡ndez", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Yuzuru Hanyu", "latency_ms": 2252.096652984619, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yuzuru Hanyu", "latency_ms": 2682.433843612671, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Yuzuru Hanyu", "latency_ms": 2531.6288471221924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Yuzuru Hanyu", "latency_ms": 2570.6417560577393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Yuzuru Hanyu", "latency_ms": 2079.500436782837, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2655}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 2030.134916305542, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3335}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 2466.254472732544, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4014}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "Password recovery and cracking.", "latency_ms": 2215.797185897827, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Password recovery", "latency_ms": 1751.063585281372, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "Password recovery tool", "latency_ms": 2107.3365211486816, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1391}, "3": {"k": 3, "answer": "Password recovery", "latency_ms": 1538.7766361236572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1996}, "4": {"k": 4, "answer": "Password recovery tool", "latency_ms": 1577.5246620178223, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2581}, "5": {"k": 5, "answer": "Password recovery tool", "latency_ms": 1368.6838150024414, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Password recovery tool", "latency_ms": 2075.1919746398926, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3816}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1882.0013999938965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "C. Vidyasagar Rao", "latency_ms": 3103.905200958252, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "C. Vidyasagar Rao", "latency_ms": 2992.2451972961426, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 2727.9651165008545, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 2890.7971382141113, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "C. Vidyasagar Rao", "latency_ms": 3175.8360862731934, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "C. Vidyasagar Rao", "latency_ms": 3471.611976623535, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3867}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "Channel 15", "latency_ms": 1319.3490505218506, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "15", "latency_ms": 978.2857894897461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 603}, "2": {"k": 2, "answer": "15", "latency_ms": 860.3050708770752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "15", "latency_ms": 2000.110387802124, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1919}, "4": {"k": 4, "answer": "15", "latency_ms": 1211.2138271331787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2565}, "5": {"k": 5, "answer": "15", "latency_ms": 1716.3279056549072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3205}, "6": {"k": 6, "answer": "15", "latency_ms": 712.5895023345947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3833}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Claudia Wells", "latency_ms": 2472.8128910064697, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elisabeth Shue", "latency_ms": 2647.5019454956055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Claudia Wells", "latency_ms": 2989.5787239074707, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "Claudia Wells", "latency_ms": 2431.92458152771, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 2120.1412677764893, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2422}, "5": {"k": 5, "answer": "Claudia Wells", "latency_ms": 2425.5523681640625, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "Claudia Wells", "latency_ms": 2186.229705810547, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3655}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 969.6886539459229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "London, United Kingdom", "latency_ms": 2907.1290493011475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 2464.9534225463867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 2180.6676387786865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1921}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 2970.66593170166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2570}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 2713.3774757385254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3224}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 2158.205509185791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3850}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The White House Chef", "latency_ms": 2404.797077178955, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The White House Executive Chef", "latency_ms": 2040.3988361358643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "The White House Executive Chef", "latency_ms": 2804.558753967285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "The White House Executive Chef", "latency_ms": 3273.854970932007, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2038}, "4": {"k": 4, "answer": "The White House Executive Chef", "latency_ms": 2960.505723953247, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2650}, "5": {"k": 5, "answer": "The White House Executive Chef", "latency_ms": 3534.486770629883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "The White House Executive Chef", "latency_ms": 2284.651517868042, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3944}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 1647.1436023712158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3700.3650665283203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2682.8243732452393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Nagendra Singh", "latency_ms": 2961.5981578826904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1876}, "4": {"k": 4, "answer": "B. N. Rao", "latency_ms": 2747.2431659698486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2446}, "5": {"k": 5, "answer": "B. N. Rao", "latency_ms": 1963.822603225708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3019}, "6": {"k": 6, "answer": "B. N. Rao", "latency_ms": 2954.099178314209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3643}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2370.4237937927246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "British Columbia", "latency_ms": 1541.337251663208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "British Columbia", "latency_ms": 2014.6129131317139, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "British Columbia", "latency_ms": 1012.8741264343262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1960}, "4": {"k": 4, "answer": "British Columbia", "latency_ms": 1561.9771480560303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2605}, "5": {"k": 5, "answer": "British Columbia", "latency_ms": 1494.3301677703857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3252}, "6": {"k": 6, "answer": "British Columbia", "latency_ms": 1534.1196060180664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3922}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2426.5127182006836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 11, 2018", "latency_ms": 3576.9717693328857, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "October 11, 2018", "latency_ms": 2668.264627456665, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 3436.1660480499268, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 3627.310037612915, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2668}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 4463.690996170044, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3289}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 2429.530382156372, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3934}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Jodie Sweetin", "latency_ms": 2429.147720336914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2601.2043952941895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Stephanie", "latency_ms": 2138.4711265563965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1251}, "3": {"k": 3, "answer": "Stephanie", "latency_ms": 1848.1013774871826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "Stephanie", "latency_ms": 2371.237277984619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2553}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1977.4672985076904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2151.7858505249023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "Millennium Tower", "latency_ms": 2417.556047439575, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Millennium Tower", "latency_ms": 2383.258104324341, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 2534.5499515533447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1379}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 2380.7008266448975, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2031}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 2316.052198410034, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2678}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 1567.4207210540771, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3337}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 2684.4067573547363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4033}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 1420.027494430542, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 1481.9080829620361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2967.6783084869385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "2015", "latency_ms": 1787.1873378753662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "2015", "latency_ms": 1614.6016120910645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2450}, "5": {"k": 5, "answer": "2015", "latency_ms": 1250.8716583251953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3104}, "6": {"k": 6, "answer": "2015", "latency_ms": 2019.6926593780518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3712}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "John Harlan", "latency_ms": 1696.1822509765625, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2101.179361343384, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 701}, "2": {"k": 2, "answer": "Harlan", "latency_ms": 784.942626953125, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Justice Harlan", "latency_ms": 2198.721408843994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2074}, "4": {"k": 4, "answer": "Harlan", "latency_ms": 2029.3166637420654, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2772}, "5": {"k": 5, "answer": "Justice Harlan", "latency_ms": 2030.9116840362549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3416}, "6": {"k": 6, "answer": "John Marshall Harlan", "latency_ms": 2580.2927017211914, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4097}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Tyrann Mathieu", "latency_ms": 3191.36381149292, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tyrann Mathieu", "latency_ms": 2732.393980026245, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 2747.110605239868, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 2969.38419342041, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 2482.7218055725098, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2627}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 2944.1418647766113, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 2447.6115703582764, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3941}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "44", "latency_ms": 1503.645420074463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "six", "latency_ms": 1199.1794109344482, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "six", "latency_ms": 969.0570831298828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Six", "latency_ms": 1454.2653560638428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "Six episodes", "latency_ms": 1474.6489524841309, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2698}, "5": {"k": 5, "answer": "Six episodes", "latency_ms": 2039.0894412994385, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3373}, "6": {"k": 6, "answer": "6 episodes", "latency_ms": 1781.097173690796, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4022}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul BaÃ¼mer's", "latency_ms": 2126.2831687927246, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Remarque's", "latency_ms": 2172.527313232422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "German soldiers'", "latency_ms": 2107.208251953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Erich Maria Remarque", "latency_ms": 3761.9528770446777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1866}, "4": {"k": 4, "answer": "Paul", "latency_ms": 2005.4662227630615, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2510}, "5": {"k": 5, "answer": "young soldiers", "latency_ms": 1816.2291049957275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "young soldiers", "latency_ms": 2038.3379459381104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3779}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris", "latency_ms": 1564.8746490478516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 5674.926042556763, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 6167.148590087891, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1347}, "3": {"k": 3, "answer": "Frank Morris, John Anglin, Clarence Anglin", "latency_ms": 4328.918933868408, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1973}, "4": {"k": 4, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 5431.312799453735, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2643}, "5": {"k": 5, "answer": "Frank Morris, John Anglin, Clarence Anglin", "latency_ms": 5678.836345672607, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3265}, "6": {"k": 6, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 5157.0494174957275, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3870}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF programs.", "latency_ms": 3110.433340072632, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF", "latency_ms": 1870.4969882965088, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 718}, "2": {"k": 2, "answer": "UNICEF", "latency_ms": 2405.0700664520264, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1448}, "3": {"k": 3, "answer": "UNICEF's global programming", "latency_ms": 2789.066791534424, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2142}, "4": {"k": 4, "answer": "UNICEF's global programming", "latency_ms": 3656.578302383423, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2867}, "5": {"k": 5, "answer": "UNICEF's global programming", "latency_ms": 2687.9184246063232, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3525}, "6": {"k": 6, "answer": "UNICEF's global programming", "latency_ms": 3113.2960319519043, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4214}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Tablet", "latency_ms": 1302.3459911346436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edge of the coin", "latency_ms": 2897.7861404418945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Edge of the coin", "latency_ms": 2157.064437866211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1334}, "3": {"k": 3, "answer": "Not mentioned", "latency_ms": 2228.4233570098877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "Not mentioned", "latency_ms": 1437.1192455291748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Not mentioned", "latency_ms": 2231.994152069092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Not mentioned", "latency_ms": 1017.157793045044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3811}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "Milan-Cortina, Sapporo", "latency_ms": 4137.3841762542725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2471.519947052002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "Beijing, China", "latency_ms": 2890.230417251587, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1192}, "3": {"k": 3, "answer": "Beijing, China and not specified", "latency_ms": 4817.1961307525635, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1785}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2190.3669834136963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Beijing, China and unknown", "latency_ms": 3072.41153717041, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3055}, "6": {"k": 6, "answer": "Beijing, China and unknown", "latency_ms": 3485.4559898376465, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3676}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "1981", "latency_ms": 1300.3652095794678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1997", "latency_ms": 1783.99658203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "1997", "latency_ms": 1546.5431213378906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "1997", "latency_ms": 2036.604642868042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "1997", "latency_ms": 1529.1407108306885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "1997", "latency_ms": 1254.8696994781494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "1997", "latency_ms": 1971.5487957000732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3865}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "Stone Gothic arch bridge", "latency_ms": 1922.6007461547852, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stone Bridge", "latency_ms": 1431.8320751190186, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 631}, "2": {"k": 2, "answer": "Historic bridge", "latency_ms": 2630.343198776245, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1332}, "3": {"k": 3, "answer": "Historic Stone Bridge", "latency_ms": 2669.6248054504395, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2012}, "4": {"k": 4, "answer": "Historic bridge", "latency_ms": 2499.4359016418457, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2649}, "5": {"k": 5, "answer": "Historic bridge", "latency_ms": 2605.133056640625, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3316}, "6": {"k": 6, "answer": "Historic bridge", "latency_ms": 2085.031032562256, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4002}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The Autocrat", "latency_ms": 1674.3578910827637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One person", "latency_ms": 1765.5446529388428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "One person", "latency_ms": 1238.595962524414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "One person", "latency_ms": 1477.4038791656494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1987}, "4": {"k": 4, "answer": "One person", "latency_ms": 1485.6832027435303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2637}, "5": {"k": 5, "answer": "One person", "latency_ms": 1226.9792556762695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3307}, "6": {"k": 6, "answer": "One person", "latency_ms": 1793.67995262146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3941}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "Affluence", "latency_ms": 1563.8511180877686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Late Modernism", "latency_ms": 2079.1263580322266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "return to domesticity", "latency_ms": 2124.572992324829, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Return to domesticity", "latency_ms": 2631.4542293548584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2006}, "4": {"k": 4, "answer": "Return to normalcy", "latency_ms": 2372.830867767334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "Return to domesticity", "latency_ms": 2408.325433731079, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3242}, "6": {"k": 6, "answer": "Affluence", "latency_ms": 1256.1404705047607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3967}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "Counterclockwise", "latency_ms": 1486.5920543670654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Along its trajectory", "latency_ms": 1307.9807758331299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "Counterclockwise", "latency_ms": 2197.4036693573, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "Counterclockwise", "latency_ms": 2104.970693588257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1734}, "4": {"k": 4, "answer": "Counterclockwise", "latency_ms": 2353.7964820861816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2319}, "5": {"k": 5, "answer": "Counterclockwise", "latency_ms": 2953.1776905059814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2994}, "6": {"k": 6, "answer": "Counterclockwise", "latency_ms": 2642.847776412964, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3564}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Statue of Freedom", "latency_ms": 2727.1764278411865, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Statue of Freedom", "latency_ms": 2986.309289932251, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "\"Statue of Freedom\"", "latency_ms": 3539.1829013824463, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1305}, "3": {"k": 3, "answer": "an outdoor walkway on top of the Capitol's dome", "latency_ms": 4775.331974029541, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "an outdoor walkway on top of the Capitol's dome", "latency_ms": 6167.438268661499, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "a dome", "latency_ms": 1689.8272037506104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3134}, "6": {"k": 6, "answer": "Statue of Freedom", "latency_ms": 2814.9096965789795, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "Taoyuan Leopards", "latency_ms": 2657.8209400177, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington Wizards", "latency_ms": 1418.8151359558105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "Washington Wizards", "latency_ms": 1974.8878479003906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Washington Wizards", "latency_ms": 1532.482385635376, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1880}, "4": {"k": 4, "answer": "Washington Wizards", "latency_ms": 1992.1023845672607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "Washington Wizards", "latency_ms": 2002.3274421691895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "Washington Wizards", "latency_ms": 2285.907030105591, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3709}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2142.364025115967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2622.8225231170654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Rey Mysterio", "latency_ms": 2724.963903427124, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Rey Mysterio", "latency_ms": 2687.0577335357666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1810}, "4": {"k": 4, "answer": "Rey Mysterio", "latency_ms": 3174.9470233917236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2404}, "5": {"k": 5, "answer": "Daniel Bryan", "latency_ms": 1787.8663539886475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3022}, "6": {"k": 6, "answer": "Daniel Bryan", "latency_ms": 1712.1551036834717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3647}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 1627.7568340301514, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake of the Ozarks", "latency_ms": 2975.691318511963, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Lake Oahe", "latency_ms": 2078.5067081451416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Lake Oahe", "latency_ms": 2751.865863800049, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Lake Oahe", "latency_ms": 2106.3294410705566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2518}, "5": {"k": 5, "answer": "Lake Oahe", "latency_ms": 2611.0408306121826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Lake Oahe", "latency_ms": 2380.293130874634, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3743}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Tagore", "latency_ms": 1296.7143058776855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tagore", "latency_ms": 1329.6287059783936, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 585}, "2": {"k": 2, "answer": "Tagore", "latency_ms": 1839.2374515533447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tagore", "latency_ms": 2134.3204975128174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1860}, "4": {"k": 4, "answer": "Tagore", "latency_ms": 1600.3267765045166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2471}, "5": {"k": 5, "answer": "Tagore", "latency_ms": 1243.3278560638428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3092}, "6": {"k": 6, "answer": "Tagore", "latency_ms": 1826.8227577209473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3730}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "George H.W. Bush", "latency_ms": 2740.6749725341797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Geraldine Ferraro", "latency_ms": 2742.4874305725098, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 682}, "2": {"k": 2, "answer": "Geraldine Ferraro, George H. W. Bush", "latency_ms": 5130.896091461182, "em": 0.0, "f1": 0.4444444444444444, "containment": 1.0, "context_chars": 1385}, "3": {"k": 3, "answer": "Geraldine Ferraro, George H. W. Bush", "latency_ms": 3987.8134727478027, "em": 0.0, "f1": 0.4444444444444444, "containment": 1.0, "context_chars": 2086}, "4": {"k": 4, "answer": "Geraldine Ferraro, George H. W. Bush", "latency_ms": 4921.849727630615, "em": 0.0, "f1": 0.4444444444444444, "containment": 1.0, "context_chars": 2813}, "5": {"k": 5, "answer": "Geraldine Ferraro, George H. W. Bush", "latency_ms": 5738.163709640503, "em": 0.0, "f1": 0.4444444444444444, "containment": 1.0, "context_chars": 3552}, "6": {"k": 6, "answer": "Geraldine Ferraro, George H. W. Bush", "latency_ms": 4630.918979644775, "em": 0.0, "f1": 0.4444444444444444, "containment": 1.0, "context_chars": 4250}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "American Rock Salt mine, Livingston County, New York", "latency_ms": 4157.222032546997, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Groveland", "latency_ms": 3485.452890396118, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners, Groveland", "latency_ms": 3558.101177215576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Hampton Corners, Groveland", "latency_ms": 3392.346143722534, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "Hampton Corners, Groveland, New York", "latency_ms": 4838.932275772095, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "Hampton Corners", "latency_ms": 2137.436628341675, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3054}, "6": {"k": 6, "answer": "Hampton Corners", "latency_ms": 2980.5748462677, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3783}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 1494.4307804107666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Armstrong", "latency_ms": 1723.0885028839111, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 555}, "2": {"k": 2, "answer": "Armstrong", "latency_ms": 1705.7404518127441, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1162}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 1423.2733249664307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1729}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 2006.2813758850098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2328}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 2044.5857048034668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2990}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 1958.205223083496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3580}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Meghalaya", "latency_ms": 2404.620885848999, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2194.1397190093994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2751.906394958496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1303}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2634.8044872283936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2741.2374019622803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3160.268545150757, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3194}, "6": {"k": 6, "answer": "Uttar Dinajpur", "latency_ms": 5212.5561237335205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3831}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Kanpur", "latency_ms": 1780.7855606079102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2730.1321029663086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2179.847002029419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1317}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2218.355417251587, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2012}, "4": {"k": 4, "answer": "Ludhiana", "latency_ms": 2379.7574043273926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "Ludhiana", "latency_ms": 3310.1234436035156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Ludhiana", "latency_ms": 2482.8474521636963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3798}}}
