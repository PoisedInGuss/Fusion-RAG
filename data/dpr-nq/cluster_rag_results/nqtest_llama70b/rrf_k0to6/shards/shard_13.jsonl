{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 1370.2154159545898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Molly", "latency_ms": 1455.0435543060303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2691.7269229888916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1634.1054439544678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2146.8279361724854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2490}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2127.4142265319824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3131}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3524.7113704681396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3794}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 2266.5653228759766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 2488.1269931793213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 2494.11678314209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 2143.242120742798, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1946}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 2460.7155323028564, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2568}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 2939.9306774139404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3241}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 2479.4063568115234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3873}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwest desert regions", "latency_ms": 1884.5281600952148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4674.570798873901, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4646.873474121094, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4938.985347747803, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 5035.262823104858, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2613}, "5": {"k": 5, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 5768.486976623535, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3217}, "6": {"k": 6, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 6001.346588134766, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3887}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 2560.2622032165527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dr. Rajendra Prasad", "latency_ms": 3324.7833251953125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 743}, "2": {"k": 2, "answer": "Dr. Rajendra Prasad", "latency_ms": 3966.296911239624, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1429}, "3": {"k": 3, "answer": "Dr. Rajendra Prasad", "latency_ms": 3891.449451446533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2127}, "4": {"k": 4, "answer": "Dr. Rajendra Prasad", "latency_ms": 3358.5288524627686, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2812}, "5": {"k": 5, "answer": "Sachchidananda Sinha", "latency_ms": 4408.867835998535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3414}, "6": {"k": 6, "answer": "Sachchidananda Sinha", "latency_ms": 2858.741283416748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4113}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2118.2069778442383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3672.299385070801, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2695.786476135254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2789.4067764282227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "10pm", "latency_ms": 1171.5893745422363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1998.2068538665771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3263}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2259.795665740967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3841}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "June 22, 2001", "latency_ms": 3199.8870372772217, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2001", "latency_ms": 2861.8948459625244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "2001", "latency_ms": 1506.8364143371582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1265}, "3": {"k": 3, "answer": "2001", "latency_ms": 1669.987678527832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "2001", "latency_ms": 2063.835382461548, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2528}, "5": {"k": 5, "answer": "2001", "latency_ms": 1980.0865650177002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3161}, "6": {"k": 6, "answer": "2001", "latency_ms": 1067.1193599700928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3803}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1902.5566577911377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 3334.4643115997314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 3922.268867492676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 2801.2218475341797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 2737.5621795654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2666}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 3601.9561290740967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3372}, "6": {"k": 6, "answer": "September 27, 2017", "latency_ms": 2907.2649478912354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4119}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3", "latency_ms": 2404.3893814086914, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sectionals", "latency_ms": 1673.4986305236816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Sectionals", "latency_ms": 2361.5970611572266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "Sectionals", "latency_ms": 1554.3453693389893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Sectionals", "latency_ms": 1978.1997203826904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2430}, "5": {"k": 5, "answer": "In \"Sectionals\"", "latency_ms": 2738.9488220214844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3019}, "6": {"k": 6, "answer": "In \"Sectionals\"", "latency_ms": 3326.674461364746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2206.3992023468018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2108.4892749786377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2183.1700801849365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2185.295820236206, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2402.172327041626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2935.236692428589, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3188}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2692.805051803589, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3792}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 1152.8737545013428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Havana Harbor, Cuba.", "latency_ms": 2658.0607891082764, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Havana Harbor, Cuba.", "latency_ms": 3202.4097442626953, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Havana Harbor", "latency_ms": 1502.6299953460693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "Havana Harbor", "latency_ms": 2532.9275131225586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Havana Harbor, Cuba", "latency_ms": 2509.571313858032, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3065}, "6": {"k": 6, "answer": "Havana Harbor, Cuba", "latency_ms": 2569.0793991088867, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3692}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 1407.3493480682373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2531.1825275421143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1899.970293045044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "No specific god mentioned", "latency_ms": 2645.059823989868, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1935}, "4": {"k": 4, "answer": "No specific god mentioned", "latency_ms": 1664.900779724121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Lord Vishnu and Lord Shiva and Ganesha", "latency_ms": 4587.092876434326, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3225}, "6": {"k": 6, "answer": "Lord Vishnu and Lord Shiva", "latency_ms": 3093.865156173706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 2761.4264488220215, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "All of them", "latency_ms": 1094.3527221679688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Honduras, Nicaragua", "latency_ms": 2964.1730785369873, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1356}, "3": {"k": 3, "answer": "All of them", "latency_ms": 1894.0742015838623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "Costa Rica, Nicaragua, Panama, Guatemala, Honduras, El Salvador", "latency_ms": 6167.102098464966, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2639}, "5": {"k": 5, "answer": "Costa Rica, Nicaragua, Panama, Honduras, Guatemala, El Salvador, Belize", "latency_ms": 7217.808485031128, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3324}, "6": {"k": 6, "answer": "Costa Rica, Nicaragua", "latency_ms": 2257.096529006958, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3983}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence.", "latency_ms": 1876.6272068023682, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 1767.8132057189941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Complex sentence", "latency_ms": 2358.804702758789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Complex sentence", "latency_ms": 1717.6239490509033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1977}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 2165.4796600341797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2683}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 2106.109857559204, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3371}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 2179.0363788604736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4097}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and trade.", "latency_ms": 2594.785213470459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 5339.921474456787, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 4226.434230804443, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3653.977155685425, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3836.7650508880615, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 2533}, "5": {"k": 5, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3462.6641273498535, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "the nature and causes of the wealth of nations", "latency_ms": 5103.616714477539, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3840}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 3388.9763355255127, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "August 28, 2018", "latency_ms": 3386.5530490875244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "August 28, 2018", "latency_ms": 3557.3604106903076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 3122.4639415740967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 4194.936752319336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 3604.6903133392334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 3627.2635459899902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere", "latency_ms": 3320.462226867676, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northern Territory", "latency_ms": 1830.4202556610107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "Northern Territory of Australia", "latency_ms": 2185.6842041015625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1370}, "3": {"k": 3, "answer": "Northern Territory of Australia, Western Australia, Queensland", "latency_ms": 2949.3727684020996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2036}, "4": {"k": 4, "answer": "Northern Territory of Australia", "latency_ms": 2715.0840759277344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2664}, "5": {"k": 5, "answer": "Northern Territory and Western Australia", "latency_ms": 2415.4818058013916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3373}, "6": {"k": 6, "answer": "Southern part of Northern Territory and Western Australia", "latency_ms": 3189.683437347412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4026}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Leia Organa", "latency_ms": 2916.0735607147217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2172.488212585449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "her", "latency_ms": 1215.759515762329, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "her", "latency_ms": 1185.5130195617676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "her", "latency_ms": 921.8947887420654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2436}, "5": {"k": 5, "answer": "Her", "latency_ms": 1751.2774467468262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2972}, "6": {"k": 6, "answer": "Mara", "latency_ms": 1579.2419910430908, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3602}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 2256.7052841186523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Barry Cryer", "latency_ms": 2854.9458980560303, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 548}, "2": {"k": 2, "answer": "Barry Cryer", "latency_ms": 1865.4701709747314, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1196}, "3": {"k": 3, "answer": "Barry Cryer", "latency_ms": 2818.7243938446045, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1779}, "4": {"k": 4, "answer": "Barry Cryer", "latency_ms": 2446.2430477142334, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2329}, "5": {"k": 5, "answer": "Barry Cryer", "latency_ms": 1702.0246982574463, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2924}, "6": {"k": 6, "answer": "Barry Cryer", "latency_ms": 1880.262851715088, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3540}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 1843.919277191162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chloroplast", "latency_ms": 2319.5009231567383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Chloroplast and Mitochondrion", "latency_ms": 2713.793992996216, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1366}, "3": {"k": 3, "answer": "Chloroplast, Mitochondrion", "latency_ms": 3161.3645553588867, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2023}, "4": {"k": 4, "answer": "Mitochondrion", "latency_ms": 1898.70023727417, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2715}, "5": {"k": 5, "answer": "Mitochondria and Chloroplasts", "latency_ms": 2821.746349334717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3391}, "6": {"k": 6, "answer": "Mitochondria and Chloroplasts", "latency_ms": 3527.214527130127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4042}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Backup.", "latency_ms": 5471.46463394165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2125.8792877197266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2394.4902420043945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1400}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2163.445472717285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2155}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3041.638135910034, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2838}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2078.2408714294434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3477}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1980.006217956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4139}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 4165.911912918091, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenny Rogers and Dottie West", "latency_ms": 2976.970911026001, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 590}, "2": {"k": 2, "answer": "Kenny Rogers and Dottie West", "latency_ms": 2961.8918895721436, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1203}, "3": {"k": 3, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3515.2428150177, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "Kenny Rogers and Dottie West", "latency_ms": 4144.54460144043, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2446}, "5": {"k": 5, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3635.080099105835, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3064}, "6": {"k": 6, "answer": "Kenny Rogers and Dottie West", "latency_ms": 4611.73939704895, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3665}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 1278.2955169677734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "36 months", "latency_ms": 2241.065502166748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 601}, "2": {"k": 2, "answer": "36 months", "latency_ms": 1508.7289810180664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "36 months", "latency_ms": 1804.476022720337, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1911}, "4": {"k": 4, "answer": "36 months old", "latency_ms": 1539.7348403930664, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "36 months old", "latency_ms": 2550.0149726867676, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3024}, "6": {"k": 6, "answer": "36 months", "latency_ms": 1493.6532974243164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3602}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 1480.5800914764404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 982.4824333190918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "Three", "latency_ms": 1208.432674407959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1317}, "3": {"k": 3, "answer": "Three", "latency_ms": 969.8538780212402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Three", "latency_ms": 1493.5433864593506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2580}, "5": {"k": 5, "answer": "Three", "latency_ms": 1481.5902709960938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "Three", "latency_ms": 1195.866584777832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3881}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 8144.414186477661, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elijah Wood", "latency_ms": 2642.740249633789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Elijah Wood", "latency_ms": 1629.110336303711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1301}, "3": {"k": 3, "answer": "Elijah Wood", "latency_ms": 2167.0877933502197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1967}, "4": {"k": 4, "answer": "Elijah Wood, Ian Holm", "latency_ms": 4028.5260677337646, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2573}, "5": {"k": 5, "answer": "Elijah Wood, Ian Holm", "latency_ms": 3154.0443897247314, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3159}, "6": {"k": 6, "answer": "Elijah Wood", "latency_ms": 2409.714698791504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3812}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party", "latency_ms": 2089.1098976135254, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume party", "latency_ms": 2598.076581954956, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Costume", "latency_ms": 1169.142484664917, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1200}, "3": {"k": 3, "answer": "Costume", "latency_ms": 2401.4837741851807, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Costume", "latency_ms": 1230.611801147461, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2533}, "5": {"k": 5, "answer": "Costume party", "latency_ms": 2651.0844230651855, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3205}, "6": {"k": 6, "answer": "Costume party", "latency_ms": 2390.526294708252, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3774}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 925.29296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2941.8423175811768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 686}, "2": {"k": 2, "answer": "1", "latency_ms": 916.6548252105713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "1", "latency_ms": 1741.7898178100586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "1", "latency_ms": 1233.964443206787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "1", "latency_ms": 1980.6768894195557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "1", "latency_ms": 1252.0198822021484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3848}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "He promised Fantine", "latency_ms": 2190.8247470855713, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fantine's debts", "latency_ms": 2700.018882751465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "Fantine's debts", "latency_ms": 2674.950122833252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Fantine's request", "latency_ms": 1970.0913429260254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "Fantine's debts", "latency_ms": 2714.962959289551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "Fantine's debts", "latency_ms": 2179.38494682312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3086}, "6": {"k": 6, "answer": "Fantine's request", "latency_ms": 1992.1290874481201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3684}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, and South Korea.", "latency_ms": 3767.940044403076, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenya", "latency_ms": 1947.4222660064697, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "Kenya", "latency_ms": 2060.9054565429688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1382}, "3": {"k": 3, "answer": "Kenya", "latency_ms": 2067.8553581237793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2083}, "4": {"k": 4, "answer": "Kenya, Russia, India", "latency_ms": 3296.9136238098145, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2794}, "5": {"k": 5, "answer": "Kenya, Russia, India, Canada", "latency_ms": 4530.961990356445, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3521}, "6": {"k": 6, "answer": "Kenya, India, Russia, Canada, United Kingdom", "latency_ms": 6664.852857589722, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 4240}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and control.", "latency_ms": 2362.027883529663, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to consolidate Bantu education", "latency_ms": 2466.731309890747, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 714}, "2": {"k": 2, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 6437.889337539673, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "to consolidate Bantu education", "latency_ms": 3471.648931503296, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 6473.1481075286865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7274.4810581207275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 6681.153774261475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4119}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 2118.6604499816895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 2226.5071868896484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 2718.524217605591, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Huge and powerful snake", "latency_ms": 2818.8652992248535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1759}, "4": {"k": 4, "answer": "Python", "latency_ms": 1676.9847869873047, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2384}, "5": {"k": 5, "answer": "Python", "latency_ms": 712.6150131225586, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "Python", "latency_ms": 1712.6996517181396, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3616}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 1753.4794807434082, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ice", "latency_ms": 1443.329095840454, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "water-ice", "latency_ms": 2112.5876903533936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "water-ice", "latency_ms": 1546.3035106658936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "water-ice", "latency_ms": 1791.487693786621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2461}, "5": {"k": 5, "answer": "water-ice", "latency_ms": 2019.4575786590576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3037}, "6": {"k": 6, "answer": "water-ice", "latency_ms": 2717.6856994628906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3686}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 3698.636293411255, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Not in season 2.", "latency_ms": 3003.9477348327637, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "The Departed", "latency_ms": 2293.017864227295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "The Departed episode", "latency_ms": 2403.355360031128, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "At the end of season 3", "latency_ms": 3104.499578475952, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2382}, "5": {"k": 5, "answer": "Season 3 finale", "latency_ms": 2407.6545238494873, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2944}, "6": {"k": 6, "answer": "At the end of season 3", "latency_ms": 3648.0231285095215, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3544}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "Home team", "latency_ms": 1571.2051391601562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Premier League clubs", "latency_ms": 2566.028356552124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2177.32310295105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1168}, "3": {"k": 3, "answer": "Team named first", "latency_ms": 2690.260648727417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1749}, "4": {"k": 4, "answer": "the team named first", "latency_ms": 2410.8517169952393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2336}, "5": {"k": 5, "answer": "the team named first", "latency_ms": 2898.243188858032, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2942}, "6": {"k": 6, "answer": "the team named first", "latency_ms": 2687.249183654785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3589}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw neighborhood", "latency_ms": 1941.1299228668213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northwest", "latency_ms": 2016.5927410125732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "Northwest Washington, DC", "latency_ms": 2846.5869426727295, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Northwest", "latency_ms": 2102.175712585449, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "Northwest Washington, DC", "latency_ms": 3207.43465423584, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2831}, "5": {"k": 5, "answer": "Northwest Washington, DC", "latency_ms": 3086.2491130828857, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3491}, "6": {"k": 6, "answer": "Northwest", "latency_ms": 2098.1736183166504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4153}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 1306.3151836395264, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mosaic covenant", "latency_ms": 2395.9274291992188, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 609}, "2": {"k": 2, "answer": "Mosaic covenant", "latency_ms": 2036.4575386047363, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Noahic", "latency_ms": 2043.442726135254, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1878}, "4": {"k": 4, "answer": "Noahic", "latency_ms": 2906.9910049438477, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Noahic", "latency_ms": 2404.2954444885254, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3188}, "6": {"k": 6, "answer": "Noahic", "latency_ms": 2380.7520866394043, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3744}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 1923.8948822021484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2114.4561767578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2604.419231414795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1164}, "3": {"k": 3, "answer": "Jack Jones", "latency_ms": 1657.9058170318604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1735}, "4": {"k": 4, "answer": "Jack Jones", "latency_ms": 1844.266414642334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2315}, "5": {"k": 5, "answer": "a singer", "latency_ms": 2446.0558891296387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2888}, "6": {"k": 6, "answer": "a singer", "latency_ms": 2082.5352668762207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3491}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2456.271171569824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Anna King", "latency_ms": 2002.3918151855469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Anna King", "latency_ms": 1805.1135540008545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "Rudy ValleÃÅe", "latency_ms": 2732.761859893799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1793}, "4": {"k": 4, "answer": "Ray Henderson", "latency_ms": 2350.0189781188965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2437}, "5": {"k": 5, "answer": "Ray Henderson", "latency_ms": 1615.6258583068848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3072}, "6": {"k": 6, "answer": "Ray Henderson", "latency_ms": 2357.001543045044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3723}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 2231.5831184387207, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 1782.4478149414062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 2092.164993286133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 2148.7066745758057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 1823.7314224243164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2529}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 1855.8616638183594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3176}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 1795.8199977874756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3827}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "2nd", "latency_ms": 1461.2336158752441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3064.805746078491, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3109.3053817749023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2932.138681411743, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1925}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2964.5793437957764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2186.8197917938232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2814.009189605713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 1912.9505157470703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mahatma Gandhi", "latency_ms": 2389.1680240631104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 706}, "2": {"k": 2, "answer": "Sonia Gandhi", "latency_ms": 2301.238775253296, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1380}, "3": {"k": 3, "answer": "Sonia Gandhi", "latency_ms": 2200.99139213562, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2102}, "4": {"k": 4, "answer": "Sonia Gandhi", "latency_ms": 1598.2701778411865, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2798}, "5": {"k": 5, "answer": "Jawaharlal Nehru", "latency_ms": 2284.463882446289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3473}, "6": {"k": 6, "answer": "Jawaharlal Nehru", "latency_ms": 2451.162576675415, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4183}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenifer Lewis", "latency_ms": 2165.987968444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bobby Flay", "latency_ms": 2918.5664653778076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Bobby Flay", "latency_ms": 2045.8948612213135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Bobby Flay", "latency_ms": 2684.304714202881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Bobby Flay", "latency_ms": 2464.3874168395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2536}, "5": {"k": 5, "answer": "Bobby Flay", "latency_ms": 2667.562484741211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "Bobby Flay", "latency_ms": 3254.0643215179443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 214.32232856750488, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 2179.5098781585693, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": ".java", "latency_ms": 667.8972244262695, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": ".java", "latency_ms": 2251.530170440674, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": ".java", "latency_ms": 1228.602647781372, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": ".java", "latency_ms": 1707.8616619110107, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3218}, "6": {"k": 6, "answer": ".java", "latency_ms": 1152.7290344238281, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3910}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 1307.237148284912, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Polish Cipher Bureau", "latency_ms": 2615.8318519592285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Poland", "latency_ms": 1961.4813327789307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "Poland", "latency_ms": 2542.269468307495, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "Poland, Britain, and France", "latency_ms": 4137.728452682495, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2669}, "5": {"k": 5, "answer": "Poland", "latency_ms": 1748.4815120697021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3396}, "6": {"k": 6, "answer": "Poland, then Britain and France", "latency_ms": 3910.9368324279785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4068}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline", "latency_ms": 2483.35337638855, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "bargain for votes", "latency_ms": 2738.0669116973877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "Offer promotion or threaten demotion within the committee system.", "latency_ms": 5371.838808059692, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "ensure members adhere to party policies", "latency_ms": 3305.4187297821045, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "ensure members adhere to party policies", "latency_ms": 3093.7623977661133, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 2586}, "5": {"k": 5, "answer": "ensure members adhere to party policies", "latency_ms": 4094.0864086151123, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 3310}, "6": {"k": 6, "answer": "ensure members adhere to party policies", "latency_ms": 3731.712818145752, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 4003}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 1523.8323211669922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1979", "latency_ms": 2490.800142288208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 576}, "2": {"k": 2, "answer": "1973", "latency_ms": 1529.9038887023926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1131}, "3": {"k": 3, "answer": "1973", "latency_ms": 2375.1211166381836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1773}, "4": {"k": 4, "answer": "1973", "latency_ms": 2218.642234802246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "1973", "latency_ms": 1373.0354309082031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3056}, "6": {"k": 6, "answer": "1973", "latency_ms": 1743.8549995422363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3755}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the‚Äã right but not the‚Äã obligation to buy foreign‚Äã currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 2309.2212677001953, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 1252.5746822357178, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 1831.5553665161133, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 1655.6940078735352, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "FX option", "latency_ms": 1492.4745559692383, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2671}, "5": {"k": 5, "answer": "Call option", "latency_ms": 2195.4197883605957, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "FX option", "latency_ms": 775.3348350524902, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3842}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 1697.5173950195312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 1725.0401973724365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360", "latency_ms": 1416.184663772583, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1380}, "3": {"k": 3, "answer": "360", "latency_ms": 1984.0736389160156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2035}, "4": {"k": 4, "answer": "360 members", "latency_ms": 738.7006282806396, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "360 members", "latency_ms": 1999.7172355651855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3315}, "6": {"k": 6, "answer": "360", "latency_ms": 938.6248588562012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4009}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 1658.447265625, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 2955.9850692749023, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 2432.9395294189453, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 2222.2518920898438, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 3270.2555656433105, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 3400.786876678467, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3224}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 2749.5133876800537, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3892}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gorm√©"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 2502.542495727539, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eydie Gorm√©", "latency_ms": 2767.7295207977295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 580}, "2": {"k": 2, "answer": "Eydie Gorm√©", "latency_ms": 4488.170385360718, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1156}, "3": {"k": 3, "answer": "Eydie Gorm√©", "latency_ms": 2787.461042404175, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1733}, "4": {"k": 4, "answer": "Eydie Gorm√©", "latency_ms": 4037.6691818237305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2334}, "5": {"k": 5, "answer": "Eydie Gorm√©", "latency_ms": 2843.5285091400146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2899}, "6": {"k": 6, "answer": "Eydie Gorm√©", "latency_ms": 3551.839590072632, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3530}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2111.140012741089, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ashok Bhushan", "latency_ms": 3503.5202503204346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 562}, "2": {"k": 2, "answer": "Ashok Bhushan", "latency_ms": 2255.2895545959473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1083}, "3": {"k": 3, "answer": "Ashok Bhushan", "latency_ms": 2901.108741760254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1698}, "4": {"k": 4, "answer": "Ashok Bhushan", "latency_ms": 3243.4282302856445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2310}, "5": {"k": 5, "answer": "Ashok Bhushan", "latency_ms": 2793.3194637298584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2867}, "6": {"k": 6, "answer": "Ashok Bhushan", "latency_ms": 2277.1153450012207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3479}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2489.567279815674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nadal", "latency_ms": 2005.2764415740967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 576}, "2": {"k": 2, "answer": "Rafael Nadal", "latency_ms": 3051.922559738159, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "Rafael Nadal", "latency_ms": 2997.0638751983643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "Rafael Nadal", "latency_ms": 3059.0176582336426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2490}, "5": {"k": 5, "answer": "Rafael Nadal", "latency_ms": 2467.149496078491, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3076}, "6": {"k": 6, "answer": "Rafael Nadal", "latency_ms": 3004.239559173584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3697}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 936.485767364502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 1486.9239330291748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 877.3689270019531, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1215}, "3": {"k": 3, "answer": "1", "latency_ms": 706.2532901763916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "1", "latency_ms": 921.727180480957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2442}, "5": {"k": 5, "answer": "1", "latency_ms": 1086.7135524749756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3025}, "6": {"k": 6, "answer": "1", "latency_ms": 1150.869369506836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3624}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 1798.6371517181396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2010", "latency_ms": 2282.273054122925, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "2010", "latency_ms": 1503.6699771881104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1275}, "3": {"k": 3, "answer": "2010", "latency_ms": 2011.331558227539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "2010", "latency_ms": 1494.755506515503, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2522}, "5": {"k": 5, "answer": "2010", "latency_ms": 2334.3734741210938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3047}, "6": {"k": 6, "answer": "2010", "latency_ms": 1315.7894611358643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3736}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 1012.505292892456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2926.250696182251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "17", "latency_ms": 1664.9765968322754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "17", "latency_ms": 1426.426887512207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "37", "latency_ms": 1476.2039184570312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "37", "latency_ms": 2014.1632556915283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "37", "latency_ms": 1727.0605564117432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3818}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 2567.1534538269043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 2221.846342086792, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 3812.842607498169, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 3390.3496265411377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 3076.836109161377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2502}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 2790.910005569458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 3243.2405948638916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3804}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 5272.313117980957, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 2176.175832748413, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "Corey, Cory", "latency_ms": 2117.0215606689453, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1192}, "3": {"k": 3, "answer": "Corey, Cory", "latency_ms": 2123.5597133636475, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "Corey, Cory", "latency_ms": 2122.783422470093, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2429}, "5": {"k": 5, "answer": "Corey, Cory", "latency_ms": 2479.7732830047607, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3060}, "6": {"k": 6, "answer": "Corey, Cory", "latency_ms": 3106.8966388702393, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3623}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 1931.9038391113281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2629.9052238464355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3066.4072036743164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1203}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2382.204294204712, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2894.1802978515625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2443}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2671.1320877075195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2005.5103302001953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3753}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 969.3608283996582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 938.5838508605957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "159", "latency_ms": 1653.0585289001465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "159", "latency_ms": 1460.216760635376, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "159", "latency_ms": 1667.7675247192383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2738}, "5": {"k": 5, "answer": "159", "latency_ms": 1674.365758895874, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3387}, "6": {"k": 6, "answer": "159", "latency_ms": 1139.780044555664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4092}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 2361.7448806762695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2109.7583770751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "Egan", "latency_ms": 1534.388780593872, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "Egan", "latency_ms": 1668.266773223877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1797}, "4": {"k": 4, "answer": "Egan", "latency_ms": 1756.3295364379883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2433}, "5": {"k": 5, "answer": "Egan", "latency_ms": 1771.2011337280273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3107}, "6": {"k": 6, "answer": "Egan", "latency_ms": 1468.5828685760498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3720}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 2042.9775714874268, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wilt Chamberlain and Adrian Dantley", "latency_ms": 4818.201541900635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Wilt Chamberlain", "latency_ms": 3126.636028289795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1184}, "3": {"k": 3, "answer": "Wilt Chamberlain", "latency_ms": 2400.982618331909, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1782}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2947.892427444458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2375}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3459.0442180633545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2957}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2882.2154998779297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3625}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 3004.6634674072266, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Right hand", "latency_ms": 1684.22532081604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 1838.942289352417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1185}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 1229.9399375915527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1739}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 2210.089921951294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2303}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 1948.0116367340088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2911}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 2289.8995876312256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3525}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 3124.6187686920166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Goofy", "latency_ms": 2353.1601428985596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3181.763172149658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Pete", "latency_ms": 1332.9458236694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Donald Duck", "latency_ms": 2306.969165802002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2541}, "5": {"k": 5, "answer": "Donald Duck", "latency_ms": 2075.0718116760254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3176}, "6": {"k": 6, "answer": "Donald Duck", "latency_ms": 1302.276849746704, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3822}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 2152.7657508850098, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1838.8724327087402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "Bernard Mayes", "latency_ms": 2335.461378097534, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "Bernard Mayes", "latency_ms": 2901.9806385040283, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1821}, "4": {"k": 4, "answer": "Bernard Mayes", "latency_ms": 2374.2752075195312, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Bernard Mayes", "latency_ms": 2153.632879257202, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "Bernard Mayes", "latency_ms": 1484.6901893615723, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3721}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2019", "latency_ms": 2986.652612686157, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2018", "latency_ms": 3302.3693561553955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 3320.197343826294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 2253.5147666931152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 3173.0706691741943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2414}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 4456.92777633667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3010}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 3965.250253677368, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3640}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 1504.5032501220703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1931.7646026611328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2993.598461151123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3247.7798461914062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1921.5099811553955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3397.3565101623535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2484.76243019104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3855}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 1257.3883533477783, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2570.863962173462, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "Claire Holt", "latency_ms": 1875.9822845458984, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1251}, "3": {"k": 3, "answer": "Claire Holt", "latency_ms": 1765.9728527069092, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Claire Holt", "latency_ms": 1866.7874336242676, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Claire Holt", "latency_ms": 2373.758316040039, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Claire Holt", "latency_ms": 2522.2702026367188, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3793}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living things", "latency_ms": 2647.5472450256348, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in wood or soil", "latency_ms": 2973.3378887176514, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 705}, "2": {"k": 2, "answer": "in wood, soil, plants, and animals' digestive tracts", "latency_ms": 4298.813343048096, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "in wood, soil, plants, and animals", "latency_ms": 4206.310510635376, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "in plants, soil, and organisms", "latency_ms": 3922.868490219116, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2760}, "5": {"k": 5, "answer": "in plants, soil, and organisms", "latency_ms": 3393.4881687164307, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3383}, "6": {"k": 6, "answer": "in all land-living organisms, soils, plants, and animals", "latency_ms": 4997.765302658081, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4085}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2014.1451358795166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chandan Shetty", "latency_ms": 3383.8143348693848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "Chandan Shetty", "latency_ms": 1940.194845199585, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Chandan Shetty", "latency_ms": 3071.2006092071533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "Chandan Shetty", "latency_ms": 2403.249502182007, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2509}, "5": {"k": 5, "answer": "Chandan Shetty", "latency_ms": 1944.4408416748047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3122}, "6": {"k": 6, "answer": "Chandan Shetty", "latency_ms": 2690.6261444091797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3751}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 3112.977981567383, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2678.7641048431396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1913.5866165161133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3230.518102645874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2698.1942653656006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2493}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3206.524610519409, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3126}, "6": {"k": 6, "answer": "Lake Powell", "latency_ms": 1263.5223865509033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3779}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 2509.9332332611084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jesper Klein", "latency_ms": 2363.872766494751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2848.0939865112305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2422.1434593200684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1875}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2301.482677459717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3054.159164428711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3175}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2640.9831047058105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3866}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Lake Winnipeg", "latency_ms": 2800.9939193725586, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 2243.3292865753174, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Rocky Mountains to Lake Winnipeg", "latency_ms": 3027.998447418213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 2499.8505115509033, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 2656.6975116729736, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2698}, "5": {"k": 5, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 2666.017532348633, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3345}, "6": {"k": 6, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 2749.492883682251, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3989}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 1520.765781402588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 1528.7835597991943, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome", "latency_ms": 825.9415626525879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Rome, Italy", "latency_ms": 1319.4594383239746, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1893}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 3083.7478637695312, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 2120.077133178711, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3096}, "6": {"k": 6, "answer": "Rome", "latency_ms": 1985.2845668792725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3697}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "Measurement mark", "latency_ms": 1250.4348754882812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "batch code", "latency_ms": 2239.6492958068848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "manufacturing company or site", "latency_ms": 1983.325719833374, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "manufacturing company or site", "latency_ms": 3195.265054702759, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "the manufacturing company or site", "latency_ms": 3351.794719696045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2500}, "5": {"k": 5, "answer": "the manufacturing company or site", "latency_ms": 3773.395538330078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3121}, "6": {"k": 6, "answer": "the manufacturing company or site", "latency_ms": 2237.576484680176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3725}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia", "latency_ms": 3147.541046142578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 3613.0969524383545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 4797.875642776489, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1352}, "3": {"k": 3, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 4228.213787078857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1952}, "4": {"k": 4, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 4475.791692733765, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 4950.316667556763, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3156}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 4529.820680618286, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3766}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Boy Meets Girl", "latency_ms": 2197.8025436401367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 1512.9427909851074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "1988", "latency_ms": 1766.693115234375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1196}, "3": {"k": 3, "answer": "1988", "latency_ms": 2328.9132118225098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1785}, "4": {"k": 4, "answer": "1988", "latency_ms": 1463.2823467254639, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2388}, "5": {"k": 5, "answer": "1988", "latency_ms": 1556.6112995147705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3016}, "6": {"k": 6, "answer": "1988", "latency_ms": 2345.8104133605957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3673}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 775.3937244415283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tute", "latency_ms": 1818.7823295593262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "Tute", "latency_ms": 1500.840425491333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1155}, "3": {"k": 3, "answer": "Tute", "latency_ms": 1770.5988883972168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1818}, "4": {"k": 4, "answer": "Tute", "latency_ms": 1518.8570022583008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2419}, "5": {"k": 5, "answer": "Tute", "latency_ms": 1453.1266689300537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2992}, "6": {"k": 6, "answer": "Truco", "latency_ms": 2035.8989238739014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3591}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 2142.425537109375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Five percent", "latency_ms": 1961.2016677856445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "5%", "latency_ms": 1739.1273975372314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1317}, "3": {"k": 3, "answer": "2% to 16%", "latency_ms": 3743.9181804656982, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 3540.4300689697266, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2533}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 2687.7682209014893, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3238}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 2664.099931716919, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3867}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 2020.4980373382568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1975", "latency_ms": 2025.2416133880615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "1975", "latency_ms": 2226.783275604248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1215}, "3": {"k": 3, "answer": "1975", "latency_ms": 1501.8610954284668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1790}, "4": {"k": 4, "answer": "1975", "latency_ms": 1812.6378059387207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2368}, "5": {"k": 5, "answer": "1975", "latency_ms": 1749.389886856079, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3067}, "6": {"k": 6, "answer": "1975", "latency_ms": 1727.7641296386719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3648}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 2697.431802749634, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2911.5610122680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 594}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2505.5413246154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2945.329427719116, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 2121.485710144043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 3185.1491928100586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3084}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 2431.64324760437, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3699}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert", "latency_ms": 2205.9991359710693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Leonard Calvert", "latency_ms": 2360.865354537964, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 688}, "2": {"k": 2, "answer": "Lord Baltimore's first settlers and Leonard Calvert", "latency_ms": 3129.0628910064697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Lord Baltimore's first settlers", "latency_ms": 2593.644618988037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "Lord Baltimore's first settlers, including Leonard Calvert", "latency_ms": 4968.271017074585, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2647}, "5": {"k": 5, "answer": "Lord Baltimore's first settlers, including Leonard Calvert", "latency_ms": 4798.517465591431, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3341}, "6": {"k": 6, "answer": "Lord Baltimore's first settlers, including his younger brother Leonard Calvert", "latency_ms": 5562.962293624878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3951}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 2012.4304294586182, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2639.9455070495605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "Tiger Woods", "latency_ms": 2300.485849380493, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Tiger Woods", "latency_ms": 1784.557580947876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1929}, "4": {"k": 4, "answer": "Tiger Woods", "latency_ms": 1914.5381450653076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2610}, "5": {"k": 5, "answer": "Tiger Woods", "latency_ms": 2546.135425567627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "Tiger Woods", "latency_ms": 1859.334945678711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3954}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 1942.4200057983398, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2644.3886756896973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "200 to 500 mg", "latency_ms": 3526.0531902313232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg", "latency_ms": 3213.0985260009766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "200 to 500 mg", "latency_ms": 2082.7338695526123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2488}, "5": {"k": 5, "answer": "200 to 500 mg", "latency_ms": 3465.9347534179688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3126}, "6": {"k": 6, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 4500.390529632568, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3753}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 2024.5699882507324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham", "latency_ms": 1534.8544120788574, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 1891.8395042419434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1166}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 2291.1159992218018, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1758}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 1557.103157043457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2277}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 1713.1056785583496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2837}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 2023.7219333648682, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3435}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 1491.7418956756592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hotel beverage rooms", "latency_ms": 1913.29026222229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 685}, "2": {"k": 2, "answer": "hotel beverage rooms", "latency_ms": 2118.8032627105713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1360}, "3": {"k": 3, "answer": "hotel beverage rooms", "latency_ms": 1747.480869293213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2081}, "4": {"k": 4, "answer": "hotel beverage rooms", "latency_ms": 2479.710102081299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2799}, "5": {"k": 5, "answer": "Hotel beverage rooms", "latency_ms": 1457.3607444763184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3492}, "6": {"k": 6, "answer": "hotel beverage rooms", "latency_ms": 1713.6225700378418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4168}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh", "latency_ms": 1874.894142150879, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 1620.3105449676514, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 2178.6553859710693, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1372}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 1904.8662185668945, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2057}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 2143.1732177734375, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 2700.877904891968, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3406}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 2656.5897464752197, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4109}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 1836.1921310424805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2406.618118286133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2435.0361824035645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "Bray Wyatt", "latency_ms": 2092.646360397339, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "Bray Wyatt", "latency_ms": 2496.13881111145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2660}, "5": {"k": 5, "answer": "Bray Wyatt", "latency_ms": 2260.8842849731445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3321}, "6": {"k": 6, "answer": "Bray Wyatt", "latency_ms": 2265.7904624938965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3989}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 2562.90864944458, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Southport, North Carolina", "latency_ms": 3891.028881072998, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Southport, North Carolina.", "latency_ms": 4834.73801612854, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Southport, North Carolina", "latency_ms": 2635.909080505371, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Southport, North Carolina.", "latency_ms": 3891.521692276001, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "Southport, North Carolina.", "latency_ms": 2778.418779373169, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3061}, "6": {"k": 6, "answer": "Southport, North Carolina.", "latency_ms": 3026.024580001831, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3695}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 2450.0110149383545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2417.0987606048584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "Sylvia F. Porter", "latency_ms": 2806.2353134155273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Sylvia F. Porter", "latency_ms": 3063.403844833374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1979}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 2391.9520378112793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2588}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 2473.4156131744385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3269}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 2293.1365966796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3907}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 1726.4277935028076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 2138.2315158843994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 704}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 2065.51456451416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1441}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 2814.7332668304443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2157}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 2360.379934310913, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2828}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 1870.4328536987305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3522}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 2295.8807945251465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4278}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 715.0771617889404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 1209.078311920166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "Max", "latency_ms": 1266.8147087097168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Max", "latency_ms": 1467.9782390594482, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1875}, "4": {"k": 4, "answer": "Max", "latency_ms": 879.0154457092285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Max", "latency_ms": 1487.656831741333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Max", "latency_ms": 716.4211273193359, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 2454.552412033081, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2650.1805782318115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2300.656795501709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2627.1891593933105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2936.8631839752197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "Megan Follows", "latency_ms": 2301.6557693481445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "Megan Follows", "latency_ms": 2596.5235233306885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3695}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "World's Fair in Paris.", "latency_ms": 2394.725561141968, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Exposition Universelle", "latency_ms": 3167.240619659424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 703}, "2": {"k": 2, "answer": "Paris 1900 chess tournament and 1900 UCI Track Cycling World Championships", "latency_ms": 7263.258934020996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1394}, "3": {"k": 3, "answer": "Exposition Universelle and UCI Track Cycling World Championships", "latency_ms": 6997.086763381958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2078}, "4": {"k": 4, "answer": "Exposition Universelle", "latency_ms": 3215.0087356567383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2716}, "5": {"k": 5, "answer": "Exposition Universelle", "latency_ms": 2967.74959564209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3358}, "6": {"k": 6, "answer": "Exposition Universelle", "latency_ms": 2095.831871032715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3968}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 1673.6979484558105, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Brisbane Roar's theme song", "latency_ms": 3910.1250171661377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 2743.267059326172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Empowerment", "latency_ms": 2318.4266090393066, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Empowerment", "latency_ms": 2410.4015827178955, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2580}, "5": {"k": 5, "answer": "Empowerment", "latency_ms": 1607.7775955200195, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3162}, "6": {"k": 6, "answer": "Empowerment", "latency_ms": 1817.0044422149658, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3764}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 1806.3881397247314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "National Football League (NFL) franchises", "latency_ms": 3834.9313735961914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "National Football League franchises", "latency_ms": 3025.97713470459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "National Football League franchises", "latency_ms": 2649.9109268188477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1849}, "4": {"k": 4, "answer": "National Football League franchises", "latency_ms": 2977.588653564453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2481}, "5": {"k": 5, "answer": "National Football League franchises", "latency_ms": 1667.6671504974365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "National Football League franchises", "latency_ms": 2213.700532913208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3731}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 2375.7240772247314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2237.1764183044434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3405.4272174835205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2999.4871616363525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2368.252754211426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2551}, "5": {"k": 5, "answer": "James Marshall", "latency_ms": 1419.1515445709229, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "James Marshall", "latency_ms": 2272.3324298858643, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3792}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 1220.8504676818848, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 2731.9369316101074, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 2595.724582672119, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 2591.9833183288574, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 3624.5462894439697, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 2121.077299118042, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 2479.154348373413, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1921.6787815093994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2523.742198944092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2641.163110733032, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2104.3131351470947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "All five ski jumping gold medals.", "latency_ms": 3571.7241764068604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2462}, "5": {"k": 5, "answer": "All five ski jumping gold medals.", "latency_ms": 3406.8312644958496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3067}, "6": {"k": 6, "answer": "All five ski jumping gold medals.", "latency_ms": 2381.530284881592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3683}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3143.1920528411865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4387.648820877075, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3996.5333938598633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 2657.243013381958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4453.373432159424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2596}, "5": {"k": 5, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3807.9450130462646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3271}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3286.107301712036, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3942}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 1277.829647064209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central Germany", "latency_ms": 1569.8516368865967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Central Germany", "latency_ms": 1212.30149269104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Central Germany", "latency_ms": 2016.6966915130615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Central Germany", "latency_ms": 1467.6339626312256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2634}, "5": {"k": 5, "answer": "Central European", "latency_ms": 2526.8640518188477, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3279}, "6": {"k": 6, "answer": "Central European cultures", "latency_ms": 2104.8831939697266, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3933}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 2596.8050956726074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 2261.7881298065186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 4229.695081710815, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 3891.402244567871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "post-medieval era", "latency_ms": 2976.8226146698, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "1648‚Äì1651", "latency_ms": 2745.681047439575, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3212}, "6": {"k": 6, "answer": "1648‚Äì1651", "latency_ms": 2948.7740993499756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3847}}}
