{"qid": "-9197932657152136610", "question": "what are the main sources of economic growth in the us currently", "gold_answers": ["pharmaceuticals", "aircraft", "telecommunications", "heavy machinery"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2706.9172859191895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "increases in labour, increase in capital and increase in efficiency", "latency_ms": 6320.379257202148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "increases in labour, capital and efficiency", "latency_ms": 3045.0119972229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1331}, "3": {"k": 3, "answer": "increases in labour, capital and efficiency", "latency_ms": 4330.267429351807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2123}, "4": {"k": 4, "answer": "increases in labour, increase in capital and increase in efficiency", "latency_ms": 4948.460340499878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2821}, "5": {"k": 5, "answer": "increases in labour, increase in capital and increase in efficiency", "latency_ms": 5323.554277420044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3505}, "6": {"k": 6, "answer": "Inputs of factors of production", "latency_ms": 3003.6258697509766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4200}}}
{"qid": "-4566914757117567579", "question": "who played ethel on the doris day show", "gold_answers": ["Carol Worthington"], "shots": {"0": {"k": 0, "answer": "Kay Chanda", "latency_ms": 1607.161521911621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2659.8269939422607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2133.6348056793213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3498.382568359375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2495.6047534942627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3154.1800498962402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3145}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2063.734769821167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3759}}}
{"qid": "212435016090205927", "question": "who played g baby in the movie hardball", "gold_answers": ["DeWayne Warren"], "shots": {"0": {"k": 0, "answer": "Keanu Reeves", "latency_ms": 1709.221363067627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "DeWayne Warren", "latency_ms": 2395.303249359131, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 644}, "2": {"k": 2, "answer": "DeWayne Warren", "latency_ms": 2435.7926845550537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "DeWayne Warren", "latency_ms": 1607.588768005371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "DeWayne Warren", "latency_ms": 2803.5998344421387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2440}, "5": {"k": 5, "answer": "DeWayne Warren", "latency_ms": 2712.8028869628906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3095}, "6": {"k": 6, "answer": "DeWayne Warren", "latency_ms": 1913.440227508545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3750}}}
{"qid": "-4190633494852415957", "question": "who played john coffey in the movie the green mile", "gold_answers": ["Michael Clarke Duncan"], "shots": {"0": {"k": 0, "answer": "Michael Clarke Duncan", "latency_ms": 1755.4612159729004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Clarke Duncan", "latency_ms": 1512.737512588501, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Michael Clarke Duncan", "latency_ms": 1856.431007385254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1227}, "3": {"k": 3, "answer": "Michael Clarke Duncan", "latency_ms": 2374.0060329437256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1866}, "4": {"k": 4, "answer": "Michael Clarke Duncan", "latency_ms": 2099.8876094818115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2534}, "5": {"k": 5, "answer": "Michael Clarke Duncan", "latency_ms": 2099.5731353759766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3200}, "6": {"k": 6, "answer": "Michael Clarke Duncan", "latency_ms": 1606.0149669647217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3840}}}
{"qid": "811267239470530686", "question": "who wrote catch 22 (both names)", "gold_answers": ["American author Joseph Heller", "Joseph Heller .", "Joseph Heller"], "shots": {"0": {"k": 0, "answer": "Joseph Heller", "latency_ms": 1485.7442378997803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Joseph Heller", "latency_ms": 1206.7623138427734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 614}, "2": {"k": 2, "answer": "Joseph Heller, Buck Henry", "latency_ms": 2355.320930480957, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1278}, "3": {"k": 3, "answer": "Joseph Heller", "latency_ms": 1806.0271739959717, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1945}, "4": {"k": 4, "answer": "Joseph Heller", "latency_ms": 1981.7144870758057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2609}, "5": {"k": 5, "answer": "Joseph Heller", "latency_ms": 1455.916404724121, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3272}, "6": {"k": 6, "answer": "Joseph Heller", "latency_ms": 2022.5787162780762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3949}}}
{"qid": "-1608179127534867277", "question": "where was the world chess tournament 2017 held", "gold_answers": ["Tbilisi , Georgia", "in Tbilisi , Georgia"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 773.7765312194824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tbilisi, Georgia", "latency_ms": 2685.359001159668, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "Tbilisi, Georgia", "latency_ms": 2661.947727203369, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Tbilisi, Georgia", "latency_ms": 2754.1069984436035, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "Tbilisi, Georgia", "latency_ms": 2196.549415588379, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "Tbilisi, Georgia", "latency_ms": 2772.8638648986816, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3201}, "6": {"k": 6, "answer": "Tbilisi, Georgia", "latency_ms": 2509.1214179992676, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3843}}}
{"qid": "7687115121611301468", "question": "who votes to elect a rajya sabha memmber", "gold_answers": ["state legislatures"], "shots": {"0": {"k": 0, "answer": "Elected members of State Legislative Assembly", "latency_ms": 3919.9020862579346, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Legislative assemblies of the states and the Electoral College of the Union Territories.", "latency_ms": 6647.861957550049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "Legislative assemblies of the states and the Electoral College of the Union Territories.", "latency_ms": 6818.8629150390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Electoral College of the State Assembly", "latency_ms": 2629.2529106140137, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "Electoral college of the elected members of the State Assembly", "latency_ms": 3679.476261138916, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2551}, "5": {"k": 5, "answer": "Electoral college of the elected members of the State Assembly", "latency_ms": 5464.752674102783, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Electoral College of the State Assembly", "latency_ms": 2845.374584197998, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3713}}}
{"qid": "-5784633834792163973", "question": "when does season 8 of hawaii five o premiere", "gold_answers": ["September 29 , 2017"], "shots": {"0": {"k": 0, "answer": "September 28, 2018", "latency_ms": 3743.1600093841553, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 29, 2017", "latency_ms": 3304.8148155212402, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "September 29, 2017", "latency_ms": 3936.5243911743164, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "September 29, 2017", "latency_ms": 3614.567279815674, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "September 29, 2017", "latency_ms": 4163.97762298584, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2477}, "5": {"k": 5, "answer": "September 29, 2017", "latency_ms": 3321.903944015503, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "September 29, 2017", "latency_ms": 3424.657106399536, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3825}}}
{"qid": "-5864397450755103545", "question": "paul walkers cars in fast and furious list", "gold_answers": ["1995 Toyota Supra", "2002 Mitsubishi Lancer OZ Rally", "1995 Dodge Stealth", "1995 Mitsubishi Eclipse"], "shots": {"0": {"k": 0, "answer": "Toyota Supra, Mitsubishi Eclipse, Nissan Skyline, Dodge Charger, Ford Gran Torino", "latency_ms": 6375.210285186768, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1806.0288429260254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2481.6060066223145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2451.0202407836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2627.321720123291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2151.388645172119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3097}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2170.847177505493, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3695}}}
{"qid": "-8491157534197669091", "question": "who won the oscar for best actor in 1975", "gold_answers": ["Art Carney"], "shots": {"0": {"k": 0, "answer": "Art Carney", "latency_ms": 2121.2399005889893, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1379.1882991790771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2726.128101348877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1814.415454864502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1843}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2382.2879791259766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2360.5992794036865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3074}, "6": {"k": 6, "answer": "Art Carney", "latency_ms": 1868.1199550628662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3745}}}
{"qid": "-8408640804522114136", "question": "when did the first episode of that 70s show air", "gold_answers": ["August 23 , 1998"], "shots": {"0": {"k": 0, "answer": "August 23, 1998", "latency_ms": 2317.652940750122, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1873.4550476074219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1937.0992183685303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2148.411989212036, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2165.997266769409, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2397}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1910.8607769012451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2999}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3215.4197692871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3659}}}
{"qid": "722920117313579366", "question": "when did the book thief movie come out", "gold_answers": ["November 27 , 2013", "2013"], "shots": {"0": {"k": 0, "answer": "November 8, 2013", "latency_ms": 3153.001546859741, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2013", "latency_ms": 1510.669469833374, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "2013", "latency_ms": 1561.976432800293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1280}, "3": {"k": 3, "answer": "2013", "latency_ms": 1552.8924465179443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1853}, "4": {"k": 4, "answer": "2013", "latency_ms": 813.8318061828613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2449}, "5": {"k": 5, "answer": "2013", "latency_ms": 1514.430284500122, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3061}, "6": {"k": 6, "answer": "2013", "latency_ms": 1227.4811267852783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3672}}}
{"qid": "-4427112594024146143", "question": "when did the eagles win the super bowl", "gold_answers": ["2017"], "shots": {"0": {"k": 0, "answer": "Super Bowl LII", "latency_ms": 2179.4676780700684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Super Bowl LII", "latency_ms": 2776.0539054870605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "Super Bowl LII", "latency_ms": 2178.586959838867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "Super Bowl LII", "latency_ms": 2414.8740768432617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Super Bowl LII", "latency_ms": 2490.6983375549316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "2018", "latency_ms": 1625.9734630584717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "2018", "latency_ms": 1512.221097946167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3759}}}
{"qid": "7078422108284431587", "question": "who is the biggest selling female group of all time", "gold_answers": ["Spice Girls"], "shots": {"0": {"k": 0, "answer": "The Spice Girls", "latency_ms": 2072.822332382202, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spice Girls", "latency_ms": 2072.0982551574707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 676}, "2": {"k": 2, "answer": "Spice Girls", "latency_ms": 2057.0318698883057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1289}, "3": {"k": 3, "answer": "Spice Girls", "latency_ms": 2079.0343284606934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Spice Girls", "latency_ms": 2652.1379947662354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "Spice Girls", "latency_ms": 2367.8972721099854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3042}, "6": {"k": 6, "answer": "Spice Girls", "latency_ms": 1833.5297107696533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3647}}}
{"qid": "1039102546557940080", "question": "who sang from russia with love james bond", "gold_answers": ["Matt Monro"], "shots": {"0": {"k": 0, "answer": "Matt Monro", "latency_ms": 1399.0707397460938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matt Monro", "latency_ms": 2424.6745109558105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Matt Monro", "latency_ms": 2075.9358406066895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Matt Monro", "latency_ms": 1582.5798511505127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1884}, "4": {"k": 4, "answer": "Matt Monro", "latency_ms": 1825.2365589141846, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2583}, "5": {"k": 5, "answer": "Matt Monro", "latency_ms": 2674.1061210632324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3195}, "6": {"k": 6, "answer": "Matt Monro", "latency_ms": 2320.0294971466064, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3814}}}
{"qid": "-8507438636601119973", "question": "where is urinary bladder located in human body", "gold_answers": ["on the pelvic floor", "pelvic floor"], "shots": {"0": {"k": 0, "answer": "Pelvic cavity", "latency_ms": 1801.1252880096436, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the base of the pelvis", "latency_ms": 3060.2548122406006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "at the base of the pelvis", "latency_ms": 3302.600860595703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "at the base of the pelvis", "latency_ms": 4010.6377601623535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "at the base of the pelvis", "latency_ms": 3834.8848819732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2490}, "5": {"k": 5, "answer": "at the base of the pelvis", "latency_ms": 3613.401412963867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3123}, "6": {"k": 6, "answer": "at the base of the pelvis", "latency_ms": 3391.498565673828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-1996951438961136762", "question": "architectural elements forming rib vaults eg wells cathedral", "gold_answers": ["two to three barrel vaults", "an armature of piped masonry", "barrel vaults"], "shots": {"0": {"k": 0, "answer": "Ribs", "latency_ms": 1267.9791450500488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ribs in a net-like form", "latency_ms": 3821.159839630127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 571}, "2": {"k": 2, "answer": "Ribs", "latency_ms": 1450.5269527435303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "lierne ribs", "latency_ms": 2381.1020851135254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1911}, "4": {"k": 4, "answer": "lierne ribs", "latency_ms": 1564.1181468963623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Lierne ribs", "latency_ms": 1864.1455173492432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "Lierne ribs", "latency_ms": 2661.4437103271484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3858}}}
{"qid": "-8490085242981497626", "question": "who sang gonna sit right down and write myself a letter", "gold_answers": ["Fats Waller"], "shots": {"0": {"k": 0, "answer": "Alicia Keys", "latency_ms": 1430.776834487915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fats Waller", "latency_ms": 1390.8133506774902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "Fats Waller", "latency_ms": 2494.1298961639404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Fats Waller", "latency_ms": 2466.9222831726074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Fats Waller", "latency_ms": 1894.3521976470947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Fats Waller", "latency_ms": 1906.7423343658447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3162}, "6": {"k": 6, "answer": "Fats Waller", "latency_ms": 1960.3168964385986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3767}}}
{"qid": "8783361206191889627", "question": "how many rooms is there in buckingham palace", "gold_answers": ["775 rooms", "775"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1440.4420852661133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "775", "latency_ms": 1651.078701019287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "775", "latency_ms": 1746.7339038848877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1197}, "3": {"k": 3, "answer": "775", "latency_ms": 1203.1254768371582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1793}, "4": {"k": 4, "answer": "775", "latency_ms": 1447.6065635681152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2363}, "5": {"k": 5, "answer": "775", "latency_ms": 933.4449768066406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2985}, "6": {"k": 6, "answer": "775", "latency_ms": 1682.981252670288, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3631}}}
{"qid": "1172792682698457582", "question": "where did they get the tree for rockefeller center", "gold_answers": ["State College , PA"], "shots": {"0": {"k": 0, "answer": "Wallkill, New York", "latency_ms": 2329.5652866363525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2648.7715244293213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 5434.468507766724, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 6321.011781692505, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 5092.84782409668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 6295.423984527588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3299}, "6": {"k": 6, "answer": "upstate New York and surrounding states, and even Ottawa in Ontario, Canada.", "latency_ms": 6640.9971714019775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3962}}}
{"qid": "-8616225749004085214", "question": "who expanded the territory of china during the qing dynasty", "gold_answers": ["Prince Bao", "the Qianlong Emperor", "Qianlong"], "shots": {"0": {"k": 0, "answer": "Qianlong Emperor", "latency_ms": 2172.7755069732666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nurhaci", "latency_ms": 2170.337200164795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Qianlong Emperor", "latency_ms": 3121.514081954956, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Kangxi Emperor", "latency_ms": 1914.9541854858398, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Kangxi Emperor", "latency_ms": 2967.1034812927246, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Qianlong Emperor", "latency_ms": 2394.3393230438232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3281}, "6": {"k": 6, "answer": "Qianlong Emperor", "latency_ms": 2336.3044261932373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3927}}}
{"qid": "-4544825586005995775", "question": "what is the second largest country in asia", "gold_answers": ["China"], "shots": {"0": {"k": 0, "answer": "Kazakhstan", "latency_ms": 2883.44669342041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2910.3822708129883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3428.7002086639404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1317}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1650.1758098602295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2132.828712463379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2596}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2614.4185066223145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3286}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2410.1645946502686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3948}}}
{"qid": "2851585794686488659", "question": "when was the last episode of vampire diaries aired", "gold_answers": ["March 10 , 2017"], "shots": {"0": {"k": 0, "answer": "March 10, 2017", "latency_ms": 3156.7697525024414, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2424.9603748321533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3010.7357501983643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1279}, "3": {"k": 3, "answer": "March 10, 2017", "latency_ms": 3145.4288959503174, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "March 10, 2017", "latency_ms": 3425.3695011138916, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "March 10, 2017", "latency_ms": 3133.213996887207, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3187}, "6": {"k": 6, "answer": "March 10, 2017", "latency_ms": 3378.633975982666, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3859}}}
{"qid": "636692438616046367", "question": "who played ashley on the young and the restless", "gold_answers": ["Shari Shattuck", "Eileen Davidson", "Brenda Epperson"], "shots": {"0": {"k": 0, "answer": "Eileen Davidson", "latency_ms": 1615.98801612854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eileen Davidson", "latency_ms": 1613.654613494873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "Eileen Davidson", "latency_ms": 2082.411527633667, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Eileen Davidson", "latency_ms": 1895.9786891937256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1887}, "4": {"k": 4, "answer": "Eileen Davidson, Brenda Epperson, Shari Shattuck", "latency_ms": 5063.306093215942, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2471}, "5": {"k": 5, "answer": "Eileen Davidson, Brenda Epperson, Shari Shattuck", "latency_ms": 5067.2571659088135, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3069}, "6": {"k": 6, "answer": "Eileen Davidson", "latency_ms": 2082.623243331909, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3673}}}
{"qid": "-2668952310493902320", "question": "who has scored the most points for wales v france", "gold_answers": ["Neil Jenkins"], "shots": {"0": {"k": 0, "answer": "Neil Jenkins", "latency_ms": 986.8378639221191, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2324.768543243408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2736.3831996917725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Barry John", "latency_ms": 1785.2756977081299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "Barry John", "latency_ms": 1791.966199874878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2455}, "5": {"k": 5, "answer": "Barry John", "latency_ms": 1366.5504455566406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2995}, "6": {"k": 6, "answer": "Barry John", "latency_ms": 1582.7100276947021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3549}}}
{"qid": "-551363795407275714", "question": "who is pictured on the 5000 dollar bill", "gold_answers": ["James Madison"], "shots": {"0": {"k": 0, "answer": "James Madison", "latency_ms": 2093.665599822998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2623.0993270874023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2896.3286876678467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1227}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2143.993616104126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1844.196081161499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2458}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2150.3512859344482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3120}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1713.2813930511475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3802}}}
{"qid": "-1776638341170409438", "question": "what is the strongest earthquake in the united states", "gold_answers": ["1700 Cascadia earthquake", "1964 Alaska earthquake and tsunami"], "shots": {"0": {"k": 0, "answer": "Great Alaska Earthquake", "latency_ms": 2345.001220703125, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5.8 magnitude", "latency_ms": 3081.0232162475586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "7.9 M", "latency_ms": 3008.721351623535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "7.9 M", "latency_ms": 2628.7190914154053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "7.9 M", "latency_ms": 2170.999765396118, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "7.9 M", "latency_ms": 2144.8774337768555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "7.9 M", "latency_ms": 2709.1877460479736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3872}}}
{"qid": "-3417376069582577712", "question": "who wrote the song balls to the wall", "gold_answers": ["Herman Frank", "Peter Baltes", "Stefan Kaufmann", "Wolf Hoffmann", "Udo Dirkschneider", "Deaffy"], "shots": {"0": {"k": 0, "answer": "Accept", "latency_ms": 717.2799110412598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2842.1130180358887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2898.3702659606934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2471.8616008758545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2392.3773765563965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2195.139169692993, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3118}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2923.279047012329, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3742}}}
{"qid": "-5788046732019278353", "question": "who talks for belle in beauty and the beast", "gold_answers": ["Julie Nathanson", "Jodi Benson", "Paige O'Hara"], "shots": {"0": {"k": 0, "answer": "Paige O'Hara", "latency_ms": 2488.4510040283203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Paige O'Hara", "latency_ms": 2965.024948120117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 689}, "2": {"k": 2, "answer": "Paige O'Hara", "latency_ms": 2914.484739303589, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1379}, "3": {"k": 3, "answer": "Paige O'Hara", "latency_ms": 2303.373098373413, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2033}, "4": {"k": 4, "answer": "Paige O'Hara", "latency_ms": 2911.310911178589, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Paige O'Hara", "latency_ms": 2658.0183506011963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3245}, "6": {"k": 6, "answer": "Paige O'Hara", "latency_ms": 2684.366226196289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3868}}}
{"qid": "-819495145099806596", "question": "what is a coherent set of values and beliefs about public policy called", "gold_answers": ["political ideology", "ideology", "a political ideology"], "shots": {"0": {"k": 0, "answer": "Ideology", "latency_ms": 1534.5590114593506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Group of Five", "latency_ms": 2133.8229179382324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Group of Five", "latency_ms": 1555.7284355163574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1371}, "3": {"k": 3, "answer": "Group of Five", "latency_ms": 1810.2600574493408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2092}, "4": {"k": 4, "answer": "Group of Five", "latency_ms": 1821.4640617370605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2691}, "5": {"k": 5, "answer": "Group of Five", "latency_ms": 1542.423963546753, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3425}, "6": {"k": 6, "answer": "Group of Five", "latency_ms": 2056.7052364349365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4086}}}
{"qid": "-467801736331608973", "question": "when do liam and annie get together season 3", "gold_answers": ["Holiday Madness"], "shots": {"0": {"k": 0, "answer": "Episode 9", "latency_ms": 1890.369176864624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Season three", "latency_ms": 1204.007863998413, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "Season three", "latency_ms": 1763.458490371704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1168}, "3": {"k": 3, "answer": "Season three", "latency_ms": 1823.7872123718262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1725}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2166.0025119781494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2275}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1872.9248046875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2887}, "6": {"k": 6, "answer": "Season 3", "latency_ms": 2348.4485149383545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3515}}}
{"qid": "7210975046317501288", "question": "what breed of cat has spots and stripes", "gold_answers": ["tabby"], "shots": {"0": {"k": 0, "answer": "Ocicat", "latency_ms": 2454.6890258789062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bengal cat", "latency_ms": 1827.524185180664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "Bengal cat", "latency_ms": 2800.738573074341, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1160}, "3": {"k": 3, "answer": "Bengal cat", "latency_ms": 1957.7131271362305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1811}, "4": {"k": 4, "answer": "Bengal cat", "latency_ms": 2402.0919799804688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2355}, "5": {"k": 5, "answer": "Bengal cat", "latency_ms": 1928.9782047271729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2947}, "6": {"k": 6, "answer": "Bengal cat", "latency_ms": 2611.584186553955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3572}}}
{"qid": "7817340376558760325", "question": "who voiced simba in the lion king 2", "gold_answers": ["Matthew Broderick"], "shots": {"0": {"k": 0, "answer": "Matthew Broderick", "latency_ms": 2310.7059001922607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matthew Broderick", "latency_ms": 2454.5516967773438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 649}, "2": {"k": 2, "answer": "Matthew Broderick", "latency_ms": 3168.799877166748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Matthew Broderick", "latency_ms": 1899.4877338409424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1880}, "4": {"k": 4, "answer": "Matthew Broderick", "latency_ms": 2408.522129058838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2532}, "5": {"k": 5, "answer": "Matthew Broderick", "latency_ms": 2078.2525539398193, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3126}, "6": {"k": 6, "answer": "Matthew Broderick", "latency_ms": 2875.3139972686768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3745}}}
{"qid": "7584034394038581786", "question": "when did the angel of the north get built", "gold_answers": ["1998", "1994"], "shots": {"0": {"k": 0, "answer": "1998", "latency_ms": 1546.9231605529785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2096.6522693634033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2731.032371520996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1324}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2219.472885131836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2545.666456222534, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2486}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2115.5948638916016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2849.998712539673, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3760}}}
{"qid": "1854394640394891866", "question": "when did mcgee became a regular on ncis", "gold_answers": ["in season two", "season two"], "shots": {"0": {"k": 0, "answer": "Season 2", "latency_ms": 1452.2664546966553, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2526.3988971710205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Season two", "latency_ms": 2649.665355682373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Season two", "latency_ms": 1578.0630111694336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "Season two", "latency_ms": 1516.556739807129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2547}, "5": {"k": 5, "answer": "Season two", "latency_ms": 1560.1933002471924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "Season two", "latency_ms": 1756.5455436706543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3885}}}
{"qid": "2247250807557083996", "question": "when was 1 john 5 7 added to the bible", "gold_answers": ["the 9th century"], "shots": {"0": {"k": 0, "answer": "15th century", "latency_ms": 1839.6046161651611, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2704.874277114868, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 547}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2864.8478984832764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1094}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2951.0273933410645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1697}, "4": {"k": 4, "answer": "19th century", "latency_ms": 1830.2364349365234, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2375}, "5": {"k": 5, "answer": "19th century", "latency_ms": 2124.9172687530518, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3042}, "6": {"k": 6, "answer": "19th century", "latency_ms": 1773.723840713501, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3678}}}
{"qid": "-2049551589682654986", "question": "when was the latest version of chrome released", "gold_answers": ["2018 - 01 - 22"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1774.1389274597168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2684.9746704101562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2126.042604446411, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2441.922187805176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2047.3158359527588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2178.8852214813232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3076}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2190.3669834136963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3767}}}
{"qid": "-3534092359651954035", "question": "who is jojo in horton hears a who", "gold_answers": ["Jesse McCartney"], "shots": {"0": {"k": 0, "answer": "JoJo", "latency_ms": 1792.900562286377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a small Who", "latency_ms": 1901.2682437896729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "a small Who", "latency_ms": 2381.7813396453857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1167}, "3": {"k": 3, "answer": "JoJo, the Mayor's son", "latency_ms": 3268.1210041046143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1746}, "4": {"k": 4, "answer": "JoJo, the Mayor's teenage son", "latency_ms": 2885.7624530792236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "JoJo, the Mayor's teenage son", "latency_ms": 4145.524501800537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3016}, "6": {"k": 6, "answer": "JoJo, the Mayor's teenage son", "latency_ms": 4121.169328689575, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}}}
{"qid": "6504412384445795967", "question": "the part of the cytoskeleton made from the protein actin is called", "gold_answers": ["Microfilaments", "microfilament"], "shots": {"0": {"k": 0, "answer": "Microfilaments", "latency_ms": 2024.8420238494873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "actin cytoskeleton", "latency_ms": 2414.4248962402344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "microfilaments", "latency_ms": 2062.664270401001, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1280}, "3": {"k": 3, "answer": "microfilaments", "latency_ms": 1785.9692573547363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1987}, "4": {"k": 4, "answer": "microfilaments", "latency_ms": 1819.5929527282715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "microfilaments", "latency_ms": 1567.36159324646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3395}, "6": {"k": 6, "answer": "microfilaments", "latency_ms": 2144.7720527648926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4056}}}
{"qid": "95888218441734902", "question": "who plays jack in battle of the sexes", "gold_answers": ["Bill Pullman", "( Bill Pullman"], "shots": {"0": {"k": 0, "answer": "Steve Carell", "latency_ms": 1605.1809787750244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bill Pullman", "latency_ms": 2361.8807792663574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 589}, "2": {"k": 2, "answer": "Bill Pullman", "latency_ms": 2308.488130569458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "Bill Pullman", "latency_ms": 2624.2852210998535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1875}, "4": {"k": 4, "answer": "Bill Pullman", "latency_ms": 1864.8056983947754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2561}, "5": {"k": 5, "answer": "Bill Pullman", "latency_ms": 1846.2483882904053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3172}, "6": {"k": 6, "answer": "Bill Pullman", "latency_ms": 2109.7068786621094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3763}}}
{"qid": "2482202658787537401", "question": "is a network connection device that can build tables that identify addresses on each network", "gold_answers": ["routing table", "a router"], "shots": {"0": {"k": 0, "answer": "Router", "latency_ms": 736.1130714416504, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Router", "latency_ms": 1745.872974395752, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 714}, "2": {"k": 2, "answer": "Router", "latency_ms": 1187.1185302734375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1409}, "3": {"k": 3, "answer": "Router", "latency_ms": 2328.321933746338, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2134}, "4": {"k": 4, "answer": "Router", "latency_ms": 674.2873191833496, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2813}, "5": {"k": 5, "answer": "Router", "latency_ms": 1392.4448490142822, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3510}, "6": {"k": 6, "answer": "Router", "latency_ms": 1420.2120304107666, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4176}}}
{"qid": "8359496728452221378", "question": "when did the royal proclamation of 1763 end", "gold_answers": ["with the American Revolutionary War", "the American Revolutionary War", "1783"], "shots": {"0": {"k": 0, "answer": "1763", "latency_ms": 1006.2475204467773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3174.257755279541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1868.4093952178955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1358}, "3": {"k": 3, "answer": "American Revolutionary War", "latency_ms": 2342.1192169189453, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "American Revolutionary War", "latency_ms": 1292.0472621917725, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2688}, "5": {"k": 5, "answer": "American Revolutionary War", "latency_ms": 2143.588066101074, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3349}, "6": {"k": 6, "answer": "American Revolutionary War", "latency_ms": 1541.0892963409424, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3974}}}
{"qid": "-2657014790962135860", "question": "the tenure of the office of the lokayukt of up", "gold_answers": ["8 years", "eight years"], "shots": {"0": {"k": 0, "answer": "8 years", "latency_ms": 1541.9576168060303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1600.5640029907227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1896.4900970458984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2936.547040939331, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2625.091075897217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2414}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2663.9163494110107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1744.805097579956, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3703}}}
{"qid": "1827180983934640653", "question": "when did response to state of the union start", "gold_answers": ["1966", "in 1966"], "shots": {"0": {"k": 0, "answer": "1966", "latency_ms": 1041.3126945495605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1970", "latency_ms": 1523.4136581420898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "1966", "latency_ms": 1465.280294418335, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1389}, "3": {"k": 3, "answer": "1966", "latency_ms": 2030.670166015625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2071}, "4": {"k": 4, "answer": "1966", "latency_ms": 1408.2438945770264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2745}, "5": {"k": 5, "answer": "1966", "latency_ms": 1994.8770999908447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3378}, "6": {"k": 6, "answer": "1966", "latency_ms": 1845.1545238494873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4039}}}
{"qid": "-8006002028754190814", "question": "who had the most governmental power under the articles of confederation", "gold_answers": ["the states"], "shots": {"0": {"k": 0, "answer": "State governments", "latency_ms": 1817.4805641174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The states", "latency_ms": 1473.839521408081, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "The states", "latency_ms": 1539.4327640533447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1364}, "3": {"k": 3, "answer": "The states", "latency_ms": 1791.5065288543701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2087}, "4": {"k": 4, "answer": "The states", "latency_ms": 1152.40478515625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2785}, "5": {"k": 5, "answer": "The states", "latency_ms": 1194.7715282440186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3468}, "6": {"k": 6, "answer": "The states", "latency_ms": 1216.1786556243896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4173}}}
{"qid": "3406509904702130536", "question": "how many hospitals are there in the united states", "gold_answers": ["5,534 registered hospitals", "5,534"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1690.2883052825928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5,534", "latency_ms": 1564.974308013916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 723}, "2": {"k": 2, "answer": "5,534", "latency_ms": 1473.2744693756104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1403}, "3": {"k": 3, "answer": "5,534", "latency_ms": 1879.4302940368652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2123}, "4": {"k": 4, "answer": "5,534", "latency_ms": 2001.713514328003, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2800}, "5": {"k": 5, "answer": "5,534", "latency_ms": 1588.4034633636475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3510}, "6": {"k": 6, "answer": "5,534", "latency_ms": 1852.4255752563477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4191}}}
{"qid": "2435796066046322163", "question": "who donates a christmas tree to trafalgar square", "gold_answers": ["Oslo , Norway"], "shots": {"0": {"k": 0, "answer": "Norway", "latency_ms": 1070.3096389770508, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The city of Oslo, Norway", "latency_ms": 2722.6765155792236, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "The city of Oslo, Norway", "latency_ms": 2292.33717918396, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Norway", "latency_ms": 985.994815826416, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1929}, "4": {"k": 4, "answer": "The city of Oslo, Norway", "latency_ms": 3253.931760787964, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2542}, "5": {"k": 5, "answer": "The city of Oslo, Norway", "latency_ms": 3350.0161170959473, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "Norway", "latency_ms": 1576.615810394287, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3832}}}
{"qid": "4926415052497472665", "question": "who starred in the movie on golden pond", "gold_answers": ["William Lanteau", "Dabney Coleman", "Henry Fonda", "Doug McKeon", "Jane Fonda", "Christopher Rydell", "Katharine Hepburn"], "shots": {"0": {"k": 0, "answer": "Henry Fonda", "latency_ms": 2189.995288848877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 3863.4886741638184, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 3592.815160751343, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 4236.747980117798, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 4435.49370765686, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2539}, "5": {"k": 5, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 4492.783784866333, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3142}, "6": {"k": 6, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 4778.931617736816, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3756}}}
{"qid": "2142753216627246962", "question": "isdn uses b & d channels. what is d channel use for", "gold_answers": ["carries control and signaling information", "data", "control and signaling information"], "shots": {"0": {"k": 0, "answer": "Signaling", "latency_ms": 868.3929443359375, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "control and signaling information", "latency_ms": 1891.6263580322266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "control and signaling information", "latency_ms": 1468.8749313354492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "signaling and control", "latency_ms": 2372.4606037139893, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 1914}, "4": {"k": 4, "answer": "signaling and control", "latency_ms": 2135.104179382324, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 2519}, "5": {"k": 5, "answer": "signaling and control", "latency_ms": 2367.9919242858887, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "signaling and control", "latency_ms": 2184.1042041778564, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3792}}}
{"qid": "1547060614805522730", "question": "what is the rate limiting enzyme of kreb's cycle", "gold_answers": ["Isocitrate dehydrogenase"], "shots": {"0": {"k": 0, "answer": "Isocitrate dehydrogenase", "latency_ms": 3261.5041732788086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2436.079740524292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 679}, "2": {"k": 2, "answer": "ALA synthase", "latency_ms": 1256.0789585113525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "ALA synthase", "latency_ms": 1870.0876235961914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1989}, "4": {"k": 4, "answer": "ALA synthase", "latency_ms": 1550.8923530578613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2680}, "5": {"k": 5, "answer": "ALA synthase", "latency_ms": 2082.0555686950684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3364}, "6": {"k": 6, "answer": "ALA synthase", "latency_ms": 2096.114158630371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4034}}}
{"qid": "8965198420725510475", "question": "when was the taj mahal built and completed", "gold_answers": ["1632 -- 53"], "shots": {"0": {"k": 0, "answer": "1653", "latency_ms": 1511.2931728363037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1643, 1653", "latency_ms": 3335.9720706939697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "1632-1653", "latency_ms": 2837.1219635009766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "1632-1653", "latency_ms": 3013.5693550109863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1830}, "4": {"k": 4, "answer": "1632-1653", "latency_ms": 2197.007894515991, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "1632-1653", "latency_ms": 2285.2156162261963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3104}, "6": {"k": 6, "answer": "1632-1653", "latency_ms": 2965.5463695526123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3655}}}
{"qid": "-6292760252056275316", "question": "which supreme court judge has surved in international court of justice", "gold_answers": ["Dalveer Bhandari"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 1922.8687286376953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justice Dalveer Bhandari", "latency_ms": 3307.873249053955, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "Justice Dalveer Bhandari", "latency_ms": 3496.318578720093, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "Justice Dalveer Bhandari", "latency_ms": 3362.110376358032, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2008}, "4": {"k": 4, "answer": "Dalveer Bhandari", "latency_ms": 2485.1162433624268, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2632}, "5": {"k": 5, "answer": "Dalveer Bhandari", "latency_ms": 3977.6134490966797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3254}, "6": {"k": 6, "answer": "Dalveer Bhandari", "latency_ms": 3659.5544815063477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3978}}}
{"qid": "8361850218460994084", "question": "who is known as father of green revolution in india", "gold_answers": ["Mankombu Sambasivan Swaminathan"], "shots": {"0": {"k": 0, "answer": "M.S. Swaminathan", "latency_ms": 2123.528242111206, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "M. S. Swaminathan", "latency_ms": 3889.0252113342285, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "M. S. Swaminathan", "latency_ms": 3069.6921348571777, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "M. S. Swaminathan", "latency_ms": 3651.949644088745, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2034}, "4": {"k": 4, "answer": "M. S. Swaminathan", "latency_ms": 3067.2106742858887, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2755}, "5": {"k": 5, "answer": "M. S. Swaminathan", "latency_ms": 2876.4913082122803, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3489}, "6": {"k": 6, "answer": "M. S. Swaminathan", "latency_ms": 2829.589605331421, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4182}}}
{"qid": "-5690645328022945594", "question": "who sing say you won't let go", "gold_answers": ["James Arthur"], "shots": {"0": {"k": 0, "answer": "James Arthur", "latency_ms": 1578.9306163787842, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Arthur", "latency_ms": 2696.2249279022217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 590}, "2": {"k": 2, "answer": "James Arthur", "latency_ms": 1321.0129737854004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1176}, "3": {"k": 3, "answer": "James Arthur", "latency_ms": 1239.3217086791992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1776}, "4": {"k": 4, "answer": "James Arthur", "latency_ms": 1256.0198307037354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2399}, "5": {"k": 5, "answer": "James Arthur", "latency_ms": 2027.923345565796, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3020}, "6": {"k": 6, "answer": "James Arthur", "latency_ms": 1802.0076751708984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3657}}}
{"qid": "-4292736993227486718", "question": "who monitor the recovery of the location during a disaster", "gold_answers": ["management team"], "shots": {"0": {"k": 0, "answer": "Incident Commander", "latency_ms": 2630.188226699829, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the organization", "latency_ms": 1582.601547241211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "The management team", "latency_ms": 2564.7711753845215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1402}, "3": {"k": 3, "answer": "The management team", "latency_ms": 2078.349828720093, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2071}, "4": {"k": 4, "answer": "The management team", "latency_ms": 1960.9453678131104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2720}, "5": {"k": 5, "answer": "The management team", "latency_ms": 1743.7856197357178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3488}, "6": {"k": 6, "answer": "The management team", "latency_ms": 2084.6447944641113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4198}}}
{"qid": "-4741747756019727470", "question": "where does the synthesis of new dna from existing dna occurs", "gold_answers": ["origins of replication"], "shots": {"0": {"k": 0, "answer": "Replication fork", "latency_ms": 2384.9434852600098, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in vivo", "latency_ms": 2015.899896621704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "in vivo", "latency_ms": 1574.570894241333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "in vivo", "latency_ms": 2028.834581375122, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2003}, "4": {"k": 4, "answer": "in vivo", "latency_ms": 1267.9038047790527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2650}, "5": {"k": 5, "answer": "in vivo", "latency_ms": 1992.4373626708984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3312}, "6": {"k": 6, "answer": "in vivo", "latency_ms": 2026.4041423797607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3995}}}
{"qid": "4268853195499399258", "question": "who sings gimme shelter with mick jagger", "gold_answers": ["Merry Clayton"], "shots": {"0": {"k": 0, "answer": "Merry Clayton", "latency_ms": 1850.623607635498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Merry Clayton", "latency_ms": 2316.629409790039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "Merry Clayton", "latency_ms": 1879.1477680206299, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Merry Clayton", "latency_ms": 2073.3091831207275, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Merry Clayton", "latency_ms": 1596.7655181884766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Merry Clayton", "latency_ms": 2435.9607696533203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3247}, "6": {"k": 6, "answer": "Merry Clayton", "latency_ms": 1833.3733081817627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3951}}}
{"qid": "7172420463912356173", "question": "who does tony end up with on skins", "gold_answers": ["Michelle"], "shots": {"0": {"k": 0, "answer": "Michelle Richardson", "latency_ms": 1317.340612411499, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michelle", "latency_ms": 1450.211524963379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 562}, "2": {"k": 2, "answer": "Michelle", "latency_ms": 1158.3812236785889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1187}, "3": {"k": 3, "answer": "Michelle", "latency_ms": 1742.0670986175537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1819}, "4": {"k": 4, "answer": "Michelle", "latency_ms": 691.79368019104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2417}, "5": {"k": 5, "answer": "Michelle", "latency_ms": 1456.190824508667, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3019}, "6": {"k": 6, "answer": "Michelle", "latency_ms": 909.9304676055908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3563}}}
{"qid": "-1400292288904470066", "question": "who sings sugar sugar you are my candy girl", "gold_answers": ["the Archies"], "shots": {"0": {"k": 0, "answer": "The Archies", "latency_ms": 1906.769037246704, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1474.926233291626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2591.89510345459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2118.063449859619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1935}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2672.6536750793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2450.5207538604736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2503.8087368011475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3832}}}
{"qid": "-1696720698220253139", "question": "who does tyler end up with in you get me", "gold_answers": ["Ali"], "shots": {"0": {"k": 0, "answer": "Holly.\nor \nAlison.", "latency_ms": 3364.330053329468, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2832.3755264282227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2260.3847980499268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2232.966423034668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2334.41162109375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2369}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3137.336492538452, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2933}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2679.4729232788086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3526}}}
{"qid": "-6797239474199900801", "question": "who won the gold for the men's figure skating", "gold_answers": ["Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2415.900945663452, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gillis Grafstrm", "latency_ms": 1976.2694835662842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "Gillis Grafstrm", "latency_ms": 2748.85630607605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1357}, "3": {"k": 3, "answer": "Gillis Grafstrm", "latency_ms": 3297.0900535583496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2015}, "4": {"k": 4, "answer": "Gillis Grafstrm", "latency_ms": 3130.3977966308594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2668}, "5": {"k": 5, "answer": "Dick Button", "latency_ms": 999.664306640625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "Gillis Grafstrm", "latency_ms": 2402.5232791900635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3857}}}
{"qid": "-7819569157752445011", "question": "when did the song holiday road come out", "gold_answers": ["1983", "June 24 , 1983"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 2005.3260326385498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1983", "latency_ms": 1535.7167720794678, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "1983", "latency_ms": 2042.5503253936768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "1983", "latency_ms": 1747.7712631225586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1907}, "4": {"k": 4, "answer": "1983", "latency_ms": 2347.1944332122803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "1983", "latency_ms": 1005.0680637359619, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "1983", "latency_ms": 1455.1193714141846, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3849}}}
{"qid": "-8839043176903626071", "question": "when does the mlb season start and finish", "gold_answers": ["October 31 , 2018", "March 29"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1930.0453662872314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2088.9759063720703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3158.4432125091553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2459.6755504608154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1801}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2847.322463989258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2390}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2658.0514907836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2971}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2615.861654281616, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3594}}}
{"qid": "6356531089429364942", "question": "when did scotland beat england in six nations", "gold_answers": ["8 March 2008", "25 February 2006", "24 February 2018", "2 April 2000"], "shots": {"0": {"k": 0, "answer": "8 February 2020", "latency_ms": 1792.2136783599854, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1871", "latency_ms": 1736.8581295013428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "1999", "latency_ms": 1235.7087135314941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "1999", "latency_ms": 2040.8906936645508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1957}, "4": {"k": 4, "answer": "2006", "latency_ms": 1764.7643089294434, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2595}, "5": {"k": 5, "answer": "2006, 1999", "latency_ms": 2280.562400817871, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3179}, "6": {"k": 6, "answer": "1999, 2006", "latency_ms": 1727.0138263702393, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "-3382335563294993978", "question": "when did the rational dress society begin to work", "gold_answers": ["1881"], "shots": {"0": {"k": 0, "answer": "1881", "latency_ms": 1234.337329864502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1881", "latency_ms": 999.3777275085449, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "1881", "latency_ms": 1494.9941635131836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "1881", "latency_ms": 941.5934085845947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1939}, "4": {"k": 4, "answer": "1881", "latency_ms": 2022.2468376159668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2593}, "5": {"k": 5, "answer": "1881", "latency_ms": 991.8003082275391, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "1881", "latency_ms": 1259.833812713623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3853}}}
{"qid": "-5630827734073464379", "question": "why is the indian ocean the warmest in the world", "gold_answers": ["human induced greenhouse warming"], "shots": {"0": {"k": 0, "answer": "High sea surface temperatures", "latency_ms": 1435.5337619781494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "human induced greenhouse warming", "latency_ms": 1375.985860824585, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2136.5325450897217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1337}, "3": {"k": 3, "answer": "Human induced greenhouse warming", "latency_ms": 1696.2783336639404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1933}, "4": {"k": 4, "answer": "Human induced greenhouse warming", "latency_ms": 1411.2093448638916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2540}, "5": {"k": 5, "answer": "Human induced greenhouse warming", "latency_ms": 2445.8813667297363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Human induced greenhouse warming", "latency_ms": 1960.2653980255127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3758}}}
{"qid": "-3544151584263258729", "question": "where was the film manchester by the sea filmed", "gold_answers": ["Middleton", "Essex", "Gloucester", "Beverly", "Swampscott", "Lynn", "Manchester", "Salem", "Tewksbury"], "shots": {"0": {"k": 0, "answer": "Gloucester, Massachusetts", "latency_ms": 2597.9552268981934, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Massachusetts, Beverly, Essex, Gloucester, Swampscott, Lynn", "latency_ms": 5163.364887237549, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 635}, "2": {"k": 2, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 9493.114709854126, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 1334}, "3": {"k": 3, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 8216.51816368103, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 1999}, "4": {"k": 4, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 10044.484615325928, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 2671}, "5": {"k": 5, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 10729.883670806885, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 3317}, "6": {"k": 6, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem.", "latency_ms": 10363.448143005371, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 3978}}}
{"qid": "-5077733789764986167", "question": "consist of the sum of the fixed and variable costs for any given level of production", "gold_answers": ["total cost ( TC )"], "shots": {"0": {"k": 0, "answer": "Total Costs", "latency_ms": 1185.1015090942383, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Total cost", "latency_ms": 1584.5937728881836, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Total cost", "latency_ms": 1485.5828285217285, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Total cost", "latency_ms": 2259.962797164917, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1849}, "4": {"k": 4, "answer": "Total cost", "latency_ms": 716.073751449585, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2454}, "5": {"k": 5, "answer": "Total cost", "latency_ms": 1779.6196937561035, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3070}, "6": {"k": 6, "answer": "Total cost", "latency_ms": 1602.1952629089355, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3738}}}
{"qid": "4892187805447493570", "question": "where was thomas and the magic railroad filmed", "gold_answers": ["Toronto , Ontario , Canada", "Isle of Man", "the Isle of Man"], "shots": {"0": {"k": 0, "answer": "Strasburg Rail Road", "latency_ms": 2236.04154586792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shepperton Studios", "latency_ms": 1726.8860340118408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "Shepperton Studios, United Kingdom and the United States, Strasburg Rail Road", "latency_ms": 5044.587135314941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Shepperton Studios, United Kingdom, United States, Toronto, Strasburg Rail Road", "latency_ms": 5645.508766174316, "em": 0.0, "f1": 0.15384615384615383, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Shepperton Studios, United Kingdom, United States, Toronto, Strasburg Rail Road", "latency_ms": 7148.841619491577, "em": 0.0, "f1": 0.15384615384615383, "containment": 0.0, "context_chars": 2522}, "5": {"k": 5, "answer": "Shepperton Studios, United Kingdom, United States, Toronto, Strasburg Rail Road", "latency_ms": 8253.121137619019, "em": 0.0, "f1": 0.15384615384615383, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "Shepperton Studios, United Kingdom, United States, Toronto, Strasburg Rail Road", "latency_ms": 6382.646799087524, "em": 0.0, "f1": 0.15384615384615383, "containment": 0.0, "context_chars": 3872}}}
{"qid": "-7094533216301278566", "question": "who has access to the presidential daily briefing", "gold_answers": ["Secretaries of State", "the President", "Defense", "National Security Advisor"], "shots": {"0": {"k": 0, "answer": "The President and senior officials.", "latency_ms": 2821.0766315460205, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President and top-level US officials", "latency_ms": 2144.789457321167, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "The President of the United States and top-level US officials approved by the President", "latency_ms": 5738.692045211792, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 1334}, "3": {"k": 3, "answer": "The President and top-level US officials", "latency_ms": 3683.3081245422363, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2006}, "4": {"k": 4, "answer": "The President and a small number of top-level US officials", "latency_ms": 4617.875099182129, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2673}, "5": {"k": 5, "answer": "The President and a small number of top-level US officials", "latency_ms": 5546.624660491943, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3345}, "6": {"k": 6, "answer": "The President and a small number of top-level US officials", "latency_ms": 5007.016658782959, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4025}}}
{"qid": "-243139310037543674", "question": "what tool is available from microsoft as an alternative to the usmt for smaller migrations", "gold_answers": ["Windows Easy Transfer"], "shots": {"0": {"k": 0, "answer": "Easy Transfer", "latency_ms": 1615.8802509307861, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Files", "latency_ms": 1300.4932403564453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Windows Easy Transfer", "latency_ms": 2300.2960681915283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Windows Easy Transfer", "latency_ms": 2162.567138671875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2036}, "4": {"k": 4, "answer": "Windows Easy Transfer", "latency_ms": 1600.5282402038574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2675}, "5": {"k": 5, "answer": "Windows Easy Transfer", "latency_ms": 2869.9684143066406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3377}, "6": {"k": 6, "answer": "Windows Easy Transfer", "latency_ms": 1616.302490234375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4032}}}
{"qid": "7079282152145474767", "question": "who appoints the chief election commissioner of india", "gold_answers": ["the president", "President of India"], "shots": {"0": {"k": 0, "answer": "The President of India", "latency_ms": 2243.57008934021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President", "latency_ms": 1772.8500366210938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "The President", "latency_ms": 1030.1997661590576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1388}, "3": {"k": 3, "answer": "The President", "latency_ms": 1985.4342937469482, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2081}, "4": {"k": 4, "answer": "The President", "latency_ms": 1259.0060234069824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2823}, "5": {"k": 5, "answer": "The President", "latency_ms": 1470.6742763519287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3504}, "6": {"k": 6, "answer": "The President", "latency_ms": 2189.1682147979736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4176}}}
{"qid": "6303430169473424975", "question": "glycogen and amylopectin are long chains of which simple sugar(s)", "gold_answers": ["glucose"], "shots": {"0": {"k": 0, "answer": "Glucose", "latency_ms": 1207.1948051452637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "glucose", "latency_ms": 1207.937240600586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "glucose", "latency_ms": 1958.7280750274658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1357}, "3": {"k": 3, "answer": "glucose", "latency_ms": 1782.7565670013428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Glucose", "latency_ms": 1035.301685333252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2621}, "5": {"k": 5, "answer": "glucose", "latency_ms": 2597.8217124938965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3247}, "6": {"k": 6, "answer": "Glucose", "latency_ms": 791.583776473999, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3969}}}
{"qid": "-3240666523350424161", "question": "who was the editor of the journal jugantor published in the time of swadeshi movement", "gold_answers": ["Bhupendranath Dutt"], "shots": {"0": {"k": 0, "answer": "Barindra Kumar Ghosh", "latency_ms": 2785.5207920074463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Barindra Kumar Ghosh", "latency_ms": 2322.685956954956, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2924.0400791168213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1354}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2205.7156562805176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2047}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1465.2729034423828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2461.747646331787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3364}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2294.4283485412598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4056}}}
{"qid": "1321443496772706078", "question": "when did indoor toilets become common in america", "gold_answers": ["After World War I"], "shots": {"0": {"k": 0, "answer": "Late 19th century", "latency_ms": 2710.259199142456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1890s", "latency_ms": 1843.5313701629639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "1890s", "latency_ms": 2805.213212966919, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "1890s", "latency_ms": 2916.1388874053955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "1890s", "latency_ms": 2219.8076248168945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2577}, "5": {"k": 5, "answer": "1890s", "latency_ms": 2290.0989055633545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3213}, "6": {"k": 6, "answer": "1890s", "latency_ms": 1732.3145866394043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3808}}}
{"qid": "6019244948248861067", "question": "who wrote were going on a bear hunt", "gold_answers": ["Michael Rosen"], "shots": {"0": {"k": 0, "answer": "Michael Rosen", "latency_ms": 1530.315637588501, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Rosen", "latency_ms": 1019.5789337158203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "Michael Rosen", "latency_ms": 1979.461431503296, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Michael Rosen", "latency_ms": 1990.785837173462, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Michael Rosen", "latency_ms": 1678.0986785888672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "Michael Rosen", "latency_ms": 2044.1200733184814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3067}, "6": {"k": 6, "answer": "Michael Rosen", "latency_ms": 1936.2387657165527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3701}}}
{"qid": "8753987902863757141", "question": "what is the revolution period of venus in earth years", "gold_answers": ["0.615 198 yr", "224.7 Earth days"], "shots": {"0": {"k": 0, "answer": "0.61519726", "latency_ms": 2815.196752548218, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0.62", "latency_ms": 1585.9668254852295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "0.62", "latency_ms": 2469.2556858062744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "0.62", "latency_ms": 2182.2969913482666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "0.62", "latency_ms": 1881.1848163604736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2529}, "5": {"k": 5, "answer": "0.615 Earth years", "latency_ms": 2718.4669971466064, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "0.615 Earth years", "latency_ms": 3004.0507316589355, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3772}}}
{"qid": "-5904934687784134086", "question": "who has the power to approve or veto legislation constitution", "gold_answers": ["the President"], "shots": {"0": {"k": 0, "answer": "The President", "latency_ms": 493.04986000061035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The president", "latency_ms": 1832.8750133514404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "The president and Congress", "latency_ms": 1787.0943546295166, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1368}, "3": {"k": 3, "answer": "The president", "latency_ms": 2266.105890274048, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1988}, "4": {"k": 4, "answer": "The president", "latency_ms": 1688.934087753296, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2671}, "5": {"k": 5, "answer": "The President and Congress", "latency_ms": 2214.2820358276367, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3385}, "6": {"k": 6, "answer": "The President", "latency_ms": 1746.6669082641602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4034}}}
{"qid": "-1910743846708408775", "question": "when was the taming ofthe shrew first performed", "gold_answers": ["prior to June 1592"], "shots": {"0": {"k": 0, "answer": "1593-1594", "latency_ms": 3121.4330196380615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1667", "latency_ms": 1232.4976921081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "11 June 1594", "latency_ms": 1951.6899585723877, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "11 June 1594", "latency_ms": 3028.554916381836, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1976}, "4": {"k": 4, "answer": "11 June 1594", "latency_ms": 2503.74174118042, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2597}, "5": {"k": 5, "answer": "11 June 1594", "latency_ms": 3009.8049640655518, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3275}, "6": {"k": 6, "answer": "11 June 1594", "latency_ms": 2745.661735534668, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3907}}}
{"qid": "6521877788261380307", "question": "who is the first prime minister of france", "gold_answers": ["Michel Debr"], "shots": {"0": {"k": 0, "answer": "Adolphe Thiers", "latency_ms": 3037.694215774536, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2346.648693084717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1903.9206504821777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1324}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2879.694700241089, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2375.14591217041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2599}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2297.437906265259, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3231}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2316.983938217163, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3825}}}
{"qid": "-3375621376413612480", "question": "list of strict nature reserve in the philippines", "gold_answers": ["Lake Malimanga", "Palawan", "Calavite and FB Harrison", "Olango Island", "Calauit Safari Park", "Lake Buluan"], "shots": {"0": {"k": 0, "answer": "Verde Island Passage, Mayon Volcano, El Nido Managed Resource Protected Area", "latency_ms": 7311.337471008301, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2684.71622467041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2980.8990955352783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1294}, "3": {"k": 3, "answer": "Masungi Georeserve", "latency_ms": 3029.8831462860107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1946}, "4": {"k": 4, "answer": "Masungi Georeserve", "latency_ms": 2512.0649337768555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2599}, "5": {"k": 5, "answer": "Masungi Georeserve", "latency_ms": 3010.4594230651855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3282}, "6": {"k": 6, "answer": "Masungi Georeserve", "latency_ms": 3461.5638256073, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3898}}}
{"qid": "-7848107192827858958", "question": "where do the events in the story take place geographically", "gold_answers": ["Persia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 3196.9919204711914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Peloponnese and Ionian Islands", "latency_ms": 3439.06569480896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "Peloponnese and Ionian Islands", "latency_ms": 3662.9931926727295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Peloponnese and Ionian Islands", "latency_ms": 4425.1954555511475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1903}, "4": {"k": 4, "answer": "Peloponnese and Ionian Islands", "latency_ms": 4202.409982681274, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2502}, "5": {"k": 5, "answer": "Peloponnese and Ionian Islands", "latency_ms": 3684.467077255249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3064}, "6": {"k": 6, "answer": "Middle-earth", "latency_ms": 1505.363941192627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3686}}}
{"qid": "-5123704261908217758", "question": "how and why were serial novels a phenomenon in the nineteenth century", "gold_answers": ["improved economics of distribution", "the rise of literacy", "technological advances in printing"], "shots": {"0": {"k": 0, "answer": "Cheap printing technology", "latency_ms": 2822.8936195373535, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "serialization and audience reaction", "latency_ms": 1459.115982055664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "serialization and audience reaction", "latency_ms": 2361.8080615997314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1378}, "3": {"k": 3, "answer": "serialization and part-publication", "latency_ms": 2924.8759746551514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2047}, "4": {"k": 4, "answer": "Responding to audience reaction and capitalizing on sensationalism.", "latency_ms": 5712.130308151245, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2797}, "5": {"k": 5, "answer": "Serialization and part-publication.", "latency_ms": 3641.98899269104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3498}, "6": {"k": 6, "answer": "Serialization and part-publication.", "latency_ms": 3754.0345191955566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4218}}}
{"qid": "8893432128322519771", "question": "who eliminated costa rica in world cup 2014", "gold_answers": ["Netherlands"], "shots": {"0": {"k": 0, "answer": "Netherlands", "latency_ms": 1442.4388408660889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2580.4553031921387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Netherlands", "latency_ms": 1748.5690116882324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Netherlands", "latency_ms": 1639.6839618682861, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Netherlands", "latency_ms": 2292.4418449401855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Netherlands", "latency_ms": 1761.2733840942383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3124}, "6": {"k": 6, "answer": "Netherlands", "latency_ms": 1481.5125465393066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3741}}}
{"qid": "-1356405650810931451", "question": "how many countries touches the land boundary of india", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "6", "latency_ms": 1702.6889324188232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "6", "latency_ms": 1244.4648742675781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "6", "latency_ms": 1680.403709411621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "6", "latency_ms": 1157.2492122650146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1990}, "4": {"k": 4, "answer": "6", "latency_ms": 1755.5961608886719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2749}, "5": {"k": 5, "answer": "6", "latency_ms": 1198.0986595153809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3426}, "6": {"k": 6, "answer": "6", "latency_ms": 1187.8857612609863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4097}}}
{"qid": "6447777231012695504", "question": "who was the 11th prime minister of canada", "gold_answers": ["R.B. Bennett", "Arthur Meighen"], "shots": {"0": {"k": 0, "answer": "William Lyon Mackenzie King", "latency_ms": 2468.4879779815674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1901.5579223632812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2575.5765438079834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1367}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1342.381238937378, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2021}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2053.5595417022705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2647}, "5": {"k": 5, "answer": "William Lyon Mackenzie King", "latency_ms": 2471.588611602783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3376}, "6": {"k": 6, "answer": "Sir Charles Tupper", "latency_ms": 2343.475341796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4018}}}
{"qid": "-5935683210985272192", "question": "when did the steel mills closed in youngstown ohio", "gold_answers": ["September 19 , 1977"], "shots": {"0": {"k": 0, "answer": "1977", "latency_ms": 1357.8822612762451, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1984", "latency_ms": 1586.460828781128, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "1984", "latency_ms": 1534.276008605957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "1977", "latency_ms": 1482.3062419891357, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "September 19, 1977", "latency_ms": 3437.681198120117, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2644}, "5": {"k": 5, "answer": "Late 1970s", "latency_ms": 2409.4271659851074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3235}, "6": {"k": 6, "answer": "Late 1970s", "latency_ms": 2751.1117458343506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3848}}}
{"qid": "1834961239491311230", "question": "who owns and operates the panama canal today", "gold_answers": ["Panama Canal Authority", "Panama", "Panamanian government"], "shots": {"0": {"k": 0, "answer": "The Panama Canal Authority", "latency_ms": 2084.10382270813, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kansas City Southern and Mi-Jack Products", "latency_ms": 3909.381628036499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "Panama Canal Authority", "latency_ms": 2461.353302001953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Panama Canal Authority", "latency_ms": 2330.5492401123047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Panamanian government", "latency_ms": 2141.1664485931396, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2621}, "5": {"k": 5, "answer": "Panamanian government", "latency_ms": 2909.4903469085693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3306}, "6": {"k": 6, "answer": "Panamanian government", "latency_ms": 2447.439193725586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "-535648230475805474", "question": "where is a simple gear train used in real life", "gold_answers": ["Automobile drivetrains"], "shots": {"0": {"k": 0, "answer": "Bicycle", "latency_ms": 1771.456003189087, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "automobile manual transmission", "latency_ms": 1671.2427139282227, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "automobile manual transmission", "latency_ms": 2145.0657844543457, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "Automobile manual transmission", "latency_ms": 1893.0394649505615, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1842}, "4": {"k": 4, "answer": "automobile manual transmission", "latency_ms": 1953.352689743042, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2430}, "5": {"k": 5, "answer": "automobile manual transmission", "latency_ms": 1780.0192832946777, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3022}, "6": {"k": 6, "answer": "automobile manual transmission", "latency_ms": 2720.0231552124023, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3672}}}
{"qid": "8911390210346559626", "question": "who plays the dad in malcom in the middle", "gold_answers": ["Bryan Cranston"], "shots": {"0": {"k": 0, "answer": "Bryan Cranston", "latency_ms": 2147.29905128479, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2119.398593902588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2831.833600997925, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2254.1632652282715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1915.6250953674316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2432.649612426758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3115}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2327.6195526123047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3737}}}
{"qid": "-8336776482564898273", "question": "who has won the most world series in baseball", "gold_answers": ["the New York Yankees", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "New York Yankees", "latency_ms": 1588.5019302368164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yogi Berra and Frankie Crosetti", "latency_ms": 4375.783205032349, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "New York Yankees", "latency_ms": 2184.032201766968, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1168}, "3": {"k": 3, "answer": "New York Yankees", "latency_ms": 2582.6218128204346, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1853}, "4": {"k": 4, "answer": "New York Yankees", "latency_ms": 1514.0843391418457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2480}, "5": {"k": 5, "answer": "New York Yankees", "latency_ms": 2291.255235671997, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3087}, "6": {"k": 6, "answer": "New York Yankees", "latency_ms": 1811.1591339111328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3694}}}
{"qid": "-8742089114148260796", "question": "where are the winter olympic games being played", "gold_answers": ["Beijing"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1708.8303565979004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sapporo, Nagano, and East Asia", "latency_ms": 4890.643835067749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Sapporo, Nagano, Seoul, Pyeongchang, Tokyo, Beijing, Graz, Schladming, Austria", "latency_ms": 8045.262336730957, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 1273}, "3": {"k": 3, "answer": "East Asia", "latency_ms": 2336.1122608184814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "Various locations", "latency_ms": 1015.3050422668457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2590}, "5": {"k": 5, "answer": "Various locations.", "latency_ms": 2421.6415882110596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "Various locations.", "latency_ms": 1889.4586563110352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3784}}}
{"qid": "3864930130255054488", "question": "who made the song falling in love with you", "gold_answers": ["Hugo Peretti", "Elvis Presley", "George David Weiss", "Luigi Creatore"], "shots": {"0": {"k": 0, "answer": "UB40", "latency_ms": 1777.841567993164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Victor Young and Edward Heyman", "latency_ms": 2561.758041381836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 5643.435716629028, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1196}, "3": {"k": 3, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 3608.5383892059326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1820}, "4": {"k": 4, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 5551.641225814819, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2447}, "5": {"k": 5, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 5750.336408615112, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3031}, "6": {"k": 6, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 5285.211563110352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3637}}}
{"qid": "8076743617384207713", "question": "where did saudi crown prince go to college", "gold_answers": ["King Saud University"], "shots": {"0": {"k": 0, "answer": "King Saud University", "latency_ms": 2116.3556575775146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1948.1489658355713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2240.705966949463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1378}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1642.000436782837, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2174.1344928741455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2122.6484775543213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2919.928550720215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3757}}}
{"qid": "1735766792677422630", "question": "who did the singing in into the woods", "gold_answers": ["the cast", "the cast members"], "shots": {"0": {"k": 0, "answer": "Meryl Streep", "latency_ms": 2324.937343597412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "All join in", "latency_ms": 2660.1603031158447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "the cast", "latency_ms": 1533.585786819458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "The cast", "latency_ms": 2338.221311569214, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1902}, "4": {"k": 4, "answer": "The cast", "latency_ms": 1484.612226486206, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2526}, "5": {"k": 5, "answer": "The cast", "latency_ms": 755.1877498626709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3133}, "6": {"k": 6, "answer": "Bernadette Peters", "latency_ms": 2716.6309356689453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3746}}}
{"qid": "5711801828691961426", "question": "who was the viceroy when the simon commission visited india", "gold_answers": ["Lord Irwin"], "shots": {"0": {"k": 0, "answer": "Lord Irwin", "latency_ms": 1369.5180416107178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1589.8213386535645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "Lord Irwin", "latency_ms": 2044.02756690979, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Lord Irwin", "latency_ms": 2061.6614818573, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1972}, "4": {"k": 4, "answer": "Lord Irwin", "latency_ms": 2766.13712310791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Lord Irwin", "latency_ms": 1260.7336044311523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3260}, "6": {"k": 6, "answer": "Lord Irwin", "latency_ms": 2370.732545852661, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3915}}}
{"qid": "9001143341771379731", "question": "who in germany signed the treaty of versailles", "gold_answers": ["colonial minister Johannes Bell", "Foreign minister Hermann Mller", "Gustav Bauer"], "shots": {"0": {"k": 0, "answer": "Ulrich Graf von Brockdorff-Rantzau", "latency_ms": 4180.623292922974, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 2293.257474899292, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 3619.4000244140625, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 2646.0957527160645, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 3522.303342819214, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 2540}, "5": {"k": 5, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 3077.53849029541, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3169}, "6": {"k": 6, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 3272.6728916168213, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3769}}}
{"qid": "-4619585332904698754", "question": "who holds the record for most platinum albums", "gold_answers": ["The Beatles", "AC / DC", "Elvis Presley"], "shots": {"0": {"k": 0, "answer": "Garth Brooks", "latency_ms": 2404.881477355957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elvis Presley", "latency_ms": 1211.869478225708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Elvis Presley", "latency_ms": 2667.630672454834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1340}, "3": {"k": 3, "answer": "Elvis Presley", "latency_ms": 1913.4061336517334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1965}, "4": {"k": 4, "answer": "Elvis Presley", "latency_ms": 2443.13383102417, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2630}, "5": {"k": 5, "answer": "Elvis Presley", "latency_ms": 2692.6920413970947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3279}, "6": {"k": 6, "answer": "Elvis Presley", "latency_ms": 2463.5677337646484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3908}}}
{"qid": "-720512252272678238", "question": "when did the movie the post begin filming", "gold_answers": ["May 30 , 2017", "May 2017"], "shots": {"0": {"k": 0, "answer": "May 30, 2016", "latency_ms": 3127.082347869873, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2199.0041732788086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1886.2457275390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1179}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1918.5924530029297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1850}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1120.527744293213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2502}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2220.085620880127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3233}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2644.779682159424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3860}}}
{"qid": "-3371798557886238687", "question": "who starred in an officer and a gentleman", "gold_answers": ["Louis Gossett Jr .", "David Keith", "Louis Gossett Jr.", "Richard Gere", "Debra Winger", "Phillip J. Salmon"], "shots": {"0": {"k": 0, "answer": "Richard Gere", "latency_ms": 1893.4612274169922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 5180.32169342041, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 4484.180688858032, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 5694.172620773315, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1850}, "4": {"k": 4, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 6532.283544540405, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 5764.468431472778, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3152}, "6": {"k": 6, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 5532.377243041992, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3788}}}
