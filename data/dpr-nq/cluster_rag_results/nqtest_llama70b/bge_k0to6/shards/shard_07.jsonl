{"qid": "5306300389470118812", "question": "what was the religion in persia before islam", "gold_answers": ["the Zoroastrian religion", "Zoroastrian"], "shots": {"0": {"k": 0, "answer": "Zoroastrianism", "latency_ms": 895.3037261962891, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Zoroastrianism", "latency_ms": 841.5203094482422, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "Zoroastrianism", "latency_ms": 874.6895790100098, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1396}, "3": {"k": 3, "answer": "Zoroastrianism", "latency_ms": 636.1868381500244, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2068}, "4": {"k": 4, "answer": "Zoroastrianism", "latency_ms": 666.6903495788574, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2746}, "5": {"k": 5, "answer": "Zoroastrianism", "latency_ms": 858.3905696868896, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3482}, "6": {"k": 6, "answer": "Zoroastrianism", "latency_ms": 664.4799709320068, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 4192}}}
{"qid": "4492088526674104172", "question": "why does kerosene oil rise up in the wick of lantern", "gold_answers": ["capillary action"], "shots": {"0": {"k": 0, "answer": "Capillary action", "latency_ms": 315.46759605407715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Capillary action", "latency_ms": 511.7917060852051, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "Capillary action", "latency_ms": 714.317798614502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Capillary action", "latency_ms": 514.7666931152344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1785}, "4": {"k": 4, "answer": "Capillary action", "latency_ms": 499.3739128112793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2402}, "5": {"k": 5, "answer": "Capillary action", "latency_ms": 548.2096672058105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3021}, "6": {"k": 6, "answer": "Capillary action", "latency_ms": 559.2122077941895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3676}}}
{"qid": "-4373262132142058334", "question": "mention the chemical change that proinsulin undergo to be able to act as mature insulin", "gold_answers": ["post translational modification"], "shots": {"0": {"k": 0, "answer": "Proteolytic cleavage", "latency_ms": 493.0908679962158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cleavage of C-peptide", "latency_ms": 977.2763252258301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Cleavage of C-peptide.", "latency_ms": 1006.4373016357422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "Cleavage of C-peptide", "latency_ms": 786.6623401641846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1967}, "4": {"k": 4, "answer": "Cleavage of C-peptide", "latency_ms": 760.7293128967285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Cleavage of C-peptide", "latency_ms": 980.4792404174805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Cleavage of C-peptide", "latency_ms": 801.6924858093262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3834}}}
{"qid": "-5298560410953979569", "question": "where does the sweetness of fruit come from", "gold_answers": ["Fructose , or fruit sugar", "Fructose"], "shots": {"0": {"k": 0, "answer": "Fructose", "latency_ms": 247.25914001464844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 546.8342304229736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "Sucrose", "latency_ms": 630.3951740264893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "photosynthesis", "latency_ms": 426.42998695373535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "photosynthesis", "latency_ms": 453.68337631225586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2636}, "5": {"k": 5, "answer": "photosynthesis", "latency_ms": 438.4586811065674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3332}, "6": {"k": 6, "answer": "photosynthesis", "latency_ms": 434.1883659362793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4020}}}
{"qid": "4344648368832551136", "question": "an object that moves around an external axis is said to be", "gold_answers": ["orbit", "revolution or orbital revolution"], "shots": {"0": {"k": 0, "answer": "rotating", "latency_ms": 242.70105361938477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "revolving", "latency_ms": 626.5146732330322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "revolving", "latency_ms": 442.0773983001709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "revolving", "latency_ms": 425.1718521118164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1758}, "4": {"k": 4, "answer": "revolving", "latency_ms": 422.34158515930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2325}, "5": {"k": 5, "answer": "revolving", "latency_ms": 442.77095794677734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2938}, "6": {"k": 6, "answer": "revolving", "latency_ms": 635.7378959655762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3603}}}
{"qid": "-724426540432437711", "question": "what was the name of the plant on little shop of horrors", "gold_answers": ["Audrey II"], "shots": {"0": {"k": 0, "answer": "Audrey II", "latency_ms": 316.23268127441406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Audrey II", "latency_ms": 495.6831932067871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Audrey II", "latency_ms": 498.21925163269043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Audrey II", "latency_ms": 525.1851081848145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "Audrey II", "latency_ms": 481.02736473083496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2594}, "5": {"k": 5, "answer": "Audrey II", "latency_ms": 722.0418453216553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Audrey II", "latency_ms": 691.0006999969482, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3852}}}
{"qid": "-5541610970112826260", "question": "who signed the declaration of independence for maryland", "gold_answers": ["Samuel Chase", "Charles Carroll of Carrollton", "Thomas Stone", "William Paca"], "shots": {"0": {"k": 0, "answer": "Samuel Chase", "latency_ms": 544.3599224090576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 1993.6914443969727, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 704}, "2": {"k": 2, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 1784.0831279754639, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 1294}, "3": {"k": 3, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 2170.5305576324463, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 1752.9253959655762, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 2568}, "5": {"k": 5, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 1942.4824714660645, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 2030.1222801208496, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 3921}}}
{"qid": "-86997217831791339", "question": "when does wonder woman come out on blue ray", "gold_answers": ["September 19 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 528.4936428070068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1005.1286220550537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "September 19, 2017", "latency_ms": 940.8714771270752, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1194}, "3": {"k": 3, "answer": "September 19, 2017", "latency_ms": 1207.1521282196045, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "September 19, 2017", "latency_ms": 1246.4847564697266, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "September 19, 2017", "latency_ms": 1197.786808013916, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "September 19, 2017", "latency_ms": 783.0870151519775, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3825}}}
{"qid": "-8062812506672279762", "question": "what nba team did derrick rose play for", "gold_answers": ["New York Knicks", "Minnesota Timberwolves", "Chicago Bulls", "Cleveland Cavaliers"], "shots": {"0": {"k": 0, "answer": "Chicago Bulls", "latency_ms": 456.51888847351074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York (implied, not directly stated, however other teams are mentioned that he played against)", "latency_ms": 2494.138479232788, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "New York Knicks, Cleveland Cavaliers, Oklahoma City Thunder, Washington Wizards, Boston Celtics, Chicago, Portland Trail Blazers, New Orleans Pelicans", "latency_ms": 3201.9107341766357, "em": 0.0, "f1": 0.2727272727272727, "containment": 1.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Washington Wizards, Oklahoma City Thunder, New Orleans Pelicans, Boston Celtics, Portland Trail Blazers, New York Knicks, Cleveland Cavaliers, Orlando Magic, Utah Jazz, Sacramento Kings, Minnesota Timberwolves", "latency_ms": 3941.754102706909, "em": 0.0, "f1": 0.20689655172413793, "containment": 1.0, "context_chars": 1766}, "4": {"k": 4, "answer": "New York Knicks, Cleveland Cavaliers, Minnesota Timberwolves, Boston Celtics, Chicago Bulls, Utah Jazz, Oklahoma City Thunder, Washington Wizards, Sacramento Kings, Orlando Magic", "latency_ms": 3202.0599842071533, "em": 0.0, "f1": 0.24000000000000005, "containment": 1.0, "context_chars": 2344}, "5": {"k": 5, "answer": "New York Knicks, Cleveland Cavaliers, Minnesota Timberwolves, Chicago Bulls, Utah Jazz", "latency_ms": 1793.447494506836, "em": 0.0, "f1": 0.42857142857142855, "containment": 1.0, "context_chars": 2919}, "6": {"k": 6, "answer": "New York Knicks, Cleveland Cavaliers, Minnesota Timberwolves, Chicago Bulls, Utah Jazz", "latency_ms": 1990.2520179748535, "em": 0.0, "f1": 0.42857142857142855, "containment": 1.0, "context_chars": 3483}}}
{"qid": "7933002036740390435", "question": "where did the term liberal arts come from", "gold_answers": ["the Roman Empire"], "shots": {"0": {"k": 0, "answer": "Medieval Europe", "latency_ms": 501.1124610900879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roman Empire", "latency_ms": 676.4316558837891, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Roman Empire", "latency_ms": 421.18310928344727, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Roman Empire", "latency_ms": 614.6416664123535, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Roman Empire", "latency_ms": 447.83926010131836, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "Roman Empire", "latency_ms": 450.37341117858887, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3228}, "6": {"k": 6, "answer": "Roman Empire", "latency_ms": 598.2205867767334, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3962}}}
{"qid": "-2991400700385487821", "question": "who heads the executive department of west virginia government", "gold_answers": ["the Governor of West Virginia", "the governor of West Virginia", "Jim Justice"], "shots": {"0": {"k": 0, "answer": "The Governor", "latency_ms": 251.68108940124512, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The governor", "latency_ms": 416.95165634155273, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "The governor", "latency_ms": 651.4325141906738, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "The governor", "latency_ms": 451.63679122924805, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2017}, "4": {"k": 4, "answer": "The governor", "latency_ms": 433.53962898254395, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2661}, "5": {"k": 5, "answer": "The governor", "latency_ms": 650.5258083343506, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3312}, "6": {"k": 6, "answer": "The governor", "latency_ms": 450.7462978363037, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3955}}}
{"qid": "-9186689755642837558", "question": "how long is the bridge between new brunswick and prince edward island", "gold_answers": ["12.9 - kilometre"], "shots": {"0": {"k": 0, "answer": "13 kilometers", "latency_ms": 242.10405349731445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 809.2617988586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 733}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 802.3350238800049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1421}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 612.602949142456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2090}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 783.311128616333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2777}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 577.6431560516357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3368}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 767.279863357544, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4029}}}
{"qid": "8029901619424338449", "question": "when did the uk and us become allies", "gold_answers": ["1940", "Since 1940"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 567.4266815185547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1958", "latency_ms": 662.2138023376465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "1958", "latency_ms": 619.4779872894287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1380}, "3": {"k": 3, "answer": "1958", "latency_ms": 639.0612125396729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "1958", "latency_ms": 455.1374912261963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2733}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 749.1509914398193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3379}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 755.9483051300049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3989}}}
{"qid": "4828649525820722736", "question": "who sang the theme song for the man with the golden gun", "gold_answers": ["Lulu"], "shots": {"0": {"k": 0, "answer": "Lulu", "latency_ms": 242.04659461975098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lulu", "latency_ms": 614.161491394043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Lulu", "latency_ms": 449.4190216064453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Lulu", "latency_ms": 638.4897232055664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1791}, "4": {"k": 4, "answer": "Lulu", "latency_ms": 646.761417388916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2446}, "5": {"k": 5, "answer": "Lulu", "latency_ms": 485.7172966003418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3096}, "6": {"k": 6, "answer": "Lulu", "latency_ms": 638.3161544799805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3703}}}
{"qid": "-7924663090486742985", "question": "american horror story freak show girl kidnapped by clown", "gold_answers": ["Bonnie Lipton"], "shots": {"0": {"k": 0, "answer": "Penny", "latency_ms": 445.14966011047363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Twisty", "latency_ms": 440.86480140686035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "Dot Tattler", "latency_ms": 800.3311157226562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Dot Tattler", "latency_ms": 783.653736114502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "Dot Tattler", "latency_ms": 941.2567615509033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "Dot Tattler", "latency_ms": 996.3157176971436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3231}, "6": {"k": 6, "answer": "Dot Tattler", "latency_ms": 564.0811920166016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3915}}}
{"qid": "-360675773049242516", "question": "the probability of making a type i error when retaining ho at the .05 level of significance is", "gold_answers": ["5 %"], "shots": {"0": {"k": 0, "answer": "0.05", "latency_ms": 500.0274181365967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0.05", "latency_ms": 708.4217071533203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "0%", "latency_ms": 440.690279006958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1167}, "3": {"k": 3, "answer": "5%", "latency_ms": 657.2127342224121, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1759}, "4": {"k": 4, "answer": "0.05", "latency_ms": 694.5364475250244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2325}, "5": {"k": 5, "answer": "0.05", "latency_ms": 710.3919982910156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2960}, "6": {"k": 6, "answer": "0.05", "latency_ms": 507.9774856567383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3634}}}
{"qid": "5819386267283467034", "question": "what year did the us hockey team won the olympics", "gold_answers": ["1960", "1980", "1960 and 1980"], "shots": {"0": {"k": 0, "answer": "1980", "latency_ms": 509.75799560546875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1960, 1980", "latency_ms": 897.6728916168213, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "1960, 1980", "latency_ms": 886.6870403289795, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1310}, "3": {"k": 3, "answer": "1960, 1980", "latency_ms": 1139.2395496368408, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1913}, "4": {"k": 4, "answer": "1960, 1980", "latency_ms": 935.3981018066406, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2510}, "5": {"k": 5, "answer": "1960, 1980", "latency_ms": 921.8227863311768, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3113}, "6": {"k": 6, "answer": "1960, 1980", "latency_ms": 943.1159496307373, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3724}}}
{"qid": "3916394566028297311", "question": "who wrote it's a long long way to pasadena", "gold_answers": ["Harry Vanda", "John Young", "David Hemmings", "George Young"], "shots": {"0": {"k": 0, "answer": "Albert E. Brumley", "latency_ms": 702.8732299804688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Harry Vanda, George Young, David Hemmings", "latency_ms": 1240.3781414031982, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 790.3025150299072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 786.937952041626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1902}, "4": {"k": 4, "answer": "Harry Vanda and George Young and David Hemmings", "latency_ms": 1226.6130447387695, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 596.7087745666504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 799.0024089813232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "-2432292250757146771", "question": "who wrote the song i hate you i love you", "gold_answers": ["Angel Benitez", "Olivia O'Brien", "Garrett Nash"], "shots": {"0": {"k": 0, "answer": "Gnash", "latency_ms": 302.1852970123291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 738.4610176086426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "Gnash", "latency_ms": 740.041971206665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "Gnash", "latency_ms": 778.1071662902832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1831}, "4": {"k": 4, "answer": "Gnash", "latency_ms": 785.9354019165039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2494}, "5": {"k": 5, "answer": "Gnash and Olivia O'Brien", "latency_ms": 968.0349826812744, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3069}, "6": {"k": 6, "answer": "Gnash and Olivia O'Brien", "latency_ms": 957.2513103485107, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3643}}}
{"qid": "2393389448844632496", "question": "what is loihi and where does it originate from", "gold_answers": ["from the Hawaii hotspot"], "shots": {"0": {"k": 0, "answer": "Loihi, Hawaii", "latency_ms": 626.7166137695312, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 779.6449661254883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 564.8782253265381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1185}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 769.0238952636719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1793}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 818.4726238250732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 802.0532131195068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3027}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 609.6780300140381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3592}}}
{"qid": "-6677440871585683891", "question": "who rebuilt the temple after the babylonian captivity", "gold_answers": ["Herod"], "shots": {"0": {"k": 0, "answer": "Zerubbabel", "latency_ms": 556.2171936035156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The exiles", "latency_ms": 668.9028739929199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "Haggai and Zechariah", "latency_ms": 1105.3833961486816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1201}, "3": {"k": 3, "answer": "Haggai and Zechariah", "latency_ms": 1135.6801986694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1820}, "4": {"k": 4, "answer": "Haggai and Zechariah", "latency_ms": 957.0386409759521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2408}, "5": {"k": 5, "answer": "Haggai and Zechariah", "latency_ms": 1173.022747039795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3104}, "6": {"k": 6, "answer": "Haggai and Zechariah", "latency_ms": 1164.3640995025635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3710}}}
{"qid": "-6750750235985613277", "question": "who was executed for being an american spy during the revolutionary war", "gold_answers": ["Nathan Hale"], "shots": {"0": {"k": 0, "answer": "Nathan Hale", "latency_ms": 530.2040576934814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nathan Hale", "latency_ms": 479.7501564025879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 593}, "2": {"k": 2, "answer": "Nathan Hale", "latency_ms": 721.5662002563477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1157}, "3": {"k": 3, "answer": "Nathan Hale", "latency_ms": 754.2130947113037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1739}, "4": {"k": 4, "answer": "Nathan Hale", "latency_ms": 710.2315425872803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2384}, "5": {"k": 5, "answer": "Nathan Hale", "latency_ms": 723.5593795776367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3008}, "6": {"k": 6, "answer": "Nathan Hale", "latency_ms": 732.795238494873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3594}}}
{"qid": "8770209312170080158", "question": "who sang the song suddenly with olivia newton john", "gold_answers": ["Cliff Richard"], "shots": {"0": {"k": 0, "answer": "Cliff Richard", "latency_ms": 532.041072845459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cliff Richard", "latency_ms": 522.730827331543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "Cliff Richard", "latency_ms": 752.6044845581055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1198}, "3": {"k": 3, "answer": "Cliff Richard", "latency_ms": 717.3519134521484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Cliff Richard", "latency_ms": 683.6836338043213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2402}, "5": {"k": 5, "answer": "Cliff Richard", "latency_ms": 742.4659729003906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3014}, "6": {"k": 6, "answer": "Cliff Richard", "latency_ms": 526.2510776519775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3672}}}
{"qid": "-180549795106449014", "question": "who is command sergeant major of the army", "gold_answers": ["Daniel A. Dailey"], "shots": {"0": {"k": 0, "answer": "Michael A. Grinston", "latency_ms": 647.0861434936523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 745.980978012085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 566.0088062286377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 749.1881847381592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 743.6683177947998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2453}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 760.4629993438721, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3123}, "6": {"k": 6, "answer": "Kenneth Preston", "latency_ms": 752.9950141906738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3732}}}
{"qid": "7815138213728640354", "question": "who sings the original windmills of your mind", "gold_answers": ["Noel Harrison"], "shots": {"0": {"k": 0, "answer": "Noel Harrison", "latency_ms": 486.5536689758301, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 818.2806968688965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "No singer mentioned", "latency_ms": 508.24809074401855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "No singer mentioned", "latency_ms": 721.3284969329834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Noel Harrison", "latency_ms": 494.36020851135254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2525}, "5": {"k": 5, "answer": "Noel Harrison", "latency_ms": 757.544994354248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3206}, "6": {"k": 6, "answer": "Noel Harrison", "latency_ms": 548.3901500701904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3812}}}
{"qid": "2098168902147822379", "question": "where will the next summer and winter olympics be held", "gold_answers": ["Beijing", "Tokyo"], "shots": {"0": {"k": 0, "answer": "Paris 2024 and Milan-Cortina 2026.", "latency_ms": 1376.6937255859375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Beijing", "latency_ms": 444.1254138946533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 623}, "2": {"k": 2, "answer": "Beijing, Tokyo, Paris, Los Angeles", "latency_ms": 1094.3856239318848, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Tokyo, Beijing, Paris, Los Angeles", "latency_ms": 1116.0461902618408, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1863}, "4": {"k": 4, "answer": "Tokyo, Beijing, Paris, Los Angeles", "latency_ms": 861.8190288543701, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2534}, "5": {"k": 5, "answer": "Tokyo, Beijing, Paris, Los Angeles, Beijing", "latency_ms": 1501.3761520385742, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 3135}, "6": {"k": 6, "answer": "Tokyo, Beijing, Paris, Los Angeles", "latency_ms": 1357.9092025756836, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3784}}}
{"qid": "-1458476052377668874", "question": "when did ole miss beat alabama in football", "gold_answers": ["September 19 , 2015", "October 3 , 1970", "October 27 , 1894", "October 13 , 2001", "October 5 , 1968", "October 4 , 2014", "September 11 , 1976", "October 8 , 1988", "October 18 , 2003", "November 5 , 1910"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 469.684362411499, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 822.3705291748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "1988", "latency_ms": 452.6066780090332, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "1988", "latency_ms": 462.1272087097168, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "1988, 2015", "latency_ms": 886.2102031707764, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2482}, "5": {"k": 5, "answer": "1988", "latency_ms": 698.4138488769531, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "1988, 2014", "latency_ms": 880.1147937774658, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3801}}}
{"qid": "-6861734002351236912", "question": "who sang the song how far is heaven", "gold_answers": ["Los Lonely Boys"], "shots": {"0": {"k": 0, "answer": "Nitty Gritty Dirt Band", "latency_ms": 736.6104125976562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 756.7934989929199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 747.4756240844727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "Carol Sue", "latency_ms": 489.429235458374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Carol Sue", "latency_ms": 403.52869033813477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Carol Sue", "latency_ms": 706.1607837677002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3114}, "6": {"k": 6, "answer": "Carol Sue", "latency_ms": 668.7545776367188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3725}}}
{"qid": "-1722216190521937227", "question": "where are the organ mountains in new mexico", "gold_answers": ["southern New Mexico"], "shots": {"0": {"k": 0, "answer": "Las Cruces", "latency_ms": 297.4984645843506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "southern New Mexico", "latency_ms": 737.7288341522217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "southern New Mexico", "latency_ms": 755.3861141204834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1325}, "3": {"k": 3, "answer": "southern New Mexico", "latency_ms": 777.0392894744873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1986}, "4": {"k": 4, "answer": "southern New Mexico", "latency_ms": 762.9885673522949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2643}, "5": {"k": 5, "answer": "southern New Mexico", "latency_ms": 761.2757682800293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "southern New Mexico", "latency_ms": 740.5896186828613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3880}}}
{"qid": "-2717119588239727064", "question": "where are the 10 plagues found in the bible", "gold_answers": ["Book of Exodus", "Exodus"], "shots": {"0": {"k": 0, "answer": "Exodus 7-12", "latency_ms": 687.9613399505615, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Book of Exodus", "latency_ms": 674.6466159820557, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Book of Exodus", "latency_ms": 483.92462730407715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Book of Exodus", "latency_ms": 747.1170425415039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1887}, "4": {"k": 4, "answer": "Book of Exodus", "latency_ms": 753.525972366333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2506}, "5": {"k": 5, "answer": "Book of Exodus", "latency_ms": 550.443172454834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3129}, "6": {"k": 6, "answer": "Book of Exodus", "latency_ms": 673.8603115081787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3701}}}
{"qid": "2988284357714596500", "question": "where are red blood cells made in adults", "gold_answers": ["in the bone marrow"], "shots": {"0": {"k": 0, "answer": "Bone marrow", "latency_ms": 433.01916122436523, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "red bone marrow", "latency_ms": 743.0782318115234, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "red bone marrow", "latency_ms": 702.1732330322266, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "the red bone marrow", "latency_ms": 753.7384033203125, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "the red bone marrow", "latency_ms": 798.3901500701904, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2607}, "5": {"k": 5, "answer": "red bone marrow", "latency_ms": 495.19848823547363, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "the red bone marrow", "latency_ms": 784.7750186920166, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3840}}}
{"qid": "-4616596799374362422", "question": "who was the pinkerton detective agency's first female detective", "gold_answers": ["Kate Warne"], "shots": {"0": {"k": 0, "answer": "Kate Warne", "latency_ms": 312.88862228393555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kate Warne", "latency_ms": 711.4319801330566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Kate Warne", "latency_ms": 512.7911567687988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1235}, "3": {"k": 3, "answer": "Kate Warne", "latency_ms": 720.8700180053711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Kate Warne", "latency_ms": 496.0601329803467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2539}, "5": {"k": 5, "answer": "Kate Warne", "latency_ms": 802.3254871368408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Kate Warne", "latency_ms": 548.8169193267822, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3862}}}
{"qid": "-3650291155113659146", "question": "how many episodes are there in modern family", "gold_answers": ["232", "201"], "shots": {"0": {"k": 0, "answer": "250 episodes", "latency_ms": 489.3059730529785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "24", "latency_ms": 369.7850704193115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "24 episodes", "latency_ms": 481.6629886627197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "24 episodes", "latency_ms": 699.6135711669922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "24 episodes", "latency_ms": 487.90621757507324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2500}, "5": {"k": 5, "answer": "24 episodes", "latency_ms": 443.8643455505371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3178}, "6": {"k": 6, "answer": "24 episodes", "latency_ms": 459.27882194519043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3805}}}
{"qid": "3381924381590631417", "question": "who built the first temple for god in jerusalem", "gold_answers": ["Solomon"], "shots": {"0": {"k": 0, "answer": "King Solomon", "latency_ms": 420.31288146972656, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "King Solomon", "latency_ms": 437.7453327178955, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 661}, "2": {"k": 2, "answer": "King Solomon", "latency_ms": 627.9456615447998, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "Solomon", "latency_ms": 626.7757415771484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "King Solomon", "latency_ms": 427.9954433441162, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2508}, "5": {"k": 5, "answer": "King Solomon", "latency_ms": 647.9580402374268, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3145}, "6": {"k": 6, "answer": "King Solomon", "latency_ms": 682.4665069580078, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3790}}}
{"qid": "-154783694579651082", "question": "what is a dropped pin on google maps for", "gold_answers": ["marks locations", "marks locations in Google Maps"], "shots": {"0": {"k": 0, "answer": "Saving a location", "latency_ms": 304.28600311279297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "marking locations", "latency_ms": 722.8355407714844, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "to mark a point on a map", "latency_ms": 982.1910858154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "to mark a point on a map", "latency_ms": 1116.7433261871338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "to mark a point on a map", "latency_ms": 929.3918609619141, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "to mark a point on a map", "latency_ms": 1156.3055515289307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "to mark a point on a map", "latency_ms": 978.245735168457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "6915606477668963399", "question": "what do the 3 dots mean in math", "gold_answers": ["the therefore sign", "therefore sign"], "shots": {"0": {"k": 0, "answer": "Ellipsis", "latency_ms": 457.9646587371826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 840.8677577972412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "Infinitely repeating set of numbers", "latency_ms": 1104.3415069580078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Ellipsis", "latency_ms": 427.6421070098877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "Ellipsis", "latency_ms": 629.9831867218018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2407}, "5": {"k": 5, "answer": "Ellipsis", "latency_ms": 431.79917335510254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2985}, "6": {"k": 6, "answer": "Ellipsis", "latency_ms": 466.1135673522949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3645}}}
{"qid": "-8366545547296627039", "question": "who wrote the song photograph by ringo starr", "gold_answers": ["Richard Starkey", "George Harrison", "Ringo Starr"], "shots": {"0": {"k": 0, "answer": "Ringo Starr and George Harrison", "latency_ms": 914.8759841918945, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ringo Starr and George Harrison", "latency_ms": 875.9338855743408, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Ringo Starr and George Harrison", "latency_ms": 871.5999126434326, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Ringo Starr and George Harrison", "latency_ms": 1091.0141468048096, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1968}, "4": {"k": 4, "answer": "Ringo Starr and George Harrison", "latency_ms": 711.7228507995605, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2578}, "5": {"k": 5, "answer": "Ringo Starr and George Harrison", "latency_ms": 914.811372756958, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3302}, "6": {"k": 6, "answer": "Ringo Starr and George Harrison", "latency_ms": 1177.4859428405762, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3958}}}
{"qid": "-5004457603684974952", "question": "who is playing the halftime show at super bowl 2016", "gold_answers": ["Beyonc√©", "Coldplay", "Bruno Mars"], "shots": {"0": {"k": 0, "answer": "Coldplay", "latency_ms": 248.4445571899414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 787.2567176818848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Coldplay", "latency_ms": 738.0640506744385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "Coldplay", "latency_ms": 652.0965099334717, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Coldplay", "latency_ms": 444.7803497314453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2581}, "5": {"k": 5, "answer": "Coldplay", "latency_ms": 474.3955135345459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3225}, "6": {"k": 6, "answer": "Coldplay", "latency_ms": 440.48523902893066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3862}}}
{"qid": "7420920477821898435", "question": "to aru kagaku no railgun s episode 3", "gold_answers": ["Project Radio Noise"], "shots": {"0": {"k": 0, "answer": "Episode 3", "latency_ms": 552.2832870483398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1027.7976989746094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 545}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 812.6804828643799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1150}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 819.9458122253418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1753}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 796.2779998779297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2389}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 620.8846569061279, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3011}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 803.8363456726074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3631}}}
{"qid": "7478795216476346339", "question": "who won the 2017 sports personality of the year", "gold_answers": ["Mo Farah"], "shots": {"0": {"k": 0, "answer": "Mo Farah", "latency_ms": 520.2431678771973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 562.2231960296631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 800.0428676605225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 806.1997890472412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 787.6913547515869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2618}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 825.8602619171143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3278}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 792.2828197479248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3913}}}
{"qid": "7217222058435937287", "question": "where was the world economic forum held this year", "gold_answers": ["Davos"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 524.6453285217285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Davos", "latency_ms": 890.3086185455322, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 748.7623691558838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 799.0145683288574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1997}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 778.8541316986084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2673}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 771.674633026123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3277}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 806.5669536590576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3957}}}
{"qid": "-143054837169120955", "question": "where are the giant redwoods located in california", "gold_answers": ["the coast of northern California", "Del Norte County", "Humboldt County"], "shots": {"0": {"k": 0, "answer": "Northern California", "latency_ms": 447.41272926330566, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "western Sierra Nevada", "latency_ms": 656.4078330993652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "Sierra Nevada", "latency_ms": 692.1813488006592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "Sierra Nevada", "latency_ms": 509.02271270751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1869}, "4": {"k": 4, "answer": "San Francisco Bay", "latency_ms": 522.5832462310791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Western Sierra Nevada, California", "latency_ms": 823.3129978179932, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3252}, "6": {"k": 6, "answer": "Western Sierra Nevada, California", "latency_ms": 814.0873908996582, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3893}}}
{"qid": "4892429640540595424", "question": "who has made the most premier league appearances", "gold_answers": ["Gareth Barry"], "shots": {"0": {"k": 0, "answer": "Gareth Barry", "latency_ms": 543.8392162322998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 773.4651565551758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Steven Gerrard", "latency_ms": 726.536750793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Steven Gerrard", "latency_ms": 498.6886978149414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "Steven Gerrard", "latency_ms": 713.886022567749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2591}, "5": {"k": 5, "answer": "Steven Gerrard", "latency_ms": 508.5766315460205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3245}, "6": {"k": 6, "answer": "Steven Gerrard", "latency_ms": 520.7977294921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3899}}}
{"qid": "5533906981191706877", "question": "who was the first chief minister of west bengal", "gold_answers": ["Prafulla Chandra Ghosh"], "shots": {"0": {"k": 0, "answer": "Prafulla Chandra Ghosh", "latency_ms": 979.5317649841309, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Prafulla Chandra Ghosh", "latency_ms": 1074.8181343078613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Prafulla Chandra Ghosh", "latency_ms": 1273.951530456543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1347}, "3": {"k": 3, "answer": "Prafulla Chandra Ghosh", "latency_ms": 1046.9191074371338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1993}, "4": {"k": 4, "answer": "Prafulla Chandra Ghosh", "latency_ms": 1051.9671440124512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2708}, "5": {"k": 5, "answer": "Prafulla Chandra Ghosh", "latency_ms": 1201.977014541626, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3304}, "6": {"k": 6, "answer": "Prafulla Chandra Ghosh", "latency_ms": 1246.8903064727783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3964}}}
{"qid": "8823076125131408628", "question": "who sings got my mind set on you", "gold_answers": ["George Harrison", "James Ray"], "shots": {"0": {"k": 0, "answer": "George Harrison", "latency_ms": 419.31653022766113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Ray and George Harrison", "latency_ms": 634.8481178283691, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 541}, "2": {"k": 2, "answer": "James Ray and George Harrison", "latency_ms": 778.0478000640869, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1183}, "3": {"k": 3, "answer": "James Ray, George Harrison", "latency_ms": 1049.699068069458, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1740}, "4": {"k": 4, "answer": "James Ray, George Harrison", "latency_ms": 828.4430503845215, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2301}, "5": {"k": 5, "answer": "James Ray, George Harrison", "latency_ms": 832.4754238128662, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2861}, "6": {"k": 6, "answer": "James Ray, George Harrison", "latency_ms": 826.0676860809326, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3406}}}
{"qid": "9168660859139861094", "question": "two main types of research methods used in psychology", "gold_answers": ["Correlational research", "Descriptive research", "quantitative data", "Quantitative psychological research", "qualitative", "quantitative", "Qualitative psychological research", "Experimental research", "qualitative data"], "shots": {"0": {"k": 0, "answer": "Qualitative and Quantitative.", "latency_ms": 515.6979560852051, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Experimental Methods", "latency_ms": 661.1945629119873, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 822}, "2": {"k": 2, "answer": "Qualitative and Quantitative", "latency_ms": 797.5504398345947, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1631}, "3": {"k": 3, "answer": "Qualitative and Quantitative", "latency_ms": 1226.3667583465576, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2337}, "4": {"k": 4, "answer": "Qualitative or quantitative", "latency_ms": 776.1745452880859, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3074}, "5": {"k": 5, "answer": "Qualitative or quantitative", "latency_ms": 548.5329627990723, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3821}, "6": {"k": 6, "answer": "Qualitative or quantitative", "latency_ms": 1005.18798828125, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4624}}}
{"qid": "-7073063191952855764", "question": "who plays peter in what we do in the shadows", "gold_answers": ["Ben Fransham"], "shots": {"0": {"k": 0, "answer": "Mark Proksch", "latency_ms": 567.6038265228271, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 814.0091896057129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 768.1882381439209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 796.9701290130615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 622.2448348999023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 788.9328002929688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 804.5108318328857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3743}}}
{"qid": "7901746249864619718", "question": "when does the 14th season of grey's anatomy come out", "gold_answers": ["September 28 , 2017"], "shots": {"0": {"k": 0, "answer": "September 28, 2017", "latency_ms": 976.5458106994629, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 28, 2017", "latency_ms": 951.8601894378662, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 28, 2017", "latency_ms": 953.3135890960693, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "September 28, 2017", "latency_ms": 774.8348712921143, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 28, 2017", "latency_ms": 1231.5902709960938, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2678}, "5": {"k": 5, "answer": "September 28, 2017", "latency_ms": 949.2588043212891, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3346}, "6": {"k": 6, "answer": "September 28, 2017", "latency_ms": 1164.8786067962646, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3933}}}
{"qid": "-896127746191949637", "question": "when was the first hunger games book published", "gold_answers": ["September 14 , 2008", "2008"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 238.88063430786133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 14, 2008", "latency_ms": 1008.6655616760254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "September 14, 2008", "latency_ms": 961.8403911590576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1322}, "3": {"k": 3, "answer": "September 14, 2008", "latency_ms": 969.1920280456543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1939}, "4": {"k": 4, "answer": "September 14, 2008", "latency_ms": 793.7107086181641, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2563}, "5": {"k": 5, "answer": "September 14, 2008", "latency_ms": 1046.3733673095703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3225}, "6": {"k": 6, "answer": "September 14, 2008", "latency_ms": 981.5688133239746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3854}}}
{"qid": "8044909700499569711", "question": "how much is the united states in debt to china", "gold_answers": ["$1.06 trillion", "1,200.5"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 375.8420944213867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$1.16 trillion", "latency_ms": 633.6700916290283, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "$1.16 trillion", "latency_ms": 863.6336326599121, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "$1.16 trillion", "latency_ms": 619.6136474609375, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "$1.16 trillion", "latency_ms": 633.1088542938232, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2582}, "5": {"k": 5, "answer": "$1.18 trillion", "latency_ms": 895.7240581512451, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3235}, "6": {"k": 6, "answer": "$1.18 trillion", "latency_ms": 671.5521812438965, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3867}}}
{"qid": "-3123234845590594961", "question": "where did the race in grease take place", "gold_answers": ["Thunder Road"], "shots": {"0": {"k": 0, "answer": "The Thunder Road Race", "latency_ms": 376.13534927368164, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles River", "latency_ms": 704.8885822296143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Los Angeles River", "latency_ms": 703.3834457397461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Los Angeles River", "latency_ms": 498.43478202819824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1824}, "4": {"k": 4, "answer": "Los Angeles River", "latency_ms": 688.4701251983643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "Los Angeles River", "latency_ms": 711.1954689025879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3143}, "6": {"k": 6, "answer": "Los Angeles River", "latency_ms": 505.7218074798584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3762}}}
{"qid": "4326992806019599297", "question": "what is the maximum data rate for the 802.11a standard select one", "gold_answers": ["54 Mbit / s"], "shots": {"0": {"k": 0, "answer": "54 Mbps", "latency_ms": 509.55653190612793, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "54 Mbit/s", "latency_ms": 806.6263198852539, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "54 Mbit/s", "latency_ms": 624.1631507873535, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "54 Mbit/s", "latency_ms": 771.7597484588623, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1950}, "4": {"k": 4, "answer": "54 Mbit/s", "latency_ms": 789.3514633178711, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2612}, "5": {"k": 5, "answer": "54 Mbit/s", "latency_ms": 796.9715595245361, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "54 Mbit/s", "latency_ms": 827.0955085754395, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3856}}}
{"qid": "6144099837933283715", "question": "a good that can be used in place of another good", "gold_answers": ["A substitute good", "substitute good"], "shots": {"0": {"k": 0, "answer": "Substitute", "latency_ms": 443.61019134521484, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Substitute good", "latency_ms": 483.5224151611328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 558}, "2": {"k": 2, "answer": "Substitute good", "latency_ms": 685.6899261474609, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1155}, "3": {"k": 3, "answer": "Substitute good", "latency_ms": 508.62669944763184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1734}, "4": {"k": 4, "answer": "Substitute good", "latency_ms": 682.7218532562256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2319}, "5": {"k": 5, "answer": "Substitute good", "latency_ms": 477.7557849884033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2925}, "6": {"k": 6, "answer": "Substitute good", "latency_ms": 708.7075710296631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3488}}}
{"qid": "-4621948696356225060", "question": "where in the bible can i find the lord's prayer", "gold_answers": ["the Gospel of Luke", "the Gospel of Matthew"], "shots": {"0": {"k": 0, "answer": "Matthew 6:9-13, Luke 11:2-4", "latency_ms": 1647.6547718048096, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gospel of Matthew and Gospel of Luke", "latency_ms": 1011.0654830932617, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "Gospel of Matthew and Gospel of Luke", "latency_ms": 1178.445816040039, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Gospel of Matthew and Gospel of Luke", "latency_ms": 1017.9240703582764, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Gospel of Matthew and Luke", "latency_ms": 1136.348009109497, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "Gospel of Matthew and Luke", "latency_ms": 889.5392417907715, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 3166}, "6": {"k": 6, "answer": "Gospel of Matthew and Luke", "latency_ms": 751.4228820800781, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 3854}}}
{"qid": "6941993254369956277", "question": "when was the last time nebraska voted democrat", "gold_answers": ["1964"], "shots": {"0": {"k": 0, "answer": "1964", "latency_ms": 413.93113136291504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 548.4871864318848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 704}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 753.9589405059814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1415}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 754.1158199310303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2030}, "4": {"k": 4, "answer": "1936", "latency_ms": 456.0718536376953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2724}, "5": {"k": 5, "answer": "1936", "latency_ms": 442.5806999206543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3450}, "6": {"k": 6, "answer": "1936", "latency_ms": 659.522294998169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4148}}}
{"qid": "-8955197065025093046", "question": "who become the ceo of it wipro company in 2016", "gold_answers": ["Abid Ali Neemuchwala"], "shots": {"0": {"k": 0, "answer": "Abidali Neemuchwala", "latency_ms": 812.5433921813965, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Abidali Neemuchwala", "latency_ms": 1048.8591194152832, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Abidali Neemuchwala", "latency_ms": 860.2368831634521, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Abidali Neemuchwala", "latency_ms": 1244.502305984497, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1991}, "4": {"k": 4, "answer": "Abidali Neemuchwala", "latency_ms": 1243.5541152954102, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2672}, "5": {"k": 5, "answer": "Abidali Neemuchwala", "latency_ms": 1014.4262313842773, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "Abidali Neemuchwala", "latency_ms": 1086.9297981262207, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3932}}}
{"qid": "-3010425579521817304", "question": "who does eric end up with in gossip girl", "gold_answers": ["Jenny"], "shots": {"0": {"k": 0, "answer": "Vanessa, then Serena, then no one, then Serena again, but ultimately Vanessa then Serena then finally  Blair's enemy, Vanessa then ultimately Serena", "latency_ms": 3066.803216934204, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 809.983491897583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 554.532527923584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1198}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 546.3078022003174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1856}, "4": {"k": 4, "answer": "Damien", "latency_ms": 674.1235256195068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2421}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 717.0677185058594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2996}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1026.9191265106201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3619}}}
{"qid": "7264112453286983469", "question": "who plays unis in she's the man", "gold_answers": ["Emily Perkins"], "shots": {"0": {"k": 0, "answer": "Amanda Bynes", "latency_ms": 623.377799987793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amanda Bynes", "latency_ms": 732.783317565918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "Amanda Bynes", "latency_ms": 570.000410079956, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "Amanda Bynes", "latency_ms": 763.6408805847168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Amanda Bynes", "latency_ms": 763.4360790252686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1105.1092147827148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 849.5237827301025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3791}}}
{"qid": "2627695648792729859", "question": "who played booster in jingle all the way", "gold_answers": ["Curtis Armstrong"], "shots": {"0": {"k": 0, "answer": "Eric Lloyd", "latency_ms": 472.17583656311035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 584.4731330871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 759.0069770812988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 747.3864555358887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 772.6230621337891, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2520}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 805.6392669677734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 568.6755180358887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3890}}}
{"qid": "-9169976182548289414", "question": "who is recognized as the founder of islam", "gold_answers": ["the Islamic prophet Muhammad", "Muhammad"], "shots": {"0": {"k": 0, "answer": "Muhammad", "latency_ms": 417.36912727355957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Muhammad", "latency_ms": 438.4500980377197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "Muhammad", "latency_ms": 625.2593994140625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Muhammad", "latency_ms": 463.93704414367676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Muhammad", "latency_ms": 487.1675968170166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2416}, "5": {"k": 5, "answer": "Muhammad", "latency_ms": 670.2351570129395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3074}, "6": {"k": 6, "answer": "Muhammad", "latency_ms": 484.7440719604492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3627}}}
{"qid": "-6696747560626271522", "question": "who plays emma in air bud world pup", "gold_answers": ["Brittany Paige Bouck"], "shots": {"0": {"k": 0, "answer": "Brittany Paige Bouck", "latency_ms": 891.486644744873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 784.5349311828613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 601.8376350402832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 758.6588859558105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 734.6241474151611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2574}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 785.3720188140869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3201}, "6": {"k": 6, "answer": "Chantal Strand", "latency_ms": 748.4302520751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3800}}}
{"qid": "5871681964137793716", "question": "how old was sasuke when his clan died", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "7 years old", "latency_ms": 509.5686912536621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 813.6422634124756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 767.2607898712158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 601.1133193969727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 773.9379405975342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 767.06862449646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3056}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 806.2121868133545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3674}}}
{"qid": "8552176802923865025", "question": "where do some of the natural air pollutants come from", "gold_answers": ["wildfires", "Dust", "Vegetation", "Carbon dioxide", "Volcanic activity"], "shots": {"0": {"k": 0, "answer": "Volcanic eruptions", "latency_ms": 630.0795078277588, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "sea spray, volcanic ash, and meteoroids", "latency_ms": 1052.7827739715576, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "sea spray, volcanic ash, and meteoroids.", "latency_ms": 1322.5510120391846, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "Sea spray, volcanic ash, and meteoroids.", "latency_ms": 941.2407875061035, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2089}, "4": {"k": 4, "answer": "sea spray, volcanic ash, dust, pollen and spores", "latency_ms": 1443.9482688903809, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2789}, "5": {"k": 5, "answer": "sea spray, volcanic ash, dust, pollen and spores, and meteoroids.", "latency_ms": 2028.9788246154785, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 3467}, "6": {"k": 6, "answer": "sea spray, volcanic ash, and meteoroids", "latency_ms": 1341.9513702392578, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 4184}}}
{"qid": "-2630525064809360052", "question": "who is the pastor of new birth missionary baptist church now", "gold_answers": ["Stephen A. Davis"], "shots": {"0": {"k": 0, "answer": "Jamal Harrison Bryant", "latency_ms": 553.0662536621094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pastor Bryant", "latency_ms": 680.9749603271484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "Jamal Bryant", "latency_ms": 680.1278591156006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1353}, "3": {"k": 3, "answer": "Jamal Bryant", "latency_ms": 694.2129135131836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2018}, "4": {"k": 4, "answer": "Jamal Bryant", "latency_ms": 725.1522541046143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2655}, "5": {"k": 5, "answer": "Jamal Bryant", "latency_ms": 569.068431854248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3328}, "6": {"k": 6, "answer": "Jamal Bryant", "latency_ms": 741.9440746307373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3991}}}
{"qid": "6434931911289860123", "question": "who is doing 2018 super bowl half time show", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "Justin Timberlake", "latency_ms": 302.3693561553955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Timberlake", "latency_ms": 928.5721778869629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "Justin Timberlake", "latency_ms": 723.1223583221436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1298}, "3": {"k": 3, "answer": "Justin Timberlake", "latency_ms": 736.3541126251221, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1921}, "4": {"k": 4, "answer": "Justin Timberlake", "latency_ms": 765.8288478851318, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2525}, "5": {"k": 5, "answer": "Justin Timberlake", "latency_ms": 491.0922050476074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3123}, "6": {"k": 6, "answer": "Justin Timberlake", "latency_ms": 715.7654762268066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3739}}}
{"qid": "8869318258439148973", "question": "who is playing the halftime show for the superbowl", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 571.6736316680908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Timberlake", "latency_ms": 490.7212257385254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "Justin Timberlake", "latency_ms": 691.9293403625488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "Maroon 5", "latency_ms": 769.758939743042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Justin Timberlake", "latency_ms": 515.3803825378418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2587}, "5": {"k": 5, "answer": "Justin Timberlake", "latency_ms": 731.9614887237549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3213}, "6": {"k": 6, "answer": "Justin Timberlake", "latency_ms": 531.919002532959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3847}}}
{"qid": "-8359866474144720253", "question": "who hosted they think it's all over", "gold_answers": ["Des Lynam", "Lee Mack", "comedian Nick Hancock", "Nick Hancock"], "shots": {"0": {"k": 0, "answer": "Nick Hancock", "latency_ms": 247.41387367248535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Des Lynam", "latency_ms": 701.6611099243164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Nick Hancock", "latency_ms": 451.60651206970215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Nick Hancock, Lee Mack", "latency_ms": 804.2037487030029, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1941}, "4": {"k": 4, "answer": "Nick Hancock, Lee Mack", "latency_ms": 845.1907634735107, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2580}, "5": {"k": 5, "answer": "Nick Hancock, Lee Mack", "latency_ms": 640.2966976165771, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Nick Hancock, Lee Mack", "latency_ms": 799.7829914093018, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3840}}}
{"qid": "-1206653570097564556", "question": "where does the movie proof of life take place", "gold_answers": ["The Republic of Tecala"], "shots": {"0": {"k": 0, "answer": "South America", "latency_ms": 242.83480644226074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tecala", "latency_ms": 718.2910442352295, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "The Republic of Tecala", "latency_ms": 627.7506351470947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Tecala", "latency_ms": 748.553991317749, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "The Republic of Tecala", "latency_ms": 626.227617263794, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2507}, "5": {"k": 5, "answer": "Tecala", "latency_ms": 691.9524669647217, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3105}, "6": {"k": 6, "answer": "Tecala, a fictional South American country", "latency_ms": 1241.9288158416748, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3756}}}
{"qid": "6144521615402262404", "question": "where does us highway 1 start and end", "gold_answers": ["Fort Kent , Maine", "to Key West , Florida", "Key West , Florida"], "shots": {"0": {"k": 0, "answer": "Fort Kent, Maine to Key West, Florida", "latency_ms": 1153.766393661499, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Key West, Florida to Fort Kent, Maine", "latency_ms": 1348.1106758117676, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Key West, Florida to Fort Kent, Maine", "latency_ms": 1243.1151866912842, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Key West, Florida to Fort Kent, Maine", "latency_ms": 1311.0017776489258, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "Key West, Florida to Fort Kent, Maine", "latency_ms": 1064.148187637329, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 2478}, "5": {"k": 5, "answer": "Key West, Florida to Fort Kent, Maine", "latency_ms": 1269.5667743682861, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Key West, Florida to Fort Kent, Maine", "latency_ms": 1305.1259517669678, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 3736}}}
{"qid": "-8631190913794477985", "question": "who scored the most points in a single game in the nba", "gold_answers": ["Wilt Chamberlain"], "shots": {"0": {"k": 0, "answer": "Wilt Chamberlain", "latency_ms": 568.7777996063232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wilt Chamberlain", "latency_ms": 767.8909301757812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "Wilt Chamberlain", "latency_ms": 568.0437088012695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Wilt Chamberlain", "latency_ms": 772.2537517547607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1844}, "4": {"k": 4, "answer": "Wilt Chamberlain", "latency_ms": 989.9191856384277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Wilt Chamberlain", "latency_ms": 774.7323513031006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Wilt Chamberlain", "latency_ms": 1008.6603164672852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3734}}}
{"qid": "199896377614951764", "question": "where is natural gas found in the us", "gold_answers": ["Texas", "Pennsylvania", "Colorado", "New Mexico", "West Virginia", "Arkansas", "Wyoming", "Louisiana"], "shots": {"0": {"k": 0, "answer": "Various states including Texas, Alaska, and Pennsylvania", "latency_ms": 921.1165904998779, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pennsylvania", "latency_ms": 430.7096004486084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Pennsylvania", "latency_ms": 672.2662448883057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Texas, Pennsylvania, Louisiana", "latency_ms": 871.3963031768799, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1972}, "4": {"k": 4, "answer": "Texas, Pennsylvania, Louisiana, Michigan", "latency_ms": 1144.5415019989014, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2588}, "5": {"k": 5, "answer": "Texas, Pennsylvania, Louisiana", "latency_ms": 883.8279247283936, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3279}, "6": {"k": 6, "answer": "Texas, Pennsylvania, Louisiana", "latency_ms": 636.5158557891846, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3926}}}
{"qid": "8986775680996674901", "question": "when were the first general elections held in independent india", "gold_answers": ["1951 -- 52"], "shots": {"0": {"k": 0, "answer": "1951", "latency_ms": 439.2504692077637, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 1263.2787227630615, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 1558.1555366516113, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 1272.1896171569824, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1974}, "4": {"k": 4, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 1287.7588272094727, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2660}, "5": {"k": 5, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 1735.3460788726807, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 3335}, "6": {"k": 6, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 1670.0177192687988, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 4052}}}
{"qid": "700604097171850168", "question": "what was the tower of london originally used for", "gold_answers": ["as a royal residence", "a royal residence"], "shots": {"0": {"k": 0, "answer": "Royal Palace", "latency_ms": 258.1982612609863, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Royal residence", "latency_ms": 437.8681182861328, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "royal residence", "latency_ms": 665.2052402496338, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "royal residence", "latency_ms": 701.5776634216309, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "royal residence", "latency_ms": 674.1354465484619, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "royal residence", "latency_ms": 691.5078163146973, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "royal residence", "latency_ms": 685.9829425811768, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3775}}}
{"qid": "6745303307988470742", "question": "what type of fuel goes in a zippo", "gold_answers": ["butane", "lighter fluid"], "shots": {"0": {"k": 0, "answer": "Lighter fluid", "latency_ms": 485.86034774780273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 1593.0306911468506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 1560.7764720916748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1227}, "3": {"k": 3, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 1549.5471954345703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1804}, "4": {"k": 4, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 1672.0123291015625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2397}, "5": {"k": 5, "answer": "Light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 1867.5956726074219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3053}, "6": {"k": 6, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 1591.3832187652588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3645}}}
{"qid": "-2060506905455252030", "question": "first jnanpith award was an autor of which language", "gold_answers": ["Malayalam"], "shots": {"0": {"k": 0, "answer": "Gujarati", "latency_ms": 560.8160495758057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Malayalam", "latency_ms": 550.1666069030762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 669}, "2": {"k": 2, "answer": "Malayalam", "latency_ms": 763.4999752044678, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1332}, "3": {"k": 3, "answer": "Malayalam", "latency_ms": 739.9365901947021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1980}, "4": {"k": 4, "answer": "Malayalam", "latency_ms": 675.9688854217529, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2644}, "5": {"k": 5, "answer": "Malayalam", "latency_ms": 747.6537227630615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3321}, "6": {"k": 6, "answer": "Malayalam", "latency_ms": 547.0752716064453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3961}}}
{"qid": "4738663028303377024", "question": "who played the mad hatter in the batman tv show", "gold_answers": ["Roddy McDowall", "David Wayne", "Benedict Samuel"], "shots": {"0": {"k": 0, "answer": "David Wayne", "latency_ms": 261.2121105194092, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 781.609058380127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 777.9538631439209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 748.1210231781006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 791.6121482849121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2562}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 820.2016353607178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 794.269323348999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "-1650946015201779846", "question": "how many cracker barrels in the united states", "gold_answers": ["639", "more than 600"], "shots": {"0": {"k": 0, "answer": "645 locations", "latency_ms": 257.9030990600586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "314", "latency_ms": 368.35646629333496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "645 stores in 44 states", "latency_ms": 852.6427745819092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1280}, "3": {"k": 3, "answer": "645 stores in 44 states", "latency_ms": 1112.135410308838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "645 stores in 44 states", "latency_ms": 882.401704788208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2581}, "5": {"k": 5, "answer": "645 stores in 44 states", "latency_ms": 915.1327610015869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3236}, "6": {"k": 6, "answer": "645 stores in 44 states", "latency_ms": 942.4941539764404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3882}}}
{"qid": "-3422350952909582054", "question": "in photosynthesis the carbon in co2 is initially fixed to what molecule", "gold_answers": ["3 - phosphoglycerate"], "shots": {"0": {"k": 0, "answer": "RuBP", "latency_ms": 260.55073738098145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 1698.8685131072998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 712}, "2": {"k": 2, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 1410.5141162872314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1383}, "3": {"k": 3, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 1313.349962234497, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2086}, "4": {"k": 4, "answer": "Phosphoenolpyruvate (PEP)", "latency_ms": 1271.721601486206, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2731}, "5": {"k": 5, "answer": "Phosphoenolpyruvate (PEP)", "latency_ms": 1255.3505897521973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3457}, "6": {"k": 6, "answer": "Phosphoenolpyruvate (PEP)", "latency_ms": 1290.7772064208984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4116}}}
{"qid": "-2704708103393811482", "question": "who voices randy in f is for family", "gold_answers": ["T.J. Miller"], "shots": {"0": {"k": 0, "answer": "Bill Burr", "latency_ms": 464.4901752471924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 554.558277130127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Haley Reinhart", "latency_ms": 831.594705581665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 575.3037929534912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 604.9633026123047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2574}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 565.9561157226562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 829.1416168212891, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3833}}}
{"qid": "5482012214308896475", "question": "how many countries does cadbury sell its products", "gold_answers": ["more than 50", "more than 50 countries worldwide"], "shots": {"0": {"k": 0, "answer": "160 countries", "latency_ms": 252.14099884033203, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "30 countries", "latency_ms": 433.2537651062012, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "More than 50 countries", "latency_ms": 647.4943161010742, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 1360}, "3": {"k": 3, "answer": "More than 50 countries", "latency_ms": 823.6348628997803, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 1983}, "4": {"k": 4, "answer": "50 countries worldwide", "latency_ms": 515.8288478851318, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 2682}, "5": {"k": 5, "answer": "50 countries worldwide", "latency_ms": 689.3506050109863, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 3410}, "6": {"k": 6, "answer": "50 countries", "latency_ms": 456.85625076293945, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 4035}}}
{"qid": "-5737509619250561344", "question": "ethiopia flight 961 crashes in to the sea", "gold_answers": ["23 November 1996"], "shots": {"0": {"k": 0, "answer": "November 23, 1996", "latency_ms": 751.8584728240967, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indian Ocean", "latency_ms": 702.9426097869873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Indian Ocean", "latency_ms": 479.6011447906494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "Indian Ocean", "latency_ms": 664.1342639923096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2016}, "4": {"k": 4, "answer": "Indian Ocean", "latency_ms": 490.755558013916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Indian Ocean", "latency_ms": 487.98274993896484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "Indian Ocean", "latency_ms": 696.1042881011963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4019}}}
{"qid": "-7175456993713717070", "question": "what does istj mean in a personality test", "gold_answers": ["Extroverted Thinking ( Te )", "Extroverted Intuition ( Ne )", "Introverted Feeling ( Fi )", "Introverted Sensing ( Si )"], "shots": {"0": {"k": 0, "answer": "Introverted, Sensing, Thinking, Judging", "latency_ms": 1007.6980590820312, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 1300.76265335083, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 724}, "2": {"k": 2, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 1282.26637840271, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1424}, "3": {"k": 3, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 1076.8258571624756, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2085}, "4": {"k": 4, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 1063.328742980957, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2796}, "5": {"k": 5, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 1322.2970962524414, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3424}, "6": {"k": 6, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 1279.3936729431152, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4117}}}
{"qid": "4437170343606050664", "question": "who does the voice of ash in sing", "gold_answers": ["Scarlett Johansson"], "shots": {"0": {"k": 0, "answer": "Scarlett Johansson", "latency_ms": 569.0021514892578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Scarlett Johansson", "latency_ms": 592.2544002532959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 688}, "2": {"k": 2, "answer": "Scarlett Johansson", "latency_ms": 822.4761486053467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1401}, "3": {"k": 3, "answer": "Scarlett Johansson", "latency_ms": 1031.6526889801025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2049}, "4": {"k": 4, "answer": "Scarlett Johansson", "latency_ms": 969.9563980102539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2716}, "5": {"k": 5, "answer": "Scarlett Johansson", "latency_ms": 806.8451881408691, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3372}, "6": {"k": 6, "answer": "Scarlett Johansson", "latency_ms": 775.1076221466064, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4036}}}
{"qid": "-8773010039077552394", "question": "who scored the most points in their nba career", "gold_answers": ["Kareem Abdul - Jabbar"], "shots": {"0": {"k": 0, "answer": "LeBron James", "latency_ms": 302.3364543914795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 751.255989074707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 771.4338302612305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1159}, "3": {"k": 3, "answer": "Michael Jordan", "latency_ms": 658.1504344940186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1778}, "4": {"k": 4, "answer": "Kareem Abdul-Jabbar", "latency_ms": 1118.9501285552979, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2390}, "5": {"k": 5, "answer": "Kareem Abdul-Jabbar", "latency_ms": 751.2764930725098, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3031}, "6": {"k": 6, "answer": "Kareem Abdul-Jabbar", "latency_ms": 974.4513034820557, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3682}}}
{"qid": "-3278224144622911032", "question": "with a land area of 54 314 square miles where does wisconsin rank among the 50 states", "gold_answers": ["25"], "shots": {"0": {"k": 0, "answer": "23rd", "latency_ms": 455.9614658355713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "23rd", "latency_ms": 645.160436630249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "23rd", "latency_ms": 696.9258785247803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "23rd", "latency_ms": 679.3811321258545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1868}, "4": {"k": 4, "answer": "23rd", "latency_ms": 718.4677124023438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "23rd", "latency_ms": 522.3701000213623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3106}, "6": {"k": 6, "answer": "23rd", "latency_ms": 715.9676551818848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3695}}}
{"qid": "-3466298422174960041", "question": "who plays charles on have and have nots", "gold_answers": ["Nick Sager", "Nick Sagar"], "shots": {"0": {"k": 0, "answer": "Aaron O'Connell", "latency_ms": 614.4552230834961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 740.856409072876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 785.2790355682373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1294}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 767.7698135375977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 577.5032043457031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2554}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 781.4550399780273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3251}, "6": {"k": 6, "answer": "Gavin Houston", "latency_ms": 725.1546382904053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3895}}}
{"qid": "1803248910342766083", "question": "who wrote the book my country my life", "gold_answers": ["L.K. Advani"], "shots": {"0": {"k": 0, "answer": "L.K. Advani", "latency_ms": 620.4116344451904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 764.7402286529541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "L. K. Advani", "latency_ms": 882.3118209838867, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "L. K. Advani", "latency_ms": 859.4067096710205, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1849}, "4": {"k": 4, "answer": "L. K. Advani", "latency_ms": 922.0395088195801, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2485}, "5": {"k": 5, "answer": "L. K. Advani", "latency_ms": 908.6956977844238, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "L. K. Advani", "latency_ms": 1142.1668529510498, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "-1176280233636154422", "question": "when did the east india company take control of india", "gold_answers": ["1757", "1799", "1612", "in 1757"], "shots": {"0": {"k": 0, "answer": "1757", "latency_ms": 441.83874130249023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 750.370979309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 779.3972492218018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "By 1818", "latency_ms": 578.6876678466797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1936}, "4": {"k": 4, "answer": "1757", "latency_ms": 435.7020854949951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2585}, "5": {"k": 5, "answer": "1757", "latency_ms": 433.0456256866455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3255}, "6": {"k": 6, "answer": "1757", "latency_ms": 437.56961822509766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3891}}}
{"qid": "5911119091653953181", "question": "where does the water come from to fill lake eyre", "gold_answers": ["Warburton River"], "shots": {"0": {"k": 0, "answer": "Cooper Creek", "latency_ms": 311.3713264465332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the north-east part of the Lake Eyre Basin", "latency_ms": 934.7691535949707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "The north-east part of the Lake Eyre Basin", "latency_ms": 1156.5325260162354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "The north-east part of the Lake Eyre Basin", "latency_ms": 1364.7825717926025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1850}, "4": {"k": 4, "answer": "The north-east part of the Lake Eyre Basin", "latency_ms": 1557.462453842163, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2432}, "5": {"k": 5, "answer": "The north-east part of the Lake Eyre Basin", "latency_ms": 1131.4070224761963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3014}, "6": {"k": 6, "answer": "The north-east part of the Lake Eyre Basin", "latency_ms": 1312.5154972076416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3635}}}
{"qid": "5557104327881436095", "question": "who is the founder of google and when was it founded", "gold_answers": ["1998", "Sergey Brin", "Larry Page and Sergey Brin", "Larry Page"], "shots": {"0": {"k": 0, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 1381.1252117156982, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 586.3220691680908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 1362.2455596923828, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 1340}, "3": {"k": 3, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 1555.9637546539307, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 1980}, "4": {"k": 4, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 1126.3799667358398, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 2647}, "5": {"k": 5, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 1598.3197689056396, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 3327}, "6": {"k": 6, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 1420.0894832611084, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 3983}}}
{"qid": "-1333328812971005142", "question": "who did the dominican republic gain its independence from", "gold_answers": ["Haiti"], "shots": {"0": {"k": 0, "answer": "Haiti and Spain", "latency_ms": 670.5620288848877, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spain and Haiti", "latency_ms": 679.7657012939453, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 667}, "2": {"k": 2, "answer": "Haiti and Spain", "latency_ms": 824.6657848358154, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1304}, "3": {"k": 3, "answer": "Haiti and Spain", "latency_ms": 857.5701713562012, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Haiti and Spain", "latency_ms": 848.7396240234375, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2613}, "5": {"k": 5, "answer": "Haiti and Spain", "latency_ms": 836.6122245788574, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3260}, "6": {"k": 6, "answer": "Haiti and Spain", "latency_ms": 809.2696666717529, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3974}}}
{"qid": "1122605495295045742", "question": "how did early humans make use of stones during the prehistoric period", "gold_answers": ["start fires", "hunt", "bury their dead"], "shots": {"0": {"k": 0, "answer": "Tool making", "latency_ms": 240.8280372619629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shaped or chipped stones for tools and weapons.", "latency_ms": 1359.2805862426758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "chipping or flaking stones", "latency_ms": 883.063554763794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "Shaping and chipping.", "latency_ms": 838.6952877044678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1944}, "4": {"k": 4, "answer": "Shaping and chipping.", "latency_ms": 1070.1873302459717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Shaping or chipping stones for tools and weapons.", "latency_ms": 1208.3868980407715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "Shaping and chipping stones for tools and weapons.", "latency_ms": 1609.6248626708984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3893}}}
{"qid": "7402184777947527945", "question": "who wrote the text for jeanie with the light brown hair", "gold_answers": ["Stephen Foster"], "shots": {"0": {"k": 0, "answer": "Maud Irving or Robert Burns", "latency_ms": 936.9268417358398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stephen Foster", "latency_ms": 454.55312728881836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Stephen Foster", "latency_ms": 421.8299388885498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Stephen Foster", "latency_ms": 655.771017074585, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Stephen Foster", "latency_ms": 654.0791988372803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Stephen Foster", "latency_ms": 468.43767166137695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3071}, "6": {"k": 6, "answer": "Stephen Foster", "latency_ms": 659.0969562530518, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3686}}}
{"qid": "1656745334095178455", "question": "the basic steps of rational decision making include defining goals and", "gold_answers": ["Implementation of plans / policies"], "shots": {"0": {"k": 0, "answer": "identifying alternatives", "latency_ms": 510.2999210357666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "problem definition", "latency_ms": 661.8094444274902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 774}, "2": {"k": 2, "answer": "problem definition", "latency_ms": 425.0941276550293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1407}, "3": {"k": 3, "answer": "problem definition", "latency_ms": 621.8757629394531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2061}, "4": {"k": 4, "answer": "problem definition", "latency_ms": 418.12753677368164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2713}, "5": {"k": 5, "answer": "defining & detailing the problem", "latency_ms": 903.7675857543945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3431}, "6": {"k": 6, "answer": "problem definition", "latency_ms": 640.4943466186523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4101}}}
{"qid": "-216657635823030751", "question": "when was the design period known as art deco", "gold_answers": ["1910 -- 1939"], "shots": {"0": {"k": 0, "answer": "1920s to 1940s", "latency_ms": 1002.2709369659424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "just before World War I", "latency_ms": 848.4716415405273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "just before World War I", "latency_ms": 812.6442432403564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1362}, "3": {"k": 3, "answer": "just before World War I", "latency_ms": 833.1916332244873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2013}, "4": {"k": 4, "answer": "just before World War I to 1939", "latency_ms": 1375.6675720214844, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2721}, "5": {"k": 5, "answer": "just before World War I", "latency_ms": 891.2041187286377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3391}, "6": {"k": 6, "answer": "just before World War I", "latency_ms": 924.6649742126465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4054}}}
{"qid": "250542332339248886", "question": "where does the bob and tom show broadcast from", "gold_answers": ["WFBQ in Indianapolis , Indiana", "Indianapolis , Indiana"], "shots": {"0": {"k": 0, "answer": "Indianapolis", "latency_ms": 496.88076972961426, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indianapolis, Indiana", "latency_ms": 586.9531631469727, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Indianapolis, Indiana", "latency_ms": 783.0774784088135, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Indianapolis, Indiana", "latency_ms": 773.2629776000977, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "Indianapolis, Indiana", "latency_ms": 816.7216777801514, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2495}, "5": {"k": 5, "answer": "Indianapolis, Indiana", "latency_ms": 567.7225589752197, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3083}, "6": {"k": 6, "answer": "Indianapolis, Indiana", "latency_ms": 823.9669799804688, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3695}}}
{"qid": "7610758795954724809", "question": "star wars the clone wars season 3 episode 1", "gold_answers": ["Clone Cadets"], "shots": {"0": {"k": 0, "answer": "Clone Cadets", "latency_ms": 526.5209674835205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Volume Two", "latency_ms": 453.1581401824951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 746.8321323394775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 579.2338848114014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1005.3818225860596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2574}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 985.7609272003174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3224}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1023.0116844177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3837}}}
{"qid": "2997223939033016160", "question": "what part of brain is responsible for complex thinking", "gold_answers": ["the frontal lobe"], "shots": {"0": {"k": 0, "answer": "Cerebrum", "latency_ms": 587.2757434844971, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frontal lobe", "latency_ms": 733.3903312683105, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Parietal lobe", "latency_ms": 818.1898593902588, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1386}, "3": {"k": 3, "answer": "Parietal lobe", "latency_ms": 1039.3362045288086, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2073}, "4": {"k": 4, "answer": "Frontal lobe", "latency_ms": 744.0910339355469, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2747}, "5": {"k": 5, "answer": "Parietal lobe", "latency_ms": 628.1275749206543, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3443}, "6": {"k": 6, "answer": "Frontal lobe", "latency_ms": 754.4636726379395, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4141}}}
{"qid": "2680196226239522881", "question": "who won the champions league final in 2016", "gold_answers": ["Real Madrid"], "shots": {"0": {"k": 0, "answer": "Real Madrid", "latency_ms": 448.00758361816406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Real Madrid", "latency_ms": 695.8367824554443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Real Madrid", "latency_ms": 694.1149234771729, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Real Madrid", "latency_ms": 671.5219020843506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1837}, "4": {"k": 4, "answer": "Real Madrid", "latency_ms": 666.301965713501, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2442}, "5": {"k": 5, "answer": "Real Madrid", "latency_ms": 463.17553520202637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3058}, "6": {"k": 6, "answer": "Real Madrid", "latency_ms": 437.4516010284424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "-8458006812258546025", "question": "who has the most gold medals in the winter olympics of all time", "gold_answers": ["Norway"], "shots": {"0": {"k": 0, "answer": "Marit Bjoergen", "latency_ms": 493.0870532989502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canada", "latency_ms": 579.1680812835693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Canada", "latency_ms": 375.4286766052246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Norway", "latency_ms": 627.6242733001709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Norway", "latency_ms": 478.49178314208984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Marit Bj√∏rgen", "latency_ms": 918.4169769287109, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "Marit Bj√∏rgen", "latency_ms": 883.6574554443359, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3750}}}
