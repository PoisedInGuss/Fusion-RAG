{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 352.18286514282227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Julie Walters", "latency_ms": 751.7454624176025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Geraldine Somerville", "latency_ms": 845.1673984527588, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Geraldine Somerville", "latency_ms": 871.0753917694092, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "Geraldine Somerville", "latency_ms": 882.9739093780518, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2504}, "5": {"k": 5, "answer": "Geraldine Somerville", "latency_ms": 890.8510208129883, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Geraldine Somerville", "latency_ms": 857.550859451294, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3801}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 587.6626968383789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 784.5485210418701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 767.8859233856201, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 753.1816959381104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 748.2006549835205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 794.6760654449463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 635.3323459625244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3838}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwest desert regions", "latency_ms": 610.5144023895264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 1355.6945323944092, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 1212.817668914795, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1328}, "3": {"k": 3, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 1425.8592128753662, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1977}, "4": {"k": 4, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 1358.1466674804688, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2622}, "5": {"k": 5, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 1369.288444519043, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3354}, "6": {"k": 6, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 1372.5013732910156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3968}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 699.5370388031006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dr. Rajendra Prasad", "latency_ms": 913.3133888244629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 743}, "2": {"k": 2, "answer": "Dr. Rajendra Prasad", "latency_ms": 876.1582374572754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1429}, "3": {"k": 3, "answer": "Dr. Rajendra Prasad", "latency_ms": 1082.7274322509766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2127}, "4": {"k": 4, "answer": "Dr. Rajendra Prasad", "latency_ms": 935.1959228515625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2802}, "5": {"k": 5, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 821.6252326965332, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3473}, "6": {"k": 6, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 1243.3397769927979, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4153}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 587.6293182373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 737.1203899383545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 740.9822940826416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1302}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 753.5243034362793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1907}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 861.4163398742676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 600.6302833557129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 775.6791114807129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3720}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "2001", "latency_ms": 230.55338859558105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 22, 2001", "latency_ms": 940.100908279419, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "June 22, 2001", "latency_ms": 1131.1750411987305, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1304}, "3": {"k": 3, "answer": "June 22, 2001", "latency_ms": 913.4190082550049, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1934}, "4": {"k": 4, "answer": "June 22, 2001", "latency_ms": 759.8984241485596, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2592}, "5": {"k": 5, "answer": "June 22, 2001", "latency_ms": 981.3923835754395, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3216}, "6": {"k": 6, "answer": "June 22, 2001", "latency_ms": 1220.2436923980713, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3847}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 586.8813991546631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 988.4285926818848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 985.0378036499023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 962.5754356384277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2052}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 924.3710041046143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2724}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 1167.7968502044678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3353}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 796.527624130249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4035}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3", "latency_ms": 510.8985900878906, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 530.7719707489014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 562}, "2": {"k": 2, "answer": "Sectionals", "latency_ms": 445.878267288208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1194}, "3": {"k": 3, "answer": "after Sectionals", "latency_ms": 720.4842567443848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1811}, "4": {"k": 4, "answer": "after Sectionals", "latency_ms": 479.28309440612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "after sectionals", "latency_ms": 722.9347229003906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3082}, "6": {"k": 6, "answer": "After the mid-season finale episode \"Sectionals\"", "latency_ms": 1122.420310974121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3671}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 566.4355754852295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 713.6020660400391, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 605.6931018829346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 787.0540618896484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 576.8301486968994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2409}, "5": {"k": 5, "answer": "Early 2019", "latency_ms": 802.4146556854248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3046}, "6": {"k": 6, "answer": "Early 2019", "latency_ms": 738.5866641998291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 495.6998825073242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Havana Harbor", "latency_ms": 684.1926574707031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 594}, "2": {"k": 2, "answer": "Havana, Cuba", "latency_ms": 789.6082401275635, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "Havana, Cuba", "latency_ms": 847.2762107849121, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "Havana, Cuba", "latency_ms": 597.1393585205078, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2459}, "5": {"k": 5, "answer": "Havana Harbor, Cuba", "latency_ms": 875.6394386291504, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3093}, "6": {"k": 6, "answer": "Havana Harbor, Cuba.", "latency_ms": 944.3907737731934, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3717}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 316.8036937713623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 798.3970642089844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 859.2934608459473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "No specific god mentioned", "latency_ms": 643.1641578674316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1935}, "4": {"k": 4, "answer": "None mentioned", "latency_ms": 495.7108497619629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "None mentioned", "latency_ms": 500.95438957214355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3171}, "6": {"k": 6, "answer": "Jains and Hindus", "latency_ms": 780.2858352661133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3800}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 573.6491680145264, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Honduras", "latency_ms": 478.72042655944824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Honduras, Guatemala", "latency_ms": 833.9943885803223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Honduras, Guatemala", "latency_ms": 638.775110244751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1958}, "4": {"k": 4, "answer": "Honduras, Guatemala", "latency_ms": 639.8537158966064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2618}, "5": {"k": 5, "answer": "Honduras, Guatemala, Nicaragua, Costa Rica, El Salvador, Panama", "latency_ms": 1873.399257659912, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3282}, "6": {"k": 6, "answer": "Honduras, Guatemala, Nicaragua, Costa Rica, El Salvador, Panama", "latency_ms": 1887.5017166137695, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3948}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence", "latency_ms": 243.19911003112793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 434.032678604126, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 708}, "2": {"k": 2, "answer": "Complex sentence", "latency_ms": 640.9697532653809, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1372}, "3": {"k": 3, "answer": "Complex sentence", "latency_ms": 419.48604583740234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2028}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 456.2673568725586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2776}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 636.3768577575684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3435}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 436.60712242126465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4059}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and trade.", "latency_ms": 414.64829444885254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 1081.165075302124, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 1018.9964771270752, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 1005.096435546875, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1998}, "4": {"k": 4, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 996.0920810699463, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 2664}, "5": {"k": 5, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 809.351921081543, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3334}, "6": {"k": 6, "answer": "the nature and causes of the wealth of nations", "latency_ms": 1113.403081893921, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3953}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 956.3703536987305, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 10, 2017", "latency_ms": 949.4199752807617, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "October 10, 2017", "latency_ms": 934.0729713439941, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 955.6066989898682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 995.0566291809082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "October 10, 2017", "latency_ms": 1133.7404251098633, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3156}, "6": {"k": 6, "answer": "October 10, 2017", "latency_ms": 1404.9904346466064, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere", "latency_ms": 509.5384120941162, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 1736.3207340240479, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 1575.1674175262451, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1341}, "3": {"k": 3, "answer": "Oceania", "latency_ms": 710.9215259552002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1985}, "4": {"k": 4, "answer": "Oceania", "latency_ms": 501.12009048461914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2644}, "5": {"k": 5, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 1551.1629581451416, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3332}, "6": {"k": 6, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 1810.0886344909668, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4057}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Leia Organa", "latency_ms": 584.7549438476562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Camie, Nakari Kelen, Mara Jade", "latency_ms": 1417.0010089874268, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Camie, Nakari Kelen, Mara Jade", "latency_ms": 1634.7625255584717, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1219}, "3": {"k": 3, "answer": "Camie, Nakari Kelen, Mara Jade", "latency_ms": 1170.109748840332, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Camie, Nakari Kelen, Mara Jade, Leia", "latency_ms": 1419.1977977752686, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2450}, "5": {"k": 5, "answer": "Camie, Nakari Kelen, Mara Jade", "latency_ms": 1570.298194885254, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3080}, "6": {"k": 6, "answer": "Camie, Nakari Kelen, Mara Jade", "latency_ms": 1106.4443588256836, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3675}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 462.3985290527344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack Barry", "latency_ms": 434.3235492706299, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Jack Barry", "latency_ms": 620.5408573150635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Jack Barry", "latency_ms": 436.75780296325684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1822}, "4": {"k": 4, "answer": "Jack Barry", "latency_ms": 646.4715003967285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2461}, "5": {"k": 5, "answer": "Jack Barry", "latency_ms": 650.9437561035156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3091}, "6": {"k": 6, "answer": "Jack Barry", "latency_ms": 432.50060081481934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3641}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 549.6387481689453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mitochondrion", "latency_ms": 766.1776542663574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 707}, "2": {"k": 2, "answer": "Mitochondria", "latency_ms": 527.0481109619141, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "Mitochondria", "latency_ms": 507.6577663421631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2072}, "4": {"k": 4, "answer": "Mitochondria", "latency_ms": 726.5505790710449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2713}, "5": {"k": 5, "answer": "Mitochondria and Chloroplasts", "latency_ms": 1149.2257118225098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3372}, "6": {"k": 6, "answer": "Mitochondria and Chloroplasts", "latency_ms": 942.9340362548828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4069}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Backup.", "latency_ms": 1352.5564670562744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Background checks, keystroke tracking, photo ID, thumb print, cameras", "latency_ms": 1576.3647556304932, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 771}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 760.8740329742432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1464}, "3": {"k": 3, "answer": "Background checks, keystroke tracking, photo ID, thumb print, cameras", "latency_ms": 1888.0369663238525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2173}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 977.6632785797119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2897}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 732.2206497192383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3580}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 972.0323085784912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4298}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 732.5081825256348, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dottie West and Kenny Rogers", "latency_ms": 899.2855548858643, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 583}, "2": {"k": 2, "answer": "Dottie West and Kenny Rogers", "latency_ms": 1086.0044956207275, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1170}, "3": {"k": 3, "answer": "Dottie West and Kenny Rogers", "latency_ms": 1088.9592170715332, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1840}, "4": {"k": 4, "answer": "Dottie West and Kenny Rogers", "latency_ms": 873.1837272644043, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2442}, "5": {"k": 5, "answer": "Dottie West and Kenny Rogers", "latency_ms": 882.2042942047119, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3118}, "6": {"k": 6, "answer": "Dottie West and Kenny Rogers", "latency_ms": 686.8212223052979, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3729}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 515.4261589050293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "36 months", "latency_ms": 402.3163318634033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 601}, "2": {"k": 2, "answer": "36 months", "latency_ms": 597.8929996490479, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "36 months", "latency_ms": 416.7821407318115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1855}, "4": {"k": 4, "answer": "36 months old", "latency_ms": 697.789192199707, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2438}, "5": {"k": 5, "answer": "36 months", "latency_ms": 634.3088150024414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "36 months", "latency_ms": 424.7019290924072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3823}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 378.74722480773926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 566.0936832427979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 800.7240295410156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 765.6173706054688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 765.6095027923584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2472}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 814.5952224731445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 781.2621593475342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3699}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 1463.3290767669678, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elijah Wood", "latency_ms": 732.3708534240723, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 787.5125408172607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1302}, "3": {"k": 3, "answer": "Elijah Wood", "latency_ms": 495.82552909851074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1968}, "4": {"k": 4, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan", "latency_ms": 1859.3103885650635, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2622}, "5": {"k": 5, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan", "latency_ms": 1415.2863025665283, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan", "latency_ms": 1614.3262386322021, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3902}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party", "latency_ms": 536.3149642944336, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume", "latency_ms": 422.93620109558105, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 749.5691776275635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1171}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 547.126293182373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1793}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 545.8359718322754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 756.7558288574219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3038}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 807.2447776794434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3692}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 178.02953720092773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 808.7058067321777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 786.3199710845947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 763.5476589202881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2009}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 805.0820827484131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2627}, "5": {"k": 5, "answer": "1", "latency_ms": 598.1278419494629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3253}, "6": {"k": 6, "answer": "1", "latency_ms": 415.65656661987305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3866}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "He promised Fantine", "latency_ms": 391.1306858062744, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "To protect her", "latency_ms": 679.1167259216309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "He promised Fantine", "latency_ms": 797.3153591156006, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "He promised Fantine", "latency_ms": 793.6091423034668, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "He promised Fantine", "latency_ms": 767.8923606872559, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "He promised Fantine", "latency_ms": 764.9643421173096, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "He promised Fantine", "latency_ms": 823.3826160430908, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3723}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, and South Korea.", "latency_ms": 617.1221733093262, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenya", "latency_ms": 644.5457935333252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "Kenya, China", "latency_ms": 733.8666915893555, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Kenya, China", "latency_ms": 967.639684677124, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2096}, "4": {"k": 4, "answer": "Kenya, China, India", "latency_ms": 1149.1951942443848, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2807}, "5": {"k": 5, "answer": "Kenya, China, India", "latency_ms": 893.4590816497803, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3497}, "6": {"k": 6, "answer": "Kenya, China, India", "latency_ms": 885.1313591003418, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4317}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and control.", "latency_ms": 624.6280670166016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Enforcing racially separated educational facilities", "latency_ms": 901.0374546051025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 675}, "2": {"k": 2, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 1779.010534286499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 1793.3242321014404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2005}, "4": {"k": 4, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 2021.343469619751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2681}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 1825.402021408081, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3380}, "6": {"k": 6, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 2026.7267227172852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4082}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 292.8156852722168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 1121.7403411865234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 636.3155841827393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Huge and powerful snake", "latency_ms": 857.7010631561279, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1759}, "4": {"k": 4, "answer": "Huge and powerful snake", "latency_ms": 904.8237800598145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2455}, "5": {"k": 5, "answer": "Huge and powerful snake", "latency_ms": 839.7932052612305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3029}, "6": {"k": 6, "answer": "Cobra", "latency_ms": 680.7613372802734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3615}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 462.4063968658447, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "water ice covered with layers of dust and sand", "latency_ms": 1055.4718971252441, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 598}, "2": {"k": 2, "answer": "water ice covered with layers of dust and sand", "latency_ms": 1135.3771686553955, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1207}, "3": {"k": 3, "answer": "Water ice and dry ice (CO2)", "latency_ms": 1051.5046119689941, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1833}, "4": {"k": 4, "answer": "ice-coated dust grains", "latency_ms": 625.4768371582031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "ice-coated dust grains", "latency_ms": 864.5644187927246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "ice-coated dust grains", "latency_ms": 864.4297122955322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3756}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 833.8258266448975, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fourth season", "latency_ms": 432.4479103088379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 577}, "2": {"k": 2, "answer": "Fourth season", "latency_ms": 419.76356506347656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1178}, "3": {"k": 3, "answer": "Season three", "latency_ms": 666.9313907623291, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1770}, "4": {"k": 4, "answer": "Season 3 finale", "latency_ms": 551.0132312774658, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2349}, "5": {"k": 5, "answer": "Season 3 finale", "latency_ms": 796.3836193084717, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2949}, "6": {"k": 6, "answer": "Season 3 finale", "latency_ms": 770.4362869262695, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3537}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "Home team", "latency_ms": 455.74378967285156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dennis Wise and Dion Dublin", "latency_ms": 1072.8340148925781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 574}, "2": {"k": 2, "answer": "Dennis Wise and Dion Dublin", "latency_ms": 876.4605522155762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "Dennis Wise and Dion Dublin", "latency_ms": 1080.1458358764648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1751}, "4": {"k": 4, "answer": "Dennis Wise and Dion Dublin", "latency_ms": 880.1672458648682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2352}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 973.7136363983154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2948}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 746.5720176696777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3521}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw neighborhood", "latency_ms": 340.93213081359863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington, D.C.", "latency_ms": 821.6521739959717, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 691}, "2": {"k": 2, "answer": "Northwest quadrant", "latency_ms": 668.0567264556885, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1348}, "3": {"k": 3, "answer": "Northwest quadrant", "latency_ms": 687.3788833618164, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2005}, "4": {"k": 4, "answer": "Northwest quadrant", "latency_ms": 482.9258918762207, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2689}, "5": {"k": 5, "answer": "Northwest quadrant", "latency_ms": 689.5816326141357, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3339}, "6": {"k": 6, "answer": "Northwest", "latency_ms": 424.1442680358887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4052}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 535.9344482421875, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noahic", "latency_ms": 736.2396717071533, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "Noahic", "latency_ms": 570.7051753997803, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1320}, "3": {"k": 3, "answer": "Noahic", "latency_ms": 496.67859077453613, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1958}, "4": {"k": 4, "answer": "Noahic", "latency_ms": 489.870548248291, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2569}, "5": {"k": 5, "answer": "Noahic", "latency_ms": 496.32811546325684, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Noahic", "latency_ms": 687.0625019073486, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3745}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 561.4428520202637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 762.8931999206543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 558.1555366516113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1224}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 971.3914394378662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 772.6495265960693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 575.8039951324463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3035}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 769.1848278045654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3665}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 539.8931503295898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 542.4559116363525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 781.2213897705078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 809.3886375427246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1035.58349609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2548}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 608.546257019043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3197}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 786.0608100891113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3992}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 710.5281352996826, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 633.1942081451416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 903.7091732025146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 498.4111785888672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 490.8430576324463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 630.6869983673096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 653.2013416290283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3848}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "2nd", "latency_ms": 436.5267753601074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Second", "latency_ms": 373.05712699890137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "Second", "latency_ms": 625.5378723144531, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Second most populated country", "latency_ms": 776.2742042541504, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Second most populated country", "latency_ms": 798.1250286102295, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Second most populated country", "latency_ms": 625.110387802124, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "Second", "latency_ms": 630.7644844055176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3937}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 396.86107635498047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jawaharlal Nehru", "latency_ms": 863.1405830383301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 699}, "2": {"k": 2, "answer": "Jawaharlal Nehru", "latency_ms": 1145.1728343963623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1390}, "3": {"k": 3, "answer": "Mahatma Gandhi", "latency_ms": 544.0194606781006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2064}, "4": {"k": 4, "answer": "Mahatma Gandhi", "latency_ms": 791.3777828216553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2740}, "5": {"k": 5, "answer": "Mahatma Gandhi", "latency_ms": 841.0239219665527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3415}, "6": {"k": 6, "answer": "Mahatma Gandhi", "latency_ms": 604.5682430267334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4088}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenae Anderson", "latency_ms": 584.4452381134033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 729.5379638671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Bobby Flay", "latency_ms": 848.3483791351318, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Bobby Flay", "latency_ms": 753.0097961425781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "Bobby Flay", "latency_ms": 751.4708042144775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2492}, "5": {"k": 5, "answer": "Bobby Flay", "latency_ms": 776.4790058135986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3115}, "6": {"k": 6, "answer": "Bobby Flay", "latency_ms": 590.1391506195068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3743}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 174.16930198669434, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 584.7983360290527, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": ".java", "latency_ms": 611.3898754119873, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "codice_22", "latency_ms": 561.4173412322998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1995}, "4": {"k": 4, "answer": "codice_22", "latency_ms": 759.3543529510498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2610}, "5": {"k": 5, "answer": "codice_22", "latency_ms": 797.4863052368164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3229}, "6": {"k": 6, "answer": "codice_22", "latency_ms": 794.9481010437012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3927}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 488.07430267333984, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alan Turing", "latency_ms": 446.5513229370117, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Alan Turing", "latency_ms": 433.4907531738281, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1373}, "3": {"k": 3, "answer": "Alan Turing", "latency_ms": 706.3033580780029, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2108}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 646.1474895477295, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2817}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 645.4017162322998, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3508}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 510.4866027832031, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4209}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline", "latency_ms": 585.1624011993408, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "manages their party's legislative program", "latency_ms": 1183.985710144043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 669}, "2": {"k": 2, "answer": "manages their party's legislative program", "latency_ms": 917.8104400634766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "manages their party's legislative program", "latency_ms": 1397.151231765747, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "manages party's legislative program", "latency_ms": 1097.6293087005615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "manages party's legislative program", "latency_ms": 894.7136402130127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3348}, "6": {"k": 6, "answer": "manage party's legislative program", "latency_ms": 787.0094776153564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3982}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 442.23690032958984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1974", "latency_ms": 466.78924560546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 679}, "2": {"k": 2, "answer": "1974", "latency_ms": 654.4299125671387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "2001", "latency_ms": 431.53929710388184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1902}, "4": {"k": 4, "answer": "1989", "latency_ms": 667.1109199523926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2484}, "5": {"k": 5, "answer": "1989", "latency_ms": 643.6865329742432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "2001", "latency_ms": 474.0467071533203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3796}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the right but not the obligation to buy foreign currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 264.6481990814209, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 640.0187015533447, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 646.0916996002197, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 702.181339263916, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "FX option", "latency_ms": 689.173698425293, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2662}, "5": {"k": 5, "answer": "FX option", "latency_ms": 710.4535102844238, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3311}, "6": {"k": 6, "answer": "FX option", "latency_ms": 667.2890186309814, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3874}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 185.9121322631836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 429.671049118042, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360", "latency_ms": 596.4248180389404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1352}, "3": {"k": 3, "answer": "360", "latency_ms": 356.5049171447754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2011}, "4": {"k": 4, "answer": "360 members", "latency_ms": 660.6905460357666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2756}, "5": {"k": 5, "answer": "360", "latency_ms": 567.8913593292236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3450}, "6": {"k": 6, "answer": "360", "latency_ms": 375.2579689025879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4146}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 583.930492401123, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 785.1712703704834, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 801.5110492706299, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 598.2418060302734, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 538.4154319763184, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 760.1263523101807, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 763.1509304046631, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3850}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gorm"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 642.3048973083496, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eydie Gorm", "latency_ms": 808.3639144897461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 580}, "2": {"k": 2, "answer": "Eydie Gorm", "latency_ms": 1074.9459266662598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1157}, "3": {"k": 3, "answer": "Eydie Gorm", "latency_ms": 638.308048248291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1758}, "4": {"k": 4, "answer": "Eydie Gorm", "latency_ms": 869.335412979126, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2359}, "5": {"k": 5, "answer": "Eydie Gorm", "latency_ms": 860.5175018310547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2935}, "6": {"k": 6, "answer": "Eydie Gorm", "latency_ms": 891.7765617370605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3552}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "Kurian Joseph", "latency_ms": 566.3447380065918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 595.6804752349854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 828.9949893951416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Mohan Shantanagoudar", "latency_ms": 1005.7270526885986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "Mohan Shantanagoudar", "latency_ms": 1035.0382328033447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2518}, "5": {"k": 5, "answer": "Mohan Shantanagoudar", "latency_ms": 950.6642818450928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3139}, "6": {"k": 6, "answer": "Mohan Shantanagoudar", "latency_ms": 1162.262201309204, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3742}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 544.1741943359375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Margaret Court", "latency_ms": 520.5514430999756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 669}, "2": {"k": 2, "answer": "Roger Federer", "latency_ms": 706.0418128967285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Roger Federer", "latency_ms": 548.250675201416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Roger Federer", "latency_ms": 736.1049652099609, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2483}, "5": {"k": 5, "answer": "Roger Federer", "latency_ms": 752.3231506347656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3057}, "6": {"k": 6, "answer": "Roger Federer", "latency_ms": 694.8881149291992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3631}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 402.41026878356934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 357.91778564453125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 628.9913654327393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1228}, "3": {"k": 3, "answer": "1", "latency_ms": 556.757926940918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1864}, "4": {"k": 4, "answer": "1", "latency_ms": 380.92970848083496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2479}, "5": {"k": 5, "answer": "1", "latency_ms": 441.6830539703369, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3092}, "6": {"k": 6, "answer": "1", "latency_ms": 375.89287757873535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3691}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 235.32485961914062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2009", "latency_ms": 683.8819980621338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "2009", "latency_ms": 623.2872009277344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "2009", "latency_ms": 481.34446144104004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "2009 and 2010", "latency_ms": 1133.0623626708984, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2589}, "5": {"k": 5, "answer": "2010", "latency_ms": 427.0670413970947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3187}, "6": {"k": 6, "answer": "2010", "latency_ms": 741.8839931488037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3839}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 407.17148780822754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "At least 1", "latency_ms": 571.0451602935791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "17", "latency_ms": 385.10608673095703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "37", "latency_ms": 604.1488647460938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1988}, "4": {"k": 4, "answer": "17", "latency_ms": 568.7997341156006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "37", "latency_ms": 606.7006587982178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "37", "latency_ms": 588.4370803833008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3916}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 828.9504051208496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 666.6955947875977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 1003.6406517028809, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 844.9785709381104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 1022.3305225372314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2556}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 807.1482181549072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3207}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 672.1885204315186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3838}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 1433.1390857696533, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1038.339376449585, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 794.156551361084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 557.232141494751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1991}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 751.3234615325928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2659}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 827.472448348999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 820.9784030914307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3926}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 517.3807144165039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Toby Keith", "latency_ms": 496.5624809265137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Toby Keith", "latency_ms": 741.4307594299316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Toby Keith", "latency_ms": 744.1391944885254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Toby Keith", "latency_ms": 508.7425708770752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2402}, "5": {"k": 5, "answer": "Toby Keith", "latency_ms": 508.9893341064453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3013}, "6": {"k": 6, "answer": "Toby Keith", "latency_ms": 725.6062030792236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3633}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 384.68146324157715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 377.2389888763428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "159", "latency_ms": 631.2541961669922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "159", "latency_ms": 367.2811985015869, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "159", "latency_ms": 604.7866344451904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2626}, "5": {"k": 5, "answer": "159", "latency_ms": 390.1681900024414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3316}, "6": {"k": 6, "answer": "159", "latency_ms": 619.2836761474609, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3989}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 570.3718662261963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matt Flinders", "latency_ms": 490.19742012023926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "Matt Flinders", "latency_ms": 760.4961395263672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1298}, "3": {"k": 3, "answer": "Matt Flinders", "latency_ms": 998.2590675354004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Matt Flinders", "latency_ms": 721.5750217437744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2562}, "5": {"k": 5, "answer": "Matt Flinders", "latency_ms": 695.7137584686279, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Matt Flinders", "latency_ms": 817.9330825805664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3869}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 516.3660049438477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 798.2180118560791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 559.9668025970459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 770.8089351654053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 775.4323482513428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2437}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 776.4811515808105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3035}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 777.949333190918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3687}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 401.3943672180176, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Right hand", "latency_ms": 400.96139907836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 629.7125816345215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1137}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 431.48279190063477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1739}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 417.7689552307129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2303}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 650.1963138580322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2897}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 435.8327388763428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3533}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 706.0067653656006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 780.0102233886719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 602.6091575622559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 803.5397529602051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1914}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 562.5903606414795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2551}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 792.8433418273926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 602.3530960083008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3821}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 589.8375511169434, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bernard Hill", "latency_ms": 952.0912170410156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 644}, "2": {"k": 2, "answer": "Bernard Hill", "latency_ms": 756.3266754150391, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "Bernard Hill", "latency_ms": 1025.8288383483887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Bernard Hill", "latency_ms": 584.3915939331055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "Bernard Hill", "latency_ms": 961.3494873046875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3233}, "6": {"k": 6, "answer": "Bernard Hill", "latency_ms": 681.4351081848145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3821}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2019", "latency_ms": 924.7922897338867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2018", "latency_ms": 1139.7655010223389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 976.555347442627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 1132.946252822876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 1129.4851303100586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 959.9964618682861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3113}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 1249.0451335906982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3704}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 243.4980869293213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles", "latency_ms": 646.5144157409668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Los Angeles", "latency_ms": 644.6831226348877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Los Angeles", "latency_ms": 716.7565822601318, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1855}, "4": {"k": 4, "answer": "Los Angeles", "latency_ms": 457.7805995941162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2487}, "5": {"k": 5, "answer": "Los Angeles", "latency_ms": 492.6340579986572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3086}, "6": {"k": 6, "answer": "Los Angeles", "latency_ms": 626.3906955718994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3708}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 298.34866523742676, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indiana Evans", "latency_ms": 629.3177604675293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 751.248836517334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1251}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 772.2091674804688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Indiana Evans", "latency_ms": 699.3269920349121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Indiana Evans", "latency_ms": 440.25301933288574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "Indiana Evans", "latency_ms": 730.9036254882812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3844}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living things", "latency_ms": 305.89795112609863, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in plants, soils, and organisms", "latency_ms": 938.7776851654053, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "in plants, soils, and organisms", "latency_ms": 914.1666889190674, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "in plants, soils, and organisms", "latency_ms": 962.6350402832031, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "in plants, soils, and organisms", "latency_ms": 938.8473033905029, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2652}, "5": {"k": 5, "answer": "in all land-living organisms, soils, plants, and forests", "latency_ms": 1300.4629611968994, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3295}, "6": {"k": 6, "answer": "in all land-living organisms, soils, plants, and animals", "latency_ms": 1308.5682392120361, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3862}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 357.2707176208496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pratham", "latency_ms": 699.7530460357666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "Pratham", "latency_ms": 465.30890464782715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Pratham", "latency_ms": 687.4666213989258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Pratham", "latency_ms": 632.838249206543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Pratham", "latency_ms": 444.183349609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "Pratham", "latency_ms": 694.2756175994873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3776}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 709.0539932250977, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake Powell", "latency_ms": 613.109827041626, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "Lake Powell, Kanab, Utah", "latency_ms": 992.7933216094971, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Lake Powell, Kanab, Utah", "latency_ms": 1209.2204093933105, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Lake Powell, Kanab, Utah, and Clay County", "latency_ms": 1679.8069477081299, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Lake Powell, Kanab, Utah, and Clay County", "latency_ms": 1190.6285285949707, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3110}, "6": {"k": 6, "answer": "Lake Powell, Kanab, Utah, Jackson County, Clay County", "latency_ms": 1802.0775318145752, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3828}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 299.8318672180176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Stevens", "latency_ms": 693.5975551605225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Henry Garrett", "latency_ms": 667.9682731628418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Kevin Kline", "latency_ms": 549.0100383758545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1983}, "4": {"k": 4, "answer": "Kevin Kline", "latency_ms": 767.8854465484619, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2621}, "5": {"k": 5, "answer": "Dan Stevens", "latency_ms": 711.618185043335, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3282}, "6": {"k": 6, "answer": "Dan Stevens", "latency_ms": 453.0763626098633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3897}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Lake Winnipeg", "latency_ms": 974.4870662689209, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 844.6569442749023, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 728}, "2": {"k": 2, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 863.2831573486328, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1438}, "3": {"k": 3, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 609.8673343658447, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Rocky Mountains to Lake Winnipeg", "latency_ms": 682.3015213012695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2761}, "5": {"k": 5, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 823.1344223022461, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3459}, "6": {"k": 6, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 818.3002471923828, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4060}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 495.12290954589844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 633.6629390716553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome", "latency_ms": 470.6432819366455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Rome", "latency_ms": 627.1848678588867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1843}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 762.0716094970703, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2487}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 577.1660804748535, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3102}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 576.4567852020264, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3764}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "Measurement mark", "latency_ms": 448.4884738922119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "batch code", "latency_ms": 433.3631992340088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "year mark", "latency_ms": 693.274974822998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "batch code", "latency_ms": 449.51486587524414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1801}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 575.3452777862549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2364}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 819.7128772735596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2987}, "6": {"k": 6, "answer": "Year mark", "latency_ms": 437.6513957977295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3608}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia", "latency_ms": 296.0796356201172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "associated liquids", "latency_ms": 445.86849212646484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "Ice", "latency_ms": 536.3528728485107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 867.5966262817383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 1098.836898803711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 871.2100982666016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 1070.9693431854248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Boy Meets Girl", "latency_ms": 376.45602226257324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 545.32790184021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 549.5662689208984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1142}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 562.9675388336182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1702}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 747.7664947509766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2287}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 752.4573802947998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2933}, "6": {"k": 6, "answer": "The Little Match Girl", "latency_ms": 738.478422164917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3494}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 433.93945693969727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hombre", "latency_ms": 457.57460594177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Hombre", "latency_ms": 602.7328968048096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Rook", "latency_ms": 475.51846504211426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "Rook", "latency_ms": 666.0809516906738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2413}, "5": {"k": 5, "answer": "Rook", "latency_ms": 467.18478202819824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3036}, "6": {"k": 6, "answer": "Rook", "latency_ms": 633.6414813995361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3612}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 544.2373752593994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 988.9256954193115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 807.183027267456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 766.4790153503418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1769}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 800.2040386199951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2354}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 758.7831020355225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3009}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 816.1990642547607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3543}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 482.97905921936035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1975", "latency_ms": 643.629789352417, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "1975", "latency_ms": 649.2671966552734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "1975", "latency_ms": 485.0955009460449, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "1975", "latency_ms": 419.54827308654785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2515}, "5": {"k": 5, "answer": "1975", "latency_ms": 698.904275894165, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3108}, "6": {"k": 6, "answer": "1975", "latency_ms": 682.018518447876, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3852}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 583.1882953643799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lionel Richie", "latency_ms": 783.3716869354248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Lionel Richie", "latency_ms": 739.2082214355469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1273}, "3": {"k": 3, "answer": "Lionel Richie", "latency_ms": 784.8732471466064, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1840}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 562.4520778656006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2426}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 795.2263355255127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3005}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 731.6029071807861, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3636}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert", "latency_ms": 856.9447994232178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cecil Calvert and Catholic settlers", "latency_ms": 1229.2060852050781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Cecil Calvert and Catholic settlers", "latency_ms": 1023.4649181365967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Cecil Calvert", "latency_ms": 824.6505260467529, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "Cecil Calvert", "latency_ms": 829.1959762573242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Cecil Calvert", "latency_ms": 854.090690612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3218}, "6": {"k": 6, "answer": "Cecil Calvert and Lord Baltimore", "latency_ms": 1185.1680278778076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3871}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 233.5805892944336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 814.2521381378174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 750.4787445068359, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Gary Player", "latency_ms": 661.2279415130615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1875}, "4": {"k": 4, "answer": "Gary Player", "latency_ms": 660.2287292480469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Gary Player", "latency_ms": 651.7705917358398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3077}, "6": {"k": 6, "answer": "Gary Player", "latency_ms": 789.3688678741455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3827}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 591.9020175933838, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "200 to 500 mg", "latency_ms": 1066.7166709899902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "200 to 500 mg", "latency_ms": 849.9057292938232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1269}, "3": {"k": 3, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 1434.3595504760742, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1889}, "4": {"k": 4, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 1309.473991394043, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2607}, "5": {"k": 5, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 1365.0486469268799, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3226}, "6": {"k": 6, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 1370.5048561096191, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3886}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 493.8545227050781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham", "latency_ms": 654.9777984619141, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 713.289737701416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1166}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 736.8123531341553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1758}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 756.948709487915, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2394}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 944.8330402374268, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2966}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 498.3961582183838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3562}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 528.7830829620361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Beer parlours", "latency_ms": 684.5202445983887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Beer parlours", "latency_ms": 495.9568977355957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Canada, Mexico, and the Caribbean.", "latency_ms": 1194.50044631958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2067}, "4": {"k": 4, "answer": "Canada, Mexico, or the Caribbean.", "latency_ms": 1212.0311260223389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2683}, "5": {"k": 5, "answer": "Canada, Mexico, or the Caribbean.", "latency_ms": 807.3406219482422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3335}, "6": {"k": 6, "answer": "nearby township of Lorneville or the town of Winton", "latency_ms": 1759.0839862823486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3983}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh", "latency_ms": 470.0498580932617, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 1053.736925125122, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 605.4027080535889, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1372}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 760.9202861785889, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2057}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 755.0809383392334, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2733}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 755.4817199707031, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3406}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 775.2394676208496, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4109}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 510.5719566345215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 734.074592590332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 706}, "2": {"k": 2, "answer": "Roman Reigns", "latency_ms": 511.17873191833496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1413}, "3": {"k": 3, "answer": "Roman Reigns", "latency_ms": 538.4275913238525, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2090}, "4": {"k": 4, "answer": "AJ Styles", "latency_ms": 608.6997985839844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2692}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 761.6190910339355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3360}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 983.0389022827148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4007}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 635.0152492523193, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Southport", "latency_ms": 627.8517246246338, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 560}, "2": {"k": 2, "answer": "Southport", "latency_ms": 455.65056800842285, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1144}, "3": {"k": 3, "answer": "Southport", "latency_ms": 676.7818927764893, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1780}, "4": {"k": 4, "answer": "Southport", "latency_ms": 410.5203151702881, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2343}, "5": {"k": 5, "answer": "Southport, North Carolina", "latency_ms": 1040.7350063323975, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2939}, "6": {"k": 6, "answer": "Southport, North Carolina", "latency_ms": 887.784481048584, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3573}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 504.03833389282227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 596.4736938476562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 705}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 819.3991184234619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 794.2376136779785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1971}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 558.3198070526123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2609}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 1148.740530014038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 913.1402969360352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3831}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 504.58717346191406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 676.8817901611328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 714}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 512.9263401031494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1460}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 736.4237308502197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2166}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 724.6837615966797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2903}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 488.45458030700684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3650}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 715.7073020935059, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4386}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 357.5284481048584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 371.91081047058105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 600}, "2": {"k": 2, "answer": "Max", "latency_ms": 585.6492519378662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1163}, "3": {"k": 3, "answer": "Max", "latency_ms": 394.25110816955566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1791}, "4": {"k": 4, "answer": "Max", "latency_ms": 587.2378349304199, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2426}, "5": {"k": 5, "answer": "Max", "latency_ms": 437.9730224609375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3027}, "6": {"k": 6, "answer": "Max", "latency_ms": 465.9090042114258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3671}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 592.045783996582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amybeth McNulty", "latency_ms": 586.7724418640137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 649}, "2": {"k": 2, "answer": "Amybeth McNulty", "latency_ms": 812.8843307495117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Amybeth McNulty", "latency_ms": 759.9573135375977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Amybeth McNulty", "latency_ms": 604.9940586090088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "Amybeth McNulty", "latency_ms": 771.4033126831055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Amybeth McNulty", "latency_ms": 835.5512619018555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3786}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "Industrialization and imperialism.", "latency_ms": 422.41525650024414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 786.6714000701904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 573.9655494689941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "The 1900s decade began.", "latency_ms": 878.8652420043945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "The start of the 1900s decade.", "latency_ms": 1365.2093410491943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "The 1900s decade began.", "latency_ms": 1266.0183906555176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3252}, "6": {"k": 6, "answer": "The 1900s decade began.", "latency_ms": 1236.1845970153809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3846}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 300.62270164489746, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "self-empowerment", "latency_ms": 629.3392181396484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 857.3341369628906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "self-empowerment", "latency_ms": 894.9978351593018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "self-empowerment", "latency_ms": 1062.903642654419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2629}, "5": {"k": 5, "answer": "self-empowerment", "latency_ms": 829.0166854858398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3212}, "6": {"k": 6, "answer": "Empowerment", "latency_ms": 696.6605186462402, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3834}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 246.14477157592773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "each team", "latency_ms": 633.0857276916504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "each team", "latency_ms": 437.03198432922363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1247}, "3": {"k": 3, "answer": "each team", "latency_ms": 634.3433856964111, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "each team", "latency_ms": 418.4257984161377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Each team", "latency_ms": 632.5020790100098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3063}, "6": {"k": 6, "answer": "The teams", "latency_ms": 638.9822959899902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3664}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 588.6504650115967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 798.7635135650635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "James W. Marshall", "latency_ms": 568.2454109191895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "James W. Marshall", "latency_ms": 556.812047958374, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1895}, "4": {"k": 4, "answer": "James W. Marshall", "latency_ms": 763.4742259979248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2573}, "5": {"k": 5, "answer": "James W. Marshall", "latency_ms": 1007.1704387664795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3200}, "6": {"k": 6, "answer": "James W. Marshall", "latency_ms": 562.9677772521973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3846}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 550.4233837127686, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 963.674783706665, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 554.9318790435791, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 759.2122554779053, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 555.7246208190918, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 541.4831638336182, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 753.0033588409424, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 560.8632564544678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 779.869794845581, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 798.0742454528809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "5", "latency_ms": 623.9433288574219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "All five ski jumping gold medals.", "latency_ms": 856.4996719360352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "5", "latency_ms": 615.7829761505127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3150}, "6": {"k": 6, "answer": "5", "latency_ms": 430.7293891906738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3814}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1034.2307090759277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 996.5214729309082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1219.2661762237549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 801.5317916870117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1517.6136493682861, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1282.533884048462, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1250.5455017089844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3850}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 455.859899520874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central Germany", "latency_ms": 430.9496879577637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Central Germany", "latency_ms": 712.8961086273193, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1374}, "3": {"k": 3, "answer": "Central Germany", "latency_ms": 451.79080963134766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2020}, "4": {"k": 4, "answer": "German-speaking world", "latency_ms": 497.12276458740234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "Central European cultures", "latency_ms": 703.6011219024658, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3349}, "6": {"k": 6, "answer": "European", "latency_ms": 388.89551162719727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4031}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 497.38574028015137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 541.9266223907471, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 789.9773120880127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 567.9116249084473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "16481651", "latency_ms": 841.7258262634277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2661}, "5": {"k": 5, "answer": "16481651", "latency_ms": 919.8989868164062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3339}, "6": {"k": 6, "answer": "16481651", "latency_ms": 803.3912181854248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3964}}}
