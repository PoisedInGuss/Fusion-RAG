{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 333.12320709228516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 22, 2018", "latency_ms": 712.8779888153076, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "June 22, 2018", "latency_ms": 716.1140441894531, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "June 22, 2018", "latency_ms": 746.7596530914307, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "June 22, 2018", "latency_ms": 723.1833934783936, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2582}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 705.7561874389648, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3233}, "6": {"k": 6, "answer": "June 22, 2018", "latency_ms": 724.6882915496826, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3935}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Freestyle, Nordic Combined, Ski Jumping, Biathlon.", "latency_ms": 1294.8331832885742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alpine skiing", "latency_ms": 478.7015914916992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Alpine skiing", "latency_ms": 459.794282913208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Alpine skiing", "latency_ms": 450.1914978027344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "Alpine, Cross-country, Ski-orienteering", "latency_ms": 901.259183883667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2604}, "5": {"k": 5, "answer": "Alpine, Cross-country, Ski jumping", "latency_ms": 779.5727252960205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3246}, "6": {"k": 6, "answer": "Alpine, Cross-country, Ski jumping, Freestyle", "latency_ms": 966.5441513061523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3901}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "Arianwen Parkes-Lockwood", "latency_ms": 577.4481296539307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 534.8353385925293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 569.2257881164551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 579.5111656188965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1949}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 569.631814956665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 589.9152755737305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3248}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 577.3899555206299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3944}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "Bengals, Dolphins, Broncos, Chargers", "latency_ms": 637.946605682373, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Giants and the record-setting year by Dan Marino", "latency_ms": 953.3190727233887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 535.2089405059814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 515.3024196624756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 526.038646697998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "Miami Dolphins", "latency_ms": 453.30357551574707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3172}, "6": {"k": 6, "answer": "Miami Dolphins", "latency_ms": 420.1481342315674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3776}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "December 8, 1985", "latency_ms": 517.9932117462158, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 December 1985", "latency_ms": 627.713680267334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 727}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 578.7220001220703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1447}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 627.7346611022949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2144}, "4": {"k": 4, "answer": "December 8, 1985", "latency_ms": 749.4447231292725, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 2861}, "5": {"k": 5, "answer": "December 8, 1985", "latency_ms": 703.9518356323242, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 3557}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 643.6338424682617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4315}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "Spanish moss", "latency_ms": 207.2606086730957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "moss", "latency_ms": 415.19737243652344, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "moss", "latency_ms": 445.63841819763184, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1343}, "3": {"k": 3, "answer": "moss", "latency_ms": 419.85106468200684, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "moss", "latency_ms": 454.8203945159912, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2635}, "5": {"k": 5, "answer": "moss", "latency_ms": 453.13191413879395, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3264}, "6": {"k": 6, "answer": "moss", "latency_ms": 461.8525505065918, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3949}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "I-IV", "latency_ms": 265.9742832183838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Class II or III", "latency_ms": 514.0824317932129, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 730}, "2": {"k": 2, "answer": "Canadian Cardiovascular Society", "latency_ms": 517.5449848175049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1494}, "3": {"k": 3, "answer": "Canadian Cardiovascular Society", "latency_ms": 521.1906433105469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2250}, "4": {"k": 4, "answer": "Canadian Cardiovascular Society grading", "latency_ms": 582.1669101715088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2959}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 537.6021862030029, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 540.6248569488525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4437}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Mick Hucknall and Neil Moss", "latency_ms": 570.1570510864258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mike Leeson and Peter Vale", "latency_ms": 635.8354091644287, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 583}, "2": {"k": 2, "answer": "Mike Leeson and Peter Vale", "latency_ms": 654.1228294372559, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1219}, "3": {"k": 3, "answer": "Mike Leeson and Peter Vale", "latency_ms": 657.4811935424805, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1856}, "4": {"k": 4, "answer": "Mike Leeson and Peter Vale", "latency_ms": 661.5622043609619, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2455}, "5": {"k": 5, "answer": "Mike Leeson and Peter Vale", "latency_ms": 663.5816097259521, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3060}, "6": {"k": 6, "answer": "Mike Leeson and Peter Vale", "latency_ms": 666.4583683013916, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3712}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 147.34220504760742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 338.82880210876465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "3", "latency_ms": 342.52190589904785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "3", "latency_ms": 340.33203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "3", "latency_ms": 359.71951484680176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "3", "latency_ms": 345.977783203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3299}, "6": {"k": 6, "answer": "3", "latency_ms": 344.4352149963379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3927}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "A cake", "latency_ms": 214.41912651062012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Biscuit-sized cakes", "latency_ms": 573.6746788024902, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "biscuit-sized cakes", "latency_ms": 624.7427463531494, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "A cake", "latency_ms": 400.61378479003906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1765}, "4": {"k": 4, "answer": "A cake.", "latency_ms": 478.1477451324463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2460}, "5": {"k": 5, "answer": "A cake.", "latency_ms": 480.58295249938965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3101}, "6": {"k": 6, "answer": "A cake.", "latency_ms": 466.04275703430176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Seth MacFarlane", "latency_ms": 390.9485340118408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rachael MacFarlane", "latency_ms": 654.0184020996094, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "Rachael MacFarlane", "latency_ms": 690.9682750701904, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1399}, "3": {"k": 3, "answer": "Rachael MacFarlane", "latency_ms": 659.2111587524414, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2065}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 629.9285888671875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2738}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 633.6555480957031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3407}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 603.3618450164795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4062}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "Heroin", "latency_ms": 212.48269081115723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amphetamines", "latency_ms": 456.4332962036133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Amphetamines", "latency_ms": 474.7304916381836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Amphetamines", "latency_ms": 459.2320919036865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1831}, "4": {"k": 4, "answer": "Amphetamines", "latency_ms": 460.8137607574463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2445}, "5": {"k": 5, "answer": "Amphetamines", "latency_ms": 460.3710174560547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3085}, "6": {"k": 6, "answer": "Amphetamines", "latency_ms": 463.32240104675293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3708}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "14 weeks", "latency_ms": 214.67018127441406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 516.9713497161865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 569.3752765655518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "364 weeks", "latency_ms": 416.762113571167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1800}, "4": {"k": 4, "answer": "364 weeks", "latency_ms": 450.8373737335205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2412}, "5": {"k": 5, "answer": "1", "latency_ms": 342.76366233825684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3023}, "6": {"k": 6, "answer": "1 week", "latency_ms": 421.88262939453125, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3656}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "Yushan, China", "latency_ms": 396.06714248657227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sheffield, England", "latency_ms": 536.9246006011963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Sheffield, England", "latency_ms": 536.0801219940186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "Sheffield, England", "latency_ms": 568.5024261474609, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1933}, "4": {"k": 4, "answer": "Sheffield, England", "latency_ms": 539.6945476531982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2562}, "5": {"k": 5, "answer": "Sheffield, England", "latency_ms": 571.3911056518555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Yushan, China", "latency_ms": 643.9299583435059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3836}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "Thad Luckinbill", "latency_ms": 396.0394859313965, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Thad Luckinbill", "latency_ms": 622.6973533630371, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "Thad Luckinbill", "latency_ms": 635.5750560760498, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Thad Luckinbill", "latency_ms": 580.8050632476807, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Thad Luckinbill", "latency_ms": 586.3957405090332, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2485}, "5": {"k": 5, "answer": "Thad Luckinbill", "latency_ms": 631.7765712738037, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "Thad Luckinbill", "latency_ms": 642.6939964294434, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3708}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 205.7805061340332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Early 1990s", "latency_ms": 575.7644176483154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "early 1990s", "latency_ms": 567.4805641174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "1973", "latency_ms": 399.58858489990234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2001}, "4": {"k": 4, "answer": "1983", "latency_ms": 447.7212429046631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2690}, "5": {"k": 5, "answer": "1983", "latency_ms": 419.8160171508789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3320}, "6": {"k": 6, "answer": "1983", "latency_ms": 404.0193557739258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3903}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "J-Rock", "latency_ms": 270.81894874572754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jakalope, Damhnait Doyle", "latency_ms": 773.2834815979004, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Jakalope, Damhnait Doyle, Alexz Johnson", "latency_ms": 998.1667995452881, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Damhnait Doyle", "latency_ms": 571.7039108276367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Damhnait Doyle", "latency_ms": 538.5935306549072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Damhnait Doyle, Jakalope, Alexz Johnson", "latency_ms": 1005.0616264343262, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Damhnait Doyle", "latency_ms": 576.8101215362549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3935}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "2006", "latency_ms": 208.8797092437744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2.6 million years ago", "latency_ms": 652.6827812194824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "360 million years ago", "latency_ms": 538.036584854126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "2.6 million years ago", "latency_ms": 696.6602802276611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "2.6 million years ago", "latency_ms": 659.041166305542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "360 million years ago", "latency_ms": 540.3149127960205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "360 million years ago", "latency_ms": 520.0979709625244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3871}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "Master Sergeant", "latency_ms": 206.43162727355957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "8th Engineer Support Battalion", "latency_ms": 576.5695571899414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 732}, "2": {"k": 2, "answer": "Master Sergeant", "latency_ms": 398.44393730163574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1425}, "3": {"k": 3, "answer": "First Sergeant", "latency_ms": 416.4891242980957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2087}, "4": {"k": 4, "answer": "First Sergeant", "latency_ms": 417.5457954406738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2737}, "5": {"k": 5, "answer": "First Sergeant", "latency_ms": 419.51894760131836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3440}, "6": {"k": 6, "answer": "First Sergeant", "latency_ms": 425.10271072387695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4176}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 266.25919342041016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Richard Stallman", "latency_ms": 456.7375183105469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 685}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 457.25226402282715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1332}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 480.09729385375977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 463.82808685302734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2594}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 466.16673469543457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3284}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 465.27624130249023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 336.90547943115234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 535.4077816009521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 566.0998821258545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 521.7940807342529, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1828}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 517.5015926361084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2433}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 542.6340103149414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3014}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 573.0979442596436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3641}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Ed Roland", "latency_ms": 208.47392082214355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 415.88497161865234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 415.8289432525635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1369}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 418.1087017059326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 419.5873737335205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2622}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 401.9012451171875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3207}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 420.9709167480469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3813}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 337.2609615325928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miami Heat", "latency_ms": 415.0245189666748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 445.2970027923584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1310}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 417.0668125152588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 417.2403812408447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2505}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 403.0184745788574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3072}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 419.9562072753906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3682}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 338.20223808288574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Guarani (PYG)", "latency_ms": 747.1492290496826, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "PYG6155", "latency_ms": 564.0320777893066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "PYG", "latency_ms": 459.4764709472656, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "PYG", "latency_ms": 452.6934623718262, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "PYG", "latency_ms": 418.7631607055664, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3030}, "6": {"k": 6, "answer": "PYG", "latency_ms": 454.4262886047363, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3667}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "Midazolam", "latency_ms": 337.96191215515137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Benzodiazepines", "latency_ms": 658.9927673339844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 678}, "2": {"k": 2, "answer": "Benzodiazepines.", "latency_ms": 698.399543762207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1397}, "3": {"k": 3, "answer": "Benzodiazepines", "latency_ms": 639.549732208252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2036}, "4": {"k": 4, "answer": "Benzodiazepines", "latency_ms": 688.4684562683105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2771}, "5": {"k": 5, "answer": "Benzodiazepines", "latency_ms": 659.609317779541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3496}, "6": {"k": 6, "answer": "Benzodiazepines", "latency_ms": 661.1456871032715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4207}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 336.0791206359863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "26,000 years", "latency_ms": 533.8890552520752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "26,000 years", "latency_ms": 535.5274677276611, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "26,000 years", "latency_ms": 522.1190452575684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1840}, "4": {"k": 4, "answer": "26,000 years", "latency_ms": 538.3493900299072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2468}, "5": {"k": 5, "answer": "26,000 years", "latency_ms": 523.4816074371338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3095}, "6": {"k": 6, "answer": "26,000 years", "latency_ms": 523.2715606689453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3720}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 270.4794406890869, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Texas A&M University", "latency_ms": 517.7536010742188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Texas A&M University", "latency_ms": 518.836259841919, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Texas A&M University", "latency_ms": 566.3862228393555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1894}, "4": {"k": 4, "answer": "Texas A&M University", "latency_ms": 540.1573181152344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2518}, "5": {"k": 5, "answer": "Texas A&M Aggies", "latency_ms": 598.825216293335, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3165}, "6": {"k": 6, "answer": "Texas A&M Aggies", "latency_ms": 584.373950958252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3823}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and Non-Renewable.", "latency_ms": 690.7913684844971, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable or non-renewable", "latency_ms": 754.9562454223633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable or non-renewable", "latency_ms": 759.850263595581, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1403}, "3": {"k": 3, "answer": "renewable or non-renewable", "latency_ms": 759.9818706512451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2201}, "4": {"k": 4, "answer": "renewable or non-renewable", "latency_ms": 758.1696510314941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2932}, "5": {"k": 5, "answer": "renewable or non-renewable", "latency_ms": 760.1094245910645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3579}, "6": {"k": 6, "answer": "renewable or non-renewable", "latency_ms": 765.5036449432373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4356}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "New life and fertility", "latency_ms": 335.04581451416016, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parental devotion", "latency_ms": 469.94471549987793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "parental devotion", "latency_ms": 474.93982315063477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Purity", "latency_ms": 401.37243270874023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1879}, "4": {"k": 4, "answer": "parental devotion", "latency_ms": 477.902889251709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2522}, "5": {"k": 5, "answer": "parental devotion", "latency_ms": 479.8240661621094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Parental devotion", "latency_ms": 461.93981170654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Virat Kohli", "latency_ms": 334.7139358520508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "558", "latency_ms": 335.16383171081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "558 runs", "latency_ms": 415.6811237335205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1203}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 580.3613662719727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1834}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 538.8476848602295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2447}, "5": {"k": 5, "answer": "558", "latency_ms": 358.75964164733887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "558", "latency_ms": 359.5740795135498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3681}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "the antimicrobial action of metal ions.", "latency_ms": 570.0089931488037, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals", "latency_ms": 683.1355094909668, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "biocidal effect of metals", "latency_ms": 687.1418952941895, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "biocidal effect of metals", "latency_ms": 640.1083469390869, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2074}, "4": {"k": 4, "answer": "biocidal effect of metals", "latency_ms": 630.4423809051514, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2740}, "5": {"k": 5, "answer": "biocidal effect of metals", "latency_ms": 660.62331199646, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3478}, "6": {"k": 6, "answer": "biocidal effect of metals", "latency_ms": 643.8412666320801, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4146}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "Dustin Higgs", "latency_ms": 330.02758026123047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rainey Bethea", "latency_ms": 515.0227546691895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 535.738468170166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1263}, "3": {"k": 3, "answer": "Eddie Lee Mays", "latency_ms": 580.5222988128662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Rainey Bethea", "latency_ms": 519.9224948883057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2532}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 519.6261405944824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3156}, "6": {"k": 6, "answer": "Nidal Hasan", "latency_ms": 462.68630027770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3776}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the auction.", "latency_ms": 329.68616485595703, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 549.7996807098389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 566.901445388794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1166}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 581.5062522888184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1736}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 581.3131332397461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2342}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 583.1990242004395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2924}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 601.168155670166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3618}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Afghanistan", "latency_ms": 266.953706741333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 457.5159549713135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 699}, "2": {"k": 2, "answer": "Afghanistan", "latency_ms": 476.43566131591797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1416}, "3": {"k": 3, "answer": "Afghanistan", "latency_ms": 508.4664821624756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2145}, "4": {"k": 4, "answer": "Afghanistan", "latency_ms": 461.6982936859131, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2851}, "5": {"k": 5, "answer": "Afghanistan", "latency_ms": 460.45804023742676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3547}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 482.100248336792, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4271}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "Coagulation, Fibrin formation, Clot retraction", "latency_ms": 876.3933181762695, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1) vasoconstriction, 2) platelet plug, 3) blood coagulation", "latency_ms": 1596.585988998413, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "Vasoconstriction, platelet plug, coagulation", "latency_ms": 1000.1745223999023, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Vasoconstriction, platelet plug formation, coagulation", "latency_ms": 1080.078363418579, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1994}, "4": {"k": 4, "answer": "Vasoconstriction, platelet plug formation, blood coagulation", "latency_ms": 1118.072271347046, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2663}, "5": {"k": 5, "answer": "Vasoconstriction, platelet plug formation, coagulation", "latency_ms": 1068.263292312622, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3321}, "6": {"k": 6, "answer": "Vasoconstriction, platelet plug formation, coagulation", "latency_ms": 1117.6793575286865, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 4042}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "Sebastian Hunsinger", "latency_ms": 395.1690196990967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 532.5453281402588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "Presley Smith", "latency_ms": 514.2498016357422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1324}, "3": {"k": 3, "answer": "Shirley Temple did not play Sunny, the answer is not in the provided context for the 2004 film, but for the TV series: Presley Smith", "latency_ms": 2320.4877376556396, "em": 0.0, "f1": 0.17391304347826084, "containment": 1.0, "context_chars": 2016}, "4": {"k": 4, "answer": "Shirley Temple did not,  Presley Smith did", "latency_ms": 1055.7444095611572, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2700}, "5": {"k": 5, "answer": "Shirley Temple did not play Sunny, the answer is:  Presley Smith", "latency_ms": 1369.3692684173584, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3306}, "6": {"k": 6, "answer": "Shirley Temple (no), Presley Smith", "latency_ms": 946.5410709381104, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4000}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "20 November 1989", "latency_ms": 396.3472843170166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "20 November 1989", "latency_ms": 578.4640312194824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 577.9380798339844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1324}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 597.1884727478027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2012}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 572.81494140625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2594}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 583.7829113006592, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3212}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 584.3870639801025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3865}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "2016", "latency_ms": 206.32147789001465, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2016", "latency_ms": 396.33941650390625, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "23 June 2016", "latency_ms": 595.5655574798584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1294}, "3": {"k": 3, "answer": "23 June 2016", "latency_ms": 597.4907875061035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1923}, "4": {"k": 4, "answer": "23 June 2016", "latency_ms": 570.7650184631348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2504}, "5": {"k": 5, "answer": "23 June 2016", "latency_ms": 586.5542888641357, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3099}, "6": {"k": 6, "answer": "23 June 2016", "latency_ms": 585.9861373901367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3773}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 330.6398391723633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Burj Khalifa", "latency_ms": 532.5348377227783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "Burj Khalifa", "latency_ms": 535.9852313995361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1320}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 535.4132652282715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2001}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 537.0931625366211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2688}, "5": {"k": 5, "answer": "Burj Khalifa", "latency_ms": 538.9926433563232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3291}, "6": {"k": 6, "answer": "Burj Khalifa", "latency_ms": 524.9390602111816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3982}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "Miriam Margolyes", "latency_ms": 395.4336643218994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miranda Hart's mother is played by  Cherie Lunghi", "latency_ms": 1107.703447341919, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "Miranda Hart", "latency_ms": 478.5957336425781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "Miranda Hart's mother is played by  Cherie Lunghi", "latency_ms": 1076.5602588653564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 538.5122299194336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2578}, "5": {"k": 5, "answer": "Miranda Hart's mother is played by  Cherie Lunghi", "latency_ms": 1068.1567192077637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3162}, "6": {"k": 6, "answer": "Miranda Hart's mother is played by  Cherie Lunghi", "latency_ms": 1099.1499423980713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3742}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Montesquieu", "latency_ms": 333.29248428344727, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montesquieu", "latency_ms": 515.6173706054688, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 566.1194324493408, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 539.3116474151611, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1992}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 521.7723846435547, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2714}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 523.7741470336914, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3352}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 574.462890625, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4054}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Myles Garrett", "latency_ms": 272.5710868835449, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 563.786506652832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 519.3939208984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 519.9675559997559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 536.7171764373779, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "Not in context.", "latency_ms": 520.6468105316162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3213}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 526.8604755401611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3758}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2063 BS", "latency_ms": 272.12071418762207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 534.5396995544434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 714}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 534.0232849121094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 536.0112190246582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2124}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 522.362232208252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2877}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 538.6474132537842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3522}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 542.2358512878418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4163}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "Captain John Smith", "latency_ms": 272.02296257019043, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Smith", "latency_ms": 395.4916000366211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 623}, "2": {"k": 2, "answer": "John Smith", "latency_ms": 398.73719215393066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "John Smith", "latency_ms": 416.9187545776367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1923}, "4": {"k": 4, "answer": "John Smith", "latency_ms": 416.1872863769531, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2569}, "5": {"k": 5, "answer": "John Smith", "latency_ms": 400.68578720092773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3241}, "6": {"k": 6, "answer": "John Smith", "latency_ms": 402.5859832763672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3966}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "Parietal cells", "latency_ms": 330.17706871032715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parietal cells", "latency_ms": 515.3887271881104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 625}, "2": {"k": 2, "answer": "Parietal cells", "latency_ms": 506.91771507263184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Parietal cells", "latency_ms": 518.6753273010254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Parietal cells", "latency_ms": 521.4393138885498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2495}, "5": {"k": 5, "answer": "Parietal cells", "latency_ms": 521.9614505767822, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3126}, "6": {"k": 6, "answer": "canaliculi", "latency_ms": 511.96908950805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3870}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "Early morning", "latency_ms": 206.67004585266113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "4 a.m.", "latency_ms": 519.0479755401611, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 507.4503421783447, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "4 a.m.", "latency_ms": 518.8848972320557, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "4 a.m.", "latency_ms": 573.164701461792, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2610}, "5": {"k": 5, "answer": "4 a.m.", "latency_ms": 523.2036113739014, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3264}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 511.74020767211914, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3895}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 211.0743522644043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Idaho", "latency_ms": 393.99266242980957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "Idaho", "latency_ms": 415.0662422180176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1332}, "3": {"k": 3, "answer": "Idaho", "latency_ms": 389.93191719055176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "Idaho", "latency_ms": 399.7676372528076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2599}, "5": {"k": 5, "answer": "Idaho", "latency_ms": 400.9256362915039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3235}, "6": {"k": 6, "answer": "Idaho", "latency_ms": 397.74227142333984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3903}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales", "latency_ms": 1714.0092849731445, "em": 0.0, "f1": 0.43478260869565216, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 514.0457153320312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 534.1012477874756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 518.6126232147217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 536.2927913665771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2520}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 535.637378692627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3151}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 538.947343826294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3775}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 215.42739868164062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "changed key", "latency_ms": 391.707181930542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 516.1387920379639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1429}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 512.9475593566895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2096}, "4": {"k": 4, "answer": "undergone a key modulation", "latency_ms": 597.1100330352783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2741}, "5": {"k": 5, "answer": "undergone key modulations", "latency_ms": 579.4491767883301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3351}, "6": {"k": 6, "answer": "undergone modulation", "latency_ms": 466.6299819946289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3963}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Male citizens", "latency_ms": 206.0699462890625, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "the Roman people", "latency_ms": 454.62942123413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "full Roman citizens", "latency_ms": 457.8092098236084, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "adult male citizens", "latency_ms": 476.4373302459717, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1991}, "4": {"k": 4, "answer": "Adult male citizens", "latency_ms": 458.44578742980957, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2685}, "5": {"k": 5, "answer": "Adult male citizens", "latency_ms": 451.8134593963623, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3347}, "6": {"k": 6, "answer": "Adult male citizens", "latency_ms": 462.01157569885254, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4058}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 329.6663761138916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "9 April 2019", "latency_ms": 622.1506595611572, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "9 April 2019", "latency_ms": 743.3812618255615, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1503}, "3": {"k": 3, "answer": "9 April 2019", "latency_ms": 628.3349990844727, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2163}, "4": {"k": 4, "answer": "9 April 2019", "latency_ms": 630.1629543304443, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2807}, "5": {"k": 5, "answer": "9 April 2019", "latency_ms": 601.3720035552979, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3421}, "6": {"k": 6, "answer": "9 April 2019", "latency_ms": 644.7656154632568, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4119}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "100 parts of blood", "latency_ms": 336.34448051452637, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "volume of blood or mass of blood", "latency_ms": 696.7456340789795, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "volume of blood or mass of blood", "latency_ms": 715.4085636138916, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1302}, "3": {"k": 3, "answer": "volume of blood or mass of blood", "latency_ms": 698.3845233917236, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "volume of blood or mass of blood", "latency_ms": 715.7354354858398, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "volume of blood or mass of blood", "latency_ms": 705.6896686553955, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3172}, "6": {"k": 6, "answer": "volume of blood or mass of blood", "latency_ms": 720.5572128295898, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3889}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "Icarus", "latency_ms": 272.9485034942627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Icarus", "latency_ms": 473.93107414245605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 603}, "2": {"k": 2, "answer": "Icarus", "latency_ms": 451.9379138946533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1200}, "3": {"k": 3, "answer": "Icarus", "latency_ms": 458.1184387207031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1736}, "4": {"k": 4, "answer": "Phaethon", "latency_ms": 571.1991786956787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2351}, "5": {"k": 5, "answer": "Icarus", "latency_ms": 476.66192054748535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2921}, "6": {"k": 6, "answer": "Icarus", "latency_ms": 479.51817512512207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3539}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "September 16, 1979", "latency_ms": 513.8063430786133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 16, 1979", "latency_ms": 697.4191665649414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "September 16, 1979", "latency_ms": 714.6265506744385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1195}, "3": {"k": 3, "answer": "September 16, 1979", "latency_ms": 716.6950702667236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1851}, "4": {"k": 4, "answer": "September 16, 1979", "latency_ms": 750.4706382751465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "September 16, 1979", "latency_ms": 708.3680629730225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3123}, "6": {"k": 6, "answer": "September 16, 1979", "latency_ms": 706.8867683410645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3752}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 am", "latency_ms": 336.9288444519043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 518.7492370605469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "09:00 am", "latency_ms": 536.0889434814453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "09:00 am", "latency_ms": 520.376443862915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1900}, "4": {"k": 4, "answer": "09:00 am", "latency_ms": 538.2907390594482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2548}, "5": {"k": 5, "answer": "09:00 am", "latency_ms": 540.8954620361328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "09:00 am", "latency_ms": 541.4509773254395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3849}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "Tiffany Coyne", "latency_ms": 354.89368438720703, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiffany Coyne", "latency_ms": 533.663272857666, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 574}, "2": {"k": 2, "answer": "Tiffany Coyne", "latency_ms": 534.9280834197998, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 519.4289684295654, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 538.2692813873291, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2398}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 573.7895965576172, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3025}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 524.3825912475586, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3639}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "Yankees, Braves, Reds, Giants", "latency_ms": 637.1409893035889, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yankees, Atlanta Braves", "latency_ms": 644.6545124053955, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 1063.3714199066162, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 1060.8954429626465, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1856}, "4": {"k": 4, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 1061.8698596954346, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2499}, "5": {"k": 5, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 1066.9875144958496, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3075}, "6": {"k": 6, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 1055.8476448059082, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3684}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "2.187 billion dollars", "latency_ms": 390.270471572876, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$343.4 million", "latency_ms": 576.4169692993164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "$1.84 billion", "latency_ms": 574.141263961792, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "$1.84 billion", "latency_ms": 580.4924964904785, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1914}, "4": {"k": 4, "answer": "$1.84 billion", "latency_ms": 578.1638622283936, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2507}, "5": {"k": 5, "answer": "$1.843 billion", "latency_ms": 633.4578990936279, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3176}, "6": {"k": 6, "answer": "$2.187 billion", "latency_ms": 600.440502166748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3827}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 329.61153984069824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 511.0664367675781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 523.2508182525635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 520.1849937438965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 539.4439697265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2535}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 540.7390594482422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 577.7842998504639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3837}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark", "latency_ms": 206.45904541015625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Denmark, Norway and Schleswig-Holstein", "latency_ms": 1017.6854133605957, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "Denmark, Norway and Schleswig-Holstein", "latency_ms": 986.536979675293, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1342}, "3": {"k": 3, "answer": "Denmark, Norway and Schleswig-Holstein", "latency_ms": 988.9962673187256, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1993}, "4": {"k": 4, "answer": "Denmark, Norway and Schleswig-Holstein", "latency_ms": 991.0433292388916, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2621}, "5": {"k": 5, "answer": "Denmark, Norway and Schleswig-Holstein", "latency_ms": 941.7493343353271, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3233}, "6": {"k": 6, "answer": "Scandinavia", "latency_ms": 483.16407203674316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3858}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "Prespio", "latency_ms": 266.12019538879395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Puritina", "latency_ms": 532.2508811950684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Christmas Tree", "latency_ms": 397.28450775146484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Christmas Tree", "latency_ms": 398.56576919555664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1949}, "4": {"k": 4, "answer": "Christmas Tree", "latency_ms": 391.47257804870605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2595}, "5": {"k": 5, "answer": "Nativity scene", "latency_ms": 479.16698455810547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3270}, "6": {"k": 6, "answer": "Puritina", "latency_ms": 544.6906089782715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3908}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "Patrick Swayze", "latency_ms": 332.11326599121094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 713.5553359985352, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 715.4076099395752, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 747.8761672973633, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 720.9546566009521, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2475}, "5": {"k": 5, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 707.3605060577393, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3098}, "6": {"k": 6, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 759.0775489807129, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3723}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Pittsburgh", "latency_ms": 266.59178733825684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pittsburgh", "latency_ms": 451.3711929321289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "Pittsburgh", "latency_ms": 506.84452056884766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Pittsburgh", "latency_ms": 459.4690799713135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1910}, "4": {"k": 4, "answer": "Pittsburgh", "latency_ms": 460.56222915649414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "Pittsburgh", "latency_ms": 479.9695014953613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Pittsburgh", "latency_ms": 483.86335372924805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3885}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1704", "latency_ms": 205.37662506103516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 532.7255725860596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "1901", "latency_ms": 411.38505935668945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "1901", "latency_ms": 400.00152587890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "18th century", "latency_ms": 460.36791801452637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2651}, "5": {"k": 5, "answer": "18th century", "latency_ms": 476.9611358642578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3319}, "6": {"k": 6, "answer": "1727", "latency_ms": 420.70770263671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3987}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier Fernndez", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Yuzuru Hanyu", "latency_ms": 455.84583282470703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yuzuru Hanyu", "latency_ms": 659.9090099334717, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Yuzuru Hanyu", "latency_ms": 686.669111251831, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Yuzuru Hanyu", "latency_ms": 657.3262214660645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Yuzuru Hanyu", "latency_ms": 642.1477794647217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2588}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 657.9334735870361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3188}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 643.5494422912598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3798}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "Password recovery and cracking.", "latency_ms": 397.07136154174805, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 532.7327251434326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 534.9085330963135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 533.9095592498779, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2023}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 538.8460159301758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2693}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 523.3478546142578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3384}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 542.3753261566162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4055}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 333.8356018066406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 505.01489639282227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "C. Vidyasagar Rao", "latency_ms": 716.8364524841309, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 698.0843544006348, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 721.339225769043, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2593}, "5": {"k": 5, "answer": "C. Vidyasagar Rao", "latency_ms": 752.7410984039307, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "C. Vidyasagar Rao", "latency_ms": 720.9916114807129, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3873}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "Channel 15", "latency_ms": 266.83998107910156, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "15", "latency_ms": 391.4203643798828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 603}, "2": {"k": 2, "answer": "15", "latency_ms": 355.5762767791748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "15", "latency_ms": 354.10237312316895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1959}, "4": {"k": 4, "answer": "15", "latency_ms": 354.2792797088623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2713}, "5": {"k": 5, "answer": "15", "latency_ms": 357.4826717376709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3390}, "6": {"k": 6, "answer": "15", "latency_ms": 391.96276664733887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4022}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Claudia Wells", "latency_ms": 329.9379348754883, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Claudia Wells", "latency_ms": 516.629695892334, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Claudia Wells", "latency_ms": 517.9281234741211, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1207}, "3": {"k": 3, "answer": "Claudia Wells", "latency_ms": 520.7164287567139, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 538.8214588165283, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2477}, "5": {"k": 5, "answer": "Claudia Wells", "latency_ms": 522.296667098999, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "Claudia Wells", "latency_ms": 524.2335796356201, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3667}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 150.94590187072754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "London, United Kingdom", "latency_ms": 533.9269638061523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 537.1501445770264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1244}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 538.8596057891846, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1891}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 522.39990234375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2490}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 570.5776214599609, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3105}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 540.8928394317627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3741}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The White House Chef", "latency_ms": 329.55002784729004, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The White House Executive Chef", "latency_ms": 565.9904479980469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "The White House Executive Chef", "latency_ms": 575.0021934509277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1369}, "3": {"k": 3, "answer": "The White House Executive Chef", "latency_ms": 600.6591320037842, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2038}, "4": {"k": 4, "answer": "The White House Executive Chef", "latency_ms": 570.3670978546143, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2656}, "5": {"k": 5, "answer": "The White House Executive Chef", "latency_ms": 581.2311172485352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3325}, "6": {"k": 6, "answer": "The White House Executive Chef", "latency_ms": 583.4953784942627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3982}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 336.9431495666504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 534.9540710449219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 567.0247077941895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Benegal Narsing Rau", "latency_ms": 700.6793022155762, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "Benegal Narsing Rau", "latency_ms": 691.8034553527832, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Benegal Narsing Rau", "latency_ms": 691.9674873352051, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "Benegal Narsing Rau", "latency_ms": 662.3978614807129, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3846}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 331.89892768859863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "British Columbia", "latency_ms": 413.4502410888672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "British Columbia", "latency_ms": 396.9895839691162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1301}, "3": {"k": 3, "answer": "British Columbia", "latency_ms": 414.00933265686035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1986}, "4": {"k": 4, "answer": "British Columbia, Abbotsford, Vancouver, Langley, Aldergrove", "latency_ms": 1199.3234157562256, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2592}, "5": {"k": 5, "answer": "British Columbia", "latency_ms": 421.1845397949219, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3250}, "6": {"k": 6, "answer": "British Columbia, Abbotsford, Vancouver, Langley, Aldergrove", "latency_ms": 1186.455488204956, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3850}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 329.43153381347656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 12, 2017", "latency_ms": 745.3489303588867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "October 11, 2018", "latency_ms": 744.269847869873, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1322}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 718.238353729248, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1949}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 753.6988258361816, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 753.4670829772949, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3233}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 762.8090381622314, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3869}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Jodie Sweetin", "latency_ms": 330.5504322052002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lori Loughlin", "latency_ms": 633.538007736206, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "Jodie Sweetin", "latency_ms": 518.7182426452637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Jodie Sweetin", "latency_ms": 538.4643077850342, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Jodie Sweetin", "latency_ms": 574.1307735443115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "Jodie Sweetin", "latency_ms": 522.0801830291748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3121}, "6": {"k": 6, "answer": "Jodie Sweetin", "latency_ms": 513.9796733856201, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3746}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "Milennium Tower", "latency_ms": 335.3254795074463, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 515.1886940002441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 535.6013774871826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1266}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 536.6120338439941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1867}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 524.5556831359863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 570.9066390991211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3248}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 525.0861644744873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3905}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 211.58885955810547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 415.0426387786865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 534.7814559936523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 518.8043117523193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "January 11, 2014", "latency_ms": 700.3397941589355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2525}, "5": {"k": 5, "answer": "January 11, 2014", "latency_ms": 722.6083278656006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3161}, "6": {"k": 6, "answer": "January 11, 2014", "latency_ms": 723.3648300170898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3787}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "John Harlan", "latency_ms": 273.39768409729004, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 561.988353729248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 564.2702579498291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1307}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 535.9108448028564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 538.8903617858887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2559}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 539.2522811889648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3165}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 541.2633419036865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3812}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Tyrann Mathieu", "latency_ms": 389.8916244506836, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tyrann Mathieu", "latency_ms": 592.7364826202393, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 595.3965187072754, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 625.4334449768066, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1968}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 597.2623825073242, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2618}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 602.4837493896484, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3236}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 583.8708877563477, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3928}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "44", "latency_ms": 147.9349136352539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "six", "latency_ms": 335.19983291625977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "6", "latency_ms": 334.1648578643799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1318}, "3": {"k": 3, "answer": "6", "latency_ms": 336.5657329559326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "six episodes", "latency_ms": 412.9626750946045, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2633}, "5": {"k": 5, "answer": "Six episodes", "latency_ms": 400.4864692687988, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3306}, "6": {"k": 6, "answer": "6 episodes", "latency_ms": 401.8592834472656, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3923}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul Bamer's", "latency_ms": 395.55811882019043, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Remarque's", "latency_ms": 515.2831077575684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "Remarque's", "latency_ms": 535.2048873901367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Paul's", "latency_ms": 400.39587020874023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Paul", "latency_ms": 339.7939205169678, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2492}, "5": {"k": 5, "answer": "Paul's", "latency_ms": 400.5773067474365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "Paul's", "latency_ms": 401.2911319732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3670}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris", "latency_ms": 209.8104953765869, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Morris and the Anglins", "latency_ms": 695.6596374511719, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Morris and the Anglins", "latency_ms": 717.0765399932861, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1175}, "3": {"k": 3, "answer": "Morris and the Anglins", "latency_ms": 718.2645797729492, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "John Paul Scott", "latency_ms": 476.3174057006836, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "John Paul Scott", "latency_ms": 478.76858711242676, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3121}, "6": {"k": 6, "answer": "John Paul Scott", "latency_ms": 479.88128662109375, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3717}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF programs.", "latency_ms": 395.0839042663574, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF", "latency_ms": 505.6581497192383, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 718}, "2": {"k": 2, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world", "latency_ms": 1379.8577785491943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1376}, "3": {"k": 3, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world.", "latency_ms": 1474.550485610962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2106}, "4": {"k": 4, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world", "latency_ms": 1425.2569675445557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2800}, "5": {"k": 5, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world", "latency_ms": 1366.8975830078125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3488}, "6": {"k": 6, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world", "latency_ms": 1372.1604347229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4121}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Tablet", "latency_ms": 209.43355560302734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Inside the statue", "latency_ms": 460.573673248291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Inside the statue", "latency_ms": 475.51727294921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "on a tabula ansata", "latency_ms": 635.577917098999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "on a tabula ansata", "latency_ms": 641.9532299041748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2421}, "5": {"k": 5, "answer": "on her tabula ansata", "latency_ms": 656.4280986785889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3013}, "6": {"k": 6, "answer": "on her tabula ansata", "latency_ms": 643.904447555542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "Milan-Cortina, Sapporo", "latency_ms": 637.5143527984619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 518.1577205657959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "Beijing, China, then unknown", "latency_ms": 716.5603637695312, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1236}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 535.7875823974609, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 540.5502319335938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 522.3443508148193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3064}, "6": {"k": 6, "answer": "Beijing, then a city to be selected for 2026", "latency_ms": 1070.319652557373, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3726}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "1981", "latency_ms": 205.7785987854004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "August 22, 1980", "latency_ms": 713.9096260070801, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "August 22, 1980", "latency_ms": 700.7062435150146, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "August 22, 1980", "latency_ms": 699.68581199646, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "August 22, 1980", "latency_ms": 720.5445766448975, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2519}, "5": {"k": 5, "answer": "August 22, 1980", "latency_ms": 723.6413955688477, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3135}, "6": {"k": 6, "answer": "August 22, 1980", "latency_ms": 722.9504585266113, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3702}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "Stone Gothic arch bridge", "latency_ms": 330.8389186859131, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stone Bridge", "latency_ms": 413.2535457611084, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 631}, "2": {"k": 2, "answer": "Historic bridge", "latency_ms": 459.0342044830322, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "Historic Stone Bridge", "latency_ms": 538.9266014099121, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Historic bridge", "latency_ms": 477.2679805755615, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2679}, "5": {"k": 5, "answer": "Historic Stone Bridge", "latency_ms": 524.829626083374, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3335}, "6": {"k": 6, "answer": "Historic Stone Bridge", "latency_ms": 574.1376876831055, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3913}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The Autocrat", "latency_ms": 272.3979949951172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One person or a small elite.", "latency_ms": 689.5360946655273, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "One person or a small elite.", "latency_ms": 696.976900100708, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "One person", "latency_ms": 415.0669574737549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "One person", "latency_ms": 400.49052238464355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2632}, "5": {"k": 5, "answer": "One person", "latency_ms": 402.48942375183105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3298}, "6": {"k": 6, "answer": "One person", "latency_ms": 421.88334465026855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3952}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "Affluence", "latency_ms": 272.1574306488037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stable jobs", "latency_ms": 455.0802707672119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "Stable jobs", "latency_ms": 458.5578441619873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1368}, "3": {"k": 3, "answer": "Affluence", "latency_ms": 478.27792167663574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2077}, "4": {"k": 4, "answer": "Affluence", "latency_ms": 461.0934257507324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2839}, "5": {"k": 5, "answer": "Affluence", "latency_ms": 479.01010513305664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3538}, "6": {"k": 6, "answer": "Affluence", "latency_ms": 465.97909927368164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4241}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "Counterclockwise", "latency_ms": 331.28833770751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Along its trajectory", "latency_ms": 457.2875499725342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "Eastward", "latency_ms": 395.4925537109375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1147}, "3": {"k": 3, "answer": "Eastward", "latency_ms": 399.7056484222412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1755}, "4": {"k": 4, "answer": "around", "latency_ms": 341.01247787475586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2362}, "5": {"k": 5, "answer": "around", "latency_ms": 339.7243022918701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2993}, "6": {"k": 6, "answer": "around", "latency_ms": 341.1297798156738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3595}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Statue of Freedom", "latency_ms": 332.2618007659912, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The dome", "latency_ms": 394.78063583374023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "Dome", "latency_ms": 397.2206115722656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "The dome", "latency_ms": 400.9900093078613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "The dome", "latency_ms": 400.02942085266113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2548}, "5": {"k": 5, "answer": "The dome", "latency_ms": 402.26101875305176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3215}, "6": {"k": 6, "answer": "A bronze eagle", "latency_ms": 480.82852363586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3811}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "Taoyuan Leopards", "latency_ms": 451.38025283813477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 563.3900165557861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "Los Angeles Lakers", "latency_ms": 474.942684173584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 540.3776168823242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 539.2014980316162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2454}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 524.6164798736572, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3053}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 525.8636474609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3657}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 332.3373794555664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 534.7781181335449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Rey Mysterio", "latency_ms": 629.3823719024658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Rey Mysterio", "latency_ms": 610.0125312805176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1803}, "4": {"k": 4, "answer": "Rey Mysterio", "latency_ms": 608.361005783081, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2411}, "5": {"k": 5, "answer": "Rey Mysterio", "latency_ms": 590.9478664398193, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3012}, "6": {"k": 6, "answer": "Rey Mysterio", "latency_ms": 582.4027061462402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3619}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 280.04932403564453, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake of the Ozarks", "latency_ms": 570.310115814209, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Lake of the Ozarks", "latency_ms": 595.6964492797852, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "Lake Mead", "latency_ms": 459.73896980285645, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "Lake Mead", "latency_ms": 478.0466556549072, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "Lake Mead", "latency_ms": 453.01342010498047, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3145}, "6": {"k": 6, "answer": "Lake Mead", "latency_ms": 462.9349708557129, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3752}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Tagore", "latency_ms": 212.81790733337402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tagore", "latency_ms": 443.36438179016113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 585}, "2": {"k": 2, "answer": "Tagore", "latency_ms": 443.7854290008545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tagore", "latency_ms": 446.1085796356201, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1860}, "4": {"k": 4, "answer": "Tagore", "latency_ms": 465.03329277038574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Tagore", "latency_ms": 452.207088470459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3232}, "6": {"k": 6, "answer": "Tagore", "latency_ms": 462.8629684448242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3904}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "George H.W. Bush", "latency_ms": 396.4865207672119, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Geraldine Ferraro", "latency_ms": 577.0220756530762, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 682}, "2": {"k": 2, "answer": "Geraldine Ferraro", "latency_ms": 597.5637435913086, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1375}, "3": {"k": 3, "answer": "Geraldine Ferraro", "latency_ms": 626.1847019195557, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2070}, "4": {"k": 4, "answer": "Geraldine Ferraro", "latency_ms": 599.799633026123, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2787}, "5": {"k": 5, "answer": "Geraldine Ferraro and George H.W. Bush", "latency_ms": 945.4638957977295, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3497}, "6": {"k": 6, "answer": "Geraldine Ferraro, George H.W. Bush", "latency_ms": 952.4357318878174, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 4186}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "American Rock Salt mine, Livingston County, New York", "latency_ms": 688.9564990997314, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Groveland", "latency_ms": 763.4294033050537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners", "latency_ms": 535.9876155853271, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Hampton Corners", "latency_ms": 519.0262794494629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "Hampton Corners", "latency_ms": 535.8221530914307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "Hampton Corners", "latency_ms": 538.3203029632568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3201}, "6": {"k": 6, "answer": "Hampton Corners", "latency_ms": 540.3516292572021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3790}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 212.92829513549805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 412.2941493988037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 565}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 414.46566581726074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1164}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 399.6596336364746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1754}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 408.825159072876, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2371}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 400.06422996520996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2961}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 419.7824001312256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3623}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Meghalaya", "latency_ms": 273.1301784515381, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bihar", "latency_ms": 446.962833404541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Meghalaya", "latency_ms": 457.37242698669434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Meghalaya", "latency_ms": 516.9198513031006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1927}, "4": {"k": 4, "answer": "Meghalaya", "latency_ms": 521.8486785888672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2569}, "5": {"k": 5, "answer": "Meghalaya", "latency_ms": 530.4927825927734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Meghalaya", "latency_ms": 517.1933174133301, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3870}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Kanpur", "latency_ms": 271.3193893432617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 565.0062561035156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 568.3426856994629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 520.2431678771973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1842}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 568.8042640686035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 523.9591598510742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 573.3275413513184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3877}}}
