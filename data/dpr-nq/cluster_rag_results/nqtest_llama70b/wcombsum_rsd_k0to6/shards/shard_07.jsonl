{"qid": "5306300389470118812", "question": "what was the religion in persia before islam", "gold_answers": ["the Zoroastrian religion", "Zoroastrian"], "shots": {"0": {"k": 0, "answer": "Zoroastrianism", "latency_ms": 3368.9475059509277, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Zoroastrian", "latency_ms": 2567.8443908691406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 637}, "2": {"k": 2, "answer": "Zoroastrian", "latency_ms": 2696.244955062866, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Zoroastrian", "latency_ms": 2410.207748413086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1985}, "4": {"k": 4, "answer": "Zoroastrianism", "latency_ms": 1936.1436367034912, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2599}, "5": {"k": 5, "answer": "Zoroastrianism", "latency_ms": 1660.7608795166016, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3219}, "6": {"k": 6, "answer": "Zoroastrianism", "latency_ms": 3209.1195583343506, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3880}}}
{"qid": "4492088526674104172", "question": "why does kerosene oil rise up in the wick of lantern", "gold_answers": ["capillary action"], "shots": {"0": {"k": 0, "answer": "Capillary action", "latency_ms": 1718.4169292449951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1686.5136623382568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Capillary action", "latency_ms": 1566.741943359375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Capillary action", "latency_ms": 2437.2291564941406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1858}, "4": {"k": 4, "answer": "Capillary action", "latency_ms": 1615.265130996704, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Capillary action", "latency_ms": 1149.0979194641113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3161}, "6": {"k": 6, "answer": "Capillary action", "latency_ms": 1879.5969486236572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3836}}}
{"qid": "-4373262132142058334", "question": "mention the chemical change that proinsulin undergo to be able to act as mature insulin", "gold_answers": ["post translational modification"], "shots": {"0": {"k": 0, "answer": "Proteolytic cleavage", "latency_ms": 3624.3081092834473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cleavage of C-peptide", "latency_ms": 2582.7157497406006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Cleavage", "latency_ms": 1577.580213546753, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1349}, "3": {"k": 3, "answer": "Cleavage", "latency_ms": 1556.1871528625488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1957}, "4": {"k": 4, "answer": "Cleavage", "latency_ms": 2382.338762283325, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "Cleavage of C-peptide", "latency_ms": 2923.7060546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3284}, "6": {"k": 6, "answer": "Cleavage of C-peptide", "latency_ms": 3229.9537658691406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3996}}}
{"qid": "-5298560410953979569", "question": "where does the sweetness of fruit come from", "gold_answers": ["Fructose , or fruit sugar", "Fructose"], "shots": {"0": {"k": 0, "answer": "Fructose", "latency_ms": 1268.0394649505615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2128.3185482025146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 677}, "2": {"k": 2, "answer": "the pulp tissue surrounding the seeds", "latency_ms": 3041.1601066589355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1360}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2157.3290824890137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2023}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2404.0281772613525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2679}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3243.4208393096924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3277}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2902.111768722534, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3944}}}
{"qid": "4344648368832551136", "question": "an object that moves around an external axis is said to be", "gold_answers": ["orbit", "revolution or orbital revolution"], "shots": {"0": {"k": 0, "answer": "rotating", "latency_ms": 1312.340259552002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "revolving", "latency_ms": 2071.7391967773438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "in a revolution or orbital revolution", "latency_ms": 2687.5081062316895, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 1258}, "3": {"k": 3, "answer": "in a revolution or orbital revolution", "latency_ms": 2259.516716003418, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 1844}, "4": {"k": 4, "answer": "revolving", "latency_ms": 2099.64656829834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2413}, "5": {"k": 5, "answer": "revolving", "latency_ms": 1799.9024391174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3073}, "6": {"k": 6, "answer": "revolving", "latency_ms": 1549.82328414917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3752}}}
{"qid": "-724426540432437711", "question": "what was the name of the plant on little shop of horrors", "gold_answers": ["Audrey II"], "shots": {"0": {"k": 0, "answer": "Audrey II", "latency_ms": 1334.585189819336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2414.188861846924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2217.95654296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "Audrey II", "latency_ms": 1815.6306743621826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Audrey II", "latency_ms": 2595.1035022735596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2534}, "5": {"k": 5, "answer": "Audrey II", "latency_ms": 2120.0239658355713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3181}, "6": {"k": 6, "answer": "Audrey II", "latency_ms": 2362.868547439575, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3810}}}
{"qid": "-5541610970112826260", "question": "who signed the declaration of independence for maryland", "gold_answers": ["Samuel Chase", "Charles Carroll of Carrollton", "Thomas Stone", "William Paca"], "shots": {"0": {"k": 0, "answer": "Samuel Chase", "latency_ms": 1365.872859954834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 7162.163972854614, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 718}, "2": {"k": 2, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 6987.810373306274, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 1372}, "3": {"k": 3, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 7690.562725067139, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 2064}, "4": {"k": 4, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 7255.928993225098, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 2739}, "5": {"k": 5, "answer": "Samuel Chase, William Paca, Thomas Stone, Charles Carroll of Carrollton", "latency_ms": 6951.938629150391, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3427}, "6": {"k": 6, "answer": "Samuel Chase, William Paca, Thomas Stone, Charles Carroll of Carrollton", "latency_ms": 6226.451873779297, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4017}}}
{"qid": "-86997217831791339", "question": "when does wonder woman come out on blue ray", "gold_answers": ["September 19 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2169.552803039551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 19, 2017", "latency_ms": 3301.149606704712, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "September 19, 2017", "latency_ms": 2588.4432792663574, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "September 19, 2017", "latency_ms": 2509.3953609466553, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1833}, "4": {"k": 4, "answer": "September 19, 2017", "latency_ms": 4034.8966121673584, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2470}, "5": {"k": 5, "answer": "September 19, 2017", "latency_ms": 3842.4713611602783, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3129}, "6": {"k": 6, "answer": "September 19, 2017", "latency_ms": 4667.099475860596, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3757}}}
{"qid": "-8062812506672279762", "question": "what nba team did derrick rose play for", "gold_answers": ["New York Knicks", "Minnesota Timberwolves", "Chicago Bulls", "Cleveland Cavaliers"], "shots": {"0": {"k": 0, "answer": "Chicago Bulls", "latency_ms": 922.6419925689697, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chicago Bulls, Minnesota Timberwolves", "latency_ms": 2824.728488922119, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 630}, "2": {"k": 2, "answer": "Chicago Bulls, Minnesota Timberwolves", "latency_ms": 3226.5536785125732, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Chicago Bulls, Minnesota Timberwolves", "latency_ms": 3517.197608947754, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Minnesota Timberwolves, Chicago Bulls, Cleveland Cavaliers", "latency_ms": 5121.206521987915, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2526}, "5": {"k": 5, "answer": "Minnesota Timberwolves, Chicago Bulls, Cleveland Cavaliers", "latency_ms": 3800.513744354248, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3122}, "6": {"k": 6, "answer": "Minnesota Timberwolves, Chicago Bulls, Cleveland Cavaliers, Boston Celtics", "latency_ms": 4742.558479309082, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3721}}}
{"qid": "7933002036740390435", "question": "where did the term liberal arts come from", "gold_answers": ["the Roman Empire"], "shots": {"0": {"k": 0, "answer": "Medieval Europe", "latency_ms": 2129.78458404541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roman Empire", "latency_ms": 753.9281845092773, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Roman Empire", "latency_ms": 1763.5526657104492, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Roman Empire", "latency_ms": 1020.4372406005859, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2046}, "4": {"k": 4, "answer": "Roman Empire", "latency_ms": 2324.6073722839355, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2753}, "5": {"k": 5, "answer": "Roman Empire", "latency_ms": 1302.6337623596191, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3467}, "6": {"k": 6, "answer": "Roman Empire", "latency_ms": 1802.1354675292969, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4180}}}
{"qid": "-2991400700385487821", "question": "who heads the executive department of west virginia government", "gold_answers": ["the Governor of West Virginia", "the governor of West Virginia", "Jim Justice"], "shots": {"0": {"k": 0, "answer": "The Governor", "latency_ms": 1087.8593921661377, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Governor of West Virginia", "latency_ms": 3522.6712226867676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "The Governor of West Virginia", "latency_ms": 2501.633644104004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "The Governor of West Virginia", "latency_ms": 2296.4119911193848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2014}, "4": {"k": 4, "answer": "The Governor of West Virginia", "latency_ms": 2210.460424423218, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2616}, "5": {"k": 5, "answer": "The Governor of West Virginia", "latency_ms": 2670.87984085083, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3256}, "6": {"k": 6, "answer": "The Governor of West Virginia", "latency_ms": 2780.528783798218, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3899}}}
{"qid": "-9186689755642837558", "question": "how long is the bridge between new brunswick and prince edward island", "gold_answers": ["12.9 - kilometre"], "shots": {"0": {"k": 0, "answer": "13 kilometers", "latency_ms": 1859.6487045288086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2001.4474391937256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 686}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1769.2747116088867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1373}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1660.7120037078857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2045}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 896.8510627746582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2780}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2668.020725250244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3458}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1672.638177871704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4049}}}
{"qid": "8029901619424338449", "question": "when did the uk and us become allies", "gold_answers": ["1940", "Since 1940"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1921.5776920318604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "After the end of the Second World War", "latency_ms": 2746.396780014038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "After the end of the Second World War in 1945", "latency_ms": 3941.641330718994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "After the end of the Second World War in 1945", "latency_ms": 4967.958211898804, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "After the end of the Second World War in 1945", "latency_ms": 4419.211864471436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2519}, "5": {"k": 5, "answer": "After the end of the Second World War in 1945", "latency_ms": 5547.000169754028, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3239}, "6": {"k": 6, "answer": "After the end of the Second World War in 1945", "latency_ms": 3462.479829788208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3857}}}
{"qid": "4828649525820722736", "question": "who sang the theme song for the man with the golden gun", "gold_answers": ["Lulu"], "shots": {"0": {"k": 0, "answer": "Lulu", "latency_ms": 1539.7136211395264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lulu", "latency_ms": 2049.2687225341797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 582}, "2": {"k": 2, "answer": "Lulu", "latency_ms": 1285.102128982544, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Lulu", "latency_ms": 1839.2250537872314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1818}, "4": {"k": 4, "answer": "Lulu", "latency_ms": 1322.7348327636719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2475}, "5": {"k": 5, "answer": "Lulu", "latency_ms": 1517.4379348754883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3088}, "6": {"k": 6, "answer": "Lulu", "latency_ms": 2308.873176574707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3758}}}
{"qid": "-7924663090486742985", "question": "american horror story freak show girl kidnapped by clown", "gold_answers": ["Bonnie Lipton"], "shots": {"0": {"k": 0, "answer": "Penny", "latency_ms": 888.2460594177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Twisty", "latency_ms": 1514.2393112182617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2652.254819869995, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2831.1665058135986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2028}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2421.3764667510986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2727}, "5": {"k": 5, "answer": "Dot Tattler", "latency_ms": 2187.9425048828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3347}, "6": {"k": 6, "answer": "Twisty", "latency_ms": 1305.462121963501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3950}}}
{"qid": "-360675773049242516", "question": "the probability of making a type i error when retaining ho at the .05 level of significance is", "gold_answers": ["5 %"], "shots": {"0": {"k": 0, "answer": "0.05", "latency_ms": 1081.918478012085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0.05", "latency_ms": 2355.375289916992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "0.05", "latency_ms": 1517.390251159668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "0.05", "latency_ms": 2900.7341861724854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "0.05", "latency_ms": 1572.0155239105225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2354}, "5": {"k": 5, "answer": "0.05", "latency_ms": 1857.841968536377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2946}, "6": {"k": 6, "answer": "0.05", "latency_ms": 1821.8538761138916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3538}}}
{"qid": "5819386267283467034", "question": "what year did the us hockey team won the olympics", "gold_answers": ["1960", "1980", "1960 and 1980"], "shots": {"0": {"k": 0, "answer": "1980", "latency_ms": 1471.344232559204, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1960, 1980", "latency_ms": 2372.5335597991943, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "1960, 1980", "latency_ms": 2948.1937885284424, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "1960, 1980", "latency_ms": 3321.305274963379, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1879}, "4": {"k": 4, "answer": "1960, 1980", "latency_ms": 3462.721347808838, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "1960, 1980", "latency_ms": 4114.607810974121, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3164}, "6": {"k": 6, "answer": "1960, 1980", "latency_ms": 2812.192678451538, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3826}}}
{"qid": "3916394566028297311", "question": "who wrote it's a long long way to pasadena", "gold_answers": ["Harry Vanda", "John Young", "David Hemmings", "George Young"], "shots": {"0": {"k": 0, "answer": "Albert E. Brumley", "latency_ms": 3153.141736984253, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2083.7528705596924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3003.085136413574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2675.5964756011963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1942.4033164978027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2963.287830352783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2220.2324867248535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3836}}}
{"qid": "-2432292250757146771", "question": "who wrote the song i hate you i love you", "gold_answers": ["Angel Benitez", "Olivia O'Brien", "Garrett Nash"], "shots": {"0": {"k": 0, "answer": "Gnash", "latency_ms": 1392.8213119506836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gnash and Olivia O'Brien", "latency_ms": 4499.306201934814, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 572}, "2": {"k": 2, "answer": "Gnash", "latency_ms": 1859.914779663086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1172}, "3": {"k": 3, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3676.2263774871826, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1747}, "4": {"k": 4, "answer": "JB", "latency_ms": 1464.1408920288086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2389}, "5": {"k": 5, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3554.7714233398438, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3030}, "6": {"k": 6, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3480.7913303375244, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3632}}}
{"qid": "2393389448844632496", "question": "what is loihi and where does it originate from", "gold_answers": ["from the Hawaii hotspot"], "shots": {"0": {"k": 0, "answer": "Loihi, Hawaii", "latency_ms": 2746.4587688446045, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Intel's self-learning neuromorphic chip, named after the Hawaiian seamount Loihi", "latency_ms": 7138.861179351807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 723}, "2": {"k": 2, "answer": "Hawaiian seamount Loihi", "latency_ms": 4044.6534156799316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1392}, "3": {"k": 3, "answer": "Hawaiian seamount Loihi", "latency_ms": 3709.7673416137695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2072}, "4": {"k": 4, "answer": "Hawaiian seamount Loihi", "latency_ms": 3488.6903762817383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2745}, "5": {"k": 5, "answer": "Hawaiian seamount", "latency_ms": 2827.2900581359863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3405}, "6": {"k": 6, "answer": "Hawaiian seamount Loihi", "latency_ms": 3426.0523319244385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4083}}}
{"qid": "-6677440871585683891", "question": "who rebuilt the temple after the babylonian captivity", "gold_answers": ["Herod"], "shots": {"0": {"k": 0, "answer": "Zerubbabel", "latency_ms": 1518.9757347106934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the Priest", "latency_ms": 1711.4324569702148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "The Priest", "latency_ms": 2261.6629600524902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "The Priest", "latency_ms": 997.2212314605713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1910}, "4": {"k": 4, "answer": "the Priest", "latency_ms": 1723.9487171173096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "Nebuchadnezzar", "latency_ms": 3854.0029525756836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3159}, "6": {"k": 6, "answer": "Nebuchadnezzar", "latency_ms": 3653.1524658203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3829}}}
{"qid": "-6750750235985613277", "question": "who was executed for being an american spy during the revolutionary war", "gold_answers": ["Nathan Hale"], "shots": {"0": {"k": 0, "answer": "Nathan Hale", "latency_ms": 1860.759973526001, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nathan Hale", "latency_ms": 2153.944492340088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 593}, "2": {"k": 2, "answer": "Nathan Hale", "latency_ms": 1567.6851272583008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Nathan Hale", "latency_ms": 2375.126361846924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1856}, "4": {"k": 4, "answer": "Nathan Hale", "latency_ms": 1585.8933925628662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Nathan Hale", "latency_ms": 1893.3706283569336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Nathan Hale", "latency_ms": 2367.28835105896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3826}}}
{"qid": "8770209312170080158", "question": "who sang the song suddenly with olivia newton john", "gold_answers": ["Cliff Richard"], "shots": {"0": {"k": 0, "answer": "Cliff Richard", "latency_ms": 1983.0379486083984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cliff Richard", "latency_ms": 1585.5965614318848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "Cliff Richard", "latency_ms": 1350.231647491455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1270}, "3": {"k": 3, "answer": "Cliff Richard", "latency_ms": 1829.3845653533936, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Cliff Richard", "latency_ms": 2156.4998626708984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2499}, "5": {"k": 5, "answer": "Cliff Richard", "latency_ms": 1807.6043128967285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3193}, "6": {"k": 6, "answer": "Cliff Richard", "latency_ms": 2132.0252418518066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3930}}}
{"qid": "-180549795106449014", "question": "who is command sergeant major of the army", "gold_answers": ["Daniel A. Dailey"], "shots": {"0": {"k": 0, "answer": "Michael A. Grinston", "latency_ms": 3010.148763656616, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sergeant Major of the Army", "latency_ms": 3004.049062728882, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1579.3426036834717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Daniel A. Dailey", "latency_ms": 1638.1988525390625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1832}, "4": {"k": 4, "answer": "Daniel A. Dailey", "latency_ms": 2183.0825805664062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2469}, "5": {"k": 5, "answer": "Daniel A. Dailey", "latency_ms": 2176.654815673828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3037}, "6": {"k": 6, "answer": "Daniel A. Dailey", "latency_ms": 1994.516372680664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3728}}}
{"qid": "7815138213728640354", "question": "who sings the original windmills of your mind", "gold_answers": ["Noel Harrison"], "shots": {"0": {"k": 0, "answer": "Noel Harrison", "latency_ms": 1385.9310150146484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noel Harrison", "latency_ms": 2039.2088890075684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 603}, "2": {"k": 2, "answer": "No singer mentioned", "latency_ms": 2091.0301208496094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "No singer mentioned", "latency_ms": 1842.986822128296, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Noel Harrison", "latency_ms": 1615.4463291168213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2554}, "5": {"k": 5, "answer": "Noel Harrison", "latency_ms": 1311.490774154663, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3143}, "6": {"k": 6, "answer": "Noel Harrison", "latency_ms": 1875.7340908050537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3749}}}
{"qid": "2098168902147822379", "question": "where will the next summer and winter olympics be held", "gold_answers": ["Beijing", "Tokyo"], "shots": {"0": {"k": 0, "answer": "Paris 2024 and Milan-Cortina 2026.", "latency_ms": 5246.789216995239, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Beijing", "latency_ms": 723.7927913665771, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 623}, "2": {"k": 2, "answer": "Beijing", "latency_ms": 1884.2647075653076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Tokyo, Beijing", "latency_ms": 2257.3845386505127, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1887}, "4": {"k": 4, "answer": "Tokyo, Beijing", "latency_ms": 3125.7829666137695, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2485}, "5": {"k": 5, "answer": "Tokyo and Beijing", "latency_ms": 2667.6225662231445, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3087}, "6": {"k": 6, "answer": "Tokyo, Beijing", "latency_ms": 3245.8877563476562, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3726}}}
{"qid": "-1458476052377668874", "question": "when did ole miss beat alabama in football", "gold_answers": ["September 19 , 2015", "October 3 , 1970", "October 27 , 1894", "October 13 , 2001", "October 5 , 1968", "October 4 , 2014", "September 11 , 1976", "October 8 , 1988", "October 18 , 2003", "November 5 , 1910"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 1827.4712562561035, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 1510.4920864105225, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "1988, 2014", "latency_ms": 3300.1465797424316, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "1988, 2014", "latency_ms": 3279.07657623291, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "1988, 2014", "latency_ms": 3744.594097137451, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2495}, "5": {"k": 5, "answer": "1988, 2014, 2015", "latency_ms": 4170.005321502686, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3108}, "6": {"k": 6, "answer": "1988, 2014, 2015", "latency_ms": 4574.929475784302, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-6861734002351236912", "question": "who sang the song how far is heaven", "gold_answers": ["Los Lonely Boys"], "shots": {"0": {"k": 0, "answer": "Nitty Gritty Dirt Band", "latency_ms": 3984.633445739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Moore", "latency_ms": 2035.5265140533447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Justin Moore", "latency_ms": 1781.6593647003174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1200}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2679.938316345215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2719.82479095459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2398}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3010.2431774139404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2987}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1910.2449417114258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3604}}}
{"qid": "-1722216190521937227", "question": "where are the organ mountains in new mexico", "gold_answers": ["southern New Mexico"], "shots": {"0": {"k": 0, "answer": "Las Cruces", "latency_ms": 2805.112361907959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "southern New Mexico", "latency_ms": 2347.7745056152344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "southern New Mexico", "latency_ms": 3022.423505783081, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "southern New Mexico", "latency_ms": 2559.1118335723877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1986}, "4": {"k": 4, "answer": "southern New Mexico", "latency_ms": 1657.5064659118652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2626}, "5": {"k": 5, "answer": "southern New Mexico", "latency_ms": 2609.004020690918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "southern New Mexico", "latency_ms": 2715.416669845581, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3900}}}
{"qid": "-2717119588239727064", "question": "where are the 10 plagues found in the bible", "gold_answers": ["Book of Exodus", "Exodus"], "shots": {"0": {"k": 0, "answer": "Exodus 7-12", "latency_ms": 3043.5028076171875, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2555.9093952178955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 570}, "2": {"k": 2, "answer": "the Hebrew Bible", "latency_ms": 2249.9523162841797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "the Book of Exodus", "latency_ms": 2367.2947883605957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Hebrew Bible", "latency_ms": 1661.21244430542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "Hebrew Bible", "latency_ms": 1862.9655838012695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3135}, "6": {"k": 6, "answer": "Hebrew Bible", "latency_ms": 2253.6518573760986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3729}}}
{"qid": "2988284357714596500", "question": "where are red blood cells made in adults", "gold_answers": ["in the bone marrow"], "shots": {"0": {"k": 0, "answer": "Bone marrow", "latency_ms": 1174.1600036621094, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "bone marrow", "latency_ms": 1970.9088802337646, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "bone marrow", "latency_ms": 1569.145917892456, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "the larger bones", "latency_ms": 2623.0669021606445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1911}, "4": {"k": 4, "answer": "the larger bones", "latency_ms": 2087.069034576416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "the larger bones", "latency_ms": 1643.6927318572998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "the larger bones", "latency_ms": 1803.1363487243652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3803}}}
{"qid": "-4616596799374362422", "question": "who was the pinkerton detective agency's first female detective", "gold_answers": ["Kate Warne"], "shots": {"0": {"k": 0, "answer": "Kate Warne", "latency_ms": 1392.0056819915771, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kate Warne", "latency_ms": 1605.8251857757568, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 681}, "2": {"k": 2, "answer": "Kate Warne", "latency_ms": 2397.5255489349365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Kate Warne", "latency_ms": 2148.182153701782, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Kate Warne", "latency_ms": 2259.561777114868, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Kate Warne", "latency_ms": 2448.566675186157, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Kate Warne", "latency_ms": 1550.0056743621826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3841}}}
{"qid": "-3650291155113659146", "question": "how many episodes are there in modern family", "gold_answers": ["232", "201"], "shots": {"0": {"k": 0, "answer": "250 episodes", "latency_ms": 934.1187477111816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "24", "latency_ms": 991.0531044006348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "24 episodes", "latency_ms": 1822.2384452819824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "24 episodes", "latency_ms": 1776.3421535491943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1890.2347087860107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2591}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1405.0076007843018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3229}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2441.394805908203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3881}}}
{"qid": "3381924381590631417", "question": "who built the first temple for god in jerusalem", "gold_answers": ["Solomon"], "shots": {"0": {"k": 0, "answer": "King Solomon", "latency_ms": 1035.0286960601807, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "King Solomon", "latency_ms": 2247.849702835083, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "King Solomon", "latency_ms": 1517.4481868743896, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1278}, "3": {"k": 3, "answer": "King Solomon", "latency_ms": 1257.4665546417236, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1900}, "4": {"k": 4, "answer": "King Solomon", "latency_ms": 1512.06636428833, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "King Solomon", "latency_ms": 1490.548849105835, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3266}, "6": {"k": 6, "answer": "King Solomon", "latency_ms": 511.51108741760254, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3905}}}
{"qid": "-154783694579651082", "question": "what is a dropped pin on google maps for", "gold_answers": ["marks locations", "marks locations in Google Maps"], "shots": {"0": {"k": 0, "answer": "Saving a location", "latency_ms": 2218.2180881500244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "marking locations", "latency_ms": 1512.0596885681152, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "to mark a point on a map", "latency_ms": 3101.3221740722656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "to mark a point on a map", "latency_ms": 3269.324779510498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "to mark a point on a map", "latency_ms": 2162.1921062469482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "to mark a point on a map", "latency_ms": 3085.40678024292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3039}, "6": {"k": 6, "answer": "to mark a point on a map", "latency_ms": 3062.0946884155273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3676}}}
{"qid": "6915606477668963399", "question": "what do the 3 dots mean in math", "gold_answers": ["the therefore sign", "therefore sign"], "shots": {"0": {"k": 0, "answer": "Ellipsis", "latency_ms": 968.9886569976807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2241.934061050415, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Therefore", "latency_ms": 1723.520278930664, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Therefore", "latency_ms": 1443.570613861084, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "Therefore sign", "latency_ms": 1047.2631454467773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2573}, "5": {"k": 5, "answer": "Therefore sign", "latency_ms": 1074.1615295410156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3289}, "6": {"k": 6, "answer": "Therefore sign", "latency_ms": 2054.370164871216, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3895}}}
{"qid": "-8366545547296627039", "question": "who wrote the song photograph by ringo starr", "gold_answers": ["Richard Starkey", "George Harrison", "Ringo Starr"], "shots": {"0": {"k": 0, "answer": "Ringo Starr and George Harrison", "latency_ms": 2005.1639080047607, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ringo Starr and George Harrison", "latency_ms": 3815.3622150421143, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Ringo Starr and George Harrison", "latency_ms": 2674.144983291626, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Ringo Starr and George Harrison", "latency_ms": 2347.7225303649902, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1985}, "4": {"k": 4, "answer": "Ringo Starr and George Harrison", "latency_ms": 2176.3861179351807, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2640}, "5": {"k": 5, "answer": "Ringo Starr and George Harrison", "latency_ms": 2725.1062393188477, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3284}, "6": {"k": 6, "answer": "Ringo Starr and George Harrison", "latency_ms": 2025.118350982666, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3979}}}
{"qid": "-5004457603684974952", "question": "who is playing the halftime show at super bowl 2016", "gold_answers": ["Beyoncé", "Coldplay", "Bruno Mars"], "shots": {"0": {"k": 0, "answer": "Coldplay", "latency_ms": 1791.3343906402588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 2649.8849391937256, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "Coldplay, Beyoncé, and Bruno Mars.", "latency_ms": 3878.378391265869, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Coldplay", "latency_ms": 1300.5225658416748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Coldplay, Beyoncé, and Bruno Mars", "latency_ms": 3562.553882598877, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Coldplay, Beyoncé, and Bruno Mars", "latency_ms": 4784.672498703003, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3246}, "6": {"k": 6, "answer": "Coldplay, Beyoncé, and Bruno Mars.", "latency_ms": 4602.356433868408, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3890}}}
{"qid": "7420920477821898435", "question": "to aru kagaku no railgun s episode 3", "gold_answers": ["Project Radio Noise"], "shots": {"0": {"k": 0, "answer": "Episode 3", "latency_ms": 1843.3468341827393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1643.4171199798584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2358.633518218994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2675.480365753174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1887}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2172.764539718628, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2557}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2378.002166748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1934.9064826965332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3839}}}
{"qid": "7478795216476346339", "question": "who won the 2017 sports personality of the year", "gold_answers": ["Mo Farah"], "shots": {"0": {"k": 0, "answer": "Mo Farah", "latency_ms": 1979.752779006958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2193.141460418701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2457.2904109954834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Mo Farah", "latency_ms": 2414.389133453369, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1933}, "4": {"k": 4, "answer": "Mo Farah", "latency_ms": 1686.126708984375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2556}, "5": {"k": 5, "answer": "Mo Farah", "latency_ms": 1853.6183834075928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Mo Farah", "latency_ms": 1032.8731536865234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3875}}}
{"qid": "7217222058435937287", "question": "where was the world economic forum held this year", "gold_answers": ["Davos"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2019.899606704712, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2651.582717895508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 669}, "2": {"k": 2, "answer": "Davos", "latency_ms": 2103.86061668396, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1342}, "3": {"k": 3, "answer": "Davos-Klosters", "latency_ms": 2830.230474472046, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2033}, "4": {"k": 4, "answer": "Davos-Klosters", "latency_ms": 3539.7095680236816, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2697}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2123.1982707977295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3352}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1954.9665451049805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4023}}}
{"qid": "-143054837169120955", "question": "where are the giant redwoods located in california", "gold_answers": ["the coast of northern California", "Del Norte County", "Humboldt County"], "shots": {"0": {"k": 0, "answer": "Northern California", "latency_ms": 1501.9288063049316, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 5883.9380741119385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 5430.154085159302, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 4078.5751342773438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 4617.433786392212, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2536}, "5": {"k": 5, "answer": "Sierra Nevada", "latency_ms": 1938.3223056793213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3257}, "6": {"k": 6, "answer": "Sierra Nevada", "latency_ms": 2137.4568939208984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3865}}}
{"qid": "4892429640540595424", "question": "who has made the most premier league appearances", "gold_answers": ["Gareth Barry"], "shots": {"0": {"k": 0, "answer": "Gareth Barry", "latency_ms": 1886.2338066101074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gareth Barry", "latency_ms": 2842.5278663635254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Gareth Barry", "latency_ms": 1578.221082687378, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Gareth Barry", "latency_ms": 2149.3046283721924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Gareth Barry", "latency_ms": 1875.2450942993164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2517}, "5": {"k": 5, "answer": "Gareth Barry", "latency_ms": 1797.4638938903809, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Gareth Barry", "latency_ms": 1850.318193435669, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3715}}}
{"qid": "5533906981191706877", "question": "who was the first chief minister of west bengal", "gold_answers": ["Prafulla Chandra Ghosh"], "shots": {"0": {"k": 0, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3961.5750312805176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3482.501983642578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3457.042455673218, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1408}, "3": {"k": 3, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3161.266565322876, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2068}, "4": {"k": 4, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3758.8047981262207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2797}, "5": {"k": 5, "answer": "Prafulla Chandra Ghosh", "latency_ms": 4299.487113952637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3451}, "6": {"k": 6, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3293.6201095581055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4053}}}
{"qid": "8823076125131408628", "question": "who sings got my mind set on you", "gold_answers": ["George Harrison", "James Ray"], "shots": {"0": {"k": 0, "answer": "George Harrison", "latency_ms": 505.14769554138184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2433.3879947662354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "James Ray, George Harrison", "latency_ms": 3264.9192810058594, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1128}, "3": {"k": 3, "answer": "James Ray", "latency_ms": 1199.793815612793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1700}, "4": {"k": 4, "answer": "James Ray", "latency_ms": 1789.1185283660889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2312}, "5": {"k": 5, "answer": "James Ray", "latency_ms": 1329.606533050537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2928}, "6": {"k": 6, "answer": "James Ray", "latency_ms": 1465.5075073242188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3462}}}
{"qid": "9168660859139861094", "question": "two main types of research methods used in psychology", "gold_answers": ["Correlational research", "Descriptive research", "quantitative data", "Quantitative psychological research", "qualitative", "quantitative", "Qualitative psychological research", "Experimental research", "qualitative data"], "shots": {"0": {"k": 0, "answer": "Qualitative and Quantitative.", "latency_ms": 2806.4212799072266, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Qualitative or quantitative", "latency_ms": 1843.3046340942383, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 745}, "2": {"k": 2, "answer": "Qualitative or quantitative", "latency_ms": 2128.3700466156006, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1482}, "3": {"k": 3, "answer": "Qualitative or quantitative", "latency_ms": 2406.740427017212, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2291}, "4": {"k": 4, "answer": "Qualitative or quantitative", "latency_ms": 2393.5530185699463, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3033}, "5": {"k": 5, "answer": "Qualitative or quantitative", "latency_ms": 1747.3304271697998, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3717}, "6": {"k": 6, "answer": "Qualitative or quantitative", "latency_ms": 2608.832359313965, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4414}}}
{"qid": "-7073063191952855764", "question": "who plays peter in what we do in the shadows", "gold_answers": ["Ben Fransham"], "shots": {"0": {"k": 0, "answer": "Mark Proksch", "latency_ms": 1952.6305198669434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1618.351936340332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2000.8728504180908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2679.2774200439453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2384.24015045166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2517}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2151.4697074890137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3150}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3720.581293106079, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7901746249864619718", "question": "when does the 14th season of grey's anatomy come out", "gold_answers": ["September 28 , 2017"], "shots": {"0": {"k": 0, "answer": "September 28, 2017", "latency_ms": 3215.258836746216, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 28, 2017", "latency_ms": 3437.5476837158203, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 28, 2017", "latency_ms": 4661.400079727173, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "September 28, 2017", "latency_ms": 3731.3647270202637, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 28, 2017", "latency_ms": 3374.361038208008, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2721}, "5": {"k": 5, "answer": "September 28, 2017", "latency_ms": 2619.3602085113525, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3389}, "6": {"k": 6, "answer": "September 28, 2017", "latency_ms": 3898.10848236084, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4057}}}
{"qid": "-896127746191949637", "question": "when was the first hunger games book published", "gold_answers": ["September 14 , 2008", "2008"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 1494.7092533111572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 14, 2008", "latency_ms": 3544.5423126220703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "September 14, 2008", "latency_ms": 3398.8564014434814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "September 14, 2008", "latency_ms": 3007.9758167266846, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1939}, "4": {"k": 4, "answer": "September 14, 2008", "latency_ms": 3639.8887634277344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2601}, "5": {"k": 5, "answer": "September 14, 2008", "latency_ms": 3619.460105895996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3261}, "6": {"k": 6, "answer": "September 14, 2008", "latency_ms": 2699.244499206543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "8044909700499569711", "question": "how much is the united states in debt to china", "gold_answers": ["$1.06 trillion", "1,200.5"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2148.84614944458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "21 percent", "latency_ms": 946.3403224945068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "$1.08 trillion", "latency_ms": 1996.9372749328613, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "21 percent", "latency_ms": 2186.8205070495605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "$1.16 trillion", "latency_ms": 1969.4833755493164, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "$1.16 trillion", "latency_ms": 3005.829095840454, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3214}, "6": {"k": 6, "answer": "$1.16 trillion", "latency_ms": 2487.452268600464, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3834}}}
{"qid": "-3123234845590594961", "question": "where did the race in grease take place", "gold_answers": ["Thunder Road"], "shots": {"0": {"k": 0, "answer": "The Thunder Road Race", "latency_ms": 1876.1694431304932, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles River", "latency_ms": 2652.728319168091, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Los Angeles River", "latency_ms": 1817.7855014801025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1166}, "3": {"k": 3, "answer": "Los Angeles River", "latency_ms": 821.1925029754639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1794}, "4": {"k": 4, "answer": "Los Angeles River", "latency_ms": 2524.51491355896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Los Angeles River", "latency_ms": 2014.8680210113525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Los Angeles River", "latency_ms": 1774.338722229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3762}}}
{"qid": "4326992806019599297", "question": "what is the maximum data rate for the 802.11a standard select one", "gold_answers": ["54 Mbit / s"], "shots": {"0": {"k": 0, "answer": "54 Mbps", "latency_ms": 1291.19873046875, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "54 Mbit/s", "latency_ms": 2405.4999351501465, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "54 Mbit/s", "latency_ms": 2424.6206283569336, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "54 Mbit/s", "latency_ms": 2670.7918643951416, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1997}, "4": {"k": 4, "answer": "54 Mbit/s", "latency_ms": 1684.3957901000977, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "54 Mbit/s", "latency_ms": 2377.094030380249, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3293}, "6": {"k": 6, "answer": "54 Mbit/s", "latency_ms": 2187.3085498809814, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3955}}}
{"qid": "6144099837933283715", "question": "a good that can be used in place of another good", "gold_answers": ["A substitute good", "substitute good"], "shots": {"0": {"k": 0, "answer": "Substitute", "latency_ms": 1306.7381381988525, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Substitute", "latency_ms": 1664.9153232574463, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Pickling salt", "latency_ms": 2694.7906017303467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1217}, "3": {"k": 3, "answer": "Pickling salt", "latency_ms": 2152.231216430664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "Pickling salt", "latency_ms": 1859.771490097046, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "Pickling salt", "latency_ms": 2400.491714477539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2944}, "6": {"k": 6, "answer": "Pickling salt", "latency_ms": 1790.9245491027832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3511}}}
{"qid": "-4621948696356225060", "question": "where in the bible can i find the lord's prayer", "gold_answers": ["the Gospel of Luke", "the Gospel of Matthew"], "shots": {"0": {"k": 0, "answer": "Matthew 6:9-13, Luke 11:2-4", "latency_ms": 6280.375003814697, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2926.5072345733643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 562}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1916.3269996643066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2171.821117401123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "Matthew 6:13", "latency_ms": 2654.893636703491, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2398}, "5": {"k": 5, "answer": "Matthew 6:13", "latency_ms": 2212.2297286987305, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3093}, "6": {"k": 6, "answer": "Matthew 6:9-13", "latency_ms": 3287.2958183288574, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3639}}}
{"qid": "6941993254369956277", "question": "when was the last time nebraska voted democrat", "gold_answers": ["1964"], "shots": {"0": {"k": 0, "answer": "1964", "latency_ms": 1879.9996376037598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Before 1860", "latency_ms": 2387.448310852051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "1908", "latency_ms": 1294.8596477508545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "1964", "latency_ms": 2260.934829711914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2024}, "4": {"k": 4, "answer": "1964", "latency_ms": 1009.8865032196045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2709}, "5": {"k": 5, "answer": "1964", "latency_ms": 2033.010721206665, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3411}, "6": {"k": 6, "answer": "1964", "latency_ms": 2289.5467281341553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4080}}}
{"qid": "-8955197065025093046", "question": "who become the ceo of it wipro company in 2016", "gold_answers": ["Abid Ali Neemuchwala"], "shots": {"0": {"k": 0, "answer": "Abidali Neemuchwala", "latency_ms": 3009.326696395874, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Abidali Neemuchwala", "latency_ms": 4763.236999511719, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Abidali Neemuchwala", "latency_ms": 3680.4983615875244, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Abidali Neemuchwala", "latency_ms": 5328.649520874023, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1991}, "4": {"k": 4, "answer": "Abidali Neemuchwala", "latency_ms": 4350.444555282593, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2675}, "5": {"k": 5, "answer": "Abidali Neemuchwala", "latency_ms": 3703.3448219299316, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3341}, "6": {"k": 6, "answer": "Abidali Neemuchwala", "latency_ms": 3869.105100631714, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3948}}}
{"qid": "-3010425579521817304", "question": "who does eric end up with in gossip girl", "gold_answers": ["Jenny"], "shots": {"0": {"k": 0, "answer": "Vanessa, then Serena, then no one, then Serena", "latency_ms": 5334.841728210449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2680.412769317627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2232.8197956085205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1227}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2759.195327758789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1833}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2166.0022735595703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2457}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2415.830373764038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3080}, "6": {"k": 6, "answer": "Jenny", "latency_ms": 1447.683572769165, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3665}}}
{"qid": "7264112453286983469", "question": "who plays unis in she's the man", "gold_answers": ["Emily Perkins"], "shots": {"0": {"k": 0, "answer": "Amanda Bynes", "latency_ms": 2975.335121154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amanda Bynes", "latency_ms": 1630.0995349884033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1691.3132667541504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Viola Hastings", "latency_ms": 2665.935754776001, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Amanda Bynes", "latency_ms": 2408.695697784424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2506}, "5": {"k": 5, "answer": "Amanda Bynes", "latency_ms": 1909.1861248016357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3094}, "6": {"k": 6, "answer": "Amanda Bynes", "latency_ms": 2474.9178886413574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3702}}}
{"qid": "2627695648792729859", "question": "who played booster in jingle all the way", "gold_answers": ["Curtis Armstrong"], "shots": {"0": {"k": 0, "answer": "Eric Lloyd", "latency_ms": 1582.8657150268555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2953.798770904541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2471.726179122925, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1342}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2174.604654312134, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2010}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2572.399616241455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2236.37318611145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3297}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1860.3346347808838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3986}}}
{"qid": "-9169976182548289414", "question": "who is recognized as the founder of islam", "gold_answers": ["the Islamic prophet Muhammad", "Muhammad"], "shots": {"0": {"k": 0, "answer": "Muhammad", "latency_ms": 1597.4771976470947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Muhammad", "latency_ms": 1697.0272064208984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 636}, "2": {"k": 2, "answer": "Muhammad", "latency_ms": 1253.654956817627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Muhammad", "latency_ms": 2026.7753601074219, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Muhammad", "latency_ms": 2254.2543411254883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2475}, "5": {"k": 5, "answer": "Muhammad", "latency_ms": 1542.079210281372, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Muhammad", "latency_ms": 2075.9687423706055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3739}}}
{"qid": "-6696747560626271522", "question": "who plays emma in air bud world pup", "gold_answers": ["Brittany Paige Bouck"], "shots": {"0": {"k": 0, "answer": "Brittany Paige Bouck", "latency_ms": 2290.043592453003, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Brittany Paige Bouck", "latency_ms": 2596.0159301757812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 592}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2334.634304046631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2307.701587677002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2097.352981567383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2652.714252471924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3077}, "6": {"k": 6, "answer": "Brittany Paige Bouck", "latency_ms": 3013.080835342407, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3715}}}
{"qid": "5871681964137793716", "question": "how old was sasuke when his clan died", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "7 years old", "latency_ms": 1936.3105297088623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seven", "latency_ms": 1182.1115016937256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Seven", "latency_ms": 1830.6081295013428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Seven", "latency_ms": 967.6895141601562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Seven", "latency_ms": 978.426456451416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Seven", "latency_ms": 1800.5115985870361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3149}, "6": {"k": 6, "answer": "Seven", "latency_ms": 1233.6981296539307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3751}}}
{"qid": "8552176802923865025", "question": "where do some of the natural air pollutants come from", "gold_answers": ["wildfires", "Dust", "Vegetation", "Carbon dioxide", "Volcanic activity"], "shots": {"0": {"k": 0, "answer": "Volcanic eruptions", "latency_ms": 2680.560827255249, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2640.946865081787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 718}, "2": {"k": 2, "answer": "Volcanic eruption", "latency_ms": 2310.6346130371094, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "forest fires, volcanic eruptions", "latency_ms": 3602.6487350463867, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2128}, "4": {"k": 4, "answer": "Volcanic eruptions, forest fires, wind erosion, pollen dispersal.", "latency_ms": 6749.65763092041, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2745}, "5": {"k": 5, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity", "latency_ms": 9848.160028457642, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 3349}, "6": {"k": 6, "answer": "Volcanic eruptions, forest fires, wind erosion, pollen dispersal.", "latency_ms": 6291.501045227051, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 4025}}}
{"qid": "-2630525064809360052", "question": "who is the pastor of new birth missionary baptist church now", "gold_answers": ["Stephen A. Davis"], "shots": {"0": {"k": 0, "answer": "Jamal Harrison Bryant", "latency_ms": 1785.0732803344727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pastor Bryant", "latency_ms": 1875.1904964447021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "Pastor Bryant", "latency_ms": 1605.5779457092285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "Jamal Bryant", "latency_ms": 1810.821771621704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2018}, "4": {"k": 4, "answer": "Jamal Bryant", "latency_ms": 2648.0116844177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2655}, "5": {"k": 5, "answer": "Jamal Bryant", "latency_ms": 2142.343282699585, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3286}, "6": {"k": 6, "answer": "Jamal Bryant", "latency_ms": 2173.6886501312256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3922}}}
{"qid": "6434931911289860123", "question": "who is doing 2018 super bowl half time show", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "Justin Timberlake", "latency_ms": 1075.275182723999, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Timberlake", "latency_ms": 2169.318437576294, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "Justin Timberlake", "latency_ms": 1848.888874053955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Justin Timberlake", "latency_ms": 2175.96697807312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Justin Timberlake", "latency_ms": 1603.6806106567383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2524}, "5": {"k": 5, "answer": "Justin Timberlake", "latency_ms": 2629.646062850952, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3212}, "6": {"k": 6, "answer": "Justin Timberlake", "latency_ms": 1924.5941638946533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3886}}}
{"qid": "8869318258439148973", "question": "who is playing the halftime show for the superbowl", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2227.8122901916504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 3118.6304092407227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "Coldplay, Beyoncé and Bruno Mars.", "latency_ms": 3535.214424133301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Coldplay, Beyoncé, and Bruno Mars.", "latency_ms": 5072.8113651275635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "Coldplay, Beyoncé, and Bruno Mars", "latency_ms": 2543.240547180176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2563}, "5": {"k": 5, "answer": "Maroon 5", "latency_ms": 1953.488826751709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "Coldplay, Beyoncé, and Bruno Mars", "latency_ms": 3942.7883625030518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3856}}}
{"qid": "-8359866474144720253", "question": "who hosted they think it's all over", "gold_answers": ["Des Lynam", "Lee Mack", "comedian Nick Hancock", "Nick Hancock"], "shots": {"0": {"k": 0, "answer": "Nick Hancock", "latency_ms": 1010.0226402282715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2412.673234939575, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1868.9234256744385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2441.7288303375244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Nick Hancock", "latency_ms": 2083.372116088867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2505}, "5": {"k": 5, "answer": "Nick Hancock", "latency_ms": 1033.0803394317627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3161}, "6": {"k": 6, "answer": "Nick Hancock", "latency_ms": 1382.091760635376, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3768}}}
{"qid": "-1206653570097564556", "question": "where does the movie proof of life take place", "gold_answers": ["The Republic of Tecala"], "shots": {"0": {"k": 0, "answer": "South America", "latency_ms": 760.2334022521973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Republic of Tecala", "latency_ms": 3238.197088241577, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "The Republic of Tecala", "latency_ms": 3461.8613719940186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1268}, "3": {"k": 3, "answer": "The Republic of Tecala", "latency_ms": 3053.966999053955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1866}, "4": {"k": 4, "answer": "The Republic of Tecala", "latency_ms": 1760.7049942016602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2466}, "5": {"k": 5, "answer": "The Republic of Tecala", "latency_ms": 2717.9806232452393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3133}, "6": {"k": 6, "answer": "The Republic of Tecala, a fictional South American country.", "latency_ms": 5519.3634033203125, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3789}}}
{"qid": "6144521615402262404", "question": "where does us highway 1 start and end", "gold_answers": ["Fort Kent , Maine", "to Key West , Florida", "Key West , Florida"], "shots": {"0": {"k": 0, "answer": "Fort Kent, Maine to Key West, Florida", "latency_ms": 4061.5487098693848, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2440.5834674835205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2726.438283920288, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1463.3352756500244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1599.4477272033691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2391.3214206695557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3106}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2080.754041671753, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3699}}}
{"qid": "-8631190913794477985", "question": "who scored the most points in a single game in the nba", "gold_answers": ["Wilt Chamberlain"], "shots": {"0": {"k": 0, "answer": "Wilt Chamberlain", "latency_ms": 1706.1100006103516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2657.7370166778564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "Wilt Chamberlain", "latency_ms": 2173.495054244995, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Wilt Chamberlain", "latency_ms": 2523.723840713501, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1850}, "4": {"k": 4, "answer": "Wilt Chamberlain", "latency_ms": 1477.0238399505615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2460}, "5": {"k": 5, "answer": "Wilt Chamberlain", "latency_ms": 2404.749870300293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3106}, "6": {"k": 6, "answer": "Wilt Chamberlain", "latency_ms": 2167.012929916382, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3688}}}
{"qid": "199896377614951764", "question": "where is natural gas found in the us", "gold_answers": ["Texas", "Pennsylvania", "Colorado", "New Mexico", "West Virginia", "Arkansas", "Wyoming", "Louisiana"], "shots": {"0": {"k": 0, "answer": "Texas, Oklahoma, Louisiana, and Alaska", "latency_ms": 3444.9453353881836, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shale formations", "latency_ms": 2118.0057525634766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Shale formations", "latency_ms": 2120.2304363250732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Louisiana, Texas, California, Alaska, shale formations", "latency_ms": 5323.266983032227, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1825}, "4": {"k": 4, "answer": "Louisiana, Texas, California, Alaska", "latency_ms": 4648.704290390015, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2501}, "5": {"k": 5, "answer": "Louisiana, Texas, California, Alaska", "latency_ms": 3476.1202335357666, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Louisiana, Texas, California, Alaska", "latency_ms": 2869.511842727661, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3860}}}
{"qid": "8986775680996674901", "question": "when were the first general elections held in independent india", "gold_answers": ["1951 -- 52"], "shots": {"0": {"k": 0, "answer": "1951", "latency_ms": 1005.2917003631592, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "25 October 1951 – 27 March 1952", "latency_ms": 6007.725715637207, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "25 October 1951 and 27 March 1952", "latency_ms": 4896.108388900757, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "25 October 1951 and 27 March 1952", "latency_ms": 4454.666376113892, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1974}, "4": {"k": 4, "answer": "1951", "latency_ms": 2056.7221641540527, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2639}, "5": {"k": 5, "answer": "1951-1952", "latency_ms": 2861.9067668914795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3305}, "6": {"k": 6, "answer": "1951-1952", "latency_ms": 2743.0944442749023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3946}}}
{"qid": "700604097171850168", "question": "what was the tower of london originally used for", "gold_answers": ["as a royal residence", "a royal residence"], "shots": {"0": {"k": 0, "answer": "Royal Palace", "latency_ms": 1536.1778736114502, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "holding prisoners was incidental", "latency_ms": 2400.9859561920166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "incidental role of holding prisoners", "latency_ms": 2810.3842735290527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "incidental role of holding prisoners", "latency_ms": 3134.4704627990723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "incidental role of holding prisoners", "latency_ms": 3217.095375061035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "incidental role of holding prisoners", "latency_ms": 2497.7967739105225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3020}, "6": {"k": 6, "answer": "incidental role of holding prisoners", "latency_ms": 2952.1279335021973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3638}}}
{"qid": "6745303307988470742", "question": "what type of fuel goes in a zippo", "gold_answers": ["butane", "lighter fluid"], "shots": {"0": {"k": 0, "answer": "Lighter fluid", "latency_ms": 1876.0933876037598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 5269.87886428833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 4547.137260437012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 7000.002384185791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1830}, "4": {"k": 4, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 6866.590261459351, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2422}, "5": {"k": 5, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 5687.05677986145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3061}, "6": {"k": 6, "answer": "Light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 7080.944776535034, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3631}}}
{"qid": "-2060506905455252030", "question": "first jnanpith award was an autor of which language", "gold_answers": ["Malayalam"], "shots": {"0": {"k": 0, "answer": "Gujarati", "latency_ms": 1917.578935623169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2290.544033050537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Not mentioned", "latency_ms": 1506.3772201538086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1310}, "3": {"k": 3, "answer": "Malayalam", "latency_ms": 2140.484571456909, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Malayalam", "latency_ms": 1132.4799060821533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2644}, "5": {"k": 5, "answer": "Malayalam", "latency_ms": 2958.4922790527344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3289}, "6": {"k": 6, "answer": "Malayalam", "latency_ms": 2522.873878479004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3968}}}
{"qid": "4738663028303377024", "question": "who played the mad hatter in the batman tv show", "gold_answers": ["Roddy McDowall", "David Wayne", "Benedict Samuel"], "shots": {"0": {"k": 0, "answer": "David Wayne", "latency_ms": 1569.2825317382812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "David Wayne", "latency_ms": 2291.245460510254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "Peter MacNicol", "latency_ms": 2574.556827545166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2362.8242015838623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2612.0779514312744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2562}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2975.5172729492188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2956.8090438842773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "-1650946015201779846", "question": "how many cracker barrels in the united states", "gold_answers": ["639", "more than 600"], "shots": {"0": {"k": 0, "answer": "645 locations", "latency_ms": 1268.9204216003418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "645 stores in 44 states", "latency_ms": 3439.450979232788, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "645 stores in 44 states", "latency_ms": 2340.726852416992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "645 stores in 44 states", "latency_ms": 2813.361406326294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "645 stores in 44 states", "latency_ms": 3168.1435108184814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2581}, "5": {"k": 5, "answer": "645 stores in 44 states", "latency_ms": 2520.4243659973145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "645 stores in 44 states", "latency_ms": 4099.454402923584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3852}}}
{"qid": "-3422350952909582054", "question": "in photosynthesis the carbon in co2 is initially fixed to what molecule", "gold_answers": ["3 - phosphoglycerate"], "shots": {"0": {"k": 0, "answer": "RuBP", "latency_ms": 777.8985500335693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 5177.286624908447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 712}, "2": {"k": 2, "answer": "ribulose 1,5-bisphosphate", "latency_ms": 5183.419466018677, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1441}, "3": {"k": 3, "answer": "ribulose 1,5-bisphosphate", "latency_ms": 4400.687456130981, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2120}, "4": {"k": 4, "answer": "Ribulose 1,5-bisphosphate or phosphoenolpyruvate (PEP)", "latency_ms": 8795.801401138306, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2846}, "5": {"k": 5, "answer": "ribulose 1,5-bisphosphate", "latency_ms": 3544.5525646209717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3491}, "6": {"k": 6, "answer": "Ribulose 1,5-bisphosphate", "latency_ms": 5265.185832977295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4192}}}
{"qid": "-2704708103393811482", "question": "who voices randy in f is for family", "gold_answers": ["T.J. Miller"], "shots": {"0": {"k": 0, "answer": "Bill Burr", "latency_ms": 1505.319595336914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parker", "latency_ms": 1192.1088695526123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "Bill Burr", "latency_ms": 2107.0799827575684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Bill Burr", "latency_ms": 1841.6407108306885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1941}, "4": {"k": 4, "answer": "Bill Burr", "latency_ms": 1262.962818145752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2506}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1989.3815517425537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3159}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2256.37149810791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "5482012214308896475", "question": "how many countries does cadbury sell its products", "gold_answers": ["more than 50", "more than 50 countries worldwide"], "shots": {"0": {"k": 0, "answer": "160 countries", "latency_ms": 1102.379322052002, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "more than fifty", "latency_ms": 2339.1926288604736, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "more than fifty", "latency_ms": 2366.3558959960938, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1401}, "3": {"k": 3, "answer": "more than fifty", "latency_ms": 2046.6067790985107, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2055}, "4": {"k": 4, "answer": "more than fifty countries", "latency_ms": 2781.275987625122, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2763}, "5": {"k": 5, "answer": "more than fifty countries", "latency_ms": 1734.4133853912354, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3397}, "6": {"k": 6, "answer": "50", "latency_ms": 1012.9716396331787, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4072}}}
{"qid": "-5737509619250561344", "question": "ethiopia flight 961 crashes in to the sea", "gold_answers": ["23 November 1996"], "shots": {"0": {"k": 0, "answer": "November 23, 1996", "latency_ms": 2988.1904125213623, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indian Ocean", "latency_ms": 2093.8966274261475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Indian Ocean", "latency_ms": 1251.258373260498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "Indian Ocean", "latency_ms": 2060.8160495758057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1991}, "4": {"k": 4, "answer": "Indian Ocean", "latency_ms": 1280.4877758026123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Indian Ocean", "latency_ms": 1335.994005203247, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "Indian Ocean", "latency_ms": 2340.620279312134, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3946}}}
{"qid": "-7175456993713717070", "question": "what does istj mean in a personality test", "gold_answers": ["Extroverted Thinking ( Te )", "Extroverted Intuition ( Ne )", "Introverted Feeling ( Fi )", "Introverted Sensing ( Si )"], "shots": {"0": {"k": 0, "answer": "Introverted, Sensing, Thinking, Judging", "latency_ms": 2803.5688400268555, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4466.5281772613525, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 724}, "2": {"k": 2, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4010.5392932891846, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 3270.7180976867676, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2101}, "4": {"k": 4, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4732.583045959473, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2801}, "5": {"k": 5, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 3718.7490463256836, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3512}, "6": {"k": 6, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4272.125244140625, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4155}}}
{"qid": "4437170343606050664", "question": "who does the voice of ash in sing", "gold_answers": ["Scarlett Johansson"], "shots": {"0": {"k": 0, "answer": "Scarlett Johansson", "latency_ms": 2457.388401031494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Veronica Taylor", "latency_ms": 2840.8524990081787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "Veronica Taylor", "latency_ms": 1574.2740631103516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "Ash King", "latency_ms": 1499.8571872711182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "Ash King", "latency_ms": 1966.9866561889648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "Ash King", "latency_ms": 1712.3205661773682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "Ash King", "latency_ms": 2560.326337814331, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3751}}}
{"qid": "-8773010039077552394", "question": "who scored the most points in their nba career", "gold_answers": ["Kareem Abdul - Jabbar"], "shots": {"0": {"k": 0, "answer": "LeBron James", "latency_ms": 1277.4689197540283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2616.360902786255, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1424.0717887878418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1138}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1590.5086994171143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1734}, "4": {"k": 4, "answer": "Kareem Abdul-Jabbar", "latency_ms": 3810.18328666687, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2363}, "5": {"k": 5, "answer": "Kareem Abdul-Jabbar", "latency_ms": 3078.965902328491, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2928}, "6": {"k": 6, "answer": "Kareem Abdul-Jabbar", "latency_ms": 4970.118284225464, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3533}}}
{"qid": "-3278224144622911032", "question": "with a land area of 54 314 square miles where does wisconsin rank among the 50 states", "gold_answers": ["25"], "shots": {"0": {"k": 0, "answer": "23rd", "latency_ms": 1490.501880645752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2706.104278564453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2437.931537628174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1734.9269390106201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1780}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1644.8402404785156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2410}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2712.920904159546, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3006}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3190.8557415008545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3621}}}
{"qid": "-3466298422174960041", "question": "who plays charles on have and have nots", "gold_answers": ["Nick Sager", "Nick Sagar"], "shots": {"0": {"k": 0, "answer": "Aaron O'Connell", "latency_ms": 1869.4219589233398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3207.3326110839844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1709.5692157745361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1251}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2132.6277256011963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2999.9020099639893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2518}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2135.833501815796, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3116}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2385.150671005249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3765}}}
{"qid": "1803248910342766083", "question": "who wrote the book my country my life", "gold_answers": ["L.K. Advani"], "shots": {"0": {"k": 0, "answer": "L.K. Advani", "latency_ms": 2815.528154373169, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "L. K. Advani", "latency_ms": 2744.675874710083, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "L. K. Advani", "latency_ms": 2567.878007888794, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1158}, "3": {"k": 3, "answer": "L. K. Advani", "latency_ms": 3085.6895446777344, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "L. K. Advani", "latency_ms": 2976.8917560577393, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2408}, "5": {"k": 5, "answer": "L. K. Advani", "latency_ms": 2721.853256225586, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3048}, "6": {"k": 6, "answer": "L. K. Advani", "latency_ms": 3040.071964263916, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3686}}}
{"qid": "-1176280233636154422", "question": "when did the east india company take control of india", "gold_answers": ["1757", "1799", "1612", "in 1757"], "shots": {"0": {"k": 0, "answer": "1757", "latency_ms": 1004.3370723724365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1757", "latency_ms": 1213.7384414672852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "1757", "latency_ms": 1187.3435974121094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "1757", "latency_ms": 1765.8052444458008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "1757", "latency_ms": 1215.9171104431152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2572}, "5": {"k": 5, "answer": "1757", "latency_ms": 2256.8271160125732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3232}, "6": {"k": 6, "answer": "1757", "latency_ms": 1040.0574207305908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3902}}}
{"qid": "5911119091653953181", "question": "where does the water come from to fill lake eyre", "gold_answers": ["Warburton River"], "shots": {"0": {"k": 0, "answer": "Cooper Creek", "latency_ms": 1805.2978515625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "inland Queensland", "latency_ms": 1152.1615982055664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "semi-arid inland Queensland", "latency_ms": 1896.3539600372314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "Semi-arid inland Queensland", "latency_ms": 3593.1549072265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1825}, "4": {"k": 4, "answer": "the river systems of semi-arid inland Queensland", "latency_ms": 3541.1293506622314, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2393}, "5": {"k": 5, "answer": "the river systems of semi-arid inland Queensland", "latency_ms": 4021.541118621826, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2980}, "6": {"k": 6, "answer": "Semi-arid inland Queensland", "latency_ms": 2778.5041332244873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3579}}}
{"qid": "5557104327881436095", "question": "who is the founder of google and when was it founded", "gold_answers": ["1998", "Sergey Brin", "Larry Page and Sergey Brin", "Larry Page"], "shots": {"0": {"k": 0, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 4067.1186447143555, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2478.47580909729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Larry Page, Sergey Brin, September 4, 1998", "latency_ms": 5200.063467025757, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1320}, "3": {"k": 3, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 5312.14165687561, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 5735.726594924927, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 2637}, "5": {"k": 5, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 5481.003999710083, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 3253}, "6": {"k": 6, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 6206.296443939209, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 3877}}}
{"qid": "-1333328812971005142", "question": "who did the dominican republic gain its independence from", "gold_answers": ["Haiti"], "shots": {"0": {"k": 0, "answer": "Haiti", "latency_ms": 1589.5984172821045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haiti", "latency_ms": 1852.8132438659668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "Haiti and Spain", "latency_ms": 2950.7932662963867, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1342}, "3": {"k": 3, "answer": "Haiti and Spain", "latency_ms": 3057.161569595337, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2056}, "4": {"k": 4, "answer": "Haiti and Spain", "latency_ms": 3274.3918895721436, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2736}, "5": {"k": 5, "answer": "Haiti and Spain", "latency_ms": 1207.0913314819336, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3373}, "6": {"k": 6, "answer": "Haiti and Spain", "latency_ms": 3022.244453430176, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4100}}}
{"qid": "1122605495295045742", "question": "how did early humans make use of stones during the prehistoric period", "gold_answers": ["start fires", "hunt", "bury their dead"], "shots": {"0": {"k": 0, "answer": "Tool making", "latency_ms": 710.6626033782959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in the manufacture of implements with a sharp edge, a point, or a percussion surface.", "latency_ms": 6332.050561904907, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 5411.157608032227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 5298.465728759766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "to make implements with a sharp edge, a point, or a percussion surface.", "latency_ms": 5786.910533905029, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 5524.766683578491, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3239}, "6": {"k": 6, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 5991.735935211182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3899}}}
{"qid": "7402184777947527945", "question": "who wrote the text for jeanie with the light brown hair", "gold_answers": ["Stephen Foster"], "shots": {"0": {"k": 0, "answer": "Maud Irving or Robert Burns", "latency_ms": 2097.2070693969727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stephen Foster", "latency_ms": 1966.4788246154785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Stephen Foster", "latency_ms": 1731.9114208221436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1222}, "3": {"k": 3, "answer": "Stephen Foster", "latency_ms": 1764.0023231506348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Stephen Foster", "latency_ms": 2008.129358291626, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Stephen Foster", "latency_ms": 995.0511455535889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3133}, "6": {"k": 6, "answer": "Stephen Foster", "latency_ms": 2039.6735668182373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3752}}}
{"qid": "1656745334095178455", "question": "the basic steps of rational decision making include defining goals and", "gold_answers": ["Implementation of plans / policies"], "shots": {"0": {"k": 0, "answer": "identifying alternatives", "latency_ms": 1627.7859210968018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "problem definition", "latency_ms": 1771.1646556854248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 774}, "2": {"k": 2, "answer": "problem definition", "latency_ms": 1501.9373893737793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1428}, "3": {"k": 3, "answer": "problem definition", "latency_ms": 1017.289400100708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2061}, "4": {"k": 4, "answer": "problem definition", "latency_ms": 1772.2477912902832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2713}, "5": {"k": 5, "answer": "problem definition", "latency_ms": 1230.323314666748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3431}, "6": {"k": 6, "answer": "problem definition", "latency_ms": 1023.329496383667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4087}}}
{"qid": "-216657635823030751", "question": "when was the design period known as art deco", "gold_answers": ["1910 -- 1939"], "shots": {"0": {"k": 0, "answer": "1920s to 1940s", "latency_ms": 2403.0425548553467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "just before World War I", "latency_ms": 2749.5367527008057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "just before World War I", "latency_ms": 1702.6381492614746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1362}, "3": {"k": 3, "answer": "just before World War I", "latency_ms": 2271.301031112671, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2025}, "4": {"k": 4, "answer": "just before World War I", "latency_ms": 2807.6186180114746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "just before World War I", "latency_ms": 2433.1929683685303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3348}, "6": {"k": 6, "answer": "just before World War I", "latency_ms": 1908.3962440490723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3978}}}
{"qid": "250542332339248886", "question": "where does the bob and tom show broadcast from", "gold_answers": ["WFBQ in Indianapolis , Indiana", "Indianapolis , Indiana"], "shots": {"0": {"k": 0, "answer": "Indianapolis", "latency_ms": 1997.2529411315918, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indianapolis, Indiana", "latency_ms": 1592.2892093658447, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Indianapolis, Indiana", "latency_ms": 3099.6365547180176, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "WFBQ in Indianapolis, Indiana", "latency_ms": 3103.039264678955, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "WFBQ in Indianapolis, Indiana", "latency_ms": 2624.856472015381, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2443}, "5": {"k": 5, "answer": "WFBQ, Indianapolis, Indiana", "latency_ms": 2817.8787231445312, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3028}, "6": {"k": 6, "answer": "WFBQ, Indianapolis, Indiana", "latency_ms": 3149.179220199585, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3662}}}
{"qid": "7610758795954724809", "question": "star wars the clone wars season 3 episode 1", "gold_answers": ["Clone Cadets"], "shots": {"0": {"k": 0, "answer": "Clone Cadets", "latency_ms": 2117.7010536193848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2693.5596466064453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2209.6006870269775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2269.7107791900635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2013}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2166.248083114624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2693}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2683.756113052368, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3333}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2412.822484970093, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4014}}}
{"qid": "2997223939033016160", "question": "what part of brain is responsible for complex thinking", "gold_answers": ["the frontal lobe"], "shots": {"0": {"k": 0, "answer": "Cerebrum", "latency_ms": 2677.929639816284, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cerebral cortex", "latency_ms": 2521.369218826294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "Cerebral cortex", "latency_ms": 1273.5438346862793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1332}, "3": {"k": 3, "answer": "Cerebral cortex", "latency_ms": 2202.8019428253174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2045}, "4": {"k": 4, "answer": "Cerebral cortex", "latency_ms": 1856.593132019043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2729}, "5": {"k": 5, "answer": "Cerebral cortex", "latency_ms": 3445.650815963745, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3372}, "6": {"k": 6, "answer": "Cerebral cortex", "latency_ms": 2163.285732269287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3988}}}
{"qid": "2680196226239522881", "question": "who won the champions league final in 2016", "gold_answers": ["Real Madrid"], "shots": {"0": {"k": 0, "answer": "Real Madrid", "latency_ms": 2093.822717666626, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1866.283655166626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "Real Madrid", "latency_ms": 1239.905834197998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Real Madrid", "latency_ms": 982.6595783233643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Real Madrid", "latency_ms": 1798.6400127410889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2523}, "5": {"k": 5, "answer": "Real Madrid", "latency_ms": 1074.6486186981201, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Real Madrid", "latency_ms": 1743.074893951416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3729}}}
{"qid": "-8458006812258546025", "question": "who has the most gold medals in the winter olympics of all time", "gold_answers": ["Norway"], "shots": {"0": {"k": 0, "answer": "Marit Bjoergen", "latency_ms": 1360.6054782867432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canada", "latency_ms": 1456.4969539642334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Canada", "latency_ms": 689.2273426055908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Norway and Canada and Germany", "latency_ms": 3788.724660873413, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Norway and Canada and Germany", "latency_ms": 2755.6679248809814, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2407}, "5": {"k": 5, "answer": "Marit Bjørgen", "latency_ms": 3733.6301803588867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3030}, "6": {"k": 6, "answer": "Marit Bjørgen", "latency_ms": 2587.7912044525146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3641}}}
