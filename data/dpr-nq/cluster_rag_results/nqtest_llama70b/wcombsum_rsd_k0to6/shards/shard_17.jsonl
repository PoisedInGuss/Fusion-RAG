{"qid": "-9197932657152136610", "question": "what are the main sources of economic growth in the us currently", "gold_answers": ["pharmaceuticals", "aircraft", "telecommunications", "heavy machinery"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1968.6486721038818, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "increases in labour, increase in capital and increase in efficiency", "latency_ms": 4995.208501815796, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "increases in labour, increase in capital and increase in efficiency", "latency_ms": 5879.652500152588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1323}, "3": {"k": 3, "answer": "increases in labour, increase in capital and increase in efficiency", "latency_ms": 4811.932563781738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2029}, "4": {"k": 4, "answer": "increases in labour, increase in capital and increase in efficiency", "latency_ms": 5456.764459609985, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2672}, "5": {"k": 5, "answer": "investments in human and non-human capital", "latency_ms": 4525.691986083984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3392}, "6": {"k": 6, "answer": "Input growth, technological change, capital, labor", "latency_ms": 3685.741901397705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4087}}}
{"qid": "-4566914757117567579", "question": "who played ethel on the doris day show", "gold_answers": ["Carol Worthington"], "shots": {"0": {"k": 0, "answer": "Kay Chandra", "latency_ms": 2127.0995140075684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2245.887041091919, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2195.180892944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1166}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2232.356071472168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1768}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1976.5923023223877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2434}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2343.533992767334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3048}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2934.2362880706787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3670}}}
{"qid": "212435016090205927", "question": "who played g baby in the movie hardball", "gold_answers": ["DeWayne Warren"], "shots": {"0": {"k": 0, "answer": "Keanu Reeves", "latency_ms": 2600.0711917877197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "DeWayne Warren", "latency_ms": 2914.5922660827637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 644}, "2": {"k": 2, "answer": "DeWayne Warren", "latency_ms": 2784.776449203491, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "DeWayne Warren", "latency_ms": 2161.715030670166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1895}, "4": {"k": 4, "answer": "DeWayne Warren", "latency_ms": 2348.9935398101807, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2505}, "5": {"k": 5, "answer": "DeWayne Warren", "latency_ms": 2477.1859645843506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3095}, "6": {"k": 6, "answer": "DeWayne Warren", "latency_ms": 2681.525707244873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3744}}}
{"qid": "-4190633494852415957", "question": "who played john coffey in the movie the green mile", "gold_answers": ["Michael Clarke Duncan"], "shots": {"0": {"k": 0, "answer": "Michael Clarke Duncan", "latency_ms": 2124.598979949951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Clarke Duncan", "latency_ms": 1321.9654560089111, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Michael Clarke Duncan", "latency_ms": 1790.4157638549805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1227}, "3": {"k": 3, "answer": "Michael Clarke Duncan", "latency_ms": 2087.2597694396973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1866}, "4": {"k": 4, "answer": "Michael Clarke Duncan", "latency_ms": 1369.6062564849854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2525}, "5": {"k": 5, "answer": "Michael Clarke Duncan", "latency_ms": 1556.8103790283203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Michael Clarke Duncan", "latency_ms": 2579.930067062378, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3763}}}
{"qid": "811267239470530686", "question": "who wrote catch 22 (both names)", "gold_answers": ["American author Joseph Heller", "Joseph Heller .", "Joseph Heller"], "shots": {"0": {"k": 0, "answer": "Joseph Heller", "latency_ms": 1035.135269165039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Joseph Heller", "latency_ms": 2100.3212928771973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 614}, "2": {"k": 2, "answer": "Joseph Heller", "latency_ms": 2103.527784347534, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Joseph Heller", "latency_ms": 1865.1771545410156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1945}, "4": {"k": 4, "answer": "Joseph Heller", "latency_ms": 2596.1413383483887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2609}, "5": {"k": 5, "answer": "Joseph Heller", "latency_ms": 2225.785493850708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3286}, "6": {"k": 6, "answer": "Joseph Heller, Louis Falstein", "latency_ms": 3091.878652572632, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3962}}}
{"qid": "-1608179127534867277", "question": "where was the world chess tournament 2017 held", "gold_answers": ["Tbilisi , Georgia", "in Tbilisi , Georgia"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 1155.1332473754883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tbilisi, Georgia", "latency_ms": 3955.287218093872, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "Tbilisi, Georgia", "latency_ms": 2971.270799636841, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Tbilisi, Georgia", "latency_ms": 2554.0568828582764, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "Tbilisi, Georgia", "latency_ms": 2761.9006633758545, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "Tbilisi, Georgia", "latency_ms": 2571.723222732544, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3213}, "6": {"k": 6, "answer": "Tbilisi, Georgia", "latency_ms": 3577.5344371795654, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "7687115121611301468", "question": "who votes to elect a rajya sabha memmber", "gold_answers": ["state legislatures"], "shots": {"0": {"k": 0, "answer": "Elected members of State Legislative Assembly", "latency_ms": 2923.7515926361084, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Legislative assemblies of the states and the Electoral College of the Union Territories.", "latency_ms": 6302.551746368408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "Legislative assemblies of the states and the Electoral College of the Union Territories.", "latency_ms": 6547.672748565674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Electoral college of the elected members of the State Assembly", "latency_ms": 6437.056064605713, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Electoral college of the elected members of the State Assembly", "latency_ms": 5999.890565872192, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2551}, "5": {"k": 5, "answer": "Members of the Legislative Assembly", "latency_ms": 2661.7519855499268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "Members of the Legislative Assembly", "latency_ms": 2493.429660797119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3784}}}
{"qid": "-5784633834792163973", "question": "when does season 8 of hawaii five o premiere", "gold_answers": ["September 29 , 2017"], "shots": {"0": {"k": 0, "answer": "September 27, 2017", "latency_ms": 3399.5308876037598, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 29, 2017", "latency_ms": 3129.0347576141357, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "September 29, 2017", "latency_ms": 4629.049301147461, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "September 29, 2017", "latency_ms": 2859.771490097046, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "September 29, 2017", "latency_ms": 3217.719554901123, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2477}, "5": {"k": 5, "answer": "September 29, 2017", "latency_ms": 3355.7941913604736, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "September 29, 2017", "latency_ms": 4486.743688583374, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-5864397450755103545", "question": "paul walkers cars in fast and furious list", "gold_answers": ["1995 Toyota Supra", "2002 Mitsubishi Lancer OZ Rally", "1995 Dodge Stealth", "1995 Mitsubishi Eclipse"], "shots": {"0": {"k": 0, "answer": "Toyota Supra, Mitsubishi Eclipse, Nissan Skyline, Dodge Charger, Ford Gran Torino", "latency_ms": 6479.773998260498, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2155.7414531707764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "Mitsubishi Lancer Evolution, green 1972 Ford Gran Torino Sport", "latency_ms": 7725.018262863159, "em": 0.0, "f1": 0.2857142857142857, "containment": 0.0, "context_chars": 1203}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2085.711717605591, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1820}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2367.547035217285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2419}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2438.3606910705566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3044}, "6": {"k": 6, "answer": "Mitsubishi Lancer Evolution, Mazda MX5, Nissan 350Z", "latency_ms": 6193.413972854614, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3650}}}
{"qid": "-8491157534197669091", "question": "who won the oscar for best actor in 1975", "gold_answers": ["Art Carney"], "shots": {"0": {"k": 0, "answer": "Art Carney", "latency_ms": 1628.1678676605225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Peter Finch", "latency_ms": 2332.5018882751465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1915.0681495666504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2223.4342098236084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2487.6346588134766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2525}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1916.4981842041016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3074}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2453.2063007354736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3751}}}
{"qid": "-8408640804522114136", "question": "when did the first episode of that 70s show air", "gold_answers": ["August 23 , 1998"], "shots": {"0": {"k": 0, "answer": "August 23, 1998", "latency_ms": 2898.455858230591, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "16 April 2012", "latency_ms": 3030.4601192474365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "16 April 2012", "latency_ms": 1766.6139602661133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1187}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1668.5047149658203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1799}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2435.2517127990723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2399}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2210.7625007629395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2999}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1895.4744338989258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3659}}}
{"qid": "722920117313579366", "question": "when did the book thief movie come out", "gold_answers": ["November 27 , 2013", "2013"], "shots": {"0": {"k": 0, "answer": "November 8, 2013", "latency_ms": 3159.1272354125977, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2013", "latency_ms": 1044.2500114440918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 637}, "2": {"k": 2, "answer": "2013", "latency_ms": 2352.926731109619, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1280}, "3": {"k": 3, "answer": "2013", "latency_ms": 1497.1189498901367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1876}, "4": {"k": 4, "answer": "2013", "latency_ms": 1233.1843376159668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2488}, "5": {"k": 5, "answer": "2013", "latency_ms": 2316.1818981170654, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3061}, "6": {"k": 6, "answer": "2013", "latency_ms": 1809.3831539154053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3672}}}
{"qid": "-4427112594024146143", "question": "when did the eagles win the super bowl", "gold_answers": ["2017"], "shots": {"0": {"k": 0, "answer": "Super Bowl LII", "latency_ms": 2140.3982639312744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Super Bowl LII", "latency_ms": 2131.740093231201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "Super Bowl LII", "latency_ms": 3257.3869228363037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "2018", "latency_ms": 1290.5819416046143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "2018", "latency_ms": 1756.612777709961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2478}, "5": {"k": 5, "answer": "2018", "latency_ms": 1011.4233493804932, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3082}, "6": {"k": 6, "answer": "2018", "latency_ms": 1784.0347290039062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3722}}}
{"qid": "7078422108284431587", "question": "who is the biggest selling female group of all time", "gold_answers": ["Spice Girls"], "shots": {"0": {"k": 0, "answer": "The Spice Girls", "latency_ms": 1844.3784713745117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spice Girls", "latency_ms": 1587.2712135314941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 676}, "2": {"k": 2, "answer": "Spice Girls", "latency_ms": 1316.5485858917236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Spice Girls", "latency_ms": 1855.73148727417, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1867}, "4": {"k": 4, "answer": "Spice Girls", "latency_ms": 1603.7402153015137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Spice Girls", "latency_ms": 1511.8591785430908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3055}, "6": {"k": 6, "answer": "Spice Girls", "latency_ms": 2423.436403274536, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3664}}}
{"qid": "1039102546557940080", "question": "who sang from russia with love james bond", "gold_answers": ["Matt Monro"], "shots": {"0": {"k": 0, "answer": "Matt Monro", "latency_ms": 1386.9092464447021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matt Monro", "latency_ms": 2323.6658573150635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Matt Monro", "latency_ms": 2396.1422443389893, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1263}, "3": {"k": 3, "answer": "Matt Monro", "latency_ms": 1288.7592315673828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1884}, "4": {"k": 4, "answer": "Matt Monro", "latency_ms": 2105.9036254882812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Matt Monro", "latency_ms": 2122.795820236206, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3195}, "6": {"k": 6, "answer": "Matt Monro", "latency_ms": 1366.7447566986084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3814}}}
{"qid": "-8507438636601119973", "question": "where is urinary bladder located in human body", "gold_answers": ["on the pelvic floor", "pelvic floor"], "shots": {"0": {"k": 0, "answer": "Pelvic cavity", "latency_ms": 1594.1526889801025, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the base of the pelvis", "latency_ms": 3558.2406520843506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "at the base of the pelvis", "latency_ms": 3863.158702850342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "at the base of the pelvis", "latency_ms": 2628.4217834472656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "at the base of the pelvis", "latency_ms": 2797.929525375366, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2469}, "5": {"k": 5, "answer": "at the base of the pelvis", "latency_ms": 2880.8326721191406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3123}, "6": {"k": 6, "answer": "at the base of the pelvis", "latency_ms": 3612.913131713867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-1996951438961136762", "question": "architectural elements forming rib vaults eg wells cathedral", "gold_answers": ["two to three barrel vaults", "an armature of piped masonry", "barrel vaults"], "shots": {"0": {"k": 0, "answer": "Ribs", "latency_ms": 776.4256000518799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ribs in a net-like form", "latency_ms": 3380.6090354919434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 571}, "2": {"k": 2, "answer": "Ribs", "latency_ms": 2086.555242538452, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "lierne ribs", "latency_ms": 1309.5340728759766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1900}, "4": {"k": 4, "answer": "lierne ribs", "latency_ms": 2396.6526985168457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "lierne ribs", "latency_ms": 1864.1417026519775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3247}, "6": {"k": 6, "answer": "lierne ribs", "latency_ms": 1890.9385204315186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3941}}}
{"qid": "-8490085242981497626", "question": "who sang gonna sit right down and write myself a letter", "gold_answers": ["Fats Waller"], "shots": {"0": {"k": 0, "answer": "Alicia Keys", "latency_ms": 1453.9458751678467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fats Waller", "latency_ms": 2112.469434738159, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "Fats Waller", "latency_ms": 2194.3416595458984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Fats Waller", "latency_ms": 2765.89035987854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Fats Waller", "latency_ms": 2184.438705444336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2585}, "5": {"k": 5, "answer": "Fats Waller", "latency_ms": 2420.6058979034424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Fats Waller", "latency_ms": 2474.860668182373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3797}}}
{"qid": "8783361206191889627", "question": "how many rooms is there in buckingham palace", "gold_answers": ["775 rooms", "775"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2280.0474166870117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "775", "latency_ms": 946.0544586181641, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "775", "latency_ms": 1154.4413566589355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1197}, "3": {"k": 3, "answer": "775", "latency_ms": 1736.0858917236328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1793}, "4": {"k": 4, "answer": "775", "latency_ms": 1172.3263263702393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2363}, "5": {"k": 5, "answer": "775", "latency_ms": 1450.3288269042969, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3009}, "6": {"k": 6, "answer": "775", "latency_ms": 1463.1078243255615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3631}}}
{"qid": "1172792682698457582", "question": "where did they get the tree for rockefeller center", "gold_answers": ["State College , PA"], "shots": {"0": {"k": 0, "answer": "Wallkill, New York", "latency_ms": 3254.9707889556885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 6264.8766040802, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 7515.552043914795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 7165.102958679199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 5988.158941268921, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2681}, "5": {"k": 5, "answer": "upstate New York and surrounding states, and even Ottawa in Ontario, Canada.", "latency_ms": 7682.427644729614, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3299}, "6": {"k": 6, "answer": "upstate New York and surrounding states, and even Ottawa in Ontario, Canada.", "latency_ms": 6936.522483825684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3945}}}
{"qid": "-8616225749004085214", "question": "who expanded the territory of china during the qing dynasty", "gold_answers": ["Prince Bao", "the Qianlong Emperor", "Qianlong"], "shots": {"0": {"k": 0, "answer": "Qianlong Emperor", "latency_ms": 1947.4644660949707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nurhaci", "latency_ms": 2323.000431060791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Qianlong Emperor", "latency_ms": 2445.732355117798, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Kangxi Emperor", "latency_ms": 2925.4937171936035, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Kangxi Emperor", "latency_ms": 2152.675151824951, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Kangxi Emperor", "latency_ms": 1833.1449031829834, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3269}, "6": {"k": 6, "answer": "Qianlong Emperor", "latency_ms": 2409.759283065796, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3958}}}
{"qid": "-4544825586005995775", "question": "what is the second largest country in asia", "gold_answers": ["China"], "shots": {"0": {"k": 0, "answer": "Kazakhstan", "latency_ms": 1122.0388412475586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1400.094747543335, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2501.9805431365967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1349}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2455.251932144165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1925.0967502593994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Iran", "latency_ms": 944.6213245391846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3201}, "6": {"k": 6, "answer": "Iran", "latency_ms": 964.4176959991455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3891}}}
{"qid": "2851585794686488659", "question": "when was the last episode of vampire diaries aired", "gold_answers": ["March 10 , 2017"], "shots": {"0": {"k": 0, "answer": "March 10, 2017", "latency_ms": 2716.0935401916504, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2342.7698612213135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "March 10, 2017", "latency_ms": 4147.8271484375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "March 10, 2017", "latency_ms": 3138.8957500457764, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "March 10, 2017", "latency_ms": 3865.8154010772705, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "March 10, 2017", "latency_ms": 3127.025365829468, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3187}, "6": {"k": 6, "answer": "March 10, 2017", "latency_ms": 2920.60923576355, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3859}}}
{"qid": "636692438616046367", "question": "who played ashley on the young and the restless", "gold_answers": ["Shari Shattuck", "Eileen Davidson", "Brenda Epperson"], "shots": {"0": {"k": 0, "answer": "Eileen Davidson", "latency_ms": 777.5435447692871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eileen Davidson", "latency_ms": 2061.434030532837, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "Eileen Davidson", "latency_ms": 2052.030563354492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Eileen Davidson, Brenda Epperson, Shari Shattuck", "latency_ms": 5262.9218101501465, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1868}, "4": {"k": 4, "answer": "Eileen Davidson", "latency_ms": 1815.351963043213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2498}, "5": {"k": 5, "answer": "Eileen Davidson", "latency_ms": 2014.815092086792, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3082}, "6": {"k": 6, "answer": "Eileen Davidson, Brenda Epperson, Shari Shattuck", "latency_ms": 5302.630186080933, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3680}}}
{"qid": "-2668952310493902320", "question": "who has scored the most points for wales v france", "gold_answers": ["Neil Jenkins"], "shots": {"0": {"k": 0, "answer": "Neil Jenkins", "latency_ms": 1786.1156463623047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2332.914352416992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "Barry John", "latency_ms": 1593.8608646392822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1172}, "3": {"k": 3, "answer": "Barry John", "latency_ms": 1889.0635967254639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1801}, "4": {"k": 4, "answer": "Barry John", "latency_ms": 2056.016445159912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2437}, "5": {"k": 5, "answer": "Barry John", "latency_ms": 2566.6558742523193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "Barry John", "latency_ms": 2348.1576442718506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3624}}}
{"qid": "-551363795407275714", "question": "who is pictured on the 5000 dollar bill", "gold_answers": ["James Madison"], "shots": {"0": {"k": 0, "answer": "James Madison", "latency_ms": 1333.2200050354004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2401.8163681030273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2654.585838317871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2383.8768005371094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2862.6813888549805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2520}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3740.163564682007, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3283}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2682.2593212127686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3939}}}
{"qid": "-1776638341170409438", "question": "what is the strongest earthquake in the united states", "gold_answers": ["1700 Cascadia earthquake", "1964 Alaska earthquake and tsunami"], "shots": {"0": {"k": 0, "answer": "Great Alaska Earthquake", "latency_ms": 1675.6367683410645, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5.8 magnitude", "latency_ms": 2357.628583908081, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "5.8 magnitude", "latency_ms": 1949.270486831665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "7.9 M", "latency_ms": 2153.7492275238037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "7.9 M", "latency_ms": 2944.2994594573975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "7.9 M", "latency_ms": 2421.194314956665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "7.9 M", "latency_ms": 3011.629104614258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3929}}}
{"qid": "-3417376069582577712", "question": "who wrote the song balls to the wall", "gold_answers": ["Herman Frank", "Peter Baltes", "Stefan Kaufmann", "Wolf Hoffmann", "Udo Dirkschneider", "Deaffy"], "shots": {"0": {"k": 0, "answer": "Accept", "latency_ms": 1235.325574874878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1935.2176189422607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2463.958740234375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2196.254253387451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1866}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1895.3971862792969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2651.8280506134033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3122}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1937.0324611663818, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3746}}}
{"qid": "-5788046732019278353", "question": "who talks for belle in beauty and the beast", "gold_answers": ["Julie Nathanson", "Jodi Benson", "Paige O'Hara"], "shots": {"0": {"k": 0, "answer": "Paige O'Hara", "latency_ms": 2023.9992141723633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Paige O'Hara", "latency_ms": 2487.3533248901367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 689}, "2": {"k": 2, "answer": "Paige O'Hara", "latency_ms": 2718.8620567321777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1379}, "3": {"k": 3, "answer": "Paige O'Hara", "latency_ms": 1943.1779384613037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2033}, "4": {"k": 4, "answer": "Paige O'Hara", "latency_ms": 3030.095100402832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2630}, "5": {"k": 5, "answer": "Paige O'Hara", "latency_ms": 1716.6428565979004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3245}, "6": {"k": 6, "answer": "Paige O'Hara", "latency_ms": 2239.3102645874023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3901}}}
{"qid": "-819495145099806596", "question": "what is a coherent set of values and beliefs about public policy called", "gold_answers": ["political ideology", "ideology", "a political ideology"], "shots": {"0": {"k": 0, "answer": "Ideology", "latency_ms": 1254.1983127593994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Group of Five", "latency_ms": 1866.8084144592285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Group of Five", "latency_ms": 2326.2500762939453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Group of Five", "latency_ms": 2423.748016357422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2032}, "4": {"k": 4, "answer": "Group of Five", "latency_ms": 2038.7005805969238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2753}, "5": {"k": 5, "answer": "Group of Five", "latency_ms": 1567.1954154968262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3352}, "6": {"k": 6, "answer": "Group of Five", "latency_ms": 1536.6661548614502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4048}}}
{"qid": "-467801736331608973", "question": "when do liam and annie get together season 3", "gold_answers": ["Holiday Madness"], "shots": {"0": {"k": 0, "answer": "Episode 9", "latency_ms": 1671.8740463256836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Season three", "latency_ms": 1819.7910785675049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "Season three", "latency_ms": 2001.7669200897217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1168}, "3": {"k": 3, "answer": "After Liam leaves and returns", "latency_ms": 2445.361614227295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1793}, "4": {"k": 4, "answer": "Season three", "latency_ms": 2297.914505004883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2350}, "5": {"k": 5, "answer": "After Liam returns from abroad", "latency_ms": 2430.263042449951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2978}, "6": {"k": 6, "answer": "After Emily leaves", "latency_ms": 1549.2558479309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3590}}}
{"qid": "7210975046317501288", "question": "what breed of cat has spots and stripes", "gold_answers": ["tabby"], "shots": {"0": {"k": 0, "answer": "Ocicat", "latency_ms": 2420.7653999328613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bengal cat", "latency_ms": 1203.249454498291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "Bengal cat", "latency_ms": 3082.1118354797363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Bengal cat", "latency_ms": 2888.8096809387207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1788}, "4": {"k": 4, "answer": "Bengal cat", "latency_ms": 2754.9586296081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2439}, "5": {"k": 5, "answer": "Bengal cat", "latency_ms": 2154.1056632995605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3087}, "6": {"k": 6, "answer": "Bengal cat", "latency_ms": 2667.7372455596924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3631}}}
{"qid": "7817340376558760325", "question": "who voiced simba in the lion king 2", "gold_answers": ["Matthew Broderick"], "shots": {"0": {"k": 0, "answer": "Matthew Broderick", "latency_ms": 1944.1864490509033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matthew Broderick", "latency_ms": 2436.3913536071777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 649}, "2": {"k": 2, "answer": "Matthew Broderick", "latency_ms": 2901.2694358825684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Matthew Broderick", "latency_ms": 2919.1675186157227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1880}, "4": {"k": 4, "answer": "Matthew Broderick", "latency_ms": 2696.0222721099854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2555}, "5": {"k": 5, "answer": "Matthew Broderick", "latency_ms": 2094.029426574707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Matthew Broderick", "latency_ms": 2485.819101333618, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3783}}}
{"qid": "7584034394038581786", "question": "when did the angel of the north get built", "gold_answers": ["1998", "1994"], "shots": {"0": {"k": 0, "answer": "1998", "latency_ms": 2109.1384887695312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1573.862075805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3210.456371307373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1324}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1829.7679424285889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2648.2179164886475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2486}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1748.8861083984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3228}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2593.5099124908447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3859}}}
{"qid": "1854394640394891866", "question": "when did mcgee became a regular on ncis", "gold_answers": ["in season two", "season two"], "shots": {"0": {"k": 0, "answer": "Season 2", "latency_ms": 2271.118640899658, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Season two", "latency_ms": 1265.746831893921, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Season two", "latency_ms": 1587.4931812286377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Season two", "latency_ms": 1642.9407596588135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Season two", "latency_ms": 1035.5679988861084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2559}, "5": {"k": 5, "answer": "Season two", "latency_ms": 2043.238878250122, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3167}, "6": {"k": 6, "answer": "Season two", "latency_ms": 1207.0434093475342, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3800}}}
{"qid": "2247250807557083996", "question": "when was 1 john 5 7 added to the bible", "gold_answers": ["the 9th century"], "shots": {"0": {"k": 0, "answer": "15th century", "latency_ms": 1652.021884918213, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2075.5929946899414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1881.8066120147705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2108.947277069092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1772}, "4": {"k": 4, "answer": "Nineteenth century", "latency_ms": 2737.9355430603027, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2375}, "5": {"k": 5, "answer": "19th century", "latency_ms": 2153.980255126953, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3042}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2428.4229278564453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-2049551589682654986", "question": "when was the latest version of chrome released", "gold_answers": ["2018 - 01 - 22"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1898.3900547027588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2402.7328491210938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2141.4389610290527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2678.6394119262695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1833}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2666.274070739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2433}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2551.3229370117188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3124}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1916.506290435791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3767}}}
{"qid": "-3534092359651954035", "question": "who is jojo in horton hears a who", "gold_answers": ["Jesse McCartney"], "shots": {"0": {"k": 0, "answer": "JoJo", "latency_ms": 1031.0921669006348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a small Who", "latency_ms": 1872.3008632659912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "JoJo, the teenage son of Mayor Ned McDodd", "latency_ms": 4929.103374481201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1157}, "3": {"k": 3, "answer": "JoJo, the Mayor's teenage son", "latency_ms": 4754.392623901367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1746}, "4": {"k": 4, "answer": "JoJo, the Mayor's teenage son", "latency_ms": 3729.036808013916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "JoJo, the Mayor's teenage son", "latency_ms": 3586.170434951782, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3034}, "6": {"k": 6, "answer": "JoJo, the Mayor's teenage son", "latency_ms": 4442.567586898804, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}}}
{"qid": "6504412384445795967", "question": "the part of the cytoskeleton made from the protein actin is called", "gold_answers": ["Microfilaments", "microfilament"], "shots": {"0": {"k": 0, "answer": "Microfilaments", "latency_ms": 2040.9409999847412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "actin cytoskeleton", "latency_ms": 2789.9584770202637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "microfilaments", "latency_ms": 1325.7157802581787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1280}, "3": {"k": 3, "answer": "Microfilaments", "latency_ms": 2276.2041091918945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1958}, "4": {"k": 4, "answer": "Microfilaments", "latency_ms": 2322.5090503692627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "Microfilaments", "latency_ms": 1747.8396892547607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3326}, "6": {"k": 6, "answer": "Microfilaments", "latency_ms": 2113.999843597412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4056}}}
{"qid": "95888218441734902", "question": "who plays jack in battle of the sexes", "gold_answers": ["Bill Pullman", "( Bill Pullman"], "shots": {"0": {"k": 0, "answer": "Steve Carell", "latency_ms": 1447.5343227386475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Steve Carell", "latency_ms": 2263.174295425415, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "Bill Pullman", "latency_ms": 2911.404848098755, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "Bill Pullman", "latency_ms": 1660.5968475341797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Bill Pullman", "latency_ms": 2363.236665725708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2439}, "5": {"k": 5, "answer": "Bill Pullman", "latency_ms": 2125.540256500244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Bill Pullman", "latency_ms": 2061.8178844451904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3749}}}
{"qid": "2482202658787537401", "question": "is a network connection device that can build tables that identify addresses on each network", "gold_answers": ["routing table", "a router"], "shots": {"0": {"k": 0, "answer": "Router", "latency_ms": 963.5512828826904, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Router", "latency_ms": 1214.2784595489502, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 723}, "2": {"k": 2, "answer": "Router", "latency_ms": 1132.7285766601562, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1418}, "3": {"k": 3, "answer": "Router", "latency_ms": 1733.2100868225098, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2134}, "4": {"k": 4, "answer": "Router", "latency_ms": 1395.075798034668, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2813}, "5": {"k": 5, "answer": "Router", "latency_ms": 1609.889030456543, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3444}, "6": {"k": 6, "answer": "Router", "latency_ms": 1690.2079582214355, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4134}}}
{"qid": "8359496728452221378", "question": "when did the royal proclamation of 1763 end", "gold_answers": ["with the American Revolutionary War", "the American Revolutionary War", "1783"], "shots": {"0": {"k": 0, "answer": "1763", "latency_ms": 743.6821460723877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2500.3528594970703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1900.2883434295654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1358}, "3": {"k": 3, "answer": "American Revolutionary War", "latency_ms": 2655.7037830352783, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "American Revolutionary War", "latency_ms": 1309.5650672912598, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2688}, "5": {"k": 5, "answer": "American Revolutionary War", "latency_ms": 2082.7836990356445, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3349}, "6": {"k": 6, "answer": "American Revolutionary War", "latency_ms": 2064.640998840332, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4039}}}
{"qid": "-2657014790962135860", "question": "the tenure of the office of the lokayukt of up", "gold_answers": ["8 years", "eight years"], "shots": {"0": {"k": 0, "answer": "8 years", "latency_ms": 977.1692752838135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2650.104522705078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2218.4698581695557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2438.197374343872, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1934.6592426300049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2414}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2722.7306365966797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1986.638069152832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3736}}}
{"qid": "1827180983934640653", "question": "when did response to state of the union start", "gold_answers": ["1966", "in 1966"], "shots": {"0": {"k": 0, "answer": "1966", "latency_ms": 1329.7724723815918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1970", "latency_ms": 1783.9789390563965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "1966", "latency_ms": 731.3880920410156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1389}, "3": {"k": 3, "answer": "1966", "latency_ms": 1770.0812816619873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2071}, "4": {"k": 4, "answer": "1966", "latency_ms": 1717.3378467559814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2745}, "5": {"k": 5, "answer": "1966", "latency_ms": 1522.7954387664795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3440}, "6": {"k": 6, "answer": "1966", "latency_ms": 1925.1317977905273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4096}}}
{"qid": "-8006002028754190814", "question": "who had the most governmental power under the articles of confederation", "gold_answers": ["the states"], "shots": {"0": {"k": 0, "answer": "State governments", "latency_ms": 1291.34202003479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The states", "latency_ms": 1251.9810199737549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "The states", "latency_ms": 1696.7666149139404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1364}, "3": {"k": 3, "answer": "The states", "latency_ms": 1554.8083782196045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2087}, "4": {"k": 4, "answer": "The states", "latency_ms": 1707.240343093872, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2785}, "5": {"k": 5, "answer": "Congress", "latency_ms": 913.9389991760254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3485}, "6": {"k": 6, "answer": "The states", "latency_ms": 1499.1934299468994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4186}}}
{"qid": "3406509904702130536", "question": "how many hospitals are there in the united states", "gold_answers": ["5,534 registered hospitals", "5,534"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1871.9708919525146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5,534", "latency_ms": 1854.0308475494385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 723}, "2": {"k": 2, "answer": "5,534", "latency_ms": 2117.446184158325, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1403}, "3": {"k": 3, "answer": "5,534", "latency_ms": 1901.810884475708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2123}, "4": {"k": 4, "answer": "5,534", "latency_ms": 2385.340929031372, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2800}, "5": {"k": 5, "answer": "5,534", "latency_ms": 2319.7338581085205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3481}, "6": {"k": 6, "answer": "5,534", "latency_ms": 2305.091142654419, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4191}}}
{"qid": "2435796066046322163", "question": "who donates a christmas tree to trafalgar square", "gold_answers": ["Oslo , Norway"], "shots": {"0": {"k": 0, "answer": "Norway", "latency_ms": 1604.5372486114502, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The city of Oslo, Norway", "latency_ms": 3338.4437561035156, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "The city of Oslo, Norway", "latency_ms": 3130.4574012756348, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Norway", "latency_ms": 1246.896505355835, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1929}, "4": {"k": 4, "answer": "The city of Oslo, Norway", "latency_ms": 4285.115718841553, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "The city of Oslo, Norway", "latency_ms": 2489.5076751708984, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "The city of Oslo, Norway", "latency_ms": 3851.3453006744385, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3783}}}
{"qid": "4926415052497472665", "question": "who starred in the movie on golden pond", "gold_answers": ["William Lanteau", "Dabney Coleman", "Henry Fonda", "Doug McKeon", "Jane Fonda", "Christopher Rydell", "Katharine Hepburn"], "shots": {"0": {"k": 0, "answer": "Henry Fonda", "latency_ms": 1543.9567565917969, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Julie Andrews and Christopher Plummer", "latency_ms": 3324.334144592285, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 609}, "2": {"k": 2, "answer": "Julie Andrews and Christopher Plummer", "latency_ms": 3363.820791244507, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Julie Andrews, Christopher Plummer, Katharine Hepburn, Henry Fonda", "latency_ms": 5926.936388015747, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1866}, "4": {"k": 4, "answer": "Julie Andrews, Christopher Plummer, Katharine Hepburn, Henry Fonda", "latency_ms": 7754.350423812866, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2482}, "5": {"k": 5, "answer": "Julie Andrews, Christopher Plummer, Katharine Hepburn, Henry Fonda", "latency_ms": 5780.716896057129, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 5414.644956588745, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3756}}}
{"qid": "2142753216627246962", "question": "isdn uses b & d channels. what is d channel use for", "gold_answers": ["carries control and signaling information", "data", "control and signaling information"], "shots": {"0": {"k": 0, "answer": "Signaling", "latency_ms": 1847.3396301269531, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "control and signaling information", "latency_ms": 2442.2316551208496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "control and signaling information", "latency_ms": 2402.803659439087, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "signaling and control", "latency_ms": 2359.912872314453, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 1914}, "4": {"k": 4, "answer": "signaling and control", "latency_ms": 1851.9339561462402, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 2519}, "5": {"k": 5, "answer": "signaling and control", "latency_ms": 2087.533950805664, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "signaling and control", "latency_ms": 1444.465160369873, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3887}}}
{"qid": "1547060614805522730", "question": "what is the rate limiting enzyme of kreb's cycle", "gold_answers": ["Isocitrate dehydrogenase"], "shots": {"0": {"k": 0, "answer": "Isocitrate dehydrogenase", "latency_ms": 3340.3923511505127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "ALA synthase", "latency_ms": 2073.378324508667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "ALA synthase", "latency_ms": 1768.2914733886719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "ALA synthase", "latency_ms": 1868.5023784637451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2039}, "4": {"k": 4, "answer": "ALA synthase", "latency_ms": 1148.9956378936768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2723}, "5": {"k": 5, "answer": "ALA synthase", "latency_ms": 2077.420234680176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3364}, "6": {"k": 6, "answer": "ALA synthase", "latency_ms": 1328.0308246612549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4073}}}
{"qid": "8965198420725510475", "question": "when was the taj mahal built and completed", "gold_answers": ["1632 -- 53"], "shots": {"0": {"k": 0, "answer": "1653", "latency_ms": 576.9670009613037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1643, 1653", "latency_ms": 2708.5771560668945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "1643, 1653", "latency_ms": 3267.899751663208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1200}, "3": {"k": 3, "answer": "1632-1653", "latency_ms": 2763.6170387268066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1830}, "4": {"k": 4, "answer": "1632-1653", "latency_ms": 3383.4941387176514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "1632-1653", "latency_ms": 2375.091075897217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "1632-1653", "latency_ms": 2474.055290222168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3654}}}
{"qid": "-6292760252056275316", "question": "which supreme court judge has surved in international court of justice", "gold_answers": ["Dalveer Bhandari"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 1797.9938983917236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justice Dalveer Bhandari", "latency_ms": 4023.96297454834, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "Dalveer Bhandari", "latency_ms": 2563.184976577759, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "Justice Dalveer Bhandari", "latency_ms": 3831.4387798309326, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2005}, "4": {"k": 4, "answer": "Dalveer Bhandari", "latency_ms": 3066.517114639282, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2629}, "5": {"k": 5, "answer": "Dalveer Bhandari", "latency_ms": 3511.4448070526123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3304}, "6": {"k": 6, "answer": "Dalveer Bhandari", "latency_ms": 2850.118637084961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4028}}}
{"qid": "8361850218460994084", "question": "who is known as father of green revolution in india", "gold_answers": ["Mankombu Sambasivan Swaminathan"], "shots": {"0": {"k": 0, "answer": "M.S. Swaminathan", "latency_ms": 2373.210906982422, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "M. S. Swaminathan", "latency_ms": 2956.6848278045654, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "M. S. Swaminathan", "latency_ms": 3032.1760177612305, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "M. S. Swaminathan", "latency_ms": 3055.2926063537598, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2034}, "4": {"k": 4, "answer": "M. S. Swaminathan", "latency_ms": 3170.7587242126465, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2755}, "5": {"k": 5, "answer": "M. S. Swaminathan", "latency_ms": 3178.048849105835, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3489}, "6": {"k": 6, "answer": "M. S. Swaminathan", "latency_ms": 3366.457223892212, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4182}}}
{"qid": "-5690645328022945594", "question": "who sing say you won't let go", "gold_answers": ["James Arthur"], "shots": {"0": {"k": 0, "answer": "James Arthur", "latency_ms": 996.4096546173096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Arthur", "latency_ms": 1521.4729309082031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "James Arthur", "latency_ms": 2017.026662826538, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1176}, "3": {"k": 3, "answer": "James Arthur", "latency_ms": 1801.398515701294, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1776}, "4": {"k": 4, "answer": "James Arthur", "latency_ms": 1306.6480159759521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2397}, "5": {"k": 5, "answer": "James Arthur", "latency_ms": 2002.7813911437988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2969}, "6": {"k": 6, "answer": "James Arthur", "latency_ms": 1036.179780960083, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3592}}}
{"qid": "-4292736993227486718", "question": "who monitor the recovery of the location during a disaster", "gold_answers": ["management team"], "shots": {"0": {"k": 0, "answer": "Incident Commander", "latency_ms": 1822.568416595459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The management team", "latency_ms": 2218.885898590088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 754}, "2": {"k": 2, "answer": "The management team", "latency_ms": 2113.7073040008545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1402}, "3": {"k": 3, "answer": "The management team", "latency_ms": 1807.8289031982422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2170}, "4": {"k": 4, "answer": "The management team", "latency_ms": 1375.9899139404297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2839}, "5": {"k": 5, "answer": "The management team", "latency_ms": 1888.5810375213623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3488}, "6": {"k": 6, "answer": "The management team", "latency_ms": 2050.8463382720947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4208}}}
{"qid": "-4741747756019727470", "question": "where does the synthesis of new dna from existing dna occurs", "gold_answers": ["origins of replication"], "shots": {"0": {"k": 0, "answer": "Replication fork", "latency_ms": 1607.5944900512695, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "In the cell", "latency_ms": 1886.7838382720947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "in vivo", "latency_ms": 1738.8465404510498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "In a cell", "latency_ms": 1305.7985305786133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2003}, "4": {"k": 4, "answer": "in the nucleus", "latency_ms": 1896.3851928710938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2686}, "5": {"k": 5, "answer": "in the nucleus", "latency_ms": 2436.4497661590576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3333}, "6": {"k": 6, "answer": "in the nucleus", "latency_ms": 1804.567575454712, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3995}}}
{"qid": "4268853195499399258", "question": "who sings gimme shelter with mick jagger", "gold_answers": ["Merry Clayton"], "shots": {"0": {"k": 0, "answer": "Merry Clayton", "latency_ms": 1395.4076766967773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Merry Clayton", "latency_ms": 1485.3155612945557, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "Merry Clayton", "latency_ms": 2307.6181411743164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Merry Clayton", "latency_ms": 2054.408311843872, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Merry Clayton", "latency_ms": 2436.837673187256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Merry Clayton", "latency_ms": 2188.6677742004395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3224}, "6": {"k": 6, "answer": "Merry Clayton", "latency_ms": 1630.5291652679443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3928}}}
{"qid": "7172420463912356173", "question": "who does tony end up with on skins", "gold_answers": ["Michelle"], "shots": {"0": {"k": 0, "answer": "Michelle Richardson", "latency_ms": 1316.3108825683594, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michelle", "latency_ms": 1160.3765487670898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 562}, "2": {"k": 2, "answer": "Michelle", "latency_ms": 1205.2831649780273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1187}, "3": {"k": 3, "answer": "Michelle", "latency_ms": 1479.7027111053467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1819}, "4": {"k": 4, "answer": "Michelle", "latency_ms": 683.9578151702881, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2417}, "5": {"k": 5, "answer": "Michelle", "latency_ms": 1461.2069129943848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3019}, "6": {"k": 6, "answer": "Michelle", "latency_ms": 1191.521406173706, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3671}}}
{"qid": "-1400292288904470066", "question": "who sings sugar sugar you are my candy girl", "gold_answers": ["the Archies"], "shots": {"0": {"k": 0, "answer": "The Archies", "latency_ms": 1314.4629001617432, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1898.7839221954346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2155.5371284484863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1307}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2113.206148147583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2149.9476432800293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1983.8309288024902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3043.3247089385986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "-1696720698220253139", "question": "who does tyler end up with in you get me", "gold_answers": ["Ali"], "shots": {"0": {"k": 0, "answer": "Holly.\nor \nAlison.", "latency_ms": 3479.4328212738037, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2661.275625228882, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2959.5186710357666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1166}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2499.772787094116, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1774}, "4": {"k": 4, "answer": "Holly", "latency_ms": 2276.998996734619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2345}, "5": {"k": 5, "answer": "Holly", "latency_ms": 1434.4608783721924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2947}, "6": {"k": 6, "answer": "Alison 'Ali'", "latency_ms": 2890.787363052368, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3561}}}
{"qid": "-6797239474199900801", "question": "who won the gold for the men's figure skating", "gold_answers": ["Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2603.6148071289062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dick Button", "latency_ms": 1245.133876800537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "Dick Button", "latency_ms": 1553.4915924072266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1360}, "3": {"k": 3, "answer": "Dick Button", "latency_ms": 2318.0994987487793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1958}, "4": {"k": 4, "answer": "Dick Button", "latency_ms": 1812.5174045562744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2587}, "5": {"k": 5, "answer": "Dick Button", "latency_ms": 1570.63627243042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3291}, "6": {"k": 6, "answer": "Dick Button", "latency_ms": 1757.4591636657715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3957}}}
{"qid": "-7819569157752445011", "question": "when did the song holiday road come out", "gold_answers": ["1983", "June 24 , 1983"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 1971.6172218322754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1983", "latency_ms": 1520.874261856079, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "1983", "latency_ms": 2092.0796394348145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "1983", "latency_ms": 1750.1516342163086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1907}, "4": {"k": 4, "answer": "1983", "latency_ms": 1229.8388481140137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "1983", "latency_ms": 1830.902338027954, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "1983", "latency_ms": 1734.1773509979248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3886}}}
{"qid": "-8839043176903626071", "question": "when does the mlb season start and finish", "gold_answers": ["October 31 , 2018", "March 29"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1924.445390701294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2771.9178199768066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2190.025806427002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2670.332431793213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1764}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2402.693033218384, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2387}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2418.1652069091797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2985}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2430.405616760254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3537}}}
{"qid": "6356531089429364942", "question": "when did scotland beat england in six nations", "gold_answers": ["8 March 2008", "25 February 2006", "24 February 2018", "2 April 2000"], "shots": {"0": {"k": 0, "answer": "8 February 2020", "latency_ms": 1556.7741394042969, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1999", "latency_ms": 1720.0984954833984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "1999", "latency_ms": 1754.2269229888916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "2018", "latency_ms": 1241.8186664581299, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "2018, 2006", "latency_ms": 3342.609405517578, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2600}, "5": {"k": 5, "answer": "2018, 2006, 1999", "latency_ms": 4918.626070022583, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3258}, "6": {"k": 6, "answer": "2018, 2006, 1999", "latency_ms": 4355.163812637329, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3879}}}
{"qid": "-3382335563294993978", "question": "when did the rational dress society begin to work", "gold_answers": ["1881"], "shots": {"0": {"k": 0, "answer": "1881", "latency_ms": 1590.2361869812012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1881", "latency_ms": 1861.9000911712646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "1881", "latency_ms": 1035.5615615844727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "1881", "latency_ms": 1576.0457515716553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1976}, "4": {"k": 4, "answer": "1881", "latency_ms": 1961.8916511535645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2630}, "5": {"k": 5, "answer": "1881", "latency_ms": 1995.0718879699707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3243}, "6": {"k": 6, "answer": "1881", "latency_ms": 2045.9787845611572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3876}}}
{"qid": "-5630827734073464379", "question": "why is the indian ocean the warmest in the world", "gold_answers": ["human induced greenhouse warming"], "shots": {"0": {"k": 0, "answer": "High sea surface temperatures", "latency_ms": 2411.1080169677734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "human induced greenhouse warming", "latency_ms": 2158.1320762634277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1699.1362571716309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1337}, "3": {"k": 3, "answer": "Human induced greenhouse warming", "latency_ms": 2478.91902923584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1933}, "4": {"k": 4, "answer": "Human induced greenhouse warming", "latency_ms": 2634.1614723205566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2540}, "5": {"k": 5, "answer": "Human induced greenhouse warming", "latency_ms": 2655.241012573242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Human induced greenhouse warming", "latency_ms": 2138.5395526885986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3765}}}
{"qid": "-3544151584263258729", "question": "where was the film manchester by the sea filmed", "gold_answers": ["Middleton", "Essex", "Gloucester", "Beverly", "Swampscott", "Lynn", "Manchester", "Salem", "Tewksbury"], "shots": {"0": {"k": 0, "answer": "Gloucester, Massachusetts", "latency_ms": 2149.822235107422, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 12732.166290283203, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 697}, "2": {"k": 2, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 12187.189817428589, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 1334}, "3": {"k": 3, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 10713.084936141968, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 1999}, "4": {"k": 4, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 9440.216779708862, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 2671}, "5": {"k": 5, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 8651.183128356934, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 3350}, "6": {"k": 6, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem.", "latency_ms": 10439.296960830688, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 4016}}}
{"qid": "-5077733789764986167", "question": "consist of the sum of the fixed and variable costs for any given level of production", "gold_answers": ["total cost ( TC )"], "shots": {"0": {"k": 0, "answer": "Total Costs", "latency_ms": 564.6970272064209, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Total cost", "latency_ms": 1307.1458339691162, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Total cost", "latency_ms": 1845.242977142334, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Total cost", "latency_ms": 1064.467430114746, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1849}, "4": {"k": 4, "answer": "Total cost", "latency_ms": 1520.3065872192383, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2465}, "5": {"k": 5, "answer": "Total cost", "latency_ms": 1251.7824172973633, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3070}, "6": {"k": 6, "answer": "Total cost", "latency_ms": 756.7353248596191, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3714}}}
{"qid": "4892187805447493570", "question": "where was thomas and the magic railroad filmed", "gold_answers": ["Toronto , Ontario , Canada", "Isle of Man", "the Isle of Man"], "shots": {"0": {"k": 0, "answer": "Strasburg Rail Road", "latency_ms": 2438.502073287964, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shepperton Studios", "latency_ms": 2121.9964027404785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "Toronto and Shepperton Studios", "latency_ms": 2245.29767036438, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1307}, "3": {"k": 3, "answer": "Toronto and Strasburg Rail Road and Shepperton Studios", "latency_ms": 4688.945531845093, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Strasburg Rail Road and Toronto", "latency_ms": 2083.7628841400146, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "Strasburg Rail Road, Toronto, and Isle of Man.", "latency_ms": 4188.262701034546, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3221}, "6": {"k": 6, "answer": "Strasburg Rail Road, Toronto, Isle of Man", "latency_ms": 5138.569593429565, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3828}}}
{"qid": "-7094533216301278566", "question": "who has access to the presidential daily briefing", "gold_answers": ["Secretaries of State", "the President", "Defense", "National Security Advisor"], "shots": {"0": {"k": 0, "answer": "The President and senior officials.", "latency_ms": 2602.733373641968, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President and top-level US officials", "latency_ms": 3389.028787612915, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "The President of the United States and top-level US officials approved by the President", "latency_ms": 6125.921726226807, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 1334}, "3": {"k": 3, "answer": "The President and top-level US officials approved by the President", "latency_ms": 4662.337303161621, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2001}, "4": {"k": 4, "answer": "The President and a small number of top-level US officials", "latency_ms": 4351.020336151123, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2673}, "5": {"k": 5, "answer": "The President and a small number of top-level US officials", "latency_ms": 4135.313987731934, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3345}, "6": {"k": 6, "answer": "The President and a small number of top-level US officials", "latency_ms": 4343.731641769409, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4001}}}
{"qid": "-243139310037543674", "question": "what tool is available from microsoft as an alternative to the usmt for smaller migrations", "gold_answers": ["Windows Easy Transfer"], "shots": {"0": {"k": 0, "answer": "Easy Transfer", "latency_ms": 1458.0366611480713, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Files", "latency_ms": 1469.783067703247, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Windows Easy Transfer", "latency_ms": 1547.572374343872, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Windows Easy Transfer", "latency_ms": 2247.811794281006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2036}, "4": {"k": 4, "answer": "Windows Easy Transfer", "latency_ms": 1363.9826774597168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2675}, "5": {"k": 5, "answer": "Windows Easy Transfer", "latency_ms": 1865.583896636963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3378}, "6": {"k": 6, "answer": "Windows Easy Transfer", "latency_ms": 1366.2760257720947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4075}}}
{"qid": "7079282152145474767", "question": "who appoints the chief election commissioner of india", "gold_answers": ["the president", "President of India"], "shots": {"0": {"k": 0, "answer": "The President of India", "latency_ms": 1375.091314315796, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President", "latency_ms": 1554.6507835388184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "The President", "latency_ms": 1013.1909847259521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1388}, "3": {"k": 3, "answer": "The President", "latency_ms": 790.9557819366455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2081}, "4": {"k": 4, "answer": "The President", "latency_ms": 1242.764949798584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2823}, "5": {"k": 5, "answer": "The President", "latency_ms": 1003.7589073181152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3504}, "6": {"k": 6, "answer": "The President", "latency_ms": 1256.1185359954834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4269}}}
{"qid": "6303430169473424975", "question": "glycogen and amylopectin are long chains of which simple sugar(s)", "gold_answers": ["glucose"], "shots": {"0": {"k": 0, "answer": "Glucose", "latency_ms": 1001.9114017486572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "glucose", "latency_ms": 1130.3558349609375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "glucose", "latency_ms": 1724.8241901397705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1375}, "3": {"k": 3, "answer": "glucose", "latency_ms": 2023.2834815979004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2079}, "4": {"k": 4, "answer": "glucose", "latency_ms": 747.9431629180908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2686}, "5": {"k": 5, "answer": "glucose", "latency_ms": 1107.2337627410889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3343}, "6": {"k": 6, "answer": "Glucose", "latency_ms": 1539.20316696167, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3969}}}
{"qid": "-3240666523350424161", "question": "who was the editor of the journal jugantor published in the time of swadeshi movement", "gold_answers": ["Bhupendranath Dutt"], "shots": {"0": {"k": 0, "answer": "Barindra Kumar Ghosh", "latency_ms": 3802.4935722351074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3332.644462585449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1720.5495834350586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "Barindra Kumar Ghosh", "latency_ms": 2116.063117980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Barindra Kumar Ghosh", "latency_ms": 2183.537006378174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2681}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2216.1002159118652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3293}, "6": {"k": 6, "answer": "Satyen Sen", "latency_ms": 2082.9379558563232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3927}}}
{"qid": "1321443496772706078", "question": "when did indoor toilets become common in america", "gold_answers": ["After World War I"], "shots": {"0": {"k": 0, "answer": "Late 19th century", "latency_ms": 1518.8047885894775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1890s", "latency_ms": 1755.875587463379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "1890s", "latency_ms": 1258.1374645233154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "1890s", "latency_ms": 1855.9799194335938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "1890s", "latency_ms": 1555.887222290039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2577}, "5": {"k": 5, "answer": "The 1890s.", "latency_ms": 3620.227336883545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3240}, "6": {"k": 6, "answer": "The 1890s.", "latency_ms": 3376.4898777008057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3876}}}
{"qid": "6019244948248861067", "question": "who wrote were going on a bear hunt", "gold_answers": ["Michael Rosen"], "shots": {"0": {"k": 0, "answer": "Michael Rosen", "latency_ms": 967.2009944915771, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Rosen", "latency_ms": 1959.9740505218506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "Michael Rosen", "latency_ms": 1514.556646347046, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Michael Rosen", "latency_ms": 1207.7291011810303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Michael Rosen", "latency_ms": 2034.2106819152832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "Michael Rosen", "latency_ms": 1270.151138305664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3146}, "6": {"k": 6, "answer": "Michael Rosen", "latency_ms": 2070.2970027923584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3751}}}
{"qid": "8753987902863757141", "question": "what is the revolution period of venus in earth years", "gold_answers": ["0.615 198 yr", "224.7 Earth days"], "shots": {"0": {"k": 0, "answer": "0.61519726", "latency_ms": 2384.3295574188232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0.616", "latency_ms": 2174.5948791503906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "0.615 years", "latency_ms": 2387.7437114715576, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1280}, "3": {"k": 3, "answer": "0.615 Earth years", "latency_ms": 2820.420503616333, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "0.615 Earth years", "latency_ms": 3529.299736022949, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2529}, "5": {"k": 5, "answer": "0.615 Earth years", "latency_ms": 2319.890022277832, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3142}, "6": {"k": 6, "answer": "0.615 Earth years", "latency_ms": 2727.752447128296, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3793}}}
{"qid": "-5904934687784134086", "question": "who has the power to approve or veto legislation constitution", "gold_answers": ["the President"], "shots": {"0": {"k": 0, "answer": "The President", "latency_ms": 1310.4004859924316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The president", "latency_ms": 1721.876859664917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "The president and Congress", "latency_ms": 2334.3992233276367, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1368}, "3": {"k": 3, "answer": "The president", "latency_ms": 2463.2534980773926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1988}, "4": {"k": 4, "answer": "The president", "latency_ms": 938.1675720214844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2671}, "5": {"k": 5, "answer": "The president", "latency_ms": 1266.4754390716553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3340}, "6": {"k": 6, "answer": "The President", "latency_ms": 2178.753614425659, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4047}}}
{"qid": "-1910743846708408775", "question": "when was the taming ofthe shrew first performed", "gold_answers": ["prior to June 1592"], "shots": {"0": {"k": 0, "answer": "1593-1594", "latency_ms": 2240.8101558685303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1948", "latency_ms": 2076.350688934326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "1667", "latency_ms": 1573.395013809204, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "Between 1590 and 1592", "latency_ms": 3197.690486907959, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Between 1590 and 1592", "latency_ms": 3503.838062286377, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2595}, "5": {"k": 5, "answer": "11 of June 1594", "latency_ms": 3651.658296585083, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "11 of June 1594", "latency_ms": 1833.9169025421143, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3919}}}
{"qid": "6521877788261380307", "question": "who is the first prime minister of france", "gold_answers": ["Michel Debr"], "shots": {"0": {"k": 0, "answer": "Adolphe Thiers", "latency_ms": 2522.2599506378174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2296.4274883270264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2169.6345806121826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2402.818441390991, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1946}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3144.534111022949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3129.950523376465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3226}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2765.1965618133545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3858}}}
{"qid": "-3375621376413612480", "question": "list of strict nature reserve in the philippines", "gold_answers": ["Lake Malimanga", "Palawan", "Calavite and FB Harrison", "Olango Island", "Calauit Safari Park", "Lake Buluan"], "shots": {"0": {"k": 0, "answer": "Verde Island Passage, Mayon Volcano, El Nido Managed Resource Protected Area", "latency_ms": 7498.624801635742, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Masungi Rock", "latency_ms": 2318.176507949829, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2823.587417602539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2609.416961669922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1946}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2717.9129123687744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2599}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1921.638011932373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3282}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2563.387155532837, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3903}}}
{"qid": "-7848107192827858958", "question": "where do the events in the story take place geographically", "gold_answers": ["Persia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2737.449884414673, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Peloponnese and Ionian Islands", "latency_ms": 3986.7184162139893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "Peloponnese and Ionian Islands", "latency_ms": 3169.377565383911, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Peloponnese and Ionian Islands", "latency_ms": 3618.1468963623047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "Peloponnese and Ionian Islands", "latency_ms": 4075.4995346069336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2577}, "5": {"k": 5, "answer": "Peloponnese and Ionian Islands", "latency_ms": 4240.674018859863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3176}, "6": {"k": 6, "answer": "Peloponnese, Ionian Islands, Troy, Phoenicia, Egypt, Crete.", "latency_ms": 7389.516353607178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3797}}}
{"qid": "-5123704261908217758", "question": "how and why were serial novels a phenomenon in the nineteenth century", "gold_answers": ["improved economics of distribution", "the rise of literacy", "technological advances in printing"], "shots": {"0": {"k": 0, "answer": "Cheap printing technology", "latency_ms": 2350.194215774536, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "serialization and audience reaction", "latency_ms": 2192.9986476898193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "installments and audience reaction", "latency_ms": 3598.9177227020264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1378}, "3": {"k": 3, "answer": "serialization and part-publication", "latency_ms": 3238.347053527832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2047}, "4": {"k": 4, "answer": "audience reaction and part-publication", "latency_ms": 3052.881956100464, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2767}, "5": {"k": 5, "answer": "Responding to audience reaction and increasing circulation.", "latency_ms": 4442.796468734741, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3420}, "6": {"k": 6, "answer": "serialization and audience reaction", "latency_ms": 2663.175582885742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4109}}}
{"qid": "8893432128322519771", "question": "who eliminated costa rica in world cup 2014", "gold_answers": ["Netherlands"], "shots": {"0": {"k": 0, "answer": "Netherlands", "latency_ms": 1206.8369388580322, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Netherlands", "latency_ms": 1994.4205284118652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "Netherlands", "latency_ms": 1485.5968952178955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Netherlands", "latency_ms": 929.5156002044678, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1889}, "4": {"k": 4, "answer": "Netherlands", "latency_ms": 2317.1327114105225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2492}, "5": {"k": 5, "answer": "Netherlands", "latency_ms": 1738.759994506836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3122}, "6": {"k": 6, "answer": "Netherlands", "latency_ms": 1254.9245357513428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3739}}}
{"qid": "-1356405650810931451", "question": "how many countries touches the land boundary of india", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "6", "latency_ms": 727.4770736694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "6", "latency_ms": 1212.7556800842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "6", "latency_ms": 1702.7063369750977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "6", "latency_ms": 974.0097522735596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1990}, "4": {"k": 4, "answer": "6", "latency_ms": 1774.916172027588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2749}, "5": {"k": 5, "answer": "6", "latency_ms": 1209.8493576049805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3420}, "6": {"k": 6, "answer": "6", "latency_ms": 1497.7807998657227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4054}}}
{"qid": "6447777231012695504", "question": "who was the 11th prime minister of canada", "gold_answers": ["R.B. Bennett", "Arthur Meighen"], "shots": {"0": {"k": 0, "answer": "William Lyon Mackenzie King", "latency_ms": 2017.829418182373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2977.5757789611816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2630.3670406341553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1381}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2931.5130710601807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2023}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3184.9234104156494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2665}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1948.7414360046387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3380}, "6": {"k": 6, "answer": "William Lyon Mackenzie King", "latency_ms": 2363.0318641662598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4034}}}
{"qid": "-5935683210985272192", "question": "when did the steel mills closed in youngstown ohio", "gold_answers": ["September 19 , 1977"], "shots": {"0": {"k": 0, "answer": "1977", "latency_ms": 1605.9620380401611, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1984", "latency_ms": 1232.067346572876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "1984", "latency_ms": 1509.2582702636719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "1977", "latency_ms": 2043.3106422424316, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "September 19, 1977", "latency_ms": 3851.5677452087402, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2644}, "5": {"k": 5, "answer": "Late 1970s", "latency_ms": 2472.6691246032715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3235}, "6": {"k": 6, "answer": "Late 1970s", "latency_ms": 2483.952283859253, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3935}}}
{"qid": "1834961239491311230", "question": "who owns and operates the panama canal today", "gold_answers": ["Panama Canal Authority", "Panama", "Panamanian government"], "shots": {"0": {"k": 0, "answer": "The Panama Canal Authority", "latency_ms": 3180.3176403045654, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kansas City Southern and Mi-Jack Products", "latency_ms": 3726.398229598999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "Panama Canal Authority", "latency_ms": 2110.8126640319824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Panama Canal Authority", "latency_ms": 2368.804931640625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Panamanian government", "latency_ms": 2437.317132949829, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Panamanian government", "latency_ms": 2655.045747756958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3306}, "6": {"k": 6, "answer": "Panamanian government", "latency_ms": 2963.3500576019287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "-535648230475805474", "question": "where is a simple gear train used in real life", "gold_answers": ["Automobile drivetrains"], "shots": {"0": {"k": 0, "answer": "Bicycle", "latency_ms": 1250.1115798950195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2936.0029697418213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2569.307565689087, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1224}, "3": {"k": 3, "answer": "automobile manual transmission", "latency_ms": 2622.0614910125732, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1842}, "4": {"k": 4, "answer": "Automobile manual transmission", "latency_ms": 2560.793876647949, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2430}, "5": {"k": 5, "answer": "Automobile manual transmission", "latency_ms": 2935.7552528381348, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3080}, "6": {"k": 6, "answer": "Automobile manual transmission", "latency_ms": 2613.645315170288, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3672}}}
{"qid": "8911390210346559626", "question": "who plays the dad in malcom in the middle", "gold_answers": ["Bryan Cranston"], "shots": {"0": {"k": 0, "answer": "Bryan Cranston", "latency_ms": 2152.108907699585, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bryan Cranston", "latency_ms": 3376.270532608032, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "Bryan Cranston", "latency_ms": 2431.7715167999268, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Bryan Cranston", "latency_ms": 2920.2589988708496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Bryan Cranston", "latency_ms": 1896.8753814697266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2537}, "5": {"k": 5, "answer": "Bryan Cranston", "latency_ms": 1915.8263206481934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3155}, "6": {"k": 6, "answer": "Bryan Cranston", "latency_ms": 2563.8701915740967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3820}}}
{"qid": "-8336776482564898273", "question": "who has won the most world series in baseball", "gold_answers": ["the New York Yankees", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "New York Yankees", "latency_ms": 1056.5941333770752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yogi Berra and Frankie Crosetti", "latency_ms": 3852.091073989868, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Yogi Berra and Frankie Crosetti", "latency_ms": 4068.483352661133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "New York Yankees", "latency_ms": 1611.7217540740967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1795}, "4": {"k": 4, "answer": "New York Yankees", "latency_ms": 2140.025854110718, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2402}, "5": {"k": 5, "answer": "New York Yankees", "latency_ms": 1825.7603645324707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3022}, "6": {"k": 6, "answer": "New York Yankees", "latency_ms": 2134.4544887542725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3707}}}
{"qid": "-8742089114148260796", "question": "where are the winter olympic games being played", "gold_answers": ["Beijing"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2210.5300426483154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sapporo, Nagano, and East Asia", "latency_ms": 4001.6374588012695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Sapporo, Nagano, Seoul, Tokyo, Beijing, Vancouver", "latency_ms": 6005.981683731079, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1278}, "3": {"k": 3, "answer": "East Asia", "latency_ms": 2087.2528553009033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1936}, "4": {"k": 4, "answer": "Various locations.", "latency_ms": 1557.323932647705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2532}, "5": {"k": 5, "answer": "Various locations.", "latency_ms": 1760.3480815887451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3130}, "6": {"k": 6, "answer": "Various locations.", "latency_ms": 2340.900421142578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3784}}}
{"qid": "3864930130255054488", "question": "who made the song falling in love with you", "gold_answers": ["Hugo Peretti", "Elvis Presley", "George David Weiss", "Luigi Creatore"], "shots": {"0": {"k": 0, "answer": "UB40", "latency_ms": 2066.007375717163, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 5311.391592025757, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 594}, "2": {"k": 2, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 5058.297872543335, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 5162.77551651001, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 6545.152187347412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2447}, "5": {"k": 5, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 5063.575506210327, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3031}, "6": {"k": 6, "answer": "Carl Perkins, Bill Cantrell, and Quinton Claunch.", "latency_ms": 6249.45855140686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3637}}}
{"qid": "8076743617384207713", "question": "where did saudi crown prince go to college", "gold_answers": ["King Saud University"], "shots": {"0": {"k": 0, "answer": "King Saud University", "latency_ms": 2091.9673442840576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2502.5832653045654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1581.9447040557861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1378}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2584.4924449920654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2574.6705532073975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "King Saud University", "latency_ms": 2008.5008144378662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3218}, "6": {"k": 6, "answer": "King Saud University", "latency_ms": 1849.1885662078857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3797}}}
{"qid": "1735766792677422630", "question": "who did the singing in into the woods", "gold_answers": ["the cast", "the cast members"], "shots": {"0": {"k": 0, "answer": "Meryl Streep", "latency_ms": 1950.319766998291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "All join in", "latency_ms": 1887.0525360107422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "the cast", "latency_ms": 1015.4883861541748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "the cast", "latency_ms": 2041.19873046875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1901}, "4": {"k": 4, "answer": "Bernadette Peters", "latency_ms": 1604.6595573425293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2526}, "5": {"k": 5, "answer": "the cast", "latency_ms": 920.182466506958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3100}, "6": {"k": 6, "answer": "the cast", "latency_ms": 2061.1820220947266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3699}}}
{"qid": "5711801828691961426", "question": "who was the viceroy when the simon commission visited india", "gold_answers": ["Lord Irwin"], "shots": {"0": {"k": 0, "answer": "Lord Irwin", "latency_ms": 944.2472457885742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lord Irwin", "latency_ms": 1852.0441055297852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "Lord Irwin", "latency_ms": 1582.129955291748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Lord Irwin", "latency_ms": 2099.8780727386475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Lord Irwin", "latency_ms": 2683.4096908569336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Lord Irwin", "latency_ms": 1901.3655185699463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3294}, "6": {"k": 6, "answer": "Lord Irwin", "latency_ms": 1841.329574584961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3890}}}
{"qid": "9001143341771379731", "question": "who in germany signed the treaty of versailles", "gold_answers": ["colonial minister Johannes Bell", "Foreign minister Hermann Mller", "Gustav Bauer"], "shots": {"0": {"k": 0, "answer": "Ulrich Graf von Brockdorff-Rantzau", "latency_ms": 3313.0171298980713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 2963.97066116333, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 3057.3596954345703, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 2130.380392074585, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 2471.7020988464355, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 3173.043727874756, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 3252.0065307617188, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3769}}}
{"qid": "-4619585332904698754", "question": "who holds the record for most platinum albums", "gold_answers": ["The Beatles", "AC / DC", "Elvis Presley"], "shots": {"0": {"k": 0, "answer": "The Beatles", "latency_ms": 1780.839204788208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elvis Presley", "latency_ms": 1458.2209587097168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Elvis Presley", "latency_ms": 1939.7826194763184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1273}, "3": {"k": 3, "answer": "Elvis Presley", "latency_ms": 2585.0424766540527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1965}, "4": {"k": 4, "answer": "Elvis Presley", "latency_ms": 2451.5676498413086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2614}, "5": {"k": 5, "answer": "Elvis Presley", "latency_ms": 1948.7802982330322, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3256}, "6": {"k": 6, "answer": "Elvis Presley", "latency_ms": 2253.33833694458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3921}}}
{"qid": "-720512252272678238", "question": "when did the movie the post begin filming", "gold_answers": ["May 30 , 2017", "May 2017"], "shots": {"0": {"k": 0, "answer": "May 30, 2016", "latency_ms": 3039.1430854797363, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2231.5468788146973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2410.010576248169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1861.7229461669922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2880.9492588043213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2613}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2968.101739883423, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3181}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2945.49822807312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3814}}}
{"qid": "-3371798557886238687", "question": "who starred in an officer and a gentleman", "gold_answers": ["Louis Gossett Jr .", "David Keith", "Louis Gossett Jr.", "Richard Gere", "Debra Winger", "Phillip J. Salmon"], "shots": {"0": {"k": 0, "answer": "Richard Gere", "latency_ms": 1616.2998676300049, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 5433.471918106079, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 7261.326551437378, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 6157.088756561279, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 5393.46170425415, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 5929.845809936523, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3132}, "6": {"k": 6, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 6896.287679672241, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3788}}}
