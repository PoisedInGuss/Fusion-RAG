{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 1396.1241245269775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Molly", "latency_ms": 1802.4415969848633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2734.550714492798, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Molly", "latency_ms": 2049.1509437561035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1880}, "4": {"k": 4, "answer": "Geraldine Somerville", "latency_ms": 2827.0771503448486, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Geraldine Somerville", "latency_ms": 2144.4127559661865, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3162}, "6": {"k": 6, "answer": "Geraldine Somerville", "latency_ms": 2442.753314971924, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3808}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 2255.1066875457764, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 1701.8663883209229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 2969.64955329895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 2169.4936752319336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 2952.219009399414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 3012.836456298828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 2773.979663848877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3873}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwest desert regions", "latency_ms": 2435.0719451904297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4440.699338912964, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4613.655805587769, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4050.833225250244, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 4362.099170684814, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2628}, "5": {"k": 5, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 4306.741237640381, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3232}, "6": {"k": 6, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 5789.724349975586, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3902}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 3400.836944580078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dr. Rajendra Prasad", "latency_ms": 2863.619565963745, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 743}, "2": {"k": 2, "answer": "Dr. Rajendra Prasad", "latency_ms": 3309.624671936035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1429}, "3": {"k": 3, "answer": "Dr. Rajendra Prasad", "latency_ms": 3083.240270614624, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2114}, "4": {"k": 4, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 4030.7626724243164, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2812}, "5": {"k": 5, "answer": "Dr. Rajendra Prasad", "latency_ms": 3202.979803085327, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3511}, "6": {"k": 6, "answer": "Dr. Rajendra Prasad", "latency_ms": 2526.3984203338623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4149}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2147.697687149048, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2694.1401958465576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2709.7208499908447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2191.8745040893555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2143.0325508117676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2602}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3642.077922821045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3245}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2603.914499282837, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3912}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "June 22, 2001", "latency_ms": 4806.523323059082, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2695.474147796631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1713.5097980499268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "2001", "latency_ms": 2018.2538032531738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "2001", "latency_ms": 1024.6782302856445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2539}, "5": {"k": 5, "answer": "2001", "latency_ms": 2267.2080993652344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3154}, "6": {"k": 6, "answer": "2001", "latency_ms": 1691.6065216064453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3785}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2928.4918308258057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 4493.665456771851, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 3908.6692333221436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 3381.314516067505, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 3104.67267036438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2739}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 4629.27508354187, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3372}, "6": {"k": 6, "answer": "September 27, 2017", "latency_ms": 4542.207956314087, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4078}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3", "latency_ms": 1539.63303565979, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sectionals", "latency_ms": 1027.390718460083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Sectionals", "latency_ms": 1976.9573211669922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "Sectionals", "latency_ms": 1213.5975360870361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Sectionals", "latency_ms": 1363.5010719299316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2462}, "5": {"k": 5, "answer": "Sectionals", "latency_ms": 1512.704849243164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3053}, "6": {"k": 6, "answer": "In \"Sectionals\"", "latency_ms": 3512.197256088257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3642}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 3138.8561725616455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2630.662441253662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2479.390859603882, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1620.4068660736084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1633.9082717895508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2987.8058433532715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3188}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2670.2277660369873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3792}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 1622.9560375213623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "the harbor", "latency_ms": 1471.0359573364258, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Havana Harbor, Cuba", "latency_ms": 2079.6096324920654, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Havana Harbor, Cuba", "latency_ms": 2701.016426086426, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1852}, "4": {"k": 4, "answer": "Havana Harbor, Cuba", "latency_ms": 2540.574073791504, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Havana Harbor, Cuba", "latency_ms": 2580.7204246520996, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3051}, "6": {"k": 6, "answer": "Havana Harbor, Cuba", "latency_ms": 2886.1653804779053, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3692}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 2456.2695026397705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2881.528377532959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2677.3223876953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "No specific god mentioned", "latency_ms": 2728.5549640655518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1935}, "4": {"k": 4, "answer": "None mentioned", "latency_ms": 1786.5421772003174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Lord Vishnu and Lord Shiva", "latency_ms": 2848.3152389526367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3238}, "6": {"k": 6, "answer": "Lord Vishnu and Lord Shiva", "latency_ms": 3163.8903617858887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 3365.3950691223145, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "All of them", "latency_ms": 2710.5157375335693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Costa Rica, Nicaragua, Panama, Honduras, Guatemala, El Salvador, Belize", "latency_ms": 6873.249769210815, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1322}, "3": {"k": 3, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 2374.5486736297607, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2020}, "4": {"k": 4, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 3725.9151935577393, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2639}, "5": {"k": 5, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 4359.231472015381, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3331}, "6": {"k": 6, "answer": "Costa Rica, Nicaragua, Panama, El Salvador, Honduras, Guatemala, Belize", "latency_ms": 6191.57600402832, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 4016}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence.", "latency_ms": 1453.0229568481445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 1490.1034832000732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 704}, "2": {"k": 2, "answer": "Complex sentence", "latency_ms": 2299.316644668579, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1368}, "3": {"k": 3, "answer": "Complex sentence", "latency_ms": 783.7245464324951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2027}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 1304.7058582305908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2683}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 2070.575952529907, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3371}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 1293.9813137054443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4053}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and trade.", "latency_ms": 1593.569278717041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 3619.562864303589, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3163.588762283325, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 4290.712833404541, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1942}, "4": {"k": 4, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3774.585723876953, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 2533}, "5": {"k": 5, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 4288.012742996216, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "the nature and causes of the wealth of nations", "latency_ms": 5135.072946548462, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3840}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 2423.2418537139893, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "August 28, 2018", "latency_ms": 3430.7305812835693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "August 28, 2018", "latency_ms": 4379.149913787842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 4381.8299770355225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 4324.5673179626465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2494}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 3964.939594268799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3109}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 4397.375822067261, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3733}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere", "latency_ms": 3404.2160511016846, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northern Territory", "latency_ms": 1265.5537128448486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "Northern Territory", "latency_ms": 1408.0677032470703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Northern Territory of Australia", "latency_ms": 2141.974925994873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1998}, "4": {"k": 4, "answer": "Northern Territory of Australia", "latency_ms": 2867.914915084839, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2707}, "5": {"k": 5, "answer": "Northern Territory and Western Australia", "latency_ms": 1494.8484897613525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3360}, "6": {"k": 6, "answer": "Oceania between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 7163.907051086426, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4002}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Leia Organa", "latency_ms": 1870.8531856536865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2501.9893646240234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "her", "latency_ms": 1165.2493476867676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "her", "latency_ms": 1682.5928688049316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "her", "latency_ms": 920.210599899292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2436}, "5": {"k": 5, "answer": "Her", "latency_ms": 1221.311330795288, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2972}, "6": {"k": 6, "answer": "Her", "latency_ms": 973.0968475341797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3543}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 984.53688621521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Barry Cryer", "latency_ms": 2524.7180461883545, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 548}, "2": {"k": 2, "answer": "Barry Cryer", "latency_ms": 2877.490758895874, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1196}, "3": {"k": 3, "answer": "Barry Cryer", "latency_ms": 2403.7535190582275, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1779}, "4": {"k": 4, "answer": "Barry Cryer", "latency_ms": 2665.2393341064453, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2329}, "5": {"k": 5, "answer": "Barry Cryer", "latency_ms": 1899.2154598236084, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2924}, "6": {"k": 6, "answer": "Barry Cryer", "latency_ms": 2445.8460807800293, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3517}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 2388.141870498657, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chloroplast", "latency_ms": 1570.3542232513428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Chloroplast and Mitochondrion", "latency_ms": 2900.327205657959, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1366}, "3": {"k": 3, "answer": "Chloroplasts and Mitochondria", "latency_ms": 4173.646688461304, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2042}, "4": {"k": 4, "answer": "Chloroplasts and Mitochondria", "latency_ms": 2950.1123428344727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2693}, "5": {"k": 5, "answer": "Mitochondria and Chloroplasts", "latency_ms": 3361.1042499542236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3385}, "6": {"k": 6, "answer": "Mitochondria and Chloroplasts", "latency_ms": 3993.5567378997803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4042}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Backup.", "latency_ms": 5964.728832244873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3214.0002250671387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2120.9726333618164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1462}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2557.1815967559814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2155}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2893.3260440826416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2838}, "5": {"k": 5, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 4127.372741699219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3533}, "6": {"k": 6, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 4550.700426101685, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4172}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 1904.9546718597412, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3594.2554473876953, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 590}, "2": {"k": 2, "answer": "Kenny Rogers and Dottie West", "latency_ms": 2609.6906661987305, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Kenny Rogers and Dottie West", "latency_ms": 2842.9462909698486, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "Dottie West and Kenny Rogers", "latency_ms": 3212.846040725708, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2421}, "5": {"k": 5, "answer": "Dottie West and Kenny Rogers", "latency_ms": 3062.9405975341797, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3008}, "6": {"k": 6, "answer": "Dottie West and Kenny Rogers", "latency_ms": 2727.776050567627, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3618}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 1815.6764507293701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "36 months", "latency_ms": 1765.8686637878418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 601}, "2": {"k": 2, "answer": "36 months", "latency_ms": 2090.5957221984863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "36 months", "latency_ms": 1019.0446376800537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1911}, "4": {"k": 4, "answer": "36 months old", "latency_ms": 2481.992244720459, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2546}, "5": {"k": 5, "answer": "36 months old", "latency_ms": 2056.1530590057373, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3129}, "6": {"k": 6, "answer": "36 months", "latency_ms": 1777.3892879486084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3707}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 743.154764175415, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Three", "latency_ms": 1008.5937976837158, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Three-part", "latency_ms": 1479.830026626587, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Three", "latency_ms": 1740.537166595459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Three", "latency_ms": 987.9541397094727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2580}, "5": {"k": 5, "answer": "Three", "latency_ms": 1269.3614959716797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "Three", "latency_ms": 731.6751480102539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3868}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 6409.80863571167, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elijah Wood", "latency_ms": 2336.886405944824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Elijah Wood", "latency_ms": 1877.617597579956, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1293}, "3": {"k": 3, "answer": "Elijah Wood", "latency_ms": 2131.960153579712, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1967}, "4": {"k": 4, "answer": "Elijah Wood", "latency_ms": 2048.8288402557373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Elijah Wood", "latency_ms": 2373.0766773223877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3159}, "6": {"k": 6, "answer": "Elijah Wood", "latency_ms": 2087.3770713806152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3812}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party", "latency_ms": 1763.143539428711, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume party", "latency_ms": 2832.2744369506836, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Costume party", "latency_ms": 1895.7083225250244, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Costume party", "latency_ms": 1528.2537937164307, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1971}, "4": {"k": 4, "answer": "Costume", "latency_ms": 1971.0540771484375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2542}, "5": {"k": 5, "answer": "Costume party", "latency_ms": 2096.5516567230225, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3111}, "6": {"k": 6, "answer": "Costume party", "latency_ms": 2405.7247638702393, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3774}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 965.1064872741699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One", "latency_ms": 1188.2073879241943, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "One", "latency_ms": 1287.6181602478027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1204}, "3": {"k": 3, "answer": "One", "latency_ms": 1442.528247833252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1902}, "4": {"k": 4, "answer": "One", "latency_ms": 945.181131362915, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2534}, "5": {"k": 5, "answer": "One", "latency_ms": 2311.259984970093, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3222}, "6": {"k": 6, "answer": "One", "latency_ms": 1197.162389755249, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3848}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "He promised Fantine", "latency_ms": 2226.494073867798, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fantine's debts", "latency_ms": 2991.3039207458496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "Fantine's debts", "latency_ms": 2736.499071121216, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Fantine's debts", "latency_ms": 3044.6598529815674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "Fantine's debts", "latency_ms": 1990.8833503723145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2449}, "5": {"k": 5, "answer": "Fantine's request", "latency_ms": 2771.4695930480957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3047}, "6": {"k": 6, "answer": "Fantine's request", "latency_ms": 2666.7749881744385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3633}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, and South Korea.", "latency_ms": 3304.4002056121826, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenya", "latency_ms": 1724.3585586547852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "Kenya", "latency_ms": 2572.5226402282715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1382}, "3": {"k": 3, "answer": "Kenya and India", "latency_ms": 2782.9320430755615, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Kenya and India", "latency_ms": 2071.718215942383, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2711}, "5": {"k": 5, "answer": "Kenya, India, Russia", "latency_ms": 4382.421493530273, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3412}, "6": {"k": 6, "answer": "Kenya, India, Russia", "latency_ms": 3308.192014694214, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4097}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and control.", "latency_ms": 3570.2335834503174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to consolidate Bantu education", "latency_ms": 3544.550895690918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 714}, "2": {"k": 2, "answer": "to consolidate Bantu education", "latency_ms": 2343.5065746307373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1413}, "3": {"k": 3, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7907.228946685791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7201.549291610718, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 8197.134256362915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 8430.3879737854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4119}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 3179.97670173645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 2855.182647705078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 3059.936046600342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Huge and powerful snake", "latency_ms": 2683.283567428589, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1759}, "4": {"k": 4, "answer": "Python", "latency_ms": 668.7438488006592, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2384}, "5": {"k": 5, "answer": "Python", "latency_ms": 2562.311887741089, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "Python", "latency_ms": 1200.9217739105225, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3613}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 1076.0893821716309, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "water-ice", "latency_ms": 1341.001033782959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "water-ice", "latency_ms": 808.713436126709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "water-ice", "latency_ms": 2590.473413467407, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "water-ice", "latency_ms": 2048.7921237945557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2382}, "5": {"k": 5, "answer": "water-ice", "latency_ms": 1797.806978225708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3031}, "6": {"k": 6, "answer": "water-ice", "latency_ms": 1568.5734748840332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3646}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 3337.796688079834, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Not in season 2.", "latency_ms": 3346.0299968719482, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "The Departed episode", "latency_ms": 1425.27437210083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "The Departed episode", "latency_ms": 3204.127788543701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "At the end of season 3", "latency_ms": 3178.7123680114746, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2382}, "5": {"k": 5, "answer": "Season 3 finale", "latency_ms": 1742.661714553833, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2999}, "6": {"k": 6, "answer": "Season 3 finale", "latency_ms": 2219.287395477295, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3561}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "Home team", "latency_ms": 1563.1675720214844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "BBC", "latency_ms": 1413.4700298309326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 581}, "2": {"k": 2, "answer": "BBC", "latency_ms": 1189.6965503692627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1161}, "3": {"k": 3, "answer": "BBC", "latency_ms": 969.3422317504883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1767}, "4": {"k": 4, "answer": "BBC", "latency_ms": 1157.2532653808594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2382}, "5": {"k": 5, "answer": "BBC", "latency_ms": 1088.0632400512695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2972}, "6": {"k": 6, "answer": "BBC", "latency_ms": 1689.107894897461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3563}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw neighborhood", "latency_ms": 2425.5309104919434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northwest", "latency_ms": 1754.0574073791504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "Northwest", "latency_ms": 1509.936809539795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Northwest", "latency_ms": 2023.2629776000977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "Northwest Washington, DC", "latency_ms": 1654.675006866455, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2689}, "5": {"k": 5, "answer": "Northwest Washington, DC", "latency_ms": 2940.8349990844727, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3480}, "6": {"k": 6, "answer": "Northwest", "latency_ms": 935.6541633605957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4172}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 2928.0481338500977, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noahic", "latency_ms": 1849.7965335845947, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "Noahic", "latency_ms": 1849.3895530700684, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Noahic", "latency_ms": 1594.4762229919434, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1878}, "4": {"k": 4, "answer": "Noahic", "latency_ms": 2294.0073013305664, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2434}, "5": {"k": 5, "answer": "Noahic", "latency_ms": 2058.3808422088623, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3042}, "6": {"k": 6, "answer": "Noahic", "latency_ms": 1838.9625549316406, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3714}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 2449.3868350982666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2438.124895095825, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2112.229347229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1164}, "3": {"k": 3, "answer": "Jack Jones", "latency_ms": 1814.5394325256348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1735}, "4": {"k": 4, "answer": "a singer", "latency_ms": 1585.127592086792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2338}, "5": {"k": 5, "answer": "a singer", "latency_ms": 1432.2338104248047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2911}, "6": {"k": 6, "answer": "a singer", "latency_ms": 2285.8028411865234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3508}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2026.28755569458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rudy Vallée", "latency_ms": 2912.0547771453857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "Ray Henderson", "latency_ms": 1477.914571762085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Ray Henderson", "latency_ms": 2029.8621654510498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Rudy Vallée", "latency_ms": 3296.20623588562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2437}, "5": {"k": 5, "answer": "Rudy Vallée", "latency_ms": 3061.481714248657, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3088}, "6": {"k": 6, "answer": "Rudy Vallée", "latency_ms": 2672.9142665863037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3682}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 2300.1368045806885, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 1501.5480518341064, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 2043.663501739502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 1535.3808403015137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 2135.469436645508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 2085.2744579315186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3176}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 1256.1607360839844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3827}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "Second", "latency_ms": 1509.7181797027588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "16.5 million to 27 people", "latency_ms": 3605.337619781494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "50 million", "latency_ms": 2021.7719078063965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1332}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3501.136541366577, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1997}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2470.283269882202, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2201.5113830566406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3236}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2393.531322479248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3787}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 2378.9525032043457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mahatma Gandhi", "latency_ms": 2518.0177688598633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 706}, "2": {"k": 2, "answer": "Mahatma Gandhi", "latency_ms": 3201.7009258270264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1428}, "3": {"k": 3, "answer": "Mahatma Gandhi", "latency_ms": 3206.2735557556152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2124}, "4": {"k": 4, "answer": "Sonia Gandhi", "latency_ms": 1877.9256343841553, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2798}, "5": {"k": 5, "answer": "Sonia Gandhi", "latency_ms": 2615.9729957580566, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3512}, "6": {"k": 6, "answer": "Jawaharlal Nehru", "latency_ms": 3295.787811279297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4187}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenifer Lewis", "latency_ms": 2430.976152420044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bobby Flay", "latency_ms": 2824.327230453491, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Bobby Flay", "latency_ms": 3043.9674854278564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "Bobby Flay", "latency_ms": 2457.3025703430176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Bobby Flay", "latency_ms": 3859.3478202819824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2536}, "5": {"k": 5, "answer": "Bobby Flay", "latency_ms": 3004.3468475341797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3144}, "6": {"k": 6, "answer": "Bobby Flay", "latency_ms": 2268.9173221588135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 1467.1027660369873, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 1205.425500869751, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": ".java", "latency_ms": 1917.8369045257568, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": ".java", "latency_ms": 1107.680082321167, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": ".java", "latency_ms": 1702.759027481079, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": ".java", "latency_ms": 1394.1893577575684, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3240}, "6": {"k": 6, "answer": ".java", "latency_ms": 2028.1741619110107, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3959}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 1246.0129261016846, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Poland", "latency_ms": 1802.1845817565918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Poland", "latency_ms": 1772.1726894378662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "Poland", "latency_ms": 1585.1707458496094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 1972.435474395752, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 1411.3192558288574, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3325}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 1275.1593589782715, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3955}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline", "latency_ms": 2132.263660430908, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ensure party members adhere to party policies", "latency_ms": 3623.2821941375732, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "ensure members adhere to party policies", "latency_ms": 2826.4031410217285, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "ensure party cohesion and enforce party policies", "latency_ms": 2591.582775115967, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "ensure party cohesion and voting", "latency_ms": 2158.623218536377, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 2586}, "5": {"k": 5, "answer": "ensure party cohesion and voting", "latency_ms": 2434.2687129974365, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3279}, "6": {"k": 6, "answer": "ensure party cohesion and voting", "latency_ms": 3296.71573638916, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3986}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 1402.42600440979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2672.471523284912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "1973", "latency_ms": 1310.7426166534424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "1973", "latency_ms": 2039.628505706787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1814}, "4": {"k": 4, "answer": "1973", "latency_ms": 1779.019832611084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "1973", "latency_ms": 1278.8004875183105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2973}, "6": {"k": 6, "answer": "1973", "latency_ms": 2133.0525875091553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3664}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the​ right but not the​ obligation to buy foreign​ currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 2272.077798843384, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 1229.1464805603027, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 1836.4899158477783, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 2554.3599128723145, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "FX option", "latency_ms": 1461.4415168762207, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2617}, "5": {"k": 5, "answer": "Call option", "latency_ms": 1307.1925640106201, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "FX option", "latency_ms": 2021.3899612426758, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3842}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 1183.2995414733887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 1460.087776184082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360", "latency_ms": 2526.9336700439453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1380}, "3": {"k": 3, "answer": "360", "latency_ms": 1462.4989032745361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2035}, "4": {"k": 4, "answer": "360 members", "latency_ms": 1526.3564586639404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "360 members", "latency_ms": 1762.6917362213135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3315}, "6": {"k": 6, "answer": "360 members", "latency_ms": 2021.432638168335, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3957}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 2711.073637008667, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 2674.9446392059326, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 2459.872007369995, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 2390.2716636657715, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 2153.1569957733154, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2583}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 2405.4088592529297, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3251}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 2390.8352851867676, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3892}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gormé"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 2828.45139503479, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eydie Gormé", "latency_ms": 4006.6802501678467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 580}, "2": {"k": 2, "answer": "Eydie Gormé", "latency_ms": 2959.907054901123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1156}, "3": {"k": 3, "answer": "Eydie Gormé", "latency_ms": 2902.6520252227783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1757}, "4": {"k": 4, "answer": "Eydie Gormé", "latency_ms": 3506.903886795044, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2334}, "5": {"k": 5, "answer": "Eydie Gormé", "latency_ms": 4070.948362350464, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2965}, "6": {"k": 6, "answer": "Eydie Gormé", "latency_ms": 3531.4440727233887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3530}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2456.395387649536, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "H.L. Dattu", "latency_ms": 3112.358808517456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "Mohan Shantanagoudar", "latency_ms": 3477.3263931274414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Mohan Shantanagoudar", "latency_ms": 4075.774908065796, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1782}, "4": {"k": 4, "answer": "Mohan Shantanagoudar", "latency_ms": 4066.0457611083984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2394}, "5": {"k": 5, "answer": "Mohan Shantanagoudar", "latency_ms": 3895.336151123047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2958}, "6": {"k": 6, "answer": "Mohan Shantanagoudar", "latency_ms": 2888.8673782348633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3623}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2674.790382385254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nadal", "latency_ms": 1760.5094909667969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 576}, "2": {"k": 2, "answer": "Nadal", "latency_ms": 1076.4641761779785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "Nadal", "latency_ms": 2078.7081718444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "Rafael Nadal", "latency_ms": 3349.246025085449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2490}, "5": {"k": 5, "answer": "Rafael Nadal", "latency_ms": 3733.318090438843, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3081}, "6": {"k": 6, "answer": "Rafael Nadal", "latency_ms": 2723.457098007202, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3713}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 1242.8407669067383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 977.614164352417, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 1279.6425819396973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1228}, "3": {"k": 3, "answer": "1", "latency_ms": 1193.4177875518799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "1", "latency_ms": 1705.883264541626, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2418}, "5": {"k": 5, "answer": "1", "latency_ms": 1182.4250221252441, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3025}, "6": {"k": 6, "answer": "1", "latency_ms": 1946.2199211120605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3624}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 2063.856840133667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2010", "latency_ms": 2065.3960704803467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "2010", "latency_ms": 2069.8280334472656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1304}, "3": {"k": 3, "answer": "2010", "latency_ms": 2299.4375228881836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "2010", "latency_ms": 1117.7730560302734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2522}, "5": {"k": 5, "answer": "2010", "latency_ms": 1548.0763912200928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3137}, "6": {"k": 6, "answer": "2010", "latency_ms": 2026.04079246521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3712}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 1375.485897064209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2428.934335708618, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "37", "latency_ms": 938.0588531494141, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "37 is incorrect, the correct answer is not in the provided context for the total, but for swimming: 5", "latency_ms": 10243.241310119629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "37", "latency_ms": 1505.4059028625488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "37", "latency_ms": 1242.2430515289307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3152}, "6": {"k": 6, "answer": "37", "latency_ms": 1245.819091796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3821}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 2580.3213119506836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 3281.1617851257324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 2808.490753173828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 3034.381628036499, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 2672.661304473877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2502}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 2762.9122734069824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 2496.9425201416016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3804}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 4297.405242919922, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 2238.072633743286, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "Corey", "latency_ms": 1522.308111190796, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "Corey, Cory", "latency_ms": 3157.3214530944824, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1809}, "4": {"k": 4, "answer": "Corey, Cory", "latency_ms": 2930.7632446289062, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2445}, "5": {"k": 5, "answer": "Corey, Cory", "latency_ms": 2135.0085735321045, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3018}, "6": {"k": 6, "answer": "Corey, Cory", "latency_ms": 3267.7507400512695, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3581}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 1366.5621280670166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Toby Keith", "latency_ms": 2660.1946353912354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Toby Keith", "latency_ms": 2509.359359741211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Toby Keith", "latency_ms": 2941.004753112793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Toby Keith", "latency_ms": 2879.5182704925537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2432}, "5": {"k": 5, "answer": "Toby Keith", "latency_ms": 1945.063829421997, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3144}, "6": {"k": 6, "answer": "Toby Keith", "latency_ms": 1846.13037109375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3746}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 729.1247844696045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 1873.1279373168945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "159", "latency_ms": 1330.7454586029053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "159", "latency_ms": 1165.022373199463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "159", "latency_ms": 1638.8976573944092, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2738}, "5": {"k": 5, "answer": "159", "latency_ms": 1482.9273223876953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3362}, "6": {"k": 6, "answer": "159", "latency_ms": 1783.8053703308105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3997}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 2210.4125022888184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Egan", "latency_ms": 1883.9995861053467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 581}, "2": {"k": 2, "answer": "Egan", "latency_ms": 1791.4063930511475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "Egan", "latency_ms": 1981.2171459197998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1797}, "4": {"k": 4, "answer": "Egan", "latency_ms": 1543.1456565856934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2360}, "5": {"k": 5, "answer": "Egan", "latency_ms": 2238.87300491333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2960}, "6": {"k": 6, "answer": "Egan", "latency_ms": 1809.3533515930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3572}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 1340.054988861084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2103.867292404175, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2150.3121852874756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2130.929708480835, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1777}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2468.2769775390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2375}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3137.096405029297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3043}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2258.727788925171, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3695}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 2556.809663772583, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Right hand", "latency_ms": 1971.444845199585, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 2029.2043685913086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1185}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 1271.6271877288818, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1739}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 2535.2256298065186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2293}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 1271.0967063903809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2901}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 2269.852876663208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3465}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 2426.2797832489014, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Donald Duck", "latency_ms": 1785.3598594665527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Donald Duck", "latency_ms": 1443.5267448425293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Donald Duck", "latency_ms": 2513.148069381714, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1951}, "4": {"k": 4, "answer": "Donald Duck", "latency_ms": 1987.1208667755127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2597}, "5": {"k": 5, "answer": "Donald Duck", "latency_ms": 1507.4849128723145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3236}, "6": {"k": 6, "answer": "Donald Duck", "latency_ms": 1724.092721939087, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3851}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 2112.7872467041016, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bernard Hill", "latency_ms": 1807.1627616882324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 644}, "2": {"k": 2, "answer": "Bernard Hill", "latency_ms": 2583.627462387085, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Bernard Hill", "latency_ms": 1828.549861907959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1913}, "4": {"k": 4, "answer": "Bernard Hill", "latency_ms": 2041.358232498169, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2556}, "5": {"k": 5, "answer": "Bernard Hill", "latency_ms": 2051.2630939483643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3162}, "6": {"k": 6, "answer": "Bernard Hill", "latency_ms": 2379.90140914917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3750}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2019", "latency_ms": 3872.5123405456543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2018", "latency_ms": 4095.8166122436523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 4162.18113899231, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 5193.070411682129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1787}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 4131.4263343811035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2417}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 3643.324136734009, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3034}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 4727.429151535034, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3640}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 2024.686336517334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2242.9261207580566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2941.4684772491455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3182.9781532287598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2735.4073524475098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2994.3413734436035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1972.3882675170898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3855}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 1816.0583972930908, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Claire Holt", "latency_ms": 1516.758918762207, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Claire Holt", "latency_ms": 2275.383234024048, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "Claire Holt", "latency_ms": 2388.4007930755615, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Claire Holt", "latency_ms": 1263.4837627410889, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Claire Holt", "latency_ms": 2346.1060523986816, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3111}, "6": {"k": 6, "answer": "Claire Holt", "latency_ms": 1609.269380569458, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3750}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living things", "latency_ms": 1398.2000350952148, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in wood or soil", "latency_ms": 2088.4246826171875, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 705}, "2": {"k": 2, "answer": "in wood, soil, plants, and animals' digestive tracts", "latency_ms": 5076.2763023376465, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "in wood, soil, plants, and animals", "latency_ms": 3726.027250289917, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "in plants, soil, and organisms", "latency_ms": 3172.2443103790283, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2663}, "5": {"k": 5, "answer": "in all land-living organisms, soils, plants, and animals", "latency_ms": 6327.983617782593, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3365}, "6": {"k": 6, "answer": "in all land-living organisms, soils, plants, and animals", "latency_ms": 6121.7052936553955, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4085}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2748.079299926758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chandan Shetty", "latency_ms": 2209.888696670532, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "Chandan Shetty", "latency_ms": 2961.7133140563965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Chandan Shetty", "latency_ms": 2899.620532989502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "Chandan Shetty", "latency_ms": 2459.886074066162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2509}, "5": {"k": 5, "answer": "Chandan Shetty", "latency_ms": 2134.8605155944824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3110}, "6": {"k": 6, "answer": "Chandan Shetty", "latency_ms": 2806.1482906341553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3777}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, Utah, and California", "latency_ms": 2547.9989051818848, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2938.934803009033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2517.9708003997803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3091.8993949890137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3228.4107208251953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2507}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2440.8581256866455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3126}, "6": {"k": 6, "answer": "Lake Powell", "latency_ms": 1801.8345832824707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3779}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 1107.499122619629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jesper Klein", "latency_ms": 1058.2430362701416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2379.7342777252197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2411.686658859253, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2496.689796447754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2070.0995922088623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3168}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2779.7563076019287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3827}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Lake Winnipeg", "latency_ms": 2551.3365268707275, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 1780.7559967041016, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Rocky Mountains to Lake Winnipeg", "latency_ms": 3581.4080238342285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 3263.8988494873047, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 3397.4430561065674, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2740}, "5": {"k": 5, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 2760.206460952759, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3345}, "6": {"k": 6, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 2516.5178775787354, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3989}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 1820.4033374786377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 1322.5703239440918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome", "latency_ms": 1761.4986896514893, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Rome, Italy", "latency_ms": 2708.8866233825684, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1893}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 1912.8644466400146, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2547}, "5": {"k": 5, "answer": "Rome", "latency_ms": 2325.962543487549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 3181.8692684173584, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3722}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "Measurement mark", "latency_ms": 1284.6946716308594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "manufacturing company or site", "latency_ms": 3314.650297164917, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "the manufacturing company or site", "latency_ms": 3117.4349784851074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1255}, "3": {"k": 3, "answer": "manufacturing company or site", "latency_ms": 2870.9769248962402, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "the manufacturing company or site", "latency_ms": 3087.977886199951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2466}, "5": {"k": 5, "answer": "the manufacturing company or site", "latency_ms": 2779.2201042175293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3106}, "6": {"k": 6, "answer": "the manufacturing company or site", "latency_ms": 3977.1595001220703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3727}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia", "latency_ms": 1830.7044506072998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 3711.5581035614014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 3486.562490463257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1352}, "3": {"k": 3, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 4224.047422409058, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1952}, "4": {"k": 4, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 4648.437738418579, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2562}, "5": {"k": 5, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 3994.0314292907715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3175}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 3321.3634490966797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3766}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Boy Meets Girl", "latency_ms": 1340.9922122955322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 2470.7934856414795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "1988", "latency_ms": 1532.8919887542725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "1988", "latency_ms": 1224.1029739379883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1785}, "4": {"k": 4, "answer": "1988", "latency_ms": 2040.2979850769043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2388}, "5": {"k": 5, "answer": "1988", "latency_ms": 1236.6948127746582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3016}, "6": {"k": 6, "answer": "1988", "latency_ms": 2272.1660137176514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3673}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 1264.348030090332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Truco", "latency_ms": 967.073917388916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Tute", "latency_ms": 2037.921667098999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1168}, "3": {"k": 3, "answer": "Truco", "latency_ms": 2089.3354415893555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1754}, "4": {"k": 4, "answer": "Truco", "latency_ms": 1821.3744163513184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2355}, "5": {"k": 5, "answer": "Manille", "latency_ms": 1762.3822689056396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2955}, "6": {"k": 6, "answer": "Manille", "latency_ms": 2376.659631729126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3618}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 1922.0359325408936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Five percent", "latency_ms": 1613.7254238128662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "5%", "latency_ms": 2188.4944438934326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "2% to 16%", "latency_ms": 3274.287700653076, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 3649.4832038879395, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2533}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 3560.3725910186768, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3238}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 3333.714723587036, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3856}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 1146.5225219726562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1975", "latency_ms": 1810.2574348449707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "1975", "latency_ms": 1729.4862270355225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1215}, "3": {"k": 3, "answer": "1975", "latency_ms": 1488.8250827789307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1790}, "4": {"k": 4, "answer": "1975", "latency_ms": 1781.829833984375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2368}, "5": {"k": 5, "answer": "1975", "latency_ms": 1705.2593231201172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3067}, "6": {"k": 6, "answer": "1975", "latency_ms": 1313.8673305511475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3664}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 2739.94517326355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2422.0824241638184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Lionel Richie", "latency_ms": 2663.877248764038, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Lionel Richie", "latency_ms": 2911.7627143859863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 2736.614942550659, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2434}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 1944.13423538208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3081}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 2713.4571075439453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3698}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert", "latency_ms": 2441.0746097564697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Leonard Calvert", "latency_ms": 2359.126567840576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 688}, "2": {"k": 2, "answer": "Lord Baltimore and brother Leonard Calvert", "latency_ms": 4102.283954620361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "Cecil Calvert", "latency_ms": 2668.083906173706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1946}, "4": {"k": 4, "answer": "Cecil Calvert", "latency_ms": 3395.402431488037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2597}, "5": {"k": 5, "answer": "Cecil Calvert", "latency_ms": 3251.424551010132, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3275}, "6": {"k": 6, "answer": "Cecil Calvert", "latency_ms": 2957.9851627349854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3973}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 885.6801986694336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiger Woods", "latency_ms": 2083.2107067108154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Tiger Woods", "latency_ms": 1756.0479640960693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Tiger Woods", "latency_ms": 2582.831621170044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Tiger Woods", "latency_ms": 2312.6537799835205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2554}, "5": {"k": 5, "answer": "Tiger Woods", "latency_ms": 2568.1214332580566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3214}, "6": {"k": 6, "answer": "Tiger Woods", "latency_ms": 2126.5299320220947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3864}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 2904.2375087738037, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "200 to 500 mg", "latency_ms": 2710.9766006469727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 5305.52339553833, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 5786.765575408936, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1878}, "4": {"k": 4, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 4566.584587097168, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2527}, "5": {"k": 5, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 4271.373271942139, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3115}, "6": {"k": 6, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 4430.514097213745, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3805}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 2712.9578590393066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham", "latency_ms": 1730.4677963256836, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 2066.14089012146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1166}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 1540.3637886047363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1758}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 2292.180299758911, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2318}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 1964.2353057861328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2837}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 2062.422513961792, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3435}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 1183.7396621704102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hotel beverage rooms", "latency_ms": 2065.2730464935303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 685}, "2": {"k": 2, "answer": "hotel beverage rooms", "latency_ms": 2566.509246826172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1360}, "3": {"k": 3, "answer": "Paris", "latency_ms": 662.9343032836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Hotel beverage rooms", "latency_ms": 2809.48543548584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2702}, "5": {"k": 5, "answer": "Hotel beverage rooms", "latency_ms": 2368.015766143799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3420}, "6": {"k": 6, "answer": "Hotel beverage rooms", "latency_ms": 2338.1102085113525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4113}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh", "latency_ms": 517.824649810791, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 3386.4235877990723, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 1210.7234001159668, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1372}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 2592.913866043091, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2057}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 3219.349145889282, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 2666.715145111084, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3359}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 2905.7047367095947, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4035}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 1748.6131191253662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2102.996587753296, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2450.2029418945312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "Alexa Bliss", "latency_ms": 1488.0702495574951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1939}, "4": {"k": 4, "answer": "Alexa Bliss", "latency_ms": 2096.146821975708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2607}, "5": {"k": 5, "answer": "Alexa Bliss", "latency_ms": 1553.943157196045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3235}, "6": {"k": 6, "answer": "Alexa Bliss", "latency_ms": 1868.6230182647705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3882}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 2809.7310066223145, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Southport, North Carolina", "latency_ms": 2890.693426132202, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Southport, North Carolina.", "latency_ms": 3023.5371589660645, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Southport, North Carolina.", "latency_ms": 2397.594451904297, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Southport, North Carolina", "latency_ms": 2538.7182235717773, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "Southport, North Carolina.", "latency_ms": 3232.649564743042, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3061}, "6": {"k": 6, "answer": "Southport, North Carolina", "latency_ms": 3142.3070430755615, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3695}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 1139.8112773895264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sylvia F. Porter", "latency_ms": 3308.563470840454, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "Sylvia F. Porter", "latency_ms": 2751.5523433685303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Sylvia F. Porter", "latency_ms": 2312.265157699585, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1910}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 2780.582904815674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2617}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 3865.6532764434814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3226}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 2783.2934856414795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3831}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 1821.7272758483887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 2086.5585803985596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 704}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 2350.5196571350098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1441}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 2108.9110374450684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2114}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 2218.035936355591, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2787}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 2579.6046257019043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3458}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 1847.5050926208496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4174}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 1197.1509456634521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 1490.2310371398926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "Max", "latency_ms": 1642.6372528076172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Max", "latency_ms": 1659.6169471740723, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1872}, "4": {"k": 4, "answer": "Max", "latency_ms": 1688.2052421569824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Max", "latency_ms": 1453.7160396575928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Max", "latency_ms": 1958.5051536560059, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 2359.5943450927734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2977.5853157043457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2867.912769317627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1314}, "3": {"k": 3, "answer": "Megan Follows", "latency_ms": 1460.616111755371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Megan Follows", "latency_ms": 2405.377149581909, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2540}, "5": {"k": 5, "answer": "Megan Follows", "latency_ms": 2493.8740730285645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Megan Follows", "latency_ms": 2690.6042098999023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3790}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "Industrialization and imperialism.", "latency_ms": 2479.4466495513916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Women starting to serve in limited military roles.", "latency_ms": 3942.453145980835, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "World War was not, but Exposition Universelle and Paris 1900 chess tournament were.", "latency_ms": 6294.6882247924805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "World Exposition", "latency_ms": 1723.1006622314453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "World Exposition", "latency_ms": 1840.9249782562256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "Exposition Universelle", "latency_ms": 2408.8046550750732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3226}, "6": {"k": 6, "answer": "Exposition Universelle", "latency_ms": 2897.494316101074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3885}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 2342.8468704223633, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "self-empowerment", "latency_ms": 3041.6650772094727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 2692.9092407226562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Empowerment", "latency_ms": 1647.9790210723877, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Empowerment", "latency_ms": 2341.564416885376, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "Empowerment", "latency_ms": 2113.3666038513184, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3162}, "6": {"k": 6, "answer": "Empowerment", "latency_ms": 1618.253469467163, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3764}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 1309.4589710235596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "National Football League franchises", "latency_ms": 3111.827850341797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "National Football League franchises", "latency_ms": 2887.232542037964, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "National Football League franchises", "latency_ms": 2136.8985176086426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "National Football League franchises", "latency_ms": 2380.322217941284, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2491}, "5": {"k": 5, "answer": "National Football League franchises", "latency_ms": 2320.8224773406982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3123}, "6": {"k": 6, "answer": "National Football League teams", "latency_ms": 2592.395782470703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3757}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 2000.2331733703613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3220.2699184417725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3287.9202365875244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2249.315023422241, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1760.3869438171387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2551}, "5": {"k": 5, "answer": "James Marshall", "latency_ms": 2555.574417114258, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "James Marshall", "latency_ms": 1529.3052196502686, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3869}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 2920.1748371124268, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 3225.278854370117, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 2979.71773147583, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 2091.2654399871826, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 1964.8346900939941, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 2446.953296661377, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 2638.2505893707275, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3785}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2193.6397552490234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3176.22971534729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2182.255744934082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1889.608383178711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1896}, "4": {"k": 4, "answer": "5", "latency_ms": 1511.7650032043457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "5", "latency_ms": 1433.1955909729004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "All five ski jumping gold medals.", "latency_ms": 4173.035144805908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3741}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4297.061204910278, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4026.1192321777344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3486.3686561584473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3998.9123344421387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4972.667217254639, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2596}, "5": {"k": 5, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4899.137258529663, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3271}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3831.9027423858643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3942}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 1820.918321609497, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central Germany", "latency_ms": 1516.8943405151367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Central Germany", "latency_ms": 1998.772382736206, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Central Germany", "latency_ms": 2227.076768875122, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Central European", "latency_ms": 2550.668954849243, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Central European cultures", "latency_ms": 2047.2233295440674, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3279}, "6": {"k": 6, "answer": "Central European cultures", "latency_ms": 2084.7198963165283, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3933}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 1921.0054874420166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 1923.11692237854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 2518.1796550750732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 2367.758274078369, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "post-medieval era", "latency_ms": 2135.8845233917236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "1648–1651", "latency_ms": 2661.851167678833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3212}, "6": {"k": 6, "answer": "1648–1651", "latency_ms": 3460.810661315918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3834}}}
