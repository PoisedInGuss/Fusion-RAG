{"qid": "5306300389470118812", "question": "what was the religion in persia before islam", "gold_answers": ["the Zoroastrian religion", "Zoroastrian"], "shots": {"0": {"k": 0, "answer": "Zoroastrianism", "latency_ms": 561.3775253295898, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Zoroastrian", "latency_ms": 976.9928455352783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 637}, "2": {"k": 2, "answer": "Zoroastrian", "latency_ms": 822.6888179779053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Zoroastrianism", "latency_ms": 1096.5626239776611, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1889}, "4": {"k": 4, "answer": "Zoroastrianism", "latency_ms": 1143.5611248016357, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2599}, "5": {"k": 5, "answer": "Zoroastrianism", "latency_ms": 1113.8851642608643, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3219}, "6": {"k": 6, "answer": "Zoroastrianism", "latency_ms": 1539.9346351623535, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3904}}}
{"qid": "4492088526674104172", "question": "why does kerosene oil rise up in the wick of lantern", "gold_answers": ["capillary action"], "shots": {"0": {"k": 0, "answer": "Capillary action", "latency_ms": 248.39019775390625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Capillary action", "latency_ms": 998.3687400817871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 586}, "2": {"k": 2, "answer": "Capillary action", "latency_ms": 1190.7827854156494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Capillary action", "latency_ms": 603.7554740905762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1818}, "4": {"k": 4, "answer": "Capillary action", "latency_ms": 992.537260055542, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2433}, "5": {"k": 5, "answer": "Capillary action", "latency_ms": 942.084550857544, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3010}, "6": {"k": 6, "answer": "Capillary action", "latency_ms": 981.0793399810791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3627}}}
{"qid": "-4373262132142058334", "question": "mention the chemical change that proinsulin undergo to be able to act as mature insulin", "gold_answers": ["post translational modification"], "shots": {"0": {"k": 0, "answer": "Proteolytic cleavage", "latency_ms": 969.3775177001953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Folding", "latency_ms": 660.8054637908936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 702}, "2": {"k": 2, "answer": "Cleavage of C-peptide", "latency_ms": 1699.3188858032227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1349}, "3": {"k": 3, "answer": "Cleavage", "latency_ms": 723.785400390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "Cleavage", "latency_ms": 754.239559173584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "Cleavage", "latency_ms": 1009.6080303192139, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "Cleavage", "latency_ms": 1040.9297943115234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3978}}}
{"qid": "-5298560410953979569", "question": "where does the sweetness of fruit come from", "gold_answers": ["Fructose , or fruit sugar", "Fructose"], "shots": {"0": {"k": 0, "answer": "Fructose", "latency_ms": 645.8311080932617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1475.4202365875244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 677}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1238.8761043548584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 859.9262237548828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1902}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1209.939956665039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 770.0409889221191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3191}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1450.9449005126953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3801}}}
{"qid": "4344648368832551136", "question": "an object that moves around an external axis is said to be", "gold_answers": ["orbit", "revolution or orbital revolution"], "shots": {"0": {"k": 0, "answer": "rotating", "latency_ms": 907.0463180541992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "revolving", "latency_ms": 398.21648597717285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "revolving", "latency_ms": 912.1463298797607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "revolving", "latency_ms": 878.7109851837158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1760}, "4": {"k": 4, "answer": "revolving", "latency_ms": 1106.8274974822998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2418}, "5": {"k": 5, "answer": "revolving", "latency_ms": 923.5599040985107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3047}, "6": {"k": 6, "answer": "revolving", "latency_ms": 1106.7514419555664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3707}}}
{"qid": "-724426540432437711", "question": "what was the name of the plant on little shop of horrors", "gold_answers": ["Audrey II"], "shots": {"0": {"k": 0, "answer": "Audrey II", "latency_ms": 670.3600883483887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1486.4823818206787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1047.6176738739014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1535.3457927703857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1294.2183017730713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1788.952350616455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3197}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1227.6294231414795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3821}}}
{"qid": "-5541610970112826260", "question": "who signed the declaration of independence for maryland", "gold_answers": ["Samuel Chase", "Charles Carroll of Carrollton", "Thomas Stone", "William Paca"], "shots": {"0": {"k": 0, "answer": "Samuel Chase", "latency_ms": 493.38531494140625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Samuel Chase, William Paca, Thomas Stone, Charles Carroll of Carrollton.", "latency_ms": 2518.5978412628174, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 726}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1489.1729354858398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1463}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 748.8703727722168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2111}, "4": {"k": 4, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 2422.808885574341, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 2831}, "5": {"k": 5, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 2281.299114227295, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 3523}, "6": {"k": 6, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton.", "latency_ms": 1900.2001285552979, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 4198}}}
{"qid": "-86997217831791339", "question": "when does wonder woman come out on blue ray", "gold_answers": ["September 19 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 834.4838619232178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 19, 2017", "latency_ms": 1232.0582866668701, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "September 19, 2017", "latency_ms": 1438.7240409851074, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "September 19, 2017", "latency_ms": 1590.8424854278564, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1849}, "4": {"k": 4, "answer": "September 19, 2017", "latency_ms": 1394.3498134613037, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "September 19, 2017", "latency_ms": 1262.9594802856445, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3183}, "6": {"k": 6, "answer": "September 19, 2017", "latency_ms": 1643.991470336914, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3784}}}
{"qid": "-8062812506672279762", "question": "what nba team did derrick rose play for", "gold_answers": ["New York Knicks", "Minnesota Timberwolves", "Chicago Bulls", "Cleveland Cavaliers"], "shots": {"0": {"k": 0, "answer": "Chicago Bulls", "latency_ms": 404.071569442749, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chicago Bulls, Minnesota Timberwolves", "latency_ms": 1150.4998207092285, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 630}, "2": {"k": 2, "answer": "Minnesota Timberwolves, Chicago Bulls", "latency_ms": 1142.672061920166, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Chicago Bulls, Minnesota Timberwolves", "latency_ms": 1332.6444625854492, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Minnesota Timberwolves, Chicago Bulls", "latency_ms": 1411.3705158233643, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "Chicago Bulls, Minnesota Timberwolves", "latency_ms": 1473.9165306091309, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3144}, "6": {"k": 6, "answer": "Chicago Bulls, Minnesota Timberwolves", "latency_ms": 1618.7160015106201, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3743}}}
{"qid": "7933002036740390435", "question": "where did the term liberal arts come from", "gold_answers": ["the Roman Empire"], "shots": {"0": {"k": 0, "answer": "Medieval Europe", "latency_ms": 546.0472106933594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1097.7990627288818, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 720}, "2": {"k": 2, "answer": "Europe", "latency_ms": 815.1352405548096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1415}, "3": {"k": 3, "answer": "Europe", "latency_ms": 805.9334754943848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2128}, "4": {"k": 4, "answer": "Europe", "latency_ms": 779.6530723571777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2862}, "5": {"k": 5, "answer": "Roman Empire", "latency_ms": 546.0038185119629, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3481}, "6": {"k": 6, "answer": "Roman Empire", "latency_ms": 1157.891035079956, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4195}}}
{"qid": "-2991400700385487821", "question": "who heads the executive department of west virginia government", "gold_answers": ["the Governor of West Virginia", "the governor of West Virginia", "Jim Justice"], "shots": {"0": {"k": 0, "answer": "The Governor", "latency_ms": 163.56849670410156, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Governor of West Virginia", "latency_ms": 976.294994354248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "The Governor of West Virginia", "latency_ms": 1212.6870155334473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1396}, "3": {"k": 3, "answer": "The Governor of West Virginia", "latency_ms": 827.822208404541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2052}, "4": {"k": 4, "answer": "The Governor of West Virginia", "latency_ms": 949.0396976470947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2773}, "5": {"k": 5, "answer": "The Governor of West Virginia", "latency_ms": 1306.0457706451416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3452}, "6": {"k": 6, "answer": "The Governor of West Virginia", "latency_ms": 774.672269821167, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4160}}}
{"qid": "-9186689755642837558", "question": "how long is the bridge between new brunswick and prince edward island", "gold_answers": ["12.9 - kilometre"], "shots": {"0": {"k": 0, "answer": "13 kilometers", "latency_ms": 703.141450881958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1012.0134353637695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1025.7573127746582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1405}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 771.237850189209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2092}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1038.7539863586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2815}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 806.0548305511475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3503}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 939.0144348144531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4178}}}
{"qid": "8029901619424338449", "question": "when did the uk and us become allies", "gold_answers": ["1940", "Since 1940"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 785.8972549438477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "After the end of the Second World War in 1945", "latency_ms": 1842.1478271484375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "After the end of the Second World War in 1945", "latency_ms": 2285.9132289886475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "After 1945", "latency_ms": 1231.3854694366455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "After the end of the Second World War in 1945", "latency_ms": 2412.9765033721924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "After the end of the Second World War in 1945", "latency_ms": 1964.5802974700928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3245}, "6": {"k": 6, "answer": "After the end of the Second World War in 1945", "latency_ms": 2832.516670227051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3861}}}
{"qid": "4828649525820722736", "question": "who sang the theme song for the man with the golden gun", "gold_answers": ["Lulu"], "shots": {"0": {"k": 0, "answer": "Lulu", "latency_ms": 398.3635902404785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lulu", "latency_ms": 710.5352878570557, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 582}, "2": {"k": 2, "answer": "Lulu", "latency_ms": 629.173755645752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Lulu", "latency_ms": 678.0498027801514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1818}, "4": {"k": 4, "answer": "Lulu", "latency_ms": 1004.4605731964111, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2431}, "5": {"k": 5, "answer": "Lulu", "latency_ms": 919.7497367858887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3088}, "6": {"k": 6, "answer": "Lulu", "latency_ms": 1232.1290969848633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3721}}}
{"qid": "-7924663090486742985", "question": "american horror story freak show girl kidnapped by clown", "gold_answers": ["Bonnie Lipton"], "shots": {"0": {"k": 0, "answer": "Penny", "latency_ms": 451.43651962280273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1294.2626476287842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1154.2940139770508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1352}, "3": {"k": 3, "answer": "Twisty", "latency_ms": 1128.525733947754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1955}, "4": {"k": 4, "answer": "Twisty", "latency_ms": 779.9649238586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "Twisty", "latency_ms": 973.1884002685547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "Twisty", "latency_ms": 915.816068649292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3897}}}
{"qid": "-360675773049242516", "question": "the probability of making a type i error when retaining ho at the .05 level of significance is", "gold_answers": ["5 %"], "shots": {"0": {"k": 0, "answer": "0.05", "latency_ms": 759.9444389343262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0.05", "latency_ms": 977.5898456573486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "0.05", "latency_ms": 1255.6872367858887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "0.05", "latency_ms": 720.3905582427979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "0.05", "latency_ms": 942.6069259643555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2462}, "5": {"k": 5, "answer": "0.05", "latency_ms": 775.5322456359863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3110}, "6": {"k": 6, "answer": "0.05", "latency_ms": 733.8471412658691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3736}}}
{"qid": "5819386267283467034", "question": "what year did the us hockey team won the olympics", "gold_answers": ["1960", "1980", "1960 and 1980"], "shots": {"0": {"k": 0, "answer": "1980", "latency_ms": 486.9828224182129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1960, 1980", "latency_ms": 1375.044584274292, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "1960, 1980", "latency_ms": 1579.4546604156494, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1276}, "3": {"k": 3, "answer": "1960, 1980", "latency_ms": 2274.9814987182617, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1938}, "4": {"k": 4, "answer": "1960, 1980", "latency_ms": 1198.028802871704, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2535}, "5": {"k": 5, "answer": "1960, 1980", "latency_ms": 1211.676836013794, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3214}, "6": {"k": 6, "answer": "1960, 1980", "latency_ms": 1702.9569149017334, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3837}}}
{"qid": "3916394566028297311", "question": "who wrote it's a long long way to pasadena", "gold_answers": ["Harry Vanda", "John Young", "David Hemmings", "George Young"], "shots": {"0": {"k": 0, "answer": "Albert E. Brumley", "latency_ms": 1096.7652797698975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1283.7719917297363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1306.725025177002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 839.777946472168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 927.9234409332275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1111.3109588623047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 624.9933242797852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3841}}}
{"qid": "-2432292250757146771", "question": "who wrote the song i hate you i love you", "gold_answers": ["Angel Benitez", "Olivia O'Brien", "Garrett Nash"], "shots": {"0": {"k": 0, "answer": "Gnash", "latency_ms": 813.2162094116211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "StarGate and Ne-Yo", "latency_ms": 1852.1668910980225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 767.1031951904297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1203}, "3": {"k": 3, "answer": "Gnash and Olivia O'Brien", "latency_ms": 1563.652515411377, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1777}, "4": {"k": 4, "answer": "Gnash and Olivia O'Brien", "latency_ms": 1704.5936584472656, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2379}, "5": {"k": 5, "answer": "Gnash and Olivia O'Brien", "latency_ms": 1049.4272708892822, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2979}, "6": {"k": 6, "answer": "Gnash and Olivia O'Brien", "latency_ms": 1895.9684371948242, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3554}}}
{"qid": "2393389448844632496", "question": "what is loihi and where does it originate from", "gold_answers": ["from the Hawaii hotspot"], "shots": {"0": {"k": 0, "answer": "Loihi, Hawaii", "latency_ms": 843.0006504058838, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Loihi submarine volcano, Hawaii", "latency_ms": 1436.981201171875, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Loihi Seamount, Hawaii", "latency_ms": 1608.4327697753906, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "Loihi Seamount, Hawaii", "latency_ms": 1492.8112030029297, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "Loihi Seamount, Hawaii", "latency_ms": 1304.3787479400635, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "Loihi Seamount, Hawaii", "latency_ms": 1220.2796936035156, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3301}, "6": {"k": 6, "answer": "Loihi Seamount, Hawaii", "latency_ms": 1574.7406482696533, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3958}}}
{"qid": "-6677440871585683891", "question": "who rebuilt the temple after the babylonian captivity", "gold_answers": ["Herod"], "shots": {"0": {"k": 0, "answer": "Zerubbabel", "latency_ms": 738.6467456817627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The exiles", "latency_ms": 934.1726303100586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "The exiles", "latency_ms": 1289.2308235168457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "the Priest", "latency_ms": 700.472354888916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "The Priest", "latency_ms": 543.830156326294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "Ezra", "latency_ms": 1267.3957347869873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "Ezra", "latency_ms": 1105.9229373931885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3873}}}
{"qid": "-6750750235985613277", "question": "who was executed for being an american spy during the revolutionary war", "gold_answers": ["Nathan Hale"], "shots": {"0": {"k": 0, "answer": "Nathan Hale", "latency_ms": 779.5307636260986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1228.7170886993408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "Nathan Hale", "latency_ms": 1191.2193298339844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1197}, "3": {"k": 3, "answer": "Nathan Hale", "latency_ms": 717.5343036651611, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Nathan Hale", "latency_ms": 1013.6759281158447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2549}, "5": {"k": 5, "answer": "Nathan Hale", "latency_ms": 1251.3694763183594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3210}, "6": {"k": 6, "answer": "Nathan Hale", "latency_ms": 1052.900791168213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3862}}}
{"qid": "8770209312170080158", "question": "who sang the song suddenly with olivia newton john", "gold_answers": ["Cliff Richard"], "shots": {"0": {"k": 0, "answer": "Cliff Richard", "latency_ms": 773.1204032897949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cliff Richard", "latency_ms": 922.4212169647217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "Cliff Richard", "latency_ms": 694.1437721252441, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1270}, "3": {"k": 3, "answer": "Cliff Richard", "latency_ms": 1292.938232421875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1903}, "4": {"k": 4, "answer": "Cliff Richard", "latency_ms": 906.745195388794, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2550}, "5": {"k": 5, "answer": "Cliff Richard", "latency_ms": 1288.9702320098877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3287}, "6": {"k": 6, "answer": "Cliff Richard", "latency_ms": 855.2842140197754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3951}}}
{"qid": "-180549795106449014", "question": "who is command sergeant major of the army", "gold_answers": ["Daniel A. Dailey"], "shots": {"0": {"k": 0, "answer": "Michael A. Grinston", "latency_ms": 910.8209609985352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1210.770845413208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "Sergeant Major of the Army", "latency_ms": 1465.9583568572998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Sergeant Major of the Army", "latency_ms": 2133.7318420410156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Sergeant Major of the Army", "latency_ms": 1704.6287059783936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "Sergeant Major of the Army", "latency_ms": 1169.8696613311768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Sergeant Major of the Army", "latency_ms": 1499.7622966766357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3847}}}
{"qid": "7815138213728640354", "question": "who sings the original windmills of your mind", "gold_answers": ["Noel Harrison"], "shots": {"0": {"k": 0, "answer": "Noel Harrison", "latency_ms": 593.4231281280518, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noel Harrison", "latency_ms": 698.2364654541016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 603}, "2": {"k": 2, "answer": "No singer mentioned", "latency_ms": 1277.2853374481201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "No singer mentioned", "latency_ms": 1094.21706199646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "No singer mentioned", "latency_ms": 1020.8456516265869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2479}, "5": {"k": 5, "answer": "Noel Harrison", "latency_ms": 598.4690189361572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3160}, "6": {"k": 6, "answer": "Noel Harrison", "latency_ms": 777.4763107299805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3842}}}
{"qid": "2098168902147822379", "question": "where will the next summer and winter olympics be held", "gold_answers": ["Beijing", "Tokyo"], "shots": {"0": {"k": 0, "answer": "Paris 2024 and Milan-Cortina 2026.", "latency_ms": 2358.7841987609863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Abu Dhabi, United Arab Emirates and not specified", "latency_ms": 1824.7003555297852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "Abu Dhabi, Beijing", "latency_ms": 779.5696258544922, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Los Angeles, Beijing, Abu Dhabi", "latency_ms": 982.0053577423096, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Los Angeles, Beijing", "latency_ms": 1224.1671085357666, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2532}, "5": {"k": 5, "answer": "Los Angeles, Beijing", "latency_ms": 861.7942333221436, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3157}, "6": {"k": 6, "answer": "Los Angeles, Beijing", "latency_ms": 836.0517024993896, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3817}}}
{"qid": "-1458476052377668874", "question": "when did ole miss beat alabama in football", "gold_answers": ["September 19 , 2015", "October 3 , 1970", "October 27 , 1894", "October 13 , 2001", "October 5 , 1968", "October 4 , 2014", "September 11 , 1976", "October 8 , 1988", "October 18 , 2003", "November 5 , 1910"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 736.8054389953613, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 1161.5791320800781, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "1988, 2014", "latency_ms": 1253.0598640441895, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "1988, 2014, 2015", "latency_ms": 1902.8432369232178, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1819}, "4": {"k": 4, "answer": "1988, 2014, 2015", "latency_ms": 1793.4913635253906, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2456}, "5": {"k": 5, "answer": "1988, 2003, 2014, 2015", "latency_ms": 2740.3323650360107, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3020}, "6": {"k": 6, "answer": "1988, 2014, 2015", "latency_ms": 2046.7369556427002, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3685}}}
{"qid": "-6861734002351236912", "question": "who sang the song how far is heaven", "gold_answers": ["Los Lonely Boys"], "shots": {"0": {"k": 0, "answer": "Nitty Gritty Dirt Band", "latency_ms": 1673.997402191162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Moore", "latency_ms": 733.2580089569092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Justin Moore", "latency_ms": 869.499921798706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1196}, "3": {"k": 3, "answer": "Justin Moore", "latency_ms": 969.9840545654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1125.2353191375732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2398}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1193.0859088897705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2987}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1764.080286026001, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3612}}}
{"qid": "-1722216190521937227", "question": "where are the organ mountains in new mexico", "gold_answers": ["southern New Mexico"], "shots": {"0": {"k": 0, "answer": "Las Cruces", "latency_ms": 952.2607326507568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "southern New Mexico", "latency_ms": 569.7536468505859, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "southern New Mexico", "latency_ms": 1213.8593196868896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "southern New Mexico", "latency_ms": 1250.3974437713623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1924}, "4": {"k": 4, "answer": "southern New Mexico", "latency_ms": 999.711275100708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2564}, "5": {"k": 5, "answer": "southern New Mexico", "latency_ms": 1317.3506259918213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "southern New Mexico", "latency_ms": 1416.3157939910889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3941}}}
{"qid": "-2717119588239727064", "question": "where are the 10 plagues found in the bible", "gold_answers": ["Book of Exodus", "Exodus"], "shots": {"0": {"k": 0, "answer": "Exodus 7-12", "latency_ms": 1133.4972381591797, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Bible", "latency_ms": 1163.0511283874512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1065.9043788909912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1376}, "3": {"k": 3, "answer": "Book of Exodus", "latency_ms": 1229.097843170166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Book of Exodus", "latency_ms": 1043.5824394226074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Book of Exodus", "latency_ms": 1100.9976863861084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3249}, "6": {"k": 6, "answer": "The Book of Exodus", "latency_ms": 1266.244649887085, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3883}}}
{"qid": "2988284357714596500", "question": "where are red blood cells made in adults", "gold_answers": ["in the bone marrow"], "shots": {"0": {"k": 0, "answer": "Bone marrow", "latency_ms": 654.700517654419, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "bone marrow", "latency_ms": 995.2297210693359, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "bone marrow", "latency_ms": 940.1226043701172, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "bone marrow", "latency_ms": 910.0031852722168, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "bone marrow", "latency_ms": 683.4914684295654, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "bone marrow", "latency_ms": 1114.8896217346191, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3102}, "6": {"k": 6, "answer": "bone marrow", "latency_ms": 651.5088081359863, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3776}}}
{"qid": "-4616596799374362422", "question": "who was the pinkerton detective agency's first female detective", "gold_answers": ["Kate Warne"], "shots": {"0": {"k": 0, "answer": "Kate Warne", "latency_ms": 736.9601726531982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kate Warne", "latency_ms": 786.3190174102783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 681}, "2": {"k": 2, "answer": "Kate Warne", "latency_ms": 1002.0155906677246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1401}, "3": {"k": 3, "answer": "Kate Warne", "latency_ms": 783.6403846740723, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2065}, "4": {"k": 4, "answer": "Kate Warne", "latency_ms": 1226.619005203247, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2743}, "5": {"k": 5, "answer": "Kate Warne", "latency_ms": 958.320140838623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3453}, "6": {"k": 6, "answer": "Kate Warne", "latency_ms": 1191.8141841888428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4064}}}
{"qid": "-3650291155113659146", "question": "how many episodes are there in modern family", "gold_answers": ["232", "201"], "shots": {"0": {"k": 0, "answer": "250 episodes", "latency_ms": 502.92420387268066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "102nd overall.", "latency_ms": 1031.1310291290283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "24", "latency_ms": 1119.8947429656982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "At least 116", "latency_ms": 1232.1817874908447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1967}, "4": {"k": 4, "answer": "At least 116", "latency_ms": 1119.5459365844727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2586}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1256.2766075134277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1211.5240097045898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3850}}}
{"qid": "3381924381590631417", "question": "who built the first temple for god in jerusalem", "gold_answers": ["Solomon"], "shots": {"0": {"k": 0, "answer": "King Solomon", "latency_ms": 768.3022022247314, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1734.4355583190918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "King Solomon", "latency_ms": 1208.9853286743164, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "King Solomon", "latency_ms": 454.69021797180176, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1829}, "4": {"k": 4, "answer": "King Solomon", "latency_ms": 891.486644744873, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "King Solomon", "latency_ms": 963.9682769775391, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3115}, "6": {"k": 6, "answer": "King Solomon", "latency_ms": 682.0971965789795, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3768}}}
{"qid": "-154783694579651082", "question": "what is a dropped pin on google maps for", "gold_answers": ["marks locations", "marks locations in Google Maps"], "shots": {"0": {"k": 0, "answer": "Saving a location", "latency_ms": 1145.4377174377441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to accurately mark a point on a map", "latency_ms": 2133.7521076202393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 574}, "2": {"k": 2, "answer": "to mark a location", "latency_ms": 811.0888004302979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "to mark a location", "latency_ms": 1232.1031093597412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "to mark a location", "latency_ms": 1276.505708694458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "to mark a location", "latency_ms": 820.0812339782715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3165}, "6": {"k": 6, "answer": "to mark a location", "latency_ms": 984.1318130493164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3760}}}
{"qid": "6915606477668963399", "question": "what do the 3 dots mean in math", "gold_answers": ["the therefore sign", "therefore sign"], "shots": {"0": {"k": 0, "answer": "Ellipsis", "latency_ms": 1063.0481243133545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 615.9074306488037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1290.3318405151367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "Therefore", "latency_ms": 374.04322624206543, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Therefore", "latency_ms": 657.081127166748, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2568}, "5": {"k": 5, "answer": "Therefore", "latency_ms": 374.9549388885498, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "Therefore", "latency_ms": 938.765287399292, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3759}}}
{"qid": "-8366545547296627039", "question": "who wrote the song photograph by ringo starr", "gold_answers": ["Richard Starkey", "George Harrison", "Ringo Starr"], "shots": {"0": {"k": 0, "answer": "Ringo Starr and George Harrison", "latency_ms": 928.8187026977539, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ringo Starr and George Harrison", "latency_ms": 1176.2990951538086, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Ringo Starr and George Harrison", "latency_ms": 1013.3757591247559, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Ringo Starr and George Harrison", "latency_ms": 1318.8297748565674, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1984}, "4": {"k": 4, "answer": "Ringo Starr and George Harrison", "latency_ms": 1213.7389183044434, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2640}, "5": {"k": 5, "answer": "Ringo Starr and George Harrison", "latency_ms": 1150.4709720611572, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3250}, "6": {"k": 6, "answer": "Ringo Starr and George Harrison", "latency_ms": 1227.4274826049805, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3894}}}
{"qid": "-5004457603684974952", "question": "who is playing the halftime show at super bowl 2016", "gold_answers": ["Beyoncé", "Coldplay", "Bruno Mars"], "shots": {"0": {"k": 0, "answer": "Coldplay", "latency_ms": 909.7175598144531, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 1346.4291095733643, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 1886.474370956421, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 1268.9878940582275, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1921}, "4": {"k": 4, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 1611.919641494751, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2554}, "5": {"k": 5, "answer": "Coldplay, Beyoncé, and Bruno Mars", "latency_ms": 1544.9740886688232, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Coldplay, Beyoncé, and Bruno Mars", "latency_ms": 1072.6187229156494, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3860}}}
{"qid": "7420920477821898435", "question": "to aru kagaku no railgun s episode 3", "gold_answers": ["Project Radio Noise"], "shots": {"0": {"k": 0, "answer": "Episode 3", "latency_ms": 992.4061298370361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 779.3858051300049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 866.9788837432861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1280}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1124.6836185455322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1950}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 827.6710510253906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2570}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 783.473014831543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3175}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1080.6326866149902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3881}}}
{"qid": "7478795216476346339", "question": "who won the 2017 sports personality of the year", "gold_answers": ["Mo Farah"], "shots": {"0": {"k": 0, "answer": "Mo Farah", "latency_ms": 575.817346572876, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1030.9743881225586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1053.093433380127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1294}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1200.4272937774658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 756.8032741546631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2606}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1002.0592212677002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "Mo Farah", "latency_ms": 746.4582920074463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3904}}}
{"qid": "7217222058435937287", "question": "where was the world economic forum held this year", "gold_answers": ["Davos"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 815.8481121063232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1026.4008045196533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 805.3998947143555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1362}, "3": {"k": 3, "answer": "Davos, Switzerland.", "latency_ms": 1334.9659442901611, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2033}, "4": {"k": 4, "answer": "Davos, Switzerland.", "latency_ms": 1401.2935161590576, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2734}, "5": {"k": 5, "answer": "Davos, Switzerland.", "latency_ms": 2552.858352661133, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3398}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1104.2978763580322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4096}}}
{"qid": "-143054837169120955", "question": "where are the giant redwoods located in california", "gold_answers": ["the coast of northern California", "Del Norte County", "Humboldt County"], "shots": {"0": {"k": 0, "answer": "Northern California", "latency_ms": 677.7017116546631, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 2197.87859916687, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "Kings Canyon National Park", "latency_ms": 1297.4536418914795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Kings Canyon National Park", "latency_ms": 845.773458480835, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Kings Canyon National Park", "latency_ms": 1445.6827640533447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2536}, "5": {"k": 5, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 2407.2353839874268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3208}, "6": {"k": 6, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 2153.326988220215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3784}}}
{"qid": "4892429640540595424", "question": "who has made the most premier league appearances", "gold_answers": ["Gareth Barry"], "shots": {"0": {"k": 0, "answer": "Gareth Barry", "latency_ms": 944.044828414917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 793.0071353912354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 594}, "2": {"k": 2, "answer": "Gareth Barry", "latency_ms": 979.0387153625488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Gareth Barry", "latency_ms": 1141.9548988342285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1857}, "4": {"k": 4, "answer": "Gareth Barry", "latency_ms": 1212.4919891357422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2497}, "5": {"k": 5, "answer": "Gareth Barry", "latency_ms": 1187.8905296325684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Gareth Barry", "latency_ms": 1222.560167312622, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3755}}}
{"qid": "5533906981191706877", "question": "who was the first chief minister of west bengal", "gold_answers": ["Prafulla Chandra Ghosh"], "shots": {"0": {"k": 0, "answer": "Prafulla Chandra Ghosh", "latency_ms": 1588.428258895874, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dr. B. C. Roy", "latency_ms": 1682.6739311218262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Dr. B. C. Roy", "latency_ms": 2082.223892211914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "Dr. B. C. Roy", "latency_ms": 1221.3318347930908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "Dr. B. C. Roy", "latency_ms": 1870.5406188964844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2660}, "5": {"k": 5, "answer": "Dr. B. C. Roy", "latency_ms": 1415.855884552002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3326}, "6": {"k": 6, "answer": "Dr. B. C. Roy", "latency_ms": 1838.7608528137207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3979}}}
{"qid": "8823076125131408628", "question": "who sings got my mind set on you", "gold_answers": ["George Harrison", "James Ray"], "shots": {"0": {"k": 0, "answer": "George Harrison", "latency_ms": 851.9659042358398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1018.3207988739014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1224.65181350708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 766.3981914520264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1816}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 874.4704723358154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2428}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 769.8123455047607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3000}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 805.4883480072021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3634}}}
{"qid": "9168660859139861094", "question": "two main types of research methods used in psychology", "gold_answers": ["Correlational research", "Descriptive research", "quantitative data", "Quantitative psychological research", "qualitative", "quantitative", "Qualitative psychological research", "Experimental research", "qualitative data"], "shots": {"0": {"k": 0, "answer": "Qualitative and Quantitative.", "latency_ms": 1098.1714725494385, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Qualitative or quantitative", "latency_ms": 1285.188913345337, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 735}, "2": {"k": 2, "answer": "Qualitative or quantitative", "latency_ms": 968.6393737792969, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1482}, "3": {"k": 3, "answer": "Qualitative or quantitative", "latency_ms": 943.5932636260986, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2166}, "4": {"k": 4, "answer": "Qualitative or quantitative", "latency_ms": 962.6915454864502, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2932}, "5": {"k": 5, "answer": "Qualitative or quantitative", "latency_ms": 750.5743503570557, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3695}, "6": {"k": 6, "answer": "Qualitative or quantitative", "latency_ms": 726.8848419189453, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4504}}}
{"qid": "-7073063191952855764", "question": "who plays peter in what we do in the shadows", "gold_answers": ["Ben Fransham"], "shots": {"0": {"k": 0, "answer": "Mark Proksch", "latency_ms": 1042.0334339141846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1244.485855102539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 777.1785259246826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 811.5530014038086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1292.8416728973389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2500}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2053.105354309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3094}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 987.3983860015869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3730}}}
{"qid": "7901746249864619718", "question": "when does the 14th season of grey's anatomy come out", "gold_answers": ["September 28 , 2017"], "shots": {"0": {"k": 0, "answer": "September 28, 2017", "latency_ms": 1488.8875484466553, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 28, 2017", "latency_ms": 1347.0854759216309, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 28, 2017", "latency_ms": 1542.4761772155762, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "September 28, 2017", "latency_ms": 1243.5486316680908, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2007}, "4": {"k": 4, "answer": "September 28, 2017", "latency_ms": 1684.6749782562256, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2695}, "5": {"k": 5, "answer": "September 28, 2017", "latency_ms": 1642.669677734375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3363}, "6": {"k": 6, "answer": "September 28, 2017", "latency_ms": 1943.9008235931396, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4005}}}
{"qid": "-896127746191949637", "question": "when was the first hunger games book published", "gold_answers": ["September 14 , 2008", "2008"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 732.6738834381104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 14, 2008", "latency_ms": 1398.766040802002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "September 14, 2008", "latency_ms": 1509.3977451324463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "September 14, 2008", "latency_ms": 972.5151062011719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1949}, "4": {"k": 4, "answer": "September 14, 2008", "latency_ms": 1917.043924331665, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2609}, "5": {"k": 5, "answer": "September 14, 2008", "latency_ms": 996.8514442443848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3258}, "6": {"k": 6, "answer": "September 14, 2008", "latency_ms": 1682.8088760375977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3913}}}
{"qid": "8044909700499569711", "question": "how much is the united states in debt to china", "gold_answers": ["$1.06 trillion", "1,200.5"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 480.7717800140381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1264.291524887085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 815.6979084014893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "21 percent", "latency_ms": 987.2875213623047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "$1.16 trillion", "latency_ms": 1051.7091751098633, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "$1.16 trillion", "latency_ms": 1039.9227142333984, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "$1.26 trillion", "latency_ms": 1095.80659866333, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3834}}}
{"qid": "-3123234845590594961", "question": "where did the race in grease take place", "gold_answers": ["Thunder Road"], "shots": {"0": {"k": 0, "answer": "The Thunder Road Race", "latency_ms": 336.8260860443115, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Novello theatre", "latency_ms": 672.2311973571777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "Rydell High School", "latency_ms": 1025.4337787628174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1207}, "3": {"k": 3, "answer": "a race course", "latency_ms": 754.8577785491943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1820}, "4": {"k": 4, "answer": "a race course", "latency_ms": 1012.4764442443848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Rydell High School", "latency_ms": 1079.7984600067139, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3102}, "6": {"k": 6, "answer": "a race course", "latency_ms": 785.6581211090088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3728}}}
{"qid": "4326992806019599297", "question": "what is the maximum data rate for the 802.11a standard select one", "gold_answers": ["54 Mbit / s"], "shots": {"0": {"k": 0, "answer": "54 Mbps", "latency_ms": 901.3204574584961, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 980.4463386535645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1079.7593593597412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1336}, "3": {"k": 3, "answer": "54 Mbit/s", "latency_ms": 1093.8849449157715, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2029}, "4": {"k": 4, "answer": "54 Mbit/s", "latency_ms": 1516.9379711151123, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2659}, "5": {"k": 5, "answer": "54 Mbit/s", "latency_ms": 1338.0012512207031, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3346}, "6": {"k": 6, "answer": "54 Mbit/s", "latency_ms": 1057.4326515197754, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3992}}}
{"qid": "6144099837933283715", "question": "a good that can be used in place of another good", "gold_answers": ["A substitute good", "substitute good"], "shots": {"0": {"k": 0, "answer": "Substitute", "latency_ms": 488.10362815856934, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "charcoal barbecues", "latency_ms": 1301.328182220459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 550}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 974.1580486297607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "Substitute", "latency_ms": 945.7993507385254, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "Substitute", "latency_ms": 955.1067352294922, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2332}, "5": {"k": 5, "answer": "Substitute", "latency_ms": 682.7037334442139, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2899}, "6": {"k": 6, "answer": "Substitute", "latency_ms": 923.7868785858154, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3473}}}
{"qid": "-4621948696356225060", "question": "where in the bible can i find the lord's prayer", "gold_answers": ["the Gospel of Luke", "the Gospel of Matthew"], "shots": {"0": {"k": 0, "answer": "Matthew 6:9-13, Luke 11:2-4", "latency_ms": 1757.5478553771973, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 983.9887619018555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 562}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 812.3397827148438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Gospel accounts", "latency_ms": 778.465986251831, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1925}, "4": {"k": 4, "answer": "the gospel accounts", "latency_ms": 1165.5070781707764, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2560}, "5": {"k": 5, "answer": "The Gospel accounts", "latency_ms": 1031.9631099700928, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1176.0964393615723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3938}}}
{"qid": "6941993254369956277", "question": "when was the last time nebraska voted democrat", "gold_answers": ["1964"], "shots": {"0": {"k": 0, "answer": "1964", "latency_ms": 653.449535369873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1936", "latency_ms": 1086.272954940796, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "1936", "latency_ms": 693.533182144165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1374}, "3": {"k": 3, "answer": "1936", "latency_ms": 1065.40846824646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2059}, "4": {"k": 4, "answer": "1936", "latency_ms": 1166.090726852417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2761}, "5": {"k": 5, "answer": "1964", "latency_ms": 1002.8407573699951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3408}, "6": {"k": 6, "answer": "1964", "latency_ms": 668.6258316040039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4059}}}
{"qid": "-8955197065025093046", "question": "who become the ceo of it wipro company in 2016", "gold_answers": ["Abid Ali Neemuchwala"], "shots": {"0": {"k": 0, "answer": "Abidali Neemuchwala", "latency_ms": 1469.8152542114258, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Not specified", "latency_ms": 475.9044647216797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 682}, "2": {"k": 2, "answer": "CEO", "latency_ms": 1138.0894184112549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1322}, "3": {"k": 3, "answer": "CEO", "latency_ms": 434.86809730529785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": "CEO", "latency_ms": 879.7626495361328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2593}, "5": {"k": 5, "answer": "Abidali Neemuchwala", "latency_ms": 1641.1542892456055, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3182}, "6": {"k": 6, "answer": "CEO from 1 February 2016", "latency_ms": 1511.6074085235596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3818}}}
{"qid": "-3010425579521817304", "question": "who does eric end up with in gossip girl", "gold_answers": ["Jenny"], "shots": {"0": {"k": 0, "answer": "Vanessa, then Serena, then no one, then Serena again, but ultimately Vanessa then Serena then finally  Blair's enemy, Vanessa's friend, and Dan's past love: Serena then finally Vanessa's friend: Serena then ultimately: Serena", "latency_ms": 7138.195037841797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1194.3776607513428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 609}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1267.9102420806885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1032.30619430542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1241.417407989502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2444}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1191.9856071472168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3069}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1023.0824947357178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3665}}}
{"qid": "7264112453286983469", "question": "who plays unis in she's the man", "gold_answers": ["Emily Perkins"], "shots": {"0": {"k": 0, "answer": "Amanda Bynes", "latency_ms": 1040.5216217041016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1029.3209552764893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1492.2852516174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1309.9181652069092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1088.9205932617188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2423}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1053.9846420288086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3098}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1546.2234020233154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3734}}}
{"qid": "2627695648792729859", "question": "who played booster in jingle all the way", "gold_answers": ["Curtis Armstrong"], "shots": {"0": {"k": 0, "answer": "Eric Lloyd", "latency_ms": 1010.528564453125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1336.6789817810059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1084.7551822662354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1310}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1001.5137195587158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1973}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1461.1055850982666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2606}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1482.9943180084229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3274}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1460.0586891174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3894}}}
{"qid": "-9169976182548289414", "question": "who is recognized as the founder of islam", "gold_answers": ["the Islamic prophet Muhammad", "Muhammad"], "shots": {"0": {"k": 0, "answer": "Muhammad", "latency_ms": 535.6655120849609, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 812.3440742492676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 679}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1168.6906814575195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Muhammad", "latency_ms": 603.0130386352539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1956}, "4": {"k": 4, "answer": "Muhammad", "latency_ms": 1194.793462753296, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2600}, "5": {"k": 5, "answer": "Muhammad", "latency_ms": 676.0861873626709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Muhammad", "latency_ms": 910.1700782775879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3824}}}
{"qid": "-6696747560626271522", "question": "who plays emma in air bud world pup", "gold_answers": ["Brittany Paige Bouck"], "shots": {"0": {"k": 0, "answer": "Brittany Paige Bouck", "latency_ms": 919.9495315551758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Brittany Paige Bouck", "latency_ms": 1162.947416305542, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 592}, "2": {"k": 2, "answer": "Brittany Paige Bouck", "latency_ms": 1187.525987625122, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "Brittany Paige Bouck", "latency_ms": 1557.9400062561035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1776}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 964.4787311553955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2393}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1835.289478302002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3000}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1297.4555492401123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3613}}}
{"qid": "5871681964137793716", "question": "how old was sasuke when his clan died", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "7 years old", "latency_ms": 826.8487453460693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seven", "latency_ms": 868.4844970703125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Seven", "latency_ms": 632.2808265686035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1247}, "3": {"k": 3, "answer": "Seven", "latency_ms": 980.6492328643799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Seven", "latency_ms": 384.51647758483887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Seven", "latency_ms": 1179.3873310089111, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3179}, "6": {"k": 6, "answer": "Seven", "latency_ms": 633.8338851928711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3832}}}
{"qid": "8552176802923865025", "question": "where do some of the natural air pollutants come from", "gold_answers": ["wildfires", "Dust", "Vegetation", "Carbon dioxide", "Volcanic activity"], "shots": {"0": {"k": 0, "answer": "Volcanic eruptions", "latency_ms": 1197.7789402008057, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "volcanic eruption", "latency_ms": 1169.957160949707, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "volcanic eruption", "latency_ms": 1217.9443836212158, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1333}, "3": {"k": 3, "answer": "Volcanic eruption", "latency_ms": 982.5847148895264, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2028}, "4": {"k": 4, "answer": "Volcanic eruption", "latency_ms": 1264.8894786834717, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2715}, "5": {"k": 5, "answer": "Volcanic eruption", "latency_ms": 1082.5610160827637, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3319}, "6": {"k": 6, "answer": "Volcanic eruptions, forest fires", "latency_ms": 2242.4445152282715, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4070}}}
{"qid": "-2630525064809360052", "question": "who is the pastor of new birth missionary baptist church now", "gold_answers": ["Stephen A. Davis"], "shots": {"0": {"k": 0, "answer": "Jamal Harrison Bryant", "latency_ms": 545.8657741546631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pastor Bryant", "latency_ms": 996.5732097625732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "Pastor Bryant", "latency_ms": 757.3647499084473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "Pastor Bryant", "latency_ms": 1222.7742671966553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1976}, "4": {"k": 4, "answer": "Jamal Bryant", "latency_ms": 1205.3706645965576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2654}, "5": {"k": 5, "answer": "Jamal Bryant", "latency_ms": 988.8172149658203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3327}, "6": {"k": 6, "answer": "Jamal Bryant", "latency_ms": 1170.292854309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3958}}}
{"qid": "6434931911289860123", "question": "who is doing 2018 super bowl half time show", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "Justin Timberlake", "latency_ms": 250.3829002380371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1169.4927215576172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1157.970905303955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1203.2675743103027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1517.7533626556396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "Maroon 5", "latency_ms": 1256.9303512573242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "Maroon 5", "latency_ms": 1260.5466842651367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3791}}}
{"qid": "8869318258439148973", "question": "who is playing the halftime show for the superbowl", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 856.0280799865723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1019.2816257476807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1062.2520446777344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1263}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 712.989091873169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Coldplay, Beyoncé, and Bruno Mars.", "latency_ms": 2257.213354110718, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2507}, "5": {"k": 5, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 1633.4011554718018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3089}, "6": {"k": 6, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 2080.049514770508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3726}}}
{"qid": "-8359866474144720253", "question": "who hosted they think it's all over", "gold_answers": ["Des Lynam", "Lee Mack", "comedian Nick Hancock", "Nick Hancock"], "shots": {"0": {"k": 0, "answer": "Nick Hancock", "latency_ms": 722.3055362701416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1044.1949367523193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1248.6388683319092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1657.1855545043945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1904}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 982.6273918151855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1285.6793403625488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1342.848539352417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3752}}}
{"qid": "-1206653570097564556", "question": "where does the movie proof of life take place", "gold_answers": ["The Republic of Tecala"], "shots": {"0": {"k": 0, "answer": "South America", "latency_ms": 830.4116725921631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 971.2128639221191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1062.5309944152832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1332}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1198.8353729248047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1974}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1339.4277095794678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2684}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1052.596092224121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3282}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1282.3481559753418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3879}}}
{"qid": "6144521615402262404", "question": "where does us highway 1 start and end", "gold_answers": ["Fort Kent , Maine", "to Key West , Florida", "Key West , Florida"], "shots": {"0": {"k": 0, "answer": "Fort Kent, Maine to Key West, Florida", "latency_ms": 1860.2409362792969, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1460.3204727172852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1053.9357662200928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 904.9568176269531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 536.5126132965088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2548}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1047.0385551452637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3132}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1302.0210266113281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3758}}}
{"qid": "-8631190913794477985", "question": "who scored the most points in a single game in the nba", "gold_answers": ["Wilt Chamberlain"], "shots": {"0": {"k": 0, "answer": "Wilt Chamberlain", "latency_ms": 612.3650074005127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1054.7173023223877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "Anthony Davis", "latency_ms": 442.6577091217041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1103}, "3": {"k": 3, "answer": "Anthony Davis", "latency_ms": 917.2368049621582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1713}, "4": {"k": 4, "answer": "Wilt Chamberlain", "latency_ms": 1337.475299835205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2281}, "5": {"k": 5, "answer": "Wilt Chamberlain", "latency_ms": 619.1024780273438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2906}, "6": {"k": 6, "answer": "Wilt Chamberlain", "latency_ms": 1347.909927368164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3538}}}
{"qid": "199896377614951764", "question": "where is natural gas found in the us", "gold_answers": ["Texas", "Pennsylvania", "Colorado", "New Mexico", "West Virginia", "Arkansas", "Wyoming", "Louisiana"], "shots": {"0": {"k": 0, "answer": "Various states including Texas, Alaska, and Pennsylvania", "latency_ms": 1042.6688194274902, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shale formations", "latency_ms": 960.9661102294922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Shale formations", "latency_ms": 883.1908702850342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "American Southwest", "latency_ms": 632.2586536407471, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1879}, "4": {"k": 4, "answer": "American Southwest", "latency_ms": 885.3511810302734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "Louisiana, Texas, California, Alaska, American Southwest", "latency_ms": 1516.935110092163, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 3187}, "6": {"k": 6, "answer": "Louisiana, Texas, California, Alaska", "latency_ms": 1251.331090927124, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3860}}}
{"qid": "8986775680996674901", "question": "when were the first general elections held in independent india", "gold_answers": ["1951 -- 52"], "shots": {"0": {"k": 0, "answer": "1951", "latency_ms": 578.8600444793701, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1951", "latency_ms": 383.96692276000977, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "25 October 1951", "latency_ms": 1325.0453472137451, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "1951-52", "latency_ms": 1024.6570110321045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "1951-52", "latency_ms": 1298.8600730895996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "1951", "latency_ms": 927.5765419006348, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3302}, "6": {"k": 6, "answer": "1951-52", "latency_ms": 1076.6277313232422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3999}}}
{"qid": "700604097171850168", "question": "what was the tower of london originally used for", "gold_answers": ["as a royal residence", "a royal residence"], "shots": {"0": {"k": 0, "answer": "Royal Palace", "latency_ms": 1036.4739894866943, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Norman Conquest of England", "latency_ms": 1387.2323036193848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 568}, "2": {"k": 2, "answer": "as part of the Norman Conquest of England", "latency_ms": 2121.976375579834, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 1166}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 975.7053852081299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1773}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1234.7095012664795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2406}, "5": {"k": 5, "answer": "Storage", "latency_ms": 647.0119953155518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2990}, "6": {"k": 6, "answer": "incidental role of the Tower – as would have been the case for any castle", "latency_ms": 2442.758083343506, "em": 0.0, "f1": 0.125, "containment": 0.0, "context_chars": 3646}}}
{"qid": "6745303307988470742", "question": "what type of fuel goes in a zippo", "gold_answers": ["butane", "lighter fluid"], "shots": {"0": {"k": 0, "answer": "Lighter fluid", "latency_ms": 785.789966583252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 765.0256156921387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "Lighter fluid", "latency_ms": 1197.9024410247803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Lighter fluid", "latency_ms": 749.3562698364258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1815}, "4": {"k": 4, "answer": "Lighter fluid", "latency_ms": 1000.6041526794434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2385}, "5": {"k": 5, "answer": "Naphtha or butane", "latency_ms": 1556.135654449463, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3011}, "6": {"k": 6, "answer": "Naphtha or butane", "latency_ms": 1063.5993480682373, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3676}}}
{"qid": "-2060506905455252030", "question": "first jnanpith award was an autor of which language", "gold_answers": ["Malayalam"], "shots": {"0": {"k": 0, "answer": "Gujarati", "latency_ms": 1068.4869289398193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 743.3874607086182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Not mentioned", "latency_ms": 672.7249622344971, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1310}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1312.041997909546, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 767.005443572998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2610}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 981.3745021820068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "Malayalam", "latency_ms": 870.1183795928955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3951}}}
{"qid": "4738663028303377024", "question": "who played the mad hatter in the batman tv show", "gold_answers": ["Roddy McDowall", "David Wayne", "Benedict Samuel"], "shots": {"0": {"k": 0, "answer": "David Wayne", "latency_ms": 681.2753677368164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "David Wayne", "latency_ms": 682.0545196533203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 791.3966178894043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Peter MacNicol", "latency_ms": 1046.1242198944092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1244.0528869628906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 569.9722766876221, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3214}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1292.7050590515137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3845}}}
{"qid": "-1650946015201779846", "question": "how many cracker barrels in the united states", "gold_answers": ["639", "more than 600"], "shots": {"0": {"k": 0, "answer": "645 locations", "latency_ms": 685.3444576263428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "645 stores in 44 states", "latency_ms": 1560.584545135498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "645 stores in 44 states", "latency_ms": 1087.7442359924316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "645 stores in 44 states", "latency_ms": 1645.0159549713135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "645 stores in 44 states", "latency_ms": 1080.3465843200684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "645 stores in 44 states", "latency_ms": 1872.335433959961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3248}, "6": {"k": 6, "answer": "645 stores in 44 states", "latency_ms": 1428.5223484039307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3892}}}
{"qid": "-3422350952909582054", "question": "in photosynthesis the carbon in co2 is initially fixed to what molecule", "gold_answers": ["3 - phosphoglycerate"], "shots": {"0": {"k": 0, "answer": "RuBP", "latency_ms": 166.37182235717773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a 3-carbon molecule", "latency_ms": 2028.3544063568115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 724}, "2": {"k": 2, "answer": "glucose", "latency_ms": 451.53260231018066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1403}, "3": {"k": 3, "answer": "carbohydrates", "latency_ms": 958.8093757629395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2067}, "4": {"k": 4, "answer": "Carbohydrates", "latency_ms": 1014.0562057495117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2871}, "5": {"k": 5, "answer": "Carbohydrates", "latency_ms": 1223.7684726715088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3552}, "6": {"k": 6, "answer": "carbohydrates", "latency_ms": 1062.8457069396973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4261}}}
{"qid": "-2704708103393811482", "question": "who voices randy in f is for family", "gold_answers": ["T.J. Miller"], "shots": {"0": {"k": 0, "answer": "Bill Burr", "latency_ms": 417.6921844482422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 815.1512145996094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 567}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1441.032886505127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1139.563798904419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "Bill Burr", "latency_ms": 1016.4413452148438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2509}, "5": {"k": 5, "answer": "Bill Burr", "latency_ms": 889.4636631011963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "Bill Burr", "latency_ms": 897.9017734527588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3769}}}
{"qid": "5482012214308896475", "question": "how many countries does cadbury sell its products", "gold_answers": ["more than 50", "more than 50 countries worldwide"], "shots": {"0": {"k": 0, "answer": "160 countries", "latency_ms": 675.4963397979736, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "At least 3", "latency_ms": 1238.842487335205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "30 countries", "latency_ms": 749.2976188659668, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "50", "latency_ms": 631.6525936126709, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2026}, "4": {"k": 4, "answer": "more than fifty", "latency_ms": 1265.0117874145508, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "50", "latency_ms": 678.2691478729248, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3438}, "6": {"k": 6, "answer": "50", "latency_ms": 593.3008193969727, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4084}}}
{"qid": "-5737509619250561344", "question": "ethiopia flight 961 crashes in to the sea", "gold_answers": ["23 November 1996"], "shots": {"0": {"k": 0, "answer": "November 23, 1996", "latency_ms": 1150.4418849945068, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indian Ocean", "latency_ms": 1010.5195045471191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Indian Ocean", "latency_ms": 650.3732204437256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "Indian Ocean", "latency_ms": 1004.3213367462158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1996}, "4": {"k": 4, "answer": "Indian Ocean", "latency_ms": 936.2101554870605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Indian Ocean", "latency_ms": 940.7575130462646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3311}, "6": {"k": 6, "answer": "Indian Ocean", "latency_ms": 462.13746070861816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3968}}}
{"qid": "-7175456993713717070", "question": "what does istj mean in a personality test", "gold_answers": ["Extroverted Thinking ( Te )", "Extroverted Intuition ( Ne )", "Introverted Feeling ( Fi )", "Introverted Sensing ( Si )"], "shots": {"0": {"k": 0, "answer": "Introverted, Sensing, Thinking, Judging", "latency_ms": 1600.6042957305908, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Introverted, Sensing, Thinking, Judging", "latency_ms": 2025.6028175354004, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 709}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1230.6385040283203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1337}, "3": {"k": 3, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 1786.9784832000732, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2063}, "4": {"k": 4, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 1758.4381103515625, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2706}, "5": {"k": 5, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 1776.9567966461182, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3367}, "6": {"k": 6, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 1759.0980529785156, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4054}}}
{"qid": "4437170343606050664", "question": "who does the voice of ash in sing", "gold_answers": ["Scarlett Johansson"], "shots": {"0": {"k": 0, "answer": "Scarlett Johansson", "latency_ms": 881.340503692627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1217.4181938171387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 794.6012020111084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1185}, "3": {"k": 3, "answer": "Veronica Taylor", "latency_ms": 1288.6228561401367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1099.0216732025146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2412}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1282.5021743774414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3011}, "6": {"k": 6, "answer": "The children", "latency_ms": 1214.7483825683594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3606}}}
{"qid": "-8773010039077552394", "question": "who scored the most points in their nba career", "gold_answers": ["Kareem Abdul - Jabbar"], "shots": {"0": {"k": 0, "answer": "LeBron James", "latency_ms": 793.1013107299805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1380.4597854614258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1113.361120223999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1144}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1582.6537609100342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1730}, "4": {"k": 4, "answer": "Kareem Abdul-Jabbar", "latency_ms": 1601.978063583374, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2335}, "5": {"k": 5, "answer": "Kareem Abdul-Jabbar", "latency_ms": 1838.5710716247559, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2900}, "6": {"k": 6, "answer": "Kareem Abdul-Jabbar", "latency_ms": 1453.3920288085938, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3496}}}
{"qid": "-3278224144622911032", "question": "with a land area of 54 314 square miles where does wisconsin rank among the 50 states", "gold_answers": ["25"], "shots": {"0": {"k": 0, "answer": "23rd", "latency_ms": 672.4779605865479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1269.5837020874023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 883.2519054412842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1311.8979930877686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1784}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1127.0465850830078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2396}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 987.5333309173584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2983}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1038.8801097869873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3540}}}
{"qid": "-3466298422174960041", "question": "who plays charles on have and have nots", "gold_answers": ["Nick Sager", "Nick Sagar"], "shots": {"0": {"k": 0, "answer": "Aaron O'Connell", "latency_ms": 719.9645042419434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1041.3341522216797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 850.5194187164307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1099.806547164917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1095.9413051605225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2489}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1309.1766834259033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1104.7897338867188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3756}}}
{"qid": "1803248910342766083", "question": "who wrote the book my country my life", "gold_answers": ["L.K. Advani"], "shots": {"0": {"k": 0, "answer": "L.K. Advani", "latency_ms": 1012.7534866333008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "L. K. Advani", "latency_ms": 871.3812828063965, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "L. K. Advani", "latency_ms": 761.2628936767578, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1158}, "3": {"k": 3, "answer": "L. K. Advani", "latency_ms": 1113.3501529693604, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1794}, "4": {"k": 4, "answer": "L. K. Advani", "latency_ms": 1432.5265884399414, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "L. K. Advani", "latency_ms": 1159.4274044036865, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3080}, "6": {"k": 6, "answer": "L. K. Advani", "latency_ms": 1370.6319332122803, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3738}}}
{"qid": "-1176280233636154422", "question": "when did the east india company take control of india", "gold_answers": ["1757", "1799", "1612", "in 1757"], "shots": {"0": {"k": 0, "answer": "1757", "latency_ms": 228.39117050170898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1757", "latency_ms": 891.7665481567383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "1757", "latency_ms": 387.01939582824707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1317}, "3": {"k": 3, "answer": "1757", "latency_ms": 501.73139572143555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1952}, "4": {"k": 4, "answer": "1757", "latency_ms": 633.7323188781738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "1757", "latency_ms": 710.3636264801025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3244}, "6": {"k": 6, "answer": "1757", "latency_ms": 697.0760822296143, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3884}}}
{"qid": "5911119091653953181", "question": "where does the water come from to fill lake eyre", "gold_answers": ["Warburton River"], "shots": {"0": {"k": 0, "answer": "Cooper Creek", "latency_ms": 916.203498840332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "inland Queensland", "latency_ms": 437.99638748168945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "semi-arid inland Queensland", "latency_ms": 1329.8473358154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "Semi-arid inland Queensland", "latency_ms": 1096.1909294128418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "the river systems of semi-arid inland Queensland", "latency_ms": 1414.4041538238525, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2374}, "5": {"k": 5, "answer": "the river systems of semi-arid inland Queensland", "latency_ms": 1209.7923755645752, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3005}, "6": {"k": 6, "answer": "the river systems of semi-arid inland Queensland", "latency_ms": 1473.785400390625, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3627}}}
{"qid": "5557104327881436095", "question": "who is the founder of google and when was it founded", "gold_answers": ["1998", "Sergey Brin", "Larry Page and Sergey Brin", "Larry Page"], "shots": {"0": {"k": 0, "answer": "Larry Page, September 4, 1998", "latency_ms": 1104.5174598693848, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 824.2933750152588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Page and Brin, September 4, 1998", "latency_ms": 1981.3008308410645, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Page and Brin, 1998", "latency_ms": 1877.2926330566406, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1916}, "4": {"k": 4, "answer": "Page and Brin, 1998", "latency_ms": 1679.161787033081, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2551}, "5": {"k": 5, "answer": "Page and Brin, 1998", "latency_ms": 1458.3525657653809, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3186}, "6": {"k": 6, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 2594.6316719055176, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 3830}}}
{"qid": "-1333328812971005142", "question": "who did the dominican republic gain its independence from", "gold_answers": ["Haiti"], "shots": {"0": {"k": 0, "answer": "Haiti", "latency_ms": 553.4713268280029, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spain and Haiti", "latency_ms": 1006.1638355255127, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 667}, "2": {"k": 2, "answer": "Spain and Haiti", "latency_ms": 934.6730709075928, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1342}, "3": {"k": 3, "answer": "Haiti and Spain", "latency_ms": 1341.691017150879, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2022}, "4": {"k": 4, "answer": "Haiti and Spain", "latency_ms": 789.3152236938477, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2736}, "5": {"k": 5, "answer": "Haiti and Spain", "latency_ms": 1097.426176071167, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3373}, "6": {"k": 6, "answer": "Haiti and Spain", "latency_ms": 1297.0924377441406, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4093}}}
{"qid": "1122605495295045742", "question": "how did early humans make use of stones during the prehistoric period", "gold_answers": ["start fires", "hunt", "bury their dead"], "shots": {"0": {"k": 0, "answer": "Tool making", "latency_ms": 216.18294715881348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in the manufacture of implements with a sharp edge, a point, or a percussion surface.", "latency_ms": 2300.3411293029785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 1689.0289783477783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 2266.087293624878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 1728.2493114471436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2626}, "5": {"k": 5, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 1766.4597034454346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3326}, "6": {"k": 6, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 1668.9176559448242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3975}}}
{"qid": "7402184777947527945", "question": "who wrote the text for jeanie with the light brown hair", "gold_answers": ["Stephen Foster"], "shots": {"0": {"k": 0, "answer": "Maud Irving's husband, Robert Burns,  is often incorrectly credited, but actually Maud's husband was not the poet, the actual poet was Robert Burns' namesake,  but the text was actually written by Maud's friend, but actually the text for \"Jeanie with the Light Brown Hair\" was written by Maud's friend's namesake, but actually it was written by: Maud Irving's friend: Robert Burns' namesake:  Robert Burns' friend:  Maud's friend: Robert's friend:  Maud's husband's namesake: Robert's namesake:  Robert's friend:  Robert's namesake:  Robert's friend:  Robert's namesake: Robert's friend:  Robert's namesake: Robert's friend: Robert's namesake: Robert's friend: Robert's namesake: Robert's friend: Robert's namesake: Robert's friend: Robert's namesake: Robert's friend: Robert's namesake: Robert's friend: Robert's namesake: Robert's friend: Robert's namesake: Robert's friend: Robert's namesake: Robert's friend: Robert's namesake: Robert's friend: Robert's namesake: Robert's friend: Robert's namesake: Robert's", "latency_ms": 30724.39956665039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stephen Foster", "latency_ms": 876.8324851989746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Stephen Foster", "latency_ms": 883.3398818969727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1222}, "3": {"k": 3, "answer": "Stephen Foster", "latency_ms": 1216.0301208496094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Stephen Foster", "latency_ms": 938.7705326080322, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Stephen Foster", "latency_ms": 944.6995258331299, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "Stephen Foster", "latency_ms": 818.1660175323486, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3757}}}
{"qid": "1656745334095178455", "question": "the basic steps of rational decision making include defining goals and", "gold_answers": ["Implementation of plans / policies"], "shots": {"0": {"k": 0, "answer": "identifying alternatives", "latency_ms": 781.5368175506592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "identifying alternatives", "latency_ms": 1179.4064044952393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1086.8449211120605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "problem definition", "latency_ms": 909.5630645751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2121}, "4": {"k": 4, "answer": "problem definition", "latency_ms": 689.2597675323486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2754}, "5": {"k": 5, "answer": "identifying problems", "latency_ms": 924.213171005249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3406}, "6": {"k": 6, "answer": "verifying", "latency_ms": 644.2849636077881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4094}}}
{"qid": "-216657635823030751", "question": "when was the design period known as art deco", "gold_answers": ["1910 -- 1939"], "shots": {"0": {"k": 0, "answer": "1920s to 1940s", "latency_ms": 961.3466262817383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "20th century", "latency_ms": 1129.1100978851318, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "just before World War I", "latency_ms": 1096.780776977539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1343}, "3": {"k": 3, "answer": "just before World War I", "latency_ms": 1291.60737991333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2025}, "4": {"k": 4, "answer": "just before World War I", "latency_ms": 888.7479305267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2688}, "5": {"k": 5, "answer": "just before World War I", "latency_ms": 1009.7196102142334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3372}, "6": {"k": 6, "answer": "just before World War I", "latency_ms": 795.2487468719482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4018}}}
{"qid": "250542332339248886", "question": "where does the bob and tom show broadcast from", "gold_answers": ["WFBQ in Indianapolis , Indiana", "Indianapolis , Indiana"], "shots": {"0": {"k": 0, "answer": "Indianapolis", "latency_ms": 492.2904968261719, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indianapolis, Indiana", "latency_ms": 1329.8423290252686, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Indianapolis, Indiana", "latency_ms": 1523.245096206665, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Indianapolis, Indiana", "latency_ms": 1021.0962295532227, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1825}, "4": {"k": 4, "answer": "WFBQ in Indianapolis, Indiana", "latency_ms": 1486.8404865264893, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2443}, "5": {"k": 5, "answer": "Indianapolis, Indiana", "latency_ms": 1539.8988723754883, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3077}, "6": {"k": 6, "answer": "WFBQ in Indianapolis, Indiana", "latency_ms": 1476.2227535247803, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3685}}}
{"qid": "7610758795954724809", "question": "star wars the clone wars season 3 episode 1", "gold_answers": ["Clone Cadets"], "shots": {"0": {"k": 0, "answer": "Clone Cadets", "latency_ms": 691.859245300293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 919.5418357849121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1066.4021968841553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1120.1064586639404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2030}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1222.1906185150146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2678}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 795.5045700073242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3310}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1263.9293670654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3953}}}
{"qid": "2997223939033016160", "question": "what part of brain is responsible for complex thinking", "gold_answers": ["the frontal lobe"], "shots": {"0": {"k": 0, "answer": "Cerebrum", "latency_ms": 825.3576755523682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Brain", "latency_ms": 822.6816654205322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Cerebral cortex", "latency_ms": 986.5400791168213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Cerebral cortex", "latency_ms": 876.7688274383545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1876}, "4": {"k": 4, "answer": "Cerebral cortex", "latency_ms": 1223.242998123169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2560}, "5": {"k": 5, "answer": "Cerebral cortex", "latency_ms": 1406.177043914795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "Cerebral cortex", "latency_ms": 1414.9158000946045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3843}}}
{"qid": "2680196226239522881", "question": "who won the champions league final in 2016", "gold_answers": ["Real Madrid"], "shots": {"0": {"k": 0, "answer": "Real Madrid", "latency_ms": 181.1072826385498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1219.1646099090576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1008.798360824585, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 583.1940174102783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Real Madrid", "latency_ms": 869.847297668457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2523}, "5": {"k": 5, "answer": "Real Madrid", "latency_ms": 753.0667781829834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Real Madrid", "latency_ms": 925.7705211639404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3744}}}
{"qid": "-8458006812258546025", "question": "who has the most gold medals in the winter olympics of all time", "gold_answers": ["Norway"], "shots": {"0": {"k": 0, "answer": "Marit Bjoergen", "latency_ms": 1124.5219707489014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canada", "latency_ms": 962.6853466033936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Canada", "latency_ms": 1124.9327659606934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Norway and Canada and Germany", "latency_ms": 946.0351467132568, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Norway and Canada and Germany", "latency_ms": 1397.2759246826172, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2407}, "5": {"k": 5, "answer": "Marit Bjørgen", "latency_ms": 1428.523063659668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3015}, "6": {"k": 6, "answer": "Marit Bjørgen", "latency_ms": 1440.2096271514893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3626}}}
