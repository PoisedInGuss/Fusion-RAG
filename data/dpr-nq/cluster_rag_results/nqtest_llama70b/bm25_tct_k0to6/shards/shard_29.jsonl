{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 837.1837139129639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1060.595989227295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "June 22, 2018", "latency_ms": 1554.7974109649658, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "June 22, 2018", "latency_ms": 1160.8734130859375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "June 22, 2018", "latency_ms": 1558.7940216064453, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 1644.8500156402588, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "June 22, 2018", "latency_ms": 1375.2126693725586, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3802}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Freestyle, Nordic Combined, Ski Jumping, Biathlon.", "latency_ms": 2734.4515323638916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alpine skiing", "latency_ms": 1196.7430114746094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Alpine, Freestyle", "latency_ms": 814.4073486328125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Alpine, Freestyle", "latency_ms": 595.1240062713623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 1421.5474128723145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 1566.3402080535889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "Alpine, Freestyle, Cross-country", "latency_ms": 1326.4811038970947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3922}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "Arianwen Parkes-Lockwood", "latency_ms": 979.8099994659424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Aldo Mignone", "latency_ms": 1461.0462188720703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 694}, "2": {"k": 2, "answer": "Aldo Mignone", "latency_ms": 1860.8357906341553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Aldo Mignone", "latency_ms": 1440.0410652160645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Aldo Mignone", "latency_ms": 1417.8218841552734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2560}, "5": {"k": 5, "answer": "Aldo Mignone", "latency_ms": 1401.289701461792, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3227}, "6": {"k": 6, "answer": "Aldo Mignone", "latency_ms": 1118.5829639434814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3824}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "Bengals, Dolphins, Broncos, Chargers", "latency_ms": 1668.4925556182861, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1306.5614700317383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 551}, "2": {"k": 2, "answer": "Giants, Chargers, and others not specified", "latency_ms": 2065.6192302703857, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 1156}, "3": {"k": 3, "answer": "Giants, Chargers, Broncos", "latency_ms": 1510.5023384094238, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1711}, "4": {"k": 4, "answer": "Giants, Chargers, Broncos", "latency_ms": 1959.186315536499, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2294}, "5": {"k": 5, "answer": "Chargers, Bengals, Broncos", "latency_ms": 1311.0003471374512, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2888}, "6": {"k": 6, "answer": "Chargers, Bengals, Broncos", "latency_ms": 2183.178186416626, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3442}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "December 8, 1985", "latency_ms": 1419.3689823150635, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 December 1985", "latency_ms": 1101.4339923858643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 727}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 1289.1299724578857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1447}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 1094.9609279632568, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2143}, "4": {"k": 4, "answer": "8 December 1985", "latency_ms": 1532.1636199951172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2840}, "5": {"k": 5, "answer": "December 8, 1985", "latency_ms": 2218.75262260437, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 3557}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 1295.5312728881836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4258}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "Spanish moss", "latency_ms": 525.8781909942627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 761.2309455871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1222.1994400024414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1381}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1203.601598739624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2092}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1275.7816314697266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2735}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1535.4714393615723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3346}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1347.9466438293457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3996}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "I-IV", "latency_ms": 1105.2861213684082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canadian Cardiovascular Society", "latency_ms": 485.5227470397949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 762}, "2": {"k": 2, "answer": "Canadian Cardiovascular Society", "latency_ms": 569.7033405303955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1494}, "3": {"k": 3, "answer": "Canadian Cardiovascular Society", "latency_ms": 997.2095489501953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2250}, "4": {"k": 4, "answer": "Canadian Cardiovascular Society grading", "latency_ms": 1488.1553649902344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2959}, "5": {"k": 5, "answer": "Canadian Cardiovascular Society", "latency_ms": 1499.6604919433594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}, "6": {"k": 6, "answer": "Canadian Cardiovascular Society", "latency_ms": 985.7304096221924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4342}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Charles and Eddie", "latency_ms": 591.7026996612549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1296.9610691070557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1329.4649124145508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1018.7649726867676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1545.9792613983154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2447}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1352.6561260223389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1450.6664276123047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3635}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 553.062915802002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 466.3245677947998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1050.3630638122559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "3", "latency_ms": 419.39568519592285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "3", "latency_ms": 935.8975887298584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2466}, "5": {"k": 5, "answer": "3", "latency_ms": 389.0516757965088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "3", "latency_ms": 403.8255214691162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3661}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "A cake", "latency_ms": 745.0940608978271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Biscuit-sized cakes", "latency_ms": 1043.8852310180664, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "cake", "latency_ms": 576.1008262634277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "cake", "latency_ms": 420.61901092529297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1764}, "4": {"k": 4, "answer": "A cake", "latency_ms": 911.7422103881836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "A cake.", "latency_ms": 703.5737037658691, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3040}, "6": {"k": 6, "answer": "A cake.", "latency_ms": 1213.3615016937256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Seth MacFarlane", "latency_ms": 599.5016098022461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seth MacFarlane", "latency_ms": 1297.3568439483643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "Seth MacFarlane", "latency_ms": 1330.9621810913086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "Seth MacFarlane", "latency_ms": 1237.0173931121826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 1619.1880702972412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 1535.2137088775635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3190}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 1558.0816268920898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3857}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "Heroin", "latency_ms": 242.9485321044922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amphetamines", "latency_ms": 589.4098281860352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1274.756908416748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1513.793706893921, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1524.9152183532715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1053.417682647705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3135}, "6": {"k": 6, "answer": "Diet pills", "latency_ms": 957.7062129974365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3712}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "14 weeks", "latency_ms": 480.6690216064453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1006.6633224487305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 571}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1031.6472053527832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1153}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1543.6136722564697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1779}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1292.4048900604248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2373}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1299.933671951294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2928}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1276.658296585083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3520}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "Yushan, China", "latency_ms": 853.5397052764893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Manchester, England", "latency_ms": 916.3346290588379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "Sheffield, England", "latency_ms": 1268.5542106628418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Sheffield, England", "latency_ms": 1241.6176795959473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1900}, "4": {"k": 4, "answer": "Sheffield, England", "latency_ms": 1218.6088562011719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2517}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1224.9462604522705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3197}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1201.6987800598145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3841}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "Thad Luckinbill", "latency_ms": 1171.215295791626, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1176.2583255767822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1548.7313270568848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1154.8781394958496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1868}, "4": {"k": 4, "answer": "Thad Luckinbill", "latency_ms": 1087.1515274047852, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Thad Luckinbill", "latency_ms": 1304.485559463501, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1208.9190483093262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3746}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 724.7998714447021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1329.533576965332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1449.3932723999023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "1986", "latency_ms": 923.4890937805176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "1986", "latency_ms": 604.5374870300293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "1986", "latency_ms": 957.4887752532959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3208}, "6": {"k": 6, "answer": "1986", "latency_ms": 1138.9727592468262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3832}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "J-Rock", "latency_ms": 783.8897705078125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alexz Johnson", "latency_ms": 950.7648944854736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Alexz Johnson", "latency_ms": 767.9309844970703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Alexz Johnson", "latency_ms": 990.1258945465088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Alexz Johnson", "latency_ms": 1017.9619789123535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2608}, "5": {"k": 5, "answer": "Alexz Johnson", "latency_ms": 1283.651351928711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3259}, "6": {"k": 6, "answer": "Alexz Johnson", "latency_ms": 1041.8453216552734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3906}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "2006", "latency_ms": 700.5176544189453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 million years ago", "latency_ms": 1038.7935638427734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "360 million years ago", "latency_ms": 968.3783054351807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "360 million years ago", "latency_ms": 1174.950361251831, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1920}, "4": {"k": 4, "answer": "360 million years ago", "latency_ms": 1518.1591510772705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "March 2002", "latency_ms": 1232.1372032165527, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3206}, "6": {"k": 6, "answer": "March 2002", "latency_ms": 1646.4998722076416, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3826}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "Master Sergeant", "latency_ms": 1014.7485733032227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Master Sergeant", "latency_ms": 903.1188488006592, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "First Sergeant", "latency_ms": 1445.450782775879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1345}, "3": {"k": 3, "answer": "First Sergeant", "latency_ms": 1100.4741191864014, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1991}, "4": {"k": 4, "answer": "First Sergeant", "latency_ms": 1065.5019283294678, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2718}, "5": {"k": 5, "answer": "First Sergeant", "latency_ms": 464.4162654876709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3336}, "6": {"k": 6, "answer": "First Sergeant", "latency_ms": 1174.0319728851318, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4052}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 1071.3396072387695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "GNU project", "latency_ms": 1114.2714023590088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 954.094648361206, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 993.8564300537109, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1999}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 1132.3127746582031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 1067.655324935913, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3296}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 842.846155166626, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3928}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1103.8801670074463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1230.7534217834473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 782.7448844909668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1180}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1262.1939182281494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1777}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1095.0822830200195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2314}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1062.668800354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2918}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1194.3600177764893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3517}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Ed Roland", "latency_ms": 928.1091690063477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 702.06618309021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 1109.278917312622, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 710.7446193695068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1992}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 450.1757621765137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2678}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 1008.049488067627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3316}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 1168.562412261963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3959}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 879.4817924499512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cleveland Cavaliers", "latency_ms": 1226.1924743652344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 1120.9478378295898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 927.6223182678223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 667.8438186645508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2450}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 862.6821041107178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3025}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 922.2376346588135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3652}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1143.815517425537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1338.3574485778809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "100 centésimos = 1 peso", "latency_ms": 1655.3668975830078, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "Guaraní", "latency_ms": 1216.63498878479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Guaraní", "latency_ms": 1023.7855911254883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2454}, "5": {"k": 5, "answer": "PYG6155", "latency_ms": 1266.5958404541016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "Guarani (PYG)", "latency_ms": 2203.5605907440186, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3749}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "Midazolam", "latency_ms": 1170.4931259155273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "It is not specified.", "latency_ms": 1608.7512969970703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "Benzodiazepine", "latency_ms": 1493.4253692626953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1445}, "3": {"k": 3, "answer": "Benzodiazepine", "latency_ms": 1837.5179767608643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2125}, "4": {"k": 4, "answer": "Benzodiazepine", "latency_ms": 1672.8174686431885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2805}, "5": {"k": 5, "answer": "Benzodiazepine", "latency_ms": 1595.5560207366943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3491}, "6": {"k": 6, "answer": "Benzodiazepine", "latency_ms": 1185.9121322631836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4171}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 1058.7687492370605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "26,000 years", "latency_ms": 1239.1400337219238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "26,000 years", "latency_ms": 1557.901382446289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1207}, "3": {"k": 3, "answer": "25,772 years", "latency_ms": 1356.933355331421, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "25,772 years", "latency_ms": 1056.2748908996582, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2481}, "5": {"k": 5, "answer": "25,772 years", "latency_ms": 1363.8696670532227, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "25,772 years", "latency_ms": 1007.3432922363281, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3729}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 1013.8363838195801, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1050.0569343566895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Texas A&M", "latency_ms": 1193.7618255615234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Texas A&M Aggies", "latency_ms": 1150.6571769714355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1904}, "4": {"k": 4, "answer": "Texas A&M Aggies", "latency_ms": 942.0533180236816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Texas A&M Aggies", "latency_ms": 1128.7901401519775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Texas A&M", "latency_ms": 807.7394962310791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3748}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and Non-Renewable.", "latency_ms": 1496.295690536499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable or non-renewable", "latency_ms": 1679.8908710479736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable or non-renewable", "latency_ms": 1955.9755325317383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1447}, "3": {"k": 3, "answer": "renewable or non-renewable", "latency_ms": 1707.094430923462, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2177}, "4": {"k": 4, "answer": "renewable or non-renewable", "latency_ms": 1937.6554489135742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2828}, "5": {"k": 5, "answer": "renewable or non-renewable", "latency_ms": 2183.3369731903076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3469}, "6": {"k": 6, "answer": "renewable or non-renewable", "latency_ms": 1693.7496662139893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4200}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "New life and good luck", "latency_ms": 1027.9088020324707, "em": 0.0, "f1": 0.20000000000000004, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parental devotion", "latency_ms": 719.7728157043457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "parental devotion", "latency_ms": 1022.8891372680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Parental devotion", "latency_ms": 1056.9641590118408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "Purity", "latency_ms": 922.1858978271484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2459}, "5": {"k": 5, "answer": "Purity", "latency_ms": 457.06844329833984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3065}, "6": {"k": 6, "answer": "Purity", "latency_ms": 1110.2404594421387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3706}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Virat Kohli", "latency_ms": 377.78711318969727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1254.4119358062744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1313.9824867248535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 881.4938068389893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1048.7499237060547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1000.2086162567139, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3144}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1028.2301902770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3769}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "the antimicrobial action of metal ions.", "latency_ms": 1068.5968399047852, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals", "latency_ms": 1138.1378173828125, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "biocidal effect of metals", "latency_ms": 1832.521915435791, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "biocidal effect of metals", "latency_ms": 1581.754446029663, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2081}, "4": {"k": 4, "answer": "biocidal effect of metals", "latency_ms": 870.7010746002197, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2746}, "5": {"k": 5, "answer": "biocidal effect of metals", "latency_ms": 1792.1996116638184, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3407}, "6": {"k": 6, "answer": "biocidal effect of metals", "latency_ms": 1425.6162643432617, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4072}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "Dustin Higgs", "latency_ms": 937.0913505554199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 942.3611164093018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1278.5134315490723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 834.4242572784424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1904}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1344.6016311645508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Walter LaGrand", "latency_ms": 993.4380054473877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3136}, "6": {"k": 6, "answer": "Walter LaGrand", "latency_ms": 1033.7941646575928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the auction.", "latency_ms": 579.5590877532959, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the conclusion of play", "latency_ms": 1036.6370677947998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 550}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 1305.1795959472656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1156}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 557.7418804168701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1797}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 1293.8826084136963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2367}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 1323.2061862945557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2949}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 1015.7780647277832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3567}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Afghanistan", "latency_ms": 803.2844066619873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 767.9197788238525, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 699}, "2": {"k": 2, "answer": "Afghanistan", "latency_ms": 718.4805870056152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Afghanistan", "latency_ms": 807.0948123931885, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2076}, "4": {"k": 4, "answer": "Afghanistan", "latency_ms": 1235.7029914855957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2735}, "5": {"k": 5, "answer": "Afghanistan", "latency_ms": 916.6710376739502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3469}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 1132.8825950622559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4195}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "Coagulation, Fibrin formation, Clot retraction", "latency_ms": 1345.9491729736328, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1202.6574611663818, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1019.08278465271, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1156.005859375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 722.7787971496582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2607}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1220.137357711792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3321}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 979.1715145111084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4055}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "Sebastian Hunsinger", "latency_ms": 1113.7819290161133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shawn Roberts", "latency_ms": 1192.5959587097168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "Shawn Roberts", "latency_ms": 492.919921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1354}, "3": {"k": 3, "answer": "Shawn Roberts", "latency_ms": 947.5226402282715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2062}, "4": {"k": 4, "answer": "Shawn Roberts", "latency_ms": 809.2854022979736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2695}, "5": {"k": 5, "answer": "Shawn Roberts", "latency_ms": 738.8710975646973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3389}, "6": {"k": 6, "answer": "Shirley Henderson", "latency_ms": 954.500675201416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4021}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "20 November 1989", "latency_ms": 581.9065570831299, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 762.3209953308105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 846.5769290924072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1313}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 1269.409418106079, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1931}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 1237.0424270629883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2637}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 1029.3054580688477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3277}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 1690.307855606079, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3945}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "2016", "latency_ms": 703.2508850097656, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2016", "latency_ms": 633.1660747528076, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "2016 EU Referendum", "latency_ms": 1094.3713188171387, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "2016 EU Referendum", "latency_ms": 1862.497091293335, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "2016 EU Referendum", "latency_ms": 1031.9454669952393, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2581}, "5": {"k": 5, "answer": "June 2016", "latency_ms": 1279.4334888458252, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3170}, "6": {"k": 6, "answer": "June 2016", "latency_ms": 1046.180248260498, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3751}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 432.70111083984375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1 World Trade Center", "latency_ms": 514.498233795166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 995.9046840667725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 1078.5646438598633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 1272.9103565216064, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2644}, "5": {"k": 5, "answer": "Burj Khalifa", "latency_ms": 937.5462532043457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3256}, "6": {"k": 6, "answer": "Burj Khalifa", "latency_ms": 1509.789228439331, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3973}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "Miriam Margolyes", "latency_ms": 664.2651557922363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1000.0991821289062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Miranda Hart", "latency_ms": 1177.2313117980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Miranda Hart", "latency_ms": 1184.1137409210205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "Miranda Hart", "latency_ms": 603.2419204711914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Miranda Hart", "latency_ms": 1142.1704292297363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3101}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1248.4123706817627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Montesquieu", "latency_ms": 769.5584297180176, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1006.2971115112305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 1726.4187335968018, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 1791.929006576538, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 1587.0225429534912, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2621}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 775.2935886383057, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3230}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 1159.5418453216553, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3906}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Myles Garrett", "latency_ms": 485.7168197631836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1232.9213619232178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 992.4476146697998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1347.2776412963867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1232.8476905822754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "Not mentioned", "latency_ms": 885.5814933776855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3116}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1108.6995601654053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3666}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2063 BS", "latency_ms": 758.042573928833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1185.1189136505127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1326.0273933410645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1184.7906112670898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1980}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1505.9082508087158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1391.6497230529785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3332}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1078.9580345153809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3999}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "Captain John Smith", "latency_ms": 749.9897480010986, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bacon", "latency_ms": 920.3941822052002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "Bacon", "latency_ms": 1092.932939529419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "Bacon", "latency_ms": 700.9077072143555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "Bacon's Rebellion", "latency_ms": 927.6711940765381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2637}, "5": {"k": 5, "answer": "Bacon", "latency_ms": 1223.4058380126953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3295}, "6": {"k": 6, "answer": "Bacon's Rebellion", "latency_ms": 740.2083873748779, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3979}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "Parietal cells", "latency_ms": 791.7172908782959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stomach", "latency_ms": 955.3203582763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "Parietal cells", "latency_ms": 1011.5156173706055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Parietal cells", "latency_ms": 1228.6157608032227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1803}, "4": {"k": 4, "answer": "Parietal cells", "latency_ms": 1238.1622791290283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2404}, "5": {"k": 5, "answer": "Parietal cells", "latency_ms": 1213.9146327972412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3055}, "6": {"k": 6, "answer": "Parietal cells", "latency_ms": 1456.130027770996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3670}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "Early morning", "latency_ms": 711.0157012939453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "4 a.m.", "latency_ms": 870.9971904754639, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 1157.3948860168457, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "4 a.m.", "latency_ms": 1181.769609451294, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "4 a.m.", "latency_ms": 1408.8585376739502, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2606}, "5": {"k": 5, "answer": "4 a.m.", "latency_ms": 1276.3137817382812, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3317}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 759.8199844360352, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4053}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 734.1814041137695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Idaho", "latency_ms": 931.7033290863037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 793.4401035308838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "Idaho", "latency_ms": 853.9609909057617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1986}, "4": {"k": 4, "answer": "Idaho", "latency_ms": 989.4936084747314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2640}, "5": {"k": 5, "answer": "Idaho", "latency_ms": 964.5819664001465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3264}, "6": {"k": 6, "answer": "Idaho", "latency_ms": 1150.972843170166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3900}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales", "latency_ms": 3752.725601196289, "em": 0.0, "f1": 0.43478260869565216, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 719.6180820465088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1186.2907409667969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1242.1278953552246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1528.7795066833496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1441.305160522461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3159}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1045.0398921966553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 650.6466865539551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "modulated", "latency_ms": 1118.3865070343018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "modulated", "latency_ms": 619.7941303253174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1171}, "3": {"k": 3, "answer": "modulated", "latency_ms": 1115.572214126587, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1761}, "4": {"k": 4, "answer": "modulate", "latency_ms": 1187.3278617858887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "modulated", "latency_ms": 1203.7551403045654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3037}, "6": {"k": 6, "answer": "modulated", "latency_ms": 700.6056308746338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3649}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Male citizens", "latency_ms": 343.5938358306885, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1129.6193599700928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "only a minority of Romans", "latency_ms": 1608.6382865905762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Roman citizens", "latency_ms": 804.2292594909668, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1994}, "4": {"k": 4, "answer": "Roman citizens", "latency_ms": 859.6436977386475, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2700}, "5": {"k": 5, "answer": "Roman citizens", "latency_ms": 926.9437789916992, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3339}, "6": {"k": 6, "answer": "Roman citizens", "latency_ms": 931.8006038665771, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4014}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 791.4667129516602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "9 April 2019", "latency_ms": 892.3041820526123, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "9 April 2019", "latency_ms": 896.6960906982422, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "9 April 2019", "latency_ms": 1368.0226802825928, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "9 April 2019", "latency_ms": 1354.1374206542969, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2542}, "5": {"k": 5, "answer": "9 April 2019", "latency_ms": 1855.0639152526855, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "9 April 2019", "latency_ms": 1098.5777378082275, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3809}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "100 parts of blood", "latency_ms": 913.5165214538574, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "volume of blood or mass of blood", "latency_ms": 1710.885763168335, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "mass of blood or volume of blood", "latency_ms": 1619.7614669799805, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1234}, "3": {"k": 3, "answer": "volume of blood or mass of blood", "latency_ms": 1446.542739868164, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1849}, "4": {"k": 4, "answer": "volume of blood or mass of blood", "latency_ms": 1633.0983638763428, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2539}, "5": {"k": 5, "answer": "volume of blood or mass of blood", "latency_ms": 1640.7127380371094, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3203}, "6": {"k": 6, "answer": "volume of blood or mass of blood", "latency_ms": 1825.7339000701904, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3800}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "Icarus", "latency_ms": 487.1346950531006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Icarus", "latency_ms": 1228.3129692077637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "Iphigenia", "latency_ms": 849.8425483703613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "Icarus", "latency_ms": 959.2494964599609, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1810}, "4": {"k": 4, "answer": "Icarus", "latency_ms": 662.8663539886475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2393}, "5": {"k": 5, "answer": "Phaethon", "latency_ms": 1074.387550354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "Phaethon", "latency_ms": 541.4996147155762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3630}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "September 16, 1979", "latency_ms": 1167.1829223632812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1979", "latency_ms": 935.5435371398926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "1979", "latency_ms": 691.0486221313477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "1979", "latency_ms": 937.9696846008301, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "1979", "latency_ms": 728.0645370483398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2551}, "5": {"k": 5, "answer": "1979", "latency_ms": 1255.8958530426025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3159}, "6": {"k": 6, "answer": "1979", "latency_ms": 787.6555919647217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3727}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 am", "latency_ms": 884.427547454834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1091.6783809661865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "2 April 1986", "latency_ms": 1110.2869510650635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "2 April 1986", "latency_ms": 1187.1681213378906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "2 April 1986", "latency_ms": 1265.8672332763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2627}, "5": {"k": 5, "answer": "2 April 1986", "latency_ms": 1320.3322887420654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3296}, "6": {"k": 6, "answer": "2 April 1986", "latency_ms": 1933.842658996582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3927}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "Tiffany Coyne", "latency_ms": 1133.7714195251465, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1100.799798965454, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "Tiffany Coyne", "latency_ms": 1055.6650161743164, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 1066.373586654663, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 1353.2664775848389, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2449}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 787.4808311462402, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3031}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 1371.0668087005615, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3658}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "Yankees, Braves, Reds, Giants", "latency_ms": 1325.1643180847168, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yankees, Atlanta Braves", "latency_ms": 1571.070671081543, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Yankees, Braves, Blue Jays", "latency_ms": 1009.1574192047119, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Yankees, Braves, Blue Jays", "latency_ms": 1739.4804954528809, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Yankees, Braves, Blue Jays", "latency_ms": 1283.930778503418, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2437}, "5": {"k": 5, "answer": "Yankees, Braves, Blue Jays", "latency_ms": 1695.3582763671875, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3043}, "6": {"k": 6, "answer": "Yankees, Braves, Blue Jays", "latency_ms": 1776.733636856079, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3676}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "2.187 billion dollars", "latency_ms": 1342.8053855895996, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$343.4 million", "latency_ms": 860.9139919281006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "$1.84 billion", "latency_ms": 1334.5966339111328, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "$1.84 billion", "latency_ms": 1239.0310764312744, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "$1.84 billion", "latency_ms": 1456.2723636627197, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "$1.84 billion", "latency_ms": 884.758472442627, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "$1.84 billion", "latency_ms": 1493.3748245239258, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3794}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 769.2410945892334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1258.577585220337, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1182.711124420166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1496.5026378631592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1518.9990997314453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2496}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 650.2780914306641, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1073.1849670410156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3718}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark", "latency_ms": 941.9493675231934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "his father", "latency_ms": 991.7712211608887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "his father", "latency_ms": 1053.7769794464111, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Denmark", "latency_ms": 1145.5755233764648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1894}, "4": {"k": 4, "answer": "Denmark", "latency_ms": 976.9370555877686, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "Denmark", "latency_ms": 796.8118190765381, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Denmark", "latency_ms": 685.7454776763916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3739}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "Presépio", "latency_ms": 774.3790149688721, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Christmas Tree", "latency_ms": 906.1660766601562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Christmas Tree", "latency_ms": 487.764835357666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Christmas Tree", "latency_ms": 1177.5908470153809, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Christmas Tree", "latency_ms": 518.0904865264893, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Christmas Tree", "latency_ms": 698.322057723999, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Christmas Tree", "latency_ms": 893.3277130126953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3845}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "Patrick Swayze", "latency_ms": 617.6867485046387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 685.5924129486084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1029.8168659210205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1004.4465065002441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Swayze", "latency_ms": 1110.85844039917, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Swayze", "latency_ms": 942.9972171783447, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3213}, "6": {"k": 6, "answer": "Swayze", "latency_ms": 756.1421394348145, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3819}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Pittsburgh", "latency_ms": 730.5843830108643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1074.2576122283936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 986.7751598358154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 922.6324558258057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1261.5118026733398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2589}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1211.2400531768799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3214}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 762.5365257263184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3876}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1704", "latency_ms": 954.5643329620361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "First Parliament", "latency_ms": 640.8812999725342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "1854", "latency_ms": 695.7440376281738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "1854", "latency_ms": 906.8961143493652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1994}, "4": {"k": 4, "answer": "1854", "latency_ms": 654.7281742095947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "1854", "latency_ms": 682.2607517242432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3243}, "6": {"k": 6, "answer": "1854", "latency_ms": 917.9995059967041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3911}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier Fernández", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Yuzuru Hanyu", "latency_ms": 1162.4433994293213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1057.2888851165771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1267.7662372589111, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1257.0912837982178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2059}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1119.6184158325195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2810}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 1897.2835540771484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3439}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 1415.022850036621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4120}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "Password recovery and cracking.", "latency_ms": 1121.2663650512695, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Password recovery", "latency_ms": 1136.3229751586914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "password recovery", "latency_ms": 1165.3416156768799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1391}, "3": {"k": 3, "answer": "password recovery", "latency_ms": 688.3258819580078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2024}, "4": {"k": 4, "answer": "Password recovery tool", "latency_ms": 812.5596046447754, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2617}, "5": {"k": 5, "answer": "Password recovery tool", "latency_ms": 926.9142150878906, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Password recovery tool", "latency_ms": 940.6020641326904, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3819}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 856.2064170837402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1176.2399673461914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "S. M. Krishna", "latency_ms": 1643.3169841766357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 1485.0850105285645, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 1758.5761547088623, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2642}, "5": {"k": 5, "answer": "S. M. Krishna, C. Vidyasagar Rao, K. Sankaranarayanan", "latency_ms": 2620.774984359741, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "S. M. Krishna, C. Vidyasagar Rao, K. Sankaranarayanan", "latency_ms": 3315.3276443481445, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3931}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "Channel 15", "latency_ms": 745.0251579284668, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1019.9735164642334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1236.757516860962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 737.7758026123047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "15", "latency_ms": 888.5014057159424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2570}, "5": {"k": 5, "answer": "15", "latency_ms": 420.1838970184326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "15", "latency_ms": 733.0856323242188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3897}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Claudia Wells", "latency_ms": 816.2431716918945, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elisabeth Shue", "latency_ms": 1264.129877090454, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Claudia Wells", "latency_ms": 1169.0504550933838, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "Claudia Wells", "latency_ms": 1426.0876178741455, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1798}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 1017.7991390228271, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2397}, "5": {"k": 5, "answer": "Claudia Wells", "latency_ms": 1076.0691165924072, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "Claudia Wells", "latency_ms": 1016.169548034668, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3631}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 707.8609466552734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "United Kingdom", "latency_ms": 474.57265853881836, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 1303.8225173950195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 1266.7851448059082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 1020.3776359558105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 1002.129316329956, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3160}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 1274.660587310791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3809}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The White House Chef", "latency_ms": 646.3959217071533, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The White House Executive Chef", "latency_ms": 1307.915210723877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "The White House Executive Chef", "latency_ms": 1314.7695064544678, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1369}, "3": {"k": 3, "answer": "White House Executive Chef", "latency_ms": 1227.0925045013428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2045}, "4": {"k": 4, "answer": "White House Executive Chef", "latency_ms": 1251.6093254089355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2708}, "5": {"k": 5, "answer": "White House Executive Chef", "latency_ms": 1221.7130661010742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3377}, "6": {"k": 6, "answer": "White House Executive Chef", "latency_ms": 1060.6989860534668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3956}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 1036.0286235809326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1233.9489459991455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 792.3996448516846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1281.1000347137451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Nagendra Singh", "latency_ms": 1492.4170970916748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "Nagendra Singh", "latency_ms": 800.3497123718262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3197}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1037.6341342926025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 360.9960079193115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles, California and Larchmont, New York", "latency_ms": 2076.6265392303467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "Virginia countryside", "latency_ms": 688.5290145874023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1626.9638538360596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 621.7329502105713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2610}, "5": {"k": 5, "answer": "British Columbia", "latency_ms": 938.0724430084229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3268}, "6": {"k": 6, "answer": "British Columbia", "latency_ms": 473.22797775268555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3895}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 815.0782585144043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 830.5568695068359, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 992.6083087921143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 1838.6776447296143, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1876}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 1232.017993927002, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 1758.1253051757812, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 1758.9216232299805, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3830}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Jodie Sweetin", "latency_ms": 780.369758605957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jodie Sweetin", "latency_ms": 959.7904682159424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 652}, "2": {"k": 2, "answer": "Jodie Sweetin", "latency_ms": 1291.7375564575195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Stephanie", "latency_ms": 931.7386150360107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "Stephanie", "latency_ms": 940.758466720581, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2526}, "5": {"k": 5, "answer": "Stephanie", "latency_ms": 706.5739631652832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1119.5337772369385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "Millennium Tower", "latency_ms": 892.1551704406738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Millennium Tower", "latency_ms": 1493.8092231750488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 989.5224571228027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1361}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 1308.5134029388428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2008}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 1059.4558715820312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2703}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 965.0790691375732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3328}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 1256.2122344970703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3988}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 784.4364643096924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 446.8047618865967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "2015", "latency_ms": 1025.1684188842773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "2015", "latency_ms": 1035.1500511169434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1820}, "4": {"k": 4, "answer": "2015", "latency_ms": 925.9216785430908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2449}, "5": {"k": 5, "answer": "2015", "latency_ms": 1204.5361995697021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3029}, "6": {"k": 6, "answer": "2015", "latency_ms": 719.2680835723877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3731}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "John Harlan", "latency_ms": 801.8927574157715, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1010.6837749481201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 693}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1006.5386295318604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1242.14506149292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1303.9448261260986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2663}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1033.277988433838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3333}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1224.656343460083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4032}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Tyrann Mathieu", "latency_ms": 684.136152267456, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1217.1924114227295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 1075.0067234039307, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 1457.8254222869873, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 1370.9290027618408, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 1273.6752033233643, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 1150.303840637207, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3837}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "44", "latency_ms": 456.1154842376709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "six", "latency_ms": 385.9288692474365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 705}, "2": {"k": 2, "answer": "six episodes", "latency_ms": 990.3640747070312, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Six episodes", "latency_ms": 931.494951248169, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1973}, "4": {"k": 4, "answer": "Six episodes", "latency_ms": 1023.0731964111328, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2646}, "5": {"k": 5, "answer": "six episodes", "latency_ms": 902.2798538208008, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3304}, "6": {"k": 6, "answer": "6 episodes", "latency_ms": 1269.685983657837, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3979}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul Baümer's", "latency_ms": 1121.8583583831787, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "German soldiers'", "latency_ms": 985.1984977722168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "German soldiers'", "latency_ms": 1272.315502166748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "German soldiers'", "latency_ms": 964.0376567840576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "German soldiers'", "latency_ms": 958.6248397827148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2564}, "5": {"k": 5, "answer": "German soldiers'", "latency_ms": 1203.3145427703857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3204}, "6": {"k": 6, "answer": "German soldiers'", "latency_ms": 1471.0657596588135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3844}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris", "latency_ms": 451.19762420654297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frank Morris, John Anglin, Clarence Anglin", "latency_ms": 2753.541946411133, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 683}, "2": {"k": 2, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 2120.5201148986816, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1339}, "3": {"k": 3, "answer": "Frank Morris, John Anglin, Clarence Anglin", "latency_ms": 1808.2616329193115, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 2183.6442947387695, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2619}, "5": {"k": 5, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 1485.6762886047363, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3224}, "6": {"k": 6, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 1936.8782043457031, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3892}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF programs.", "latency_ms": 860.3386878967285, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF's global programming", "latency_ms": 1513.6101245880127, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "UNICEF's global programming", "latency_ms": 1193.9353942871094, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1417}, "3": {"k": 3, "answer": "UNICEF's global programming", "latency_ms": 1415.3082370758057, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2137}, "4": {"k": 4, "answer": "UNICEF's global programming", "latency_ms": 1127.8903484344482, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2808}, "5": {"k": 5, "answer": "UNICEF's global programming", "latency_ms": 1610.7337474822998, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3538}, "6": {"k": 6, "answer": "UNICEF's global programming", "latency_ms": 1267.6963806152344, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4217}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Tablet", "latency_ms": 695.7182884216309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1029.2937755584717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 987.2610569000244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 788.0070209503174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1472.6645946502686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "Not mentioned", "latency_ms": 454.75149154663086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1266.798496246338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3882}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "Milan-Cortina, Sapporo", "latency_ms": 1254.1849613189697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 742.903470993042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "Beijing, China", "latency_ms": 768.7265872955322, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1183}, "3": {"k": 3, "answer": "Beijing, China", "latency_ms": 723.374605178833, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1785}, "4": {"k": 4, "answer": "Beijing, China; Ushuaia", "latency_ms": 1930.079698562622, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2423}, "5": {"k": 5, "answer": "Beijing, China; unknown", "latency_ms": 790.6663417816162, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3062}, "6": {"k": 6, "answer": "Beijing, China; unknown", "latency_ms": 1072.3109245300293, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3712}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "1981", "latency_ms": 453.0181884765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1997", "latency_ms": 507.3122978210449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "1997", "latency_ms": 702.1024227142334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "1997", "latency_ms": 930.264949798584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "1997", "latency_ms": 947.0789432525635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "1997", "latency_ms": 941.7917728424072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "1997", "latency_ms": 662.5814437866211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3865}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "Stone Gothic arch bridge", "latency_ms": 823.5037326812744, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1066.1530494689941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "Through-truss, rolling bascule bridges", "latency_ms": 1287.182331085205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "Through-truss, rolling bascule bridges", "latency_ms": 1764.7652626037598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1970}, "4": {"k": 4, "answer": "Not specified", "latency_ms": 1152.4770259857178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2650}, "5": {"k": 5, "answer": "Not specified", "latency_ms": 657.4597358703613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "Not specified", "latency_ms": 1150.564193725586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3922}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The Autocrat", "latency_ms": 1038.0308628082275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One person", "latency_ms": 431.93602561950684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "One person", "latency_ms": 621.7348575592041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "One person", "latency_ms": 831.279993057251, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1987}, "4": {"k": 4, "answer": "One person", "latency_ms": 837.0637893676758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2671}, "5": {"k": 5, "answer": "One person", "latency_ms": 1170.6275939941406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3321}, "6": {"k": 6, "answer": "One person", "latency_ms": 427.23536491394043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3955}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "Affluence", "latency_ms": 806.7893981933594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1275.386095046997, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 995.8832263946533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "Return to normalcy", "latency_ms": 825.1934051513672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Return to normalcy", "latency_ms": 814.990758895874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "Prosperous postwar era", "latency_ms": 1599.8284816741943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "prosperous postwar era", "latency_ms": 1396.7835903167725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3945}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "Counterclockwise", "latency_ms": 805.8700561523438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Along its trajectory", "latency_ms": 906.7325592041016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "Along the ecliptic", "latency_ms": 779.7126770019531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1180}, "3": {"k": 3, "answer": "Counterclockwise", "latency_ms": 806.6682815551758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1748}, "4": {"k": 4, "answer": "Counterclockwise", "latency_ms": 1008.307695388794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2293}, "5": {"k": 5, "answer": "Counterclockwise", "latency_ms": 965.0421142578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2864}, "6": {"k": 6, "answer": "Counterclockwise", "latency_ms": 1178.2240867614746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3478}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Statue of Freedom", "latency_ms": 1026.5862941741943, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Dome", "latency_ms": 670.095682144165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 492.8739070892334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 953.0045986175537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "\"Statue of Freedom\"", "latency_ms": 1555.7315349578857, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "\"Statue of Freedom\"", "latency_ms": 1290.7099723815918, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3285}, "6": {"k": 6, "answer": "\"Statue of Freedom\"", "latency_ms": 1061.479091644287, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3928}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "Taoyuan Leopards", "latency_ms": 1261.3451480865479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington Wizards", "latency_ms": 636.023998260498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "Washington Wizards", "latency_ms": 940.8688545227051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Washington Wizards", "latency_ms": 947.4701881408691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "Washington Wizards", "latency_ms": 698.7957954406738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2501}, "5": {"k": 5, "answer": "Washington Wizards", "latency_ms": 900.8126258850098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3105}, "6": {"k": 6, "answer": "Washington Wizards", "latency_ms": 729.1829586029053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3777}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1095.7636833190918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 987.1511459350586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1652.1501541137695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Rey Mysterio", "latency_ms": 1288.2368564605713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Rey Mysterio", "latency_ms": 1593.7635898590088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2454}, "5": {"k": 5, "answer": "Mysterio", "latency_ms": 979.5167446136475, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3107}, "6": {"k": 6, "answer": "Rey Mysterio", "latency_ms": 1367.495059967041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3708}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 968.9409732818604, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake of the Ozarks", "latency_ms": 1519.1643238067627, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Lake Mead", "latency_ms": 753.1962394714355, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "Lake Mead", "latency_ms": 916.5060520172119, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Lake Mead", "latency_ms": 1136.821985244751, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2387}, "5": {"k": 5, "answer": "Lake Mead", "latency_ms": 977.4413108825684, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2959}, "6": {"k": 6, "answer": "Lake Mead", "latency_ms": 720.0520038604736, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3536}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Tagore", "latency_ms": 460.0942134857178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tagore", "latency_ms": 1056.1702251434326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 585}, "2": {"k": 2, "answer": "Tagore", "latency_ms": 1234.0078353881836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tagore", "latency_ms": 1022.038459777832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1847}, "4": {"k": 4, "answer": "Tagore", "latency_ms": 1003.1819343566895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2483}, "5": {"k": 5, "answer": "Tagore", "latency_ms": 1196.4900493621826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3134}, "6": {"k": 6, "answer": "Tagore", "latency_ms": 1036.4692211151123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3745}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "George H.W. Bush", "latency_ms": 1097.158670425415, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "George H. W. Bush", "latency_ms": 1549.7057437896729, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "George H. W. Bush", "latency_ms": 1104.769229888916, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "George H. W. Bush", "latency_ms": 1063.486099243164, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2073}, "4": {"k": 4, "answer": "George H. W. Bush", "latency_ms": 1584.1445922851562, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2776}, "5": {"k": 5, "answer": "George H. W. Bush", "latency_ms": 1421.7324256896973, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3479}, "6": {"k": 6, "answer": "George H. W. Bush", "latency_ms": 851.2706756591797, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 4204}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "American Rock Salt mine, Livingston County, New York", "latency_ms": 1560.0512027740479, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Groveland", "latency_ms": 1499.8056888580322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners, Groveland", "latency_ms": 957.9746723175049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Hampton Corners, Groveland", "latency_ms": 1447.5946426391602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "Hampton Corners", "latency_ms": 1386.7862224578857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Hampton Corners, Groveland, New York", "latency_ms": 2131.2451362609863, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Hampton Corners, Groveland, New York", "latency_ms": 2046.7417240142822, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3723}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 263.0143165588379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 591.3546085357666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 912.0299816131592, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1172}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 920.4785823822021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1818}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 734.2722415924072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2449}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 916.8903827667236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3090}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 980.750322341919, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3647}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Meghalaya", "latency_ms": 532.8474044799805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 842.8363800048828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Uttar Dinajpur", "latency_ms": 1306.3597679138184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "Uttar Dinajpur", "latency_ms": 1684.401512145996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Uttar Dinajpur", "latency_ms": 1140.883207321167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "Uttar Dinajpur", "latency_ms": 1161.2436771392822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Uttar Dinajpur", "latency_ms": 1108.8438034057617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3733}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Kanpur", "latency_ms": 969.94948387146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 917.2897338867188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1115.199327468872, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1368.636131286621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1936}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1603.9137840270996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 983.0336570739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1031.275749206543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3876}}}
