{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 1031.0642719268799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Molly", "latency_ms": 985.2161407470703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1388.5581493377686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1482.0187091827393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1011.3716125488281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1239.985466003418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3129}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1242.53249168396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3760}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 841.0265445709229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 1258.5115432739258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 1295.7735061645508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 1075.9310722351074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1946}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 1300.389289855957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2583}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 1009.589433670044, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3176}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 1566.5264129638672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3781}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwest desert regions", "latency_ms": 1039.2422676086426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 2099.0774631500244, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "arid lowland or mountainous shrubland", "latency_ms": 2025.5343914031982, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1288}, "3": {"k": 3, "answer": "arid lowland or mountainous shrubland", "latency_ms": 2265.434503555298, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1951}, "4": {"k": 4, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 2102.4515628814697, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2601}, "5": {"k": 5, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 2215.7199382781982, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3274}, "6": {"k": 6, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 2452.0559310913086, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3870}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 1096.9359874725342, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Karl Seitz", "latency_ms": 988.0344867706299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Dr. Rajendra Prasad", "latency_ms": 1553.6999702453613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1428}, "3": {"k": 3, "answer": "Karl Seitz", "latency_ms": 980.2036285400391, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2127}, "4": {"k": 4, "answer": "Karl Seitz", "latency_ms": 1232.095718383789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2827}, "5": {"k": 5, "answer": "Karl Seitz", "latency_ms": 1152.6098251342773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3522}, "6": {"k": 6, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 1443.3419704437256, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4236}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 872.1754550933838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1519.5200443267822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1003.4856796264648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1301.3174533843994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 994.8530197143555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2567}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1232.3687076568604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1366.9137954711914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3803}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "June 22, 2001", "latency_ms": 1359.0312004089355, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2001", "latency_ms": 397.49765396118164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "2001", "latency_ms": 711.2007141113281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "2001", "latency_ms": 700.2453804016113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "2001", "latency_ms": 872.9264736175537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "2001", "latency_ms": 700.4294395446777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3112}, "6": {"k": 6, "answer": "2001", "latency_ms": 988.917350769043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3738}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1018.7630653381348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 1412.140130996704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 1802.917718887329, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 1187.237024307251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 1818.756341934204, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2653}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 1635.1335048675537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3286}, "6": {"k": 6, "answer": "September 27, 2017", "latency_ms": 1225.6817817687988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4033}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3", "latency_ms": 981.0261726379395, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1003.1647682189941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "Yes/No episode", "latency_ms": 1050.8098602294922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "Yes/No episode", "latency_ms": 1025.1293182373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1775}, "4": {"k": 4, "answer": "In \"Hell-O\"", "latency_ms": 1473.1457233428955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2338}, "5": {"k": 5, "answer": "In \"The Power of Madonna\"", "latency_ms": 1618.6306476593018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2957}, "6": {"k": 6, "answer": "In \"Hell-O\"", "latency_ms": 1550.3952503204346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3580}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 783.7538719177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 821.0818767547607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1237.5025749206543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 734.9753379821777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1856}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1500.3647804260254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 958.1985473632812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3136}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 993.9441680908203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3782}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 547.797441482544, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "the harbor", "latency_ms": 1124.4051456451416, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "the harbor", "latency_ms": 879.6248435974121, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Havana Harbor", "latency_ms": 499.4170665740967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1790}, "4": {"k": 4, "answer": "Havana Harbor", "latency_ms": 979.4244766235352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2364}, "5": {"k": 5, "answer": "Havana Harbor", "latency_ms": 905.5678844451904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2991}, "6": {"k": 6, "answer": "Havana Harbor", "latency_ms": 1227.7405261993408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3625}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 993.8662052154541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1059.8764419555664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1390.279769897461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "No specific god mentioned", "latency_ms": 1120.488166809082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1935}, "4": {"k": 4, "answer": "None mentioned", "latency_ms": 1170.987844467163, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "No specific god mentioned", "latency_ms": 1251.2855529785156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "Lord Vishnu and Lord Shiva", "latency_ms": 1413.0995273590088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3740}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 1841.1498069763184, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "All of them", "latency_ms": 712.0509147644043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Belize and Guatemala", "latency_ms": 1455.8119773864746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Costa Rica, Nicaragua, Panama, Guatemala, Honduras, El Salvador, Belize", "latency_ms": 2847.668409347534, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1944}, "4": {"k": 4, "answer": "Belize and Guatemala", "latency_ms": 1062.4232292175293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2591}, "5": {"k": 5, "answer": "Guatemala, Belize, Costa Rica, Nicaragua, Honduras, Panama, and El Salvador", "latency_ms": 3239.2024993896484, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3186}, "6": {"k": 6, "answer": "Guatemala, Belize", "latency_ms": 1370.3362941741943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence.", "latency_ms": 1028.7001132965088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 645.7202434539795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 704}, "2": {"k": 2, "answer": "A typical sentence", "latency_ms": 1195.2753067016602, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1360}, "3": {"k": 3, "answer": "Typical sentence", "latency_ms": 1222.353219985962, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2042}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 976.1843681335449, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2701}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 1216.5634632110596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3365}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 886.1219882965088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4053}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and trade.", "latency_ms": 1351.4659404754639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 2263.936758041382, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Nations' wealth", "latency_ms": 1241.6338920593262, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "what builds nations' wealth", "latency_ms": 1505.8143138885498, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "Nations' wealth", "latency_ms": 745.3479766845703, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 1881.7615509033203, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3218}, "6": {"k": 6, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 1430.8922290802002, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3881}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 875.9820461273193, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "August 28, 2018", "latency_ms": 1456.1614990234375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "August 28, 2018", "latency_ms": 1262.855052947998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 2273.571491241455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1844}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 1656.733512878418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2491}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 1655.3566455841064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3106}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 1866.2502765655518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere", "latency_ms": 487.02049255371094, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Western Australia", "latency_ms": 906.7282676696777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 742}, "2": {"k": 2, "answer": "Western Australia", "latency_ms": 920.0220108032227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1408}, "3": {"k": 3, "answer": "Western Australia", "latency_ms": 692.410945892334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2036}, "4": {"k": 4, "answer": "Western Australia", "latency_ms": 628.8893222808838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2664}, "5": {"k": 5, "answer": "Western Australia", "latency_ms": 1238.9793395996094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3339}, "6": {"k": 6, "answer": "Eastern coast", "latency_ms": 1223.1884002685547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3998}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Leia Organa", "latency_ms": 1072.700023651123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Leia", "latency_ms": 711.4989757537842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Leia", "latency_ms": 888.2687091827393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "Leia", "latency_ms": 1141.7713165283203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "Leia", "latency_ms": 1211.85302734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2435}, "5": {"k": 5, "answer": "Mara Jade", "latency_ms": 1049.4263172149658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3055}, "6": {"k": 6, "answer": "Mara Jade", "latency_ms": 1244.5950508117676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3620}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 954.2465209960938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack Barry", "latency_ms": 494.89641189575195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Barry Cryer", "latency_ms": 1200.3304958343506, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1167}, "3": {"k": 3, "answer": "Barry Cryer", "latency_ms": 1182.8832626342773, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1717}, "4": {"k": 4, "answer": "Barry Cryer", "latency_ms": 1141.118049621582, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2312}, "5": {"k": 5, "answer": "Barry Cryer", "latency_ms": 1017.780065536499, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2905}, "6": {"k": 6, "answer": "Barry Cryer", "latency_ms": 1491.9826984405518, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3488}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 998.9361763000488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "mitochondrial membrane", "latency_ms": 1033.850908279419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "mitochondrial membrane", "latency_ms": 992.5405979156494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1347}, "3": {"k": 3, "answer": "Mitochondria", "latency_ms": 985.6984615325928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1998}, "4": {"k": 4, "answer": "Mitochondria", "latency_ms": 799.9796867370605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Mitochondria and Chloroplast", "latency_ms": 1358.8528633117676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3366}, "6": {"k": 6, "answer": "Mitochondrion", "latency_ms": 1335.8616828918457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4139}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Backup.", "latency_ms": 1969.0637588500977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 959.9406719207764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 753}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 786.8430614471436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1462}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1517.9481506347656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2155}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 997.5016117095947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2794}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1211.2858295440674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3477}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 800.2047538757324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4207}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 1230.3974628448486, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 744.9135780334473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1270.5588340759277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1263}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 749.061107635498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1847}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1351.2287139892578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2465}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1259.6900463104248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3066}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1010.561466217041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3669}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 477.36644744873047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "36 months", "latency_ms": 1101.8521785736084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 601}, "2": {"k": 2, "answer": "36 months", "latency_ms": 906.9669246673584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "36 months", "latency_ms": 880.4047107696533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1765}, "4": {"k": 4, "answer": "Three years old", "latency_ms": 979.6617031097412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2456}, "5": {"k": 5, "answer": "36 months", "latency_ms": 908.7588787078857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3064}, "6": {"k": 6, "answer": "36 months", "latency_ms": 948.0259418487549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3657}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 904.6523571014404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Three-part", "latency_ms": 880.1271915435791, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 652}, "2": {"k": 2, "answer": "Three-part", "latency_ms": 908.2670211791992, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Three-part", "latency_ms": 773.9887237548828, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Three-part", "latency_ms": 1157.6025485992432, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2532}, "5": {"k": 5, "answer": "Three-part", "latency_ms": 696.1486339569092, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3179}, "6": {"k": 6, "answer": "Three-part", "latency_ms": 950.7648944854736, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3783}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 2853.4648418426514, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1360.9838485717773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 3533.1544876098633, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 4442.328929901123, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 4690.55438041687, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 3783.656597137451, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 3118}, "6": {"k": 6, "answer": "Elijah Wood, Ian Holm", "latency_ms": 1692.4645900726318, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3747}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party", "latency_ms": 794.3646907806396, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume.", "latency_ms": 518.1887149810791, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "Costume.", "latency_ms": 1388.7925148010254, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1181}, "3": {"k": 3, "answer": "Costume.", "latency_ms": 983.6199283599854, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1750}, "4": {"k": 4, "answer": "Costume.", "latency_ms": 945.8518028259277, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2363}, "5": {"k": 5, "answer": "Costume", "latency_ms": 646.0847854614258, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3033}, "6": {"k": 6, "answer": "Costume", "latency_ms": 853.7793159484863, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3705}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 445.5385208129883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One", "latency_ms": 588.8137817382812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "One", "latency_ms": 839.3266201019287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1204}, "3": {"k": 3, "answer": "One", "latency_ms": 594.5289134979248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1902}, "4": {"k": 4, "answer": "One", "latency_ms": 640.4030323028564, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2527}, "5": {"k": 5, "answer": "One", "latency_ms": 894.8862552642822, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3150}, "6": {"k": 6, "answer": "One", "latency_ms": 1115.959644317627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3776}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "He promised Fantine", "latency_ms": 1598.7937450408936, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1567.690134048462, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 762.2849941253662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "He pitied her.", "latency_ms": 1557.0647716522217, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1210.789442062378, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Fantine's letter authorizing him to take Cosette", "latency_ms": 3917.8626537323, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "Fantine's letter authorizing him to take Cosette", "latency_ms": 1900.294303894043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3717}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, and South Korea.", "latency_ms": 1987.3216152191162, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Russia", "latency_ms": 811.6312026977539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 699}, "2": {"k": 2, "answer": "Russia", "latency_ms": 614.687442779541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1393}, "3": {"k": 3, "answer": "Russia, United Kingdom", "latency_ms": 1033.921241760254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2112}, "4": {"k": 4, "answer": "Kenya", "latency_ms": 951.4753818511963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2802}, "5": {"k": 5, "answer": "Russia, United Kingdom, Kenya, Canada", "latency_ms": 1470.7634449005127, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3529}, "6": {"k": 6, "answer": "Kenya, Canada, Russia", "latency_ms": 1061.8937015533447, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4223}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and control.", "latency_ms": 1254.1143894195557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to consolidate Bantu education", "latency_ms": 1194.0813064575195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 714}, "2": {"k": 2, "answer": "to consolidate Bantu education", "latency_ms": 1034.008264541626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1413}, "3": {"k": 3, "answer": "to consolidate Bantu education", "latency_ms": 817.6741600036621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2090}, "4": {"k": 4, "answer": "to ensure blacks had only enough education to work as unskilled laborers", "latency_ms": 2691.260814666748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 2311.4678859710693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "to consolidate Bantu education and implement discriminatory practices uniformly", "latency_ms": 1928.5471439361572, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4022}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 478.0895709991455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 1312.2344017028809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 1069.4713592529297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Huge and powerful snake", "latency_ms": 1114.290714263916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1759}, "4": {"k": 4, "answer": "Python", "latency_ms": 882.8654289245605, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2384}, "5": {"k": 5, "answer": "Python", "latency_ms": 895.4257965087891, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "Python", "latency_ms": 564.246654510498, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3616}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 970.0908660888672, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "frost or snow mixed with dust", "latency_ms": 1296.3337898254395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "frost or snow mixed generously with dust", "latency_ms": 1967.522382736206, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "frost or snow mixed generously with dust", "latency_ms": 1718.9059257507324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Ice with dust", "latency_ms": 1003.2651424407959, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2522}, "5": {"k": 5, "answer": "Ice with surface debris", "latency_ms": 982.872724533081, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3140}, "6": {"k": 6, "answer": "water-ice", "latency_ms": 1172.5332736968994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3727}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 1504.8742294311523, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "End of the second season", "latency_ms": 1265.371561050415, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "In the hospital.", "latency_ms": 989.6223545074463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "End of season 3", "latency_ms": 1061.100721359253, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "End of season 3", "latency_ms": 2243.7264919281006, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2348}, "5": {"k": 5, "answer": "End of season 3", "latency_ms": 1064.0311241149902, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2913}, "6": {"k": 6, "answer": "End of season 3", "latency_ms": 1269.1738605499268, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3477}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "Home team", "latency_ms": 990.2124404907227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "None", "latency_ms": 372.56526947021484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "Premier League clubs", "latency_ms": 1329.770803451538, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1168}, "3": {"k": 3, "answer": "Premier League clubs", "latency_ms": 1259.5398426055908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1749}, "4": {"k": 4, "answer": "Premier League clubs", "latency_ms": 1251.9035339355469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2396}, "5": {"k": 5, "answer": "the team named first", "latency_ms": 830.7149410247803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2983}, "6": {"k": 6, "answer": "the team named first", "latency_ms": 1268.841028213501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3592}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw neighborhood", "latency_ms": 583.2841396331787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northwest", "latency_ms": 932.9493045806885, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "Northwest Washington, DC", "latency_ms": 1363.0058765411377, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Northwest", "latency_ms": 444.95105743408203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "Northwest Washington, DC", "latency_ms": 1520.9410190582275, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2831}, "5": {"k": 5, "answer": "Northwest", "latency_ms": 1187.0613098144531, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3517}, "6": {"k": 6, "answer": "Northwest Washington, DC", "latency_ms": 1131.9301128387451, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 4166}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 568.4678554534912, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1029.9012660980225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Judaism's understanding of the covenant", "latency_ms": 1451.1964321136475, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Mosaic covenant", "latency_ms": 1010.9641551971436, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Mosaic covenant", "latency_ms": 1253.7696361541748, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "Mosaic covenant", "latency_ms": 1006.0572624206543, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3140}, "6": {"k": 6, "answer": "Mosaic covenant", "latency_ms": 1166.2111282348633, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3810}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 576.9271850585938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1234.2185974121094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 799.6151447296143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1188}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1439.4505023956299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1768}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1468.5168266296387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2371}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 954.6890258789062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2968}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1310.5695247650146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3539}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1258.2590579986572, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rudy Vallée", "latency_ms": 1709.9313735961914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "Rudy Vallée", "latency_ms": 1380.2456855773926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1180}, "3": {"k": 3, "answer": "Rudy Vallée", "latency_ms": 1368.0126667022705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1785}, "4": {"k": 4, "answer": "Rudy Vallée", "latency_ms": 1142.2295570373535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2383}, "5": {"k": 5, "answer": "Rudy Vallée", "latency_ms": 1247.7474212646484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3018}, "6": {"k": 6, "answer": "Rudy Vallée", "latency_ms": 1060.5535507202148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3669}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 1022.282600402832, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 1132.2331428527832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 973.3288288116455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 886.6250514984131, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 1019.8278427124023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2529}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 878.4046173095703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3149}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 995.1431751251221, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3746}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "Second", "latency_ms": 915.8408641815186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1517.5542831420898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1026.5002250671387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "77%", "latency_ms": 1976.2294292449951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1010.5657577514648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1256.2031745910645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1068.1421756744385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3922}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 1275.3405570983887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mahatma Gandhi", "latency_ms": 1319.3638324737549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 694}, "2": {"k": 2, "answer": "Mahatma Gandhi", "latency_ms": 1250.3316402435303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1402}, "3": {"k": 3, "answer": "Mahatma Gandhi", "latency_ms": 1313.3556842803955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2124}, "4": {"k": 4, "answer": "Mahatma Gandhi", "latency_ms": 1026.4816284179688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2818}, "5": {"k": 5, "answer": "Sonia Gandhi", "latency_ms": 1457.3042392730713, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3492}, "6": {"k": 6, "answer": "Mahatma Gandhi", "latency_ms": 1739.013910293579, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4202}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenae Anderson", "latency_ms": 1081.1030864715576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1318.5701370239258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1059.279441833496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1272.5496292114258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1857}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1333.8439464569092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2448}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1192.917823791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3034}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1226.696491241455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3645}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 953.8609981536865, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 388.2453441619873, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": ".java", "latency_ms": 632.9741477966309, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": ".java", "latency_ms": 873.8970756530762, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": ".java", "latency_ms": 617.2926425933838, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": ".java", "latency_ms": 907.3240756988525, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3152}, "6": {"k": 6, "answer": ".java", "latency_ms": 845.8576202392578, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 795.0997352600098, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Poland", "latency_ms": 1161.6742610931396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Poland", "latency_ms": 679.0997982025146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "Poland", "latency_ms": 1173.0878353118896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1995}, "4": {"k": 4, "answer": "Poland", "latency_ms": 754.9219131469727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2696}, "5": {"k": 5, "answer": "Poland", "latency_ms": 741.2707805633545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3423}, "6": {"k": 6, "answer": "Poland", "latency_ms": 960.4020118713379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4102}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline", "latency_ms": 895.2615261077881, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to offer promotion or threaten demotion", "latency_ms": 2156.029224395752, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "Offer promotion or threaten demotion within the committee system.", "latency_ms": 1853.264570236206, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Offer promotion or threaten demotion within the committee system.", "latency_ms": 2457.200765609741, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1952}, "4": {"k": 4, "answer": "ensure members adhere to party policies", "latency_ms": 1124.1464614868164, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 2586}, "5": {"k": 5, "answer": "ensure members adhere to party policies", "latency_ms": 1607.0172786712646, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 3310}, "6": {"k": 6, "answer": "ensure members adhere to party policies", "latency_ms": 1545.6061363220215, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 4003}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 699.0432739257812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 945.57785987854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "1978", "latency_ms": 1158.1382751464844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1157}, "3": {"k": 3, "answer": "1979", "latency_ms": 1026.3547897338867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1776}, "4": {"k": 4, "answer": "1973", "latency_ms": 444.4160461425781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2331}, "5": {"k": 5, "answer": "1973", "latency_ms": 945.4946517944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3013}, "6": {"k": 6, "answer": "1973", "latency_ms": 1154.5000076293945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the​ right but not the​ obligation to buy foreign​ currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 742.5751686096191, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 660.2749824523926, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 900.7706642150879, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 614.574670791626, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "FX option", "latency_ms": 1404.125452041626, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2709}, "5": {"k": 5, "answer": "FX option", "latency_ms": 890.8078670501709, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3368}, "6": {"k": 6, "answer": "FX option", "latency_ms": 615.3934001922607, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3985}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 541.3410663604736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 970.5321788787842, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360", "latency_ms": 1202.7156352996826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1380}, "3": {"k": 3, "answer": "360", "latency_ms": 690.1898384094238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2030}, "4": {"k": 4, "answer": "360", "latency_ms": 648.1442451477051, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2724}, "5": {"k": 5, "answer": "360", "latency_ms": 704.7035694122314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3379}, "6": {"k": 6, "answer": "360 members", "latency_ms": 1213.9265537261963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4027}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 954.7863006591797, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 1266.0956382751465, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 1096.3842868804932, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 963.5000228881836, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 1565.9399032592773, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2599}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 1059.3950748443604, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3240}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 1114.3615245819092, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3952}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gormé"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 909.5823764801025, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gormé", "latency_ms": 1288.175344467163, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Eydie Gormé", "latency_ms": 1333.4455490112305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1181}, "3": {"k": 3, "answer": "Eydie Gormé", "latency_ms": 1440.995693206787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1757}, "4": {"k": 4, "answer": "Eydie Gormé", "latency_ms": 1372.1108436584473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2334}, "5": {"k": 5, "answer": "Eydie Gormé", "latency_ms": 1662.2672080993652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2899}, "6": {"k": 6, "answer": "Eydie Gormé", "latency_ms": 1196.8357563018799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3505}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "Kurian Joseph", "latency_ms": 632.4901580810547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "H.L. Dattu", "latency_ms": 1531.4834117889404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "H.L. Dattu", "latency_ms": 1604.9468517303467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "H.L. Dattu", "latency_ms": 1124.8078346252441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "M. Jagannadha Rao", "latency_ms": 1593.160629272461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2406}, "5": {"k": 5, "answer": "M. Jagannadha Rao", "latency_ms": 940.3612613677979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3081}, "6": {"k": 6, "answer": "M. Jagannadha Rao", "latency_ms": 1644.005298614502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1045.0184345245361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1202.463150024414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Nadal", "latency_ms": 438.51280212402344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Nadal", "latency_ms": 1120.6495761871338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Serena Williams", "latency_ms": 683.6819648742676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2489}, "5": {"k": 5, "answer": "Serena Williams", "latency_ms": 707.6609134674072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3128}, "6": {"k": 6, "answer": "Serena Williams", "latency_ms": 1185.7662200927734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3728}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 484.2813014984131, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 917.7694320678711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 417.6785945892334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1228}, "3": {"k": 3, "answer": "1", "latency_ms": 857.4965000152588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1827}, "4": {"k": 4, "answer": "1", "latency_ms": 638.5083198547363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2434}, "5": {"k": 5, "answer": "1", "latency_ms": 834.3760967254639, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3017}, "6": {"k": 6, "answer": "1", "latency_ms": 585.7698917388916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3624}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 1017.9827213287354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2010", "latency_ms": 444.0755844116211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "2010", "latency_ms": 734.5521450042725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "2010", "latency_ms": 1135.436773300171, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1883}, "4": {"k": 4, "answer": "2010", "latency_ms": 975.7709503173828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2534}, "5": {"k": 5, "answer": "2010", "latency_ms": 904.9241542816162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3130}, "6": {"k": 6, "answer": "2010", "latency_ms": 658.0195426940918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3751}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 448.3194351196289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1274.8897075653076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "17", "latency_ms": 598.1459617614746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "17", "latency_ms": 853.8942337036133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "17", "latency_ms": 623.7821578979492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2519}, "5": {"k": 5, "answer": "17", "latency_ms": 812.6981258392334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "17", "latency_ms": 947.2692012786865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3831}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 820.6357955932617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1229.346513748169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 1167.1597957611084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 1782.4592590332031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 1602.55765914917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 962.1593952178955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3144}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 1285.390853881836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3795}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 1818.711519241333, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 1167.3977375030518, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "Corey, Cory", "latency_ms": 1224.161148071289, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1255}, "3": {"k": 3, "answer": "Corey, Cory", "latency_ms": 1182.2195053100586, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1857}, "4": {"k": 4, "answer": "Corey, Cory", "latency_ms": 797.7814674377441, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2430}, "5": {"k": 5, "answer": "Corey, Cory", "latency_ms": 1495.640516281128, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3038}, "6": {"k": 6, "answer": "Corey, Cory", "latency_ms": 1007.5738430023193, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3682}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 533.3936214447021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Randy Houser", "latency_ms": 1244.0075874328613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1076.5888690948486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1259.152889251709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 859.1728210449219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2450}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1052.032709121704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1205.0590515136719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3751}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 676.1291027069092, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 686.4407062530518, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "159", "latency_ms": 860.227108001709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "159", "latency_ms": 391.7253017425537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1974}, "4": {"k": 4, "answer": "159", "latency_ms": 1188.7412071228027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2617}, "5": {"k": 5, "answer": "159", "latency_ms": 413.5425090789795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3252}, "6": {"k": 6, "answer": "159", "latency_ms": 964.0491008758545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3867}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 592.9100513458252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 984.0590953826904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1208.3470821380615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1178.546667098999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1758}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1218.2762622833252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2349}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 981.6746711730957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2979}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1395.7719802856445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3514}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 1195.8773136138916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 746.6826438903809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1559.6301555633545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1048.025369644165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1821}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1430.3174018859863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1754.035234451294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1027.8558731079102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3741}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 768.0397033691406, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Left hand fourth finger", "latency_ms": 1211.9855880737305, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 1097.2537994384766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1137}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 366.93549156188965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1691}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 937.8445148468018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2293}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 1165.3790473937988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2857}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 885.8387470245361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3471}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 1161.3061428070068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Donald Duck", "latency_ms": 938.133716583252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Donald Duck", "latency_ms": 1198.8391876220703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Donald Duck", "latency_ms": 1231.4410209655762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1934}, "4": {"k": 4, "answer": "Donald Duck", "latency_ms": 799.2691993713379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2561}, "5": {"k": 5, "answer": "Donald Duck", "latency_ms": 1265.998363494873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3199}, "6": {"k": 6, "answer": "Donald Duck", "latency_ms": 909.7375869750977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3868}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 800.0414371490479, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 987.7910614013672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 979.7501564025879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "Bernard Mayes", "latency_ms": 1243.9019680023193, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "Bernard Mayes", "latency_ms": 1013.6876106262207, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2466}, "5": {"k": 5, "answer": "Bernard Mayes", "latency_ms": 816.7176246643066, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3067}, "6": {"k": 6, "answer": "Bernard Mayes", "latency_ms": 1257.1463584899902, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3680}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2019", "latency_ms": 1668.9112186431885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1211.5166187286377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 1660.1839065551758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 1244.7690963745117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1792}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 1527.7183055877686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2426}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 1143.6512470245361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 1180.4726123809814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3656}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 514.4197940826416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1035.0444316864014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1061.9258880615234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1305}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1492.3665523529053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1996}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1242.6352500915527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2635}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1488.6901378631592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3260}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1222.7470874786377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3875}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 774.7480869293213, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Claire Holt", "latency_ms": 748.5294342041016, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1271.9669342041016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1045.8896160125732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 977.0174026489258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2564}, "5": {"k": 5, "answer": "Claire Holt", "latency_ms": 686.1007213592529, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3135}, "6": {"k": 6, "answer": "Claire Holt", "latency_ms": 955.585241317749, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3752}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living things", "latency_ms": 699.2335319519043, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "plants, animals, dead plant matter", "latency_ms": 1034.9855422973633, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "plants, soils, animals, organisms", "latency_ms": 960.860013961792, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "plants, animals, soils", "latency_ms": 1218.2817459106445, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1956}, "4": {"k": 4, "answer": "in plants, soils, and organisms", "latency_ms": 1896.7986106872559, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2663}, "5": {"k": 5, "answer": "in plants, soils, and organisms", "latency_ms": 1904.3185710906982, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3396}, "6": {"k": 6, "answer": "in plants, soils, and organisms", "latency_ms": 1398.435115814209, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 4116}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 904.0188789367676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1256.4146518707275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1574.1162300109863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1187}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 985.1443767547607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1761}, "4": {"k": 4, "answer": "Chandan Shetty", "latency_ms": 1045.295238494873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2373}, "5": {"k": 5, "answer": "Chandan Shetty", "latency_ms": 892.4381732940674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2968}, "6": {"k": 6, "answer": "Chandan Shetty", "latency_ms": 1376.7850399017334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3611}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 1175.6460666656494, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1037.8403663635254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1007.7364444732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 799.6904850006104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1866}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1042.4704551696777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1572.744369506836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3126}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1068.6266422271729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3744}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 969.2909717559814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1682.9960346221924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1223.9887714385986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1172}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1248.5620975494385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1831}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1252.3009777069092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2457}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 762.6309394836426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3100}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1715.9464359283447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3777}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Lake Winnipeg", "latency_ms": 969.3336486816406, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 1542.6025390625, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Rocky Mountains to Lake Winnipeg", "latency_ms": 1081.9988250732422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1383}, "3": {"k": 3, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 1125.7174015045166, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 2019.1888809204102, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2737}, "5": {"k": 5, "answer": "Alberta Rockies to Lake Winnipeg", "latency_ms": 1771.4738845825195, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3342}, "6": {"k": 6, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 1078.3910751342773, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4010}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 454.6196460723877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 890.8607959747314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 649}, "2": {"k": 2, "answer": "Rome", "latency_ms": 674.8785972595215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Rome", "latency_ms": 860.633134841919, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1916}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 1464.5442962646484, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2547}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 1206.8696022033691, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3180}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 1025.2118110656738, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3778}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "Measurement mark", "latency_ms": 498.9044666290283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "manufacturing company or site", "latency_ms": 1486.1781597137451, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "the manufacturing company or site", "latency_ms": 1202.1470069885254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "the manufacturing company or site", "latency_ms": 1519.9062824249268, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1903}, "4": {"k": 4, "answer": "the manufacturing company or site", "latency_ms": 1125.2284049987793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2507}, "5": {"k": 5, "answer": "the manufacturing company or site", "latency_ms": 1264.9953365325928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3117}, "6": {"k": 6, "answer": "the manufacturing company or site", "latency_ms": 1275.3629684448242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3724}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia", "latency_ms": 976.8674373626709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1417.701005935669, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 1971.0941314697266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Hydrogen fluoride, ammonia, methanol, hydrogen sulfide", "latency_ms": 2605.703830718994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Hydrogen fluoride, ammonia, methanol, hydrogen sulfide", "latency_ms": 2264.073133468628, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "Hydrogen fluoride, ammonia, methanol, hydrogen sulfide", "latency_ms": 2426.1770248413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 1069.7641372680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Boy Meets Girl", "latency_ms": 1066.749095916748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "April 1989", "latency_ms": 1257.206678390503, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "1988", "latency_ms": 1156.0838222503662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "1988", "latency_ms": 935.7733726501465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "1988", "latency_ms": 633.7895393371582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2433}, "5": {"k": 5, "answer": "1988", "latency_ms": 1164.0043258666992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3094}, "6": {"k": 6, "answer": "1988", "latency_ms": 531.3904285430908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3718}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 948.0550289154053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hombre", "latency_ms": 405.9720039367676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "Hombre", "latency_ms": 874.2175102233887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Hombre", "latency_ms": 977.3950576782227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Hombre", "latency_ms": 397.3836898803711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Hombre", "latency_ms": 621.0296154022217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "Hombre", "latency_ms": 1177.0515441894531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3628}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 850.5189418792725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Five percent", "latency_ms": 461.17401123046875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "5%", "latency_ms": 1154.9644470214844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1317}, "3": {"k": 3, "answer": "2% to 16%", "latency_ms": 1289.7429466247559, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 1349.7810363769531, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 1609.581708908081, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3261}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 970.64208984375, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3867}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 689.4881725311279, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1384.2790126800537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "1975", "latency_ms": 897.7999687194824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1178}, "3": {"k": 3, "answer": "1975", "latency_ms": 855.586051940918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1756}, "4": {"k": 4, "answer": "1975", "latency_ms": 1223.5684394836426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2368}, "5": {"k": 5, "answer": "1975", "latency_ms": 426.69081687927246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2949}, "6": {"k": 6, "answer": "1975", "latency_ms": 853.9621829986572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3539}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 775.8445739746094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1394.7889804840088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1255.7759284973145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1175}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 753.258228302002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1769}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1287.82320022583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2356}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1023.0159759521484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2941}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1256.5035820007324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3537}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert", "latency_ms": 1066.7262077331543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lord Baltimore", "latency_ms": 428.1880855560303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "English Catholics and Protestants", "latency_ms": 1295.2964305877686, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1302}, "3": {"k": 3, "answer": "Lord Baltimore and Leonard Calvert", "latency_ms": 1574.946641921997, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1992}, "4": {"k": 4, "answer": "Lord Baltimore and settlers", "latency_ms": 797.0812320709229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2603}, "5": {"k": 5, "answer": "Lord Baltimore", "latency_ms": 695.4030990600586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3254}, "6": {"k": 6, "answer": "Cecil Calvert, the second Lord Baltimore of England, and his brother Leonard Calvert.", "latency_ms": 3486.6485595703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3916}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 442.6305294036865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1194.6344375610352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 525.2811908721924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 738.2986545562744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1024.2891311645508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2632}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1046.037197113037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3302}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1542.553186416626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3997}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 743.0107593536377, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1245.835542678833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "200 to 500 mg", "latency_ms": 1297.8971004486084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg", "latency_ms": 561.9795322418213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1878}, "4": {"k": 4, "answer": "200 to 500 mg", "latency_ms": 1651.0670185089111, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2466}, "5": {"k": 5, "answer": "200 to 500 mg", "latency_ms": 1073.6308097839355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3105}, "6": {"k": 6, "answer": "200 to 500 mg", "latency_ms": 1080.58500289917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3765}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 1128.1318664550781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham", "latency_ms": 1152.8139114379883, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 997.6520538330078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1166}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 1130.547285079956, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1758}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 724.4102954864502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2356}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 970.1175689697266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2944}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 922.7356910705566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3536}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 750.7731914520264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1242.3131465911865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1363.5740280151367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1395}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1506.1686038970947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2113}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1249.4192123413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2806}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1487.797498703003, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3481}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1275.2110958099365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4165}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh", "latency_ms": 216.9663906097412, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 1237.1761798858643, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 984.6057891845703, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1379}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 1437.7126693725586, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2052}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 1494.077444076538, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2728}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 1093.4486389160156, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3406}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 1516.58034324646, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4109}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 1067.1241283416748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1263.8320922851562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1102.3118495941162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1354}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1250.0734329223633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2028}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1242.1886920928955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2688}, "5": {"k": 5, "answer": "Roman Reigns", "latency_ms": 1014.3373012542725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3374}, "6": {"k": 6, "answer": "Roman Reigns", "latency_ms": 871.645450592041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4068}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 1273.8730907440186, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Boston", "latency_ms": 612.6372814178467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "Boston", "latency_ms": 368.73698234558105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Southport, North Carolina", "latency_ms": 592.4932956695557, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Southport, North Carolina.", "latency_ms": 1612.917184829712, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "Southport, North Carolina", "latency_ms": 1309.7419738769531, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "Southport, North Carolina.", "latency_ms": 1371.25563621521, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3725}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 257.17663764953613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 999.6528625488281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1218.4977531433105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 844.0635204315186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 1649.9693393707275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 1513.3864879608154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 1772.634744644165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3861}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 753.4172534942627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 748.0447292327881, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 669}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 1137.0928287506104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 564.8245811462402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2012}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 1191.612720489502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2728}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 962.517499923706, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3465}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 1209.9387645721436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4170}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 661.7505550384521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 425.11892318725586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "Max", "latency_ms": 1094.0625667572021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Max", "latency_ms": 426.0210990905762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1967}, "4": {"k": 4, "answer": "Max", "latency_ms": 697.7219581604004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2615}, "5": {"k": 5, "answer": "Max", "latency_ms": 958.1234455108643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3269}, "6": {"k": 6, "answer": "Max", "latency_ms": 401.5021324157715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3871}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 756.9625377655029, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 696.5179443359375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Dawn O'Day", "latency_ms": 1233.1790924072266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Mary Miles Minter", "latency_ms": 929.9213886260986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1816}, "4": {"k": 4, "answer": "Mary Miles Minter", "latency_ms": 1198.2030868530273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2412}, "5": {"k": 5, "answer": "Mary Miles Minter", "latency_ms": 1014.2438411712646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3019}, "6": {"k": 6, "answer": "Megan Follows", "latency_ms": 1016.6873931884766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3676}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "World's Fair in Paris.", "latency_ms": 1111.4585399627686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Women starting to serve in limited military roles.", "latency_ms": 1988.767385482788, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "No liberal democracy with universal suffrage", "latency_ms": 1453.3960819244385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "No liberal democracy with universal suffrage", "latency_ms": 1122.0393180847168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "Women starting to serve in limited military roles.", "latency_ms": 1696.4995861053467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2502}, "5": {"k": 5, "answer": "World War I and World War II had not yet started.", "latency_ms": 1831.3531875610352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3133}, "6": {"k": 6, "answer": "World War I and World War II had not yet started.", "latency_ms": 1367.077350616455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3699}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 760.8799934387207, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "self-empowerment", "latency_ms": 1237.9028797149658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 830.9447765350342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "self-empowerment", "latency_ms": 1242.0692443847656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "self-empowerment", "latency_ms": 1072.9339122772217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2540}, "5": {"k": 5, "answer": "self-empowerment", "latency_ms": 1634.639024734497, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3165}, "6": {"k": 6, "answer": "self-empowerment", "latency_ms": 1278.2163619995117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 405.6284427642822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "National Football League franchises", "latency_ms": 783.3247184753418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 576}, "2": {"k": 2, "answer": "National Football League (NFL) franchises", "latency_ms": 2020.7045078277588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1175}, "3": {"k": 3, "answer": "National Football League (NFL) franchises", "latency_ms": 1412.4646186828613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1822}, "4": {"k": 4, "answer": "National Football League (NFL) franchises", "latency_ms": 1696.7871189117432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "National Football League franchises", "latency_ms": 1185.4937076568604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3074}, "6": {"k": 6, "answer": "National Football League franchises", "latency_ms": 883.4424018859863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3714}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 1462.7854824066162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1156.71706199646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1271.787166595459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1457.07368850708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 972.2561836242676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1205.0628662109375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1006.8352222442627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3789}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 965.2841091156006, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 1274.9710083007812, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 1221.632719039917, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 760.4947090148926, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 1163.341999053955, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 1022.0785140991211, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3126}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 619.4062232971191, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3768}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1060.7001781463623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1415.1606559753418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 967.0071601867676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "5", "latency_ms": 679.6014308929443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "All five ski jumping gold medals.", "latency_ms": 1676.210880279541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2513}, "5": {"k": 5, "answer": "All five ski jumping gold medals.", "latency_ms": 1845.6768989562988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "5", "latency_ms": 713.7844562530518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3850}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1277.9631614685059, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1677.3109436035156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1475.6860733032227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1767.8430080413818, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1844}, "4": {"k": 4, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1749.373197555542, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2508}, "5": {"k": 5, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 2131.6421031951904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3165}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1635.383129119873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3840}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 687.9754066467285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central Germany", "latency_ms": 631.3962936401367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 629}, "2": {"k": 2, "answer": "Central Germany", "latency_ms": 1150.4168510437012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Central German", "latency_ms": 1185.445785522461, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Central European", "latency_ms": 1148.9613056182861, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2568}, "5": {"k": 5, "answer": "Central European", "latency_ms": 861.032247543335, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Central European cultures", "latency_ms": 783.1237316131592, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3933}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 1049.2942333221436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 1237.0548248291016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 1401.8902778625488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 1337.8863334655762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "post-medieval era", "latency_ms": 1029.996395111084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "post-medieval era", "latency_ms": 1050.7867336273193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3248}, "6": {"k": 6, "answer": "Post-medieval era", "latency_ms": 1020.6570625305176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3845}}}
