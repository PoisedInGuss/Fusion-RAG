{"qid": "-9197932657152136610", "question": "what are the main sources of economic growth in the us currently", "gold_answers": ["pharmaceuticals", "aircraft", "telecommunications", "heavy machinery"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1103.0120849609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1042.5968170166016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1038.4881496429443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1335}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1266.3581371307373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1306.8525791168213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2728}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1241.988182067871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3448}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1018.8655853271484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4209}}}
{"qid": "-4566914757117567579", "question": "who played ethel on the doris day show", "gold_answers": ["Carol Worthington"], "shots": {"0": {"k": 0, "answer": "Kay Chandra", "latency_ms": 957.9854011535645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1262.6361846923828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 842.6823616027832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1463.6638164520264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1476.6533374786377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2469}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1068.6028003692627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1478.8157939910889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3749}}}
{"qid": "212435016090205927", "question": "who played g baby in the movie hardball", "gold_answers": ["DeWayne Warren"], "shots": {"0": {"k": 0, "answer": "Keanu Reeves", "latency_ms": 1047.7147102355957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1528.4943580627441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1242.5215244293213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1021.5537548065186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1281.1613082885742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1204.725742340088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3284}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1241.2619590759277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3892}}}
{"qid": "-4190633494852415957", "question": "who played john coffey in the movie the green mile", "gold_answers": ["Michael Clarke Duncan"], "shots": {"0": {"k": 0, "answer": "Michael Clarke Duncan", "latency_ms": 1052.91748046875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Clarke Duncan", "latency_ms": 1187.6580715179443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 570}, "2": {"k": 2, "answer": "Michael Clarke Duncan", "latency_ms": 1160.1288318634033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1155}, "3": {"k": 3, "answer": "Michael Clarke Duncan", "latency_ms": 1025.8698463439941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1775}, "4": {"k": 4, "answer": "Michael Clarke Duncan", "latency_ms": 1205.2850723266602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2441}, "5": {"k": 5, "answer": "Michael Clarke Duncan", "latency_ms": 916.602611541748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3053}, "6": {"k": 6, "answer": "Michael Clarke Duncan", "latency_ms": 786.1199378967285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3703}}}
{"qid": "811267239470530686", "question": "who wrote catch 22 (both names)", "gold_answers": ["American author Joseph Heller", "Joseph Heller .", "Joseph Heller"], "shots": {"0": {"k": 0, "answer": "Joseph Heller", "latency_ms": 733.9498996734619, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rand and Robyn Miller", "latency_ms": 1514.1932964324951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "Rand and Robyn Miller", "latency_ms": 1307.3632717132568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Joseph Heller", "latency_ms": 741.5275573730469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1946}, "4": {"k": 4, "answer": "Joseph Heller", "latency_ms": 950.5465030670166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2601}, "5": {"k": 5, "answer": "Joseph Heller", "latency_ms": 1035.5513095855713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3253}, "6": {"k": 6, "answer": "Joseph Heller", "latency_ms": 646.0340023040771, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3916}}}
{"qid": "-1608179127534867277", "question": "where was the world chess tournament 2017 held", "gold_answers": ["Tbilisi , Georgia", "in Tbilisi , Georgia"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 630.1205158233643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tbilisi, Georgia", "latency_ms": 1506.9911479949951, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "Tbilisi, Georgia", "latency_ms": 1199.793815612793, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Tbilisi, Georgia", "latency_ms": 1094.6235656738281, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "Tbilisi, Georgia", "latency_ms": 842.6518440246582, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2613}, "5": {"k": 5, "answer": "Tbilisi, Georgia", "latency_ms": 1007.7927112579346, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "Tbilisi, Georgia", "latency_ms": 1257.8606605529785, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3809}}}
{"qid": "7687115121611301468", "question": "who votes to elect a rajya sabha memmber", "gold_answers": ["state legislatures"], "shots": {"0": {"k": 0, "answer": "Elected members of State Legislative Assembly", "latency_ms": 1208.8937759399414, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elected members of the State Assembly", "latency_ms": 1565.1514530181885, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "Elected members of the State Assembly", "latency_ms": 1594.3074226379395, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1224}, "3": {"k": 3, "answer": "Elected members of the State Assembly", "latency_ms": 1171.8266010284424, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "Elected members of the State Assembly", "latency_ms": 1638.6165618896484, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "Elected members of the State Assembly", "latency_ms": 1315.1984214782715, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3109}, "6": {"k": 6, "answer": "Members of the State Assembly", "latency_ms": 1025.8889198303223, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3734}}}
{"qid": "-5784633834792163973", "question": "when does season 8 of hawaii five o premiere", "gold_answers": ["September 29 , 2017"], "shots": {"0": {"k": 0, "answer": "September 27, 2017", "latency_ms": 1424.6833324432373, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1063.0171298980713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "September 29, 2017", "latency_ms": 1165.5337810516357, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1296}, "3": {"k": 3, "answer": "September 29, 2017", "latency_ms": 1504.2874813079834, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1911}, "4": {"k": 4, "answer": "September 29, 2017", "latency_ms": 1247.4117279052734, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2574}, "5": {"k": 5, "answer": "September 29, 2017", "latency_ms": 1878.162145614624, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3263}, "6": {"k": 6, "answer": "September 29, 2017", "latency_ms": 982.6478958129883, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3854}}}
{"qid": "-5864397450755103545", "question": "paul walkers cars in fast and furious list", "gold_answers": ["1995 Toyota Supra", "2002 Mitsubishi Lancer OZ Rally", "1995 Dodge Stealth", "1995 Mitsubishi Eclipse"], "shots": {"0": {"k": 0, "answer": "Toyota Supra, Mitsubishi Eclipse, Nissan Skyline, Dodge Charger, Ford Gran Torino", "latency_ms": 2778.961181640625, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 780.0595760345459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1188.786268234253, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1035.7496738433838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1097.017765045166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2495}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 987.863302230835, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3093}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 954.1134834289551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3712}}}
{"qid": "-8491157534197669091", "question": "who won the oscar for best actor in 1975", "gold_answers": ["Art Carney"], "shots": {"0": {"k": 0, "answer": "Art Carney", "latency_ms": 725.6636619567871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Peter Finch", "latency_ms": 780.8055877685547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "Peter Finch", "latency_ms": 723.7815856933594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1558.8233470916748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 936.2804889678955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1267.6911354064941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3250}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 719.1226482391357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3885}}}
{"qid": "-8408640804522114136", "question": "when did the first episode of that 70s show air", "gold_answers": ["August 23 , 1998"], "shots": {"0": {"k": 0, "answer": "August 23, 1998", "latency_ms": 1632.1535110473633, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 996.4699745178223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 778.1283855438232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1204.8654556274414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 959.7299098968506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2495}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1058.720588684082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1259.7968578338623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3769}}}
{"qid": "722920117313579366", "question": "when did the book thief movie come out", "gold_answers": ["November 27 , 2013", "2013"], "shots": {"0": {"k": 0, "answer": "November 8, 2013", "latency_ms": 1648.0116844177246, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1069.3345069885254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 555}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 831.8796157836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1177}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1191.5574073791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1794}, "4": {"k": 4, "answer": "2013", "latency_ms": 702.6412487030029, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2437}, "5": {"k": 5, "answer": "2013", "latency_ms": 410.3412628173828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3056}, "6": {"k": 6, "answer": "2013", "latency_ms": 1113.2280826568604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3629}}}
{"qid": "-4427112594024146143", "question": "when did the eagles win the super bowl", "gold_answers": ["2017"], "shots": {"0": {"k": 0, "answer": "Super Bowl LII", "latency_ms": 1107.6419353485107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 951.7152309417725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "Super Bowl LII", "latency_ms": 1197.6017951965332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1217}, "3": {"k": 3, "answer": "Super Bowl LII", "latency_ms": 1095.2081680297852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2075}, "4": {"k": 4, "answer": "Super Bowl LII", "latency_ms": 538.088321685791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2686}, "5": {"k": 5, "answer": "Super Bowl LII", "latency_ms": 1202.805519104004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3314}, "6": {"k": 6, "answer": "Super Bowl LII", "latency_ms": 1249.3577003479004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3916}}}
{"qid": "7078422108284431587", "question": "who is the biggest selling female group of all time", "gold_answers": ["Spice Girls"], "shots": {"0": {"k": 0, "answer": "The Spice Girls", "latency_ms": 259.43970680236816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spice Girls", "latency_ms": 723.3388423919678, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 603}, "2": {"k": 2, "answer": "Spice Girls", "latency_ms": 664.0455722808838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1178}, "3": {"k": 3, "answer": "Spice Girls", "latency_ms": 912.0233058929443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1809}, "4": {"k": 4, "answer": "Spice Girls", "latency_ms": 1184.6797466278076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2418}, "5": {"k": 5, "answer": "Spice Girls", "latency_ms": 694.2329406738281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3004}, "6": {"k": 6, "answer": "Spice Girls", "latency_ms": 1002.4750232696533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3682}}}
{"qid": "1039102546557940080", "question": "who sang from russia with love james bond", "gold_answers": ["Matt Monro"], "shots": {"0": {"k": 0, "answer": "Matt Monro", "latency_ms": 502.5448799133301, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matt Monro", "latency_ms": 734.3518733978271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Matt Monro", "latency_ms": 698.5137462615967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1263}, "3": {"k": 3, "answer": "Matt Monro", "latency_ms": 706.4495086669922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Matt Monro", "latency_ms": 466.57657623291016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2503}, "5": {"k": 5, "answer": "Matt Monro", "latency_ms": 698.1747150421143, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3103}, "6": {"k": 6, "answer": "Matt Monro", "latency_ms": 957.8096866607666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3716}}}
{"qid": "-8507438636601119973", "question": "where is urinary bladder located in human body", "gold_answers": ["on the pelvic floor", "pelvic floor"], "shots": {"0": {"k": 0, "answer": "Pelvic cavity", "latency_ms": 776.7951488494873, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1248.5363483428955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1258.5020065307617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "at the base of the pelvis", "latency_ms": 1890.4085159301758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "at the base of the pelvis", "latency_ms": 1670.6798076629639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2568}, "5": {"k": 5, "answer": "at the base of the pelvis", "latency_ms": 1619.7729110717773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3183}, "6": {"k": 6, "answer": "at the base of the pelvis", "latency_ms": 1587.2831344604492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3893}}}
{"qid": "-1996951438961136762", "question": "architectural elements forming rib vaults eg wells cathedral", "gold_answers": ["two to three barrel vaults", "an armature of piped masonry", "barrel vaults"], "shots": {"0": {"k": 0, "answer": "Ribs", "latency_ms": 992.3155307769775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ribs", "latency_ms": 659.7576141357422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "flying buttress", "latency_ms": 1007.1315765380859, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1334}, "3": {"k": 3, "answer": "tierceron", "latency_ms": 935.8947277069092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2074}, "4": {"k": 4, "answer": "tierceron", "latency_ms": 1223.3541011810303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2758}, "5": {"k": 5, "answer": "tierceron and lierne ribs", "latency_ms": 1345.0989723205566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3400}, "6": {"k": 6, "answer": "tierceron and lierne ribs", "latency_ms": 1627.1448135375977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3990}}}
{"qid": "-8490085242981497626", "question": "who sang gonna sit right down and write myself a letter", "gold_answers": ["Fats Waller"], "shots": {"0": {"k": 0, "answer": "Alicia Keys", "latency_ms": 446.274995803833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fats Waller", "latency_ms": 1081.8443298339844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "Fats Waller, Cleo Laine, Uncle Floyd, Madeleine Peyroux, Tony Danza, Paul McCartney", "latency_ms": 4868.6277866363525, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Fats Waller", "latency_ms": 992.6867485046387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1876}, "4": {"k": 4, "answer": "Fats Waller", "latency_ms": 1078.8590908050537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2540}, "5": {"k": 5, "answer": "Fats Waller", "latency_ms": 1309.3702793121338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3144}, "6": {"k": 6, "answer": "Fats Waller", "latency_ms": 1075.9203433990479, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3752}}}
{"qid": "8783361206191889627", "question": "how many rooms is there in buckingham palace", "gold_answers": ["775 rooms", "775"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1207.1082592010498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 993.2246208190918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 594}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1491.7495250701904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1240}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1237.5540733337402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 607.6929569244385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1635.3836059570312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3109}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1149.7244834899902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3731}}}
{"qid": "1172792682698457582", "question": "where did they get the tree for rockefeller center", "gold_answers": ["State College , PA"], "shots": {"0": {"k": 0, "answer": "Wallkill, New York", "latency_ms": 1413.6221408843994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1510.3557109832764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 687}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1259.0734958648682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1365}, "3": {"k": 3, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 2385.612726211548, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada", "latency_ms": 3227.898359298706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2673}, "5": {"k": 5, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada", "latency_ms": 2141.8540477752686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3337}, "6": {"k": 6, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada", "latency_ms": 2508.943557739258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3991}}}
{"qid": "-8616225749004085214", "question": "who expanded the territory of china during the qing dynasty", "gold_answers": ["Prince Bao", "the Qianlong Emperor", "Qianlong"], "shots": {"0": {"k": 0, "answer": "Qianlong Emperor", "latency_ms": 832.5338363647461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The founding emperors", "latency_ms": 876.5966892242432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 687}, "2": {"k": 2, "answer": "the founding emperors", "latency_ms": 1291.9456958770752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "The founding emperors", "latency_ms": 1492.150068283081, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2006}, "4": {"k": 4, "answer": "The founding emperors", "latency_ms": 1091.7243957519531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "The founding emperors", "latency_ms": 1587.040662765503, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3277}, "6": {"k": 6, "answer": "The founding emperors", "latency_ms": 1574.7549533843994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3916}}}
{"qid": "-4544825586005995775", "question": "what is the second largest country in asia", "gold_answers": ["China"], "shots": {"0": {"k": 0, "answer": "Kazakhstan", "latency_ms": 545.4041957855225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1011.1050605773926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 781}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1197.9947090148926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1430}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 773.8065719604492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2090}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1498.0583190917969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2822}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1252.9592514038086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3421}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 758.03542137146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4025}}}
{"qid": "2851585794686488659", "question": "when was the last episode of vampire diaries aired", "gold_answers": ["March 10 , 2017"], "shots": {"0": {"k": 0, "answer": "March 10, 2017", "latency_ms": 703.6769390106201, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1077.4915218353271, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1127.387285232544, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1296}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1329.6518325805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1144.6316242218018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1286.4110469818115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3226}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1102.3814678192139, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3860}}}
{"qid": "636692438616046367", "question": "who played ashley on the young and the restless", "gold_answers": ["Shari Shattuck", "Eileen Davidson", "Brenda Epperson"], "shots": {"0": {"k": 0, "answer": "Eileen Davidson", "latency_ms": 1485.281229019165, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1730.6969165802002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Eileen Davidson", "latency_ms": 1256.4740180969238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1236}, "3": {"k": 3, "answer": "Eileen Davidson", "latency_ms": 1085.885763168335, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1847}, "4": {"k": 4, "answer": "Eileen Davidson", "latency_ms": 696.3636875152588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2501}, "5": {"k": 5, "answer": "Eileen Davidson", "latency_ms": 1179.3367862701416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3112}, "6": {"k": 6, "answer": "Eileen Davidson", "latency_ms": 913.8984680175781, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3787}}}
{"qid": "-2668952310493902320", "question": "who has scored the most points for wales v france", "gold_answers": ["Neil Jenkins"], "shots": {"0": {"k": 0, "answer": "Neil Jenkins", "latency_ms": 242.27333068847656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1004.6463012695312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 730.635404586792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 987.8706932067871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "William Cummins", "latency_ms": 796.980619430542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2517}, "5": {"k": 5, "answer": "William Cummins", "latency_ms": 714.1947746276855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3071}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1047.5621223449707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3625}}}
{"qid": "-551363795407275714", "question": "who is pictured on the 5000 dollar bill", "gold_answers": ["James Madison"], "shots": {"0": {"k": 0, "answer": "James Madison", "latency_ms": 723.5317230224609, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 545.3953742980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 976.0780334472656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1058.9690208435059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1993}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 734.2984676361084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2595}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 795.6054210662842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3203}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 989.4275665283203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3812}}}
{"qid": "-1776638341170409438", "question": "what is the strongest earthquake in the united states", "gold_answers": ["1700 Cascadia earthquake", "1964 Alaska earthquake and tsunami"], "shots": {"0": {"k": 0, "answer": "Great Alaska Earthquake", "latency_ms": 563.4317398071289, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1867 Manhattan, Kansas earthquake", "latency_ms": 1176.238775253296, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1072.209358215332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "2002 Denali earthquake", "latency_ms": 1494.6415424346924, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "7.9 M", "latency_ms": 574.1987228393555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2603}, "5": {"k": 5, "answer": "7.9 M", "latency_ms": 1223.951816558838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3301}, "6": {"k": 6, "answer": "1964 magnitude 9.2 Good Friday earthquake", "latency_ms": 1810.2083206176758, "em": 0.0, "f1": 0.3636363636363636, "containment": 0.0, "context_chars": 3949}}}
{"qid": "-3417376069582577712", "question": "who wrote the song balls to the wall", "gold_answers": ["Herman Frank", "Peter Baltes", "Stefan Kaufmann", "Wolf Hoffmann", "Udo Dirkschneider", "Deaffy"], "shots": {"0": {"k": 0, "answer": "Accept", "latency_ms": 649.1503715515137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 768.873929977417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "Accept", "latency_ms": 881.0708522796631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1170}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1090.6412601470947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1767}, "4": {"k": 4, "answer": "Accept", "latency_ms": 528.5391807556152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2360}, "5": {"k": 5, "answer": "Accept", "latency_ms": 863.8889789581299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2966}, "6": {"k": 6, "answer": "Accept", "latency_ms": 422.4510192871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3588}}}
{"qid": "-5788046732019278353", "question": "who talks for belle in beauty and the beast", "gold_answers": ["Julie Nathanson", "Jodi Benson", "Paige O'Hara"], "shots": {"0": {"k": 0, "answer": "Paige O'Hara", "latency_ms": 1476.0465621948242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 975.7974147796631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "Paige O'Hara", "latency_ms": 1756.9005489349365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1293}, "3": {"k": 3, "answer": "Paige O'Hara", "latency_ms": 1167.5362586975098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1890}, "4": {"k": 4, "answer": "Paige O'Hara", "latency_ms": 1067.2662258148193, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2544}, "5": {"k": 5, "answer": "Paige O'Hara", "latency_ms": 1341.4702415466309, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3248}, "6": {"k": 6, "answer": "Paige O'Hara", "latency_ms": 849.5769500732422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3842}}}
{"qid": "-819495145099806596", "question": "what is a coherent set of values and beliefs about public policy called", "gold_answers": ["political ideology", "ideology", "a political ideology"], "shots": {"0": {"k": 0, "answer": "Ideology", "latency_ms": 845.207929611206, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 985.832691192627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 851.0675430297852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1399}, "3": {"k": 3, "answer": "Civic ideology", "latency_ms": 689.1498565673828, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2095}, "4": {"k": 4, "answer": "ideology", "latency_ms": 740.8168315887451, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2783}, "5": {"k": 5, "answer": "ideology", "latency_ms": 830.0344944000244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3572}, "6": {"k": 6, "answer": "ideology", "latency_ms": 955.0817012786865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4329}}}
{"qid": "-467801736331608973", "question": "when do liam and annie get together season 3", "gold_answers": ["Holiday Madness"], "shots": {"0": {"k": 0, "answer": "Episode 9", "latency_ms": 288.0280017852783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1702.1350860595703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "After Naomi leaves for France", "latency_ms": 1550.2243041992188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Season 3", "latency_ms": 593.1549072265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Season 3", "latency_ms": 922.0728874206543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Season 3", "latency_ms": 1010.4079246520996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3056}, "6": {"k": 6, "answer": "Season 2", "latency_ms": 1253.9079189300537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3613}}}
{"qid": "7210975046317501288", "question": "what breed of cat has spots and stripes", "gold_answers": ["tabby"], "shots": {"0": {"k": 0, "answer": "Ocicat", "latency_ms": 763.7605667114258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bengal cat", "latency_ms": 798.370361328125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "Bengal cat", "latency_ms": 1220.491886138916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1294}, "3": {"k": 3, "answer": "Bengal", "latency_ms": 705.3060531616211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1933}, "4": {"k": 4, "answer": "Bengal cat", "latency_ms": 1236.4976406097412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2581}, "5": {"k": 5, "answer": "Bengal", "latency_ms": 1008.6832046508789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Bengal cat", "latency_ms": 1165.3249263763428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3838}}}
{"qid": "7817340376558760325", "question": "who voiced simba in the lion king 2", "gold_answers": ["Matthew Broderick"], "shots": {"0": {"k": 0, "answer": "Matthew Broderick", "latency_ms": 1083.5766792297363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1312.8557205200195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1273.2112407684326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 854.3961048126221, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1311.5558624267578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2530}, "5": {"k": 5, "answer": "Matthew Broderick", "latency_ms": 1302.9701709747314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3139}, "6": {"k": 6, "answer": "Matthew Broderick", "latency_ms": 1289.8688316345215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3751}}}
{"qid": "7584034394038581786", "question": "when did the angel of the north get built", "gold_answers": ["1998", "1994"], "shots": {"0": {"k": 0, "answer": "1998", "latency_ms": 675.0824451446533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1243.0944442749023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1066.2047863006592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 874.0906715393066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1257.9166889190674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1043.7042713165283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3118}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1521.8453407287598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3745}}}
{"qid": "1854394640394891866", "question": "when did mcgee became a regular on ncis", "gold_answers": ["in season two", "season two"], "shots": {"0": {"k": 0, "answer": "Season 2", "latency_ms": 1026.5226364135742, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1265.157699584961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "September 23, 2008", "latency_ms": 1163.3152961730957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Season two", "latency_ms": 1201.6804218292236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Season two", "latency_ms": 470.844030380249, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2557}, "5": {"k": 5, "answer": "Season two", "latency_ms": 860.2678775787354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3190}, "6": {"k": 6, "answer": "Season two", "latency_ms": 645.1163291931152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3816}}}
{"qid": "2247250807557083996", "question": "when was 1 john 5 7 added to the bible", "gold_answers": ["the 9th century"], "shots": {"0": {"k": 0, "answer": "15th century", "latency_ms": 699.6877193450928, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 824.5687484741211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1032.6189994812012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1214.9391174316406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1875}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1374.485731124878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2416}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1266.505479812622, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3094}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1291.1183834075928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3715}}}
{"qid": "-2049551589682654986", "question": "when was the latest version of chrome released", "gold_answers": ["2018 - 01 - 22"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 787.1537208557129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2003", "latency_ms": 914.3657684326172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1183.3677291870117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1384}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1431.656837463379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2046}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1202.2252082824707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2669}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 701.9150257110596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3324}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 744.7690963745117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4001}}}
{"qid": "-3534092359651954035", "question": "who is jojo in horton hears a who", "gold_answers": ["Jesse McCartney"], "shots": {"0": {"k": 0, "answer": "JoJo", "latency_ms": 864.9775981903076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a small Who", "latency_ms": 937.5419616699219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "a small Who", "latency_ms": 681.0739040374756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1167}, "3": {"k": 3, "answer": "a small Who", "latency_ms": 986.8197441101074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "a small Who", "latency_ms": 1194.751501083374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2455}, "5": {"k": 5, "answer": "JoJo, the Mayor's son", "latency_ms": 1313.591480255127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3034}, "6": {"k": 6, "answer": "JoJo, the Mayor's son", "latency_ms": 1621.96946144104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3646}}}
{"qid": "6504412384445795967", "question": "the part of the cytoskeleton made from the protein actin is called", "gold_answers": ["Microfilaments", "microfilament"], "shots": {"0": {"k": 0, "answer": "Microfilaments", "latency_ms": 733.0949306488037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "actin cytoskeleton", "latency_ms": 1057.321548461914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "Microfilament", "latency_ms": 990.0295734405518, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1425}, "3": {"k": 3, "answer": "Microfilament", "latency_ms": 966.9444561004639, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2148}, "4": {"k": 4, "answer": "Microfilament", "latency_ms": 739.1946315765381, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2839}, "5": {"k": 5, "answer": "Microfilament", "latency_ms": 1346.8506336212158, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3532}, "6": {"k": 6, "answer": "Microfilament", "latency_ms": 1262.9640102386475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4258}}}
{"qid": "95888218441734902", "question": "who plays jack in battle of the sexes", "gold_answers": ["Bill Pullman", "( Bill Pullman"], "shots": {"0": {"k": 0, "answer": "Steve Carell", "latency_ms": 776.496410369873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack McLaughlin", "latency_ms": 1089.3030166625977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "Jack McLaughlin", "latency_ms": 1409.5008373260498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Jack McLaughlin", "latency_ms": 993.5741424560547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1784}, "4": {"k": 4, "answer": "Jack McLaughlin", "latency_ms": 1232.7165603637695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2393}, "5": {"k": 5, "answer": "Jack Kramer", "latency_ms": 894.888162612915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2991}, "6": {"k": 6, "answer": "Jack Kramer", "latency_ms": 675.1325130462646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3641}}}
{"qid": "2482202658787537401", "question": "is a network connection device that can build tables that identify addresses on each network", "gold_answers": ["routing table", "a router"], "shots": {"0": {"k": 0, "answer": "Router", "latency_ms": 640.8417224884033, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1071.385383605957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Router", "latency_ms": 889.7380828857422, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1330}, "3": {"k": 3, "answer": "Router", "latency_ms": 834.5334529876709, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Zigbee coordinator", "latency_ms": 1211.909532546997, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2603}, "5": {"k": 5, "answer": "Zigbee coordinator", "latency_ms": 1190.324306488037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3282}, "6": {"k": 6, "answer": "Zigbee coordinator", "latency_ms": 1012.9179954528809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3972}}}
{"qid": "8359496728452221378", "question": "when did the royal proclamation of 1763 end", "gold_answers": ["with the American Revolutionary War", "the American Revolutionary War", "1783"], "shots": {"0": {"k": 0, "answer": "1763", "latency_ms": 752.5503635406494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 970.0613021850586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 963.4640216827393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1358}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 810.1129531860352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2071}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1203.1617164611816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2742}, "5": {"k": 5, "answer": "American Revolutionary War", "latency_ms": 1185.6005191802979, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3365}, "6": {"k": 6, "answer": "American Revolutionary War", "latency_ms": 1145.064115524292, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4050}}}
{"qid": "-2657014790962135860", "question": "the tenure of the office of the lokayukt of up", "gold_answers": ["8 years", "eight years"], "shots": {"0": {"k": 0, "answer": "8 years", "latency_ms": 253.29852104187012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1559.91530418396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1205.9550285339355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 743.5059547424316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1286.1077785491943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1275.4418849945068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3151}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1219.7601795196533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3805}}}
{"qid": "1827180983934640653", "question": "when did response to state of the union start", "gold_answers": ["1966", "in 1966"], "shots": {"0": {"k": 0, "answer": "1966", "latency_ms": 693.9041614532471, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1183.3791732788086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1279.9975872039795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 941.2984848022461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1977}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1225.3773212432861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2652}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1053.4882545471191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1249.9325275421143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3915}}}
{"qid": "-8006002028754190814", "question": "who had the most governmental power under the articles of confederation", "gold_answers": ["the states"], "shots": {"0": {"k": 0, "answer": "State governments", "latency_ms": 704.7042846679688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The states", "latency_ms": 396.25048637390137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 722}, "2": {"k": 2, "answer": "Congress", "latency_ms": 998.1496334075928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1394}, "3": {"k": 3, "answer": "The states", "latency_ms": 647.9272842407227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2088}, "4": {"k": 4, "answer": "The states", "latency_ms": 877.8061866760254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2766}, "5": {"k": 5, "answer": "The states", "latency_ms": 909.2526435852051, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3531}, "6": {"k": 6, "answer": "The states", "latency_ms": 1007.0054531097412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4232}}}
{"qid": "3406509904702130536", "question": "how many hospitals are there in the united states", "gold_answers": ["5,534 registered hospitals", "5,534"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1054.2240142822266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seven", "latency_ms": 595.6437587738037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 679}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 699.3308067321777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1368}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1032.8667163848877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2050}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1236.0103130340576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2752}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 519.9825763702393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3404}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 958.8499069213867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4063}}}
{"qid": "2435796066046322163", "question": "who donates a christmas tree to trafalgar square", "gold_answers": ["Oslo , Norway"], "shots": {"0": {"k": 0, "answer": "Norway", "latency_ms": 741.4309978485107, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The city of Oslo, Norway", "latency_ms": 1307.2421550750732, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "The city of Oslo, Norway", "latency_ms": 1366.7511940002441, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Norway", "latency_ms": 902.6997089385986, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1929}, "4": {"k": 4, "answer": "Norway", "latency_ms": 427.7777671813965, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Norway", "latency_ms": 672.3124980926514, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3213}, "6": {"k": 6, "answer": "Norway", "latency_ms": 866.7705059051514, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3826}}}
{"qid": "4926415052497472665", "question": "who starred in the movie on golden pond", "gold_answers": ["William Lanteau", "Dabney Coleman", "Henry Fonda", "Doug McKeon", "Jane Fonda", "Christopher Rydell", "Katharine Hepburn"], "shots": {"0": {"k": 0, "answer": "Henry Fonda", "latency_ms": 744.2176342010498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Julie Andrews and Christopher Plummer", "latency_ms": 1598.2251167297363, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 609}, "2": {"k": 2, "answer": "Julie Andrews, Christopher Plummer, Henry Fonda, Katharine Hepburn, Jane Fonda, Dabney Coleman", "latency_ms": 3972.0680713653564, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Henry Fonda, Katharine Hepburn, Jane Fonda, Dabney Coleman, Julie Andrews, Christopher Plummer", "latency_ms": 4263.423681259155, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1826}, "4": {"k": 4, "answer": "Henry Fonda, Katharine Hepburn, Jane Fonda, Dabney Coleman, Julie Andrews, Christopher Plummer", "latency_ms": 4475.767612457275, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 2469}, "5": {"k": 5, "answer": "Henry Fonda, Katharine Hepburn, Jane Fonda, Dabney Coleman, Julie Andrews, Christopher Plummer.", "latency_ms": 4360.525131225586, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 3059}, "6": {"k": 6, "answer": "Henry Fonda, Katharine Hepburn, Jane Fonda, Dabney Coleman, Julie Andrews, Christopher Plummer", "latency_ms": 4615.922451019287, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 3615}}}
{"qid": "2142753216627246962", "question": "isdn uses b & d channels. what is d channel use for", "gold_answers": ["carries control and signaling information", "data", "control and signaling information"], "shots": {"0": {"k": 0, "answer": "Signaling", "latency_ms": 249.80401992797852, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Signaling", "latency_ms": 930.901050567627, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 702}, "2": {"k": 2, "answer": "Signaling", "latency_ms": 618.7033653259277, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1415}, "3": {"k": 3, "answer": "signaling", "latency_ms": 601.1369228363037, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2063}, "4": {"k": 4, "answer": "signaling", "latency_ms": 917.0665740966797, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2692}, "5": {"k": 5, "answer": "signaling", "latency_ms": 1186.5177154541016, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3297}, "6": {"k": 6, "answer": "signaling", "latency_ms": 632.3294639587402, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3904}}}
{"qid": "1547060614805522730", "question": "what is the rate limiting enzyme of kreb's cycle", "gold_answers": ["Isocitrate dehydrogenase"], "shots": {"0": {"k": 0, "answer": "Isocitrate dehydrogenase", "latency_ms": 1255.2590370178223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "ALA synthase", "latency_ms": 696.9027519226074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "ALA synthase", "latency_ms": 1241.8038845062256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1376}, "3": {"k": 3, "answer": "ALA synthase", "latency_ms": 924.7992038726807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2008}, "4": {"k": 4, "answer": "ALA synthase", "latency_ms": 718.8146114349365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2651}, "5": {"k": 5, "answer": "ALA synthase", "latency_ms": 934.4794750213623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3295}, "6": {"k": 6, "answer": "ALA synthase", "latency_ms": 1249.5975494384766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3965}}}
{"qid": "8965198420725510475", "question": "when was the taj mahal built and completed", "gold_answers": ["1632 -- 53"], "shots": {"0": {"k": 0, "answer": "1653", "latency_ms": 694.0841674804688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1871 to 1884", "latency_ms": 1382.9057216644287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "1871 to 1884", "latency_ms": 1557.0850372314453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "1871 to 1884", "latency_ms": 720.5305099487305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "1643", "latency_ms": 685.5740547180176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2430}, "5": {"k": 5, "answer": "1643", "latency_ms": 690.798282623291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3029}, "6": {"k": 6, "answer": "1643", "latency_ms": 1205.9545516967773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3653}}}
{"qid": "-6292760252056275316", "question": "which supreme court judge has surved in international court of justice", "gold_answers": ["Dalveer Bhandari"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 755.5022239685059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justice Dalveer Bhandari", "latency_ms": 1166.748285293579, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "Dalveer Bhandari", "latency_ms": 1146.941900253296, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1289}, "3": {"k": 3, "answer": "Dalveer Bhandari", "latency_ms": 1088.4928703308105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2013}, "4": {"k": 4, "answer": "Justice Dalveer Bhandari", "latency_ms": 1297.501564025879, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2654}, "5": {"k": 5, "answer": "Dalveer Bhandari", "latency_ms": 1330.6231498718262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3354}, "6": {"k": 6, "answer": "Dalveer Bhandari", "latency_ms": 1079.0586471557617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3987}}}
{"qid": "8361850218460994084", "question": "who is known as father of green revolution in india", "gold_answers": ["Mankombu Sambasivan Swaminathan"], "shots": {"0": {"k": 0, "answer": "M.S. Swaminathan", "latency_ms": 1184.6308708190918, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "M. S. Swaminathan", "latency_ms": 945.4686641693115, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "M. S. Swaminathan", "latency_ms": 1169.3761348724365, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "M. S. Swaminathan", "latency_ms": 1315.9723281860352, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2049}, "4": {"k": 4, "answer": "M. S. Swaminathan", "latency_ms": 1323.3656883239746, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2755}, "5": {"k": 5, "answer": "M. S. Swaminathan", "latency_ms": 1110.612154006958, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3356}, "6": {"k": 6, "answer": "M. S. Swaminathan", "latency_ms": 1596.0814952850342, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4090}}}
{"qid": "-5690645328022945594", "question": "who sing say you won't let go", "gold_answers": ["James Arthur"], "shots": {"0": {"k": 0, "answer": "James Arthur", "latency_ms": 476.24683380126953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rascal Flatts", "latency_ms": 1012.2599601745605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Rascal Flatts", "latency_ms": 507.93933868408203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "Rascal Flatts", "latency_ms": 960.3047370910645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1712}, "4": {"k": 4, "answer": "Rascal Flatts", "latency_ms": 716.1355018615723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2284}, "5": {"k": 5, "answer": "Rascal Flatts", "latency_ms": 714.1056060791016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2899}, "6": {"k": 6, "answer": "Rascal Flatts", "latency_ms": 1012.7294063568115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3520}}}
{"qid": "-4292736993227486718", "question": "who monitor the recovery of the location during a disaster", "gold_answers": ["management team"], "shots": {"0": {"k": 0, "answer": "Emergency Management Team", "latency_ms": 281.3906669616699, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Susan Cutter", "latency_ms": 602.2815704345703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "The management team", "latency_ms": 523.0140686035156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1411}, "3": {"k": 3, "answer": "The management team", "latency_ms": 1166.806697845459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2035}, "4": {"k": 4, "answer": "The management team", "latency_ms": 964.3988609313965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2755}, "5": {"k": 5, "answer": "The management team", "latency_ms": 651.5047550201416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3394}, "6": {"k": 6, "answer": "The management team", "latency_ms": 744.1105842590332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4199}}}
{"qid": "-4741747756019727470", "question": "where does the synthesis of new dna from existing dna occurs", "gold_answers": ["origins of replication"], "shots": {"0": {"k": 0, "answer": "Replication fork", "latency_ms": 1186.9151592254639, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in vivo", "latency_ms": 607.7368259429932, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "in vivo", "latency_ms": 927.0491600036621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1433}, "3": {"k": 3, "answer": "in vivo", "latency_ms": 682.3866367340088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2095}, "4": {"k": 4, "answer": "in vivo", "latency_ms": 875.6229877471924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2726}, "5": {"k": 5, "answer": "in vivo", "latency_ms": 612.699031829834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3373}, "6": {"k": 6, "answer": "in vivo", "latency_ms": 961.1835479736328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4100}}}
{"qid": "4268853195499399258", "question": "who sings gimme shelter with mick jagger", "gold_answers": ["Merry Clayton"], "shots": {"0": {"k": 0, "answer": "Merry Clayton", "latency_ms": 941.5020942687988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Merry Clayton", "latency_ms": 914.3738746643066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Merry Clayton", "latency_ms": 932.4836730957031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Merry Clayton", "latency_ms": 765.5391693115234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1844}, "4": {"k": 4, "answer": "Merry Clayton", "latency_ms": 808.0532550811768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2499}, "5": {"k": 5, "answer": "Merry Clayton", "latency_ms": 1368.3888912200928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3146}, "6": {"k": 6, "answer": "Merry Clayton", "latency_ms": 806.0624599456787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3781}}}
{"qid": "7172420463912356173", "question": "who does tony end up with on skins", "gold_answers": ["Michelle"], "shots": {"0": {"k": 0, "answer": "Michelle", "latency_ms": 672.9159355163574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michelle", "latency_ms": 821.7580318450928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 623}, "2": {"k": 2, "answer": "Michelle", "latency_ms": 673.9242076873779, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1205}, "3": {"k": 3, "answer": "Michelle", "latency_ms": 863.7497425079346, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1792}, "4": {"k": 4, "answer": "Michelle", "latency_ms": 869.0230846405029, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2356}, "5": {"k": 5, "answer": "Michelle", "latency_ms": 394.1504955291748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2942}, "6": {"k": 6, "answer": "Michelle", "latency_ms": 967.6227569580078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3565}}}
{"qid": "-1400292288904470066", "question": "who sings sugar sugar you are my candy girl", "gold_answers": ["the Archies"], "shots": {"0": {"k": 0, "answer": "The Archies", "latency_ms": 567.5230026245117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1038.5463237762451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1196.7473030090332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 699.293851852417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 741.422176361084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2545}, "5": {"k": 5, "answer": "The Archies", "latency_ms": 1010.8392238616943, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3191}, "6": {"k": 6, "answer": "The Archies", "latency_ms": 1139.5206451416016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3791}}}
{"qid": "-1696720698220253139", "question": "who does tyler end up with in you get me", "gold_answers": ["Ali"], "shots": {"0": {"k": 0, "answer": "Holly.\nor \nAlison.", "latency_ms": 818.1438446044922, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 968.2283401489258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1054.5852184295654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1080.1599025726318, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 774.766206741333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2418}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 963.759183883667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3006}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1250.2720355987549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3600}}}
{"qid": "-6797239474199900801", "question": "who won the gold for the men's figure skating", "gold_answers": ["Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 331.15625381469727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1486.811876296997, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1040.9772396087646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1179}, "3": {"k": 3, "answer": "Hayes Jenkins", "latency_ms": 920.2919006347656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1847}, "4": {"k": 4, "answer": "Hayes Jenkins", "latency_ms": 692.8746700286865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2500}, "5": {"k": 5, "answer": "Hayes Jenkins", "latency_ms": 964.2915725708008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3199}, "6": {"k": 6, "answer": "Hayes Jenkins", "latency_ms": 722.1605777740479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3901}}}
{"qid": "-7819569157752445011", "question": "when did the song holiday road come out", "gold_answers": ["1983", "June 24 , 1983"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 296.4797019958496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1983", "latency_ms": 983.9143753051758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "1983", "latency_ms": 922.1818447113037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "1983", "latency_ms": 912.7881526947021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2013}, "4": {"k": 4, "answer": "1983", "latency_ms": 975.959062576294, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2683}, "5": {"k": 5, "answer": "1983", "latency_ms": 1296.3063716888428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3421}, "6": {"k": 6, "answer": "1983", "latency_ms": 1048.8100051879883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4017}}}
{"qid": "-8839043176903626071", "question": "when does the mlb season start and finish", "gold_answers": ["October 31 , 2018", "March 29"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 704.7057151794434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 994.9808120727539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1395.1220512390137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1182.232141494751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1856}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1402.130365371704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2431}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1228.851079940796, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3020}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 795.1126098632812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3595}}}
{"qid": "6356531089429364942", "question": "when did scotland beat england in six nations", "gold_answers": ["8 March 2008", "25 February 2006", "24 February 2018", "2 April 2000"], "shots": {"0": {"k": 0, "answer": "8 February 2020", "latency_ms": 1057.4913024902344, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1871", "latency_ms": 934.4959259033203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "1871", "latency_ms": 391.5543556213379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "1971", "latency_ms": 1096.5814590454102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "1871", "latency_ms": 1203.8993835449219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2522}, "5": {"k": 5, "answer": "1871", "latency_ms": 922.4638938903809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "1971", "latency_ms": 939.1767978668213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3776}}}
{"qid": "-3382335563294993978", "question": "when did the rational dress society begin to work", "gold_answers": ["1881"], "shots": {"0": {"k": 0, "answer": "1881", "latency_ms": 726.9492149353027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1881", "latency_ms": 862.642765045166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "1881", "latency_ms": 671.6551780700684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "1881", "latency_ms": 692.6820278167725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2013}, "4": {"k": 4, "answer": "1881", "latency_ms": 1114.2797470092773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2614}, "5": {"k": 5, "answer": "1881", "latency_ms": 1152.9209613800049, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3241}, "6": {"k": 6, "answer": "1881", "latency_ms": 922.3730564117432, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3891}}}
{"qid": "-5630827734073464379", "question": "why is the indian ocean the warmest in the world", "gold_answers": ["human induced greenhouse warming"], "shots": {"0": {"k": 0, "answer": "High salt content and tropical location.", "latency_ms": 1406.3305854797363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "human induced greenhouse warming", "latency_ms": 751.3906955718994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "human induced greenhouse warming", "latency_ms": 1221.022129058838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1337}, "3": {"k": 3, "answer": "Long-term ocean temperature records show a rapid, continuous warming", "latency_ms": 1975.68678855896, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 2014}, "4": {"k": 4, "answer": "human induced greenhouse warming", "latency_ms": 1493.5884475708008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2690}, "5": {"k": 5, "answer": "human induced greenhouse warming", "latency_ms": 1291.2862300872803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3340}, "6": {"k": 6, "answer": "human induced greenhouse warming", "latency_ms": 1092.0162200927734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4041}}}
{"qid": "-3544151584263258729", "question": "where was the film manchester by the sea filmed", "gold_answers": ["Middleton", "Essex", "Gloucester", "Beverly", "Swampscott", "Lynn", "Manchester", "Salem", "Tewksbury"], "shots": {"0": {"k": 0, "answer": "Gloucester, Massachusetts", "latency_ms": 1030.578851699829, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Massachusetts, Beverly, Essex, Gloucester, Swampscott, Lynn", "latency_ms": 2690.551996231079, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 635}, "2": {"k": 2, "answer": "Massachusetts, Beverly, Essex, Gloucester, Swampscott, Lynn", "latency_ms": 1823.9152431488037, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1296}, "3": {"k": 3, "answer": "Massachusetts, Beverly, Essex, Gloucester, Swampscott, Lynn", "latency_ms": 2675.663948059082, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1960}, "4": {"k": 4, "answer": "Manchester, Beverly, Essex, Gloucester, Swampscott, Lynn", "latency_ms": 2127.901792526245, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 2659}, "5": {"k": 5, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 3786.5285873413086, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 3325}, "6": {"k": 6, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem.", "latency_ms": 4075.098752975464, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 4032}}}
{"qid": "-5077733789764986167", "question": "consist of the sum of the fixed and variable costs for any given level of production", "gold_answers": ["total cost ( TC )"], "shots": {"0": {"k": 0, "answer": "Total Costs", "latency_ms": 555.830717086792, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1181.6222667694092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1126.206874847412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Semi-variable cost", "latency_ms": 1226.8750667572021, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "Semi-variable cost", "latency_ms": 735.4903221130371, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2623}, "5": {"k": 5, "answer": "Total cost", "latency_ms": 1070.63627243042, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3269}, "6": {"k": 6, "answer": "Total cost", "latency_ms": 934.9474906921387, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3885}}}
{"qid": "4892187805447493570", "question": "where was thomas and the magic railroad filmed", "gold_answers": ["Toronto , Ontario , Canada", "Isle of Man", "the Isle of Man"], "shots": {"0": {"k": 0, "answer": "Strasburg Rail Road", "latency_ms": 902.1351337432861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 948.3873844146729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1272.6695537567139, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1245.4769611358643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1238.8806343078613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2674}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1199.6219158172607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3296}, "6": {"k": 6, "answer": "Shepperton Studios", "latency_ms": 968.8992500305176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3939}}}
{"qid": "-7094533216301278566", "question": "who has access to the presidential daily briefing", "gold_answers": ["Secretaries of State", "the President", "Defense", "National Security Advisor"], "shots": {"0": {"k": 0, "answer": "The President and senior officials.", "latency_ms": 1389.3280029296875, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President", "latency_ms": 976.5262603759766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 665}, "2": {"k": 2, "answer": "The President", "latency_ms": 595.156192779541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1337}, "3": {"k": 3, "answer": "The President", "latency_ms": 1208.5673809051514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1970}, "4": {"k": 4, "answer": "The President", "latency_ms": 1189.4350051879883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2660}, "5": {"k": 5, "answer": "John Brennan, Donald Trump, Jared Kushner, Mike Flynn", "latency_ms": 2597.874641418457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3379}, "6": {"k": 6, "answer": "Jared Kushner, Mike Flynn, John F. Kennedy, Lyndon B. Johnson, Richard Nixon, Gerald Ford, Donald Trump", "latency_ms": 4562.4024868011475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4051}}}
{"qid": "-243139310037543674", "question": "what tool is available from microsoft as an alternative to the usmt for smaller migrations", "gold_answers": ["Windows Easy Transfer"], "shots": {"0": {"k": 0, "answer": "Easy Transfer", "latency_ms": 456.15410804748535, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Files", "latency_ms": 804.7423362731934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Windows Easy Transfer", "latency_ms": 1259.8118782043457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Windows Easy Transfer", "latency_ms": 719.7389602661133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1983}, "4": {"k": 4, "answer": "Windows Easy Transfer", "latency_ms": 884.9797248840332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2675}, "5": {"k": 5, "answer": "Windows Easy Transfer", "latency_ms": 747.9922771453857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3378}, "6": {"k": 6, "answer": "Windows Easy Transfer", "latency_ms": 1180.1056861877441, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4064}}}
{"qid": "7079282152145474767", "question": "who appoints the chief election commissioner of india", "gold_answers": ["the president", "President of India"], "shots": {"0": {"k": 0, "answer": "The President of India", "latency_ms": 877.1228790283203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1266.3943767547607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "The President", "latency_ms": 662.5823974609375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "The President", "latency_ms": 974.517822265625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1989}, "4": {"k": 4, "answer": "The President", "latency_ms": 438.33351135253906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2682}, "5": {"k": 5, "answer": "The President", "latency_ms": 879.3549537658691, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3375}, "6": {"k": 6, "answer": "The President", "latency_ms": 671.7433929443359, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4068}}}
{"qid": "6303430169473424975", "question": "glycogen and amylopectin are long chains of which simple sugar(s)", "gold_answers": ["glucose"], "shots": {"0": {"k": 0, "answer": "Glucose", "latency_ms": 523.1828689575195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "glucose", "latency_ms": 866.981029510498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "glucose", "latency_ms": 1176.569938659668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1357}, "3": {"k": 3, "answer": "glucose", "latency_ms": 647.9587554931641, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2007}, "4": {"k": 4, "answer": "glucose", "latency_ms": 898.5745906829834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2678}, "5": {"k": 5, "answer": "glucose", "latency_ms": 721.9858169555664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3292}, "6": {"k": 6, "answer": "Glucose", "latency_ms": 646.6288566589355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3938}}}
{"qid": "-3240666523350424161", "question": "who was the editor of the journal jugantor published in the time of swadeshi movement", "gold_answers": ["Bhupendranath Dutt"], "shots": {"0": {"k": 0, "answer": "Barindra Kumar Ghosh", "latency_ms": 1166.0537719726562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 828.624963760376, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "Barindra Kumar Ghosh", "latency_ms": 1351.52006149292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Barindra Kumar Ghosh", "latency_ms": 1363.739252090454, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Barindra Kumar Ghosh", "latency_ms": 623.5072612762451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2685}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 797.053337097168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "Barindra Kumar Ghosh", "latency_ms": 1472.4476337432861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3999}}}
{"qid": "1321443496772706078", "question": "when did indoor toilets become common in america", "gold_answers": ["After World War I"], "shots": {"0": {"k": 0, "answer": "Late 19th century", "latency_ms": 420.1703071594238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1030.6000709533691, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 770.4801559448242, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "1890s", "latency_ms": 1000.6606578826904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "1890s", "latency_ms": 1240.1528358459473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2602}, "5": {"k": 5, "answer": "1890s", "latency_ms": 1061.1870288848877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "1890s", "latency_ms": 979.1727066040039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3950}}}
{"qid": "6019244948248861067", "question": "who wrote were going on a bear hunt", "gold_answers": ["Michael Rosen"], "shots": {"0": {"k": 0, "answer": "Michael Rosen", "latency_ms": 468.28699111938477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Rosen", "latency_ms": 499.39680099487305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "Michael Rosen", "latency_ms": 710.8736038208008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Michael Rosen", "latency_ms": 400.52080154418945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Michael Rosen", "latency_ms": 857.0230007171631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2503}, "5": {"k": 5, "answer": "Michael Rosen", "latency_ms": 1112.9767894744873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3087}, "6": {"k": 6, "answer": "Michael Rosen", "latency_ms": 853.1875610351562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3690}}}
{"qid": "8753987902863757141", "question": "what is the revolution period of venus in earth years", "gold_answers": ["0.615 198 yr", "224.7 Earth days"], "shots": {"0": {"k": 0, "answer": "0.61519726", "latency_ms": 1060.1506233215332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0.616", "latency_ms": 982.2664260864258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "0.615 years", "latency_ms": 1229.842185974121, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1280}, "3": {"k": 3, "answer": "0.615 years", "latency_ms": 1086.897611618042, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1952}, "4": {"k": 4, "answer": "0.615 years", "latency_ms": 1231.1818599700928, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2611}, "5": {"k": 5, "answer": "0.615 years", "latency_ms": 1070.3511238098145, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3206}, "6": {"k": 6, "answer": "0.615", "latency_ms": 720.5932140350342, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3814}}}
{"qid": "-5904934687784134086", "question": "who has the power to approve or veto legislation constitution", "gold_answers": ["the President"], "shots": {"0": {"k": 0, "answer": "The President", "latency_ms": 737.0643615722656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Prince of Liechtenstein", "latency_ms": 1346.8296527862549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 702}, "2": {"k": 2, "answer": "The President", "latency_ms": 595.5808162689209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1407}, "3": {"k": 3, "answer": "The Governor", "latency_ms": 679.4998645782471, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2084}, "4": {"k": 4, "answer": "The Prince", "latency_ms": 1188.8127326965332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2848}, "5": {"k": 5, "answer": "The Prince", "latency_ms": 644.5126533508301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3520}, "6": {"k": 6, "answer": "The Governor", "latency_ms": 725.853443145752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4198}}}
{"qid": "-1910743846708408775", "question": "when was the taming ofthe shrew first performed", "gold_answers": ["prior to June 1592"], "shots": {"0": {"k": 0, "answer": "1594", "latency_ms": 944.2734718322754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1948", "latency_ms": 545.0179576873779, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "November 1633", "latency_ms": 995.0428009033203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1304}, "3": {"k": 3, "answer": "Between 1590 and 1592", "latency_ms": 1389.843463897705, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1936}, "4": {"k": 4, "answer": "Between 1590 and 1592", "latency_ms": 1718.2235717773438, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2605}, "5": {"k": 5, "answer": "Between 1590 and 1592", "latency_ms": 1773.6339569091797, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3237}, "6": {"k": 6, "answer": "Between 1590 and 1592", "latency_ms": 2237.2140884399414, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3914}}}
{"qid": "6521877788261380307", "question": "who is the first prime minister of france", "gold_answers": ["Michel Debr"], "shots": {"0": {"k": 0, "answer": "Adolphe Thiers", "latency_ms": 1075.1185417175293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1284.003496170044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1021.8966007232666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 977.8144359588623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1963}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1254.343032836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2589}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1141.5917873382568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1498.7597465515137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3843}}}
{"qid": "-3375621376413612480", "question": "list of strict nature reserve in the philippines", "gold_answers": ["Lake Malimanga", "Palawan", "Calavite and FB Harrison", "Olango Island", "Calauit Safari Park", "Lake Buluan"], "shots": {"0": {"k": 0, "answer": "Verde Island Passage, Mayon Volcano, El Nido Managed Resource Protected Area", "latency_ms": 3335.751533508301, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 800.7369041442871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1603.86323928833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 783.4737300872803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1995}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1078.9117813110352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2701}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 959.3055248260498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3328}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1357.4192523956299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3966}}}
{"qid": "-7848107192827858958", "question": "where do the events in the story take place geographically", "gold_answers": ["Persia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 884.9906921386719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1085.6940746307373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 563}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1265.181064605713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "Middle-earth", "latency_ms": 675.2138137817383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1805}, "4": {"k": 4, "answer": "Middle-earth", "latency_ms": 899.8358249664307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2439}, "5": {"k": 5, "answer": "Middle-earth", "latency_ms": 946.4950561523438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Middle-earth", "latency_ms": 525.0296592712402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3718}}}
{"qid": "-5123704261908217758", "question": "how and why were serial novels a phenomenon in the nineteenth century", "gold_answers": ["improved economics of distribution", "the rise of literacy", "technological advances in printing"], "shots": {"0": {"k": 0, "answer": "Cheap printing technology", "latency_ms": 516.9708728790283, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "serialization and audience reaction", "latency_ms": 966.4566516876221, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "audience reaction and circulation increase", "latency_ms": 1370.3854084014893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1393}, "3": {"k": 3, "answer": "audience reaction and circulation increase", "latency_ms": 1502.4116039276123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2078}, "4": {"k": 4, "answer": "responding to audience reaction", "latency_ms": 1522.7241516113281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2719}, "5": {"k": 5, "answer": "responding to audience reaction", "latency_ms": 1090.9473896026611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3330}, "6": {"k": 6, "answer": "responding to audience reaction", "latency_ms": 1361.6466522216797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3989}}}
{"qid": "8893432128322519771", "question": "who eliminated costa rica in world cup 2014", "gold_answers": ["Netherlands"], "shots": {"0": {"k": 0, "answer": "Netherlands", "latency_ms": 947.8216171264648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Graham Zusi", "latency_ms": 1464.1847610473633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "Graham Zusi", "latency_ms": 1245.582103729248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "Graham Zusi", "latency_ms": 1207.411766052246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1760}, "4": {"k": 4, "answer": "Graham Zusi", "latency_ms": 1173.8107204437256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2356}, "5": {"k": 5, "answer": "Greece", "latency_ms": 1159.0499877929688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2996}, "6": {"k": 6, "answer": "Greece", "latency_ms": 471.8489646911621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3585}}}
{"qid": "-1356405650810931451", "question": "how many countries touches the land boundary of india", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "6", "latency_ms": 909.6176624298096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2", "latency_ms": 632.2615146636963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "2", "latency_ms": 900.3803730010986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1391}, "3": {"k": 3, "answer": "2", "latency_ms": 854.7267913818359, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2017}, "4": {"k": 4, "answer": "6", "latency_ms": 909.1331958770752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2652}, "5": {"k": 5, "answer": "6", "latency_ms": 704.4656276702881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3317}, "6": {"k": 6, "answer": "6", "latency_ms": 627.9199123382568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3963}}}
{"qid": "6447777231012695504", "question": "who was the 11th prime minister of canada", "gold_answers": ["R.B. Bennett", "Arthur Meighen"], "shots": {"0": {"k": 0, "answer": "William Lyon Mackenzie King", "latency_ms": 928.0869960784912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1180.3321838378906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 727}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1197.8843212127686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "Marek Belka", "latency_ms": 1172.3747253417969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2076}, "4": {"k": 4, "answer": "Marek Belka", "latency_ms": 1035.1943969726562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2707}, "5": {"k": 5, "answer": "Marek Belka", "latency_ms": 1029.9007892608643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3333}, "6": {"k": 6, "answer": "Marek Belka", "latency_ms": 1178.8537502288818, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4022}}}
{"qid": "-5935683210985272192", "question": "when did the steel mills closed in youngstown ohio", "gold_answers": ["September 19 , 1977"], "shots": {"0": {"k": 0, "answer": "1977", "latency_ms": 706.3651084899902, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "late 1970s", "latency_ms": 1356.576919555664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "late 1970s", "latency_ms": 1077.9545307159424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "late 1970s", "latency_ms": 1335.6602191925049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "late 1970s", "latency_ms": 1368.2880401611328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2618}, "5": {"k": 5, "answer": "late 1970s", "latency_ms": 959.4926834106445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3282}, "6": {"k": 6, "answer": "late 1970s", "latency_ms": 937.1280670166016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3963}}}
{"qid": "1834961239491311230", "question": "who owns and operates the panama canal today", "gold_answers": ["Panama Canal Authority", "Panama", "Panamanian government"], "shots": {"0": {"k": 0, "answer": "The Panama Canal Authority", "latency_ms": 1126.7054080963135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kansas City Southern and Mi-Jack Products", "latency_ms": 1850.5632877349854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "Panama", "latency_ms": 1188.3327960968018, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1296}, "3": {"k": 3, "answer": "Panama", "latency_ms": 885.638952255249, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Panama", "latency_ms": 794.640064239502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2580}, "5": {"k": 5, "answer": "Panama Canal Authority", "latency_ms": 1033.9336395263672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3265}, "6": {"k": 6, "answer": "Panama Canal Authority", "latency_ms": 769.2306041717529, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3923}}}
{"qid": "-535648230475805474", "question": "where is a simple gear train used in real life", "gold_answers": ["Automobile drivetrains"], "shots": {"0": {"k": 0, "answer": "Bicycle", "latency_ms": 699.5949745178223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1014.0225887298584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 701.4598846435547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 976.0994911193848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1014.2574310302734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2447}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 964.98703956604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "automobile manual transmission", "latency_ms": 1244.229793548584, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3625}}}
{"qid": "8911390210346559626", "question": "who plays the dad in malcom in the middle", "gold_answers": ["Bryan Cranston"], "shots": {"0": {"k": 0, "answer": "Bryan Cranston", "latency_ms": 1050.4612922668457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1037.1272563934326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 993.8387870788574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1274.5945453643799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1174.2849349975586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2539}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1284.3396663665771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3182}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 967.2811031341553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3785}}}
{"qid": "-8336776482564898273", "question": "who has won the most world series in baseball", "gold_answers": ["the New York Yankees", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "New York Yankees", "latency_ms": 553.1139373779297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1166.980266571045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "New York Giants", "latency_ms": 982.9347133636475, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "New York Giants", "latency_ms": 1274.491310119629, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "New York Yankees", "latency_ms": 749.2771148681641, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "New York Yankees", "latency_ms": 1876.0478496551514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3094}, "6": {"k": 6, "answer": "New York Yankees", "latency_ms": 1279.9186706542969, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3731}}}
{"qid": "-8742089114148260796", "question": "where are the winter olympic games being played", "gold_answers": ["Beijing"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 386.8677616119385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake Placid", "latency_ms": 803.2655715942383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Lake Placid, Vancouver", "latency_ms": 1276.9908905029297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Lake Placid, Vancouver, Innsbruck", "latency_ms": 2021.3661193847656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Lake Placid, Vancouver, Innsbruck, Turin", "latency_ms": 2170.1793670654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2574}, "5": {"k": 5, "answer": "Lake Placid, Vancouver, Innsbruck, Turin, Nagano", "latency_ms": 1671.8792915344238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3211}, "6": {"k": 6, "answer": "Innsbruck, Austria; Turin, Italy; Lake Placid; Vancouver; Nagano.", "latency_ms": 3983.5147857666016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3921}}}
{"qid": "3864930130255054488", "question": "who made the song falling in love with you", "gold_answers": ["Hugo Peretti", "Elvis Presley", "George David Weiss", "Luigi Creatore"], "shots": {"0": {"k": 0, "answer": "UB40", "latency_ms": 519.3700790405273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Taio Cruz", "latency_ms": 1170.9082126617432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Taio Cruz", "latency_ms": 1216.16792678833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1217}, "3": {"k": 3, "answer": "Taio Cruz", "latency_ms": 901.219367980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "Taio Cruz", "latency_ms": 1161.823034286499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2411}, "5": {"k": 5, "answer": "Taio Cruz", "latency_ms": 488.3439540863037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3019}, "6": {"k": 6, "answer": "Taio Cruz", "latency_ms": 977.1945476531982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3639}}}
{"qid": "8076743617384207713", "question": "where did saudi crown prince go to college", "gold_answers": ["King Saud University"], "shots": {"0": {"k": 0, "answer": "King Saud University", "latency_ms": 732.2280406951904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 835.2646827697754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 711}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1162.844181060791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1310}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1200.021743774414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1228.2686233520508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1020.5800533294678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3152}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 932.2786331176758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3819}}}
{"qid": "1735766792677422630", "question": "who did the singing in into the woods", "gold_answers": ["the cast", "the cast members"], "shots": {"0": {"k": 0, "answer": "Anna Kendrick", "latency_ms": 928.9216995239258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tweedledum and Tweedledee", "latency_ms": 1626.9123554229736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Tweedledum and Tweedledee", "latency_ms": 1243.3891296386719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "Tweedledum and Tweedledee", "latency_ms": 1668.7698364257812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "Tweedledum and Tweedledee", "latency_ms": 1827.1770477294922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2428}, "5": {"k": 5, "answer": "Tweedledum and Tweedledee", "latency_ms": 2191.9569969177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3067}, "6": {"k": 6, "answer": "Tweedledum and Tweedledee", "latency_ms": 1450.1254558563232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3716}}}
{"qid": "5711801828691961426", "question": "who was the viceroy when the simon commission visited india", "gold_answers": ["Lord Irwin"], "shots": {"0": {"k": 0, "answer": "Lord Irwin", "latency_ms": 741.3408756256104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lord Irwin", "latency_ms": 1014.3792629241943, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "Lord Irwin", "latency_ms": 1000.5877017974854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1247}, "3": {"k": 3, "answer": "Lord Irwin", "latency_ms": 645.3189849853516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Lord Irwin", "latency_ms": 909.1477394104004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2536}, "5": {"k": 5, "answer": "Lord Irwin", "latency_ms": 1137.8405094146729, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3232}, "6": {"k": 6, "answer": "Lord Irwin", "latency_ms": 764.620304107666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3923}}}
{"qid": "9001143341771379731", "question": "who in germany signed the treaty of versailles", "gold_answers": ["colonial minister Johannes Bell", "Foreign minister Hermann Mller", "Gustav Bauer"], "shots": {"0": {"k": 0, "answer": "Ulrich Graf von Brockdorff-Rantzau", "latency_ms": 1867.663860321045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1185.7500076293945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 746.5083599090576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1220.132827758789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1257.7183246612549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2582}, "5": {"k": 5, "answer": "Germany", "latency_ms": 857.1231365203857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3269}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1248.626947402954, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3898}}}
{"qid": "-4619585332904698754", "question": "who holds the record for most platinum albums", "gold_answers": ["The Beatles", "AC / DC", "Elvis Presley"], "shots": {"0": {"k": 0, "answer": "The Beatles", "latency_ms": 698.4701156616211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elvis Presley", "latency_ms": 1010.7653141021729, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Elvis Presley", "latency_ms": 1287.6698970794678, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Elvis Presley", "latency_ms": 1002.3229122161865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1973}, "4": {"k": 4, "answer": "Elvis Presley", "latency_ms": 1004.7802925109863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2609}, "5": {"k": 5, "answer": "Elvis Presley", "latency_ms": 931.4792156219482, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3234}, "6": {"k": 6, "answer": "Elvis Presley", "latency_ms": 1644.2713737487793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3859}}}
{"qid": "-720512252272678238", "question": "when did the movie the post begin filming", "gold_answers": ["May 30 , 2017", "May 2017"], "shots": {"0": {"k": 0, "answer": "May 30, 2016", "latency_ms": 1100.2781391143799, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1013.4289264678955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 563}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1012.6943588256836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1267.3051357269287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 761.5931034088135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2501}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1465.691328048706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3114}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1044.3015098571777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3771}}}
{"qid": "-3371798557886238687", "question": "who starred in an officer and a gentleman", "gold_answers": ["Louis Gossett Jr .", "David Keith", "Louis Gossett Jr.", "Richard Gere", "Debra Winger", "Phillip J. Salmon"], "shots": {"0": {"k": 0, "answer": "Richard Gere", "latency_ms": 807.2836399078369, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 3022.5181579589844, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 2774.8169898986816, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 3069.326877593994, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 2864.6719455718994, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 2539}, "5": {"k": 5, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 3237.724781036377, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3149}, "6": {"k": 6, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 2593.616724014282, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3765}}}
