{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 805.1614761352539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1232.8622341156006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1463.9337062835693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1254.2483806610107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 889.3499374389648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2602}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 951.6875743865967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3243}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1245.175838470459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3875}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 1267.674207687378, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 1049.8855113983154, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 1116.4417266845703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 1325.516700744629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 1841.3739204406738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2533}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 1551.8090724945068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 1808.593511581421, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3853}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwest desert regions", "latency_ms": 864.4864559173584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 2305.4826259613037, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "arid lowland or mountainous shrubland", "latency_ms": 2359.5728874206543, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1310}, "3": {"k": 3, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 1857.7251434326172, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2042}, "4": {"k": 4, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 2174.6575832366943, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 1895.5469131469727, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3326}, "6": {"k": 6, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 1843.332052230835, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3971}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 1205.8546543121338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Karl Seitz", "latency_ms": 1428.6205768585205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Karl Seitz", "latency_ms": 1469.2072868347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1382}, "3": {"k": 3, "answer": "Karl Seitz", "latency_ms": 1260.509729385376, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2096}, "4": {"k": 4, "answer": "Karl Seitz", "latency_ms": 1271.1734771728516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2753}, "5": {"k": 5, "answer": "Karl Seitz", "latency_ms": 1021.1071968078613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3439}, "6": {"k": 6, "answer": "Karl Seitz", "latency_ms": 1520.4463005065918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4065}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1354.6607494354248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "10pm (Eastern)", "latency_ms": 1285.9032154083252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "10pm (Eastern)", "latency_ms": 1288.4747982025146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "10pm (Eastern)", "latency_ms": 1526.4756679534912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "10pm (Eastern)", "latency_ms": 1116.1539554595947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "10pm (Eastern)", "latency_ms": 1815.4118061065674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "10pm (Eastern)", "latency_ms": 1355.574131011963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3889}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "2001", "latency_ms": 252.9776096343994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1542.1791076660156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 699}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1288.8774871826172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1331}, "3": {"k": 3, "answer": "Not in the context.", "latency_ms": 1115.4465675354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "2001", "latency_ms": 950.8388042449951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2593}, "5": {"k": 5, "answer": "2001", "latency_ms": 922.5358963012695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3212}, "6": {"k": 6, "answer": "2001", "latency_ms": 992.3615455627441, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3891}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1060.2736473083496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 1410.7825756072998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1258.0442428588867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1378}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1241.2855625152588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2043}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 837.0089530944824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2682}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 770.9391117095947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3345}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1394.6962356567383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3948}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3", "latency_ms": 729.3779850006104, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1194.2882537841797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Hell-O", "latency_ms": 648.9214897155762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "Hell-O", "latency_ms": 651.6368389129639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2007}, "4": {"k": 4, "answer": "May 19, 2009", "latency_ms": 1409.118890762329, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2624}, "5": {"k": 5, "answer": "In \"Hell-O\"", "latency_ms": 1258.2881450653076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3187}, "6": {"k": 6, "answer": "In \"Hell-O\"", "latency_ms": 1234.065294265747, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3794}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 971.2522029876709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1475.2211570739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1147.43971824646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 805.8550357818604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 903.9020538330078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1077.387809753418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1451.188325881958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3926}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 540.898323059082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Havana harbor", "latency_ms": 1156.5001010894775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "Havana harbor", "latency_ms": 679.2361736297607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Havana harbor", "latency_ms": 1200.1066207885742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Havana harbor", "latency_ms": 1100.5561351776123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2640}, "5": {"k": 5, "answer": "Havana Harbor, Cuba", "latency_ms": 805.2113056182861, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3214}, "6": {"k": 6, "answer": "Havana Harbor, Cuba", "latency_ms": 1209.4624042510986, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3838}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 792.996883392334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1439.7621154785156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 790.5590534210205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "No specific god mentioned", "latency_ms": 1361.4041805267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1236.5026473999023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2502}, "5": {"k": 5, "answer": "Lord Vasupujya", "latency_ms": 815.809965133667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Lord Vasupujya", "latency_ms": 1438.9948844909668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3869}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 1463.1125926971436, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Honduras and Nicaragua", "latency_ms": 1274.2433547973633, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 696}, "2": {"k": 2, "answer": "Honduras", "latency_ms": 1173.783302307129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Honduras, Nicaragua", "latency_ms": 1041.2678718566895, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1912}, "4": {"k": 4, "answer": "Honduras, Nicaragua, Costa Rica", "latency_ms": 1513.805866241455, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2478}, "5": {"k": 5, "answer": "Honduras, Nicaragua, Costa Rica, Panama", "latency_ms": 1797.2712516784668, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3110}, "6": {"k": 6, "answer": "Honduras, Nicaragua, Costa Rica, Panama", "latency_ms": 2009.418249130249, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3764}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence", "latency_ms": 854.0229797363281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 661.8869304656982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "Complex sentence", "latency_ms": 1096.7493057250977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Complex sentence", "latency_ms": 462.39709854125977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2008}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 958.6465358734131, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2672}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 623.2287883758545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3356}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 693.6750411987305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4062}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and trade.", "latency_ms": 875.8647441864014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 1929.100513458252, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Nations' wealth", "latency_ms": 1239.2470836639404, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1337}, "3": {"k": 3, "answer": "the nature and causes of the wealth of nations", "latency_ms": 2189.108371734619, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1989}, "4": {"k": 4, "answer": "The Wealth of Nations", "latency_ms": 613.1010055541992, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2670}, "5": {"k": 5, "answer": "The Wealth of Nations", "latency_ms": 1232.010841369629, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3356}, "6": {"k": 6, "answer": "The Wealth of Nations", "latency_ms": 1192.8346157073975, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3972}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 1936.8896484375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1265.1686668395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1038.6159420013428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1062.6246929168701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1339.1039371490479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 1971.3807106018066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3131}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 1638.4317874908447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3757}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere", "latency_ms": 1357.91015625, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Western Australia", "latency_ms": 902.4710655212402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "Western Australia, Tasmania", "latency_ms": 980.571985244751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "South-west corner of Western Australia", "latency_ms": 1307.7607154846191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1998}, "4": {"k": 4, "answer": "South-west corner of Western Australia", "latency_ms": 1833.251714706421, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2721}, "5": {"k": 5, "answer": "South-west corner", "latency_ms": 978.3995151519775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3450}, "6": {"k": 6, "answer": "South-west corner of Western Australia", "latency_ms": 1196.777105331421, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4184}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Leia Organa", "latency_ms": 810.9867572784424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1217.1878814697266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 534}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 952.5492191314697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1121}, "3": {"k": 3, "answer": "Mara", "latency_ms": 416.46718978881836, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1751}, "4": {"k": 4, "answer": "Mara", "latency_ms": 1073.7810134887695, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2322}, "5": {"k": 5, "answer": "Mara", "latency_ms": 836.205005645752, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2967}, "6": {"k": 6, "answer": "Mara", "latency_ms": 699.2616653442383, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3558}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 938.3375644683838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Barry Cryer", "latency_ms": 1271.9707489013672, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 548}, "2": {"k": 2, "answer": "Barry Cryer", "latency_ms": 1258.6467266082764, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1098}, "3": {"k": 3, "answer": "Barry Cryer", "latency_ms": 1509.631633758545, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1711}, "4": {"k": 4, "answer": "Barry Cryer", "latency_ms": 1440.708875656128, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2327}, "5": {"k": 5, "answer": "Barry Cryer", "latency_ms": 770.6210613250732, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2920}, "6": {"k": 6, "answer": "Barry Cryer", "latency_ms": 1488.5411262512207, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3568}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 712.6893997192383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mitochondrial", "latency_ms": 1022.7243900299072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 728}, "2": {"k": 2, "answer": "Chloroplast", "latency_ms": 1182.0242404937744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1438}, "3": {"k": 3, "answer": "Chloroplast", "latency_ms": 977.3342609405518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2097}, "4": {"k": 4, "answer": "Chloroplast", "latency_ms": 926.5222549438477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2776}, "5": {"k": 5, "answer": "Chloroplast and mitochondria", "latency_ms": 1549.5116710662842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3452}, "6": {"k": 6, "answer": "Chloroplast, Mitochondria", "latency_ms": 1414.1132831573486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4245}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Backup.", "latency_ms": 2179.6603202819824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 626.1484622955322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1127.0523071289062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1455.765724182129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2066}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 960.3233337402344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2775}, "5": {"k": 5, "answer": "FLAIM, CANINE, Scrub-PA, Digital Evidence Investigator, Triage-G2", "latency_ms": 4445.754289627075, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3489}, "6": {"k": 6, "answer": "FLAIM, CANINE, Scrub-PA, Digital Evidence Investigator, Triage-G2", "latency_ms": 3041.656017303467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4232}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 1357.4509620666504, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1520.784616470337, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1353.3744812011719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 943.9547061920166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1195.302963256836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1214.6775722503662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3067}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1557.560920715332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3666}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 762.7272605895996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Five to seven years", "latency_ms": 1255.4309368133545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "Five to seven years", "latency_ms": 1331.164836883545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "Five to seven years", "latency_ms": 1235.3026866912842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1703}, "4": {"k": 4, "answer": "Two years old", "latency_ms": 918.84446144104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2352}, "5": {"k": 5, "answer": "Two years old", "latency_ms": 881.9971084594727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3015}, "6": {"k": 6, "answer": "five to seven years", "latency_ms": 1164.4530296325684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3700}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 400.1636505126953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 869.2107200622559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "3", "latency_ms": 582.7910900115967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "3", "latency_ms": 962.3565673828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "3", "latency_ms": 693.2015419006348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": "3", "latency_ms": 407.96852111816406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "3", "latency_ms": 877.7251243591309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3891}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 2823.897361755371, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1309.9958896636963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1088.266134262085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1331}, "3": {"k": 3, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 3153.352737426758, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 4818.933725357056, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 2604}, "5": {"k": 5, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 3571.546792984009, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "Elijah Wood", "latency_ms": 1277.4183750152588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3863}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party", "latency_ms": 585.5083465576172, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume", "latency_ms": 905.4751396179199, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "Costume", "latency_ms": 915.2264595031738, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Costume", "latency_ms": 450.70886611938477, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1952}, "4": {"k": 4, "answer": "party fashion", "latency_ms": 1106.66823387146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Costume party", "latency_ms": 982.5172424316406, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3152}, "6": {"k": 6, "answer": "party fashion", "latency_ms": 877.3119449615479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3774}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 867.6767349243164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One", "latency_ms": 587.5051021575928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 598}, "2": {"k": 2, "answer": "One", "latency_ms": 425.92477798461914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1204}, "3": {"k": 3, "answer": "One", "latency_ms": 852.7867794036865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "One", "latency_ms": 934.7856044769287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2534}, "5": {"k": 5, "answer": "One", "latency_ms": 871.7079162597656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3184}, "6": {"k": 6, "answer": "One", "latency_ms": 888.261079788208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3840}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "He promised Fantine", "latency_ms": 858.3762645721436, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1459.0272903442383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "Fantine's authorization", "latency_ms": 1279.2413234710693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "Fantine's daughter", "latency_ms": 798.0258464813232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1781}, "4": {"k": 4, "answer": "Fantine's daughter", "latency_ms": 1075.6878852844238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2420}, "5": {"k": 5, "answer": "Fantine's daughter", "latency_ms": 1030.6849479675293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3077}, "6": {"k": 6, "answer": "Fantine's daughter", "latency_ms": 1324.6128559112549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3730}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, and South Korea.", "latency_ms": 1302.3459911346436, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Congo River basin Bantu-speaking tribes", "latency_ms": 1171.382188796997, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "Kenya", "latency_ms": 957.817792892456, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Kenya", "latency_ms": 1173.3837127685547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2000}, "4": {"k": 4, "answer": "Kenya", "latency_ms": 743.4077262878418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2685}, "5": {"k": 5, "answer": "Kenya", "latency_ms": 1012.6097202301025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3425}, "6": {"k": 6, "answer": "Kenya", "latency_ms": 683.4466457366943, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4082}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and control.", "latency_ms": 852.0314693450928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to consolidate Bantu education", "latency_ms": 1126.573085784912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "to consolidate Bantu education", "latency_ms": 1547.879695892334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1413}, "3": {"k": 3, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 3336.475133895874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 2539.5119190216064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2764}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 2982.1770191192627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3440}, "6": {"k": 6, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 3857.969045639038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4117}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 921.9651222229004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 1128.7975311279297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 1973.1488227844238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Python", "latency_ms": 669.7590351104736, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1780}, "4": {"k": 4, "answer": "Python", "latency_ms": 1134.6628665924072, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2403}, "5": {"k": 5, "answer": "Python", "latency_ms": 637.3014450073242, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3028}, "6": {"k": 6, "answer": "Python", "latency_ms": 894.4039344787598, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3724}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 1259.2058181762695, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1342.8537845611572, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 572}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1048.2347011566162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1152}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1709.36918258667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1799}, "4": {"k": 4, "answer": "Ice", "latency_ms": 929.9056529998779, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2448}, "5": {"k": 5, "answer": "Ice", "latency_ms": 1462.2459411621094, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3108}, "6": {"k": 6, "answer": "Ice", "latency_ms": 843.20068359375, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3733}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22", "latency_ms": 1525.850534439087, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Not in season 2.", "latency_ms": 1115.2732372283936, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Not on page 200.", "latency_ms": 1421.266794204712, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "The Departed episode", "latency_ms": 1677.1240234375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1921}, "4": {"k": 4, "answer": "At the end of the third season", "latency_ms": 1462.4063968658447, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2605}, "5": {"k": 5, "answer": "At the hospital", "latency_ms": 931.5898418426514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "The Departed episode", "latency_ms": 976.4015674591064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3918}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "Home team", "latency_ms": 971.6355800628662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ITV", "latency_ms": 420.0718402862549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "ITV", "latency_ms": 472.02444076538086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1182}, "3": {"k": 3, "answer": "ITV", "latency_ms": 894.4368362426758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1748}, "4": {"k": 4, "answer": "ITV", "latency_ms": 584.1786861419678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2331}, "5": {"k": 5, "answer": "ITV", "latency_ms": 895.2736854553223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2905}, "6": {"k": 6, "answer": "ITV", "latency_ms": 699.7871398925781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3542}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw neighborhood", "latency_ms": 740.5214309692383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1069.941520690918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Washington", "latency_ms": 392.06719398498535, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "Washington", "latency_ms": 594.8081016540527, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Washington", "latency_ms": 656.88157081604, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Washington", "latency_ms": 641.54052734375, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "Washington", "latency_ms": 378.94749641418457, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3900}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 476.9105911254883, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 492.19799041748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 981.4529418945312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Mosaic covenant", "latency_ms": 940.4075145721436, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1929}, "4": {"k": 4, "answer": "Mosaic covenant", "latency_ms": 737.5681400299072, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2539}, "5": {"k": 5, "answer": "Mosaic covenant", "latency_ms": 978.9876937866211, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Mosaic covenant", "latency_ms": 1042.1812534332275, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3869}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 1055.9279918670654, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1341.9592380523682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1471.583366394043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1306.999921798706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 954.1168212890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1243.2680130004883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 862.7855777740479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3827}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1041.877269744873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1178.969144821167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1266.6904926300049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1300.0211715698242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1069.5083141326904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1304.915428161621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3128}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1248.9702701568604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3750}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 517.7145004272461, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 672.8363037109375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 1459.1500759124756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 1341.9854640960693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1909}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 446.98548316955566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2587}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 1196.6967582702637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3210}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 1066.9293403625488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3832}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "Second", "latency_ms": 411.3786220550537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1280.5125713348389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1252.2974014282227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1317}, "3": {"k": 3, "answer": "Third", "latency_ms": 653.2878875732422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "Not mentioned.", "latency_ms": 738.2650375366211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1072.7438926696777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3204}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 987.5662326812744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3800}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 608.6900234222412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Subhas Chandra Bose", "latency_ms": 1529.1101932525635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Surendranath Banerjee", "latency_ms": 1426.954984664917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1323}, "3": {"k": 3, "answer": "Surendranath Banerjee", "latency_ms": 1838.0999565124512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1980}, "4": {"k": 4, "answer": "Surendranath Banerjee", "latency_ms": 1733.184576034546, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "Subhas Chandra Bose", "latency_ms": 860.6185913085938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3342}, "6": {"k": 6, "answer": "Surendranath Banerjee", "latency_ms": 1437.842607498169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4070}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenifer Lewis", "latency_ms": 810.6164932250977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1022.0499038696289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1509.333610534668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1191.927433013916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1942}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 829.3163776397705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1262.237787246704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3166}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1015.7420635223389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3777}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 450.76560974121094, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 800.281286239624, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": ".java", "latency_ms": 631.7141056060791, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": ".java", "latency_ms": 602.6668548583984, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2009}, "4": {"k": 4, "answer": ".java", "latency_ms": 625.2346038818359, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2656}, "5": {"k": 5, "answer": ".java", "latency_ms": 786.0794067382812, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3294}, "6": {"k": 6, "answer": ".java", "latency_ms": 952.103853225708, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3891}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 452.93354988098145, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alan Turing", "latency_ms": 939.2204284667969, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Alan Turing", "latency_ms": 1145.5328464508057, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Alan Turing", "latency_ms": 872.4043369293213, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1935}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 1057.0096969604492, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2563}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 981.9114208221436, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3219}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 422.7719306945801, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3849}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline", "latency_ms": 799.2901802062988, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "assistant majority or minority leader", "latency_ms": 1528.6643505096436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "assistant majority or minority leader", "latency_ms": 1315.2287006378174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "assistant majority or minority leader", "latency_ms": 1168.705940246582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "assistant majority or minority leader", "latency_ms": 1719.5930480957031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "assistant majority or minority leader", "latency_ms": 1390.8531665802002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3277}, "6": {"k": 6, "answer": "assistant majority or minority leader", "latency_ms": 1725.7215976715088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 969.9091911315918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1545.2792644500732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1267.7137851715088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1272.2322940826416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2069.056510925293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2513}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1262.9525661468506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3137}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1268.7242031097412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the right but not the obligation to buy foreign currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 474.8711585998535, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 921.1413860321045, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 984.0261936187744, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 649.3959426879883, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "FX option", "latency_ms": 921.4909076690674, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2694}, "5": {"k": 5, "answer": "FX option", "latency_ms": 1213.4099006652832, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3386}, "6": {"k": 6, "answer": "FX option", "latency_ms": 964.0815258026123, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4003}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 511.1417770385742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "One", "latency_ms": 1052.8168678283691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 698}, "2": {"k": 2, "answer": "360 members", "latency_ms": 1146.8420028686523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1421}, "3": {"k": 3, "answer": "360 members", "latency_ms": 717.111349105835, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2114}, "4": {"k": 4, "answer": "360 members", "latency_ms": 958.9102268218994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2776}, "5": {"k": 5, "answer": "360 members", "latency_ms": 938.4286403656006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3435}, "6": {"k": 6, "answer": "360 members", "latency_ms": 1024.214744567871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4134}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 766.6921615600586, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 984.8654270172119, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 1312.8552436828613, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 1191.9188499450684, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1939}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 1228.163480758667, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 1274.4040489196777, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 758.5914134979248, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3909}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gorm"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 1492.8371906280518, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack Mac Ferland", "latency_ms": 1698.4021663665771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Eydie Gorm", "latency_ms": 1133.2452297210693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Eydie Gorm", "latency_ms": 1511.6922855377197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1787}, "4": {"k": 4, "answer": "Eydie Gorm", "latency_ms": 1550.649881362915, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2388}, "5": {"k": 5, "answer": "Eydie Gorm", "latency_ms": 1123.173713684082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2965}, "6": {"k": 6, "answer": "Eydie Gorm", "latency_ms": 1392.8539752960205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3566}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 548.1274127960205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1181.0173988342285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "Mohan Shantanagoudar", "latency_ms": 1627.103328704834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Mohan Shantanagoudar", "latency_ms": 1656.722068786621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "Mohan Shantanagoudar", "latency_ms": 1307.2383403778076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "Mohan Shantanagoudar", "latency_ms": 1651.3385772705078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3042}, "6": {"k": 6, "answer": "Mohan Shantanagoudar", "latency_ms": 1689.5766258239746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3653}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 988.2934093475342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1222.65625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 973.0141162872314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1252.0902156829834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1773}, "4": {"k": 4, "answer": "Ashley Cooper", "latency_ms": 1323.0552673339844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2388}, "5": {"k": 5, "answer": "Ken Rosewall", "latency_ms": 1010.6844902038574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2967}, "6": {"k": 6, "answer": "Ken Rosewall", "latency_ms": 1196.3520050048828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3554}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 710.4120254516602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1484.6129417419434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 581}, "2": {"k": 2, "answer": "1", "latency_ms": 615.74387550354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "1", "latency_ms": 861.3357543945312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "1", "latency_ms": 659.4436168670654, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2469}, "5": {"k": 5, "answer": "1", "latency_ms": 816.5712356567383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3062}, "6": {"k": 6, "answer": "1", "latency_ms": 607.2614192962646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3644}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 583.7626457214355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2000", "latency_ms": 964.4317626953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "2000", "latency_ms": 1233.3662509918213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "2002 NBA Finals", "latency_ms": 1309.5030784606934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2014}, "4": {"k": 4, "answer": "2002", "latency_ms": 755.5716037750244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2636}, "5": {"k": 5, "answer": "2002", "latency_ms": 1174.4251251220703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3319}, "6": {"k": 6, "answer": "2002", "latency_ms": 851.1312007904053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4003}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 443.77970695495605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 990.1978969573975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1063.8153553009033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Not stated", "latency_ms": 867.4204349517822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "1", "latency_ms": 940.2952194213867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "1", "latency_ms": 681.2407970428467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3165}, "6": {"k": 6, "answer": "17", "latency_ms": 956.1111927032471, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3830}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 1211.815357208252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 902.9803276062012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 1662.907361984253, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 1068.984031677246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 1472.0852375030518, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2566}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 1269.2532539367676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3217}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 1628.4520626068115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3848}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 1776.3381004333496, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 1025.2690315246582, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 571}, "2": {"k": 2, "answer": "Corey, Cory", "latency_ms": 1475.1667976379395, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1134}, "3": {"k": 3, "answer": "Corey, Cory", "latency_ms": 994.6248531341553, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1819}, "4": {"k": 4, "answer": "Corey, Cory", "latency_ms": 827.307939529419, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2507}, "5": {"k": 5, "answer": "Corey, Cory", "latency_ms": 973.9797115325928, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3130}, "6": {"k": 6, "answer": "Corey, Cory", "latency_ms": 960.9041213989258, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3715}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 548.7594604492188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1075.1500129699707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "Elvis Presley", "latency_ms": 1291.6603088378906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "Elvis Presley", "latency_ms": 1004.7152042388916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 994.9657917022705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2451}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1449.4714736938477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3085}, "6": {"k": 6, "answer": "Elvis Presley", "latency_ms": 981.5666675567627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 657.6025485992432, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "60", "latency_ms": 640.1889324188232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "60th", "latency_ms": 481.40859603881836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1292.7095890045166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1474.015235900879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1436.0980987548828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1406.005620956421, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3816}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 864.5610809326172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1500.6418228149414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 561}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1447.0300674438477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1115.0095462799072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1785}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1038.1083488464355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2381}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 938.5571479797363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2981}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1444.7393417358398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3562}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 775.4907608032227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wilt Chamberlain and Adrian Dantley", "latency_ms": 1816.6468143463135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Wilt Chamberlain", "latency_ms": 1190.2258396148682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "Wilt Chamberlain", "latency_ms": 1130.5186748504639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "Wilt Chamberlain", "latency_ms": 1236.349105834961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2545}, "5": {"k": 5, "answer": "Wilt Chamberlain", "latency_ms": 1263.8309001922607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "Wilt Chamberlain", "latency_ms": 1661.05055809021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3742}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 293.58649253845215, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1215.1329517364502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1034.1033935546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "Fourth finger", "latency_ms": 696.2411403656006, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1920}, "4": {"k": 4, "answer": "4th finger", "latency_ms": 1161.4198684692383, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2455}, "5": {"k": 5, "answer": "4th finger", "latency_ms": 1227.3666858673096, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3057}, "6": {"k": 6, "answer": "4th finger", "latency_ms": 1144.747018814087, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3711}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 910.5064868927002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1508.6541175842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1005.7311058044434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1069.2930221557617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1956}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 749.9551773071289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2653}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1034.2621803283691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1259.749174118042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3918}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 849.5156764984131, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bernard Mayes", "latency_ms": 1066.54691696167, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Bernard Mayes", "latency_ms": 1255.7590007781982, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "Bernard Mayes", "latency_ms": 1308.9966773986816, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Bernard Mayes", "latency_ms": 1239.8791313171387, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2557}, "5": {"k": 5, "answer": "Bernard Mayes", "latency_ms": 1587.3465538024902, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3191}, "6": {"k": 6, "answer": "Bernard Mayes", "latency_ms": 1084.010124206543, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3789}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2019", "latency_ms": 1432.652235031128, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1018.3122158050537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 1523.4708786010742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 1814.1717910766602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 1733.2932949066162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2404}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 1843.5194492340088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3055}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 1713.8237953186035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3689}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 922.4960803985596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1471.7977046966553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 539}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1754.2636394500732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1045.8812713623047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1847}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 788.3796691894531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2489}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1214.5624160766602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3141}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1395.3447341918945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3751}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 984.9414825439453, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1251.7890930175781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1210.4768753051758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 824.9778747558594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Claire Holt", "latency_ms": 947.7312564849854, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Claire Holt", "latency_ms": 1188.2290840148926, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3108}, "6": {"k": 6, "answer": "Claire Holt", "latency_ms": 1236.46879196167, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3747}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living things", "latency_ms": 805.2670955657959, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in wood or soil", "latency_ms": 1525.7761478424072, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 705}, "2": {"k": 2, "answer": "in wood or soil", "latency_ms": 1031.5029621124268, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1425}, "3": {"k": 3, "answer": "in wood or soil", "latency_ms": 988.8632297515869, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2048}, "4": {"k": 4, "answer": "in wood or soil", "latency_ms": 1217.2889709472656, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2759}, "5": {"k": 5, "answer": "in wood or soil", "latency_ms": 1283.2813262939453, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3428}, "6": {"k": 6, "answer": "in wood or soil", "latency_ms": 1016.1154270172119, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 4095}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 853.6536693572998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shruti", "latency_ms": 1231.9045066833496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Chandan Shetty", "latency_ms": 1086.059331893921, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Shruthi", "latency_ms": 942.5036907196045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1824}, "4": {"k": 4, "answer": "Shruthi", "latency_ms": 1476.980209350586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2427}, "5": {"k": 5, "answer": "Shruthi", "latency_ms": 1061.6888999938965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3070}, "6": {"k": 6, "answer": "Season 1: Not specified, Season 2: Akul Balaji, Season 3: Shruthi, Season 4: Not specified, Season 5: Chandan Shetty", "latency_ms": 5605.5450439453125, "em": 0.0, "f1": 0.19047619047619052, "containment": 1.0, "context_chars": 3713}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 1112.1015548706055, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1320.7557201385498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1249.1405010223389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1458.8665962219238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1274.9345302581787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1211.7712497711182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3124}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1305.4840564727783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3728}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 822.5610256195068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1036.841869354248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1244.5790767669678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 992.2361373901367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1009.7496509552002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 749.3908405303955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3028}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 901.5626907348633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3621}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Lake Winnipeg", "latency_ms": 961.4648818969727, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 1266.2906646728516, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1303.73215675354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 711.8325233459473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1254.9784183502197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2557}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1488.1274700164795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 549.7562885284424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 769.0842151641846, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 891.2286758422852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome", "latency_ms": 688.751220703125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Rome", "latency_ms": 738.3677959442139, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1954}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 1292.4156188964844, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2583}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 1258.530616760254, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3146}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 893.3231830596924, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3862}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "Measurement mark", "latency_ms": 802.2089004516602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1133.3701610565186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1017.3032283782959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1280}, "3": {"k": 3, "answer": "the manufacturing company or site", "latency_ms": 1364.513874053955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1927}, "4": {"k": 4, "answer": "the manufacturing company or site", "latency_ms": 1074.2461681365967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2500}, "5": {"k": 5, "answer": "the manufacturing company or site", "latency_ms": 1101.562738418579, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "the manufacturing company or site", "latency_ms": 1564.9440288543701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3770}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia", "latency_ms": 1056.574821472168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "solute molecules", "latency_ms": 982.8488826751709, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Hydrogen sulfide", "latency_ms": 1735.5740070343018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1356}, "3": {"k": 3, "answer": "Hydrogen sulfide, hydrogen fluoride, ammonia, methanol", "latency_ms": 3113.708734512329, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2025}, "4": {"k": 4, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 2214.355707168579, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 1805.5450916290283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol, hydrogen sulfide", "latency_ms": 2634.4292163848877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3829}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Boy Meets Girl", "latency_ms": 1082.3769569396973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 1135.1006031036377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "1988", "latency_ms": 924.1025447845459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "1988", "latency_ms": 1167.0148372650146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1824}, "4": {"k": 4, "answer": "1988", "latency_ms": 950.6244659423828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2427}, "5": {"k": 5, "answer": "1988", "latency_ms": 461.1706733703613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3038}, "6": {"k": 6, "answer": "1988", "latency_ms": 661.2694263458252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3645}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 902.5478363037109, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 994.3792819976807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Truco", "latency_ms": 636.4579200744629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Manille", "latency_ms": 1106.9846153259277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1857}, "4": {"k": 4, "answer": "Manille", "latency_ms": 618.8094615936279, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "Manille", "latency_ms": 895.3061103820801, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3061}, "6": {"k": 6, "answer": "Manille", "latency_ms": 892.6761150360107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3685}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 627.4993419647217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Five percent", "latency_ms": 911.9091033935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "5%", "latency_ms": 1083.39524269104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1317}, "3": {"k": 3, "answer": "Five percent", "latency_ms": 635.7834339141846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2022}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 1559.3860149383545, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2632}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 1177.0060062408447, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3257}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 1552.4682998657227, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3904}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 684.8354339599609, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1228.9249897003174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "1975", "latency_ms": 827.4173736572266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1200}, "3": {"k": 3, "answer": "1975", "latency_ms": 1118.0474758148193, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1854}, "4": {"k": 4, "answer": "1975", "latency_ms": 883.2435607910156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2458}, "5": {"k": 5, "answer": "1971", "latency_ms": 511.2440586090088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3128}, "6": {"k": 6, "answer": "1975", "latency_ms": 1160.0956916809082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3740}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 826.3726234436035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1407.7866077423096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 720.4432487487793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 734.9452972412109, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1844}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1271.578311920166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2518}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 600.395917892456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3151}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 998.8665580749512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert", "latency_ms": 697.9820728302002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "William Stone", "latency_ms": 971.6534614562988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "William Stone", "latency_ms": 892.0230865478516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "William Stone", "latency_ms": 458.3003520965576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1956}, "4": {"k": 4, "answer": "William Stone", "latency_ms": 1163.7811660766602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "Leonard Calvert", "latency_ms": 1469.6261882781982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3324}, "6": {"k": 6, "answer": "Leonard Calvert", "latency_ms": 1260.8692646026611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4035}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 534.2895984649658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1208.888053894043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1015.6033039093018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1284.3132019042969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Tiger Woods", "latency_ms": 675.2796173095703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "Tiger Woods", "latency_ms": 1216.6290283203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3172}, "6": {"k": 6, "answer": "Tiger Woods", "latency_ms": 810.2562427520752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3842}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 1267.7125930786133, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "high amounts", "latency_ms": 636.7518901824951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 688}, "2": {"k": 2, "answer": "high amounts", "latency_ms": 673.7039089202881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "high amounts", "latency_ms": 1112.0848655700684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "high amounts", "latency_ms": 472.5642204284668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2642}, "5": {"k": 5, "answer": "high amounts", "latency_ms": 937.065601348877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "high amounts", "latency_ms": 741.7697906494141, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3888}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 921.3001728057861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sunderland", "latency_ms": 739.8521900177002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 558}, "2": {"k": 2, "answer": "West Ham", "latency_ms": 869.5402145385742, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1138}, "3": {"k": 3, "answer": "West Ham", "latency_ms": 597.2120761871338, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1730}, "4": {"k": 4, "answer": "West Ham", "latency_ms": 1075.5231380462646, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2340}, "5": {"k": 5, "answer": "West Ham", "latency_ms": 637.5813484191895, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2982}, "6": {"k": 6, "answer": "Sunderland", "latency_ms": 1229.7749519348145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3574}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 930.2582740783691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 772.7541923522949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1167.0665740966797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1343}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1225.8944511413574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2066}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1002.4087429046631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2742}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1249.3181228637695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3426}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 705.1503658294678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4160}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh", "latency_ms": 718.0964946746826, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh", "latency_ms": 932.8441619873047, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "Edinburgh", "latency_ms": 663.341760635376, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1356}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 1066.8511390686035, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 1276.0233879089355, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 1224.1497039794922, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3359}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 1030.5252075195312, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3999}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 790.4303073883057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1015.9890651702881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 996.5012073516846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 536.7910861968994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2030}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1048.682689666748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2707}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 995.9115982055664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3338}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 968.8553810119629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3952}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 857.7814102172852, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haven", "latency_ms": 651.0665416717529, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Southport, North Carolina.", "latency_ms": 1379.8301219940186, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Southport, North Carolina.", "latency_ms": 1677.257776260376, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1902}, "4": {"k": 4, "answer": "Southport, North Carolina.", "latency_ms": 1572.9711055755615, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "Southport, North Carolina.", "latency_ms": 1095.3631401062012, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "Southport, North Carolina.", "latency_ms": 1098.182201385498, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 994.7209358215332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1405.3568840026855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 705}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 784.7459316253662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1065.0532245635986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1990}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 747.870683670044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2599}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1213.660478591919, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1662.625789642334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3932}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 715.3441905975342, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hoover", "latency_ms": 437.9842281341553, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 703}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 976.4454364776611, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1440}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 936.4337921142578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2145}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 734.5740795135498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2887}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 1199.6304988861084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3615}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 1239.4440174102783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4337}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 372.42937088012695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 897.2082138061523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "Max", "latency_ms": 610.7368469238281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1244}, "3": {"k": 3, "answer": "Max", "latency_ms": 873.8434314727783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Max", "latency_ms": 914.926290512085, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2519}, "5": {"k": 5, "answer": "Max", "latency_ms": 630.3284168243408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "Max", "latency_ms": 825.5374431610107, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3742}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 610.8767986297607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Megan Follows", "latency_ms": 1035.4032516479492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1228.9519309997559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1440.8018589019775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1914}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1490.7467365264893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2514}, "5": {"k": 5, "answer": "Megan Follows", "latency_ms": 1089.949607849121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3160}, "6": {"k": 6, "answer": "Megan Follows", "latency_ms": 1504.518985748291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3869}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "World's Fair in Paris.", "latency_ms": 1454.8923969268799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Navy committed to ocean-going battleships", "latency_ms": 1997.9169368743896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "Navy expansion", "latency_ms": 1266.646385192871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Navy expansion", "latency_ms": 1152.0771980285645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1880}, "4": {"k": 4, "answer": "Navy expansion and stagnation", "latency_ms": 1440.8679008483887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "Navy expansion and industrial heritage", "latency_ms": 1302.962303161621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "Navy expansion and industrial heritage.", "latency_ms": 1614.5110130310059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3848}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 467.58055686950684, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Brisbane Roar's theme song", "latency_ms": 1706.312894821167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "Brisbane Roar's theme song", "latency_ms": 1719.670057296753, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1370}, "3": {"k": 3, "answer": "Brisbane Roar's theme song", "latency_ms": 1491.7821884155273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2041}, "4": {"k": 4, "answer": "self-empowerment", "latency_ms": 1246.3908195495605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2654}, "5": {"k": 5, "answer": "self-empowerment", "latency_ms": 1047.6210117340088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3272}, "6": {"k": 6, "answer": "self-empowerment", "latency_ms": 1137.3767852783203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3854}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 202.3172378540039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the team", "latency_ms": 1068.589687347412, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "National Football League teams", "latency_ms": 1206.8672180175781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "National Football League teams", "latency_ms": 1196.5019702911377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "National Football League teams", "latency_ms": 1276.535987854004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "National Football League teams", "latency_ms": 789.0870571136475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3118}, "6": {"k": 6, "answer": "National Football League teams", "latency_ms": 1187.7264976501465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3730}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 607.7971458435059, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "one of the sailors", "latency_ms": 1191.3273334503174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "one of the sailors", "latency_ms": 977.4448871612549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "sailors", "latency_ms": 1170.0499057769775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "sailors", "latency_ms": 1026.9110202789307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2562}, "5": {"k": 5, "answer": "one of the sailors", "latency_ms": 1530.1904678344727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3148}, "6": {"k": 6, "answer": "James W. Marshall", "latency_ms": 820.4326629638672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3813}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 1211.8923664093018, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 547.2939014434814, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 905.900239944458, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 974.5404720306396, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1879}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 931.7407608032227, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 1192.2011375427246, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 1200.117588043213, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 790.5075550079346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 806.3948154449463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1296.701431274414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 686.3055229187012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1095.6799983978271, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2612}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1060.2519512176514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3340}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 989.8874759674072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3938}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1434.3385696411133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ken Hill", "latency_ms": 648.3995914459229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 669}, "2": {"k": 2, "answer": "Ken Hill", "latency_ms": 445.6355571746826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "Ken Hill, Charles Hart, Richard Stilgoe", "latency_ms": 1747.1754550933838, "em": 0.0, "f1": 0.7272727272727272, "containment": 1.0, "context_chars": 2023}, "4": {"k": 4, "answer": "Ken Hill, Charles Hart, Richard Stilgoe", "latency_ms": 1371.0429668426514, "em": 0.0, "f1": 0.7272727272727272, "containment": 1.0, "context_chars": 2687}, "5": {"k": 5, "answer": "Ken Hill, Charles Hart, Richard Stilgoe", "latency_ms": 2057.098627090454, "em": 0.0, "f1": 0.7272727272727272, "containment": 1.0, "context_chars": 3303}, "6": {"k": 6, "answer": "Ken Hill, Charles Hart", "latency_ms": 1312.0989799499512, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3962}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 706.6841125488281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central Germany", "latency_ms": 400.18749237060547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Central Germany", "latency_ms": 960.627555847168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1357}, "3": {"k": 3, "answer": "Central Germany", "latency_ms": 714.5860195159912, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Central Germany", "latency_ms": 648.6835479736328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2757}, "5": {"k": 5, "answer": "European", "latency_ms": 615.1189804077148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3406}, "6": {"k": 6, "answer": "Central European", "latency_ms": 402.8012752532959, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4051}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 736.1488342285156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 1195.8348751068115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 1195.2190399169922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 1040.1082038879395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "post-medieval era", "latency_ms": 1174.5131015777588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "16481651", "latency_ms": 1095.6599712371826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3260}, "6": {"k": 6, "answer": "16481651", "latency_ms": 1293.0195331573486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
