{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 772.0494270324707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Molly", "latency_ms": 1241.3218021392822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "Molly", "latency_ms": 1166.0151481628418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1196}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1181.3178062438965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1462.0332717895508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1281.8043231964111, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3099}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1351.048469543457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3727}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 827.4309635162354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 801.6798496246338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 1455.0516605377197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 1228.3916473388672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1950}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 1221.9738960266113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 836.4126682281494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 1252.6054382324219, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3867}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwest desert regions", "latency_ms": 1042.046070098877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 1598.8223552703857, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "arid lowland or mountainous shrubland", "latency_ms": 2443.1803226470947, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 2024.9855518341064, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 2104.2819023132324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 2468.1663513183594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3315}, "6": {"k": 6, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 2517.6868438720703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3929}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 1194.105863571167, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rajendra Prasad", "latency_ms": 1735.6858253479004, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 2240.725517272949, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1441}, "3": {"k": 3, "answer": "Dr. Rajendra Prasad", "latency_ms": 1347.2914695739746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2126}, "4": {"k": 4, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 2113.8837337493896, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2764}, "5": {"k": 5, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 1996.8781471252441, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3463}, "6": {"k": 6, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 1438.403606414795, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4137}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 859.5023155212402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1073.5270977020264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "10pm", "latency_ms": 920.860767364502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "10pm (Eastern)", "latency_ms": 1319.9315071105957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1271.1517810821533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2586}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1198.8537311553955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3277}, "6": {"k": 6, "answer": "September 22, 2014", "latency_ms": 1633.6803436279297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "2001", "latency_ms": 561.5248680114746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1062.1819496154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "1955", "latency_ms": 636.3363265991211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "1955", "latency_ms": 1097.6788997650146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "June 22, 2001", "latency_ms": 1325.60133934021, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2497}, "5": {"k": 5, "answer": "June 22, 2001", "latency_ms": 1958.263635635376, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3123}, "6": {"k": 6, "answer": "June 22, 2001", "latency_ms": 1472.4647998809814, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3781}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1106.0914993286133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 1906.524896621704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 1446.129560470581, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 1196.8040466308594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 1686.1803531646729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2739}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 1899.3136882781982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3445}, "6": {"k": 6, "answer": "September 27, 2017", "latency_ms": 1706.5012454986572, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4141}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3", "latency_ms": 1027.8968811035156, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hell-O", "latency_ms": 1037.8906726837158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "mid-season finale episode \"Sectionals\"", "latency_ms": 1422.8451251983643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "In \"Sectionals\"", "latency_ms": 1698.1573104858398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "In \"Hell-O\"", "latency_ms": 1542.346715927124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2430}, "5": {"k": 5, "answer": "In \"Sectionals\"", "latency_ms": 1221.7094898223877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3053}, "6": {"k": 6, "answer": "In Season 4", "latency_ms": 1241.8372631072998, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3691}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 945.2474117279053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1509.7095966339111, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1578.4986019134521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1332.6952457427979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1473.0818271636963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1043.846845626831, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1247.3878860473633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3792}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 790.7650470733643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Havana Harbor, Cuba.", "latency_ms": 1046.701431274414, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Havana Harbor, Cuba.", "latency_ms": 1292.8481101989746, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Havana Harbor", "latency_ms": 1207.8070640563965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "Havana Harbor", "latency_ms": 804.253339767456, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2505}, "5": {"k": 5, "answer": "Havana Harbor", "latency_ms": 770.2426910400391, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3132}, "6": {"k": 6, "answer": "Havana Harbor", "latency_ms": 1008.2070827484131, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3796}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 968.7950611114502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1338.0212783813477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1384.5913410186768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "No specific god mentioned", "latency_ms": 1233.6204051971436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "Vishnu", "latency_ms": 964.33424949646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Vishnu", "latency_ms": 1300.1065254211426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3239}, "6": {"k": 6, "answer": "Lord Vishnu", "latency_ms": 1080.5978775024414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3905}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 1346.1823463439941, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "All of them", "latency_ms": 1204.8571109771729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Costa Rica, Nicaragua, Panama, Honduras, Guatemala, El Salvador", "latency_ms": 3040.6877994537354, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1322}, "3": {"k": 3, "answer": "Costa Rica, Nicaragua", "latency_ms": 1779.3538570404053, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2007}, "4": {"k": 4, "answer": "Costa Rica, Nicaragua", "latency_ms": 1530.726671218872, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2705}, "5": {"k": 5, "answer": "Costa Rica, Nicaragua", "latency_ms": 1250.9820461273193, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3397}, "6": {"k": 6, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 1782.6833724975586, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4029}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence.", "latency_ms": 870.1157569885254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 960.9053134918213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Complex sentence", "latency_ms": 1163.9785766601562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Complex sentence", "latency_ms": 1102.285385131836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1977}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 664.7522449493408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 943.171501159668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3371}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 1209.5787525177002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4067}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and trade.", "latency_ms": 1071.8779563903809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 1755.5649280548096, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 2257.6379776000977, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "the Nature and Causes of the Wealth of Nations", "latency_ms": 2031.2302112579346, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 1860.612392425537, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 2578}, "5": {"k": 5, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 1753.1039714813232, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3225}, "6": {"k": 6, "answer": "the nature and causes of the wealth of nations", "latency_ms": 2123.4824657440186, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3841}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 1520.432710647583, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 10, 2017", "latency_ms": 1639.8942470550537, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "August 28, 2018", "latency_ms": 1689.168930053711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 1384.8111629486084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 1782.6473712921143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 2204.3097019195557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 1723.7694263458252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3769}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere", "latency_ms": 1414.1943454742432, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Australian state of Queensland", "latency_ms": 1234.835147857666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Western Australia and Queensland", "latency_ms": 991.631031036377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1374}, "3": {"k": 3, "answer": "Western Australia", "latency_ms": 1097.0687866210938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2040}, "4": {"k": 4, "answer": "Australian state of Queensland and Western Australia", "latency_ms": 1476.7730236053467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2714}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1206.899642944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3367}, "6": {"k": 6, "answer": "Southwest corner of the world", "latency_ms": 1129.878282546997, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4042}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Leia Organa", "latency_ms": 835.1113796234131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1399.198055267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "her", "latency_ms": 1147.5601196289062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "her", "latency_ms": 892.0185565948486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1741}, "4": {"k": 4, "answer": "her", "latency_ms": 663.3737087249756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2312}, "5": {"k": 5, "answer": "her", "latency_ms": 1113.4922504425049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2909}, "6": {"k": 6, "answer": "her", "latency_ms": 580.4493427276611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3440}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 713.7997150421143, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack Barry", "latency_ms": 580.6846618652344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Jack Barry", "latency_ms": 898.2830047607422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Allen Ludden", "latency_ms": 1591.794729232788, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1779}, "4": {"k": 4, "answer": "Allen Ludden", "latency_ms": 926.152229309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Allen Ludden", "latency_ms": 1030.3473472595215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3017}, "6": {"k": 6, "answer": "Allen Ludden", "latency_ms": 1183.605432510376, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3633}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 1020.1399326324463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "mitochondria", "latency_ms": 826.4665603637695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "mitochondria", "latency_ms": 1180.511713027954, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "Mitochondria, Chloroplasts", "latency_ms": 1460.810899734497, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "Mitochondria and Chloroplasts", "latency_ms": 1108.349323272705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2693}, "5": {"k": 5, "answer": "Mitochondria and Chloroplast", "latency_ms": 1272.6335525512695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3377}, "6": {"k": 6, "answer": "Mitochondria and Chloroplast", "latency_ms": 1418.8344478607178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4111}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Backup.", "latency_ms": 2312.9594326019287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1116.5614128112793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 1455.110788345337, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1402}, "3": {"k": 3, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 1715.4147624969482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2091}, "4": {"k": 4, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 2029.768705368042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2791}, "5": {"k": 5, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 1281.0931205749512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3484}, "6": {"k": 6, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 1975.935459136963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4220}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 1506.227970123291, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenny Rogers and Dottie West", "latency_ms": 1444.3168640136719, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 590}, "2": {"k": 2, "answer": "Kenny Rogers and Dottie West", "latency_ms": 1701.2858390808105, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Kenny Rogers and Dottie West", "latency_ms": 917.9246425628662, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1843}, "4": {"k": 4, "answer": "Kenny Rogers and Dottie West", "latency_ms": 1600.01802444458, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "Kenny Rogers and Dottie West", "latency_ms": 1437.3109340667725, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3051}, "6": {"k": 6, "answer": "Dottie West and Kenny Rogers", "latency_ms": 1359.4508171081543, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3627}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 931.6420555114746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Three years old", "latency_ms": 899.9416828155518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 689}, "2": {"k": 2, "answer": "36 months old", "latency_ms": 1162.9197597503662, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "36 months old", "latency_ms": 661.7927551269531, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1911}, "4": {"k": 4, "answer": "36 months old", "latency_ms": 766.7379379272461, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "36 months old", "latency_ms": 942.9934024810791, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3077}, "6": {"k": 6, "answer": "36 months", "latency_ms": 872.5316524505615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3660}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 677.9313087463379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 1141.1669254302979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "3", "latency_ms": 1109.180212020874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "3", "latency_ms": 1115.9155368804932, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Three", "latency_ms": 442.3379898071289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2610}, "5": {"k": 5, "answer": "3", "latency_ms": 890.2878761291504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3226}, "6": {"k": 6, "answer": "3", "latency_ms": 659.0907573699951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3842}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 2681.565284729004, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Felix Felton", "latency_ms": 953.7644386291504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "Felix Felton, Ian Holm, Elijah Wood", "latency_ms": 2365.675926208496, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Felix Felton, Paul Daneman, Ian Holm, Elijah Wood", "latency_ms": 3273.1683254241943, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "Ian Holm, Elijah Wood", "latency_ms": 1589.6029472351074, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2472}, "5": {"k": 5, "answer": "Ian Holm, Elijah Wood", "latency_ms": 1180.9911727905273, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3146}, "6": {"k": 6, "answer": "Ian Holm, Elijah Wood", "latency_ms": 1889.0001773834229, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3812}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party", "latency_ms": 721.6651439666748, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume party", "latency_ms": 1257.4970722198486, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Costume party", "latency_ms": 943.6349868774414, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Costume party", "latency_ms": 986.504316329956, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Costume party", "latency_ms": 737.4322414398193, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Costume party", "latency_ms": 883.8241100311279, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "Costume party", "latency_ms": 845.25465965271, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3778}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 437.2270107269287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One", "latency_ms": 882.2851181030273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "One", "latency_ms": 633.2454681396484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1204}, "3": {"k": 3, "answer": "One", "latency_ms": 854.1882038116455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1902}, "4": {"k": 4, "answer": "One", "latency_ms": 396.73352241516113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2527}, "5": {"k": 5, "answer": "One", "latency_ms": 1104.5477390289307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3159}, "6": {"k": 6, "answer": "One", "latency_ms": 661.062479019165, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3782}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "He promised Fantine", "latency_ms": 490.3898239135742, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 931.6554069519043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Fantine's debts", "latency_ms": 1423.9344596862793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Fantine's debts", "latency_ms": 1038.4340286254883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "Fantine's debts", "latency_ms": 1567.5830841064453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "Fantine's request", "latency_ms": 1119.8432445526123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3130}, "6": {"k": 6, "answer": "Fantine's debts", "latency_ms": 999.8359680175781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3743}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, and South Korea.", "latency_ms": 1427.0238876342773, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "India", "latency_ms": 629.2946338653564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 709}, "2": {"k": 2, "answer": "India and Kenya", "latency_ms": 1158.717155456543, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1403}, "3": {"k": 3, "answer": "India and Kenya", "latency_ms": 983.896017074585, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "India and Kenya", "latency_ms": 826.021671295166, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2743}, "5": {"k": 5, "answer": "India, Kenya, Russia", "latency_ms": 1362.4608516693115, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3444}, "6": {"k": 6, "answer": "India, Kenya, Russia", "latency_ms": 1406.059980392456, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4072}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and control.", "latency_ms": 1443.0456161499023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 3413.1462574005127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 3262.279748916626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 2733.5598468780518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 2845.506429672241, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 3363.933563232422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3441}, "6": {"k": 6, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 3137.2621059417725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4119}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 986.1681461334229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 1312.2308254241943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 1727.1881103515625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Huge and powerful snake", "latency_ms": 1523.7348079681396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1759}, "4": {"k": 4, "answer": "Indian python", "latency_ms": 1184.2877864837646, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "Indian python", "latency_ms": 1051.0084629058838, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3021}, "6": {"k": 6, "answer": "Indian python", "latency_ms": 491.15681648254395, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3717}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 693.946361541748, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "water-ice", "latency_ms": 905.6901931762695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "water-ice", "latency_ms": 802.8075695037842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "water-ice", "latency_ms": 1098.2110500335693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "water-ice", "latency_ms": 1183.548927307129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2382}, "5": {"k": 5, "answer": "water-ice", "latency_ms": 989.539623260498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3042}, "6": {"k": 6, "answer": "water-ice", "latency_ms": 1007.0688724517822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3655}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 1274.2290496826172, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Not in season 2.", "latency_ms": 1746.8953132629395, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "The Departed", "latency_ms": 881.4795017242432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "The Departed episode", "latency_ms": 1260.7002258300781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "The Departed episode", "latency_ms": 1068.4335231781006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2379}, "5": {"k": 5, "answer": "The Departed episode", "latency_ms": 1222.8243350982666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2941}, "6": {"k": 6, "answer": "The Departed episode", "latency_ms": 1152.2016525268555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3525}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "Home team", "latency_ms": 920.8579063415527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1234.3010902404785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "ITV", "latency_ms": 635.4494094848633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "ITV", "latency_ms": 425.4016876220703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "ITV", "latency_ms": 1180.2523136138916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2421}, "5": {"k": 5, "answer": "ITV", "latency_ms": 1205.4314613342285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2995}, "6": {"k": 6, "answer": "ITV", "latency_ms": 713.2389545440674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3592}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw neighborhood", "latency_ms": 1074.1655826568604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northwest", "latency_ms": 1201.5380859375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "Northwest", "latency_ms": 743.6978816986084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Northwest", "latency_ms": 985.5985641479492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "Northwest Washington, DC", "latency_ms": 1181.1017990112305, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2831}, "5": {"k": 5, "answer": "Northwest Washington, DC", "latency_ms": 1702.6162147521973, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3507}, "6": {"k": 6, "answer": "Northwest Washington, DC.", "latency_ms": 1715.6870365142822, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 4217}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 751.0764598846436, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noahic", "latency_ms": 944.6496963500977, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "Noahic", "latency_ms": 868.4332370758057, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Noahic", "latency_ms": 874.4773864746094, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "Noahic", "latency_ms": 1547.8167533874512, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2431}, "5": {"k": 5, "answer": "Noahic", "latency_ms": 968.796968460083, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3042}, "6": {"k": 6, "answer": "Noahic", "latency_ms": 950.0792026519775, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3695}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 1089.1470909118652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 903.038740158081, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1245.3370094299316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1150}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1274.2738723754883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1721}, "4": {"k": 4, "answer": "Jack Jones", "latency_ms": 1197.2246170043945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2354}, "5": {"k": 5, "answer": "a singer", "latency_ms": 1219.6869850158691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2940}, "6": {"k": 6, "answer": "a singer", "latency_ms": 817.5134658813477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3560}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 817.1250820159912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rudy Vallée", "latency_ms": 1255.199909210205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "Rudy Vallée", "latency_ms": 1304.9297332763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "Rudy Vallée", "latency_ms": 1041.2003993988037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Rudy Vallée", "latency_ms": 1252.899169921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2444}, "5": {"k": 5, "answer": "Rudy Vallée", "latency_ms": 1247.3936080932617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3079}, "6": {"k": 6, "answer": "Rudy Vallée", "latency_ms": 586.1005783081055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3673}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 922.2333431243896, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 837.7690315246582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 912.6343727111816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 915.3106212615967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 1209.681510925293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Southwest Florida", "latency_ms": 1042.4389839172363, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "Southwest Florida", "latency_ms": 747.8458881378174, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3758}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "Second", "latency_ms": 932.5735569000244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "50 million", "latency_ms": 640.2380466461182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 713}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1020.535945892334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 970.0539112091064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 947.4906921386719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 781.65602684021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3143}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1223.3715057373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3736}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 1084.0661525726318, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jawaharlal Nehru", "latency_ms": 1320.1937675476074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "Pattom A. Thanu Pillai", "latency_ms": 1800.1148700714111, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "Pattom A. Thanu Pillai", "latency_ms": 1717.4649238586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2058}, "4": {"k": 4, "answer": "Pattom A. Thanu Pillai", "latency_ms": 2256.082534790039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2766}, "5": {"k": 5, "answer": "Pattom A. Thanu Pillai", "latency_ms": 1755.5265426635742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3373}, "6": {"k": 6, "answer": "Pattom A. Thanu Pillai", "latency_ms": 2732.980728149414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4101}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenae Anderson", "latency_ms": 668.6334609985352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bobby Flay", "latency_ms": 976.5219688415527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Bobby Flay", "latency_ms": 1460.3137969970703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Bobby Flay", "latency_ms": 1246.018409729004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Bobby Flay", "latency_ms": 951.6949653625488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "Bobby Flay", "latency_ms": 1182.4467182159424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3158}, "6": {"k": 6, "answer": "Bobby Flay", "latency_ms": 923.4147071838379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 677.2885322570801, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "codice_22", "latency_ms": 538.6977195739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 687}, "2": {"k": 2, "answer": ".java", "latency_ms": 586.2932205200195, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": ".java", "latency_ms": 600.968599319458, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": ".java", "latency_ms": 587.1620178222656, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": ".java", "latency_ms": 401.5939235687256, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": ".java", "latency_ms": 646.4717388153076, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3911}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 472.0280170440674, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alan Turing", "latency_ms": 1133.352518081665, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Alan Turing", "latency_ms": 438.1265640258789, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Alan Turing", "latency_ms": 912.7781391143799, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 945.0423717498779, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2519}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 703.1731605529785, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3187}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 581.798791885376, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3876}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline", "latency_ms": 808.1374168395996, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ensure party cohesion and voting adherence", "latency_ms": 1556.1223030090332, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "ensure members adhere to party policies", "latency_ms": 1047.4069118499756, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "to ensure members adhere to party policies", "latency_ms": 1821.0251331329346, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "to ensure members adhere to party policies", "latency_ms": 957.2665691375732, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "to make sure that House members vote in line with party leadership", "latency_ms": 1827.605962753296, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3223}, "6": {"k": 6, "answer": "to make sure that House members vote in line with party leadership", "latency_ms": 1836.3771438598633, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3947}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 699.8403072357178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1088.6695384979248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "1973", "latency_ms": 966.3257598876953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "1973", "latency_ms": 1259.770154953003, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "1973", "latency_ms": 408.2472324371338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "1973", "latency_ms": 970.1497554779053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3039}, "6": {"k": 6, "answer": "1999", "latency_ms": 935.46462059021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3675}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the​ right but not the​ obligation to buy foreign​ currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 955.1832675933838, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 867.2049045562744, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 671.001672744751, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 1189.8484230041504, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "Call option", "latency_ms": 844.5534706115723, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2702}, "5": {"k": 5, "answer": "Call option", "latency_ms": 657.2046279907227, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "FX option", "latency_ms": 1020.0543403625488, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3910}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 451.859712600708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 790.271520614624, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360 members", "latency_ms": 1073.857069015503, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1380}, "3": {"k": 3, "answer": "360", "latency_ms": 1127.5053024291992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2010}, "4": {"k": 4, "answer": "360 members", "latency_ms": 1022.881269454956, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "360 members", "latency_ms": 1176.5820980072021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3307}, "6": {"k": 6, "answer": "360", "latency_ms": 933.610200881958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4001}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 1063.683032989502, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 801.3322353363037, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 1028.4004211425781, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 941.178560256958, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 954.7708034515381, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2559}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 1054.598331451416, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3205}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 1462.0027542114258, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3856}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gormé"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 1039.95680809021, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eydie Gormé", "latency_ms": 1355.231523513794, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 580}, "2": {"k": 2, "answer": "Eydie Gormé", "latency_ms": 1055.678129196167, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Eydie Gormé", "latency_ms": 1317.5570964813232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1787}, "4": {"k": 4, "answer": "Eydie Gormé", "latency_ms": 1655.1661491394043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2364}, "5": {"k": 5, "answer": "Eydie Gormé", "latency_ms": 1403.5165309906006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2981}, "6": {"k": 6, "answer": "Eydie Gormé", "latency_ms": 1461.6408348083496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3582}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1057.1880340576172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "K. K. Usha", "latency_ms": 1389.3158435821533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 519}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1051.1515140533447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1132}, "3": {"k": 3, "answer": "K. K. Usha", "latency_ms": 1549.7393608093262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1756}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 945.2896118164062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2317}, "5": {"k": 5, "answer": "Mohan Shantanagoudar", "latency_ms": 1363.8229370117188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2929}, "6": {"k": 6, "answer": "Mohan Shantanagoudar", "latency_ms": 1152.0867347717285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3493}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 838.7930393218994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Martina Navratilova", "latency_ms": 882.0657730102539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "Nadal", "latency_ms": 686.1317157745361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "Roger Federer", "latency_ms": 1006.0088634490967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1851}, "4": {"k": 4, "answer": "Roger Federer", "latency_ms": 693.7251091003418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2410}, "5": {"k": 5, "answer": "Roger Federer", "latency_ms": 695.9536075592041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3008}, "6": {"k": 6, "answer": "Roger Federer", "latency_ms": 488.08765411376953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3594}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 579.0305137634277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 841.3553237915039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 621.5918064117432, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1228}, "3": {"k": 3, "answer": "1", "latency_ms": 827.5754451751709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "1", "latency_ms": 866.8622970581055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2418}, "5": {"k": 5, "answer": "1", "latency_ms": 577.6622295379639, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3054}, "6": {"k": 6, "answer": "1", "latency_ms": 606.6381931304932, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3661}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 454.8637866973877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2000", "latency_ms": 941.2376880645752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "2000", "latency_ms": 952.1100521087646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "2000", "latency_ms": 692.6319599151611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1826}, "4": {"k": 4, "answer": "2000", "latency_ms": 662.351131439209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2351}, "5": {"k": 5, "answer": "2000", "latency_ms": 863.426685333252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2965}, "6": {"k": 6, "answer": "2000", "latency_ms": 1101.8331050872803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3565}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 474.37143325805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 877.1712779998779, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "37", "latency_ms": 376.27553939819336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "37 is incorrect, the correct answer is not in the provided context for the overall number, but for swimming: 5", "latency_ms": 4077.782154083252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "37", "latency_ms": 721.0471630096436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "37", "latency_ms": 558.7344169616699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3203}, "6": {"k": 6, "answer": "37", "latency_ms": 940.0436878204346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3872}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 1053.3838272094727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 1395.998239517212, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 1302.1912574768066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 1418.5044765472412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 1540.8499240875244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2512}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 1336.3547325134277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3163}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 1087.2559547424316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3814}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 2440.009355545044, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 1404.6273231506348, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1207.4220180511475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1182}, "3": {"k": 3, "answer": "Corey, Cory", "latency_ms": 1448.5971927642822, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1783}, "4": {"k": 4, "answer": "Corey, Cory", "latency_ms": 1327.6989459991455, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2419}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1003.4866333007812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3011}, "6": {"k": 6, "answer": "Corey, Cory", "latency_ms": 1447.2012519836426, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3596}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 683.7973594665527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1415.8174991607666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 745.8646297454834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1199.3193626403809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1210.0069522857666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 981.9314479827881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1258.3141326904297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 639.1637325286865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 679.9297332763672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "159", "latency_ms": 877.4707317352295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "159", "latency_ms": 432.0521354675293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "159", "latency_ms": 1101.348876953125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2708}, "5": {"k": 5, "answer": "159", "latency_ms": 836.9078636169434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3443}, "6": {"k": 6, "answer": "159", "latency_ms": 853.8846969604492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4090}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 1221.8034267425537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Egan", "latency_ms": 959.5482349395752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 581}, "2": {"k": 2, "answer": "Egan", "latency_ms": 859.0958118438721, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1181}, "3": {"k": 3, "answer": "Egan", "latency_ms": 718.4977531433105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1701}, "4": {"k": 4, "answer": "Egan", "latency_ms": 1160.2723598480225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2317}, "5": {"k": 5, "answer": "Egan", "latency_ms": 945.2235698699951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2889}, "6": {"k": 6, "answer": "Egan", "latency_ms": 1170.02272605896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3427}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 285.07304191589355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1260.4377269744873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1239.4664287567139, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1315.9081935882568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1805}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1278.7251472473145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2383}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1205.5811882019043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2948}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 940.5882358551025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3548}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 1627.2828578948975, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Right hand", "latency_ms": 879.9455165863037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 394.7422504425049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1137}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 901.2887477874756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1701}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 926.506519317627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2255}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 677.1318912506104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2857}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 937.4401569366455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3451}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 1395.1635360717773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Donald Duck", "latency_ms": 682.3832988739014, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Donald Duck", "latency_ms": 677.0601272583008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1293}, "3": {"k": 3, "answer": "Donald Duck", "latency_ms": 1155.937671661377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1945}, "4": {"k": 4, "answer": "Donald Duck", "latency_ms": 664.6542549133301, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2597}, "5": {"k": 5, "answer": "Donald Duck", "latency_ms": 863.2805347442627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3236}, "6": {"k": 6, "answer": "Donald Duck", "latency_ms": 842.7107334136963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3851}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 783.9303016662598, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bernard Mayes", "latency_ms": 846.1620807647705, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "Bernard Mayes", "latency_ms": 1687.525987625122, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Bernard Mayes", "latency_ms": 1084.369421005249, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Bernard Mayes", "latency_ms": 1080.336093902588, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2470}, "5": {"k": 5, "answer": "Bernard Mayes", "latency_ms": 1069.5457458496094, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "Bernard Mayes", "latency_ms": 1419.342279434204, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3679}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2019", "latency_ms": 1611.8357181549072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2018", "latency_ms": 1811.3117218017578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 1785.5195999145508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1169}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 1479.5434474945068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 1836.6529941558838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2404}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 1849.8954772949219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3055}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 2234.534740447998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3661}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 680.3288459777832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1062.7779960632324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1441.5090084075928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1195.4636573791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1484.560251235962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2600}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 842.663049697876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1026.6492366790771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3825}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 776.9176959991455, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Claire Holt", "latency_ms": 1177.1214008331299, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Claire Holt", "latency_ms": 1186.891794204712, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Claire Holt", "latency_ms": 707.2689533233643, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Claire Holt", "latency_ms": 934.1442584991455, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2471}, "5": {"k": 5, "answer": "Claire Holt", "latency_ms": 786.198616027832, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3111}, "6": {"k": 6, "answer": "Claire Holt", "latency_ms": 1194.8447227478027, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3750}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "Every living thing", "latency_ms": 770.8470821380615, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in wood or soil", "latency_ms": 999.8390674591064, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 705}, "2": {"k": 2, "answer": "in wood or soil", "latency_ms": 982.9874038696289, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1407}, "3": {"k": 3, "answer": "in wood, soil, plants, and organisms", "latency_ms": 1207.1146965026855, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 2057}, "4": {"k": 4, "answer": "in wood, soil, plants, and animals", "latency_ms": 1945.643424987793, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 2742}, "5": {"k": 5, "answer": "in all land-living organisms, soils, and water bodies", "latency_ms": 2068.3348178863525, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 3462}, "6": {"k": 6, "answer": "in all land-living organisms, soils, and water bodies", "latency_ms": 1890.1934623718262, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 4116}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1058.8605403900146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Akul Balaji", "latency_ms": 1274.6508121490479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Akul Balaji", "latency_ms": 1210.4010581970215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1324}, "3": {"k": 3, "answer": "Akul Balaji", "latency_ms": 1320.591926574707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "Akul Balaji", "latency_ms": 1294.8582172393799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Akul Balaji", "latency_ms": 814.0823841094971, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Akul Balaji", "latency_ms": 1122.3945617675781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3817}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 894.5391178131104, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jackson County", "latency_ms": 640.0630474090576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "Clay County", "latency_ms": 1124.8571872711182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Kanab, Utah", "latency_ms": 1217.7479267120361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1863}, "4": {"k": 4, "answer": "Kanab, Utah", "latency_ms": 1764.5385265350342, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2490}, "5": {"k": 5, "answer": "Clay County", "latency_ms": 742.5124645233154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3115}, "6": {"k": 6, "answer": "Kanab, Utah", "latency_ms": 1038.888931274414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3730}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 470.3326225280762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jesper Klein", "latency_ms": 873.7282752990723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 921.7562675476074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1335}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 996.8078136444092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 981.2636375427246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1070.807695388794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 979.3722629547119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3896}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Lake Winnipeg", "latency_ms": 485.2557182312012, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Saskatchewan Glacier to Rocky Mountain House", "latency_ms": 1848.5784530639648, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 965.6171798706055, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "at the confluence of its two main tributaries, Hudson Bay", "latency_ms": 2766.3917541503906, "em": 0.0, "f1": 0.3636363636363636, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Canadian Rockies to Lake Winnipeg", "latency_ms": 1530.940055847168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2674}, "5": {"k": 5, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 1156.2247276306152, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3279}, "6": {"k": 6, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 1360.5682849884033, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 4009}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 485.8415126800537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 881.8657398223877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome", "latency_ms": 942.4123764038086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Rome, Italy", "latency_ms": 975.0473499298096, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1816}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 1427.7658462524414, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2417}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 1343.5797691345215, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3068}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 1165.9207344055176, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3755}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "Measurement mark", "latency_ms": 673.7048625946045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "batch code", "latency_ms": 895.7333564758301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "manufacturing company or site", "latency_ms": 1238.828420639038, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "manufacturing company or site", "latency_ms": 1198.4283924102783, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "the manufacturing company or site", "latency_ms": 1278.52463722229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2500}, "5": {"k": 5, "answer": "the manufacturing company or site", "latency_ms": 1256.760835647583, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3089}, "6": {"k": 6, "answer": "the manufacturing company or site", "latency_ms": 1649.2199897766113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3710}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia", "latency_ms": 789.902925491333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 1430.058479309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "hydrogen fluoride, ammonia and methanol", "latency_ms": 1632.1425437927246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 2156.8124294281006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 1984.6010208129883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "hydrogen fluoride, ammonia, methanol, DNA, proteins", "latency_ms": 2042.4413681030273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3212}, "6": {"k": 6, "answer": "hydrogen fluoride, ammonia, methanol, DNA, proteins", "latency_ms": 2473.1698036193848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3812}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Boy Meets Girl", "latency_ms": 986.4416122436523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 658.5900783538818, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "1988", "latency_ms": 1212.5892639160156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "1988", "latency_ms": 754.8911571502686, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1785}, "4": {"k": 4, "answer": "1988", "latency_ms": 1152.3756980895996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2409}, "5": {"k": 5, "answer": "1988", "latency_ms": 1187.159538269043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3012}, "6": {"k": 6, "answer": "1988", "latency_ms": 645.0645923614502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3628}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 720.6053733825684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tute", "latency_ms": 684.7729682922363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "Truco", "latency_ms": 855.0522327423096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1168}, "3": {"k": 3, "answer": "Manille", "latency_ms": 1135.5228424072266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1763}, "4": {"k": 4, "answer": "Manille", "latency_ms": 1069.6053504943848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2363}, "5": {"k": 5, "answer": "Manille", "latency_ms": 576.7970085144043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2949}, "6": {"k": 6, "answer": "Manille", "latency_ms": 923.0136871337891, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3609}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 763.0858421325684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1038.4893417358398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1040.7984256744385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "5%", "latency_ms": 848.0403423309326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 1516.608715057373, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 1066.3318634033203, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 1302.6962280273438, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3724}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 709.5482349395752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 966.8426513671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1040.6184196472168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "1971", "latency_ms": 458.1713676452637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "1971", "latency_ms": 608.1051826477051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2510}, "5": {"k": 5, "answer": "1971", "latency_ms": 1165.4703617095947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3133}, "6": {"k": 6, "answer": "1971", "latency_ms": 677.6790618896484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3692}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 572.556734085083, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1197.9396343231201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1060.9514713287354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Lionel Richie", "latency_ms": 928.6839962005615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 947.7758407592773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 522.72629737854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3062}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 1178.0846118927002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3679}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert", "latency_ms": 606.7285537719727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cecil Calvert and Catholic settlers", "latency_ms": 1617.4678802490234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Cecil Calvert", "latency_ms": 1202.4664878845215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1336}, "3": {"k": 3, "answer": "Cecil Calvert and Lord Baltimore's first settlers, including Leonard Calvert", "latency_ms": 2057.5032234191895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Cecil Calvert", "latency_ms": 1131.3397884368896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2617}, "5": {"k": 5, "answer": "Cecil Calvert and Leonard Calvert", "latency_ms": 1653.3167362213135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3294}, "6": {"k": 6, "answer": "Cecil Calvert and his brother Leonard Calvert", "latency_ms": 2124.5365142822266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3952}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 482.0096492767334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiger Woods", "latency_ms": 840.8854007720947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Tiger Woods", "latency_ms": 524.4395732879639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Tiger Woods", "latency_ms": 1203.6054134368896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Tiger Woods", "latency_ms": 900.8870124816895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Tiger Woods", "latency_ms": 818.4065818786621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3188}, "6": {"k": 6, "answer": "Tiger Woods", "latency_ms": 800.4963397979736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3848}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 795.2532768249512, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "200 to 500 mg", "latency_ms": 1676.1410236358643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 1800.1315593719482, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg", "latency_ms": 1740.0691509246826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1930}, "4": {"k": 4, "answer": "200 to 500 mg", "latency_ms": 1356.5261363983154, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 2058.260440826416, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 2007.852554321289, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3816}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 1895.7982063293457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham United", "latency_ms": 1255.8767795562744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 586}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 980.3647994995117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1105}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 1187.1767044067383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1685}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 1138.9479637145996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2245}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 1135.2558135986328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2887}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 1186.44380569458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3467}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 1147.3162174224854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hotel beverage rooms", "latency_ms": 960.1826667785645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 685}, "2": {"k": 2, "answer": "Windsor", "latency_ms": 735.6748580932617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "Windsor", "latency_ms": 659.5950126647949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1993}, "4": {"k": 4, "answer": "Windsor", "latency_ms": 1108.138084411621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2668}, "5": {"k": 5, "answer": "Windsor", "latency_ms": 1417.207956314087, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3361}, "6": {"k": 6, "answer": "Windsor", "latency_ms": 923.3787059783936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4082}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh", "latency_ms": 1206.1495780944824, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 985.2826595306396, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 1078.8638591766357, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1379}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 1457.258939743042, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2057}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 1530.8094024658203, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 1446.0201263427734, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3428}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 1174.8831272125244, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4106}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 521.1858749389648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alexa Bliss", "latency_ms": 945.5304145812988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1122.1606731414795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Alexa Bliss", "latency_ms": 882.58957862854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "Roman Reigns", "latency_ms": 1399.5399475097656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2596}, "5": {"k": 5, "answer": "Roman Reigns", "latency_ms": 1000.4410743713379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3264}, "6": {"k": 6, "answer": "Roman Reigns", "latency_ms": 1144.3376541137695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3881}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 1095.280647277832, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Southport, North Carolina", "latency_ms": 1249.6144771575928, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Southport, North Carolina.", "latency_ms": 1631.2718391418457, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Southport, North Carolina.", "latency_ms": 1353.1804084777832, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "Southport, North Carolina", "latency_ms": 1095.3421592712402, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2425}, "5": {"k": 5, "answer": "Southport, North Carolina.", "latency_ms": 1299.8361587524414, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3028}, "6": {"k": 6, "answer": "Southport, North Carolina.", "latency_ms": 1236.1671924591064, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3649}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 973.5982418060303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1094.0625667572021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 705}, "2": {"k": 2, "answer": "Sylvia F. Porter", "latency_ms": 804.6343326568604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Sylvia F. Porter", "latency_ms": 1113.2042407989502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 1759.5813274383545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 1764.4672393798828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3327}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 1284.8408222198486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3932}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 943.641185760498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 960.2451324462891, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 735}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 951.1539936065674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1441}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 865.1430606842041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2187}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 870.8972930908203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2881}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 1110.1863384246826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3642}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 918.53928565979, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4403}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 621.124267578125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 371.9780445098877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "Max", "latency_ms": 897.089958190918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Max", "latency_ms": 455.52754402160645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1872}, "4": {"k": 4, "answer": "Max", "latency_ms": 616.9073581695557, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Max", "latency_ms": 813.0507469177246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Max", "latency_ms": 636.7228031158447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3716}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 965.278148651123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1264.967441558838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1230.7555675506592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1534.4834327697754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1935}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1488.8195991516113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1016.249418258667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3156}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1297.8150844573975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3815}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "World's Fair in Paris.", "latency_ms": 1271.388292312622, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1900 Summer Olympics", "latency_ms": 1433.1481456756592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "1900 Summer Olympics", "latency_ms": 1466.803789138794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Summer Olympics in Paris", "latency_ms": 1526.1194705963135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "Summer Olympics in Paris", "latency_ms": 1221.4627265930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2635}, "5": {"k": 5, "answer": "Summer Olympics in Paris", "latency_ms": 1218.9428806304932, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3326}, "6": {"k": 6, "answer": "Olympics and World Championships", "latency_ms": 1780.9114456176758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4010}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 520.3094482421875, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Empowerment", "latency_ms": 1194.1723823547363, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Empowerment", "latency_ms": 1244.9572086334229, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Empowerment", "latency_ms": 1188.58003616333, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Empowerment", "latency_ms": 828.324556350708, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "Empowerment", "latency_ms": 1187.6511573791504, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "Empowerment", "latency_ms": 680.2542209625244, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3787}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 937.5588893890381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "National Football League teams", "latency_ms": 967.174768447876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "National Football League teams", "latency_ms": 1191.7731761932373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "National Football League teams", "latency_ms": 990.5641078948975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "National Football League teams", "latency_ms": 1025.3705978393555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2451}, "5": {"k": 5, "answer": "National Football League teams", "latency_ms": 1436.9006156921387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3069}, "6": {"k": 6, "answer": "National Football League teams", "latency_ms": 1023.0245590209961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3686}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 818.0115222930908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1246.60325050354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 972.7332592010498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1305}, "3": {"k": 3, "answer": "James Marshall", "latency_ms": 1326.228380203247, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "James Marshall", "latency_ms": 709.2812061309814, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2617}, "5": {"k": 5, "answer": "James Marshall", "latency_ms": 1110.255479812622, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3191}, "6": {"k": 6, "answer": "James Marshall", "latency_ms": 946.3014602661133, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3743}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 981.1892509460449, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 1224.5638370513916, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 1268.3701515197754, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 1428.7824630737305, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 1201.019525527954, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 1159.2659950256348, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 1157.1550369262695, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1032.067060470581, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1076.246738433838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1071.8870162963867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1158}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1483.3364486694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1756}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1205.0442695617676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2372}, "5": {"k": 5, "answer": "All five ski jumping gold medals.", "latency_ms": 2062.145948410034, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3035}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1198.8744735717773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3689}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1324.9540328979492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart", "latency_ms": 873.4769821166992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1967.6258563995361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1929.863691329956, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1952}, "4": {"k": 4, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 2098.7637042999268, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2631}, "5": {"k": 5, "answer": "Charles Hart", "latency_ms": 680.0069808959961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3306}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 1461.7664813995361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3997}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 887.9749774932861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central Germany", "latency_ms": 607.853889465332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Central Germany", "latency_ms": 628.4952163696289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Central Germany", "latency_ms": 959.467887878418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Central Germany", "latency_ms": 670.170783996582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Central Germany", "latency_ms": 658.482551574707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3288}, "6": {"k": 6, "answer": "Central Germany", "latency_ms": 1150.1460075378418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4016}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 281.329870223999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 1118.2236671447754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 1001.4603137969971, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 814.7928714752197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "1648–1651", "latency_ms": 988.5458946228027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "1648–1651", "latency_ms": 1478.3289432525635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "1648–1651", "latency_ms": 800.6598949432373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3902}}}
