{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 824.1965770721436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 22, 2018", "latency_ms": 1603.8994789123535, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "June 22, 2018", "latency_ms": 1319.3082809448242, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "June 22, 2018", "latency_ms": 1929.011583328247, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "June 22, 2018", "latency_ms": 1216.3176536560059, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 1882.10129737854, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3170}, "6": {"k": 6, "answer": "June 22, 2018", "latency_ms": 1428.6015033721924, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3788}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Freestyle, Nordic Combined, Ski Jumping, Biathlon.", "latency_ms": 3136.766195297241, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alpine skiing", "latency_ms": 1253.2308101654053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Alpine skiing", "latency_ms": 1229.276180267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Alpine, Freestyle", "latency_ms": 1541.9135093688965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 2153.278589248657, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2564}, "5": {"k": 5, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 1484.269380569458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 1335.8933925628662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3886}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "Arianwen Parkes-Lockwood", "latency_ms": 1886.2640857696533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Aldo Mignone", "latency_ms": 1580.1560878753662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 694}, "2": {"k": 2, "answer": "Aldo Mignone", "latency_ms": 1653.6200046539307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Aldo Mignone", "latency_ms": 1147.6080417633057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Aldo Mignone", "latency_ms": 1891.9012546539307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2564}, "5": {"k": 5, "answer": "Aldo Mignone", "latency_ms": 1540.3339862823486, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3137}, "6": {"k": 6, "answer": "Aldo Mignone", "latency_ms": 1576.7145156860352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3789}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "Bengals, Dolphins, Broncos, Chargers", "latency_ms": 1732.8944206237793, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bengals", "latency_ms": 944.9319839477539, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Bengals, Dolphins", "latency_ms": 1240.347146987915, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Bengals, Dolphins", "latency_ms": 1983.5386276245117, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "Miami Dolphins, Bengals", "latency_ms": 1388.4270191192627, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2414}, "5": {"k": 5, "answer": "Miami Dolphins, Cincinnati Bengals", "latency_ms": 1109.8229885101318, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3042}, "6": {"k": 6, "answer": "Miami Dolphins, Denver Broncos", "latency_ms": 1542.241096496582, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3660}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "December 8, 1985", "latency_ms": 1653.665542602539, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1013.1263732910156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 1575.3505229949951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1424}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 1343.8594341278076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2144}, "4": {"k": 4, "answer": "8 December 1985", "latency_ms": 1399.9791145324707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2845}, "5": {"k": 5, "answer": "8 December 1985", "latency_ms": 1741.774082183838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3484}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 1587.369680404663, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4210}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "Spanish moss", "latency_ms": 918.5740947723389, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spanish moss", "latency_ms": 980.8957576751709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "Spanish moss", "latency_ms": 495.35369873046875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Spanish moss", "latency_ms": 1100.9113788604736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1939}, "4": {"k": 4, "answer": "Spanish moss", "latency_ms": 886.5253925323486, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2570}, "5": {"k": 5, "answer": "Spanish moss", "latency_ms": 880.9309005737305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3309}, "6": {"k": 6, "answer": "Spanish moss", "latency_ms": 822.1540451049805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3987}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "I-IV", "latency_ms": 964.5752906799316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canadian Cardiovascular Society", "latency_ms": 1256.824016571045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 762}, "2": {"k": 2, "answer": "Canadian Cardiovascular Society", "latency_ms": 959.679126739502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1494}, "3": {"k": 3, "answer": "Canadian Cardiovascular Society", "latency_ms": 760.4894638061523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2250}, "4": {"k": 4, "answer": "Canadian Cardiovascular Society grading", "latency_ms": 1523.6103534698486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2959}, "5": {"k": 5, "answer": "Canadian Cardiovascular Society", "latency_ms": 756.2038898468018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3606}, "6": {"k": 6, "answer": "Canadian Cardiovascular Society grading", "latency_ms": 1426.6598224639893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4395}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Charles and Eddie", "latency_ms": 747.5149631500244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1051.778793334961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1227.7731895446777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1148.21195602417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 942.8389072418213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2442}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1053.2464981079102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3052}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1402.6224613189697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3708}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 376.995325088501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1196.4998245239258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "3", "latency_ms": 639.6443843841553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "3", "latency_ms": 624.5853900909424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "3", "latency_ms": 877.5596618652344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2442}, "5": {"k": 5, "answer": "3", "latency_ms": 426.8651008605957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3038}, "6": {"k": 6, "answer": "3", "latency_ms": 1044.954538345337, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "A cake", "latency_ms": 440.79089164733887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Biscuit-sized cakes", "latency_ms": 1446.5296268463135, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "cake", "latency_ms": 604.2487621307373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "cake", "latency_ms": 892.4262523651123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1764}, "4": {"k": 4, "answer": "A cake", "latency_ms": 480.92007637023926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "A cake", "latency_ms": 900.2737998962402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2986}, "6": {"k": 6, "answer": "A cake.", "latency_ms": 1239.0894889831543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Seth MacFarlane", "latency_ms": 1095.5901145935059, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seth MacFarlane", "latency_ms": 1248.6536502838135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "Seth MacFarlane", "latency_ms": 1122.3206520080566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Seth MacFarlane", "latency_ms": 1257.3165893554688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 1057.1746826171875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2550}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 1343.986988067627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3184}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 1446.2099075317383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3850}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "Heroin", "latency_ms": 437.8635883331299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amphetamines", "latency_ms": 1188.762903213501, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Amphetamines", "latency_ms": 973.7386703491211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1186}, "3": {"k": 3, "answer": "Amphetamines", "latency_ms": 1417.0892238616943, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1794}, "4": {"k": 4, "answer": "Amphetamines", "latency_ms": 1046.6649532318115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2436}, "5": {"k": 5, "answer": "Amphetamines", "latency_ms": 1187.1178150177002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3116}, "6": {"k": 6, "answer": "Amphetamines", "latency_ms": 982.839822769165, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3735}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "14 weeks", "latency_ms": 973.7720489501953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1282.2434902191162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1032.8209400177002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "Not stated", "latency_ms": 1154.5090675354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "Not specified", "latency_ms": 1139.8146152496338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2390}, "5": {"k": 5, "answer": "only a week", "latency_ms": 1263.8380527496338, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2958}, "6": {"k": 6, "answer": "1 week", "latency_ms": 854.9580574035645, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3577}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "Yushan, China", "latency_ms": 1256.7756175994873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haikou", "latency_ms": 1124.3252754211426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 573}, "2": {"k": 2, "answer": "Yushan, China", "latency_ms": 1069.4811344146729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "Yushan, China", "latency_ms": 1180.6936264038086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "Yushan, China", "latency_ms": 1507.6429843902588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2434}, "5": {"k": 5, "answer": "Yushan, China", "latency_ms": 1546.7321872711182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3038}, "6": {"k": 6, "answer": "Yushan, China", "latency_ms": 1280.0440788269043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3680}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "Thad Luckinbill", "latency_ms": 1272.8581428527832, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1509.4828605651855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1039.5712852478027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1215.8558368682861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1456.5811157226562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1062.166452407837, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3098}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1429.4190406799316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3758}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 449.8021602630615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1983", "latency_ms": 1136.793613433838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "1986", "latency_ms": 629.5583248138428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "1973", "latency_ms": 626.4410018920898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1853}, "4": {"k": 4, "answer": "1986", "latency_ms": 1112.489938735962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "1973", "latency_ms": 897.8147506713867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3124}, "6": {"k": 6, "answer": "1973", "latency_ms": 869.2677021026611, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3769}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "J-Rock", "latency_ms": 492.9516315460205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jakalope, Damhnait Doyle", "latency_ms": 1427.0915985107422, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Jakalope, Damhnait Doyle, Alexz Johnson", "latency_ms": 1342.3864841461182, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Damhnait Doyle", "latency_ms": 814.61501121521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Damhnait Doyle", "latency_ms": 1315.403699874878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Damhnait Doyle, Jakalope, Alexz Johnson", "latency_ms": 1868.6695098876953, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3268}, "6": {"k": 6, "answer": "Damhnait Doyle, Jakalope, Alexz Johnson", "latency_ms": 2520.8280086517334, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3879}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "2006", "latency_ms": 508.53633880615234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2002", "latency_ms": 1422.3508834838867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 629}, "2": {"k": 2, "answer": "March 15, 2002", "latency_ms": 1607.2633266448975, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "March 15, 2002", "latency_ms": 1723.9398956298828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1822}, "4": {"k": 4, "answer": "March 15, 2002", "latency_ms": 1107.595682144165, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2449}, "5": {"k": 5, "answer": "June 1995", "latency_ms": 691.6389465332031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "March 15, 2002", "latency_ms": 1847.8965759277344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3707}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "Master Sergeant", "latency_ms": 702.6944160461426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Master Sergeant", "latency_ms": 635.9212398529053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Master Sergeant", "latency_ms": 649.9042510986328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1336}, "3": {"k": 3, "answer": "Master Sergeant", "latency_ms": 1180.07230758667, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1912}, "4": {"k": 4, "answer": "Master Sergeant", "latency_ms": 660.2776050567627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2484}, "5": {"k": 5, "answer": "Master Sergeant", "latency_ms": 1205.094575881958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3052}, "6": {"k": 6, "answer": "First Sergeant", "latency_ms": 739.877462387085, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 586.8892669677734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "GNU project", "latency_ms": 942.3680305480957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 1221.2951183319092, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 1266.2384510040283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1973}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 1226.2301445007324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 1246.8698024749756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3249}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 988.5766506195068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3886}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1128.56125831604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Heena Sidhu", "latency_ms": 967.2360420227051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 580}, "2": {"k": 2, "answer": "Heena Sidhu", "latency_ms": 1733.4022521972656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1164}, "3": {"k": 3, "answer": "Heena Sidhu", "latency_ms": 1552.048921585083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1777}, "4": {"k": 4, "answer": "Heena Sidhu", "latency_ms": 1483.3693504333496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2408}, "5": {"k": 5, "answer": "Heena Sidhu", "latency_ms": 838.8593196868896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3018}, "6": {"k": 6, "answer": "Heena Sidhu", "latency_ms": 1654.3467044830322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3627}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Ed Roland", "latency_ms": 691.5237903594971, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 939.9363994598389, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 861.4728450775146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1278}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 1146.1284160614014, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1916}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 784.520149230957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 1155.235767364502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 814.791202545166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3849}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 863.9907836914062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1217.3519134521484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 609}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 1173.9625930786133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 1179.224967956543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 440.9494400024414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2461}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 1175.8098602294922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3047}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 783.0345630645752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3643}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 750.6129741668701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "100 cent√©simos = 1 peso", "latency_ms": 1606.8172454833984, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 567}, "2": {"k": 2, "answer": "PYG6155", "latency_ms": 816.2181377410889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "PYG", "latency_ms": 909.0194702148438, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1794}, "4": {"k": 4, "answer": "PYG", "latency_ms": 677.2441864013672, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 2431}, "5": {"k": 5, "answer": "PYG", "latency_ms": 977.0240783691406, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3097}, "6": {"k": 6, "answer": "PYG", "latency_ms": 955.5649757385254, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3735}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "Midazolam", "latency_ms": 739.80712890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "It is not specified.", "latency_ms": 1034.0707302093506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "It is ideal for short appointments and simple procedures.", "latency_ms": 2063.582181930542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1425}, "3": {"k": 3, "answer": "Midazolam", "latency_ms": 1263.4873390197754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2151}, "4": {"k": 4, "answer": "Midazolam", "latency_ms": 1085.3240489959717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2889}, "5": {"k": 5, "answer": "Midazolam", "latency_ms": 833.9779376983643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3573}, "6": {"k": 6, "answer": "Midazolam", "latency_ms": 1016.1621570587158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4219}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 505.3400993347168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "26,000 years", "latency_ms": 1217.2613143920898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "26,000 years", "latency_ms": 1062.3786449432373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "26,000 years", "latency_ms": 955.7127952575684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1900}, "4": {"k": 4, "answer": "25,772 years", "latency_ms": 1061.3279342651367, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "25,772 years", "latency_ms": 1035.219669342041, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "25,772 years", "latency_ms": 1047.2161769866943, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3775}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 741.6093349456787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Texas A&M Aggies", "latency_ms": 999.2532730102539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Texas A&M Aggies", "latency_ms": 1266.98899269104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1310}, "3": {"k": 3, "answer": "Texas A&M Aggies", "latency_ms": 1219.6273803710938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Texas A&M Aggies", "latency_ms": 1083.5473537445068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2554}, "5": {"k": 5, "answer": "Texas A&M Aggies", "latency_ms": 1671.2045669555664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Texas A&M Aggies", "latency_ms": 1220.8421230316162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3810}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and Non-Renewable.", "latency_ms": 1962.0676040649414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable or non-renewable", "latency_ms": 1458.3961963653564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable or non-renewable", "latency_ms": 2104.3002605438232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1428}, "3": {"k": 3, "answer": "renewable or non-renewable", "latency_ms": 1167.5539016723633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2178}, "4": {"k": 4, "answer": "renewable or non-renewable", "latency_ms": 1727.236032485962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2876}, "5": {"k": 5, "answer": "renewable or non-renewable", "latency_ms": 1672.2795963287354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3636}, "6": {"k": 6, "answer": "renewable or non-renewable", "latency_ms": 1546.3299751281738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4314}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "New life and fertility", "latency_ms": 540.3332710266113, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1407.886266708374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Parental devotion", "latency_ms": 1211.8659019470215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "parental devotion", "latency_ms": 982.2030067443848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "parental devotion", "latency_ms": 936.2702369689941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "Parental devotion", "latency_ms": 917.9677963256836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3081}, "6": {"k": 6, "answer": "parental devotion", "latency_ms": 1159.3539714813232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3727}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Virat Kohli", "latency_ms": 1014.1732692718506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "558", "latency_ms": 604.7842502593994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1205.8017253875732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "558", "latency_ms": 588.1969928741455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1765}, "4": {"k": 4, "answer": "558", "latency_ms": 1136.3978385925293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2384}, "5": {"k": 5, "answer": "558", "latency_ms": 647.7830410003662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3033}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1614.574909210205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "the antimicrobial action of metal ions.", "latency_ms": 2191.3068294525146, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals", "latency_ms": 868.4713840484619, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "biocidal effect of metals", "latency_ms": 1030.102014541626, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "biocidal effect of metals", "latency_ms": 1784.8231792449951, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2074}, "4": {"k": 4, "answer": "biocidal effect of metals", "latency_ms": 1071.0399150848389, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2765}, "5": {"k": 5, "answer": "biocidal effect of metals", "latency_ms": 1068.3577060699463, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3503}, "6": {"k": 6, "answer": "biocidal effect of metals", "latency_ms": 1131.9286823272705, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4193}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "Dustin Higgs", "latency_ms": 688.0221366882324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Coburn", "latency_ms": 981.8069934844971, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "James Coburn", "latency_ms": 944.7205066680908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Ronald Wolfe", "latency_ms": 1090.733289718628, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "James Coburn", "latency_ms": 1203.5412788391113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1244.8234558105469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3187}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1448.4519958496094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3818}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the auction.", "latency_ms": 640.0337219238281, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "when they hold two \"touching honors\"", "latency_ms": 1449.6874809265137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 580}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 1719.9363708496094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1132}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 965.4068946838379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1704}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 1443.9365863800049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2308}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 995.0885772705078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2924}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 1410.3899002075195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3509}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Afghanistan", "latency_ms": 599.2183685302734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 1225.893259048462, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 699}, "2": {"k": 2, "answer": "Afghanistan", "latency_ms": 983.428955078125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1373}, "3": {"k": 3, "answer": "Afghanistan", "latency_ms": 523.923397064209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2069}, "4": {"k": 4, "answer": "Afghanistan", "latency_ms": 980.3235530853271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2775}, "5": {"k": 5, "answer": "Afghanistan", "latency_ms": 968.5027599334717, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3420}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 748.9542961120605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4149}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "Coagulation, Fibrin formation, Clot retraction", "latency_ms": 1786.41676902771, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 1940.5326843261719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1213.5004997253418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1337}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 974.0960597991943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1995}, "4": {"k": 4, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 2611.1810207366943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2689}, "5": {"k": 5, "answer": "primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 1886.073350906372, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3414}, "6": {"k": 6, "answer": "primary hemostasis, secondary hemostasis, and fibrin cross-linking", "latency_ms": 2295.3274250030518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4135}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "Sebastian Hunsinger", "latency_ms": 1105.0219535827637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Presley Smith", "latency_ms": 747.2734451293945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 698}, "2": {"k": 2, "answer": "Presley Smith", "latency_ms": 910.8655452728271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1362}, "3": {"k": 3, "answer": "Shirley Temple did not play, Presley Smith played Sunny", "latency_ms": 1985.8686923980713, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 2054}, "4": {"k": 4, "answer": "Presley Smith", "latency_ms": 974.3421077728271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2684}, "5": {"k": 5, "answer": "Presley Smith", "latency_ms": 985.8317375183105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3368}, "6": {"k": 6, "answer": "Shirley Temple did not play Sunny, Presley Smith did.", "latency_ms": 2333.855390548706, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 4050}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "20 November 1989", "latency_ms": 878.7617683410645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "20 November 1989", "latency_ms": 774.3163108825684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 959.7160816192627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 1247.8101253509521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1976}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 1054.2988777160645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2607}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 825.2193927764893, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3202}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 659.7239971160889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3869}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "2016", "latency_ms": 510.7407569885254, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "13 April 2016", "latency_ms": 1047.1031665802002, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "23 June 2016", "latency_ms": 828.2637596130371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1236}, "3": {"k": 3, "answer": "23 June 2016", "latency_ms": 1067.0294761657715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "23 June 2016", "latency_ms": 809.9527359008789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2502}, "5": {"k": 5, "answer": "23 June 2016", "latency_ms": 1012.7804279327393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3128}, "6": {"k": 6, "answer": "23 June 2016", "latency_ms": 795.7134246826172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3808}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 608.6993217468262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Burj Khalifa", "latency_ms": 803.6317825317383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 679}, "2": {"k": 2, "answer": "Burj Khalifa", "latency_ms": 809.0527057647705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1360}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 1124.5863437652588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2001}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 1047.1415519714355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2688}, "5": {"k": 5, "answer": "Burj Khalifa", "latency_ms": 863.8896942138672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3291}, "6": {"k": 6, "answer": "Burj Khalifa", "latency_ms": 1021.503210067749, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3982}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "Miranda Hart", "latency_ms": 541.5470600128174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1247.1182346343994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1189.7976398468018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1324}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 895.1914310455322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1100.3568172454834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1115.837574005127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3247}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1020.8978652954102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3827}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Montesquieu", "latency_ms": 1006.4117908477783, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montesquieu", "latency_ms": 1053.8749694824219, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 1070.7404613494873, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 1021.3260650634766, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2070}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 1207.6594829559326, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2751}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 1212.1200561523438, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3389}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 963.6151790618896, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4037}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Myles Garrett", "latency_ms": 940.0017261505127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Myles Garrett", "latency_ms": 922.1856594085693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Myles Garrett", "latency_ms": 1111.9751930236816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Myles Garrett", "latency_ms": 743.2482242584229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1843}, "4": {"k": 4, "answer": "Myles Garrett", "latency_ms": 946.2947845458984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2484}, "5": {"k": 5, "answer": "Myles Garrett", "latency_ms": 1187.288522720337, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3060}, "6": {"k": 6, "answer": "Myles Garrett", "latency_ms": 972.480058670044, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3662}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2063 BS", "latency_ms": 959.1357707977295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2063 BS", "latency_ms": 1004.0946006774902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 751}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1055.2287101745605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1409}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1166.8107509613037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1644.824743270874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2763}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1228.9273738861084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3408}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1250.067949295044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4120}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "Captain John Smith", "latency_ms": 1131.8142414093018, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sir Thomas Gates", "latency_ms": 1115.4475212097168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "Sir Thomas Gates", "latency_ms": 1224.825382232666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1296}, "3": {"k": 3, "answer": "John Smith", "latency_ms": 1107.7535152435303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1946}, "4": {"k": 4, "answer": "John Smith", "latency_ms": 941.3378238677979, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "John Smith", "latency_ms": 1162.2109413146973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3229}, "6": {"k": 6, "answer": "John Smith", "latency_ms": 999.4571208953857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3861}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "Parietal cells", "latency_ms": 1068.8879489898682, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parietal cells", "latency_ms": 572.0853805541992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 625}, "2": {"k": 2, "answer": "Parietal cells", "latency_ms": 1174.1290092468262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Parietal cells", "latency_ms": 1437.6800060272217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1803}, "4": {"k": 4, "answer": "Parietal cells", "latency_ms": 1001.2385845184326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2404}, "5": {"k": 5, "answer": "Parietal cells", "latency_ms": 1148.745059967041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3019}, "6": {"k": 6, "answer": "Parietal cells", "latency_ms": 1240.8881187438965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3729}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "Early morning", "latency_ms": 502.46119499206543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "second half of the sleep cycle", "latency_ms": 1369.4911003112793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 1488.6696338653564, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "4 a.m.", "latency_ms": 981.9445610046387, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2022}, "4": {"k": 4, "answer": "4 a.m.", "latency_ms": 1247.6434707641602, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2686}, "5": {"k": 5, "answer": "4 a.m.", "latency_ms": 1159.9481105804443, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3364}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 1257.9669952392578, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4038}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 440.4613971710205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Idaho", "latency_ms": 817.1675205230713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "Idaho", "latency_ms": 1160.7980728149414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "Idaho", "latency_ms": 943.6874389648438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2028}, "4": {"k": 4, "answer": "Idaho", "latency_ms": 1168.997049331665, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2730}, "5": {"k": 5, "answer": "Idaho", "latency_ms": 1001.7304420471191, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3391}, "6": {"k": 6, "answer": "Idaho", "latency_ms": 954.883337020874, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4015}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales", "latency_ms": 4584.91587638855, "em": 0.0, "f1": 0.43478260869565216, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1221.2185859680176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1282.120704650879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1334.1717720031738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1958}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1262.8376483917236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2626}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1041.8856143951416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3272}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 956.3994407653809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3934}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 705.2881717681885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "undergone a modulation", "latency_ms": 1214.9319648742676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "undergone a modulation", "latency_ms": 1137.1591091156006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "modulated", "latency_ms": 884.1688632965088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1973}, "4": {"k": 4, "answer": "modulated", "latency_ms": 604.6481132507324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "modulated", "latency_ms": 1113.8098239898682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "modulated", "latency_ms": 701.8325328826904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3779}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Male citizens", "latency_ms": 692.9500102996826, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roman citizens, patricians and plebeians.", "latency_ms": 2550.4398345947266, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 668}, "2": {"k": 2, "answer": "Roman citizens, patricians and plebeians.", "latency_ms": 2344.5956707000732, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1307}, "3": {"k": 3, "answer": "Roman citizens", "latency_ms": 979.2959690093994, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2006}, "4": {"k": 4, "answer": "Roman citizens", "latency_ms": 966.0892486572266, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2595}, "5": {"k": 5, "answer": "Roman citizens, patricians and plebeians.", "latency_ms": 2507.4620246887207, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3237}, "6": {"k": 6, "answer": "Roman citizens, patricians and plebeians, adult male citizens.", "latency_ms": 2932.626962661743, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3917}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1278.005838394165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "9 April 2019", "latency_ms": 1419.0928936004639, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "9 April 2019", "latency_ms": 1288.4721755981445, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "9 April 2019", "latency_ms": 1410.799503326416, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "9 April 2019", "latency_ms": 1483.0632209777832, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "9 April 2019", "latency_ms": 1190.1483535766602, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "9 April 2019", "latency_ms": 1332.730770111084, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3810}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "100 parts of blood", "latency_ms": 819.0538883209229, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "volume of blood or mass of blood", "latency_ms": 1820.0085163116455, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "volume of blood or mass of blood", "latency_ms": 1817.0816898345947, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "volume of blood or mass of blood", "latency_ms": 1257.4384212493896, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "volume of blood or mass of blood", "latency_ms": 1585.4253768920898, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2596}, "5": {"k": 5, "answer": "volume of blood or mass of blood", "latency_ms": 1688.5309219360352, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3239}, "6": {"k": 6, "answer": "volume of blood or mass of blood", "latency_ms": 1983.6504459381104, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3854}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "Icarus", "latency_ms": 533.3898067474365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Icarus", "latency_ms": 1250.915288925171, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "Icarus", "latency_ms": 754.6710968017578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Icarus", "latency_ms": 1090.92378616333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Icarus", "latency_ms": 1226.2303829193115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2409}, "5": {"k": 5, "answer": "Icarus", "latency_ms": 1171.7138290405273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3006}, "6": {"k": 6, "answer": "Icarus", "latency_ms": 1007.7216625213623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3643}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "September 16, 1979", "latency_ms": 1362.429141998291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "January 1980", "latency_ms": 1016.5252685546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "1979", "latency_ms": 918.3909893035889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1146}, "3": {"k": 3, "answer": "1979", "latency_ms": 895.4429626464844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1802}, "4": {"k": 4, "answer": "1979", "latency_ms": 1111.1814975738525, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2419}, "5": {"k": 5, "answer": "September 16, 1979", "latency_ms": 2190.5834674835205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3041}, "6": {"k": 6, "answer": "1979", "latency_ms": 720.689058303833, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3688}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 am", "latency_ms": 826.3466358184814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1293.5972213745117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "2 April 1986", "latency_ms": 1435.279369354248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "2 April 1986", "latency_ms": 1516.7815685272217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "2 April 1986", "latency_ms": 1516.4132118225098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2591}, "5": {"k": 5, "answer": "2 April 1986", "latency_ms": 1232.9328060150146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3229}, "6": {"k": 6, "answer": "2 April 1986", "latency_ms": 1426.4414310455322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3869}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "Tiffany Coyne", "latency_ms": 828.242301940918, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Carol Merrill", "latency_ms": 932.1432113647461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Carol Merrill", "latency_ms": 444.87547874450684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 957.6823711395264, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 1238.2957935333252, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2417}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 1039.2322540283203, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2993}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 1169.6913242340088, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3637}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "Yankees, Braves, Reds, Giants", "latency_ms": 1331.2954902648926, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 2282.118320465088, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 2022.1760272979736, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1269}, "3": {"k": 3, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 2402.592182159424, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 2621.1860179901123, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 2150.3145694732666, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3065}, "6": {"k": 6, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 2339.972972869873, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3708}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "2.187 billion dollars", "latency_ms": 1387.4962329864502, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$343.4 million", "latency_ms": 1270.9834575653076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "$2 billion", "latency_ms": 936.643123626709, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "$1.84 billion", "latency_ms": 1338.7479782104492, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "$1.84 billion", "latency_ms": 1288.5351181030273, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2581}, "5": {"k": 5, "answer": "$2 billion", "latency_ms": 1177.8841018676758, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3208}, "6": {"k": 6, "answer": "$1.84 billion", "latency_ms": 1547.2991466522217, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3819}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1007.1723461151123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 986.8452548980713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1248.7947940826416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 558.8829517364502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1288.0022525787354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1783.1127643585205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3135}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1271.0418701171875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3768}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark", "latency_ms": 910.0892543792725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1080.6143283843994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 674.9711036682129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Norway", "latency_ms": 1160.0255966186523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1862}, "4": {"k": 4, "answer": "Norway", "latency_ms": 936.9041919708252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2457}, "5": {"k": 5, "answer": "Norway", "latency_ms": 707.5815200805664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3037}, "6": {"k": 6, "answer": "Norway and Denmark", "latency_ms": 1125.1466274261475, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3655}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "Pres√©pio", "latency_ms": 938.9939308166504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Puritina", "latency_ms": 1465.3809070587158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Puritina", "latency_ms": 1225.9771823883057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Puritina", "latency_ms": 719.7442054748535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "Christmas Tree", "latency_ms": 1319.5390701293945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2541}, "5": {"k": 5, "answer": "Christmas Tree", "latency_ms": 869.8430061340332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3193}, "6": {"k": 6, "answer": "Puritina", "latency_ms": 1045.3598499298096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3913}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "Patrick Swayze", "latency_ms": 1090.2631282806396, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Swayze", "latency_ms": 921.1850166320801, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Swayze", "latency_ms": 1146.7061042785645, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Swayze", "latency_ms": 1208.0020904541016, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "Swayze", "latency_ms": 796.2474822998047, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Swayze", "latency_ms": 1196.5053081512451, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "Swayze", "latency_ms": 678.6191463470459, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3730}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Pittsburgh", "latency_ms": 1035.60471534729, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sweden, US, 60 countries", "latency_ms": 2101.8893718719482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1660.3844165802002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 780.3540229797363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1173.2540130615234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2605}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1141.1993503570557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3294}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1249.7098445892334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3902}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1704", "latency_ms": 700.9978294372559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1006.0622692108154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "after 1901", "latency_ms": 1299.78346824646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1354}, "3": {"k": 3, "answer": "after 1901", "latency_ms": 821.4325904846191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2022}, "4": {"k": 4, "answer": "after 1901", "latency_ms": 1154.0727615356445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2674}, "5": {"k": 5, "answer": "1901", "latency_ms": 830.4305076599121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3396}, "6": {"k": 6, "answer": "1905", "latency_ms": 875.2319812774658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4057}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier Fern√°ndez", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Yuzuru Hanyu", "latency_ms": 1079.848051071167, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yuzuru Hanyu", "latency_ms": 1049.9579906463623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Yuzuru Hanyu", "latency_ms": 1575.6971836090088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Yuzuru Hanyu", "latency_ms": 1137.2132301330566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1904}, "4": {"k": 4, "answer": "Yuzuru Hanyu", "latency_ms": 1982.8155040740967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2468}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 1334.665298461914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 1881.8359375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3756}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "Password recovery and cracking.", "latency_ms": 1205.6477069854736, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Password recovery", "latency_ms": 729.1014194488525, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "password recovery", "latency_ms": 928.6017417907715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1391}, "3": {"k": 3, "answer": "Password recovery", "latency_ms": 1201.507329940796, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Password recovery tool", "latency_ms": 1199.0907192230225, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2619}, "5": {"k": 5, "answer": "Password recovery", "latency_ms": 974.0705490112305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3261}, "6": {"k": 6, "answer": "Password recovery tool", "latency_ms": 1029.7298431396484, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3840}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1024.4932174682617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "C. Vidyasagar Rao", "latency_ms": 1268.1381702423096, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "C. Vidyasagar Rao", "latency_ms": 1578.83620262146, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 1878.199815750122, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 1204.7228813171387, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2588}, "5": {"k": 5, "answer": "C. Vidyasagar Rao", "latency_ms": 1844.604253768921, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3242}, "6": {"k": 6, "answer": "C. Vidyasagar Rao", "latency_ms": 1195.8012580871582, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3899}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "Channel 15", "latency_ms": 935.513973236084, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "15", "latency_ms": 905.4887294769287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 682}, "2": {"k": 2, "answer": "15", "latency_ms": 689.441442489624, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "15", "latency_ms": 885.443925857544, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1919}, "4": {"k": 4, "answer": "15", "latency_ms": 447.62468338012695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2565}, "5": {"k": 5, "answer": "15", "latency_ms": 856.7676544189453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3252}, "6": {"k": 6, "answer": "15", "latency_ms": 656.2700271606445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Claudia Wells", "latency_ms": 1303.0588626861572, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elisabeth Shue", "latency_ms": 1166.4669513702393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Claudia Wells", "latency_ms": 1077.2860050201416, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "Claudia Wells", "latency_ms": 1235.4958057403564, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1777}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 1012.7818584442139, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2408}, "5": {"k": 5, "answer": "Claudia Wells", "latency_ms": 1020.6072330474854, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "Claudia Wells", "latency_ms": 1265.4991149902344, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3629}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 390.75303077697754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "London, United Kingdom", "latency_ms": 1041.1760807037354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 1206.4754962921143, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 714.0786647796631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1955}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 1428.553819656372, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2581}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 1026.4692306518555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3235}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 1431.9992065429688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3909}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The White House Chef", "latency_ms": 795.5162525177002, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Executive Chef", "latency_ms": 707.5247764587402, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "White House Executive Chef", "latency_ms": 1176.2597560882568, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "White House Executive Chef", "latency_ms": 1207.9527378082275, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1967}, "4": {"k": 4, "answer": "White House Executive Chef", "latency_ms": 1695.9812641143799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "White House Executive Chef", "latency_ms": 1058.931827545166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3150}, "6": {"k": 6, "answer": "White House Executive Chef", "latency_ms": 1021.9311714172363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3783}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 809.4885349273682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1043.5547828674316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1230.649471282959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Nagendra Singh", "latency_ms": 977.4982929229736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1821}, "4": {"k": 4, "answer": "B. N. Rao", "latency_ms": 1112.1163368225098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2391}, "5": {"k": 5, "answer": "B. N. Rao", "latency_ms": 1361.0236644744873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3019}, "6": {"k": 6, "answer": "B. N. Rao", "latency_ms": 1088.8938903808594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3672}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 545.3794002532959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "British Columbia", "latency_ms": 857.72705078125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "British Columbia", "latency_ms": 661.8046760559082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1305}, "3": {"k": 3, "answer": "British Columbia", "latency_ms": 657.7479839324951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1960}, "4": {"k": 4, "answer": "British Columbia", "latency_ms": 688.0660057067871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2605}, "5": {"k": 5, "answer": "British Columbia", "latency_ms": 874.7856616973877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3252}, "6": {"k": 6, "answer": "British Columbia", "latency_ms": 499.91369247436523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3932}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 744.8959350585938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 11, 2018", "latency_ms": 888.8533115386963, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "October 11, 2018", "latency_ms": 1552.215576171875, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 989.5186424255371, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 1470.402479171753, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2654}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 1166.2695407867432, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3378}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 1455.2578926086426, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4032}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Jodie Sweetin", "latency_ms": 1181.7364692687988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 802.6995658874512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 517.1175003051758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 978.7113666534424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "Stephanie", "latency_ms": 979.3379306793213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 501.3465881347656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "Stephanie", "latency_ms": 487.93864250183105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "Millennium Tower", "latency_ms": 834.3536853790283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Millennium Tower", "latency_ms": 954.8618793487549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 1224.0188121795654, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1345}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 1459.0544700622559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2031}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 1228.5730838775635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2688}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 997.5776672363281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3347}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 836.1866474151611, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4043}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 424.24678802490234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 1153.0635356903076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1258.6100101470947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1215.3756618499756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1819}, "4": {"k": 4, "answer": "2015", "latency_ms": 860.1274490356445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2429}, "5": {"k": 5, "answer": "2015", "latency_ms": 902.4944305419922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3080}, "6": {"k": 6, "answer": "2015", "latency_ms": 647.9246616363525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3703}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "John Harlan", "latency_ms": 763.9141082763672, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Marshall Harlan", "latency_ms": 1249.5672702789307, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "John Marshall Harlan", "latency_ms": 1051.0997772216797, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "John Marshall Harlan", "latency_ms": 1178.1988143920898, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2080}, "4": {"k": 4, "answer": "John Marshall Harlan", "latency_ms": 1134.8764896392822, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2774}, "5": {"k": 5, "answer": "John Marshall Harlan", "latency_ms": 1121.1504936218262, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3453}, "6": {"k": 6, "answer": "John Marshall Harlan", "latency_ms": 708.7318897247314, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4030}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Tyrann Mathieu", "latency_ms": 809.0548515319824, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tyrann Mathieu", "latency_ms": 1298.7794876098633, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 1003.0548572540283, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 1066.8962001800537, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 1153.113603591919, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 1552.7119636535645, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 1343.573808670044, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3869}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "44", "latency_ms": 744.6253299713135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "six", "latency_ms": 648.3309268951416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "6", "latency_ms": 944.058895111084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1318}, "3": {"k": 3, "answer": "6", "latency_ms": 692.3141479492188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1991}, "4": {"k": 4, "answer": "six episodes", "latency_ms": 693.6883926391602, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2698}, "5": {"k": 5, "answer": "Six episodes", "latency_ms": 981.8003177642822, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3373}, "6": {"k": 6, "answer": "6 episodes", "latency_ms": 1228.461742401123, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4022}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul Ba√ºmer's", "latency_ms": 1156.069040298462, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a German infantryman", "latency_ms": 971.8708992004395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "a German infantryman", "latency_ms": 1464.231252670288, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "a German infantryman", "latency_ms": 1162.9807949066162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1966}, "4": {"k": 4, "answer": "a German infantryman", "latency_ms": 803.347110748291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "German infantryman", "latency_ms": 727.3130416870117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "German infantryman", "latency_ms": 745.8727359771729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3798}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris", "latency_ms": 662.7545356750488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Henri Young", "latency_ms": 741.386890411377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Frank Morris, John Anglin, Clarence Anglin", "latency_ms": 1683.0015182495117, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1308}, "3": {"k": 3, "answer": "John Paul Scott", "latency_ms": 924.9372482299805, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "John Paul Scott", "latency_ms": 782.1128368377686, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2632}, "5": {"k": 5, "answer": "John Paul Scott", "latency_ms": 916.6834354400635, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3307}, "6": {"k": 6, "answer": "John Paul Scott", "latency_ms": 649.8582363128662, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3933}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF programs.", "latency_ms": 811.4416599273682, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF", "latency_ms": 499.15409088134766, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 718}, "2": {"k": 2, "answer": "UNICEF", "latency_ms": 926.7899990081787, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1448}, "3": {"k": 3, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world", "latency_ms": 2122.159957885742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2106}, "4": {"k": 4, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world", "latency_ms": 2480.40509223938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2795}, "5": {"k": 5, "answer": "UNICEF's global programming", "latency_ms": 1449.6581554412842, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3489}, "6": {"k": 6, "answer": "UNICEF's global programming", "latency_ms": 1384.1795921325684, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4214}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Tablet", "latency_ms": 506.300687789917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edge of the coin", "latency_ms": 768.4717178344727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Edge of the coin", "latency_ms": 1182.544469833374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1334}, "3": {"k": 3, "answer": "Edge of the coin", "latency_ms": 941.0254955291748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1956}, "4": {"k": 4, "answer": "Not mentioned", "latency_ms": 763.0164623260498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2548}, "5": {"k": 5, "answer": "Not mentioned", "latency_ms": 1175.4357814788818, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3226}, "6": {"k": 6, "answer": "Below the statue", "latency_ms": 988.2638454437256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3876}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "Milan-Cortina, Sapporo", "latency_ms": 1845.5450534820557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1256.7250728607178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 993.9191341400146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1092.069387435913, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "Beijing, China and unknown", "latency_ms": 1429.0239810943604, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2439}, "5": {"k": 5, "answer": "Beijing, China; Abu Dhabi is incorrect as Abu Dhabi is for Special Olympics, the next Winter Olympics after Beijing is not specified.", "latency_ms": 4429.038763046265, "em": 0.0, "f1": 0.0909090909090909, "containment": 1.0, "context_chars": 3031}, "6": {"k": 6, "answer": "Beijing, China; Abu Dhabi is incorrect as Abu Dhabi is for Special Olympics, the next Winter Olympics after Beijing is not specified. \n Beijing, China", "latency_ms": 4572.449207305908, "em": 0.0, "f1": 0.08333333333333331, "containment": 1.0, "context_chars": 3641}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "1981", "latency_ms": 415.1113033294678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1997", "latency_ms": 1092.3731327056885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "1997", "latency_ms": 880.2168369293213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "1997", "latency_ms": 665.3962135314941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1802}, "4": {"k": 4, "answer": "1997", "latency_ms": 936.1610412597656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2441}, "5": {"k": 5, "answer": "1997", "latency_ms": 446.6261863708496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3040}, "6": {"k": 6, "answer": "1997", "latency_ms": 679.7497272491455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3694}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "Stone Gothic arch bridge", "latency_ms": 1018.8446044921875, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rolling bascule bridge", "latency_ms": 2024.829387664795, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Stone Bridge", "latency_ms": 932.3849678039551, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "Stone Bridge", "latency_ms": 930.1650524139404, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Historic bridge", "latency_ms": 518.16725730896, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2615}, "5": {"k": 5, "answer": "Historic bridge", "latency_ms": 895.6530094146729, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3316}, "6": {"k": 6, "answer": "Historic bridge", "latency_ms": 922.1503734588623, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4009}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The Autocrat", "latency_ms": 703.9408683776855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One person", "latency_ms": 892.1172618865967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "One person", "latency_ms": 906.5260887145996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1323}, "3": {"k": 3, "answer": "One person", "latency_ms": 699.0566253662109, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1987}, "4": {"k": 4, "answer": "One person", "latency_ms": 485.6832027435303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2722}, "5": {"k": 5, "answer": "One person", "latency_ms": 725.6951332092285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3364}, "6": {"k": 6, "answer": "One person", "latency_ms": 908.4477424621582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4034}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "Affluence", "latency_ms": 831.8493366241455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Economic expansion", "latency_ms": 704.5304775238037, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 726}, "2": {"k": 2, "answer": "other-directedness", "latency_ms": 711.3358974456787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1442}, "3": {"k": 3, "answer": "other-directedness", "latency_ms": 465.79527854919434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2050}, "4": {"k": 4, "answer": "other-directedness", "latency_ms": 760.124683380127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2759}, "5": {"k": 5, "answer": "Consumer culture", "latency_ms": 669.475793838501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3484}, "6": {"k": 6, "answer": "Consumer culture", "latency_ms": 1416.1055088043213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4112}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "Counterclockwise", "latency_ms": 982.8372001647949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Counterclockwise", "latency_ms": 1434.450626373291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "Counterclockwise", "latency_ms": 1312.5159740447998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "Counterclockwise", "latency_ms": 960.7706069946289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1737}, "4": {"k": 4, "answer": "Counterclockwise", "latency_ms": 1021.3227272033691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2359}, "5": {"k": 5, "answer": "Counterclockwise", "latency_ms": 725.8765697479248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2966}, "6": {"k": 6, "answer": "Counterclockwise", "latency_ms": 1149.101734161377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3511}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Statue of Freedom", "latency_ms": 861.5748882293701, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Statue of Freedom", "latency_ms": 1218.5111045837402, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 555}, "2": {"k": 2, "answer": "Statue of Freedom", "latency_ms": 1307.9965114593506, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1177}, "3": {"k": 3, "answer": "Statue of Freedom", "latency_ms": 980.8328151702881, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "Statue of Freedom", "latency_ms": 1192.2063827514648, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2446}, "5": {"k": 5, "answer": "Statue of Freedom", "latency_ms": 1250.8337497711182, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3022}, "6": {"k": 6, "answer": "Statue of Freedom", "latency_ms": 1021.4622020721436, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3682}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "Taoyuan Leopards", "latency_ms": 1149.0421295166016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington Wizards", "latency_ms": 1176.9952774047852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "Washington Wizards", "latency_ms": 1156.2583446502686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "Washington Wizards", "latency_ms": 402.59408950805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Washington Wizards", "latency_ms": 1019.4804668426514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2490}, "5": {"k": 5, "answer": "Washington Wizards", "latency_ms": 952.864408493042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3050}, "6": {"k": 6, "answer": "Washington Wizards", "latency_ms": 914.9794578552246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3644}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1014.0419006347656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mysterio", "latency_ms": 1183.7151050567627, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Rey Mysterio", "latency_ms": 1734.450101852417, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1191}, "3": {"k": 3, "answer": "Mysterio", "latency_ms": 1002.6533603668213, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1801}, "4": {"k": 4, "answer": "Mysterio", "latency_ms": 963.4952545166016, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2426}, "5": {"k": 5, "answer": "Mysterio", "latency_ms": 1077.5489807128906, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3027}, "6": {"k": 6, "answer": "Rey Mysterio", "latency_ms": 1544.2225933074951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 702.4011611938477, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake Oahe", "latency_ms": 1630.5789947509766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 601}, "2": {"k": 2, "answer": "Lake Oahe", "latency_ms": 1276.4134407043457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Lake Oahe", "latency_ms": 1478.2583713531494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1818}, "4": {"k": 4, "answer": "Lake Oahe", "latency_ms": 1230.4811477661133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2428}, "5": {"k": 5, "answer": "Lake Oahe", "latency_ms": 1223.2739925384521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3093}, "6": {"k": 6, "answer": "Lake Oahe", "latency_ms": 1229.1297912597656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3723}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Tagore", "latency_ms": 238.8608455657959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tagore", "latency_ms": 1089.8795127868652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 585}, "2": {"k": 2, "answer": "Tagore", "latency_ms": 944.211483001709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tagore", "latency_ms": 926.8708229064941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1860}, "4": {"k": 4, "answer": "Tagore", "latency_ms": 653.8577079772949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2481}, "5": {"k": 5, "answer": "Tagore", "latency_ms": 1132.2104930877686, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3167}, "6": {"k": 6, "answer": "Tagore", "latency_ms": 1261.2833976745605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3819}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "George H.W. Bush", "latency_ms": 1081.315517425537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Geraldine Ferraro", "latency_ms": 1110.525131225586, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 682}, "2": {"k": 2, "answer": "Geraldine Ferraro", "latency_ms": 1470.5309867858887, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1348}, "3": {"k": 3, "answer": "Geraldine Ferraro", "latency_ms": 1603.4698486328125, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2037}, "4": {"k": 4, "answer": "Geraldine Ferraro", "latency_ms": 1320.9726810455322, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2752}, "5": {"k": 5, "answer": "Geraldine Ferraro", "latency_ms": 1053.3828735351562, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3448}, "6": {"k": 6, "answer": "Geraldine Ferraro", "latency_ms": 1310.302734375, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4123}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "American Rock Salt mine, Livingston County, New York", "latency_ms": 1796.3979244232178, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Groveland", "latency_ms": 1625.3857612609863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners", "latency_ms": 1036.923885345459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Hampton Corners", "latency_ms": 1429.0015697479248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Goderich, Ontario", "latency_ms": 1413.4678840637207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2570}, "5": {"k": 5, "answer": "Hampton Corners", "latency_ms": 980.9131622314453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3178}, "6": {"k": 6, "answer": "Goderich, Ontario", "latency_ms": 1477.2310256958008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3804}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 514.5788192749023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 759.8145008087158, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 588}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 1124.3221759796143, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1200}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 1225.9430885314941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1757}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 1177.0915985107422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2377}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 1114.213466644287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2997}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 635.2944374084473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3659}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Meghalaya", "latency_ms": 1033.9226722717285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1035.7105731964111, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1100.417137145996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1294}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1885.9262466430664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1246.3383674621582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2613}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1493.6881065368652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3264}, "6": {"k": 6, "answer": "Uttar Dinajpur", "latency_ms": 1429.8374652862549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3911}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Kanpur", "latency_ms": 735.8713150024414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ludhiana", "latency_ms": 1167.7172183990479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 565}, "2": {"k": 2, "answer": "Ludhiana", "latency_ms": 1096.2159633636475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "Kanpur", "latency_ms": 627.5804042816162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1831}, "4": {"k": 4, "answer": "Kanpur", "latency_ms": 1174.4301319122314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2412}, "5": {"k": 5, "answer": "Ludhiana", "latency_ms": 1226.9995212554932, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3109}, "6": {"k": 6, "answer": "Kanpur", "latency_ms": 908.95676612854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3702}}}
