{"qid": "5306300389470118812", "question": "what was the religion in persia before islam", "gold_answers": ["the Zoroastrian religion", "Zoroastrian"], "shots": {"0": {"k": 0, "answer": "Zoroastrianism", "latency_ms": 1256.0181617736816, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Zoroastrian", "latency_ms": 1320.2662467956543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 637}, "2": {"k": 2, "answer": "Zoroastrian", "latency_ms": 1250.3712177276611, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Zoroastrian", "latency_ms": 1015.8154964447021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1985}, "4": {"k": 4, "answer": "Zoroastrian", "latency_ms": 887.6693248748779, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2650}, "5": {"k": 5, "answer": "Zoroastrian", "latency_ms": 1024.0459442138672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3335}, "6": {"k": 6, "answer": "Zoroastrian", "latency_ms": 1315.887212753296, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3996}}}
{"qid": "4492088526674104172", "question": "why does kerosene oil rise up in the wick of lantern", "gold_answers": ["capillary action"], "shots": {"0": {"k": 0, "answer": "Capillary action", "latency_ms": 498.5160827636719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 965.4395580291748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Capillary action", "latency_ms": 1430.5365085601807, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Capillary action", "latency_ms": 826.7664909362793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1876}, "4": {"k": 4, "answer": "Capillary action", "latency_ms": 540.8120155334473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Capillary action", "latency_ms": 952.6410102844238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3112}, "6": {"k": 6, "answer": "Capillary action", "latency_ms": 979.6788692474365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "-4373262132142058334", "question": "mention the chemical change that proinsulin undergo to be able to act as mature insulin", "gold_answers": ["post translational modification"], "shots": {"0": {"k": 0, "answer": "Proteolytic cleavage", "latency_ms": 1166.705846786499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cleavage of C-peptide", "latency_ms": 2012.453317642212, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Cleavage", "latency_ms": 832.2315216064453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Cleavage", "latency_ms": 1012.5653743743896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "Cleavage of C-peptide", "latency_ms": 1461.4758491516113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "Cleavage of C-peptide", "latency_ms": 1199.8236179351807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3306}, "6": {"k": 6, "answer": "Cleavage of C-peptide", "latency_ms": 1640.7585144042969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3855}}}
{"qid": "-5298560410953979569", "question": "where does the sweetness of fruit come from", "gold_answers": ["Fructose , or fruit sugar", "Fructose"], "shots": {"0": {"k": 0, "answer": "Fructose", "latency_ms": 791.2936210632324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1238.511085510254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 677}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 790.9829616546631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1224.217414855957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1097.747802734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2653}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1273.9486694335938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1260.770320892334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3894}}}
{"qid": "4344648368832551136", "question": "an object that moves around an external axis is said to be", "gold_answers": ["orbit", "revolution or orbital revolution"], "shots": {"0": {"k": 0, "answer": "rotating", "latency_ms": 769.2687511444092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "revolving", "latency_ms": 1220.4070091247559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "in a revolution or orbital revolution", "latency_ms": 1243.9968585968018, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 1206}, "3": {"k": 3, "answer": "in a revolution or orbital revolution", "latency_ms": 1530.8756828308105, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 1864}, "4": {"k": 4, "answer": "in a revolution or orbital revolution", "latency_ms": 1491.8789863586426, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 2543}, "5": {"k": 5, "answer": "in revolution or orbital revolution", "latency_ms": 1556.455135345459, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 3112}, "6": {"k": 6, "answer": "in revolution or orbital revolution", "latency_ms": 1044.6527004241943, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 3772}}}
{"qid": "-724426540432437711", "question": "what was the name of the plant on little shop of horrors", "gold_answers": ["Audrey II"], "shots": {"0": {"k": 0, "answer": "Audrey II", "latency_ms": 740.8394813537598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Audrey II", "latency_ms": 1237.2615337371826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Audrey II", "latency_ms": 1020.2276706695557, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1244}, "3": {"k": 3, "answer": "Audrey II", "latency_ms": 549.7848987579346, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "Audrey II", "latency_ms": 1181.584358215332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2538}, "5": {"k": 5, "answer": "Audrey II", "latency_ms": 814.5449161529541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3191}, "6": {"k": 6, "answer": "Audrey II", "latency_ms": 1229.9365997314453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3833}}}
{"qid": "-5541610970112826260", "question": "who signed the declaration of independence for maryland", "gold_answers": ["Samuel Chase", "Charles Carroll of Carrollton", "Thomas Stone", "William Paca"], "shots": {"0": {"k": 0, "answer": "Samuel Chase", "latency_ms": 1071.5746879577637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 2604.9447059631348, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 3428.7610054016113, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 1263}, "3": {"k": 3, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 2917.370557785034, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 2134.669065475464, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 2844.2187309265137, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 3263}, "6": {"k": 6, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton.", "latency_ms": 2571.0864067077637, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 3926}}}
{"qid": "-86997217831791339", "question": "when does wonder woman come out on blue ray", "gold_answers": ["September 19 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1034.3225002288818, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 19, 2017", "latency_ms": 1444.211721420288, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "September 19, 2017", "latency_ms": 1402.2862911224365, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "September 19, 2017", "latency_ms": 1840.7890796661377, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1872}, "4": {"k": 4, "answer": "September 19, 2017", "latency_ms": 873.1050491333008, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "September 19, 2017", "latency_ms": 1049.741506576538, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3144}, "6": {"k": 6, "answer": "September 19, 2017", "latency_ms": 1089.4265174865723, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "-8062812506672279762", "question": "what nba team did derrick rose play for", "gold_answers": ["New York Knicks", "Minnesota Timberwolves", "Chicago Bulls", "Cleveland Cavaliers"], "shots": {"0": {"k": 0, "answer": "Chicago Bulls", "latency_ms": 780.6310653686523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chicago Bulls, Minnesota Timberwolves", "latency_ms": 931.5316677093506, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 630}, "2": {"k": 2, "answer": "Minnesota Timberwolves, Chicago Bulls, Cleveland Cavaliers, Boston Celtics", "latency_ms": 1693.8550472259521, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1238}, "3": {"k": 3, "answer": "Minnesota Timberwolves, Chicago Bulls, Cleveland Cavaliers, Boston Celtics", "latency_ms": 2272.3729610443115, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1808}, "4": {"k": 4, "answer": "Minnesota Timberwolves, Chicago Bulls, Cleveland Cavaliers", "latency_ms": 1672.7173328399658, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2463}, "5": {"k": 5, "answer": "Chicago Bulls, Minnesota Timberwolves, Cleveland Cavaliers, New York Knicks", "latency_ms": 2393.017292022705, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3066}, "6": {"k": 6, "answer": "Chicago Bulls, Minnesota Timberwolves, Cleveland Cavaliers, New York Knicks", "latency_ms": 2490.1351928710938, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3667}}}
{"qid": "7933002036740390435", "question": "where did the term liberal arts come from", "gold_answers": ["the Roman Empire"], "shots": {"0": {"k": 0, "answer": "Latin term \"liberalis\"", "latency_ms": 1511.2793445587158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roman Empire", "latency_ms": 642.8697109222412, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Roman Empire", "latency_ms": 942.6836967468262, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1351}, "3": {"k": 3, "answer": "Roman Empire", "latency_ms": 923.7611293792725, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2046}, "4": {"k": 4, "answer": "Roman Empire", "latency_ms": 476.7131805419922, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2760}, "5": {"k": 5, "answer": "Roman Empire", "latency_ms": 657.9835414886475, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3467}, "6": {"k": 6, "answer": "Roman Empire", "latency_ms": 680.4015636444092, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4188}}}
{"qid": "-2991400700385487821", "question": "who heads the executive department of west virginia government", "gold_answers": ["the Governor of West Virginia", "the governor of West Virginia", "Jim Justice"], "shots": {"0": {"k": 0, "answer": "The Governor", "latency_ms": 495.4395294189453, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The governor", "latency_ms": 643.9366340637207, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "The Governor of West Virginia", "latency_ms": 828.5813331604004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "The Governor of West Virginia", "latency_ms": 1056.9524765014648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1911}, "4": {"k": 4, "answer": "The Governor of West Virginia", "latency_ms": 788.860559463501, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2616}, "5": {"k": 5, "answer": "The Governor of West Virginia", "latency_ms": 1020.7605361938477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3308}, "6": {"k": 6, "answer": "The Governor of West Virginia", "latency_ms": 812.7355575561523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4002}}}
{"qid": "-9186689755642837558", "question": "how long is the bridge between new brunswick and prince edward island", "gold_answers": ["12.9 - kilometre"], "shots": {"0": {"k": 0, "answer": "13 kilometers", "latency_ms": 250.6396770477295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 782.5992107391357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 686}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 713.9720916748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1050.3599643707275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2032}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 758.0833435058594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2691}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 536.3245010375977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3279}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 969.5227146148682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3940}}}
{"qid": "8029901619424338449", "question": "when did the uk and us become allies", "gold_answers": ["1940", "Since 1940"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 590.1319980621338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "After the end of the Second World War in 1945", "latency_ms": 1349.6105670928955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "After the end of the Second World War in 1945", "latency_ms": 1347.6924896240234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "After the end of the Second World War in 1945", "latency_ms": 1362.0316982269287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "After the end of the Second World War in 1945", "latency_ms": 1410.5865955352783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "After the end of the Second World War in 1945", "latency_ms": 1348.7498760223389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3132}, "6": {"k": 6, "answer": "After the end of the Second World War in 1945", "latency_ms": 1353.332281112671, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "4828649525820722736", "question": "who sang the theme song for the man with the golden gun", "gold_answers": ["Lulu"], "shots": {"0": {"k": 0, "answer": "Lulu", "latency_ms": 444.6115493774414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lulu", "latency_ms": 638.4854316711426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 582}, "2": {"k": 2, "answer": "Lulu", "latency_ms": 499.5694160461426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Lulu", "latency_ms": 750.0970363616943, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1810}, "4": {"k": 4, "answer": "Lulu", "latency_ms": 938.9064311981201, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2423}, "5": {"k": 5, "answer": "Lulu", "latency_ms": 939.6531581878662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3016}, "6": {"k": 6, "answer": "Lulu", "latency_ms": 712.6483917236328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3686}}}
{"qid": "-7924663090486742985", "question": "american horror story freak show girl kidnapped by clown", "gold_answers": ["Bonnie Lipton"], "shots": {"0": {"k": 0, "answer": "Penny", "latency_ms": 806.9665431976318, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Twisty", "latency_ms": 1005.8639049530029, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "Twisty", "latency_ms": 964.9090766906738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Twisty", "latency_ms": 518.7036991119385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Twisty", "latency_ms": 997.8950023651123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2582}, "5": {"k": 5, "answer": "the girl", "latency_ms": 873.4567165374756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3202}, "6": {"k": 6, "answer": "Twisty", "latency_ms": 789.8344993591309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3823}}}
{"qid": "-360675773049242516", "question": "the probability of making a type i error when retaining ho at the .05 level of significance is", "gold_answers": ["5 %"], "shots": {"0": {"k": 0, "answer": "0.05", "latency_ms": 653.3353328704834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0.05", "latency_ms": 844.977855682373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "0.05", "latency_ms": 716.7036533355713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1151}, "3": {"k": 3, "answer": "0.05", "latency_ms": 707.5085639953613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "0.05", "latency_ms": 775.8133411407471, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2354}, "5": {"k": 5, "answer": "0.05", "latency_ms": 724.229097366333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2946}, "6": {"k": 6, "answer": "0.05", "latency_ms": 507.28797912597656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3538}}}
{"qid": "5819386267283467034", "question": "what year did the us hockey team won the olympics", "gold_answers": ["1960", "1980", "1960 and 1980"], "shots": {"0": {"k": 0, "answer": "1980", "latency_ms": 730.3359508514404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1960, 1980", "latency_ms": 1103.442668914795, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "1960, 1980", "latency_ms": 844.3458080291748, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1338}, "3": {"k": 3, "answer": "1960, 1980", "latency_ms": 1005.5716037750244, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1935}, "4": {"k": 4, "answer": "1960, 1980", "latency_ms": 1119.2574501037598, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "1960, 1980", "latency_ms": 1190.1016235351562, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3219}, "6": {"k": 6, "answer": "1960, 1980", "latency_ms": 953.2537460327148, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3843}}}
{"qid": "3916394566028297311", "question": "who wrote it's a long long way to pasadena", "gold_answers": ["Harry Vanda", "John Young", "David Hemmings", "George Young"], "shots": {"0": {"k": 0, "answer": "Albert E. Brumley", "latency_ms": 1539.9115085601807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1217.7724838256836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1475.4488468170166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1164.2699241638184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 885.7448101043701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 784.6128940582275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3201}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1173.5124588012695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3837}}}
{"qid": "-2432292250757146771", "question": "who wrote the song i hate you i love you", "gold_answers": ["Angel Benitez", "Olivia O'Brien", "Garrett Nash"], "shots": {"0": {"k": 0, "answer": "Gnash", "latency_ms": 1003.3581256866455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ne-Yo and StarGate", "latency_ms": 1551.1369705200195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Ne-Yo and StarGate", "latency_ms": 1540.9483909606934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Ne-Yo and StarGate", "latency_ms": 894.6690559387207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1803}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1411.6740226745605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2431}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 743.3841228485107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3072}, "6": {"k": 6, "answer": "Celine Dion and others", "latency_ms": 1300.4114627838135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3660}}}
{"qid": "2393389448844632496", "question": "what is loihi and where does it originate from", "gold_answers": ["from the Hawaii hotspot"], "shots": {"0": {"k": 0, "answer": "Loihi, Hawaii", "latency_ms": 888.8134956359863, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Intel's self-learning neuromorphic chip, named after the Hawaiian seamount Loihi", "latency_ms": 2279.351234436035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 723}, "2": {"k": 2, "answer": "Hawaiian seamount Loihi", "latency_ms": 2146.8334197998047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1403}, "3": {"k": 3, "answer": "Hawaiian seamount Loihi", "latency_ms": 1694.8294639587402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2072}, "4": {"k": 4, "answer": "Hawaiian seamount Loihi", "latency_ms": 1447.9484558105469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2750}, "5": {"k": 5, "answer": "Loihi, Hawaii", "latency_ms": 1494.8575496673584, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3404}, "6": {"k": 6, "answer": "Hawaiian seamount Loihi", "latency_ms": 1503.9479732513428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4077}}}
{"qid": "-6677440871585683891", "question": "who rebuilt the temple after the babylonian captivity", "gold_answers": ["Herod"], "shots": {"0": {"k": 0, "answer": "Zerubbabel", "latency_ms": 734.2383861541748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1189.4259452819824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "the Jews", "latency_ms": 720.3836441040039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1171}, "3": {"k": 3, "answer": "the Jews", "latency_ms": 931.1504364013672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1822}, "4": {"k": 4, "answer": "The Jews who had returned from the Babylonian captivity", "latency_ms": 2050.0171184539795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "Jews who had returned from the Babylonian captivity", "latency_ms": 2007.645845413208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3096}, "6": {"k": 6, "answer": "Jews who had returned from the Babylonian captivity", "latency_ms": 2491.1091327667236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3694}}}
{"qid": "-6750750235985613277", "question": "who was executed for being an american spy during the revolutionary war", "gold_answers": ["Nathan Hale"], "shots": {"0": {"k": 0, "answer": "Nathan Hale", "latency_ms": 316.5109157562256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nathan Hale", "latency_ms": 1128.978967666626, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Nathan Hale", "latency_ms": 1065.9115314483643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Nathan Hale", "latency_ms": 1126.1389255523682, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1884}, "4": {"k": 4, "answer": "Nathan Hale", "latency_ms": 648.113489151001, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Nathan Hale", "latency_ms": 1170.682430267334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Nathan Hale", "latency_ms": 950.0577449798584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3833}}}
{"qid": "8770209312170080158", "question": "who sang the song suddenly with olivia newton john", "gold_answers": ["Cliff Richard"], "shots": {"0": {"k": 0, "answer": "Cliff Richard", "latency_ms": 558.3500862121582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cliff Richard", "latency_ms": 924.5898723602295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "Cliff Richard", "latency_ms": 971.9746112823486, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1270}, "3": {"k": 3, "answer": "Cliff Richard", "latency_ms": 756.4971446990967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Cliff Richard", "latency_ms": 1014.9643421173096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2542}, "5": {"k": 5, "answer": "Cliff Richard", "latency_ms": 1036.54146194458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Cliff Richard", "latency_ms": 1385.1499557495117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3808}}}
{"qid": "-180549795106449014", "question": "who is command sergeant major of the army", "gold_answers": ["Daniel A. Dailey"], "shots": {"0": {"k": 0, "answer": "Michael A. Grinston", "latency_ms": 1204.1687965393066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Daniel A. Dailey", "latency_ms": 834.4886302947998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 569}, "2": {"k": 2, "answer": "Daniel A. Dailey", "latency_ms": 1307.9674243927002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1137}, "3": {"k": 3, "answer": "Daniel A. Dailey", "latency_ms": 1409.4796180725098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1843}, "4": {"k": 4, "answer": "Daniel A. Dailey", "latency_ms": 1351.3264656066895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2520}, "5": {"k": 5, "answer": "Daniel A. Dailey", "latency_ms": 1098.1626510620117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3166}, "6": {"k": 6, "answer": "Daniel A. Dailey", "latency_ms": 1011.7251873016357, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3911}}}
{"qid": "7815138213728640354", "question": "who sings the original windmills of your mind", "gold_answers": ["Noel Harrison"], "shots": {"0": {"k": 0, "answer": "Noel Harrison", "latency_ms": 1017.1492099761963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noel Harrison", "latency_ms": 848.9725589752197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 603}, "2": {"k": 2, "answer": "No singer mentioned", "latency_ms": 1052.7663230895996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Noel Harrison", "latency_ms": 544.7072982788086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Noel Harrison", "latency_ms": 724.6458530426025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2570}, "5": {"k": 5, "answer": "Noel Harrison", "latency_ms": 775.7902145385742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3206}, "6": {"k": 6, "answer": "Noel Harrison", "latency_ms": 963.374137878418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3812}}}
{"qid": "2098168902147822379", "question": "where will the next summer and winter olympics be held", "gold_answers": ["Beijing", "Tokyo"], "shots": {"0": {"k": 0, "answer": "Paris 2024 and Milan-Cortina 2026.", "latency_ms": 1762.5811100006104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Beijing", "latency_ms": 878.962516784668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 623}, "2": {"k": 2, "answer": "Beijing", "latency_ms": 1092.0677185058594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Beijing", "latency_ms": 739.248514175415, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1855}, "4": {"k": 4, "answer": "Beijing and Abu Dhabi", "latency_ms": 1284.3785285949707, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2457}, "5": {"k": 5, "answer": "Tokyo, Beijing", "latency_ms": 915.3716564178467, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3128}, "6": {"k": 6, "answer": "Tokyo, Japan and Beijing, China", "latency_ms": 1448.2336044311523, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3804}}}
{"qid": "-1458476052377668874", "question": "when did ole miss beat alabama in football", "gold_answers": ["September 19 , 2015", "October 3 , 1970", "October 27 , 1894", "October 13 , 2001", "October 5 , 1968", "October 4 , 2014", "September 11 , 1976", "October 8 , 1988", "October 18 , 2003", "November 5 , 1910"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 683.5744380950928, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 967.6785469055176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "1988", "latency_ms": 580.0590515136719, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "1988", "latency_ms": 675.9507656097412, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1825}, "4": {"k": 4, "answer": "1988", "latency_ms": 933.945894241333, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2438}, "5": {"k": 5, "answer": "1988, 2014, 2015", "latency_ms": 2200.9875774383545, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3073}, "6": {"k": 6, "answer": "1988, 2014, 1968, 1910", "latency_ms": 2249.861717224121, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3701}}}
{"qid": "-6861734002351236912", "question": "who sang the song how far is heaven", "gold_answers": ["Los Lonely Boys"], "shots": {"0": {"k": 0, "answer": "Nitty Gritty Dirt Band", "latency_ms": 708.8267803192139, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Moore", "latency_ms": 905.7016372680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Justin Moore", "latency_ms": 687.507152557373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1196}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1020.0841426849365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1785}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 768.1863307952881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2374}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 998.831033706665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2973}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1386.5325450897217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3590}}}
{"qid": "-1722216190521937227", "question": "where are the organ mountains in new mexico", "gold_answers": ["southern New Mexico"], "shots": {"0": {"k": 0, "answer": "Las Cruces", "latency_ms": 681.9198131561279, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "southern New Mexico", "latency_ms": 1035.447597503662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "southern New Mexico", "latency_ms": 990.4448986053467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1325}, "3": {"k": 3, "answer": "southern New Mexico", "latency_ms": 1265.8214569091797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1986}, "4": {"k": 4, "answer": "southern New Mexico", "latency_ms": 827.31032371521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2643}, "5": {"k": 5, "answer": "southern New Mexico", "latency_ms": 1024.3914127349854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3235}, "6": {"k": 6, "answer": "southern New Mexico", "latency_ms": 1032.1707725524902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3856}}}
{"qid": "-2717119588239727064", "question": "where are the 10 plagues found in the bible", "gold_answers": ["Book of Exodus", "Exodus"], "shots": {"0": {"k": 0, "answer": "Exodus 7-12", "latency_ms": 862.6995086669922, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 984.9579334259033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 570}, "2": {"k": 2, "answer": "the Hebrew Bible", "latency_ms": 781.0671329498291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "Hebrew Bible", "latency_ms": 788.1476879119873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Hebrew Bible", "latency_ms": 544.734001159668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2465}, "5": {"k": 5, "answer": "Hebrew Bible", "latency_ms": 1000.8542537689209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "Hebrew Bible", "latency_ms": 1009.1283321380615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "2988284357714596500", "question": "where are red blood cells made in adults", "gold_answers": ["in the bone marrow"], "shots": {"0": {"k": 0, "answer": "Bone marrow", "latency_ms": 687.1893405914307, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "bone marrow", "latency_ms": 880.6860446929932, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "bone marrow", "latency_ms": 654.1035175323486, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "the larger bones", "latency_ms": 937.4058246612549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1911}, "4": {"k": 4, "answer": "the larger bones", "latency_ms": 801.0015487670898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "bone marrow", "latency_ms": 731.7075729370117, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3245}, "6": {"k": 6, "answer": "bone marrow", "latency_ms": 883.3417892456055, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3887}}}
{"qid": "-4616596799374362422", "question": "who was the pinkerton detective agency's first female detective", "gold_answers": ["Kate Warne"], "shots": {"0": {"k": 0, "answer": "Kate Warne", "latency_ms": 755.5100917816162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kate Warne", "latency_ms": 1040.4047966003418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Kate Warne", "latency_ms": 938.2781982421875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1235}, "3": {"k": 3, "answer": "Kate Warne", "latency_ms": 968.024730682373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Kate Warne", "latency_ms": 996.5755939483643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2548}, "5": {"k": 5, "answer": "Kate Warne", "latency_ms": 474.884033203125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3173}, "6": {"k": 6, "answer": "Kate Warne", "latency_ms": 754.4214725494385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3846}}}
{"qid": "-3650291155113659146", "question": "how many episodes are there in modern family", "gold_answers": ["232", "201"], "shots": {"0": {"k": 0, "answer": "250 episodes", "latency_ms": 698.3511447906494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "24", "latency_ms": 852.0963191986084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "At least 141", "latency_ms": 977.7274131774902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "At least 141", "latency_ms": 1187.8609657287598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "At least 141", "latency_ms": 600.1620292663574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "At least 141", "latency_ms": 977.2152900695801, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "At least 141", "latency_ms": 767.5590515136719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3768}}}
{"qid": "3381924381590631417", "question": "who built the first temple for god in jerusalem", "gold_answers": ["Solomon"], "shots": {"0": {"k": 0, "answer": "King Solomon", "latency_ms": 450.1528739929199, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "King Solomon", "latency_ms": 956.641674041748, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "King Solomon", "latency_ms": 907.172679901123, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1276}, "3": {"k": 3, "answer": "King Solomon", "latency_ms": 443.0356025695801, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1911}, "4": {"k": 4, "answer": "King Solomon", "latency_ms": 638.263463973999, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2471}, "5": {"k": 5, "answer": "King Solomon", "latency_ms": 889.0585899353027, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3155}, "6": {"k": 6, "answer": "King Solomon", "latency_ms": 698.8787651062012, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3777}}}
{"qid": "-154783694579651082", "question": "what is a dropped pin on google maps for", "gold_answers": ["marks locations", "marks locations in Google Maps"], "shots": {"0": {"k": 0, "answer": "Saving a location", "latency_ms": 547.0137596130371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "marking locations", "latency_ms": 936.1469745635986, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "to mark a point on a map", "latency_ms": 945.5521106719971, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "to mark a point on a map", "latency_ms": 1380.5921077728271, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "to mark a point on a map", "latency_ms": 1623.4843730926514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "to mark a point on a map", "latency_ms": 1142.3044204711914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3039}, "6": {"k": 6, "answer": "to mark a point on a map", "latency_ms": 1726.9608974456787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3715}}}
{"qid": "6915606477668963399", "question": "what do the 3 dots mean in math", "gold_answers": ["the therefore sign", "therefore sign"], "shots": {"0": {"k": 0, "answer": "Ellipsis", "latency_ms": 559.5147609710693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1182.3070049285889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "∧", "latency_ms": 556.6065311431885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Therefore", "latency_ms": 844.1219329833984, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "Therefore sign", "latency_ms": 494.140625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2565}, "5": {"k": 5, "answer": "Therefore sign", "latency_ms": 1199.9092102050781, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3281}, "6": {"k": 6, "answer": "Therefore sign", "latency_ms": 1238.063097000122, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3870}}}
{"qid": "-8366545547296627039", "question": "who wrote the song photograph by ringo starr", "gold_answers": ["Richard Starkey", "George Harrison", "Ringo Starr"], "shots": {"0": {"k": 0, "answer": "Ringo Starr and George Harrison", "latency_ms": 1088.1338119506836, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ringo Starr and George Harrison", "latency_ms": 1150.324821472168, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Ringo Starr and George Harrison", "latency_ms": 1428.558349609375, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Ringo Starr and George Harrison", "latency_ms": 1354.4507026672363, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1957}, "4": {"k": 4, "answer": "Ringo Starr and George Harrison", "latency_ms": 1134.9530220031738, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2652}, "5": {"k": 5, "answer": "Ringo Starr and George Harrison", "latency_ms": 1380.8495998382568, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3307}, "6": {"k": 6, "answer": "Ringo Starr and George Harrison", "latency_ms": 1117.647409439087, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3963}}}
{"qid": "-5004457603684974952", "question": "who is playing the halftime show at super bowl 2016", "gold_answers": ["Beyoncé", "Coldplay", "Bruno Mars"], "shots": {"0": {"k": 0, "answer": "Coldplay", "latency_ms": 702.0044326782227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 1411.3883972167969, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "Coldplay, Beyoncé, and Bruno Mars.", "latency_ms": 1316.7333602905273, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Coldplay, Beyoncé, and Bruno Mars.", "latency_ms": 1928.846836090088, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Coldplay, Beyoncé, and Bruno Mars", "latency_ms": 1651.9591808319092, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2580}, "5": {"k": 5, "answer": "Coldplay", "latency_ms": 676.9757270812988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "Coldplay, Beyoncé, and Bruno Mars.", "latency_ms": 1845.8812236785889, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3884}}}
{"qid": "7420920477821898435", "question": "to aru kagaku no railgun s episode 3", "gold_answers": ["Project Radio Noise"], "shots": {"0": {"k": 0, "answer": "Episode 3", "latency_ms": 971.2131023406982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1183.7983131408691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1273.9644050598145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1389}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1521.9700336456299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1980}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1155.1587581634521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2650}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1115.0918006896973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3267}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 917.0506000518799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3872}}}
{"qid": "7478795216476346339", "question": "who won the 2017 sports personality of the year", "gold_answers": ["Mo Farah"], "shots": {"0": {"k": 0, "answer": "Mo Farah", "latency_ms": 928.7197589874268, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1412.6269817352295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1066.8749809265137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1313.0378723144531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1249.0825653076172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2542}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1239.3512725830078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3122}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1035.5863571166992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3761}}}
{"qid": "7217222058435937287", "question": "where was the world economic forum held this year", "gold_answers": ["Davos"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1189.3203258514404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Baku", "latency_ms": 869.7266578674316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1029.470682144165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1392.9708003997803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1971}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 802.7422428131104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2591}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1190.6650066375732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1039.9060249328613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3935}}}
{"qid": "-143054837169120955", "question": "where are the giant redwoods located in california", "gold_answers": ["the coast of northern California", "Del Norte County", "Humboldt County"], "shots": {"0": {"k": 0, "answer": "Northern California", "latency_ms": 440.5641555786133, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 1679.9547672271729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "Kings Canyon National Park and Sierra Nevada", "latency_ms": 1366.499423980713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Kings Canyon National Park and Sierra Nevada", "latency_ms": 1629.5325756072998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Kings Canyon National Park, Sierra Nevada, Santa Cruz County, Humboldt County, Fresno County", "latency_ms": 2820.453405380249, "em": 0.0, "f1": 0.2666666666666667, "containment": 1.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Kings Canyon National Park, Sierra Nevada, Santa Cruz County, Humboldt County", "latency_ms": 2817.9969787597656, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Sierra Nevada, Santa Cruz County, Humboldt County", "latency_ms": 2363.5916709899902, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3832}}}
{"qid": "4892429640540595424", "question": "who has made the most premier league appearances", "gold_answers": ["Gareth Barry"], "shots": {"0": {"k": 0, "answer": "Gareth Barry", "latency_ms": 1280.9481620788574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gareth Barry", "latency_ms": 799.1886138916016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Gareth Barry", "latency_ms": 1368.9115047454834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Gareth Barry", "latency_ms": 985.3930473327637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Gareth Barry", "latency_ms": 932.7659606933594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2542}, "5": {"k": 5, "answer": "Gareth Barry", "latency_ms": 1413.5808944702148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3203}, "6": {"k": 6, "answer": "Gareth Barry", "latency_ms": 969.050407409668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3858}}}
{"qid": "5533906981191706877", "question": "who was the first chief minister of west bengal", "gold_answers": ["Prafulla Chandra Ghosh"], "shots": {"0": {"k": 0, "answer": "Prafulla Chandra Ghosh", "latency_ms": 1209.5942497253418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Prafulla Chandra Ghosh", "latency_ms": 1770.2858448028564, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Prafulla Chandra Ghosh", "latency_ms": 1674.0999221801758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1408}, "3": {"k": 3, "answer": "Prafulla Chandra Ghosh", "latency_ms": 2192.3975944519043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2054}, "4": {"k": 4, "answer": "Prafulla Chandra Ghosh", "latency_ms": 1333.9128494262695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2656}, "5": {"k": 5, "answer": "Prafulla Chandra Ghosh", "latency_ms": 1960.0911140441895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "Prafulla Chandra Ghosh", "latency_ms": 1951.3933658599854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4012}}}
{"qid": "8823076125131408628", "question": "who sings got my mind set on you", "gold_answers": ["George Harrison", "James Ray"], "shots": {"0": {"k": 0, "answer": "George Harrison", "latency_ms": 927.3300170898438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 543.9352989196777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1194.4985389709473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 967.3717021942139, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1784}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1105.595588684082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2318}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1019.3946361541748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2971}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 956.4526081085205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3545}}}
{"qid": "9168660859139861094", "question": "two main types of research methods used in psychology", "gold_answers": ["Correlational research", "Descriptive research", "quantitative data", "Quantitative psychological research", "qualitative", "quantitative", "Qualitative psychological research", "Experimental research", "qualitative data"], "shots": {"0": {"k": 0, "answer": "Qualitative and Quantitative", "latency_ms": 889.2993927001953, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Qualitative and quantitative", "latency_ms": 1055.8998584747314, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 807}, "2": {"k": 2, "answer": "Qualitative or quantitative", "latency_ms": 905.5209159851074, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1554}, "3": {"k": 3, "answer": "Qualitative or quantitative", "latency_ms": 945.0826644897461, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2378}, "4": {"k": 4, "answer": "Qualitative or quantitative", "latency_ms": 1203.6306858062744, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3120}, "5": {"k": 5, "answer": "Qualitative or quantitative", "latency_ms": 1023.2980251312256, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3923}, "6": {"k": 6, "answer": "Qualitative or quantitative", "latency_ms": 1219.94948387146, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4660}}}
{"qid": "-7073063191952855764", "question": "who plays peter in what we do in the shadows", "gold_answers": ["Ben Fransham"], "shots": {"0": {"k": 0, "answer": "Mark Proksch", "latency_ms": 628.3597946166992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1353.33251953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1426.1958599090576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1576.1308670043945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1252.0885467529297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1007.0199966430664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1489.2473220825195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "7901746249864619718", "question": "when does the 14th season of grey's anatomy come out", "gold_answers": ["September 28 , 2017"], "shots": {"0": {"k": 0, "answer": "September 28, 2017", "latency_ms": 1608.7095737457275, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 28, 2017", "latency_ms": 1359.6928119659424, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 28, 2017", "latency_ms": 2105.740547180176, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "September 28, 2017", "latency_ms": 1179.0721416473389, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 28, 2017", "latency_ms": 1983.7689399719238, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2701}, "5": {"k": 5, "answer": "September 28, 2017", "latency_ms": 976.0701656341553, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3389}, "6": {"k": 6, "answer": "September 28, 2017", "latency_ms": 2076.4646530151367, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4057}}}
{"qid": "-896127746191949637", "question": "when was the first hunger games book published", "gold_answers": ["September 14 , 2008", "2008"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 730.2200794219971, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 14, 2008", "latency_ms": 1647.9213237762451, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "September 14, 2008", "latency_ms": 1547.3999977111816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1322}, "3": {"k": 3, "answer": "September 14, 2008", "latency_ms": 1639.4257545471191, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1996}, "4": {"k": 4, "answer": "September 14, 2008", "latency_ms": 1959.6383571624756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2679}, "5": {"k": 5, "answer": "September 14, 2008", "latency_ms": 1491.7752742767334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3304}, "6": {"k": 6, "answer": "September 14, 2008", "latency_ms": 1119.654655456543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3917}}}
{"qid": "8044909700499569711", "question": "how much is the united states in debt to china", "gold_answers": ["$1.06 trillion", "1,200.5"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1031.82053565979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "21 percent", "latency_ms": 745.7623481750488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "$1.18 trillion", "latency_ms": 1084.7229957580566, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "$1.18 trillion", "latency_ms": 1146.1188793182373, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "$1.18 trillion", "latency_ms": 1184.340238571167, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "$1.18 trillion", "latency_ms": 1551.9225597381592, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3199}, "6": {"k": 6, "answer": "$1.18 trillion", "latency_ms": 795.8347797393799, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3843}}}
{"qid": "-3123234845590594961", "question": "where did the race in grease take place", "gold_answers": ["Thunder Road"], "shots": {"0": {"k": 0, "answer": "Thunder Road", "latency_ms": 461.84706687927246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles River", "latency_ms": 785.7694625854492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Los Angeles River", "latency_ms": 824.0690231323242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "Los Angeles River", "latency_ms": 970.0374603271484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Los Angeles River", "latency_ms": 1241.5125370025635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Los Angeles River", "latency_ms": 964.8087024688721, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3141}, "6": {"k": 6, "answer": "Los Angeles River", "latency_ms": 876.7120838165283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "4326992806019599297", "question": "what is the maximum data rate for the 802.11a standard select one", "gold_answers": ["54 Mbit / s"], "shots": {"0": {"k": 0, "answer": "54 Mbps", "latency_ms": 795.1476573944092, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "54 Mbit/s", "latency_ms": 854.9587726593018, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "54 Mbit/s", "latency_ms": 1085.789442062378, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "54 Mbit/s", "latency_ms": 1236.0467910766602, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1997}, "4": {"k": 4, "answer": "54 Mbit/s", "latency_ms": 994.93408203125, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "54 Mbit/s", "latency_ms": 1464.9772644042969, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "54 Mbit/s", "latency_ms": 986.2020015716553, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3927}}}
{"qid": "6144099837933283715", "question": "a good that can be used in place of another good", "gold_answers": ["A substitute good", "substitute good"], "shots": {"0": {"k": 0, "answer": "Substitute", "latency_ms": 690.4642581939697, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pickling salt", "latency_ms": 786.0465049743652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 537}, "2": {"k": 2, "answer": "Pickling salt", "latency_ms": 1080.2912712097168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1157}, "3": {"k": 3, "answer": "Pickling salt", "latency_ms": 1092.2925472259521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1814}, "4": {"k": 4, "answer": "Pickling salt", "latency_ms": 1446.3176727294922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2368}, "5": {"k": 5, "answer": "Pickling salt", "latency_ms": 957.6382637023926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3048}, "6": {"k": 6, "answer": "Pickling salt", "latency_ms": 774.3644714355469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-4621948696356225060", "question": "where in the bible can i find the lord's prayer", "gold_answers": ["the Gospel of Luke", "the Gospel of Matthew"], "shots": {"0": {"k": 0, "answer": "Matthew 6:9-13, Luke 11:2-4", "latency_ms": 3069.8843002319336, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1298.5727787017822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 562}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1220.6249237060547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Matthew 6:9", "latency_ms": 1325.1161575317383, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1769}, "4": {"k": 4, "answer": "Matthew 6:9-13", "latency_ms": 1444.8304176330566, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2350}, "5": {"k": 5, "answer": "Matthew 6:9-13", "latency_ms": 1456.502914428711, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2985}, "6": {"k": 6, "answer": "Matthew 6:9-13", "latency_ms": 2041.5303707122803, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3623}}}
{"qid": "6941993254369956277", "question": "when was the last time nebraska voted democrat", "gold_answers": ["1964"], "shots": {"0": {"k": 0, "answer": "1964", "latency_ms": 944.4034099578857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1908", "latency_ms": 943.2199001312256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "1908", "latency_ms": 1177.9396533966064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1397}, "3": {"k": 3, "answer": "1994", "latency_ms": 686.4423751831055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2129}, "4": {"k": 4, "answer": "1994", "latency_ms": 702.7692794799805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2814}, "5": {"k": 5, "answer": "1908", "latency_ms": 921.4396476745605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3495}, "6": {"k": 6, "answer": "1994", "latency_ms": 919.5873737335205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4146}}}
{"qid": "-8955197065025093046", "question": "who become the ceo of it wipro company in 2016", "gold_answers": ["Abid Ali Neemuchwala"], "shots": {"0": {"k": 0, "answer": "Abidali Neemuchwala", "latency_ms": 995.445728302002, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Abidali Neemuchwala", "latency_ms": 1531.818151473999, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Abidali Neemuchwala", "latency_ms": 1263.8599872589111, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Abidali Neemuchwala", "latency_ms": 1441.894769668579, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2047}, "4": {"k": 4, "answer": "Abidali Neemuchwala", "latency_ms": 1688.136339187622, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2675}, "5": {"k": 5, "answer": "Abidali Neemuchwala", "latency_ms": 1178.2341003417969, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3341}, "6": {"k": 6, "answer": "Abidali Neemuchwala", "latency_ms": 1416.9249534606934, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3981}}}
{"qid": "-3010425579521817304", "question": "who does eric end up with in gossip girl", "gold_answers": ["Jenny"], "shots": {"0": {"k": 0, "answer": "Vanessa, then Serena, then no one, then actually Vanessa again but then finally with  Serena", "latency_ms": 2995.4826831817627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 986.943244934082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 810.9917640686035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1059.1695308685303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1004.2533874511719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "Jenny", "latency_ms": 860.1436614990234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3068}, "6": {"k": 6, "answer": "Jenny", "latency_ms": 902.8306007385254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3658}}}
{"qid": "7264112453286983469", "question": "who plays unis in she's the man", "gold_answers": ["Emily Perkins"], "shots": {"0": {"k": 0, "answer": "Amanda Bynes", "latency_ms": 794.6479320526123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1003.7486553192139, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 576.6019821166992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 688.7292861938477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 979.8758029937744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 969.0146446228027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1000.2708435058594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3767}}}
{"qid": "2627695648792729859", "question": "who played booster in jingle all the way", "gold_answers": ["Curtis Armstrong"], "shots": {"0": {"k": 0, "answer": "Eric Lloyd", "latency_ms": 677.0613193511963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 775.5823135375977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 679}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 860.8975410461426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1342}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1176.6331195831299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2010}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 871.0055351257324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2699}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1097.4807739257812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3332}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1252.5966167449951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3986}}}
{"qid": "-9169976182548289414", "question": "who is recognized as the founder of islam", "gold_answers": ["the Islamic prophet Muhammad", "Muhammad"], "shots": {"0": {"k": 0, "answer": "Muhammad", "latency_ms": 494.5411682128906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urwah ibn Zubayr", "latency_ms": 1476.5682220458984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "Muhammad", "latency_ms": 1018.4605121612549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Muhammad", "latency_ms": 928.7581443786621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1925}, "4": {"k": 4, "answer": "Muhammad", "latency_ms": 1029.817819595337, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Muhammad", "latency_ms": 877.0091533660889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3193}, "6": {"k": 6, "answer": "Muhammad", "latency_ms": 627.3000240325928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3813}}}
{"qid": "-6696747560626271522", "question": "who plays emma in air bud world pup", "gold_answers": ["Brittany Paige Bouck"], "shots": {"0": {"k": 0, "answer": "Brittany Paige Bouck", "latency_ms": 1176.328182220459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Brittany Paige Bouck", "latency_ms": 1416.4090156555176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 592}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 717.9594039916992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1267.4291133880615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1248.4831809997559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 787.2154712677002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3169}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1029.4575691223145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3794}}}
{"qid": "5871681964137793716", "question": "how old was sasuke when his clan died", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "7 years old", "latency_ms": 753.3786296844482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seven", "latency_ms": 1054.0056228637695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Seven", "latency_ms": 385.75291633605957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1247}, "3": {"k": 3, "answer": "Seven", "latency_ms": 981.731653213501, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1875}, "4": {"k": 4, "answer": "Seven", "latency_ms": 829.211950302124, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Seven", "latency_ms": 683.6576461791992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3145}, "6": {"k": 6, "answer": "Seven", "latency_ms": 691.0459995269775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3760}}}
{"qid": "8552176802923865025", "question": "where do some of the natural air pollutants come from", "gold_answers": ["wildfires", "Dust", "Vegetation", "Carbon dioxide", "Volcanic activity"], "shots": {"0": {"k": 0, "answer": "Volcanic eruptions", "latency_ms": 1349.1089344024658, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1288.8047695159912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 718}, "2": {"k": 2, "answer": "Volcanic eruption", "latency_ms": 1218.8999652862549, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "Volcanic eruption", "latency_ms": 691.2434101104736, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2025}, "4": {"k": 4, "answer": "forest fires, volcanic eruptions", "latency_ms": 1252.889633178711, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2776}, "5": {"k": 5, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity.", "latency_ms": 4620.478630065918, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 3506}, "6": {"k": 6, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity.", "latency_ms": 4314.183712005615, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 4123}}}
{"qid": "-2630525064809360052", "question": "who is the pastor of new birth missionary baptist church now", "gold_answers": ["Stephen A. Davis"], "shots": {"0": {"k": 0, "answer": "Jamal Harrison Bryant", "latency_ms": 1051.5038967132568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jamal Bryant", "latency_ms": 1225.5744934082031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Jamal Bryant", "latency_ms": 1012.2470855712891, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1353}, "3": {"k": 3, "answer": "Jamal Bryant", "latency_ms": 775.0849723815918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1990}, "4": {"k": 4, "answer": "Jamal Bryant", "latency_ms": 1304.4846057891846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2621}, "5": {"k": 5, "answer": "Jamal Bryant", "latency_ms": 1207.3407173156738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3286}, "6": {"k": 6, "answer": "Jamal Bryant", "latency_ms": 1453.7248611450195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3959}}}
{"qid": "6434931911289860123", "question": "who is doing 2018 super bowl half time show", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "Justin Timberlake", "latency_ms": 1203.5105228424072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Timberlake", "latency_ms": 977.7357578277588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "Justin Timberlake", "latency_ms": 773.0193138122559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Justin Timberlake", "latency_ms": 762.5508308410645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Justin Timberlake", "latency_ms": 1134.0930461883545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2587}, "5": {"k": 5, "answer": "Justin Timberlake", "latency_ms": 1003.5231113433838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3249}, "6": {"k": 6, "answer": "Justin Timberlake", "latency_ms": 962.8112316131592, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3874}}}
{"qid": "8869318258439148973", "question": "who is playing the halftime show for the superbowl", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 562.2313022613525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 1937.7360343933105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "Coldplay, Beyoncé, and Bruno Mars.", "latency_ms": 1372.389316558838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Coldplay, Beyoncé, and Bruno Mars.", "latency_ms": 1671.0028648376465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Coldplay, Beyoncé, Bruno Mars", "latency_ms": 1236.088514328003, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2526}, "5": {"k": 5, "answer": "Maroon 5", "latency_ms": 506.9773197174072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3158}, "6": {"k": 6, "answer": "Maroon 5", "latency_ms": 1028.0945301055908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3819}}}
{"qid": "-8359866474144720253", "question": "who hosted they think it's all over", "gold_answers": ["Des Lynam", "Lee Mack", "comedian Nick Hancock", "Nick Hancock"], "shots": {"0": {"k": 0, "answer": "Nick Hancock", "latency_ms": 782.0339202880859, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1026.6430377960205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1242.8929805755615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 915.7741069793701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1204.822063446045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1372.4331855773926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 808.9420795440674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3703}}}
{"qid": "-1206653570097564556", "question": "where does the movie proof of life take place", "gold_answers": ["The Republic of Tecala"], "shots": {"0": {"k": 0, "answer": "South America", "latency_ms": 435.1015090942383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1460.7644081115723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 988.5284900665283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "London and Leipzig", "latency_ms": 1129.5697689056396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "The Republic of Tecala", "latency_ms": 1318.000316619873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2486}, "5": {"k": 5, "answer": "The Republic of Tecala", "latency_ms": 1020.6305980682373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3083}, "6": {"k": 6, "answer": "The Republic of Tecala", "latency_ms": 1105.2300930023193, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3728}}}
{"qid": "6144521615402262404", "question": "where does us highway 1 start and end", "gold_answers": ["Fort Kent , Maine", "to Key West , Florida", "Key West , Florida"], "shots": {"0": {"k": 0, "answer": "Fort Kent, Maine to Key West, Florida", "latency_ms": 1674.8790740966797, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1390.8207416534424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1169.6045398712158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1217}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 847.5954532623291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1811}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 926.6400337219238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2442}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1136.7859840393066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1436.5568161010742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3823}}}
{"qid": "-8631190913794477985", "question": "who scored the most points in a single game in the nba", "gold_answers": ["Wilt Chamberlain"], "shots": {"0": {"k": 0, "answer": "Wilt Chamberlain", "latency_ms": 831.4938545227051, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wilt Chamberlain", "latency_ms": 1109.3158721923828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "Wilt Chamberlain", "latency_ms": 884.7289085388184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1310}, "3": {"k": 3, "answer": "Wilt Chamberlain", "latency_ms": 1002.1727085113525, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Wilt Chamberlain", "latency_ms": 1285.3844165802002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Wilt Chamberlain", "latency_ms": 659.590482711792, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3083}, "6": {"k": 6, "answer": "Wilt Chamberlain", "latency_ms": 1154.4339656829834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3637}}}
{"qid": "199896377614951764", "question": "where is natural gas found in the us", "gold_answers": ["Texas", "Pennsylvania", "Colorado", "New Mexico", "West Virginia", "Arkansas", "Wyoming", "Louisiana"], "shots": {"0": {"k": 0, "answer": "Various states including Texas, Alaska, and Pennsylvania", "latency_ms": 1301.4945983886719, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Louisiana, Texas, California, and Alaska.", "latency_ms": 1857.996940612793, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 630}, "2": {"k": 2, "answer": "Louisiana, Texas, California, and Alaska", "latency_ms": 2409.675121307373, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Louisiana, Texas, California, Alaska, shale formations", "latency_ms": 1828.204870223999, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1825}, "4": {"k": 4, "answer": "Louisiana, Texas, California, Alaska", "latency_ms": 1469.0403938293457, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2501}, "5": {"k": 5, "answer": "Louisiana, Texas, California, Alaska", "latency_ms": 1201.446533203125, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Louisiana, Texas, California, Alaska", "latency_ms": 1174.100399017334, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3889}}}
{"qid": "8986775680996674901", "question": "when were the first general elections held in independent india", "gold_answers": ["1951 -- 52"], "shots": {"0": {"k": 0, "answer": "1951", "latency_ms": 533.0767631530762, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1952", "latency_ms": 686.1405372619629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "1952", "latency_ms": 446.34342193603516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "1952", "latency_ms": 622.94602394104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1977}, "4": {"k": 4, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 1879.4872760772705, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "January 1952", "latency_ms": 909.7578525543213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3250}, "6": {"k": 6, "answer": "January 1952", "latency_ms": 982.5751781463623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3884}}}
{"qid": "700604097171850168", "question": "what was the tower of london originally used for", "gold_answers": ["as a royal residence", "a royal residence"], "shots": {"0": {"k": 0, "answer": "Royal Palace", "latency_ms": 578.6418914794922, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "holding prisoners was incidental", "latency_ms": 986.5241050720215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "incidental role of holding prisoners", "latency_ms": 1100.4199981689453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "incidental role of holding prisoners as would have been the case for any castle", "latency_ms": 2142.2975063323975, "em": 0.0, "f1": 0.125, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "incidental role of holding prisoners", "latency_ms": 1082.542896270752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "incidental role of holding prisoners", "latency_ms": 1103.9929389953613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3097}, "6": {"k": 6, "answer": "incidental role of holding prisoners", "latency_ms": 951.451301574707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3720}}}
{"qid": "6745303307988470742", "question": "what type of fuel goes in a zippo", "gold_answers": ["butane", "lighter fluid"], "shots": {"0": {"k": 0, "answer": "Lighter fluid", "latency_ms": 726.6006469726562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 2012.3355388641357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 2170.2253818511963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 1879.1794776916504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1830}, "4": {"k": 4, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 2159.4743728637695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2400}, "5": {"k": 5, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 1820.9316730499268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3039}, "6": {"k": 6, "answer": "Light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 2467.38862991333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-2060506905455252030", "question": "first jnanpith award was an autor of which language", "gold_answers": ["Malayalam"], "shots": {"0": {"k": 0, "answer": "Gujarati", "latency_ms": 739.4504547119141, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Malayalam", "latency_ms": 573.4121799468994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 669}, "2": {"k": 2, "answer": "Malayalam", "latency_ms": 724.1671085357666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1332}, "3": {"k": 3, "answer": "Malayalam", "latency_ms": 983.4146499633789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1980}, "4": {"k": 4, "answer": "Malayalam", "latency_ms": 1018.359899520874, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2625}, "5": {"k": 5, "answer": "Malayalam", "latency_ms": 1292.3109531402588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3265}, "6": {"k": 6, "answer": "Malayalam", "latency_ms": 1198.2979774475098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3990}}}
{"qid": "4738663028303377024", "question": "who played the mad hatter in the batman tv show", "gold_answers": ["Roddy McDowall", "David Wayne", "Benedict Samuel"], "shots": {"0": {"k": 0, "answer": "David Wayne", "latency_ms": 994.6835041046143, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1649.5394706726074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 893.4967517852783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "David Wayne", "latency_ms": 961.5285396575928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Benedict Samuel", "latency_ms": 1254.1980743408203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2543}, "5": {"k": 5, "answer": "David Wayne", "latency_ms": 917.1500205993652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3213}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1279.649019241333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3868}}}
{"qid": "-1650946015201779846", "question": "how many cracker barrels in the united states", "gold_answers": ["639", "more than 600"], "shots": {"0": {"k": 0, "answer": "645 locations", "latency_ms": 957.7414989471436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "645 stores in 44 states", "latency_ms": 1348.0195999145508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "645 stores in 44 states", "latency_ms": 1364.8850917816162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "645 stores in 44 states", "latency_ms": 1483.2682609558105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "645 stores in 44 states", "latency_ms": 1332.0329189300537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2593}, "5": {"k": 5, "answer": "645 stores in 44 states", "latency_ms": 1604.8030853271484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3218}, "6": {"k": 6, "answer": "645 stores in 44 states", "latency_ms": 1569.0937042236328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3864}}}
{"qid": "-3422350952909582054", "question": "in photosynthesis the carbon in co2 is initially fixed to what molecule", "gold_answers": ["3 - phosphoglycerate"], "shots": {"0": {"k": 0, "answer": "RuBP", "latency_ms": 536.1006259918213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 2129.2600631713867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 712}, "2": {"k": 2, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 2217.608690261841, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1411}, "3": {"k": 3, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 2249.532699584961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2116}, "4": {"k": 4, "answer": "Phosphoenolpyruvate (PEP)", "latency_ms": 2235.8760833740234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2845}, "5": {"k": 5, "answer": "Phosphoenolpyruvate (PEP)", "latency_ms": 2389.1494274139404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3553}, "6": {"k": 6, "answer": "Ribulose 1,5-bisphosphate", "latency_ms": 2003.8456916809082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4269}}}
{"qid": "-2704708103393811482", "question": "who voices randy in f is for family", "gold_answers": ["T.J. Miller"], "shots": {"0": {"k": 0, "answer": "Bill Burr", "latency_ms": 748.7261295318604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1269.209861755371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 892.5817012786865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1004.4224262237549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1925}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1250.8513927459717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2554}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1212.7392292022705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 988.5125160217285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3688}}}
{"qid": "5482012214308896475", "question": "how many countries does cadbury sell its products", "gold_answers": ["more than 50", "more than 50 countries worldwide"], "shots": {"0": {"k": 0, "answer": "160 countries", "latency_ms": 967.9620265960693, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "30", "latency_ms": 917.5574779510498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "more than fifty", "latency_ms": 991.3105964660645, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1356}, "3": {"k": 3, "answer": "50 countries worldwide", "latency_ms": 1150.1469612121582, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 2064}, "4": {"k": 4, "answer": "50 countries worldwide", "latency_ms": 697.7012157440186, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 2698}, "5": {"k": 5, "answer": "50 countries worldwide", "latency_ms": 1157.883644104004, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 3397}, "6": {"k": 6, "answer": "50 countries worldwide", "latency_ms": 1301.0106086730957, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 4125}}}
{"qid": "-5737509619250561344", "question": "ethiopia flight 961 crashes in to the sea", "gold_answers": ["23 November 1996"], "shots": {"0": {"k": 0, "answer": "November 23, 1996", "latency_ms": 1587.5160694122314, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indian Ocean", "latency_ms": 803.1477928161621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "Indian Ocean", "latency_ms": 1247.84255027771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1304}, "3": {"k": 3, "answer": "Indian Ocean", "latency_ms": 998.3718395233154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1967}, "4": {"k": 4, "answer": "Indian Ocean", "latency_ms": 950.7570266723633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Indian Ocean", "latency_ms": 1177.8278350830078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3256}, "6": {"k": 6, "answer": "Indian Ocean", "latency_ms": 1156.1462879180908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3857}}}
{"qid": "-7175456993713717070", "question": "what does istj mean in a personality test", "gold_answers": ["Extroverted Thinking ( Te )", "Extroverted Intuition ( Ne )", "Introverted Feeling ( Fi )", "Introverted Sensing ( Si )"], "shots": {"0": {"k": 0, "answer": "Introverted, Sensing, Thinking, Judging", "latency_ms": 1919.8086261749268, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 2029.0982723236084, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 724}, "2": {"k": 2, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 2216.7587280273438, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 2201.1454105377197, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2101}, "4": {"k": 4, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 1477.3304462432861, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2729}, "5": {"k": 5, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 1946.6402530670166, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3404}, "6": {"k": 6, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 1539.928674697876, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4115}}}
{"qid": "4437170343606050664", "question": "who does the voice of ash in sing", "gold_answers": ["Scarlett Johansson"], "shots": {"0": {"k": 0, "answer": "Scarlett Johansson", "latency_ms": 1294.9609756469727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ash King", "latency_ms": 730.2331924438477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Ash King", "latency_ms": 648.4794616699219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Ash King", "latency_ms": 854.1128635406494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Ash King", "latency_ms": 946.4786052703857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2525}, "5": {"k": 5, "answer": "Ash King", "latency_ms": 890.0666236877441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "Ash King", "latency_ms": 942.0061111450195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3662}}}
{"qid": "-8773010039077552394", "question": "who scored the most points in their nba career", "gold_answers": ["Kareem Abdul - Jabbar"], "shots": {"0": {"k": 0, "answer": "LeBron James", "latency_ms": 570.7945823669434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nowitzki", "latency_ms": 458.728551864624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1250.3223419189453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1152}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 935.9843730926514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1709}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 982.0618629455566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2263}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 854.5329570770264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2868}, "6": {"k": 6, "answer": "Kareem Abdul-Jabbar", "latency_ms": 1642.4410343170166, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3486}}}
{"qid": "-3278224144622911032", "question": "with a land area of 54 314 square miles where does wisconsin rank among the 50 states", "gold_answers": ["25"], "shots": {"0": {"k": 0, "answer": "23rd", "latency_ms": 770.0941562652588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 838.7594223022461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1588.3104801177979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1178}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1006.0393810272217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1793}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1596.592664718628, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2405}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1057.046890258789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2999}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1227.670669555664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3592}}}
{"qid": "-3466298422174960041", "question": "who plays charles on have and have nots", "gold_answers": ["Nick Sager", "Nick Sagar"], "shots": {"0": {"k": 0, "answer": "Aaron O'Connell", "latency_ms": 1085.5133533477783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1027.611255645752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1521.294355392456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1006.4647197723389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1027.7464389801025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 953.6597728729248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1256.5827369689941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3804}}}
{"qid": "1803248910342766083", "question": "who wrote the book my country my life", "gold_answers": ["L.K. Advani"], "shots": {"0": {"k": 0, "answer": "L.K. Advani", "latency_ms": 1126.9915103912354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "L. K. Advani", "latency_ms": 1503.854513168335, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "L. K. Advani", "latency_ms": 1520.437240600586, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1158}, "3": {"k": 3, "answer": "L. K. Advani", "latency_ms": 1321.434497833252, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1798}, "4": {"k": 4, "answer": "L. K. Advani", "latency_ms": 1712.766170501709, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "L. K. Advani", "latency_ms": 1442.8093433380127, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3173}, "6": {"k": 6, "answer": "L. K. Advani", "latency_ms": 1099.7121334075928, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3849}}}
{"qid": "-1176280233636154422", "question": "when did the east india company take control of india", "gold_answers": ["1757", "1799", "1612", "in 1757"], "shots": {"0": {"k": 0, "answer": "1757", "latency_ms": 975.3596782684326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1757", "latency_ms": 736.0105514526367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "1757", "latency_ms": 971.4701175689697, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1307}, "3": {"k": 3, "answer": "1757", "latency_ms": 1178.5125732421875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1925}, "4": {"k": 4, "answer": "1757", "latency_ms": 437.46042251586914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2557}, "5": {"k": 5, "answer": "1757", "latency_ms": 891.5503025054932, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3205}, "6": {"k": 6, "answer": "1757", "latency_ms": 650.5460739135742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3853}}}
{"qid": "5911119091653953181", "question": "where does the water come from to fill lake eyre", "gold_answers": ["Warburton River"], "shots": {"0": {"k": 0, "answer": "Cooper Creek", "latency_ms": 833.3761692047119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the west, the Channel Country of Queensland", "latency_ms": 1452.7645111083984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "the west, the Channel Country of Queensland", "latency_ms": 1170.0408458709717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1154}, "3": {"k": 3, "answer": "the west, the Channel Country of Queensland", "latency_ms": 1350.7580757141113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1775}, "4": {"k": 4, "answer": "the west, the Channel Country of Queensland", "latency_ms": 956.7382335662842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2401}, "5": {"k": 5, "answer": "Channel Country of Queensland", "latency_ms": 1092.7035808563232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2998}, "6": {"k": 6, "answer": "Channel Country of Queensland", "latency_ms": 833.8174819946289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3609}}}
{"qid": "5557104327881436095", "question": "who is the founder of google and when was it founded", "gold_answers": ["1998", "Sergey Brin", "Larry Page and Sergey Brin", "Larry Page"], "shots": {"0": {"k": 0, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 1141.4060592651367, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 516.4666175842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 2010.2155208587646, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 1358}, "3": {"k": 3, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 2241.464853286743, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 1991.6651248931885, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 2698}, "5": {"k": 5, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 1736.208200454712, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 3334}, "6": {"k": 6, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 1807.8885078430176, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 4003}}}
{"qid": "-1333328812971005142", "question": "who did the dominican republic gain its independence from", "gold_answers": ["Haiti"], "shots": {"0": {"k": 0, "answer": "Haiti and Spain", "latency_ms": 1031.1825275421143, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haiti", "latency_ms": 460.7553482055664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 725}, "2": {"k": 2, "answer": "Haiti", "latency_ms": 954.1823863983154, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1394}, "3": {"k": 3, "answer": "Haiti", "latency_ms": 726.3662815093994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2069}, "4": {"k": 4, "answer": "Haiti and Spain", "latency_ms": 951.8980979919434, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2783}, "5": {"k": 5, "answer": "Haiti", "latency_ms": 783.301591873169, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3420}, "6": {"k": 6, "answer": "Haiti", "latency_ms": 707.9756259918213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4106}}}
{"qid": "1122605495295045742", "question": "how did early humans make use of stones during the prehistoric period", "gold_answers": ["start fires", "hunt", "bury their dead"], "shots": {"0": {"k": 0, "answer": "Tool making", "latency_ms": 298.45499992370605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 2463.2322788238525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 2101.057767868042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 2093.3237075805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 2438.3151531219482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 2760.5369091033936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3228}, "6": {"k": 6, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 2590.1944637298584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "7402184777947527945", "question": "who wrote the text for jeanie with the light brown hair", "gold_answers": ["Stephen Foster"], "shots": {"0": {"k": 0, "answer": "Maud Irving or Robert Burns", "latency_ms": 1101.2327671051025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stephen Foster", "latency_ms": 580.9183120727539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Stephen Foster", "latency_ms": 1157.365322113037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1222}, "3": {"k": 3, "answer": "Stephen Foster", "latency_ms": 923.2544898986816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Stephen Foster", "latency_ms": 984.7347736358643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2490}, "5": {"k": 5, "answer": "Stephen Foster", "latency_ms": 933.5451126098633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3107}, "6": {"k": 6, "answer": "Stephen Foster", "latency_ms": 1128.9360523223877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3752}}}
{"qid": "1656745334095178455", "question": "the basic steps of rational decision making include defining goals and", "gold_answers": ["Implementation of plans / policies"], "shots": {"0": {"k": 0, "answer": "identifying alternatives", "latency_ms": 545.3536510467529, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "problem definition", "latency_ms": 865.0064468383789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 774}, "2": {"k": 2, "answer": "problem definition", "latency_ms": 933.7501525878906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1428}, "3": {"k": 3, "answer": "problem definition", "latency_ms": 721.2655544281006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2061}, "4": {"k": 4, "answer": "problem definition", "latency_ms": 906.757116317749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2713}, "5": {"k": 5, "answer": "problem definition", "latency_ms": 903.0885696411133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3412}, "6": {"k": 6, "answer": "problem definition", "latency_ms": 932.9319000244141, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4068}}}
{"qid": "-216657635823030751", "question": "when was the design period known as art deco", "gold_answers": ["1910 -- 1939"], "shots": {"0": {"k": 0, "answer": "1920s to 1940s", "latency_ms": 1650.9513854980469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1930s", "latency_ms": 1214.521884918213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "just before World War I", "latency_ms": 1015.6035423278809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "just before World War I", "latency_ms": 1303.0602931976318, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2011}, "4": {"k": 4, "answer": "just before World War I", "latency_ms": 1581.5019607543945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2679}, "5": {"k": 5, "answer": "just before World War I", "latency_ms": 1561.5899562835693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "just before World War I", "latency_ms": 1240.751028060913, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3972}}}
{"qid": "250542332339248886", "question": "where does the bob and tom show broadcast from", "gold_answers": ["WFBQ in Indianapolis , Indiana", "Indianapolis , Indiana"], "shots": {"0": {"k": 0, "answer": "Indianapolis", "latency_ms": 1011.3556385040283, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indianapolis, Indiana", "latency_ms": 832.024097442627, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 1970.7770347595215, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 1567.6825046539307, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 1709.787368774414, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2574}, "5": {"k": 5, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 1544.2836284637451, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 1684.2448711395264, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3777}}}
{"qid": "7610758795954724809", "question": "star wars the clone wars season 3 episode 1", "gold_answers": ["Clone Cadets"], "shots": {"0": {"k": 0, "answer": "Clone Cadets", "latency_ms": 611.2532615661621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1028.9638042449951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "Nightsisters", "latency_ms": 1205.505132675171, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1370}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1269.254207611084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2013}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1245.7797527313232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2693}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1158.8046550750732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3333}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1534.0073108673096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3979}}}
{"qid": "2997223939033016160", "question": "what part of brain is responsible for complex thinking", "gold_answers": ["the frontal lobe"], "shots": {"0": {"k": 0, "answer": "Cerebrum", "latency_ms": 634.5336437225342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frontal lobe", "latency_ms": 1419.4700717926025, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 702}, "2": {"k": 2, "answer": "Frontal lobe", "latency_ms": 1230.5920124053955, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "Cerebral cortex", "latency_ms": 1703.5751342773438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "Cerebral cortex", "latency_ms": 783.9794158935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2688}, "5": {"k": 5, "answer": "Cerebral cortex", "latency_ms": 927.6459217071533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3385}, "6": {"k": 6, "answer": "Cerebral cortex", "latency_ms": 1144.1845893859863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4069}}}
{"qid": "2680196226239522881", "question": "who won the champions league final in 2016", "gold_answers": ["Real Madrid"], "shots": {"0": {"k": 0, "answer": "Real Madrid", "latency_ms": 797.684907913208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1332.9992294311523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "Real Madrid", "latency_ms": 1185.2428913116455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Real Madrid", "latency_ms": 718.9242839813232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1880}, "4": {"k": 4, "answer": "Real Madrid", "latency_ms": 676.5270233154297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2536}, "5": {"k": 5, "answer": "Real Madrid", "latency_ms": 863.7616634368896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3169}, "6": {"k": 6, "answer": "Real Madrid", "latency_ms": 1088.3796215057373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3831}}}
{"qid": "-8458006812258546025", "question": "who has the most gold medals in the winter olympics of all time", "gold_answers": ["Norway"], "shots": {"0": {"k": 0, "answer": "Marit Bjoergen", "latency_ms": 1141.3049697875977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canada", "latency_ms": 917.2813892364502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Johannes Høsflot Klæbo and Martin Fourcade", "latency_ms": 2252.903699874878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Canada", "latency_ms": 861.5286350250244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1941}, "4": {"k": 4, "answer": "Canada", "latency_ms": 937.469482421875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2564}, "5": {"k": 5, "answer": "Canada", "latency_ms": 636.0299587249756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3175}, "6": {"k": 6, "answer": "Marit Bjørgen", "latency_ms": 1840.4350280761719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3792}}}
