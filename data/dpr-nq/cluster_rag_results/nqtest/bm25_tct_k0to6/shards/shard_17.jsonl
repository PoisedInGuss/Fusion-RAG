{"qid": "-9197932657152136610", "question": "what are the main sources of economic growth in the us currently", "gold_answers": ["pharmaceuticals", "aircraft", "telecommunications", "heavy machinery"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1235.3601455688477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3519.592761993408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "increases in labour, capital, and efficiency of factors of production", "latency_ms": 6978.692293167114, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2567.50750541687, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2113}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 12753.15260887146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2808}, "5": {"k": 5, "answer": "increases in labour, capital, and efficiency of factors of production; technological advancement", "latency_ms": 4890.405893325806, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3473}, "6": {"k": 6, "answer": "increases in labour, capital, and efficiency of factors of production; technological advancement", "latency_ms": 8564.727783203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4195}}}
{"qid": "-4566914757117567579", "question": "who played ethel on the doris day show", "gold_answers": ["Carol Worthington"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1357.3510646820068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 10862.468957901001, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2000.2942085266113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 4489.145040512085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2468.440055847168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2538}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 19035.460472106934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3178}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 4473.521709442139, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "212435016090205927", "question": "who played g baby in the movie hardball", "gold_answers": ["DeWayne Warren"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1218.1968688964844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1596.1296558380127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3580.256462097168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 13007.981538772583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 6268.611669540405, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2449}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 13630.902290344238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3819.298028945923, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3666}}}
{"qid": "-4190633494852415957", "question": "who played john coffey in the movie the green mile", "gold_answers": ["Michael Clarke Duncan"], "shots": {"0": {"k": 0, "answer": "Tom Hanks", "latency_ms": 1041.2917137145996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Clarke Duncan", "latency_ms": 3306.180238723755, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Michael Clarke Duncan", "latency_ms": 6553.824663162231, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1227}, "3": {"k": 3, "answer": "Michael Clarke Duncan", "latency_ms": 2089.343547821045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1799}, "4": {"k": 4, "answer": "Michael Clarke Duncan", "latency_ms": 7507.398366928101, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2438}, "5": {"k": 5, "answer": "Michael Clarke Duncan", "latency_ms": 2865.969657897949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3023}, "6": {"k": 6, "answer": "Michael Clarke Duncan", "latency_ms": 3074.288845062256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "811267239470530686", "question": "who wrote catch 22 (both names)", "gold_answers": ["American author Joseph Heller", "Joseph Heller .", "Joseph Heller"], "shots": {"0": {"k": 0, "answer": "Joseph Heller", "latency_ms": 809.6411228179932, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1546.8430519104004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 609}, "2": {"k": 2, "answer": "Tomas Kalnoky", "latency_ms": 6199.3749141693115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "Joseph Heller", "latency_ms": 3274.6667861938477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Joseph Heller", "latency_ms": 4488.959074020386, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2606}, "5": {"k": 5, "answer": "Joseph Heller", "latency_ms": 2783.1432819366455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Joseph Heller", "latency_ms": 2881.9682598114014, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3828}}}
{"qid": "-1608179127534867277", "question": "where was the world chess tournament 2017 held", "gold_answers": ["Tbilisi , Georgia", "in Tbilisi , Georgia"], "shots": {"0": {"k": 0, "answer": "Budapest, Hungary", "latency_ms": 1448.9037990570068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1794.7571277618408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3820.9779262542725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "Tbilisi, Georgia", "latency_ms": 2824.8696327209473, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1939}, "4": {"k": 4, "answer": "Tbilisi, Georgia", "latency_ms": 3116.3504123687744, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2597}, "5": {"k": 5, "answer": "Tbilisi, Georgia", "latency_ms": 14134.602308273315, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3261}, "6": {"k": 6, "answer": "Tbilisi, Georgia", "latency_ms": 8765.633344650269, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3966}}}
{"qid": "7687115121611301468", "question": "who votes to elect a rajya sabha memmber", "gold_answers": ["state legislatures"], "shots": {"0": {"k": 0, "answer": "Elected by the state legislative assemblies", "latency_ms": 1411.1130237579346, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Electors in the respective states and union territories", "latency_ms": 2294.8172092437744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2643.150806427002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1160}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 4993.165016174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1795}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 10655.521631240845, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2432}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 7401.397943496704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3061}, "6": {"k": 6, "answer": "electoral college of the elected members of the State Assembly", "latency_ms": 5955.068349838257, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 3695}}}
{"qid": "-5784633834792163973", "question": "when does season 8 of hawaii five o premiere", "gold_answers": ["September 29 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 4193.995475769043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 29, 2017", "latency_ms": 3638.3936405181885, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "September 29, 2017", "latency_ms": 7058.293342590332, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "September 29, 2017", "latency_ms": 3700.6325721740723, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "September 29, 2017", "latency_ms": 20348.82688522339, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2477}, "5": {"k": 5, "answer": "September 29, 2017", "latency_ms": 8291.809797286987, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "September 29, 2017", "latency_ms": 13806.014776229858, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3801}}}
{"qid": "-5864397450755103545", "question": "paul walkers cars in fast and furious list", "gold_answers": ["1995 Toyota Supra", "2002 Mitsubishi Lancer OZ Rally", "1995 Dodge Stealth", "1995 Mitsubishi Eclipse"], "shots": {"0": {"k": 0, "answer": "Pontiac Firebird, Dodge Charger, Toyota Supra, Nissan 350Z, Mitsubishi Lancer, Ford Mustang, Chevrolet Camaro, Dodge Viper, BMW M3, Honda Civic, Toyota Corolla, Ford Explorer, Nissan Skyline, Toyota Land Cruiser, Chevrolet Silverado, Ford F-150, Toyota Tundra, Honda CR-V, Toyota RAV4, Ford Ranger, Chevrolet Tahoe, Toyota 4Runner, Honda Odyssey, Toyota Sienna, Ford Transit, Chevrolet Suburban, Ford Expedition, Toyota Highlander, Honda Pilot, Toyota Camry, Ford Focus, Honda Accord, Toyota Corolla, Ford Escape, Honda CR-V, Toyota RAV4, Ford Transit, Chevrolet Suburban, Ford Expedition, Toyota Highlander, Honda Pilot, Toyota Camry, Ford Focus, Honda Accord, Toyota Corolla, Ford Escape, Honda CR-V, Toyota RAV4, Ford Transit, Chevrolet Suburban, Ford Expedition, Toyota Highlander, Honda Pilot, Toyota Camry, Ford Focus, Honda Accord, Toyota Corolla, Ford Escape, Honda CR-V, Toyota RAV4, Ford Transit, Chevrolet Suburban, Ford Expedition, Toyota Highlander, Honda Pilot, Toyota Camry, Ford Focus, Honda Accord, Toyota Corolla, Ford Escape", "latency_ms": 51902.19283103943, "em": 0.0, "f1": 0.027777777777777776, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2876.903533935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2631.1194896698, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 4101.536512374878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2727.3457050323486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2438}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3221.9297885894775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3071}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3290.9324169158936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3688}}}
{"qid": "-8491157534197669091", "question": "who won the oscar for best actor in 1975", "gold_answers": ["Art Carney"], "shots": {"0": {"k": 0, "answer": "Dustin Hoffman", "latency_ms": 1246.382236480713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 11138.224363327026, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 10090.17300605774, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3563.0664825439453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1782}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2814.9502277374268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2425}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 8025.182723999023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3014}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 7920.185089111328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3624}}}
{"qid": "-8408640804522114136", "question": "when did the first episode of that 70s show air", "gold_answers": ["August 23 , 1998"], "shots": {"0": {"k": 0, "answer": "July 15, 1998", "latency_ms": 5511.822938919067, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3490.504264831543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2229.0565967559814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1175}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 5726.344347000122, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1802}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 5590.315580368042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2400}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3356.1413288116455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2995}, "6": {"k": 6, "answer": "3 January 1988", "latency_ms": 10893.542289733887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3595}}}
{"qid": "722920117313579366", "question": "when did the book thief movie come out", "gold_answers": ["November 27 , 2013", "2013"], "shots": {"0": {"k": 0, "answer": "2013", "latency_ms": 1056.5502643585205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2013", "latency_ms": 10368.618726730347, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 637}, "2": {"k": 2, "answer": "2013", "latency_ms": 1981.823205947876, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1233}, "3": {"k": 3, "answer": "2013", "latency_ms": 2200.3443241119385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1876}, "4": {"k": 4, "answer": "March 11, 2014", "latency_ms": 6605.0567626953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2449}, "5": {"k": 5, "answer": "2013", "latency_ms": 3388.5350227355957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3061}, "6": {"k": 6, "answer": "March 11, 2014", "latency_ms": 4505.9850215911865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3718}}}
{"qid": "-4427112594024146143", "question": "when did the eagles win the super bowl", "gold_answers": ["2017"], "shots": {"0": {"k": 0, "answer": "1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002", "latency_ms": 57500.18358230591, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Super Bowl LII", "latency_ms": 8161.967515945435, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "Super Bowl LII", "latency_ms": 5809.215307235718, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "2018", "latency_ms": 2276.0000228881836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1875}, "4": {"k": 4, "answer": "2018", "latency_ms": 22495.772123336792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2479}, "5": {"k": 5, "answer": "2018", "latency_ms": 13858.247995376587, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3070}, "6": {"k": 6, "answer": "2018", "latency_ms": 3067.194938659668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3672}}}
{"qid": "7078422108284431587", "question": "who is the biggest selling female group of all time", "gold_answers": ["Spice Girls"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1932.225227355957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spice Girls", "latency_ms": 13934.60202217102, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 676}, "2": {"k": 2, "answer": "Spice Girls", "latency_ms": 13957.845211029053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Spice Girls", "latency_ms": 2527.0957946777344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1877}, "4": {"k": 4, "answer": "Spice Girls", "latency_ms": 2339.6382331848145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2463}, "5": {"k": 5, "answer": "Spice Girls", "latency_ms": 2767.3840522766113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3076}, "6": {"k": 6, "answer": "Spice Girls", "latency_ms": 17636.215448379517, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3651}}}
{"qid": "1039102546557940080", "question": "who sang from russia with love james bond", "gold_answers": ["Matt Monro"], "shots": {"0": {"k": 0, "answer": "Tommy Steele", "latency_ms": 1044.1832542419434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 4404.792308807373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 6781.959295272827, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "Matt Monro", "latency_ms": 2438.688039779663, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Matt Monro", "latency_ms": 8106.251001358032, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2517}, "5": {"k": 5, "answer": "Matt Monro", "latency_ms": 10171.569108963013, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Matt Monro", "latency_ms": 4989.524364471436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3845}}}
{"qid": "-8507438636601119973", "question": "where is urinary bladder located in human body", "gold_answers": ["on the pelvic floor", "pelvic floor"], "shots": {"0": {"k": 0, "answer": "pelvic cavity", "latency_ms": 1096.8384742736816, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "base of the pelvis", "latency_ms": 2125.736951828003, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "at the base of the pelvis", "latency_ms": 2519.3817615509033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1232}, "3": {"k": 3, "answer": "base of the pelvis", "latency_ms": 4400.708913803101, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "on the pelvic floor", "latency_ms": 3346.363306045532, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2544}, "5": {"k": 5, "answer": "base of the pelvis", "latency_ms": 3143.3608531951904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3201}, "6": {"k": 6, "answer": "base of the pelvis", "latency_ms": 10814.810752868652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3877}}}
{"qid": "-1996951438961136762", "question": "architectural elements forming rib vaults eg wells cathedral", "gold_answers": ["two to three barrel vaults", "an armature of piped masonry", "barrel vaults"], "shots": {"0": {"k": 0, "answer": "wells", "latency_ms": 1677.8137683868408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "rib vaults", "latency_ms": 2764.695644378662, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "multiplicity of ribs", "latency_ms": 4305.530548095703, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "ribs", "latency_ms": 3129.1301250457764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "ribs, piped masonry, decorative patterns", "latency_ms": 5621.749639511108, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 2530}, "5": {"k": 5, "answer": "ribs", "latency_ms": 2893.315315246582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3193}, "6": {"k": 6, "answer": "ribs", "latency_ms": 2537.818193435669, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3838}}}
{"qid": "-8490085242981497626", "question": "who sang gonna sit right down and write myself a letter", "gold_answers": ["Fats Waller"], "shots": {"0": {"k": 0, "answer": "Linda Ronstadt", "latency_ms": 1274.5654582977295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fats Waller", "latency_ms": 1602.6170253753662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "Fats Waller", "latency_ms": 2117.9873943328857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Fats Waller, Cleo Laine, Uncle Floyd, Madeleine Peyroux, Tony Danza, Paul McCartney, Gregory Isaacs, Barry Manilow, Dean Martin, Anne Murray, Willie Nelson, Linda Scott, Shakin' Stevens, Al Bowlly, Sarah Vaughan, Charlie Gracie, Bill Haley & His Comets, Fabian", "latency_ms": 32719.87223625183, "em": 0.0, "f1": 0.10256410256410257, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Fats Waller, Cleo Laine, Tony Danza, Paul McCartney, Gregory Isaacs, Barry Manilow, Dean Martin, Anne Murray, Willie Nelson, Linda Scott, Shakin' Stevens, Al Bowlly, Sarah Vaughan, Charlie Gracie, Bill Haley & His Comets, Fabian, Billy Williams, Frank Sinatra, Bing Crosby, Nat \"King\" Cole, Scatman Crothers", "latency_ms": 24285.303115844727, "em": 0.0, "f1": 0.08695652173913045, "containment": 1.0, "context_chars": 2585}, "5": {"k": 5, "answer": "Fats Waller, Cleo Laine, Tony Danza, Paul McCartney, Charlie Gracie, Bill Haley & His Comets, Fabian, Frank Sinatra, Bing Crosby, The Boswell Sisters, Connee Boswell, Nat \"King\" Cole, Scatman Crothers, Barry Manilow, Dean Martin, Anne Murray, Willie Nelson, Linda Scott, Shakin' Stevens, Al Bowlly, Sarah Vaughan, Uncle Floyd, Madeleine Peyroux", "latency_ms": 43557.94620513916, "em": 0.0, "f1": 0.07999999999999999, "containment": 1.0, "context_chars": 3193}, "6": {"k": 6, "answer": "Fats Waller, Cleo Laine, Uncle Floyd, Madeleine Peyroux, Tony Danza, Paul McCartney, Gregory Isaacs, Barry Manilow, Dean Martin, Anne Murray, Willie Nelson, Linda Scott, Shakin' Stevens, Al Bowlly, Sarah Vaughan, Charlie Gracie, Bill Haley & His Comets, Fabian, Frank Sinatra, Bing Crosby, The Boswell Sisters, Connee Boswell, Nat \"King\" Cole, Scatman Crothers", "latency_ms": 26492.260217666626, "em": 0.0, "f1": 0.07692307692307693, "containment": 1.0, "context_chars": 3798}}}
{"qid": "8783361206191889627", "question": "how many rooms is there in buckingham palace", "gold_answers": ["775 rooms", "775"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 9588.821172714233, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "775 rooms", "latency_ms": 6567.648410797119, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "775 rooms", "latency_ms": 1985.7823848724365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1222}, "3": {"k": 3, "answer": "775 rooms", "latency_ms": 4388.507843017578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1827}, "4": {"k": 4, "answer": "775 rooms", "latency_ms": 9647.262334823608, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2438}, "5": {"k": 5, "answer": "775 rooms", "latency_ms": 4262.441396713257, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3044}, "6": {"k": 6, "answer": "775 rooms", "latency_ms": 3008.5196495056152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3690}}}
{"qid": "1172792682698457582", "question": "where did they get the tree for rockefeller center", "gold_answers": ["State College , PA"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1234.3165874481201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "upstate New York and surrounding states, and even Ottawa in Ontario, Canada", "latency_ms": 3779.390573501587, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "upstate New York and surrounding states, and even Ottawa in Ontario, Canada", "latency_ms": 4672.325134277344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1314}, "3": {"k": 3, "answer": "upstate New York and surrounding states, and even Ottawa in Ontario, Canada", "latency_ms": 4716.103315353394, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "upstate New York and surrounding states, and even Ottawa in Ontario, Canada", "latency_ms": 6620.715856552124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2623}, "5": {"k": 5, "answer": "upstate New York and surrounding states, and even Ottawa in Ontario, Canada", "latency_ms": 24727.617025375366, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3301}, "6": {"k": 6, "answer": "upstate New York and surrounding states, and even Ottawa in Ontario, Canada", "latency_ms": 5821.351766586304, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3990}}}
{"qid": "-8616225749004085214", "question": "who expanded the territory of china during the qing dynasty", "gold_answers": ["Prince Bao", "the Qianlong Emperor", "Qianlong"], "shots": {"0": {"k": 0, "answer": "Qing Dynasty emperors, including Kangxi and Qianlong", "latency_ms": 4601.126194000244, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Manchu Aisin Gioro clan", "latency_ms": 2628.1509399414062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Qing dynasty", "latency_ms": 2950.371503829956, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "Qing dynasty", "latency_ms": 3024.906635284424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "Qing dynasty", "latency_ms": 5411.062955856323, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2632}, "5": {"k": 5, "answer": "European empires", "latency_ms": 13370.33724784851, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3300}, "6": {"k": 6, "answer": "Qing dynasty", "latency_ms": 2760.3375911712646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3919}}}
{"qid": "-4544825586005995775", "question": "what is the second largest country in asia", "gold_answers": ["China"], "shots": {"0": {"k": 0, "answer": "India", "latency_ms": 1885.63871383667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1374.5040893554688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1918.1880950927734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Iran", "latency_ms": 4769.926309585571, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "Iran", "latency_ms": 3582.247257232666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "Iran", "latency_ms": 22353.139638900757, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3075}, "6": {"k": 6, "answer": "Iran", "latency_ms": 4648.972749710083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3778}}}
{"qid": "2851585794686488659", "question": "when was the last episode of vampire diaries aired", "gold_answers": ["March 10 , 2017"], "shots": {"0": {"k": 0, "answer": "2017", "latency_ms": 1231.999397277832, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "April 28, 2011", "latency_ms": 3022.416830062866, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "March 10, 2017", "latency_ms": 4977.443695068359, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "March 10, 2017", "latency_ms": 19724.493503570557, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1955}, "4": {"k": 4, "answer": "March 10, 2017", "latency_ms": 19404.395580291748, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2589}, "5": {"k": 5, "answer": "March 10, 2017", "latency_ms": 9048.378467559814, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3204}, "6": {"k": 6, "answer": "March 10, 2017", "latency_ms": 16335.848093032837, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3841}}}
{"qid": "636692438616046367", "question": "who played ashley on the young and the restless", "gold_answers": ["Shari Shattuck", "Eileen Davidson", "Brenda Epperson"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2443.983554840088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eileen Davidson", "latency_ms": 1379.3253898620605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 629}, "2": {"k": 2, "answer": "Eileen Davidson", "latency_ms": 1815.8831596374512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Eileen Davidson", "latency_ms": 8314.022302627563, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1868}, "4": {"k": 4, "answer": "Eileen Davidson", "latency_ms": 4229.689121246338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2498}, "5": {"k": 5, "answer": "Eileen Davidson, Brenda Epperson, Shari Shattuck", "latency_ms": 7346.112012863159, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3082}, "6": {"k": 6, "answer": "Eileen Davidson", "latency_ms": 10892.379999160767, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3692}}}
{"qid": "-2668952310493902320", "question": "who has scored the most points for wales v france", "gold_answers": ["Neil Jenkins"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1232.750415802002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1602.182149887085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2805.7339191436768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1157}, "3": {"k": 3, "answer": "Barry John", "latency_ms": 4062.5553131103516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1777}, "4": {"k": 4, "answer": "Barry John", "latency_ms": 2476.149082183838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2317}, "5": {"k": 5, "answer": "Barry John", "latency_ms": 2616.6634559631348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2964}, "6": {"k": 6, "answer": "Barry John", "latency_ms": 14500.264644622803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3518}}}
{"qid": "-551363795407275714", "question": "who is pictured on the 5000 dollar bill", "gold_answers": ["James Madison"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 11884.856224060059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 5707.333564758301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2000.0889301300049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 9873.46887588501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 6816.249847412109, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 14223.870754241943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 5082.0152759552, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3806}}}
{"qid": "-1776638341170409438", "question": "what is the strongest earthquake in the united states", "gold_answers": ["1700 Cascadia earthquake", "1964 Alaska earthquake and tsunami"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 3253.448009490967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 4523.265361785889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "2016 Oklahoma earthquake", "latency_ms": 4172.9161739349365, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "2016 Oklahoma earthquake", "latency_ms": 18324.29838180542, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "2016 Oklahoma earthquake", "latency_ms": 5156.048536300659, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2542}, "5": {"k": 5, "answer": "2002 Denali earthquake", "latency_ms": 11210.999011993408, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3140}, "6": {"k": 6, "answer": "2002 Denali earthquake", "latency_ms": 4507.94792175293, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3761}}}
{"qid": "-3417376069582577712", "question": "who wrote the song balls to the wall", "gold_answers": ["Herman Frank", "Peter Baltes", "Stefan Kaufmann", "Wolf Hoffmann", "Udo Dirkschneider", "Deaffy"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1276.1390209197998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Accept", "latency_ms": 1782.1447849273682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "Wolf Hoffmann", "latency_ms": 6542.477369308472, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1186}, "3": {"k": 3, "answer": "Wolf Hoffmann", "latency_ms": 3504.3697357177734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1866}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 16238.09790611267, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2462}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 7407.731771469116, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3093}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3500.427484512329, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-5788046732019278353", "question": "who talks for belle in beauty and the beast", "gold_answers": ["Julie Nathanson", "Jodi Benson", "Paige O'Hara"], "shots": {"0": {"k": 0, "answer": "Gaston", "latency_ms": 1824.6409893035889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Paige O'Hara", "latency_ms": 7014.0252113342285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 689}, "2": {"k": 2, "answer": "Paige O'Hara", "latency_ms": 3975.4395484924316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Paige O'Hara", "latency_ms": 5798.94495010376, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Paige O'Hara", "latency_ms": 7631.843328475952, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2606}, "5": {"k": 5, "answer": "Paige O'Hara", "latency_ms": 9135.218143463135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3273}, "6": {"k": 6, "answer": "Paige O'Hara", "latency_ms": 5592.789173126221, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3863}}}
{"qid": "-819495145099806596", "question": "what is a coherent set of values and beliefs about public policy called", "gold_answers": ["political ideology", "ideology", "a political ideology"], "shots": {"0": {"k": 0, "answer": "political ideology", "latency_ms": 1068.343162536621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3073.44126701355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Coherentism", "latency_ms": 4590.987205505371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1351}, "3": {"k": 3, "answer": "Coherentism", "latency_ms": 1794.7275638580322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1950}, "4": {"k": 4, "answer": "Group of Five", "latency_ms": 4633.296728134155, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2635}, "5": {"k": 5, "answer": "Group of Five", "latency_ms": 8017.182111740112, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3249}, "6": {"k": 6, "answer": "Group of Five", "latency_ms": 5630.386590957642, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3970}}}
{"qid": "-467801736331608973", "question": "when do liam and annie get together season 3", "gold_answers": ["Holiday Madness"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1279.2937755584717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3702.45361328125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3024.149179458618, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 4950.1953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1816}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 22327.818393707275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2405}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2443.669319152832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2962}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 10493.66283416748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3512}}}
{"qid": "7210975046317501288", "question": "what breed of cat has spots and stripes", "gold_answers": ["tabby"], "shots": {"0": {"k": 0, "answer": "tiger cat", "latency_ms": 1083.1725597381592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 8217.164039611816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Fishing cat", "latency_ms": 2409.9326133728027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1135}, "3": {"k": 3, "answer": "Fishing cat", "latency_ms": 1810.4195594787598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1739}, "4": {"k": 4, "answer": "Bengal cat", "latency_ms": 3175.813674926758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2384}, "5": {"k": 5, "answer": "Bengal cat", "latency_ms": 3139.012575149536, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2963}, "6": {"k": 6, "answer": "Bengal cat", "latency_ms": 3287.4557971954346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3507}}}
{"qid": "7817340376558760325", "question": "who voiced simba in the lion king 2", "gold_answers": ["Matthew Broderick"], "shots": {"0": {"k": 0, "answer": "James Earl Jones", "latency_ms": 1042.3901081085205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2817.803382873535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3210.627317428589, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 9047.46961593628, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 4236.665725708008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2802.684783935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3173}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2956.015110015869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3826}}}
{"qid": "7584034394038581786", "question": "when did the angel of the north get built", "gold_answers": ["1998", "1994"], "shots": {"0": {"k": 0, "answer": "2000", "latency_ms": 1258.4238052368164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1817.7154064178467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 4262.153625488281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 8680.466651916504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 7641.884326934814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2548}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 7070.422649383545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3142}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 20867.319345474243, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3730}}}
{"qid": "1854394640394891866", "question": "when did mcgee became a regular on ncis", "gold_answers": ["in season two", "season two"], "shots": {"0": {"k": 0, "answer": "2004", "latency_ms": 7495.649576187134, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Season 1", "latency_ms": 1970.1206684112549, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2957.3535919189453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "September 28, 2004", "latency_ms": 5178.707838058472, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "September 28, 2004", "latency_ms": 3879.188060760498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "2003", "latency_ms": 11055.901288986206, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3178}, "6": {"k": 6, "answer": "2004", "latency_ms": 9919.967412948608, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3800}}}
{"qid": "2247250807557083996", "question": "when was 1 john 5 7 added to the bible", "gold_answers": ["the 9th century"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 5940.044403076172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1821.8908309936523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 547}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 4937.855958938599, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1150}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1855.332612991333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1697}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 7085.429430007935, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2253}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 7041.189908981323, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2828}, "6": {"k": 6, "answer": "19th century", "latency_ms": 13592.467069625854, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3506}}}
{"qid": "-2049551589682654986", "question": "when was the latest version of chrome released", "gold_answers": ["2018 - 01 - 22"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1273.751974105835, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "May 25, 2010", "latency_ms": 14646.102666854858, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "May 25, 2010", "latency_ms": 3593.428373336792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 9999.484539031982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1833}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 7211.439371109009, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3494.771718978882, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3100}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3648.341417312622, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3724}}}
{"qid": "-3534092359651954035", "question": "who is jojo in horton hears a who", "gold_answers": ["Jesse McCartney"], "shots": {"0": {"k": 0, "answer": "Jojo is not a character in \"Horton Hears a Who!\" The character is named Jojo in \"The Adventures of Jimmy Neutron: Boy Genius,\" not in \"Horton Hears a Who.\" Therefore, Jojo is not in \"Horton Hears a Who.\" I cannot answer.", "latency_ms": 13815.820693969727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1594.2046642303467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "JoJo is the teenage son of Mayor Ned McDodd in Whoville.", "latency_ms": 4462.195158004761, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1201}, "3": {"k": 3, "answer": "JoJo is the teenage son of Mayor Ned McDodd in Whoville.", "latency_ms": 4705.661058425903, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1781}, "4": {"k": 4, "answer": "JoJo is the teenage son of the Mayor of Whoville and a member of the Whos.", "latency_ms": 5955.532550811768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2370}, "5": {"k": 5, "answer": "JoJo is the teenage son of the Mayor of Whoville and a small shirker who plays with a yo-yo instead of making noise.", "latency_ms": 11148.032426834106, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3016}, "6": {"k": 6, "answer": "JoJo is the teenage son of the Mayor of Whoville and a small shirker who plays with a yo-yo instead of making noise.", "latency_ms": 9478.489875793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3622}}}
{"qid": "6504412384445795967", "question": "the part of the cytoskeleton made from the protein actin is called", "gold_answers": ["Microfilaments", "microfilament"], "shots": {"0": {"k": 0, "answer": "microfilaments", "latency_ms": 8885.175943374634, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "actin cytoskeleton", "latency_ms": 5750.0, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "microfilaments", "latency_ms": 3757.3676109313965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1379}, "3": {"k": 3, "answer": "microfilaments", "latency_ms": 5905.13277053833, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2037}, "4": {"k": 4, "answer": "microfilaments", "latency_ms": 4146.555185317993, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2767}, "5": {"k": 5, "answer": "microfilaments", "latency_ms": 6356.730937957764, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3375}, "6": {"k": 6, "answer": "microfilaments", "latency_ms": 10837.656021118164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4073}}}
{"qid": "95888218441734902", "question": "who plays jack in battle of the sexes", "gold_answers": ["Bill Pullman", "( Bill Pullman"], "shots": {"0": {"k": 0, "answer": "Peter Falk", "latency_ms": 1983.7329387664795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Robert Harron", "latency_ms": 1407.0396423339844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Robert Harron", "latency_ms": 5370.482683181763, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2512.432336807251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2701.4477252960205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2397}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 9190.600633621216, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2992}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 9040.883779525757, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3655}}}
{"qid": "2482202658787537401", "question": "is a network connection device that can build tables that identify addresses on each network", "gold_answers": ["routing table", "a router"], "shots": {"0": {"k": 0, "answer": "switch", "latency_ms": 1952.8920650482178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1754.7366619110107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 693}, "2": {"k": 2, "answer": "router", "latency_ms": 1299.5209693908691, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1418}, "3": {"k": 3, "answer": "router", "latency_ms": 2722.1527099609375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2097}, "4": {"k": 4, "answer": "router", "latency_ms": 13403.473854064941, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2731}, "5": {"k": 5, "answer": "router", "latency_ms": 3849.672317504883, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3397}, "6": {"k": 6, "answer": "router", "latency_ms": 2486.673355102539, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4070}}}
{"qid": "8359496728452221378", "question": "when did the royal proclamation of 1763 end", "gold_answers": ["with the American Revolutionary War", "the American Revolutionary War", "1783"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1250.1146793365479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 4403.890132904053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1961.5256786346436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1387}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 14357.643365859985, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2065}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 4619.059085845947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2750}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3120.5713748931885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3400}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 8403.865098953247, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4009}}}
{"qid": "-2657014790962135860", "question": "the tenure of the office of the lokayukt of up", "gold_answers": ["8 years", "eight years"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1033.2598686218262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1839.7786617279053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2001.72758102417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 4554.224491119385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 24536.382913589478, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2525}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 9204.29515838623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3137}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3910.4321002960205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3804}}}
{"qid": "1827180983934640653", "question": "when did response to state of the union start", "gold_answers": ["1966", "in 1966"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1351.7098426818848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1936", "latency_ms": 2564.2831325531006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "1970", "latency_ms": 13173.131227493286, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "1966", "latency_ms": 4005.455493927002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2022}, "4": {"k": 4, "answer": "1966", "latency_ms": 2529.6311378479004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2687}, "5": {"k": 5, "answer": "1966", "latency_ms": 3006.572484970093, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3361}, "6": {"k": 6, "answer": "1966", "latency_ms": 2972.364902496338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4022}}}
{"qid": "-8006002028754190814", "question": "who had the most governmental power under the articles of confederation", "gold_answers": ["the states"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2560.8816146850586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the states", "latency_ms": 6683.883428573608, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "Congress of the Confederation", "latency_ms": 2562.4637603759766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1392}, "3": {"k": 3, "answer": "the states", "latency_ms": 1846.804141998291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2115}, "4": {"k": 4, "answer": "Congress", "latency_ms": 5165.996789932251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2787}, "5": {"k": 5, "answer": "the states", "latency_ms": 5589.50400352478, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3455}, "6": {"k": 6, "answer": "the states", "latency_ms": 14260.63847541809, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4138}}}
{"qid": "3406509904702130536", "question": "how many hospitals are there in the united states", "gold_answers": ["5,534 registered hospitals", "5,534"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1221.5361595153809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5,534", "latency_ms": 3551.9378185272217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 723}, "2": {"k": 2, "answer": "5,534", "latency_ms": 20411.157369613647, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1403}, "3": {"k": 3, "answer": "5,534", "latency_ms": 14720.22533416748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2052}, "4": {"k": 4, "answer": "5,534", "latency_ms": 9254.156589508057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2762}, "5": {"k": 5, "answer": "5,534", "latency_ms": 4473.868846893311, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3402}, "6": {"k": 6, "answer": "5,534", "latency_ms": 3290.301561355591, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4122}}}
{"qid": "2435796066046322163", "question": "who donates a christmas tree to trafalgar square", "gold_answers": ["Oslo , Norway"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1246.3359832763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Oslo, Norway", "latency_ms": 3417.3882007598877, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "Oslo, Norway", "latency_ms": 10411.83352470398, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Oslo, Norway", "latency_ms": 4784.982204437256, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Oslo, Norway", "latency_ms": 2429.564952850342, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "Oslo, Norway", "latency_ms": 9874.417066574097, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3139}, "6": {"k": 6, "answer": "Oslo", "latency_ms": 2551.96475982666, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3783}}}
{"qid": "4926415052497472665", "question": "who starred in the movie on golden pond", "gold_answers": ["William Lanteau", "Dabney Coleman", "Henry Fonda", "Doug McKeon", "Jane Fonda", "Christopher Rydell", "Katharine Hepburn"], "shots": {"0": {"k": 0, "answer": "Elliott Gould", "latency_ms": 2618.000030517578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Julie Andrews, Christopher Plummer, Glenne Headly", "latency_ms": 3412.346363067627, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Julie Andrews and Christopher Plummer", "latency_ms": 2605.4940223693848, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Julie Andrews and Christopher Plummer", "latency_ms": 2953.688144683838, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Katharine Hepburn, Henry Fonda, Jane Fonda", "latency_ms": 11380.002975463867, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2510}, "5": {"k": 5, "answer": "Katharine Hepburn, Henry Fonda, Jane Fonda", "latency_ms": 4881.535053253174, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Katharine Hepburn, Henry Fonda, Jane Fonda", "latency_ms": 4734.214782714844, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3737}}}
{"qid": "2142753216627246962", "question": "isdn uses b & d channels. what is d channel use for", "gold_answers": ["carries control and signaling information", "data", "control and signaling information"], "shots": {"0": {"k": 0, "answer": "D channel is used for signaling.", "latency_ms": 1884.8612308502197, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "control and signaling information", "latency_ms": 11902.522563934326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "control and signaling information", "latency_ms": 1899.4247913360596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1365}, "3": {"k": 3, "answer": "control and signaling information", "latency_ms": 5953.01365852356, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1970}, "4": {"k": 4, "answer": "control and signaling information", "latency_ms": 8361.918449401855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2694}, "5": {"k": 5, "answer": "control and signaling information", "latency_ms": 7187.705516815186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3358}, "6": {"k": 6, "answer": "control and signaling information", "latency_ms": 3555.842399597168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3966}}}
{"qid": "1547060614805522730", "question": "what is the rate limiting enzyme of kreb's cycle", "gold_answers": ["Isocitrate dehydrogenase"], "shots": {"0": {"k": 0, "answer": "Isocitrate dehydrogenase", "latency_ms": 1407.3801040649414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3161.4718437194824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 682}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 4876.641273498535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 5477.5071144104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2046}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 8156.614780426025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2675}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3176.5918731689453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3316}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3716.603994369507, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3959}}}
{"qid": "8965198420725510475", "question": "when was the taj mahal built and completed", "gold_answers": ["1632 -- 53"], "shots": {"0": {"k": 0, "answer": "16321653", "latency_ms": 3340.5630588531494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1868.4983253479004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2057.30938911438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1209}, "3": {"k": 3, "answer": "built in the 17th century, completed in 1643", "latency_ms": 4853.681564331055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "1643 (mausoleum completed), 1653 (entire complex completed)", "latency_ms": 11905.351400375366, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2492}, "5": {"k": 5, "answer": "1632 AD to 1653", "latency_ms": 6876.352071762085, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3122}, "6": {"k": 6, "answer": "1632 AD to 1653", "latency_ms": 10938.161373138428, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3787}}}
{"qid": "-6292760252056275316", "question": "which supreme court judge has surved in international court of justice", "gold_answers": ["Dalveer Bhandari"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 3851.878881454468, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dalveer Bhandari", "latency_ms": 2146.7032432556152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "Justice Dalveer Bhandari", "latency_ms": 2665.2817726135254, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Justice Dalveer Bhandari", "latency_ms": 3370.643138885498, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2050}, "4": {"k": 4, "answer": "Justice Dalveer Bhandari", "latency_ms": 10063.7686252594, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2660}, "5": {"k": 5, "answer": "Justice Dalveer Bhandari", "latency_ms": 3938.5640621185303, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3282}, "6": {"k": 6, "answer": "Justice Dalveer Bhandari", "latency_ms": 3940.713882446289, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3899}}}
{"qid": "8361850218460994084", "question": "who is known as father of green revolution in india", "gold_answers": ["Mankombu Sambasivan Swaminathan"], "shots": {"0": {"k": 0, "answer": "M.S. Swaminathan", "latency_ms": 1846.6181755065918, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 4590.246677398682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 704}, "2": {"k": 2, "answer": "Norman Borlaug", "latency_ms": 2190.979242324829, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1438}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 6025.543689727783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2174}, "4": {"k": 4, "answer": "M. S. Swaminathan", "latency_ms": 7848.761796951294, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2837}, "5": {"k": 5, "answer": "M. S. Swaminathan", "latency_ms": 5845.420837402344, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3504}, "6": {"k": 6, "answer": "M. S. Swaminathan", "latency_ms": 3789.999485015869, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4197}}}
{"qid": "-5690645328022945594", "question": "who sing say you won't let go", "gold_answers": ["James Arthur"], "shots": {"0": {"k": 0, "answer": "James Arthur Auld", "latency_ms": 2414.8693084716797, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Arthur", "latency_ms": 1381.244421005249, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "James Arthur", "latency_ms": 1566.7152404785156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1176}, "3": {"k": 3, "answer": "James Arthur", "latency_ms": 1893.3804035186768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1797}, "4": {"k": 4, "answer": "James Arthur", "latency_ms": 4315.118312835693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2425}, "5": {"k": 5, "answer": "James Arthur", "latency_ms": 8882.608652114868, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3025}, "6": {"k": 6, "answer": "James Arthur", "latency_ms": 2881.3605308532715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3645}}}
{"qid": "-4292736993227486718", "question": "who monitor the recovery of the location during a disaster", "gold_answers": ["management team"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1013.8936042785645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2102.4489402770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1807.0063591003418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1435}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 5220.3369140625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2106}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 5182.748556137085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2856}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2583.958387374878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3504}, "6": {"k": 6, "answer": "disaster recovery officer", "latency_ms": 3197.420597076416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4232}}}
{"qid": "-4741747756019727470", "question": "where does the synthesis of new dna from existing dna occurs", "gold_answers": ["origins of replication"], "shots": {"0": {"k": 0, "answer": "nucleus", "latency_ms": 897.7851867675781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "replication forks", "latency_ms": 2079.63228225708, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "replication forks", "latency_ms": 5094.435691833496, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1305}, "3": {"k": 3, "answer": "in the cell during DNA replication", "latency_ms": 6607.955694198608, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2003}, "4": {"k": 4, "answer": "at the origin of replication", "latency_ms": 2714.9317264556885, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2665}, "5": {"k": 5, "answer": "during interphase", "latency_ms": 2574.0609169006348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3312}, "6": {"k": 6, "answer": "during interphase", "latency_ms": 10279.072523117065, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3974}}}
{"qid": "4268853195499399258", "question": "who sings gimme shelter with mick jagger", "gold_answers": ["Merry Clayton"], "shots": {"0": {"k": 0, "answer": "Janis Joplin", "latency_ms": 1445.3449249267578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Merry Clayton", "latency_ms": 13733.25800895691, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "Merry Clayton", "latency_ms": 1797.0714569091797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Merry Clayton", "latency_ms": 6351.450681686401, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Merry Clayton", "latency_ms": 2197.9007720947266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2642}, "5": {"k": 5, "answer": "Merry Clayton", "latency_ms": 5709.144830703735, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3302}, "6": {"k": 6, "answer": "Merry Clayton", "latency_ms": 4638.62156867981, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3978}}}
{"qid": "7172420463912356173", "question": "who does tony end up with on skins", "gold_answers": ["Michelle"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1495.2847957611084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 4111.790180206299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3253.432035446167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1179}, "3": {"k": 3, "answer": "the girl", "latency_ms": 1905.0662517547607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1743}, "4": {"k": 4, "answer": "the girl", "latency_ms": 4485.2752685546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2341}, "5": {"k": 5, "answer": "Michelle", "latency_ms": 7742.713212966919, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2966}, "6": {"k": 6, "answer": "Michelle", "latency_ms": 9843.883514404297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3558}}}
{"qid": "-1400292288904470066", "question": "who sings sugar sugar you are my candy girl", "gold_answers": ["the Archies"], "shots": {"0": {"k": 0, "answer": "The Archies", "latency_ms": 1029.1476249694824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1594.240427017212, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2004.288911819458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3073.077917098999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 10023.492097854614, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2589}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3043.1876182556152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3217}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 14077.895402908325, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3851}}}
{"qid": "-1696720698220253139", "question": "who does tyler end up with in you get me", "gold_answers": ["Ali"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 7770.977020263672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lily", "latency_ms": 5564.02325630188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3654.006242752075, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1187}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2050.532579421997, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1795}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 7390.197038650513, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2369}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 8336.585998535156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2942}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3211.254119873047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3499}}}
{"qid": "-6797239474199900801", "question": "who won the gold for the men's figure skating", "gold_answers": ["Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1237.2441291809082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 4133.649587631226, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 702}, "2": {"k": 2, "answer": "Todd Eldredge", "latency_ms": 4543.923139572144, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1380}, "3": {"k": 3, "answer": "Todd Eldredge", "latency_ms": 7082.883596420288, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2096}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 4871.387481689453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2808}, "5": {"k": 5, "answer": "Todd Eldredge", "latency_ms": 3212.0325565338135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3496}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 13471.010446548462, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4236}}}
{"qid": "-7819569157752445011", "question": "when did the song holiday road come out", "gold_answers": ["1983", "June 24 , 1983"], "shots": {"0": {"k": 0, "answer": "2007", "latency_ms": 2547.89662361145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "30th anniversary of the song's release", "latency_ms": 5109.77578163147, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 594}, "2": {"k": 2, "answer": "1983", "latency_ms": 7561.129570007324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "1983", "latency_ms": 2462.8918170928955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1907}, "4": {"k": 4, "answer": "1983", "latency_ms": 2641.6406631469727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "1983", "latency_ms": 4877.353668212891, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "1983", "latency_ms": 5241.225719451904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3853}}}
{"qid": "-8839043176903626071", "question": "when does the mlb season start and finish", "gold_answers": ["October 31 , 2018", "March 29"], "shots": {"0": {"k": 0, "answer": "March 31 to October 4", "latency_ms": 2647.0673084259033, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 12039.307832717896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1914.0052795410156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 9173.21515083313, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1834}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 6981.324672698975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2427}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 8749.106884002686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3016}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 24469.082593917847, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3620}}}
{"qid": "6356531089429364942", "question": "when did scotland beat england in six nations", "gold_answers": ["8 March 2008", "25 February 2006", "24 February 2018", "2 April 2000"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1244.7261810302734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1365.5192852020264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 4187.719106674194, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3104.719400405884, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 5725.559234619141, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2813.3456707000732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3224}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 12576.340198516846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3808}}}
{"qid": "-3382335563294993978", "question": "when did the rational dress society begin to work", "gold_answers": ["1881"], "shots": {"0": {"k": 0, "answer": "1881", "latency_ms": 7184.2217445373535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1881", "latency_ms": 1357.0547103881836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "1881", "latency_ms": 1949.6641159057617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "1881", "latency_ms": 2643.5000896453857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1976}, "4": {"k": 4, "answer": "1881", "latency_ms": 8251.078605651855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2609}, "5": {"k": 5, "answer": "1881", "latency_ms": 3107.717514038086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3236}, "6": {"k": 6, "answer": "1881", "latency_ms": 22896.212339401245, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3849}}}
{"qid": "-5630827734073464379", "question": "why is the indian ocean the warmest in the world", "gold_answers": ["human induced greenhouse warming"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2498.411178588867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 4438.493490219116, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2930.7327270507812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1337}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3700.868606567383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1933}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 6114.809036254883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2611}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2962.6967906951904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3218}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 26540.00997543335, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3927}}}
{"qid": "-3544151584263258729", "question": "where was the film manchester by the sea filmed", "gold_answers": ["Middleton", "Essex", "Gloucester", "Beverly", "Swampscott", "Lynn", "Manchester", "Salem", "Tewksbury"], "shots": {"0": {"k": 0, "answer": "Massachusetts, New Hampshire, and Maine", "latency_ms": 2357.097864151001, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Massachusetts town of the same name as well as Beverly, Essex, Gloucester, Swampscott, Lynn", "latency_ms": 10326.818704605103, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 635}, "2": {"k": 2, "answer": "Massachusetts town of the same name as well as Beverly, Essex, Gloucester, Swampscott, Lynn", "latency_ms": 5635.278701782227, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 1296}, "3": {"k": 3, "answer": "Manchester-by-the-Sea, Massachusetts, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "latency_ms": 10416.277885437012, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 1995}, "4": {"k": 4, "answer": "Manchester-by-the-Sea, Massachusetts, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "latency_ms": 13483.712911605835, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 2623}, "5": {"k": 5, "answer": "Manchester-by-the-Sea, Massachusetts, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "latency_ms": 18497.212886810303, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 3330}, "6": {"k": 6, "answer": "Manchester-by-the-Sea, Massachusetts, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "latency_ms": 21128.25584411621, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 3995}}}
{"qid": "-5077733789764986167", "question": "consist of the sum of the fixed and variable costs for any given level of production", "gold_answers": ["total cost ( TC )"], "shots": {"0": {"k": 0, "answer": "total cost", "latency_ms": 1918.903112411499, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "total cost", "latency_ms": 1831.0136795043945, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "total cost", "latency_ms": 4120.226144790649, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "total cost", "latency_ms": 5121.726512908936, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "total cost", "latency_ms": 8317.978382110596, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2486}, "5": {"k": 5, "answer": "total cost", "latency_ms": 11011.651515960693, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "total cost", "latency_ms": 9350.602626800537, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3755}}}
{"qid": "4892187805447493570", "question": "where was thomas and the magic railroad filmed", "gold_answers": ["Toronto , Ontario , Canada", "Isle of Man", "the Isle of Man"], "shots": {"0": {"k": 0, "answer": "California", "latency_ms": 1726.7842292785645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3843.093156814575, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3147.402763366699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 6754.188299179077, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Strasburg Rail Road", "latency_ms": 2785.6285572052, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "Strasburg Rail Road", "latency_ms": 3415.8902168273926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3172}, "6": {"k": 6, "answer": "Strasburg Rail Road", "latency_ms": 3713.1667137145996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-7094533216301278566", "question": "who has access to the presidential daily briefing", "gold_answers": ["Secretaries of State", "the President", "Defense", "National Security Advisor"], "shots": {"0": {"k": 0, "answer": "Presidential personnel and select advisors", "latency_ms": 5061.7995262146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "President of the United States, approved top-level US officials, President-elect", "latency_ms": 4810.053110122681, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "President of the United States, small number of top-level US officials approved by the President, President-elect of the United States", "latency_ms": 9252.968072891235, "em": 0.0, "f1": 0.1111111111111111, "containment": 1.0, "context_chars": 1334}, "3": {"k": 3, "answer": "President of the United States, small number of top-level US officials approved by the President, President-elect of the United States", "latency_ms": 8937.747240066528, "em": 0.0, "f1": 0.1111111111111111, "containment": 1.0, "context_chars": 2006}, "4": {"k": 4, "answer": "President of the United States and approved top-level US officials", "latency_ms": 21725.343227386475, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2766}, "5": {"k": 5, "answer": "President of the United States, small number of top-level US officials approved by the President, President-elect of the United States", "latency_ms": 17437.031269073486, "em": 0.0, "f1": 0.1111111111111111, "containment": 1.0, "context_chars": 3420}, "6": {"k": 6, "answer": "President of the United States, small number of top-level US officials approved by the President, President-elect of the United States", "latency_ms": 13495.423793792725, "em": 0.0, "f1": 0.1111111111111111, "containment": 1.0, "context_chars": 4155}}}
{"qid": "-243139310037543674", "question": "what tool is available from microsoft as an alternative to the usmt for smaller migrations", "gold_answers": ["Windows Easy Transfer"], "shots": {"0": {"k": 0, "answer": "Microsoft Migration Wizard", "latency_ms": 951.7676830291748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Files and Settings Transfer Wizard", "latency_ms": 2526.522397994995, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Windows Easy Transfer", "latency_ms": 3107.3882579803467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Windows Easy Transfer", "latency_ms": 2100.569725036621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2036}, "4": {"k": 4, "answer": "Windows Easy Transfer", "latency_ms": 2389.4968032836914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2675}, "5": {"k": 5, "answer": "Windows Easy Transfer", "latency_ms": 5467.442750930786, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3377}, "6": {"k": 6, "answer": "Windows Easy Transfer", "latency_ms": 3026.9997119903564, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4083}}}
{"qid": "7079282152145474767", "question": "who appoints the chief election commissioner of india", "gold_answers": ["the president", "President of India"], "shots": {"0": {"k": 0, "answer": "President of India", "latency_ms": 1242.375135421753, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "President of India", "latency_ms": 13187.575578689575, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "President of India", "latency_ms": 3857.9697608947754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1437}, "3": {"k": 3, "answer": "President of India", "latency_ms": 2920.8860397338867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2202}, "4": {"k": 4, "answer": "President of India", "latency_ms": 4717.569351196289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2874}, "5": {"k": 5, "answer": "President of India", "latency_ms": 3789.452075958252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3567}, "6": {"k": 6, "answer": "President of India", "latency_ms": 9813.46344947815, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4272}}}
{"qid": "6303430169473424975", "question": "glycogen and amylopectin are long chains of which simple sugar(s)", "gold_answers": ["glucose"], "shots": {"0": {"k": 0, "answer": "glucose", "latency_ms": 882.2231292724609, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "glucose", "latency_ms": 3350.5241870880127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "glucose", "latency_ms": 3319.962978363037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "glucose", "latency_ms": 2584.9573612213135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1966}, "4": {"k": 4, "answer": "glucose", "latency_ms": 7424.381256103516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2630}, "5": {"k": 5, "answer": "glucose", "latency_ms": 3643.8803672790527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3262}, "6": {"k": 6, "answer": "glucose", "latency_ms": 12478.32727432251, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3958}}}
{"qid": "-3240666523350424161", "question": "who was the editor of the journal jugantor published in the time of swadeshi movement", "gold_answers": ["Bhupendranath Dutt"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 4963.582277297974, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 4020.024061203003, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 5488.9562129974365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1354}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2483.5705757141113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2010}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 8448.888301849365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2701}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 9451.025247573853, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3331}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 5427.665948867798, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3974}}}
{"qid": "1321443496772706078", "question": "when did indoor toilets become common in america", "gold_answers": ["After World War I"], "shots": {"0": {"k": 0, "answer": "1880s", "latency_ms": 1742.7771091461182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1890s", "latency_ms": 13739.434003829956, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "1890s", "latency_ms": 2224.973201751709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "1890s", "latency_ms": 10116.774559020996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "1890s", "latency_ms": 5437.607526779175, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2583}, "5": {"k": 5, "answer": "1890s", "latency_ms": 3057.7609539031982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "1890s", "latency_ms": 6576.79295539856, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3830}}}
{"qid": "6019244948248861067", "question": "who wrote were going on a bear hunt", "gold_answers": ["Michael Rosen"], "shots": {"0": {"k": 0, "answer": "Michael Rosen", "latency_ms": 881.2615871429443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Rosen", "latency_ms": 4910.841464996338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "Michael Rosen", "latency_ms": 5187.766551971436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Michael Rosen", "latency_ms": 8837.331771850586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1802}, "4": {"k": 4, "answer": "Michael Rosen", "latency_ms": 4037.9064083099365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2407}, "5": {"k": 5, "answer": "Michael Rosen", "latency_ms": 4434.0198040008545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3052}, "6": {"k": 6, "answer": "Michael Rosen", "latency_ms": 5036.936283111572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3676}}}
{"qid": "8753987902863757141", "question": "what is the revolution period of venus in earth years", "gold_answers": ["0.615 198 yr", "224.7 Earth days"], "shots": {"0": {"k": 0, "answer": "225 Earth years", "latency_ms": 11197.556495666504, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "225 Earth years", "latency_ms": 1770.190954208374, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "225 Earth years", "latency_ms": 8854.44712638855, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "224.7", "latency_ms": 5153.664588928223, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1843}, "4": {"k": 4, "answer": "224.7 Earth days", "latency_ms": 6931.75745010376, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2469}, "5": {"k": 5, "answer": "224.7 Earth days", "latency_ms": 3883.8579654693604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3085}, "6": {"k": 6, "answer": "224.7", "latency_ms": 4554.168224334717, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3708}}}
{"qid": "-5904934687784134086", "question": "who has the power to approve or veto legislation constitution", "gold_answers": ["the President"], "shots": {"0": {"k": 0, "answer": "President of the United States", "latency_ms": 2307.504892349243, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "governor", "latency_ms": 1485.0397109985352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 609}, "2": {"k": 2, "answer": "President", "latency_ms": 6896.849870681763, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1323}, "3": {"k": 3, "answer": "President", "latency_ms": 1246.2069988250732, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1983}, "4": {"k": 4, "answer": "governor", "latency_ms": 3015.497922897339, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2632}, "5": {"k": 5, "answer": "Governor", "latency_ms": 2070.497512817383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3278}, "6": {"k": 6, "answer": "President", "latency_ms": 2674.1602420806885, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3939}}}
{"qid": "-1910743846708408775", "question": "when was the taming ofthe shrew first performed", "gold_answers": ["prior to June 1592"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1263.7431621551514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 4156.56042098999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 701}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 4882.694959640503, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1353}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2437.281847000122, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1974}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 7494.765996932983, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2593}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 18099.50590133667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3271}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3874.804735183716, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3969}}}
{"qid": "6521877788261380307", "question": "who is the first prime minister of france", "gold_answers": ["Michel Debr"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 8482.87057876587, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 6896.038770675659, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2421.0383892059326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 7362.475872039795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 4350.874662399292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2604}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2467.167377471924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3268}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 11701.743364334106, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3894}}}
{"qid": "-3375621376413612480", "question": "list of strict nature reserve in the philippines", "gold_answers": ["Lake Malimanga", "Palawan", "Calavite and FB Harrison", "Olango Island", "Calauit Safari Park", "Lake Buluan"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1318.2048797607422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 20053.927659988403, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2639.110326766968, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2645.798444747925, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 5250.979661941528, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2609}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3135.8509063720703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3292}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 8402.128219604492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3899}}}
{"qid": "-7848107192827858958", "question": "where do the events in the story take place geographically", "gold_answers": ["Persia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1248.5682964324951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "geographic location", "latency_ms": 3441.2147998809814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "geographic location", "latency_ms": 10300.734043121338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "geographic location", "latency_ms": 1882.0369243621826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "the College, and about the College, in and around the Yard, and near the dormitories", "latency_ms": 8430.113554000854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2367}, "5": {"k": 5, "answer": "Egypt itself", "latency_ms": 9201.59935951233, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2982}, "6": {"k": 6, "answer": "Egypt itself", "latency_ms": 9960.98017692566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3638}}}
{"qid": "-5123704261908217758", "question": "how and why were serial novels a phenomenon in the nineteenth century", "gold_answers": ["improved economics of distribution", "the rise of literacy", "technological advances in printing"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 4339.08486366272, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "serialized to engage audiences, increase circulation, and drive book sales", "latency_ms": 7791.976690292358, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "through audience reaction; increased circulation; production in book form", "latency_ms": 6924.2048263549805, "em": 0.0, "f1": 0.15384615384615383, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Serial novels were a phenomenon in the nineteenth century because they allowed authors and publishers to engage with audiences through ongoing content, respond to reader reactions, and increase circulation, as seen with works like \"The Count of Monte Cristo\" and \"Le Juif errant,\" which boosted newspaper readership and led to widespread popularity and book production.", "latency_ms": 17838.640928268433, "em": 0.0, "f1": 0.03636363636363637, "containment": 0.0, "context_chars": 2024}, "4": {"k": 4, "answer": "Serialized novels were a phenomenon in the nineteenth century due to their ability to engage audiences through installment releases, fostering reader interaction and increasing circulation, as seen with works like \"The Count of Monte Cristo\" and \"Le Juif errant,\" which boosted periodical sales and led to widespread popularity and book form production.", "latency_ms": 16700.52695274353, "em": 0.0, "f1": 0.03846153846153846, "containment": 0.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Serialized novels were a phenomenon in the nineteenth century due to their widespread popularity, ability to engage audiences through ongoing narratives, and the resulting increase in circulation and public interest, as seen with works like \"The Count of Monte Cristo\" and \"Le Juif errant,\" which boosted periodical sales significantly.", "latency_ms": 26201.579332351685, "em": 0.0, "f1": 0.04166666666666667, "containment": 0.0, "context_chars": 3403}, "6": {"k": 6, "answer": "serialized through installments, increased circulation, engaged audience reaction, led to book form production", "latency_ms": 7221.142292022705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4108}}}
{"qid": "8893432128322519771", "question": "who eliminated costa rica in world cup 2014", "gold_answers": ["Netherlands"], "shots": {"0": {"k": 0, "answer": "Germany", "latency_ms": 9207.725763320923, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3988.3227348327637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Turkey", "latency_ms": 1461.0590934753418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Turkey", "latency_ms": 1713.9081954956055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1828}, "4": {"k": 4, "answer": "Turkey", "latency_ms": 7278.396368026733, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2472}, "5": {"k": 5, "answer": "Turkey", "latency_ms": 10281.800508499146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3128}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 8420.951128005981, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3757}}}
{"qid": "-1356405650810931451", "question": "how many countries touches the land boundary of india", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "7", "latency_ms": 622.3411560058594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "6", "latency_ms": 1150.2397060394287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "6", "latency_ms": 1453.1714916229248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1304}, "3": {"k": 3, "answer": "6", "latency_ms": 2267.237424850464, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "6", "latency_ms": 12636.490106582642, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2596}, "5": {"k": 5, "answer": "6", "latency_ms": 5190.446615219116, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "6", "latency_ms": 11660.178661346436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3896}}}
{"qid": "6447777231012695504", "question": "who was the 11th prime minister of canada", "gold_answers": ["R.B. Bennett", "Arthur Meighen"], "shots": {"0": {"k": 0, "answer": "Pierre Elliott Trudeau", "latency_ms": 1271.4760303497314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1769.8259353637695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 4635.408639907837, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 8261.045932769775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1957}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 7565.746068954468, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2607}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 13667.722225189209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3249}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 6779.296398162842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3903}}}
{"qid": "-5935683210985272192", "question": "when did the steel mills closed in youngstown ohio", "gold_answers": ["September 19 , 1977"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1133.631944656372, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 19, 1977", "latency_ms": 2558.1116676330566, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "1977", "latency_ms": 2580.303907394409, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "September 19, 1977", "latency_ms": 3781.161308288574, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1958}, "4": {"k": 4, "answer": "September 19, 1977", "latency_ms": 11665.287733078003, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "September 19, 1977", "latency_ms": 4067.6286220550537, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "September 19, 1977", "latency_ms": 5212.639093399048, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3947}}}
{"qid": "1834961239491311230", "question": "who owns and operates the panama canal today", "gold_answers": ["Panama Canal Authority", "Panama", "Panamanian government"], "shots": {"0": {"k": 0, "answer": "Panama Canal Authority", "latency_ms": 2264.336109161377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kansas City Southern and Mi-Jack Products own and operate the Panama Canal Railway today.", "latency_ms": 3993.8836097717285, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Panama Canal Authority", "latency_ms": 2065.221071243286, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Panama Canal Authority", "latency_ms": 2491.3108348846436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1956}, "4": {"k": 4, "answer": "Panama Canal Authority", "latency_ms": 4420.66764831543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2641}, "5": {"k": 5, "answer": "Panama Canal Authority", "latency_ms": 6394.449234008789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3313}, "6": {"k": 6, "answer": "Panama Canal Authority", "latency_ms": 5272.845506668091, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3959}}}
{"qid": "-535648230475805474", "question": "where is a simple gear train used in real life", "gold_answers": ["Automobile drivetrains"], "shots": {"0": {"k": 0, "answer": "Cars", "latency_ms": 743.206262588501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "car transmission", "latency_ms": 1426.6893863677979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "car transmission", "latency_ms": 3598.5069274902344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1224}, "3": {"k": 3, "answer": "automobile manual transmission", "latency_ms": 6079.277753829956, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1842}, "4": {"k": 4, "answer": "automobile manual transmission", "latency_ms": 3402.411460876465, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2492}, "5": {"k": 5, "answer": "automobile manual transmission", "latency_ms": 12959.635019302368, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "automobile manual transmission", "latency_ms": 9233.26826095581, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3614}}}
{"qid": "8911390210346559626", "question": "who plays the dad in malcom in the middle", "gold_answers": ["Bryan Cranston"], "shots": {"0": {"k": 0, "answer": "John Rigby", "latency_ms": 6988.823413848877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2257.925510406494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2097.7582931518555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 7646.046161651611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1850}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 4262.15934753418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 16264.051914215088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2935.9724521636963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3778}}}
{"qid": "-8336776482564898273", "question": "who has won the most world series in baseball", "gold_answers": ["the New York Yankees", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "New York Yankees", "latency_ms": 2337.7091884613037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Yankees", "latency_ms": 1248.0111122131348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 6154.321908950806, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 5902.854204177856, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1879}, "4": {"k": 4, "answer": "New York Yankees", "latency_ms": 2695.3489780426025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2460}, "5": {"k": 5, "answer": "New York Yankees", "latency_ms": 2934.563398361206, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3067}, "6": {"k": 6, "answer": "New York Yankees", "latency_ms": 3276.458501815796, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3699}}}
{"qid": "-8742089114148260796", "question": "where are the winter olympic games being played", "gold_answers": ["Beijing"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2407.20534324646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "third year of each Olympiad", "latency_ms": 8386.95740699768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "third year of each Olympiad", "latency_ms": 2308.6695671081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "third year of each Olympiad", "latency_ms": 2606.1205863952637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Sochi, Tokyo, Beijing", "latency_ms": 15209.35344696045, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2498}, "5": {"k": 5, "answer": "in different locations, including Sochi, PyeongChang, and Beijing", "latency_ms": 22498.548984527588, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3156}, "6": {"k": 6, "answer": "in different host cities each time, such as Sapporo, Nagano, and PyeongChang, with the most recent being in Beijing in 2022", "latency_ms": 10774.618864059448, "em": 0.0, "f1": 0.09523809523809523, "containment": 1.0, "context_chars": 3808}}}
{"qid": "3864930130255054488", "question": "who made the song falling in love with you", "gold_answers": ["Hugo Peretti", "Elvis Presley", "George David Weiss", "Luigi Creatore"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 985.7323169708252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Victor Young and Edward Heyman", "latency_ms": 14597.926616668701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "Michael Jackson", "latency_ms": 1607.5644493103027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Doris Day", "latency_ms": 2445.122480392456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1800}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 9983.003854751587, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2427}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 6716.14408493042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3003}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 4702.623605728149, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3584}}}
{"qid": "8076743617384207713", "question": "where did saudi crown prince go to college", "gold_answers": ["King Saud University"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 3556.7057132720947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3843.9230918884277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1957.9248428344727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 10299.2103099823, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2628.687858581543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2560}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 12419.18683052063, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3158}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 4439.972639083862, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3737}}}
{"qid": "1735766792677422630", "question": "who did the singing in into the woods", "gold_answers": ["the cast", "the cast members"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 5655.349969863892, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cinderella", "latency_ms": 1730.6981086730957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "Cinderella", "latency_ms": 6261.728525161743, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "James Lapine", "latency_ms": 2096.632719039917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1825}, "4": {"k": 4, "answer": "Bernadette Peters", "latency_ms": 14489.386796951294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2450}, "5": {"k": 5, "answer": "Bernadette Peters", "latency_ms": 5340.975761413574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "Bernadette Peters", "latency_ms": 3022.780656814575, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3662}}}
{"qid": "5711801828691961426", "question": "who was the viceroy when the simon commission visited india", "gold_answers": ["Lord Irwin"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 5753.446578979492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 4104.426860809326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3475.064516067505, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 12944.00405883789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3219.008684158325, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2649}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 5365.761280059814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3300}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 11827.792406082153, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3963}}}
{"qid": "9001143341771379731", "question": "who in germany signed the treaty of versailles", "gold_answers": ["colonial minister Johannes Bell", "Foreign minister Hermann Mller", "Gustav Bauer"], "shots": {"0": {"k": 0, "answer": "Wilhelm II", "latency_ms": 7108.610153198242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Germany", "latency_ms": 1440.8681392669678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Germany", "latency_ms": 2239.7966384887695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "Germany's new political leadership", "latency_ms": 2515.7628059387207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "Germany's new political leadership", "latency_ms": 2859.2159748077393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2485}, "5": {"k": 5, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 12725.253582000732, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3132}, "6": {"k": 6, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 14705.584049224854, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3794}}}
{"qid": "-4619585332904698754", "question": "who holds the record for most platinum albums", "gold_answers": ["The Beatles", "AC / DC", "Elvis Presley"], "shots": {"0": {"k": 0, "answer": "Michael Jackson", "latency_ms": 3339.036703109741, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elvis Presley", "latency_ms": 1594.804048538208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Elvis Presley", "latency_ms": 3037.910223007202, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Elvis Presley", "latency_ms": 7438.949823379517, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1989}, "4": {"k": 4, "answer": "Elvis Presley", "latency_ms": 2439.0718936920166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2614}, "5": {"k": 5, "answer": "Elvis Presley", "latency_ms": 3171.903610229492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3340}, "6": {"k": 6, "answer": "Elvis Presley", "latency_ms": 9295.028448104858, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4005}}}
{"qid": "-720512252272678238", "question": "when did the movie the post begin filming", "gold_answers": ["May 30 , 2017", "May 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1425.6682395935059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 5980.40771484375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2334.0179920196533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3021.336555480957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 5497.434377670288, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2509}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 6154.667377471924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3179}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3006.05845451355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3782}}}
{"qid": "-3371798557886238687", "question": "who starred in an officer and a gentleman", "gold_answers": ["Louis Gossett Jr .", "David Keith", "Louis Gossett Jr.", "Richard Gere", "Debra Winger", "Phillip J. Salmon"], "shots": {"0": {"k": 0, "answer": "Richard Gere, Richard Attenborough, and others", "latency_ms": 5350.927829742432, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dustin Hoffman", "latency_ms": 4506.5882205963135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 6887.633562088013, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 6466.245889663696, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 1851}, "4": {"k": 4, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 4765.331983566284, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 15897.055864334106, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3076}, "6": {"k": 6, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 10031.468391418457, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3732}}}
