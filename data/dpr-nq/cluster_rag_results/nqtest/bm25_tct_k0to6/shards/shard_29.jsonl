{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 140.09928703308105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 157.24682807922363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "June 22, 2018", "latency_ms": 196.5501308441162, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "June 22, 2018", "latency_ms": 293.03908348083496, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "June 22, 2018", "latency_ms": 235.9154224395752, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 258.8016986846924, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "June 22, 2018", "latency_ms": 246.23799324035645, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3802}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Ski Jumping, Nordic Combined, Freestyle", "latency_ms": 343.5051441192627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alpine skiing", "latency_ms": 127.11572647094727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 201.1253833770752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 225.06976127624512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 208.4510326385498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 266.7253017425537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "Alpine, Freestyle, Cross-country", "latency_ms": 340.53707122802734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3922}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 111.05227470397949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gino Poletti", "latency_ms": 135.6680393218994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Gino Poletti", "latency_ms": 156.64410591125488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Gino Poletti", "latency_ms": 239.80307579040527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 194.28396224975586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2560}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 161.71979904174805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 159.5590114593506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3824}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 106.43267631530762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Giants", "latency_ms": 68.4959888458252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 551}, "2": {"k": 2, "answer": "Giants", "latency_ms": 121.54006958007812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1156}, "3": {"k": 3, "answer": "Giants, Broncos, Rams, Chargers", "latency_ms": 320.084810256958, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1711}, "4": {"k": 4, "answer": "Giants, Broncos, Rams, Denver Broncos", "latency_ms": 223.7710952758789, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2294}, "5": {"k": 5, "answer": "Giants, Broncos, Bengals", "latency_ms": 203.1996250152588, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2888}, "6": {"k": 6, "answer": "Giants, Broncos, Bengals", "latency_ms": 218.48487854003906, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3442}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "1985", "latency_ms": 143.7225341796875, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 December 1985", "latency_ms": 224.90382194519043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 727}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 191.41864776611328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1447}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 217.81396865844727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2143}, "4": {"k": 4, "answer": "8 December 1985", "latency_ms": 230.8809757232666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2840}, "5": {"k": 5, "answer": "8 December 1985", "latency_ms": 251.17063522338867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3557}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 208.43768119812012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4258}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 113.45100402832031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 88.71889114379883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 143.74732971191406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1381}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 159.41596031188965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2092}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 112.92028427124023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2735}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 193.36175918579102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3346}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 219.88582611083984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3996}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "NYHA functional class", "latency_ms": 79.90431785583496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 100.0223159790039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 762}, "2": {"k": 2, "answer": "shortness of breath and/or angina", "latency_ms": 187.48116493225098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1494}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 100.97050666809082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2250}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 158.42890739440918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2959}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 177.46710777282715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 194.58556175231934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4342}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Tommy Roe", "latency_ms": 134.45758819580078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 106.37331008911133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.0836410522461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 123.72350692749023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 111.81831359863281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2447}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 130.12266159057617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 141.94226264953613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3635}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 57.79004096984863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 50.35710334777832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "3", "latency_ms": 58.222055435180664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "3", "latency_ms": 69.05198097229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "3", "latency_ms": 86.27462387084961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2466}, "5": {"k": 5, "answer": "3", "latency_ms": 91.38059616088867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "3", "latency_ms": 103.91712188720703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3661}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "biscuit", "latency_ms": 112.81394958496094, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biscuit-sized cake", "latency_ms": 102.25629806518555, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "cake", "latency_ms": 102.68497467041016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "cake", "latency_ms": 69.29707527160645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1764}, "4": {"k": 4, "answer": "a cake", "latency_ms": 87.53347396850586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "a cake", "latency_ms": 133.40353965759277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3040}, "6": {"k": 6, "answer": "cake", "latency_ms": 111.94849014282227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Dan Castellaneta", "latency_ms": 80.2304744720459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seth MacFarlane", "latency_ms": 165.9400463104248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "Seth MacFarlane", "latency_ms": 125.33998489379883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "Seth MacFarlane", "latency_ms": 150.4344940185547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 160.75420379638672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 186.3996982574463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3190}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 236.87148094177246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3857}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 98.97398948669434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 144.75131034851074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.71187400817871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 135.76769828796387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 147.04179763793945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 173.75588417053223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3135}, "6": {"k": 6, "answer": "diet pills", "latency_ms": 105.13687133789062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3712}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "19 minutes 38 seconds", "latency_ms": 230.03172874450684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 168.19047927856445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 571}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 113.13986778259277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1153}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 136.1098289489746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1779}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 146.46649360656738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2373}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 172.08051681518555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2928}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 180.85432052612305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3520}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 145.33710479736328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 153.0764102935791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 114.26615715026855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 148.00477027893066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1900}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 139.81199264526367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2517}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 164.5045280456543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3197}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 188.97652626037598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3841}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 133.29577445983887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 120.90516090393066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 98.68812561035156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 130.0981044769287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1868}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 147.10307121276855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 150.85387229919434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 152.06575393676758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3746}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 129.8675537109375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.08911323547363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 95.72577476501465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "1986", "latency_ms": 172.81126976013184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "1986", "latency_ms": 112.03122138977051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "1986", "latency_ms": 125.67758560180664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3208}, "6": {"k": 6, "answer": "1986", "latency_ms": 130.25283813476562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3832}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "Lori Michaels", "latency_ms": 128.312349319458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alexz Johnson", "latency_ms": 70.71661949157715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Alexz Johnson, Dave Ogilvie, Anthony Valcic, Damhnait Doyle, in-show band", "latency_ms": 449.3710994720459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Alexz Johnson, Jakalope, Damhnait Doyle, in-show band", "latency_ms": 476.7765998840332, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Alexz Johnson", "latency_ms": 116.56975746154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2608}, "5": {"k": 5, "answer": "Jim McGrath (composer), lyrics by Jody Colero and Stephen Stohn; performed by Lisa Dalbello with children's choir in early seasons; later versions performed by Jakalope, Alexz Johnson, Damhnait Doyle, and in-show bands.", "latency_ms": 1288.569688796997, "em": 0.0, "f1": 0.06060606060606061, "containment": 1.0, "context_chars": 3259}, "6": {"k": 6, "answer": "Jim McGrath (composer), with lyrics by Jody Colero and Stephen Stohn; performed by Lisa Dalbello and children's choir in early seasons; later performed by Damhnait Doyle and in-show bands.", "latency_ms": 1060.206651687622, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3906}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 95.02148628234863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 million years ago", "latency_ms": 142.1201229095459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "360 million years ago", "latency_ms": 156.92973136901855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "360 million years ago", "latency_ms": 134.04607772827148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1920}, "4": {"k": 4, "answer": "360 million years ago", "latency_ms": 185.32776832580566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 151.63159370422363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3206}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 155.91001510620117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3826}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.55646514892578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 151.28755569458008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 90.21854400634766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 177.7958869934082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1991}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 112.3654842376709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2718}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 143.5375213623047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3336}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 174.87668991088867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4052}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 69.9148178100586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "GNU project", "latency_ms": 99.2727279663086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 134.26470756530762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 146.09742164611816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1999}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 167.86503791809082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 131.94012641906738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3296}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 140.71369171142578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3928}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 106.65631294250488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 131.68931007385254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 149.82318878173828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1180}, "3": {"k": 3, "answer": "Martina Veloso", "latency_ms": 169.5537567138672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1777}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 158.53643417358398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2314}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 143.93353462219238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2918}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 165.82107543945312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3517}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Chris Bell", "latency_ms": 56.76913261413574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 85.67404747009277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 81.18486404418945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 108.1697940826416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1992}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 100.59237480163574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2678}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 136.20257377624512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3316}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 126.31344795227051, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3959}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 159.95311737060547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 102.73981094360352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 98.35481643676758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 116.57905578613281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 133.69131088256836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2450}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 151.02720260620117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3025}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 169.86942291259766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3652}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "Paraguayan guaraní", "latency_ms": 201.11727714538574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 104.57468032836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Paraguayan peso", "latency_ms": 120.41068077087402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "guaraní", "latency_ms": 98.87528419494629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1885}, "4": {"k": 4, "answer": "guaraní", "latency_ms": 156.79121017456055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2454}, "5": {"k": 5, "answer": "guaraní", "latency_ms": 168.7304973602295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "guaraní", "latency_ms": 196.5310573577881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3749}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "ketamine", "latency_ms": 122.49350547790527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "amnesic properties", "latency_ms": 101.55534744262695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "benzodiazepine", "latency_ms": 143.49842071533203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1445}, "3": {"k": 3, "answer": "remifentanil", "latency_ms": 149.66583251953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2125}, "4": {"k": 4, "answer": "remifentanil", "latency_ms": 125.71048736572266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2805}, "5": {"k": 5, "answer": "remifentanil", "latency_ms": 171.59557342529297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3491}, "6": {"k": 6, "answer": "remifentanil", "latency_ms": 204.65636253356934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4171}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 183.2284927368164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "26,000 years", "latency_ms": 197.58987426757812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "26,000 years", "latency_ms": 152.85873413085938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1207}, "3": {"k": 3, "answer": "25,772 years", "latency_ms": 209.3644142150879, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "25,772 years", "latency_ms": 246.75559997558594, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2481}, "5": {"k": 5, "answer": "25,772 years", "latency_ms": 303.0242919921875, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "25,772 years", "latency_ms": 208.86516571044922, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3729}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 99.96175765991211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 85.30259132385254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Texas A&M", "latency_ms": 83.40072631835938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Texas A&M", "latency_ms": 142.97819137573242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1904}, "4": {"k": 4, "answer": "Texas A&M", "latency_ms": 183.46261978149414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Texas A&M University", "latency_ms": 185.51135063171387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Texas A&M University", "latency_ms": 175.53257942199707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3748}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and non-renewable", "latency_ms": 131.54196739196777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable and non-renewable", "latency_ms": 135.82420349121094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable and non-renewable", "latency_ms": 170.212984085083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1447}, "3": {"k": 3, "answer": "renewable or non-renewable", "latency_ms": 195.40882110595703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2177}, "4": {"k": 4, "answer": "renewable and non-renewable", "latency_ms": 161.10825538635254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2828}, "5": {"k": 5, "answer": "renewable or non-renewable", "latency_ms": 164.34884071350098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3469}, "6": {"k": 6, "answer": "renewable and non-renewable", "latency_ms": 179.0633201599121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4200}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "Good luck and prosperity", "latency_ms": 81.03275299072266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "parental devotion", "latency_ms": 123.79884719848633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "parental devotion", "latency_ms": 82.87262916564941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "parental devotion", "latency_ms": 96.11845016479492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "maternal symbols, purity, kindness, parental devotion", "latency_ms": 190.61732292175293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2459}, "5": {"k": 5, "answer": "purity, maternal devotion, and child-birth", "latency_ms": 203.86195182800293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3065}, "6": {"k": 6, "answer": "mercy, parental devotion, purity, good luck, child-bringing", "latency_ms": 311.6140365600586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3706}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Rohit Sharma", "latency_ms": 79.91290092468262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.40001106262207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 97.91135787963867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.75415802001953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 112.98203468322754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 128.70359420776367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3144}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 141.6788101196289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3769}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 130.86771965026855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals", "latency_ms": 115.59820175170898, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 403.11312675476074, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 1412}, "3": {"k": 3, "answer": "the biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 288.5572910308838, "em": 0.0, "f1": 0.4705882352941176, "containment": 0.0, "context_chars": 2081}, "4": {"k": 4, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 328.4728527069092, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 2746}, "5": {"k": 5, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 354.0019989013672, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 3407}, "6": {"k": 6, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 363.01565170288086, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 4072}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 78.95684242248535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 88.99688720703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.79508209228516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 157.83143043518066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1904}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 112.89238929748535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Walter LaGrand", "latency_ms": 127.19869613647461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3136}, "6": {"k": 6, "answer": "Walter LaGrand", "latency_ms": 131.64043426513672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the opening lead and before the first trick is played.", "latency_ms": 261.29150390625, "em": 0.0, "f1": 0.15384615384615383, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the conclusion of play", "latency_ms": 96.48489952087402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 550}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 103.09672355651855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1156}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 109.85207557678223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1797}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 138.5977268218994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2367}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 153.20134162902832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2949}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 196.671724319458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3567}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Sri Lanka", "latency_ms": 76.28488540649414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 121.78897857666016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 699}, "2": {"k": 2, "answer": "Sri Lanka", "latency_ms": 83.26601982116699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Afghanistan", "latency_ms": 96.7857837677002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2076}, "4": {"k": 4, "answer": "Afghanistan", "latency_ms": 99.02620315551758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2735}, "5": {"k": 5, "answer": "Afghanistan", "latency_ms": 113.71850967407227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3469}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 183.15887451171875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4195}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 160.13598442077637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 101.49478912353516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 123.68440628051758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 142.5638198852539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 158.45417976379395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2607}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 178.33447456359863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3321}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 199.20063018798828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4055}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 159.87753868103027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 107.0713996887207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 124.62925910949707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1354}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 167.6013469696045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2062}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 200.7157802581787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2695}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 198.3475685119629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3389}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 242.5823211669922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4021}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "1989", "latency_ms": 94.65503692626953, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1989", "latency_ms": 83.07051658630371, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 176.3017177581787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1313}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 206.2675952911377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1931}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 215.2695655822754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2637}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 246.5193271636963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3277}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 263.99803161621094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3945}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "2016", "latency_ms": 93.7042236328125, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2016", "latency_ms": 99.94196891784668, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "2016", "latency_ms": 95.58367729187012, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "2016", "latency_ms": 128.65471839904785, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "2016", "latency_ms": 143.3432102203369, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2581}, "5": {"k": 5, "answer": "2016", "latency_ms": 163.5134220123291, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3170}, "6": {"k": 6, "answer": "2016", "latency_ms": 183.93349647521973, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3751}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 142.70281791687012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.71858024597168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 111.39941215515137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 128.91030311584473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 143.6760425567627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2644}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 163.24901580810547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3256}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 183.6702823638916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3973}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 143.92352104187012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.86830711364746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 112.08033561706543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 140.00344276428223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 156.8775177001953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 179.72922325134277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3101}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 187.8666877746582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Montesquieu", "latency_ms": 144.23036575317383, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montesquieu", "latency_ms": 90.65389633178711, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 112.2744083404541, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 96.52876853942871, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 142.77124404907227, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2621}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 112.55621910095215, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3230}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 151.12638473510742, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3906}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Kyler Murray", "latency_ms": 76.61151885986328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.47964286804199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 147.19319343566895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.61730575561523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 177.51312255859375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 126.93166732788086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3116}, "6": {"k": 6, "answer": "Kevin King", "latency_ms": 104.77519035339355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3666}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 159.32917594909668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 84.00297164916992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "2008", "latency_ms": 112.92290687561035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "2008", "latency_ms": 122.8795051574707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1980}, "4": {"k": 4, "answer": "2008", "latency_ms": 111.72890663146973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "2008", "latency_ms": 161.64350509643555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3332}, "6": {"k": 6, "answer": "2008", "latency_ms": 163.75732421875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3999}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 89.65897560119629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 139.87064361572266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 128.7236213684082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 128.2205581665039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 191.30444526672363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2637}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 126.82032585144043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3295}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 147.46594429016113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3979}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 97.3196029663086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "stomach", "latency_ms": 98.13427925109863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "parietal cells", "latency_ms": 136.9035243988037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "parietal cells", "latency_ms": 157.1524143218994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1803}, "4": {"k": 4, "answer": "parietal cells", "latency_ms": 170.33123970031738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2404}, "5": {"k": 5, "answer": "parietal cells", "latency_ms": 186.15341186523438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3055}, "6": {"k": 6, "answer": "parietal cells", "latency_ms": 140.11597633361816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3670}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "between 2 and 4 a.m.", "latency_ms": 189.88299369812012, "em": 0.0, "f1": 0.20000000000000004, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "4 a.m.", "latency_ms": 125.09870529174805, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 141.38460159301758, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "second half of the sleep cycle", "latency_ms": 183.72035026550293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "4 a.m.", "latency_ms": 142.85683631896973, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2606}, "5": {"k": 5, "answer": "4 a.m.", "latency_ms": 134.8559856414795, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3317}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 127.29120254516602, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4053}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 70.2202320098877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 111.82904243469238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 89.74575996398926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 142.76885986328125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 158.79344940185547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2640}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 190.66786766052246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3264}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 199.7528076171875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3900}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "1. The Curse of the Black Pearl  \n2. Dead Man's Chest  \n3. At World's End  \n4. On Stranger Tides  \n5. Pirates of the Caribbean: Dead Men Tell No Tales", "latency_ms": 780.2462577819824, "em": 0.0, "f1": 0.32258064516129037, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 147.81427383422852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 90.85750579833984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 174.9277114868164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Pirates of the Caribbean: The Curse of the Black Pearl (2003), Pirates of the Caribbean: Dead Man's Chest (2006), Pirates of the Caribbean: At World's End (2007), Pirates of the Caribbean: On Stranger Tides (2011), Pirates of the Caribbean: Dead Men Tell No Tales (2017)", "latency_ms": 1688.1585121154785, "em": 0.0, "f1": 0.23255813953488372, "containment": 1.0, "context_chars": 2550}, "5": {"k": 5, "answer": "The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales", "latency_ms": 639.4753456115723, "em": 0.0, "f1": 0.43478260869565216, "containment": 1.0, "context_chars": 3159}, "6": {"k": 6, "answer": "The Pirate of the Caribbean films in order: The Curse of the Black Pearl (2003), Dead Man's Chest (2006), At World's End (2007), On Stranger Tides (2011), Dead Men Tell No Tales (2017).", "latency_ms": 1278.9676189422607, "em": 0.0, "f1": 0.29411764705882354, "containment": 1.0, "context_chars": 3820}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 78.69696617126465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "changed key", "latency_ms": 70.55139541625977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "changed key", "latency_ms": 64.05282020568848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1171}, "3": {"k": 3, "answer": "changed key", "latency_ms": 70.79362869262695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1761}, "4": {"k": 4, "answer": "modulated", "latency_ms": 116.45627021789551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "modulated", "latency_ms": 119.65560913085938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3037}, "6": {"k": 6, "answer": "modulated", "latency_ms": 102.71263122558594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3649}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Roman citizens of certain property thresholds", "latency_ms": 185.07742881774902, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.37235450744629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "a minority of Romans", "latency_ms": 105.60345649719238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Roman citizens", "latency_ms": 72.49188423156738, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1994}, "4": {"k": 4, "answer": "Roman citizens", "latency_ms": 105.28683662414551, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2700}, "5": {"k": 5, "answer": "Full Roman citizens", "latency_ms": 152.99582481384277, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3339}, "6": {"k": 6, "answer": "Full Roman citizens", "latency_ms": 152.36830711364746, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4014}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 155.5640697479248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 174.66282844543457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 112.10274696350098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 114.20345306396484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 125.96964836120605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2542}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 156.60643577575684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 142.39811897277832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3809}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "total blood volume", "latency_ms": 66.29061698913574, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "blood volume", "latency_ms": 57.785749435424805, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "blood volume", "latency_ms": 64.34416770935059, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "blood volume", "latency_ms": 81.77304267883301, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1849}, "4": {"k": 4, "answer": "volume of blood", "latency_ms": 99.09605979919434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2539}, "5": {"k": 5, "answer": "volume of blood", "latency_ms": 147.73011207580566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3203}, "6": {"k": 6, "answer": "volume of blood", "latency_ms": 116.45126342773438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3800}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.85520362854004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.44821357727051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.58527374267578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.33358764648438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 162.85324096679688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2393}, "5": {"k": 5, "answer": "Phaethon", "latency_ms": 126.81341171264648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "Phaethon", "latency_ms": 130.75613975524902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3630}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "1979", "latency_ms": 78.93228530883789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1979", "latency_ms": 83.4968090057373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "1979", "latency_ms": 95.88861465454102, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "1979", "latency_ms": 141.04342460632324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "1979", "latency_ms": 132.0974826812744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2551}, "5": {"k": 5, "answer": "1979", "latency_ms": 129.67896461486816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3159}, "6": {"k": 6, "answer": "1979", "latency_ms": 141.84331893920898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3727}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 AM Hong Kong Time", "latency_ms": 131.32643699645996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 88.97209167480469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.04549407958984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 109.0705394744873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 113.04664611816406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2627}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 181.8850040435791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3296}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 130.45358657836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3927}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.28388023376465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.72187614440918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "Tiffany Coyne", "latency_ms": 96.55141830444336, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 109.29441452026367, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 113.24429512023926, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2449}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 128.40533256530762, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3031}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 157.91606903076172, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3658}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 96.57716751098633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Atlanta Braves", "latency_ms": 57.42383003234863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Atlanta Braves", "latency_ms": 63.99798393249512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Atlanta Braves", "latency_ms": 72.28684425354004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1861}, "4": {"k": 4, "answer": "New York Yankees, Atlanta Braves", "latency_ms": 173.10619354248047, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 2437}, "5": {"k": 5, "answer": "New York Yankees, Atlanta Braves", "latency_ms": 174.86190795898438, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 3043}, "6": {"k": 6, "answer": "New York Yankees, Atlanta Braves", "latency_ms": 166.38731956481934, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 3676}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 105.53503036499023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$343.4 million", "latency_ms": 136.15942001342773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "$1.84 billion", "latency_ms": 188.01522254943848, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "over $2 billion worldwide", "latency_ms": 121.36697769165039, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "over $2 billion worldwide", "latency_ms": 205.67965507507324, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "over $1.84 billion worldwide", "latency_ms": 200.42037963867188, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "over $1.84 billion worldwide", "latency_ms": 217.46158599853516, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3794}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 107.93066024780273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 88.94705772399902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 132.3249340057373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 109.79795455932617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 112.71166801452637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2496}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 159.4829559326172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 131.05106353759766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3718}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark/Norway", "latency_ms": 157.5033664703369, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "mother's home village", "latency_ms": 89.41340446472168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "mother's home village", "latency_ms": 164.34860229492188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "mother's home village", "latency_ms": 108.74080657958984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "mother's home village", "latency_ms": 128.75962257385254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2513}, "5": {"k": 5, "answer": "mother's home village", "latency_ms": 146.32534980773926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "mother's home village", "latency_ms": 162.98198699951172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 125.52475929260254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Christmas tree and Nativity scene", "latency_ms": 159.9874496459961, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Christmas Tree and Nativity scene", "latency_ms": 237.02287673950195, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Christmas tree", "latency_ms": 81.81023597717285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Christmas tree", "latency_ms": 107.99288749694824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Christmas tree and Nativity scene", "latency_ms": 234.21144485473633, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Christmas tree", "latency_ms": 129.1031837463379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3845}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 92.71788597106934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 142.1377658843994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 158.2949161529541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 127.49767303466797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Swayze", "latency_ms": 98.38557243347168, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Swayze", "latency_ms": 149.11770820617676, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3213}, "6": {"k": 6, "answer": "Swayze", "latency_ms": 175.16064643859863, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3819}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Rhode Island", "latency_ms": 116.15180969238281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 149.37067031860352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 172.0268726348877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 113.43550682067871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 131.422758102417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2589}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 124.94468688964844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3214}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 129.7895908355713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3876}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1801", "latency_ms": 79.37097549438477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "24 May 1854", "latency_ms": 182.80863761901855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "24 May 1854", "latency_ms": 148.1459140777588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "24 May 1854", "latency_ms": 159.90734100341797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1994}, "4": {"k": 4, "answer": "24 May 1854", "latency_ms": 215.33441543579102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "First Parliament, 1854", "latency_ms": 178.39384078979492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3243}, "6": {"k": 6, "answer": "24 May 1854", "latency_ms": 247.03574180603027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3911}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier Fernández", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.17539978027344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.79507064819336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.2381362915039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 142.6076889038086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2059}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 134.64903831481934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2810}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 153.9013385772705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3439}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 167.23275184631348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4120}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.43010330200195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "password recovery", "latency_ms": 63.32874298095703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "password recovery", "latency_ms": 85.89863777160645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1391}, "3": {"k": 3, "answer": "password recovery for Microsoft Windows", "latency_ms": 149.65486526489258, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2024}, "4": {"k": 4, "answer": "recovering passwords using methods such as network packet sniffing, dictionary attacks, brute force, and cryptanalysis attacks", "latency_ms": 453.0038833618164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2617}, "5": {"k": 5, "answer": "recovering passwords using methods such as network packet sniffing, dictionary attacks, brute force, and cryptanalysis attacks", "latency_ms": 539.2005443572998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "recovering passwords using methods such as network packet sniffing, dictionary attacks, brute force, and cryptanalysis attacks", "latency_ms": 617.1181201934814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3819}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "Eknath Shinde", "latency_ms": 108.80255699157715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 125.10490417480469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "S. M. Krishna", "latency_ms": 191.8182373046875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 280.92408180236816, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 151.88264846801758, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2642}, "5": {"k": 5, "answer": "C. Vidyasagar Rao", "latency_ms": 164.8111343383789, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "C. Vidyasagar Rao", "latency_ms": 168.39218139648438, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3931}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 106.5053939819336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 134.44137573242188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 106.55570030212402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.08134078979492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "15", "latency_ms": 87.19420433044434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2570}, "5": {"k": 5, "answer": "15", "latency_ms": 103.61313819885254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "15", "latency_ms": 114.75014686584473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3897}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Michael J. Fox", "latency_ms": 126.29270553588867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elisabeth Shue", "latency_ms": 96.49038314819336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Elisabeth Shue", "latency_ms": 102.13613510131836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "Claudia Wells initially played Jennifer Parker in \"Back to the Future\", but she declined due to personal issues. Elisabeth Shue replaced her in \"Back to the Future Part II\" and \"Part III\". Therefore, the answer is: Claudia Wells and Elisabeth Shue.", "latency_ms": 1061.6908073425293, "em": 0.0, "f1": 0.0975609756097561, "containment": 0.0, "context_chars": 1798}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 111.51933670043945, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2397}, "5": {"k": 5, "answer": "Claudia Wells (first film), Elisabeth Shue (Part II and III)", "latency_ms": 510.0445747375488, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "Claudia Wells (first film), Elisabeth Shue (Part II and III)", "latency_ms": 446.69604301452637, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 3631}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 53.43747138977051, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "London", "latency_ms": 50.76789855957031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 164.17694091796875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 181.41722679138184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 125.7944107055664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 131.0751438140869, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3160}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 142.69137382507324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3809}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The president's chef", "latency_ms": 79.23460006713867, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "White House Executive Chef", "latency_ms": 96.17209434509277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "White House Executive Chef", "latency_ms": 124.65023994445801, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1369}, "3": {"k": 3, "answer": "White House Executive Chef", "latency_ms": 139.74499702453613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2045}, "4": {"k": 4, "answer": "White House Executive Chef", "latency_ms": 108.45637321472168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2708}, "5": {"k": 5, "answer": "White House Executive Chef", "latency_ms": 151.11565589904785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3377}, "6": {"k": 6, "answer": "White House Executive Chef", "latency_ms": 143.78643035888672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3956}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.71453666687012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.20741081237793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 97.0458984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 157.6249599456787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 113.6326789855957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 170.07851600646973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3197}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 167.99235343933105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.3370475769043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Larchmont, New York", "latency_ms": 133.64124298095703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 117.7358627319336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 175.67014694213867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 164.26682472229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2610}, "5": {"k": 5, "answer": "British Columbia", "latency_ms": 100.53110122680664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3268}, "6": {"k": 6, "answer": "British Columbia", "latency_ms": 148.0729579925537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3895}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 168.15900802612305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 106.93144798278809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 111.18483543395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 186.11764907836914, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1876}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 238.5389804840088, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 207.8554630279541, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 245.96643447875977, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3830}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Dana Delany", "latency_ms": 78.86028289794922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stephanie", "latency_ms": 100.8291244506836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Stephanie", "latency_ms": 95.81136703491211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Stephanie", "latency_ms": 95.1237678527832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "Stephanie", "latency_ms": 99.19881820678711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2526}, "5": {"k": 5, "answer": "Stephanie", "latency_ms": 113.86442184448242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 196.57325744628906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.17730712890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Millennium Tower", "latency_ms": 83.89449119567871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 96.15349769592285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1361}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 177.09016799926758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2008}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 112.56861686706543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2703}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 128.74865531921387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3328}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 131.75725936889648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3988}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 123.56209754943848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 88.72509002685547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "2014", "latency_ms": 126.15799903869629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "2014", "latency_ms": 155.11775016784668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1820}, "4": {"k": 4, "answer": "2014", "latency_ms": 225.1274585723877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2449}, "5": {"k": 5, "answer": "2014", "latency_ms": 226.82857513427734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3029}, "6": {"k": 6, "answer": "2014", "latency_ms": 142.25530624389648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3731}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "T.S. Eliot", "latency_ms": 132.9059600830078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 119.70877647399902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 693}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 167.3891544342041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 154.61039543151855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 149.55592155456543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2663}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 143.16153526306152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3333}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 137.24279403686523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4032}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Chris Berman", "latency_ms": 67.45672225952148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.71210098266602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 137.59326934814453, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 156.16607666015625, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 175.26721954345703, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 140.40184020996094, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 207.90815353393555, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3837}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.52380180358887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "6", "latency_ms": 50.34065246582031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 705}, "2": {"k": 2, "answer": "6", "latency_ms": 57.74426460266113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "6 episodes", "latency_ms": 132.99131393432617, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1973}, "4": {"k": 4, "answer": "6", "latency_ms": 73.35638999938965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2646}, "5": {"k": 5, "answer": "6", "latency_ms": 87.83221244812012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3304}, "6": {"k": 6, "answer": "6", "latency_ms": 91.68744087219238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3979}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul Baumer's", "latency_ms": 79.17451858520508, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "German soldiers' perspective", "latency_ms": 100.36206245422363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "German soldiers' perspective", "latency_ms": 109.27033424377441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "German soldiers' perspective", "latency_ms": 174.62825775146484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "German soldiers' perspective", "latency_ms": 256.72221183776855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2564}, "5": {"k": 5, "answer": "German soldiers' perspective", "latency_ms": 165.2848720550537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3204}, "6": {"k": 6, "answer": "German soldiers' perspective", "latency_ms": 163.8658046722412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3844}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris and the Anglin brothers", "latency_ms": 152.53305435180664, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 277.51755714416504, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 683}, "2": {"k": 2, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 317.371129989624, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1339}, "3": {"k": 3, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 258.4421634674072, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 301.6631603240967, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2619}, "5": {"k": 5, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 344.93374824523926, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3224}, "6": {"k": 6, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 289.3342971801758, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3892}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF", "latency_ms": 113.02328109741211, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF's global programming and domestic causes like Hurricane Katrina victims", "latency_ms": 256.31260871887207, "em": 0.0, "f1": 0.14285714285714288, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "UNICEF's global programing, with half of proceeds in 2005 targeted to Hurricane Katrina victims in the U.S.", "latency_ms": 775.7458686828613, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 1417}, "3": {"k": 3, "answer": "UNICEF's global programming and domestic causes, such as aiding Hurricane Katrina victims", "latency_ms": 415.80700874328613, "em": 0.0, "f1": 0.125, "containment": 0.0, "context_chars": 2137}, "4": {"k": 4, "answer": "UNICEF's global programming, with half of proceeds in 2005 targeted to Hurricane Katrina victims in the U.S.", "latency_ms": 690.8769607543945, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 2808}, "5": {"k": 5, "answer": "UNICEF's global programing, with half of proceeds in 2005 targeted to Hurricane Katrina victims in the U.S.", "latency_ms": 722.4643230438232, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 3538}, "6": {"k": 6, "answer": "UNICEF's global programming, with half of proceeds in 2005 targeted to Hurricane Katrina victims in the U.S.", "latency_ms": 617.3667907714844, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 4217}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Statue of Liberty's inscription is on the pedestal.", "latency_ms": 314.7001266479492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 101.10783576965332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 123.92139434814453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 142.29846000671387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 158.77795219421387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "on the pedestal of the statue of liberty, which includes the inscription \"Liberty Enlightening the World\" and the date of dedication, October 28, 1886.", "latency_ms": 1152.4503231048584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 228.06453704833984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3882}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 178.67350578308105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 128.587007522583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "Beijing, 2022", "latency_ms": 147.5057601928711, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1183}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.08539390563965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1785}, "4": {"k": 4, "answer": "Beijing 2022, next Winter Olympics not specified in context. I cannot answer.", "latency_ms": 370.77784538269043, "em": 0.0, "f1": 0.15384615384615385, "containment": 1.0, "context_chars": 2423}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 162.1530055999756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 154.25658226013184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3712}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "1994", "latency_ms": 89.40362930297852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1997", "latency_ms": 113.57522010803223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 111.6020679473877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "1997", "latency_ms": 141.9367790222168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 133.19993019104004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 141.58248901367188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 150.4385471343994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3865}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "stone arch bridge", "latency_ms": 70.70446014404297, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "stone arch bridge", "latency_ms": 97.98240661621094, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 144.10853385925293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 157.0892333984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1970}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 179.83269691467285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2650}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 188.28868865966797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 165.9383773803711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3922}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The ruler or leader", "latency_ms": 126.81150436401367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "one person", "latency_ms": 62.5758171081543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "one person", "latency_ms": 113.66009712219238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "one person", "latency_ms": 130.40423393249512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1987}, "4": {"k": 4, "answer": "one person", "latency_ms": 143.7397003173828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2671}, "5": {"k": 5, "answer": "one person", "latency_ms": 100.99911689758301, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3321}, "6": {"k": 6, "answer": "one person", "latency_ms": 131.52146339416504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3955}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "Consumerism", "latency_ms": 87.62931823730469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 130.49697875976562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 174.8788356781006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "return to domesticity", "latency_ms": 162.12821006774902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "return to domesticity", "latency_ms": 150.07758140563965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "prosperous, suburban, consumer-driven society with heavy advertising and emphasis on domesticity", "latency_ms": 417.68431663513184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "prosperity and suburban growth", "latency_ms": 276.23605728149414, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3945}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "counterclockwise", "latency_ms": 159.06333923339844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "counterclockwise", "latency_ms": 106.76026344299316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "counterclockwise", "latency_ms": 106.06956481933594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1180}, "3": {"k": 3, "answer": "counterclockwise", "latency_ms": 107.01537132263184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1748}, "4": {"k": 4, "answer": "counterclockwise", "latency_ms": 146.62933349609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2293}, "5": {"k": 5, "answer": "counterclockwise", "latency_ms": 172.41764068603516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2864}, "6": {"k": 6, "answer": "counterclockwise", "latency_ms": 193.91918182373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3478}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Dome", "latency_ms": 121.04249000549316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Statue of Liberty I cannot answer.", "latency_ms": 217.8966999053955, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 107.31053352355957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 124.1912841796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "Statue of Freedom", "latency_ms": 127.38728523254395, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "Statue of Freedom", "latency_ms": 117.05136299133301, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3285}, "6": {"k": 6, "answer": "Statue of Freedom", "latency_ms": 174.11565780639648, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3928}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 111.51337623596191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington Wizards", "latency_ms": 82.5967788696289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 131.0408115386963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 129.45008277893066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 195.78003883361816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2501}, "5": {"k": 5, "answer": "Washington Wizards", "latency_ms": 100.93235969543457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3105}, "6": {"k": 6, "answer": "Washington Wizards", "latency_ms": 121.4137077331543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3777}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 96.21357917785645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Greatest Royal Rumble", "latency_ms": 137.14265823364258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 143.1295871734619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Mysterio", "latency_ms": 145.40743827819824, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Mysterio", "latency_ms": 150.73657035827637, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2454}, "5": {"k": 5, "answer": "Mysterio", "latency_ms": 170.64738273620605, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3107}, "6": {"k": 6, "answer": "Mysterio", "latency_ms": 129.4853687286377, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3708}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 111.60969734191895, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake of the Ozarks", "latency_ms": 211.5006446838379, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Lake of the Ozarks", "latency_ms": 266.3874626159668, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "Lake Mead", "latency_ms": 98.82378578186035, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Lake Mead", "latency_ms": 95.53360939025879, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2387}, "5": {"k": 5, "answer": "Lake Mead", "latency_ms": 134.7365379333496, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2959}, "6": {"k": 6, "answer": "Lake Mead", "latency_ms": 164.28446769714355, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3536}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Gabbar Is Back", "latency_ms": 156.1727523803711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 144.0129280090332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 164.8252010345459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tagore", "latency_ms": 85.8926773071289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1847}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 140.98381996154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 156.7060947418213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3134}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 270.63679695129395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3745}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "John Baker", "latency_ms": 114.97211456298828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "George H. W. Bush", "latency_ms": 161.70358657836914, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "Walter Mondale", "latency_ms": 111.43708229064941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "Walter Mondale", "latency_ms": 142.88973808288574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2073}, "4": {"k": 4, "answer": "George H. W. Bush", "latency_ms": 211.32850646972656, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2776}, "5": {"k": 5, "answer": "George H. W. Bush", "latency_ms": 198.96340370178223, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3479}, "6": {"k": 6, "answer": "George H. W. Bush", "latency_ms": 211.5166187286377, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 4204}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "Utah", "latency_ms": 74.9056339263916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Town of Groveland", "latency_ms": 178.47681045532227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners", "latency_ms": 113.12985420227051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Hampton Corners, New York", "latency_ms": 221.73213958740234, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "Hampton Corners, New York", "latency_ms": 267.00711250305176, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Hampton Corners, New York", "latency_ms": 238.80529403686523, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Hampton Corners, New York", "latency_ms": 217.32115745544434, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3723}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 87.12148666381836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 83.01520347595215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 84.33389663696289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1172}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 117.31505393981934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1818}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 107.38921165466309, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2449}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 140.68984985351562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3090}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 133.67176055908203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3647}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Uttar Pradesh", "latency_ms": 97.40662574768066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 135.33353805541992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 124.27043914794922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 148.8974094390869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 173.09331893920898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 195.67370414733887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 182.30032920837402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3733}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Lucknow", "latency_ms": 54.61931228637695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 104.41970825195312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 171.13876342773438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 159.8496437072754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1936}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 261.72804832458496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 144.37437057495117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 158.34379196166992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3876}}}
