{"qid": "6323609752938888061", "question": "when was to god be the glory written", "gold_answers": ["around 1872"], "shots": {"0": {"k": 0, "answer": "1860", "latency_ms": 73.67944717407227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1872", "latency_ms": 88.08493614196777, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "1872", "latency_ms": 93.57929229736328, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "1872", "latency_ms": 102.3263931274414, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1824}, "4": {"k": 4, "answer": "1872", "latency_ms": 108.89601707458496, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2394}, "5": {"k": 5, "answer": "around 1872", "latency_ms": 146.41928672790527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3028}, "6": {"k": 6, "answer": "around 1872", "latency_ms": 159.76691246032715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3608}}}
{"qid": "2403376289624018951", "question": "billy ocean when the going gets tough movie", "gold_answers": ["The Jewel of the Nile"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 71.25377655029297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 81.9094181060791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 91.93778038024902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "Romancing the Stone", "latency_ms": 102.49996185302734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1880}, "4": {"k": 4, "answer": "The Jewel of the Nile", "latency_ms": 118.32165718078613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2531}, "5": {"k": 5, "answer": "The Jewel of the Nile", "latency_ms": 135.47515869140625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3139}, "6": {"k": 6, "answer": "The Jewel of the Nile", "latency_ms": 139.634370803833, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3749}}}
{"qid": "-1177164544786365294", "question": "who won the 30 man royal rumble match", "gold_answers": ["Shinsuke Nakamura", "Randy Orton"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 72.01051712036133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Cena", "latency_ms": 61.948299407958984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 94.27261352539062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 101.57418251037598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "John Cena", "latency_ms": 84.18989181518555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2513}, "5": {"k": 5, "answer": "John Cena", "latency_ms": 98.9224910736084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "John Cena", "latency_ms": 101.06420516967773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3781}}}
{"qid": "4098923323570147395", "question": "where did maria work in west side story", "gold_answers": ["the dress shop", "dress shop"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 70.8920955657959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 77.2867202758789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 556}, "2": {"k": 2, "answer": "Broadway revival", "latency_ms": 75.6082534790039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "bridal shop", "latency_ms": 90.21520614624023, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1828}, "4": {"k": 4, "answer": "bridal shop", "latency_ms": 91.54558181762695, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2460}, "5": {"k": 5, "answer": "bridal shop", "latency_ms": 108.62541198730469, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3086}, "6": {"k": 6, "answer": "bridal shop", "latency_ms": 115.21673202514648, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3763}}}
{"qid": "6598465593542733817", "question": "which is the largest great lake in north america", "gold_answers": ["Lake Superior"], "shots": {"0": {"k": 0, "answer": "Superior", "latency_ms": 52.20198631286621, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake Superior", "latency_ms": 56.064605712890625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 587}, "2": {"k": 2, "answer": "Lake Superior", "latency_ms": 67.91090965270996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1227}, "3": {"k": 3, "answer": "Lake Superior", "latency_ms": 76.45177841186523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "Lake Superior", "latency_ms": 84.97023582458496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2520}, "5": {"k": 5, "answer": "Lake Superior", "latency_ms": 96.86946868896484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3106}, "6": {"k": 6, "answer": "Lake Superior", "latency_ms": 99.98893737792969, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3760}}}
{"qid": "4366713309044937565", "question": "during the first world war against which country germany did not fight", "gold_answers": ["Austria - Hungary"], "shots": {"0": {"k": 0, "answer": "Russia", "latency_ms": 40.22645950317383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Russia", "latency_ms": 38.332462310791016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Russia", "latency_ms": 46.83709144592285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "France", "latency_ms": 68.8328742980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1936}, "4": {"k": 4, "answer": "Belgium", "latency_ms": 79.30445671081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "Italy", "latency_ms": 83.68158340454102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "Italy", "latency_ms": 91.23516082763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3953}}}
{"qid": "-7891787418755685108", "question": "when is season 7 race to the edge coming out", "gold_answers": ["February 16 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.26867294311523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 81.65764808654785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 90.29650688171387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 105.8645248413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 119.53473091125488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2525}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 126.49798393249512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3151}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 139.0528678894043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3768}}}
{"qid": "-1942065851308587391", "question": "how many countries in the world have scouts", "gold_answers": ["216 countries and territories", "216", "169"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.55961608886719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "216", "latency_ms": 70.1444149017334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 738}, "2": {"k": 2, "answer": "216", "latency_ms": 75.35243034362793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1383}, "3": {"k": 3, "answer": "216", "latency_ms": 92.09012985229492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2154}, "4": {"k": 4, "answer": "216", "latency_ms": 95.48091888427734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2724}, "5": {"k": 5, "answer": "216", "latency_ms": 108.96587371826172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3425}, "6": {"k": 6, "answer": "216", "latency_ms": 113.1899356842041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4152}}}
{"qid": "1660122524963141000", "question": "how many seasons of johnny bravo are there", "gold_answers": ["four"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 34.2409610748291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 82.9305648803711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 693}, "2": {"k": 2, "answer": "four", "latency_ms": 51.02276802062988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1377}, "3": {"k": 3, "answer": "four seasons", "latency_ms": 81.44187927246094, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2058}, "4": {"k": 4, "answer": "four seasons", "latency_ms": 84.19561386108398, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2632}, "5": {"k": 5, "answer": "4 seasons", "latency_ms": 96.9240665435791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3236}, "6": {"k": 6, "answer": "4", "latency_ms": 101.89223289489746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3875}}}
{"qid": "-3028443905799016518", "question": "how many times have the golden state warriors been to the playoffs", "gold_answers": ["nine"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.54142379760742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 76.55477523803711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 93.03140640258789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 105.73196411132812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1820}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 108.48808288574219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2443}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 121.50812149047852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3070}, "6": {"k": 6, "answer": "9", "latency_ms": 89.90764617919922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3692}}}
{"qid": "-4748546458506417454", "question": "who's the guy in call me maybe", "gold_answers": ["Holden Nowell"], "shots": {"0": {"k": 0, "answer": "Calvin Harris", "latency_ms": 63.64941596984863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Holden Nowell", "latency_ms": 80.68346977233887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 568}, "2": {"k": 2, "answer": "Holden Nowell", "latency_ms": 89.88261222839355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1149}, "3": {"k": 3, "answer": "Holden Nowell", "latency_ms": 101.53436660766602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1705}, "4": {"k": 4, "answer": "Holden Nowell", "latency_ms": 105.77249526977539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2313}, "5": {"k": 5, "answer": "Holden Nowell", "latency_ms": 120.38230895996094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2892}, "6": {"k": 6, "answer": "Holden Nowell", "latency_ms": 127.92778015136719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3485}}}
{"qid": "5898512601992001509", "question": "who did the united states fight in the war of 1812", "gold_answers": ["United Kingdom"], "shots": {"0": {"k": 0, "answer": "Great Britain", "latency_ms": 47.203779220581055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "United Kingdom and their allies", "latency_ms": 94.03419494628906, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 592}, "2": {"k": 2, "answer": "United Kingdom and their respective allies", "latency_ms": 113.89565467834473, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1174}, "3": {"k": 3, "answer": "United Kingdom and their respective allies", "latency_ms": 129.73761558532715, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1792}, "4": {"k": 4, "answer": "United Kingdom and their respective allies", "latency_ms": 134.25540924072266, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2450}, "5": {"k": 5, "answer": "United Kingdom and their respective allies", "latency_ms": 146.13008499145508, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3076}, "6": {"k": 6, "answer": "United Kingdom and their allies", "latency_ms": 139.8923397064209, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3718}}}
{"qid": "-4248204617651187901", "question": "when does the new episodes of supernatural start", "gold_answers": ["October 12 , 2017", "May 3 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.10256767272949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 87.9058837890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "October 11, 2018", "latency_ms": 163.65289688110352, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1322}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 181.35643005371094, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1974}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 195.19376754760742, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 198.42767715454102, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3233}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 213.44947814941406, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3869}}}
{"qid": "-8934076303964179830", "question": "why was the plague that struck athens so devastating", "gold_answers": ["close quarters and poor hygiene"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.2934684753418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "entered through Piraeus, the city's port and sole source of food and supplies", "latency_ms": 235.22377014160156, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "It entered through Piraeus, the city's port and sole source of food and supplies.", "latency_ms": 273.90336990356445, "em": 0.0, "f1": 0.1111111111111111, "containment": 0.0, "context_chars": 1216}, "3": {"k": 3, "answer": "wiped out over 30,000 citizens, sailors and soldiers, including Pericles and his sons; reduced Athenian manpower drastically; caused one-third to two-thirds of the population to die", "latency_ms": 555.3653240203857, "em": 0.0, "f1": 0.06666666666666667, "containment": 0.0, "context_chars": 1872}, "4": {"k": 4, "answer": "devastating due to high mortality rate and loss of manpower", "latency_ms": 206.88319206237793, "em": 0.0, "f1": 0.13333333333333333, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "crowding, inadequate supplies, insects, lice, rats, and waste", "latency_ms": 256.8323612213135, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 3204}, "6": {"k": 6, "answer": "crowding, inadequate supplies, insects, lice, rats, and waste", "latency_ms": 260.0691318511963, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 3837}}}
{"qid": "8565998783583575256", "question": "who was it that described the structure of dna", "gold_answers": ["James Watson", "Francis Crick", "James Watson and Francis Crick"], "shots": {"0": {"k": 0, "answer": "Watson and Crick", "latency_ms": 87.51630783081055, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Watson and Francis Crick", "latency_ms": 105.70812225341797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 676}, "2": {"k": 2, "answer": "James Watson and Francis Crick", "latency_ms": 118.19744110107422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1339}, "3": {"k": 3, "answer": "James Watson and Francis Crick", "latency_ms": 130.0191879272461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2019}, "4": {"k": 4, "answer": "James Watson and Francis Crick", "latency_ms": 132.08556175231934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2763}, "5": {"k": 5, "answer": "James Watson and Francis Crick", "latency_ms": 144.9873447418213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3387}, "6": {"k": 6, "answer": "James Watson and Francis Crick", "latency_ms": 160.51506996154785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4030}}}
{"qid": "-7169979332070555515", "question": "what does a heart rate of 131 mean", "gold_answers": ["Tachycardia", "tachycardia in adults"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.96819305419922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elevated heart rate; above normal resting range; may indicate stress, exertion, or medical condition", "latency_ms": 283.95605087280273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "elevated heart rate, indicating potential cardiovascular concern", "latency_ms": 160.10165214538574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "tachycardia", "latency_ms": 115.9830093383789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1873}, "4": {"k": 4, "answer": "tachycardia", "latency_ms": 118.23201179504395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2540}, "5": {"k": 5, "answer": "tachycardia", "latency_ms": 132.612943649292, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "tachycardia", "latency_ms": 137.4056339263916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3757}}}
{"qid": "8954395166333101592", "question": "who sings for the beast in the new movie", "gold_answers": ["Dan Stevens"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 71.16866111755371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Stevens", "latency_ms": 62.415361404418945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Dan Stevens", "latency_ms": 64.8643970489502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1335}, "3": {"k": 3, "answer": "Dan Stevens", "latency_ms": 78.1404972076416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1987}, "4": {"k": 4, "answer": "Dan Stevens", "latency_ms": 80.58452606201172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Dan Stevens", "latency_ms": 103.25121879577637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "Dan Stevens", "latency_ms": 113.75141143798828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3888}}}
{"qid": "-2938895990276127289", "question": "what is the current rate of interest on ppf", "gold_answers": ["7.6 % Per Annum", "7.6 %"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.26056671142578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8.0% per annum", "latency_ms": 102.29897499084473, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "8.0%", "latency_ms": 93.60194206237793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1176}, "3": {"k": 3, "answer": "8.0%", "latency_ms": 105.6663990020752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1766}, "4": {"k": 4, "answer": "8.0%", "latency_ms": 105.68881034851074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2348}, "5": {"k": 5, "answer": "8.0%", "latency_ms": 123.73089790344238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2976}, "6": {"k": 6, "answer": "8.0%", "latency_ms": 125.8401870727539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3565}}}
{"qid": "1949369884900729065", "question": "when is the fa cup semi-finals being played", "gold_answers": ["Wembley Stadium"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.66046714782715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Saturday 21 April and Sunday 22 April 2018", "latency_ms": 228.09243202209473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "21 April and 22 April 2018", "latency_ms": 202.68774032592773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Saturday 21 April and Sunday 22 April 2018", "latency_ms": 251.94954872131348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Saturday 21 April and Sunday 22 April 2018", "latency_ms": 255.62095642089844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2448}, "5": {"k": 5, "answer": "Saturday 21 April and Sunday 22 April 2018", "latency_ms": 269.2575454711914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3073}, "6": {"k": 6, "answer": "Saturday 21 April and Sunday 22 April 2018", "latency_ms": 274.29699897766113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3678}}}
{"qid": "930703855764177846", "question": "civil war what did the north fight for", "gold_answers": ["loyalty to the U.S. Constitution", "maintaining the republic"], "shots": {"0": {"k": 0, "answer": "Union preservation and abolition of slavery", "latency_ms": 100.04448890686035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "preserve the union as an expression of American nationalism", "latency_ms": 138.24748992919922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "preserve the union as an expression of American nationalism", "latency_ms": 154.4640064239502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "preserve the union and maintain the Constitution's guarantees of rights and liberties", "latency_ms": 213.09185028076172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1997}, "4": {"k": 4, "answer": "preserve the union as an expression of American nationalism", "latency_ms": 166.87488555908203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2596}, "5": {"k": 5, "answer": "preserve the union and maintain constitutional rights and liberties", "latency_ms": 183.5920810699463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3228}, "6": {"k": 6, "answer": "preserve the Union and maintain constitutional rights", "latency_ms": 163.47718238830566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3869}}}
{"qid": "8498415218701324220", "question": "how many states have a cracker barrel restaurant", "gold_answers": ["43"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 72.40867614746094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 80.31439781188965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "44", "latency_ms": 64.97383117675781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1280}, "3": {"k": 3, "answer": "44", "latency_ms": 80.83367347717285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "44", "latency_ms": 82.01026916503906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2563}, "5": {"k": 5, "answer": "44 states", "latency_ms": 106.45508766174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3247}, "6": {"k": 6, "answer": "44 states", "latency_ms": 115.71121215820312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3923}}}
{"qid": "5046802918953054509", "question": "who wrote papa got a brand new bag", "gold_answers": ["James Brown"], "shots": {"0": {"k": 0, "answer": "Laurie Anderson", "latency_ms": 75.50907135009766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Brown", "latency_ms": 58.287620544433594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 588}, "2": {"k": 2, "answer": "James Brown", "latency_ms": 68.04490089416504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1194}, "3": {"k": 3, "answer": "James Brown", "latency_ms": 81.1011791229248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1784}, "4": {"k": 4, "answer": "James Brown", "latency_ms": 81.6802978515625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "James Brown", "latency_ms": 101.64403915405273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2930}, "6": {"k": 6, "answer": "James Brown", "latency_ms": 114.50695991516113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3526}}}
{"qid": "5600309892472942305", "question": "when was national service abolished in the uk", "gold_answers": ["1960", "November 1960", "31 December 1960"], "shots": {"0": {"k": 0, "answer": "1960", "latency_ms": 75.25396347045898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "31 December 1960", "latency_ms": 132.188081741333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 607}, "2": {"k": 2, "answer": "1957", "latency_ms": 88.78231048583984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "1963", "latency_ms": 104.62474822998047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "1957", "latency_ms": 120.78189849853516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2539}, "5": {"k": 5, "answer": "1963", "latency_ms": 122.39336967468262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "1963", "latency_ms": 139.59336280822754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3826}}}
{"qid": "-7184968347544956967", "question": "who plays genie in ferris bueller's day off", "gold_answers": ["Jennifer Grey"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 72.10016250610352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 86.5626335144043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 89.87760543823242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1296}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.60347747802734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 123.80862236022949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2518}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 125.33259391784668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3113}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 140.47884941101074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3755}}}
{"qid": "-5340036721442264822", "question": "who was the main character in their eyes were watching god", "gold_answers": ["Janie Crawford"], "shots": {"0": {"k": 0, "answer": "Janie Crawford", "latency_ms": 59.01837348937988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Janie", "latency_ms": 52.41227149963379, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "Janie", "latency_ms": 62.990427017211914, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Janie Crawford", "latency_ms": 93.28103065490723, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1852}, "4": {"k": 4, "answer": "Janie Crawford", "latency_ms": 96.00567817687988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2489}, "5": {"k": 5, "answer": "Janie Crawford", "latency_ms": 110.71491241455078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3070}, "6": {"k": 6, "answer": "Janie Crawford", "latency_ms": 114.82691764831543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3654}}}
{"qid": "-4088049636139478618", "question": "describe the various uses of forests to human beings", "gold_answers": ["acting as a carbon sink", "purifying water", "serving as a genetic reserve", "a source of lumber", "aiding in regulating climate ,", "recreational areas"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.7286548614502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "timber, fuel wood, wildlife habitat, water quality management, recreation, landscape and community protection, employment, aesthetically appealing landscapes, biodiversity management, watershed management, erosion control, preserving forests as \"sinks\" for atmospheric carbon", "latency_ms": 603.6295890808105, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 792}, "2": {"k": 2, "answer": "timber, fuel wood, wildlife habitat, water quality management, recreation, erosion control, biodiversity management, watershed management, employment, aesthetically appealing landscapes, carbon storage, food (fruit), shade, shelter", "latency_ms": 549.1712093353271, "em": 0.0, "f1": 0.07407407407407407, "containment": 0.0, "context_chars": 1423}, "3": {"k": 3, "answer": "timber, fuel wood, wildlife habitat, water quality management, recreation, erosion control, biodiversity management, watershed management, employment, aesthetically appealing landscapes, carbon storage, shade, shelter, fruit, construction, cooking, heating", "latency_ms": 608.6323261260986, "em": 0.0, "f1": 0.06896551724137931, "containment": 0.0, "context_chars": 2076}, "4": {"k": 4, "answer": "Timber, fuel wood, wildlife habitat, water quality management, recreation, erosion control, biodiversity management, watershed management, employment, aesthetically appealing landscapes, carbon storage, food (fruit), shelter, shade, fodder, landscape and community protection", "latency_ms": 657.3841571807861, "em": 0.0, "f1": 0.0625, "containment": 0.0, "context_chars": 2743}, "5": {"k": 5, "answer": "timber, fuel wood, wildlife habitat, water quality management, recreation, erosion control, biodiversity management, watershed management, employment, aesthetically appealing landscapes, carbon storage, food (fruit), shelter, shade, fodder, and landscape protection", "latency_ms": 650.5513191223145, "em": 0.0, "f1": 0.06451612903225806, "containment": 0.0, "context_chars": 3430}, "6": {"k": 6, "answer": "timber, fuel wood, wildlife habitat, water quality management, recreation, erosion control, biodiversity management, watershed management, employment, aesthetically appealing landscapes, carbon storage, food (fruit), shelter, shade, fodder, and landscape protection", "latency_ms": 673.6631393432617, "em": 0.0, "f1": 0.06451612903225806, "containment": 0.0, "context_chars": 4163}}}
{"qid": "3515985474543482606", "question": "what does it mean to fuse the spine", "gold_answers": ["joins two or more vertebrae"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 72.38435745239258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to join two or more vertebrae to prevent movement and promote healing through bone grafting and hardware", "latency_ms": 278.3193588256836, "em": 0.0, "f1": 0.3636363636363636, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "to join two or more vertebrae together to prevent movement and relieve pain", "latency_ms": 223.30832481384277, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "to join two or more vertebrae together to prevent movement and promote healing using bone grafts or artificial substitutes, often with hardware for stability", "latency_ms": 398.23460578918457, "em": 0.0, "f1": 0.27586206896551724, "containment": 0.0, "context_chars": 2073}, "4": {"k": 4, "answer": "to join two or more vertebrae together to prevent movement and relieve pain", "latency_ms": 240.87047576904297, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 2683}, "5": {"k": 5, "answer": "to join two or more vertebrae together using bone grafts and hardware to prevent movement and relieve pain", "latency_ms": 332.3976993560791, "em": 0.0, "f1": 0.3478260869565218, "containment": 0.0, "context_chars": 3303}, "6": {"k": 6, "answer": "to join two or more vertebrae together to prevent movement and stabilize the spine", "latency_ms": 273.62775802612305, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 3978}}}
{"qid": "-8761541385334924915", "question": "who is the highest selling r&b artist of all time", "gold_answers": ["Rihanna", "Michael Jackson"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 71.9594955444336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "R. Kelly", "latency_ms": 74.05209541320801, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "R. Kelly", "latency_ms": 76.69925689697266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "R. Kelly", "latency_ms": 95.1383113861084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1825}, "4": {"k": 4, "answer": "R. Kelly", "latency_ms": 111.14859580993652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 125.6558895111084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3076}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 141.54934883117676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3678}}}
{"qid": "-1414931910309881085", "question": "a country having an island location and a country having continental location", "gold_answers": ["Australia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.85883140563965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Australia, United Kingdom", "latency_ms": 80.7182788848877, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Greenland, Australia", "latency_ms": 84.42282676696777, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Greenland, Australia", "latency_ms": 102.95224189758301, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2015}, "4": {"k": 4, "answer": "Greenland, Australia", "latency_ms": 108.53743553161621, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2686}, "5": {"k": 5, "answer": "Greenland, Australia", "latency_ms": 122.86496162414551, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3322}, "6": {"k": 6, "answer": "Greenland, Australia", "latency_ms": 127.75897979736328, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4045}}}
{"qid": "-5483795084355435186", "question": "who plays the girl in wreck it ralph", "gold_answers": ["Stefanie Scott", "Sarah Silverman"], "shots": {"0": {"k": 0, "answer": "Riley Smith", "latency_ms": 60.25385856628418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.02736282348633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "Sarah Silverman", "latency_ms": 78.51266860961914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1325}, "3": {"k": 3, "answer": "Sarah Silverman", "latency_ms": 89.69712257385254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1999}, "4": {"k": 4, "answer": "Sarah Silverman", "latency_ms": 106.31084442138672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2641}, "5": {"k": 5, "answer": "Sarah Silverman", "latency_ms": 113.94739151000977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3281}, "6": {"k": 6, "answer": "Sarah Silverman", "latency_ms": 127.03108787536621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3923}}}
{"qid": "-1067956350108837521", "question": "love is not love that alters when it alteration finds meaning", "gold_answers": ["Sonnet 116"], "shots": {"0": {"k": 0, "answer": "Shakespeare", "latency_ms": 48.16889762878418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Berit Brogaard", "latency_ms": 74.9814510345459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "Sonnet 116", "latency_ms": 113.95573616027832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Sonnet 116", "latency_ms": 124.99642372131348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Sonnet 116", "latency_ms": 132.77959823608398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2494}, "5": {"k": 5, "answer": "Sonnet 116", "latency_ms": 133.41093063354492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3112}, "6": {"k": 6, "answer": "Sonnet 116", "latency_ms": 149.37782287597656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3708}}}
{"qid": "-2126374007719970792", "question": "what olympic athlete has won the most medals", "gold_answers": ["Michael Phelps", "Marit Bj√∏rgen", "American swimmer Michael Phelps"], "shots": {"0": {"k": 0, "answer": "Larisa Latynina", "latency_ms": 100.23355484008789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Natalie Coughlin", "latency_ms": 110.2755069732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "Michael Phelps", "latency_ms": 68.19391250610352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Michael Phelps", "latency_ms": 80.53088188171387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1857}, "4": {"k": 4, "answer": "Michael Phelps", "latency_ms": 84.38658714294434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2477}, "5": {"k": 5, "answer": "Michael Phelps", "latency_ms": 96.32468223571777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3110}, "6": {"k": 6, "answer": "Michael Phelps", "latency_ms": 110.62407493591309, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3722}}}
{"qid": "1895553409990436687", "question": "list all the planet of the ape movies", "gold_answers": ["Planet of the Apes"], "shots": {"0": {"k": 0, "answer": "Planet of the Apes (1968), Planet of the Apes (1973), Planet of the Apes (1974), Planet of the Apes (1977), Planet of the Apes (1984), Planet of the Apes (1999), Planet of the Apes (2011), Planet of the Apes (2014), Planet of the Apes (2017)", "latency_ms": 1229.393720626831, "em": 0.0, "f1": 0.15384615384615385, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rise of the Planet of the Apes, Dawn of the Planet of the Apes, War for the Planet of the Apes", "latency_ms": 364.13049697875977, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "Rise of the Planet of the Apes, Dawn of the Planet of the Apes, War for the Planet of the Apes", "latency_ms": 375.3247261047363, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Rise of the Planet of the Apes, Dawn of the Planet of the Apes, War for the Planet of the Apes", "latency_ms": 387.12620735168457, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "Rise of the Planet of the Apes, Dawn of the Planet of the Apes, War for the Planet of the Apes", "latency_ms": 391.9551372528076, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2527}, "5": {"k": 5, "answer": "Rise of the Planet of the Apes, Dawn of the Planet of the Apes, War for the Planet of the Apes", "latency_ms": 406.15034103393555, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3149}, "6": {"k": 6, "answer": "Rise of the Planet of the Apes, Dawn of the Planet of the Apes, War for the Planet of the Apes", "latency_ms": 412.22405433654785, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3815}}}
{"qid": "7483656096034094185", "question": "what is the highest base on the ph scale", "gold_answers": ["greater than 14"], "shots": {"0": {"k": 0, "answer": "14", "latency_ms": 51.35607719421387, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "greater than 14", "latency_ms": 93.73664855957031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 638}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 85.86359024047852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 107.78617858886719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1842}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 109.17329788208008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2386}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 121.25682830810547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2998}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 122.94268608093262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3656}}}
{"qid": "514606611619187835", "question": "who sang if this world were mine with luther vandross", "gold_answers": ["Tammi Terrell", "Cheryl Lynn"], "shots": {"0": {"k": 0, "answer": "Toni Braxton", "latency_ms": 88.72222900390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cheryl Lynn", "latency_ms": 72.94726371765137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 581}, "2": {"k": 2, "answer": "Cheryl Lynn", "latency_ms": 78.13405990600586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "Cheryl Lynn", "latency_ms": 92.58198738098145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1763}, "4": {"k": 4, "answer": "Cheryl Lynn", "latency_ms": 97.48482704162598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2369}, "5": {"k": 5, "answer": "Cheryl Lynn", "latency_ms": 113.27815055847168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2965}, "6": {"k": 6, "answer": "Cheryl Lynn", "latency_ms": 125.76866149902344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3565}}}
{"qid": "-8782267081987454950", "question": "what grade was arnold from hey arnold in", "gold_answers": ["fourth"], "shots": {"0": {"k": 0, "answer": "6th grade", "latency_ms": 59.82327461242676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "C", "latency_ms": 43.897151947021484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 93.49656105041504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 103.14393043518066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1887}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 106.70638084411621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 123.62003326416016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3197}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 137.3918056488037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3885}}}
{"qid": "-5579812134939807145", "question": "who has the most rings in the nba right now 2017", "gold_answers": ["Boston Celtics center Bill Russell", "Bill Russell"], "shots": {"0": {"k": 0, "answer": "Kareem Abdul-Jabbar", "latency_ms": 110.59975624084473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kareem Abdul-Jabbar", "latency_ms": 123.27098846435547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "Red Auerbach", "latency_ms": 90.38686752319336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "Red Auerbach", "latency_ms": 105.08871078491211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1796}, "4": {"k": 4, "answer": "Red Auerbach", "latency_ms": 109.14134979248047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2450}, "5": {"k": 5, "answer": "Red Auerbach", "latency_ms": 123.5051155090332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3072}, "6": {"k": 6, "answer": "Red Auerbach", "latency_ms": 135.7278823852539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3693}}}
{"qid": "6169250924115231970", "question": "when was the first wonder woman comic released", "gold_answers": ["December 1941", "January 1942", "October 1941"], "shots": {"0": {"k": 0, "answer": "1941", "latency_ms": 76.10177993774414, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 25, 1940", "latency_ms": 158.23674201965332, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 712}, "2": {"k": 2, "answer": "January 1942", "latency_ms": 117.8584098815918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1356}, "3": {"k": 3, "answer": "October 1941", "latency_ms": 129.7433376312256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2022}, "4": {"k": 4, "answer": "October 1941", "latency_ms": 134.1700553894043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2691}, "5": {"k": 5, "answer": "October 1941", "latency_ms": 146.11196517944336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3356}, "6": {"k": 6, "answer": "October 1941", "latency_ms": 161.5290641784668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3998}}}
{"qid": "-2610209560699528896", "question": "who is the writer of 50 shades of grey", "gold_answers": ["E.L. James", "Erika Mitchell Leonard"], "shots": {"0": {"k": 0, "answer": "E.L. James", "latency_ms": 76.66707038879395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "E.L. James", "latency_ms": 80.64723014831543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "E. L. James", "latency_ms": 102.59795188903809, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1378}, "3": {"k": 3, "answer": "E. L. James", "latency_ms": 115.23962020874023, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2077}, "4": {"k": 4, "answer": "E. L. James", "latency_ms": 123.36301803588867, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2737}, "5": {"k": 5, "answer": "E. L. James", "latency_ms": 138.22531700134277, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3360}, "6": {"k": 6, "answer": "E. L. James", "latency_ms": 147.78637886047363, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4013}}}
{"qid": "-737552813357159486", "question": "when does synapsis of homologous chromosomes occur in mitosis", "gold_answers": ["prophase I of meiosis", "during prophase I of meiosis"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.69408416748047, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.45150947570801, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 728}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 93.19162368774414, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1404}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 104.89964485168457, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2192}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 109.45701599121094, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2958}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 123.63624572753906, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3621}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 137.44854927062988, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4344}}}
{"qid": "1679657142367725037", "question": "when did the age of new media began", "gold_answers": ["the 1980s"], "shots": {"0": {"k": 0, "answer": "1990s", "latency_ms": 87.53371238708496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 80.41644096374512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 682}, "2": {"k": 2, "answer": "1995", "latency_ms": 84.53559875488281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "1980s", "latency_ms": 112.84685134887695, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1933}, "4": {"k": 4, "answer": "1995", "latency_ms": 108.34050178527832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2559}, "5": {"k": 5, "answer": "1995", "latency_ms": 121.94252014160156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "1995", "latency_ms": 126.2509822845459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3916}}}
{"qid": "-3281440710636336200", "question": "who sang it going to take a miracle", "gold_answers": ["The Royalettes"], "shots": {"0": {"k": 0, "answer": "Whitney Houston", "latency_ms": 72.12162017822266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Royalettes", "latency_ms": 86.73262596130371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 588}, "2": {"k": 2, "answer": "Deniece Williams", "latency_ms": 75.7591724395752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Deniece Williams", "latency_ms": 92.74888038635254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1794}, "4": {"k": 4, "answer": "Deniece Williams", "latency_ms": 97.85699844360352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2418}, "5": {"k": 5, "answer": "Deniece Williams", "latency_ms": 114.28475379943848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3030}, "6": {"k": 6, "answer": "Deniece Williams", "latency_ms": 126.62911415100098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3725}}}
{"qid": "1855937371513832647", "question": "the legend of heroes trails in the sky the 3rd vita", "gold_answers": ["July 14 , 2016"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 72.0677375793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "July 14, 2016", "latency_ms": 154.0369987487793, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "July 14, 2016", "latency_ms": 167.19841957092285, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "July 14, 2016", "latency_ms": 181.43963813781738, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "July 14, 2016", "latency_ms": 181.29730224609375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "July 14, 2016", "latency_ms": 198.65751266479492, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "July 14, 2016", "latency_ms": 210.38579940795898, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3877}}}
{"qid": "-6558748163299033937", "question": "where does the us launch space shuttles from", "gold_answers": ["Florida"], "shots": {"0": {"k": 0, "answer": "Kennedy Space Center, Florida", "latency_ms": 96.21381759643555, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 79.79226112365723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Kennedy Space Center in Cape Canaveral, Florida", "latency_ms": 176.3162612915039, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Cape Canaveral Air Force Station in Florida", "latency_ms": 175.80318450927734, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Kennedy Space Center in Cape Canaveral, Florida", "latency_ms": 193.32122802734375, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 2544}, "5": {"k": 5, "answer": "Kennedy Space Center at Cape Canaveral, Florida", "latency_ms": 208.42242240905762, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 3167}, "6": {"k": 6, "answer": "Kennedy Space Center", "latency_ms": 127.06232070922852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3855}}}
{"qid": "-3130775636464914942", "question": "where did the peanut butter jelly time song come from", "gold_answers": ["Buckwheat Boyz", "The Buckwheat Boyz"], "shots": {"0": {"k": 0, "answer": "Peanut Butter Jelly Time song originated from a children's educational program.", "latency_ms": 206.3310146331787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Galantis", "latency_ms": 58.096885681152344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "Galantis", "latency_ms": 65.51861763000488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "Bettye Swann's \"Kiss My Love Goodbye\" (1974)", "latency_ms": 302.02507972717285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1929}, "4": {"k": 4, "answer": "The Buckwheat Boyz self-titled album", "latency_ms": 193.861722946167, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2582}, "5": {"k": 5, "answer": "The Buckwheat Boyz self-titled album", "latency_ms": 200.36029815673828, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3214}, "6": {"k": 6, "answer": "The Buckwheat Boyz self-titled album", "latency_ms": 212.92686462402344, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3826}}}
{"qid": "2064553657789426310", "question": "who was the drummer with the travelling wilburys", "gold_answers": ["Jim Keltner"], "shots": {"0": {"k": 0, "answer": "Bob Dylan", "latency_ms": 52.31308937072754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 87.33677864074707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 681}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 95.02363204956055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1358}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 105.69572448730469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 106.82058334350586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2689}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 124.13144111633301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "Jim Keltner", "latency_ms": 137.18581199645996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4054}}}
{"qid": "2527076947511613283", "question": "what was the actual year that the movie regarding the titans took place", "gold_answers": ["1971"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.92582702636719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 80.04140853881836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 93.07718276977539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1232}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 102.83493995666504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1850}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 105.15284538269043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 121.27566337585449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3114}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 135.1456642150879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3733}}}
{"qid": "-3334598732942808226", "question": "when was the cleveland browns last winning game", "gold_answers": ["2016"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.32231712341309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.00662040710449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "1964", "latency_ms": 89.2493724822998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "1986", "latency_ms": 109.0855598449707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1844}, "4": {"k": 4, "answer": "1969", "latency_ms": 120.61262130737305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "1969", "latency_ms": 126.22547149658203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3100}, "6": {"k": 6, "answer": "1986", "latency_ms": 137.3581886291504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3680}}}
{"qid": "6043941490080483660", "question": "who is the first indian climber of mount everest", "gold_answers": ["Bachendri Pal"], "shots": {"0": {"k": 0, "answer": "Sati Devi", "latency_ms": 75.64449310302734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ganesh Jena", "latency_ms": 96.17114067077637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 574}, "2": {"k": 2, "answer": "Ganesh Jena", "latency_ms": 101.76277160644531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1185}, "3": {"k": 3, "answer": "Ganesh Jena", "latency_ms": 117.46931076049805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1920}, "4": {"k": 4, "answer": "H. P. S. Ahluwalia", "latency_ms": 181.25629425048828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "H. P. S. Ahluwalia", "latency_ms": 200.22988319396973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "H. P. S. Ahluwalia", "latency_ms": 210.96467971801758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3711}}}
{"qid": "-446953971794550129", "question": "how many games does a team have to win for the world series", "gold_answers": ["best - of - seven"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 71.88534736633301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "4", "latency_ms": 43.51544380187988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "4", "latency_ms": 52.47163772583008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "4", "latency_ms": 58.04634094238281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1811}, "4": {"k": 4, "answer": "4 games", "latency_ms": 81.5126895904541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2427}, "5": {"k": 5, "answer": "4 games", "latency_ms": 95.76606750488281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3042}, "6": {"k": 6, "answer": "4 games", "latency_ms": 98.5100269317627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3629}}}
{"qid": "8653383319877139807", "question": "what does a yellow 35 mph sign mean", "gold_answers": ["advisory speed limits"], "shots": {"0": {"k": 0, "answer": "Speed limit is 35 mph", "latency_ms": 109.26246643066406, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "35 mph speed limit", "latency_ms": 93.55854988098145, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "35 mph speed limit", "latency_ms": 105.73863983154297, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Reduce speed to 35 mph", "latency_ms": 139.56618309020996, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1872}, "4": {"k": 4, "answer": "Reduce speed to 35 mph", "latency_ms": 142.17209815979004, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "reduce speed to 35 mph", "latency_ms": 159.35230255126953, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Reduce speed to 35 mph", "latency_ms": 161.59915924072266, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3758}}}
{"qid": "6560069079547802297", "question": "who is the robot in lost in space 2018", "gold_answers": ["Brian Steele"], "shots": {"0": {"k": 0, "answer": "C-3PO", "latency_ms": 75.64687728881836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "an alien AI", "latency_ms": 64.51916694641113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "an alien AI", "latency_ms": 76.61819458007812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "an alien AI", "latency_ms": 93.08862686157227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1925}, "4": {"k": 4, "answer": "an alien AI", "latency_ms": 96.71306610107422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2617}, "5": {"k": 5, "answer": "an alien AI", "latency_ms": 110.73064804077148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3239}, "6": {"k": 6, "answer": "an alien AI", "latency_ms": 112.63513565063477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3934}}}
{"qid": "-8498528300766844409", "question": "how long is a prime minister term in uk", "gold_answers": ["At Her Majesty 's pleasure"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.92630386352539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "varies", "latency_ms": 58.305978775024414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "five years", "latency_ms": 68.49551200866699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "five years", "latency_ms": 77.18634605407715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "five years", "latency_ms": 82.48353004455566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2606}, "5": {"k": 5, "answer": "five years", "latency_ms": 96.27723693847656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "five years", "latency_ms": 102.50282287597656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3904}}}
{"qid": "-3946622065085295485", "question": "when was the letter j introduced to the alphabet", "gold_answers": ["1524", "in Middle High German"], "shots": {"0": {"k": 0, "answer": "1500", "latency_ms": 75.97851753234863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 86.1055850982666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "17th century", "latency_ms": 90.32225608825684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "17th century", "latency_ms": 106.35256767272949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "17th century", "latency_ms": 110.7034683227539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2410}, "5": {"k": 5, "answer": "17th century", "latency_ms": 124.25351142883301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3038}, "6": {"k": 6, "answer": "17th century", "latency_ms": 125.06389617919922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3610}}}
{"qid": "-7134557580880481094", "question": "what is money as a medium of exchange", "gold_answers": ["fiat money"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.14691352844238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "widely accepted token which can be exchanged for goods and services", "latency_ms": 178.37762832641602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "a widely accepted token that can be exchanged for goods and services", "latency_ms": 182.24549293518066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "a widely accepted token that can be exchanged for goods and services", "latency_ms": 191.15734100341797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1831}, "4": {"k": 4, "answer": "a widely accepted token that can be exchanged for goods and services", "latency_ms": 203.02152633666992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2413}, "5": {"k": 5, "answer": "a widely accepted token that can be exchanged for goods and services", "latency_ms": 207.35907554626465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3059}, "6": {"k": 6, "answer": "a widely accepted token that can be exchanged for goods and services", "latency_ms": 220.62993049621582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3702}}}
{"qid": "1766492609128749018", "question": "when was the last time the boston red sox pitched a no-hitter", "gold_answers": ["May 19 , 2008"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 72.96633720397949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "April 22, 1993", "latency_ms": 155.4255485534668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "September 1, 2007", "latency_ms": 150.15602111816406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1157}, "3": {"k": 3, "answer": "April 22, 1993", "latency_ms": 176.66292190551758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1759}, "4": {"k": 4, "answer": "September 1, 2007", "latency_ms": 167.83833503723145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2358}, "5": {"k": 5, "answer": "September 1, 2007", "latency_ms": 183.44521522521973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2936}, "6": {"k": 6, "answer": "September 1, 2007", "latency_ms": 199.46813583374023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3523}}}
{"qid": "-3991542393876701651", "question": "how many levels are there on the eiffel tower", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3 levels", "latency_ms": 51.42521858215332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "three", "latency_ms": 44.137001037597656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 577}, "2": {"k": 2, "answer": "three", "latency_ms": 52.88553237915039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "three", "latency_ms": 64.74709510803223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1825}, "4": {"k": 4, "answer": "three", "latency_ms": 73.00972938537598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2412}, "5": {"k": 5, "answer": "three", "latency_ms": 81.84075355529785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3007}, "6": {"k": 6, "answer": "three", "latency_ms": 87.43810653686523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3611}}}
{"qid": "7273651277313451649", "question": "when will fairy tail final season be released", "gold_answers": ["2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.28376579284668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 7, 2018", "latency_ms": 147.66550064086914, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 591}, "2": {"k": 2, "answer": "2018", "latency_ms": 92.47303009033203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1222}, "3": {"k": 3, "answer": "2018", "latency_ms": 105.92842102050781, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "2018", "latency_ms": 124.22418594360352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2466}, "5": {"k": 5, "answer": "2018", "latency_ms": 128.1723976135254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3064}, "6": {"k": 6, "answer": "2018", "latency_ms": 140.66243171691895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3699}}}
{"qid": "3797700825907085260", "question": "when did somewhere over the rainbow come out", "gold_answers": ["1939"], "shots": {"0": {"k": 0, "answer": "1939", "latency_ms": 71.27523422241211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "April 2007", "latency_ms": 111.20104789733887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 92.56291389465332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1187}, "3": {"k": 3, "answer": "October 7, 1938", "latency_ms": 164.42227363586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "October 7, 1938", "latency_ms": 172.29604721069336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "October 7, 1938", "latency_ms": 182.570219039917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "1939", "latency_ms": 139.87040519714355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3672}}}
{"qid": "7311273005529291652", "question": "which layer of the osi model handles physical addressing", "gold_answers": ["physical layer or layer 1"], "shots": {"0": {"k": 0, "answer": "Data Link Layer", "latency_ms": 59.90910530090332, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 76.18546485900879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "Data Link Layer", "latency_ms": 73.77934455871582, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "Data Link Layer", "latency_ms": 80.68704605102539, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2140}, "4": {"k": 4, "answer": "Data Link Layer", "latency_ms": 91.76874160766602, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2806}, "5": {"k": 5, "answer": "Physical layer", "latency_ms": 85.73341369628906, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3461}, "6": {"k": 6, "answer": "Data link layer", "latency_ms": 112.30063438415527, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 4057}}}
{"qid": "3216644197084568934", "question": "when does season 7 game of thrones dvd release", "gold_answers": ["December 12 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.88164710998535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "December 12, 2017", "latency_ms": 155.50518035888672, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "December 12, 2017", "latency_ms": 167.11020469665527, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1196}, "3": {"k": 3, "answer": "December 12, 2017", "latency_ms": 176.79524421691895, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1789}, "4": {"k": 4, "answer": "December 12, 2017", "latency_ms": 184.12351608276367, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2464}, "5": {"k": 5, "answer": "December 12, 2017", "latency_ms": 197.87979125976562, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3090}, "6": {"k": 6, "answer": "December 12, 2017", "latency_ms": 212.10241317749023, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3737}}}
{"qid": "-8667457702492888266", "question": "when did hootie and the blowfish come out", "gold_answers": ["1986", "March 4 , 2003", "2003"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.27654075622559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1986", "latency_ms": 82.01241493225098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 628}, "2": {"k": 2, "answer": "1986", "latency_ms": 88.63306045532227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1244}, "3": {"k": 3, "answer": "1986", "latency_ms": 102.07271575927734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1867}, "4": {"k": 4, "answer": "July 5, 1994", "latency_ms": 169.19445991516113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2494}, "5": {"k": 5, "answer": "July 5, 1994", "latency_ms": 188.05718421936035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3136}, "6": {"k": 6, "answer": "July 5, 1994", "latency_ms": 202.33488082885742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3770}}}
{"qid": "3333632246774892382", "question": "what is the dogs name in wizard of oz", "gold_answers": ["Toto"], "shots": {"0": {"k": 0, "answer": "Toto", "latency_ms": 52.258968353271484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Toto", "latency_ms": 55.245161056518555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 572}, "2": {"k": 2, "answer": "Toto", "latency_ms": 64.61310386657715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1164}, "3": {"k": 3, "answer": "Toto", "latency_ms": 81.29072189331055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1764}, "4": {"k": 4, "answer": "Toto", "latency_ms": 83.95600318908691, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2352}, "5": {"k": 5, "answer": "Toto", "latency_ms": 97.08642959594727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2905}, "6": {"k": 6, "answer": "Toto", "latency_ms": 103.15394401550293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3498}}}
{"qid": "8095609166102020574", "question": "third president of the united states of america", "gold_answers": ["Thomas Jefferson"], "shots": {"0": {"k": 0, "answer": "John Adams", "latency_ms": 51.79142951965332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "George Washington", "latency_ms": 52.06871032714844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "George Washington", "latency_ms": 65.65070152282715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "James Madison", "latency_ms": 80.88469505310059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1985}, "4": {"k": 4, "answer": "George Washington", "latency_ms": 85.38579940795898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2655}, "5": {"k": 5, "answer": "George Washington", "latency_ms": 100.7843017578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3346}, "6": {"k": 6, "answer": "George Washington", "latency_ms": 102.64396667480469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4021}}}
{"qid": "-5476409518666505226", "question": "what's the medal count for canada in the olympics", "gold_answers": ["501", "302"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 71.9761848449707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "29", "latency_ms": 53.231239318847656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "29", "latency_ms": 69.03719902038574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "29", "latency_ms": 80.85036277770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1910}, "4": {"k": 4, "answer": "29", "latency_ms": 82.30853080749512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2568}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 122.22099304199219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "29", "latency_ms": 111.3893985748291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3834}}}
{"qid": "-6639256684125098362", "question": "when was the last easter fell on april 1", "gold_answers": ["2018"], "shots": {"0": {"k": 0, "answer": "2018", "latency_ms": 76.0657787322998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2018", "latency_ms": 80.66368103027344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "2023", "latency_ms": 94.16460990905762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 103.12032699584961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 108.96086692810059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2448}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 120.09048461914062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3012}, "6": {"k": 6, "answer": "549", "latency_ms": 112.72048950195312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3571}}}
{"qid": "604994066909407376", "question": "who won nfl football coach of the year", "gold_answers": ["Sean McVay"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 71.48623466491699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sean McVay", "latency_ms": 76.91216468811035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 636}, "2": {"k": 2, "answer": "Sean McVay", "latency_ms": 82.70740509033203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Sean McVay", "latency_ms": 104.7976016998291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Sean McVay", "latency_ms": 106.81962966918945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2536}, "5": {"k": 5, "answer": "Sean McVay", "latency_ms": 122.91097640991211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3218}, "6": {"k": 6, "answer": "Sean McVay", "latency_ms": 124.89628791809082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3852}}}
{"qid": "2098451012213010201", "question": "who abolished the monarchy and declared france a republic", "gold_answers": ["Convention", "France 's Legislative Assembly"], "shots": {"0": {"k": 0, "answer": "Louis-Napoleon Bonaparte", "latency_ms": 111.78874969482422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The French Revolution abolished the monarchy and declared France a republic.", "latency_ms": 174.67355728149414, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "The French Revolution did not abolish the monarchy and declare France a republic at its outset. The monarchy was abolished and France declared a republic after the Flight to Varennes, when Louis XVI was sent to the guillotine. However, the French Second Republic was created in 1848, and the French Third Republic was established in 1870 when a civil revolutionary committee refused to accept Napoleon III's surrender during the Franco-Prussian War. Thus, the revolutionary committee in 1870 abolished the monarchy and declared France a republic.\n\nAnswer: civil revolutionary committee", "latency_ms": 1484.8575592041016, "em": 0.0, "f1": 0.025316455696202535, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "The French Revolution", "latency_ms": 92.16785430908203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "The National Guard", "latency_ms": 94.48862075805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2574}, "5": {"k": 5, "answer": "National Constituent Assembly", "latency_ms": 118.89767646789551, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "National Constituent Assembly", "latency_ms": 125.40245056152344, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3935}}}
{"qid": "7054790124152837084", "question": "location of the ten commandments in the bible", "gold_answers": ["Deuteronomy", "Exodus"], "shots": {"0": {"k": 0, "answer": "Exodus 20", "latency_ms": 88.01603317260742, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Exodus 20", "latency_ms": 92.17476844787598, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Exodus 20", "latency_ms": 106.52303695678711, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Exodus 20 and Deuteronomy 5", "latency_ms": 191.3907527923584, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1894}, "4": {"k": 4, "answer": "Exodus and Deuteronomy", "latency_ms": 134.58991050720215, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2613}, "5": {"k": 5, "answer": "Exodus and Deuteronomy", "latency_ms": 144.55175399780273, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Exodus and Deuteronomy", "latency_ms": 150.8958339691162, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3854}}}
{"qid": "3052797144690241914", "question": "who is new prime minister of italy 2018", "gold_answers": ["TBD"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.9124755859375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Giuseppe Conte", "latency_ms": 64.20350074768066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 572}, "2": {"k": 2, "answer": "Giuseppe Conte", "latency_ms": 77.86822319030762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1173}, "3": {"k": 3, "answer": "Giuseppe Conte", "latency_ms": 89.10894393920898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "Giuseppe Conte", "latency_ms": 94.62094306945801, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2479}, "5": {"k": 5, "answer": "Giuseppe Conte", "latency_ms": 107.35273361206055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3108}, "6": {"k": 6, "answer": "Giuseppe Conte", "latency_ms": 114.72868919372559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3762}}}
{"qid": "7025373941205601404", "question": "who did the us share the oregon country with", "gold_answers": ["British", "French Canadian"], "shots": {"0": {"k": 0, "answer": "Britain", "latency_ms": 39.3986701965332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Britain", "latency_ms": 44.348955154418945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Britain", "latency_ms": 50.74119567871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Britain, France, Russia, and Spain", "latency_ms": 155.92312812805176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Britain", "latency_ms": 69.4282054901123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "United Kingdom", "latency_ms": 95.85714340209961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3159}, "6": {"k": 6, "answer": "United Kingdom", "latency_ms": 100.71659088134766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "-2651390481836592629", "question": "when did rob dyrdek's fantasy factory end", "gold_answers": ["March 5 , 2015"], "shots": {"0": {"k": 0, "answer": "2019", "latency_ms": 75.35147666931152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "May 19, 2014", "latency_ms": 159.8522663116455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "May 19, 2014", "latency_ms": 165.52162170410156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1322}, "3": {"k": 3, "answer": "May 19, 2014", "latency_ms": 176.41687393188477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1941}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 122.4820613861084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2551}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 126.7693042755127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3179}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 139.35303688049316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3847}}}
{"qid": "-9179790505411585724", "question": "roman god of the underworld also called orcus or pluto", "gold_answers": ["Dis Pater"], "shots": {"0": {"k": 0, "answer": "Pluto", "latency_ms": 47.212839126586914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hades", "latency_ms": 57.97600746154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 567}, "2": {"k": 2, "answer": "Hades", "latency_ms": 69.3352222442627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1132}, "3": {"k": 3, "answer": "Hades", "latency_ms": 76.48944854736328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1704}, "4": {"k": 4, "answer": "Hades", "latency_ms": 81.7711353302002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2325}, "5": {"k": 5, "answer": "Pluto", "latency_ms": 95.74604034423828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2970}, "6": {"k": 6, "answer": "Pluto", "latency_ms": 103.38616371154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3623}}}
{"qid": "5533390825531418240", "question": "who won the first celebrity big brother on channel 5", "gold_answers": ["Jack Dee"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 72.02577590942383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 86.21025085449219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 90.51799774169922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 104.90870475769043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 107.47241973876953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2569}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 123.62527847290039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3146}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 127.66456604003906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3822}}}
{"qid": "2039311614003499003", "question": "cast of a nightmare on elm street 1984", "gold_answers": ["Nick Corri", "Ronee Blakley", "Robert Englund", "Johnny Depp", "Heather Langenkamp", "Amanda Wyss", "John Saxon"], "shots": {"0": {"k": 0, "answer": "Johnny Depp, Heather Langenkamp, Robert Englund, David Gale, Jerry O'Connell, John Saxon, David Koechner, David M. Allen, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John Saxon, John", "latency_ms": 3146.7156410217285, "em": 0.0, "f1": 0.03076923076923077, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Heather Langenkamp, John Saxon, Ronee Blakley, Amanda Wyss, Jsu Garcia, Robert Englund, Johnny Depp", "latency_ms": 427.929162979126, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 596}, "2": {"k": 2, "answer": "Heather Langenkamp, John Saxon, Ronee Blakley, Amanda Wyss, Jsu Garcia, Robert Englund, Johnny Depp", "latency_ms": 434.19337272644043, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Robert Englund, John Saxon, Heather Langenkamp, Johnny Depp", "latency_ms": 249.44758415222168, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1822}, "4": {"k": 4, "answer": "Heather Langenkamp, John Saxon, Ronee Blakley, Amanda Wyss, Jsu Garcia, Robert Englund, Johnny Depp", "latency_ms": 451.1570930480957, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 2494}, "5": {"k": 5, "answer": "Heather Langenkamp, John Saxon, Ronee Blakley, Amanda Wyss, Jsu Garcia, Robert Englund, Johnny Depp", "latency_ms": 468.58811378479004, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Robert Englund, John Saxon, Heather Langenkamp, Amanda Wyss, Jsu Garcia, Johnny Depp", "latency_ms": 371.14834785461426, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 3790}}}
{"qid": "-6357653156553488447", "question": "african countries that begin with the letter a", "gold_answers": ["Algeria ‚Äé", "Algeria", "Angola", "Angola ‚Äé"], "shots": {"0": {"k": 0, "answer": "Algeria, Angola, and Angola", "latency_ms": 124.07827377319336, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Algeria, Angola, and Angola", "latency_ms": 127.06565856933594, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Algeria, Angola, and Angola", "latency_ms": 142.2410011291504, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1361}, "3": {"k": 3, "answer": "Algeria, Angola, and Angola (only one starts with A)  \nAlgeria", "latency_ms": 290.7743453979492, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Algeria, Angola, Angola, Zambia, Zimbabwe, Sudan, South Africa, Namibia, Nigeria, Ghana, Ethiopia, Eritrea, Mali, Malawi, Uganda, Tanzania, Zambia, Rwanda, Kenya, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia, Zambia", "latency_ms": 3192.180395126343, "em": 0.0, "f1": 0.015748031496062992, "containment": 1.0, "context_chars": 2653}, "5": {"k": 5, "answer": "Algeria, Angola, Benin, Burkina Faso, Cameroon, Chad, C√¥te d‚ÄôIvoire, Djibouti, Egypt, Equatorial Guinea, Ethiopia, Gabon, Gambia, Ghana, Kenya, Lesotho, Liberia, Malawi, Mali, Mauritania, Mauritius, Mozambique, Niger, Namibia, Nigeria, Republic of Congo, Rwanda, Sao Tome & Principe, Senegal, Sierra Leone, South Africa, Sudan, Tanzania, Togo, Tunisia, Uganda, Zambia", "latency_ms": 1431.7381381988525, "em": 0.0, "f1": 0.042553191489361694, "containment": 1.0, "context_chars": 3371}, "6": {"k": 6, "answer": "Algeria, Angola, Benin, Burkina Faso, Cameroon, Chad, C√¥te d‚ÄôIvoire, Djibouti, Egypt, Equatorial Guinea, Ethiopia, Gabon, Gambia, Ghana, Kenya, Lesotho, Liberia, Malawi, Mali, Mauritania, Mauritius, Mozambique, Niger, Namibia, Nigeria, Republic of Congo, Rwanda, Sao Tome & Principe, Senegal, Sierra Leone, South Africa, Sudan, Tanzania, Togo, Tunisia, Uganda, Zambia", "latency_ms": 1430.6445121765137, "em": 0.0, "f1": 0.042553191489361694, "containment": 1.0, "context_chars": 4030}}}
{"qid": "-234095069418298051", "question": "who is regarded as the founder of psychoanalysis", "gold_answers": ["Austrian neurologist Sigmund Freud", "Sigmund Freud"], "shots": {"0": {"k": 0, "answer": "Sigmund Freud", "latency_ms": 72.9670524597168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sigmund Freud", "latency_ms": 86.61055564880371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 699}, "2": {"k": 2, "answer": "Sigmund Freud", "latency_ms": 95.46208381652832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1384}, "3": {"k": 3, "answer": "Sigmund Freud", "latency_ms": 103.04141044616699, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2047}, "4": {"k": 4, "answer": "Sigmund Freud", "latency_ms": 105.91793060302734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2765}, "5": {"k": 5, "answer": "Sigmund Freud", "latency_ms": 123.72779846191406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3468}, "6": {"k": 6, "answer": "Sigmund Freud", "latency_ms": 127.20894813537598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4103}}}
{"qid": "6655886167018306286", "question": "who was the chief guest of 2014 republic day", "gold_answers": ["Prime Minister Shinzo Abe"], "shots": {"0": {"k": 0, "answer": "U.S. President Barack Obama", "latency_ms": 96.32015228271484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 87.35013008117676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 90.93403816223145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Shinzo Abe", "latency_ms": 106.7972183227539, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Shinzo Abe", "latency_ms": 105.8816909790039, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "Shinzo Abe", "latency_ms": 122.15924263000488, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3194}, "6": {"k": 6, "answer": "Shinzo Abe", "latency_ms": 127.76041030883789, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3823}}}
{"qid": "-6740873139243659712", "question": "name of volcano that erupted in iceland in 2010", "gold_answers": ["Eyjafjallaj√∂kull"], "shots": {"0": {"k": 0, "answer": "Eyjafjallaj√∂kull", "latency_ms": 124.46808815002441, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eyjafjallaj√∂kull", "latency_ms": 132.68351554870605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 725}, "2": {"k": 2, "answer": "Eyjafjallaj√∂kull", "latency_ms": 143.15080642700195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1364}, "3": {"k": 3, "answer": "Eyjafjallaj√∂kull", "latency_ms": 150.78449249267578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Eyjafjallaj√∂kull", "latency_ms": 169.83366012573242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2735}, "5": {"k": 5, "answer": "Eyjafjallaj√∂kull", "latency_ms": 176.58424377441406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3396}, "6": {"k": 6, "answer": "Eyjafjallaj√∂kull", "latency_ms": 187.3924732208252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4053}}}
{"qid": "-33411903170288457", "question": "where is the second largest mall in america", "gold_answers": ["Florida", "Aventura , Florida"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.6981372833252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 77.26359367370605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 87.96191215515137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1240}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 104.22730445861816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1896}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 106.64725303649902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 123.64888191223145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3246}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 128.4186840057373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3872}}}
{"qid": "922896385310656150", "question": "legends of tomorrow season 3 finale air date", "gold_answers": ["April 9 , 2018"], "shots": {"0": {"k": 0, "answer": "2020-05-19", "latency_ms": 144.74225044250488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "April 9, 2018", "latency_ms": 145.40886878967285, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "April 9, 2018", "latency_ms": 150.29454231262207, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "April 9, 2018", "latency_ms": 164.98136520385742, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1996}, "4": {"k": 4, "answer": "April 9, 2018", "latency_ms": 168.19262504577637, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2674}, "5": {"k": 5, "answer": "April 9, 2018", "latency_ms": 187.76583671569824, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3281}, "6": {"k": 6, "answer": "April 9, 2018", "latency_ms": 199.67174530029297, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3983}}}
{"qid": "-7210254135900506188", "question": "where is the meridian that is opposite the prime meridian located", "gold_answers": ["antimeridian", "the 180th meridian"], "shots": {"0": {"k": 0, "answer": "180 degrees", "latency_ms": 78.86838912963867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "180¬∞W and 180¬∞E", "latency_ms": 181.9932460784912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 706}, "2": {"k": 2, "answer": "180¬∞ longitude near the International Date Line", "latency_ms": 162.81604766845703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1354}, "3": {"k": 3, "answer": "180¬∞ longitude near the International Date Line", "latency_ms": 176.9115924835205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1991}, "4": {"k": 4, "answer": "180¬∞ longitude near the International Date Line", "latency_ms": 182.77215957641602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "180¬∞ longitude near the International Date Line", "latency_ms": 194.47946548461914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3254}, "6": {"k": 6, "answer": "180¬∞ longitude near the International Date Line", "latency_ms": 211.38572692871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3898}}}
{"qid": "-2985892305125459809", "question": "where is the orinoco river located on a map", "gold_answers": ["in South America"], "shots": {"0": {"k": 0, "answer": "South America", "latency_ms": 51.345109939575195, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "South America", "latency_ms": 52.396535873413086, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "South America", "latency_ms": 62.90864944458008, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1168}, "3": {"k": 3, "answer": "South America", "latency_ms": 80.91139793395996, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1811}, "4": {"k": 4, "answer": "South America, primarily in Venezuela and Colombia", "latency_ms": 160.1710319519043, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 2444}, "5": {"k": 5, "answer": "South America, primarily in Venezuela and Colombia", "latency_ms": 172.71876335144043, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "South America, primarily in Venezuela and Colombia", "latency_ms": 176.1949062347412, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 3680}}}
{"qid": "-3461224156694569605", "question": "what does it mean when your baby comes out feet first", "gold_answers": ["A footling breech"], "shots": {"0": {"k": 0, "answer": "It means the baby is in a breech position.", "latency_ms": 159.6975326538086, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "breech", "latency_ms": 64.45169448852539, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "breech", "latency_ms": 71.01678848266602, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "breech birth", "latency_ms": 93.8105583190918, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1814}, "4": {"k": 4, "answer": "breech birth", "latency_ms": 106.01997375488281, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2375}, "5": {"k": 5, "answer": "breech birth", "latency_ms": 123.34895133972168, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3002}, "6": {"k": 6, "answer": "breech birth", "latency_ms": 125.67448616027832, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3624}}}
{"qid": "-5473444875466431416", "question": "what does zonia receive from reuben in the play", "gold_answers": ["kiss"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 72.7999210357666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 76.71952247619629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 543}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 89.99896049499512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1121}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 102.64992713928223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1755}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 111.08279228210449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2337}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 123.98123741149902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2941}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 127.3653507232666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3513}}}
{"qid": "-3846471400629212038", "question": "dynamin is associated with which type of vesicle", "gold_answers": ["newly formed vesicles"], "shots": {"0": {"k": 0, "answer": "clathrin-coated vesicle", "latency_ms": 108.45136642456055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "endocytosis", "latency_ms": 85.79683303833008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 703}, "2": {"k": 2, "answer": "neuronal vesicles", "latency_ms": 103.44791412353516, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1392}, "3": {"k": 3, "answer": "clathrin-mediated endocytosis vesicle", "latency_ms": 174.43251609802246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2089}, "4": {"k": 4, "answer": "clathrin-coated vesicle", "latency_ms": 146.1508274078369, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2749}, "5": {"k": 5, "answer": "clathrin-mediated vesicle", "latency_ms": 146.6820240020752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3440}, "6": {"k": 6, "answer": "clathrin-mediated endocytosis", "latency_ms": 176.92112922668457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4124}}}
{"qid": "4072647923415167061", "question": "what is the multiplication sign on the computer", "gold_answers": ["the symbol √ó", "a rotationally symmetric saltire", "*"], "shots": {"0": {"k": 0, "answer": "asterisk (* )", "latency_ms": 75.72412490844727, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "*", "latency_ms": 44.40665245056152, "em": 1.0, "f1": 0.0, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "asterisk (* )", "latency_ms": 83.70208740234375, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1310}, "3": {"k": 3, "answer": "asterisk (*))", "latency_ms": 104.8130989074707, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "asterisk (*).", "latency_ms": 106.29487037658691, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2583}, "5": {"k": 5, "answer": "asterisk (*).", "latency_ms": 119.33231353759766, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3186}, "6": {"k": 6, "answer": "asterisk (*))", "latency_ms": 124.88532066345215, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3818}}}
{"qid": "343968022755473370", "question": "kings and queens of england in the 1900s", "gold_answers": ["Edward VIII", "George V", "George VI", "Edward VII", "Elizabeth II"], "shots": {"0": {"k": 0, "answer": "Edward VII, George V", "latency_ms": 88.30618858337402, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Victoria, Edward VII", "latency_ms": 86.50326728820801, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 661}, "2": {"k": 2, "answer": "Victoria, Edward VII, George V", "latency_ms": 126.4345645904541, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1340}, "3": {"k": 3, "answer": "Victoria, Edward VII, George V", "latency_ms": 141.0832405090332, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2000}, "4": {"k": 4, "answer": "Edward VII, George V", "latency_ms": 134.05418395996094, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Edward VII, George V", "latency_ms": 136.05856895446777, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3289}, "6": {"k": 6, "answer": "Edward VII, George V", "latency_ms": 150.7585048675537, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3892}}}
{"qid": "3572898465421645948", "question": "when did they stop making the nissan xterra", "gold_answers": ["after the 2015 model year", "2015"], "shots": {"0": {"k": 0, "answer": "2019", "latency_ms": 75.8814811706543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 85.8612060546875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 661}, "2": {"k": 2, "answer": "2015", "latency_ms": 94.20490264892578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "2015", "latency_ms": 104.98166084289551, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2032}, "4": {"k": 4, "answer": "2015", "latency_ms": 122.15948104858398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2685}, "5": {"k": 5, "answer": "2015", "latency_ms": 124.8626708984375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3290}, "6": {"k": 6, "answer": "2015", "latency_ms": 138.41772079467773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3919}}}
{"qid": "6997422338613101186", "question": "who played the nurse on andy griffith show", "gold_answers": ["Julie Adams", "Langdon"], "shots": {"0": {"k": 0, "answer": "Agnes Moorehead", "latency_ms": 75.67739486694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alberta Nelson", "latency_ms": 71.12956047058105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 89.18190002441406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Julie Adams and Sue Ane Langdon", "latency_ms": 163.73753547668457, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1961}, "4": {"k": 4, "answer": "Julie Adams and Sue Ane Langdon", "latency_ms": 180.82380294799805, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Aneta Corsaut", "latency_ms": 125.09846687316895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3271}, "6": {"k": 6, "answer": "Aneta Corsaut", "latency_ms": 137.43853569030762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3923}}}
{"qid": "-6542642245388793003", "question": "where was the tv show in the heat of the night filmed", "gold_answers": ["Atlanta", "Hammond , Louisiana", "Covington , Georgia", "Decatur in Dekalb County"], "shots": {"0": {"k": 0, "answer": "Tennessee and Louisiana", "latency_ms": 70.88160514831543, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hammond, Louisiana", "latency_ms": 81.06756210327148, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 730}, "2": {"k": 2, "answer": "Hammond, Louisiana (season 1); downtown Covington, Georgia (subsequent seasons)", "latency_ms": 273.63109588623047, "em": 0.0, "f1": 0.3636363636363636, "containment": 0.0, "context_chars": 1343}, "3": {"k": 3, "answer": "Hammond, Louisiana; Covington, Georgia; surrounding Georgia counties", "latency_ms": 212.7528190612793, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 2007}, "4": {"k": 4, "answer": "Hammond, Louisiana; downtown Covington, Georgia; Newton, Rockdale, Walton, Morgan, and Jasper counties, Georgia; Decatur, Georgia; Atlanta, Georgia", "latency_ms": 479.22635078430176, "em": 0.0, "f1": 0.21052631578947367, "containment": 1.0, "context_chars": 2709}, "5": {"k": 5, "answer": "Hammond, Louisiana (season 1); downtown Covington, Georgia (subsequent seasons)", "latency_ms": 307.9829216003418, "em": 0.0, "f1": 0.3636363636363636, "containment": 0.0, "context_chars": 3314}, "6": {"k": 6, "answer": "Hammond, Louisiana (season 1); downtown Covington, Georgia (subsequent seasons)", "latency_ms": 313.2650852203369, "em": 0.0, "f1": 0.3636363636363636, "containment": 0.0, "context_chars": 3963}}}
{"qid": "3282428170958535508", "question": "who sang the end of the world as we know it", "gold_answers": ["R.E.M."], "shots": {"0": {"k": 0, "answer": "The Killers", "latency_ms": 59.676408767700195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "R.E.M.", "latency_ms": 83.67657661437988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "R.E.M.", "latency_ms": 89.21289443969727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "R.E.M.", "latency_ms": 105.26800155639648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1838}, "4": {"k": 4, "answer": "R.E.M.", "latency_ms": 120.79453468322754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2502}, "5": {"k": 5, "answer": "R.E.M.", "latency_ms": 126.65319442749023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3089}, "6": {"k": 6, "answer": "R.E.M.", "latency_ms": 137.12453842163086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3680}}}
{"qid": "-4978380012076786896", "question": "who became the it company ceo in 2016", "gold_answers": ["Abid Ali Neemuchwala"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 72.49617576599121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 85.66641807556152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "Joe Bergera", "latency_ms": 77.19993591308594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 104.56085205078125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1985}, "4": {"k": 4, "answer": "L√©o Apotheker", "latency_ms": 123.0161190032959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2626}, "5": {"k": 5, "answer": "L√©o Apotheker", "latency_ms": 136.26766204833984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3277}, "6": {"k": 6, "answer": "IBM eliminated forced rankings in 2016, but no CEO change is mentioned.  \nNo specific CEO appointment in 2016 is stated in the provided context for any company.  \nI cannot answer.", "latency_ms": 631.2639713287354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3936}}}
{"qid": "924019955308411209", "question": "who headed the 7th central pay commission of india", "gold_answers": ["Justice A.K Mathur"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.73342323303223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ashok Kumar Mathur", "latency_ms": 95.37720680236816, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "Ashok Kumar Mathur", "latency_ms": 106.25290870666504, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "A.K. Mathur", "latency_ms": 118.52025985717773, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1971}, "4": {"k": 4, "answer": "A.K. Mathur", "latency_ms": 119.05694007873535, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2700}, "5": {"k": 5, "answer": "A.K. Mathur", "latency_ms": 138.047456741333, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3393}, "6": {"k": 6, "answer": "A.K. Mathur", "latency_ms": 152.10890769958496, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4107}}}
{"qid": "3197263819650216852", "question": "when did john steinbeck write of mice and me", "gold_answers": ["1937"], "shots": {"0": {"k": 0, "answer": "1939", "latency_ms": 72.26729393005371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1937", "latency_ms": 80.07311820983887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 596}, "2": {"k": 2, "answer": "1937", "latency_ms": 92.91243553161621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1190}, "3": {"k": 3, "answer": "1937", "latency_ms": 102.69308090209961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1834}, "4": {"k": 4, "answer": "1937", "latency_ms": 109.9233627319336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "1937", "latency_ms": 123.97265434265137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3108}, "6": {"k": 6, "answer": "1937", "latency_ms": 137.72320747375488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3700}}}
{"qid": "-708585645485251245", "question": "what types of cells go through binary fission", "gold_answers": ["domains of Archaea and Bacteria", "prokaryotic"], "shots": {"0": {"k": 0, "answer": "bacteria", "latency_ms": 51.671743392944336, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "prokaryotic cells", "latency_ms": 92.42129325866699, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "prokaryotic cells and some eukaryotic organelles (e.g., mitochondria)", "latency_ms": 303.1017780303955, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1378}, "3": {"k": 3, "answer": "prokaryotic cells and some organelles (e.g., mitochondria)", "latency_ms": 262.3460292816162, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 2043}, "4": {"k": 4, "answer": "prokaryotic cells and some eukaryotic organelles (e.g., mitochondria)", "latency_ms": 314.7299289703369, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2668}, "5": {"k": 5, "answer": "prokaryotic cells and some eukaryotic organelles (e.g., mitochondria)", "latency_ms": 330.2338123321533, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3329}, "6": {"k": 6, "answer": "prokaryotic cells and some eukaryotic organelles (e.g., mitochondria)", "latency_ms": 336.09652519226074, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4016}}}
{"qid": "-7711650252404011102", "question": "real name of daya in taarak mehta ka ooltah chashmah", "gold_answers": ["Disha Vakani"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.72650909423828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Disha Vakani", "latency_ms": 99.7626781463623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 607}, "2": {"k": 2, "answer": "Daya Jethalal Gada", "latency_ms": 139.58024978637695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1296}, "3": {"k": 3, "answer": "Daya Jethalal Gada", "latency_ms": 157.37104415893555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Daya Jethalal Gada", "latency_ms": 170.87602615356445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2562}, "5": {"k": 5, "answer": "Daya Jethalal Gada", "latency_ms": 172.71184921264648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3160}, "6": {"k": 6, "answer": "Daya Jethalal Gada", "latency_ms": 190.57416915893555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "7749931351008827886", "question": "when did vat change from 17.5 to 20", "gold_answers": ["4 January 2011"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.44541358947754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 87.78810501098633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 94.23327445983887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 106.34827613830566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 123.39925765991211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "4 January 2011", "latency_ms": 161.42702102661133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3141}, "6": {"k": 6, "answer": "4 January 2011", "latency_ms": 177.99758911132812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3773}}}
{"qid": "5647740185675767611", "question": "what is the location at the end of minority report", "gold_answers": ["an undisclosed location"], "shots": {"0": {"k": 0, "answer": "end of the film shows the protagonist, John Anderton, in a future where he has been arrested for a crime he did not commit, and the story ends with him being released after the events of the film. The final scene takes place in a futuristic city, where the protagonist is seen walking through a cityscape with a sense of hope and resolution. The exact location is not specified, but it is implied to be a modern, advanced urban environment. The final scene is set in a city that reflects the technological advancements and societal changes depicted throughout the film. The specific name or address of the location is not provided in the context. Therefore, the answer is: a futuristic urban environment.", "latency_ms": 1703.2849788665771, "em": 0.0, "f1": 0.019801980198019806, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Crow's hotel room", "latency_ms": 79.89263534545898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "Washington, D.C., Baltimore, and Northern Virginia", "latency_ms": 160.34412384033203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Butter Island off North Haven, Maine in the Penobscot Bay", "latency_ms": 242.07806587219238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Butter Island off North Haven, Maine in the Penobscot Bay", "latency_ms": 242.7957057952881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2482}, "5": {"k": 5, "answer": "Butter Island off North Haven, Maine in the Penobscot Bay", "latency_ms": 258.82720947265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "Butter Island off North Haven, Maine in the Penobscot Bay", "latency_ms": 260.35475730895996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3781}}}
{"qid": "3930701751459648736", "question": "where does florida natural orange juice come from", "gold_answers": ["Lake Wales , Florida"], "shots": {"0": {"k": 0, "answer": "Florida", "latency_ms": 38.996219635009766, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "US-grown fruit in Florida", "latency_ms": 110.82839965820312, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 705}, "2": {"k": 2, "answer": "US-grown fruit (grown by its cooperative members primarily in Polk County, Florida)", "latency_ms": 264.4073963165283, "em": 0.0, "f1": 0.13333333333333333, "containment": 0.0, "context_chars": 1390}, "3": {"k": 3, "answer": "US-grown fruit (grown by its cooperative members primarily in Polk County, Florida)", "latency_ms": 276.54123306274414, "em": 0.0, "f1": 0.13333333333333333, "containment": 0.0, "context_chars": 2035}, "4": {"k": 4, "answer": "US-grown fruit (grown by its cooperative members in Florida)", "latency_ms": 216.46904945373535, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 2640}, "5": {"k": 5, "answer": "US-grown fruit (grown by its cooperative members in Florida)", "latency_ms": 233.81495475769043, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 3275}, "6": {"k": 6, "answer": "US-grown fruit (grown by its cooperative members in Florida)", "latency_ms": 237.3363971710205, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 3995}}}
