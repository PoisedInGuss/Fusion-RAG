{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 141.98851585388184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 21, 2018", "latency_ms": 249.48692321777344, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "June 22, 2018", "latency_ms": 318.90320777893066, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "June 22, 2018", "latency_ms": 404.280424118042, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1885}, "4": {"k": 4, "answer": "June 22, 2018", "latency_ms": 218.10603141784668, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2509}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 400.07972717285156, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3136}, "6": {"k": 6, "answer": "June 22, 2018", "latency_ms": 277.0204544067383, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3742}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Biathlon, Freestyle, Snowboard", "latency_ms": 315.8133029937744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alpine skiing", "latency_ms": 105.53979873657227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 205.89542388916016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 147.45450019836426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 255.71656227111816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 179.304838180542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 243.95489692687988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3931}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.30538940429688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gino Poletti", "latency_ms": 98.5708236694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Gino Poletti", "latency_ms": 178.53546142578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Gino Poletti", "latency_ms": 153.65314483642578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Gino Poletti", "latency_ms": 196.3040828704834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2564}, "5": {"k": 5, "answer": "Gino Poletti", "latency_ms": 211.03549003601074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3178}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 252.42042541503906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3751}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.91480827331543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Giants", "latency_ms": 76.81083679199219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "New York Giants", "latency_ms": 83.74881744384766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1170}, "3": {"k": 3, "answer": "San Diego Chargers", "latency_ms": 93.20425987243652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1768}, "4": {"k": 4, "answer": "Miami Dolphins", "latency_ms": 98.62470626831055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2417}, "5": {"k": 5, "answer": "Miami Dolphins, New York Giants, San Diego Chargers", "latency_ms": 276.7908573150635, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3039}, "6": {"k": 6, "answer": "New York Giants, Miami Dolphins, Dallas Cowboys", "latency_ms": 364.3486499786377, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3633}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "1985", "latency_ms": 72.22914695739746, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 December 1985", "latency_ms": 219.07329559326172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 727}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 174.0431785583496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1447}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 178.83801460266113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2144}, "4": {"k": 4, "answer": "8 December 1985", "latency_ms": 267.06814765930176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2840}, "5": {"k": 5, "answer": "8 December 1985", "latency_ms": 300.9755611419678, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3541}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 270.8423137664795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4247}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 154.51574325561523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spanish moss", "latency_ms": 57.16109275817871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "Spanish moss", "latency_ms": 92.1940803527832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Spanish moss", "latency_ms": 156.21304512023926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1939}, "4": {"k": 4, "answer": "Spanish moss", "latency_ms": 113.47150802612305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2678}, "5": {"k": 5, "answer": "Spanish moss", "latency_ms": 115.88406562805176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3330}, "6": {"k": 6, "answer": "Spanish moss", "latency_ms": 133.31198692321777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4041}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "NYHA functional class", "latency_ms": 72.22914695739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 135.01262664794922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 762}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 224.7602939605713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1518}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 111.49096488952637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2250}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 152.32443809509277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2959}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 193.0525302886963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 131.06632232666016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4447}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Dolly Parton", "latency_ms": 76.63273811340332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 88.39535713195801, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "Mike Leeson and Peter Vale", "latency_ms": 119.37737464904785, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1162}, "3": {"k": 3, "answer": "Mike Leeson and Peter Vale", "latency_ms": 300.9448051452637, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1798}, "4": {"k": 4, "answer": "Mike Leeson and Peter Vale", "latency_ms": 295.8793640136719, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2415}, "5": {"k": 5, "answer": "Mike Leeson and Peter Vale", "latency_ms": 254.0903091430664, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3017}, "6": {"k": 6, "answer": "Mike Leeson and Peter Vale (Charles & Eddie)  \nor  \nEurythmics (for the 1985 version)", "latency_ms": 499.5138645172119, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 3661}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 39.52169418334961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 46.53143882751465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "3", "latency_ms": 173.0506420135498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "3", "latency_ms": 70.04499435424805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "3", "latency_ms": 75.93035697937012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2490}, "5": {"k": 5, "answer": "3", "latency_ms": 90.37399291992188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "3", "latency_ms": 120.5594539642334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3738}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "biscuit", "latency_ms": 72.20244407653809, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biscuit-sized cake", "latency_ms": 129.60553169250488, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "biscuit-sized cake", "latency_ms": 150.88534355163574, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "a cake", "latency_ms": 84.01942253112793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1765}, "4": {"k": 4, "answer": "a cake", "latency_ms": 117.18225479125977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "a cake", "latency_ms": 219.53511238098145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3040}, "6": {"k": 6, "answer": "cake", "latency_ms": 88.56916427612305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Dan Castellaneta", "latency_ms": 94.70343589782715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seth MacFarlane", "latency_ms": 164.6900177001953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Seth MacFarlane", "latency_ms": 218.9769744873047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Seth MacFarlane", "latency_ms": 230.61347007751465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1913}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 172.04594612121582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2554}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 159.1966152191162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 135.64276695251465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3844}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 199.27024841308594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "amphetamines", "latency_ms": 166.29552841186523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "amphetamines", "latency_ms": 201.32923126220703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1186}, "3": {"k": 3, "answer": "amphetamines", "latency_ms": 106.20570182800293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "amphetamines", "latency_ms": 170.11427879333496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2447}, "5": {"k": 5, "answer": "amphetamines", "latency_ms": 168.5011386871338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3127}, "6": {"k": 6, "answer": "amphetamines", "latency_ms": 138.71455192565918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3735}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "19 minutes 30 seconds", "latency_ms": 158.80417823791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 113.32535743713379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 571}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 137.99738883972168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 109.48634147644043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "one week", "latency_ms": 85.71958541870117, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2354}, "5": {"k": 5, "answer": "one week", "latency_ms": 172.163724899292, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2936}, "6": {"k": 6, "answer": "one week", "latency_ms": 188.33661079406738, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3555}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 88.42992782592773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 181.83541297912598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 159.70516204833984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 194.67592239379883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 166.75353050231934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2501}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 268.2955265045166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3130}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 163.3470058441162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3745}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 174.2088794708252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 132.0784091949463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 118.28184127807617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 132.1389675140381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1831}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 174.96919631958008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2482}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 137.86864280700684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3156}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 140.21706581115723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3816}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 167.7420139312744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 118.99161338806152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "1973", "latency_ms": 130.5844783782959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "1973", "latency_ms": 102.08487510681152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1946}, "4": {"k": 4, "answer": "1983", "latency_ms": 114.20321464538574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2597}, "5": {"k": 5, "answer": "1983", "latency_ms": 167.20986366271973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3252}, "6": {"k": 6, "answer": "1983", "latency_ms": 206.50076866149902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3909}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "Lori Michaels", "latency_ms": 118.7276840209961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alexz Johnson", "latency_ms": 70.33920288085938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Alexz Johnson, Dave Ogilvie, Anthony Valcic, Damhnait Doyle, in-show band", "latency_ms": 340.8501148223877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Alexz Johnson", "latency_ms": 191.0421848297119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Jim McGrath", "latency_ms": 100.94022750854492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Jim McGrath", "latency_ms": 145.6618309020996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Jim McGrath", "latency_ms": 117.33627319335938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3930}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.09891891479492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 million years ago", "latency_ms": 120.96428871154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 162.43720054626465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 137.1002197265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 128.0670166015625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2557}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 232.03802108764648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3122}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 211.43674850463867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 146.49629592895508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 77.49295234680176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "master sergeant", "latency_ms": 131.71672821044922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1336}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 190.62328338623047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 182.6627254486084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2484}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 124.75323677062988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3052}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 158.4618091583252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3619}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 79.73098754882812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "GNU project", "latency_ms": 62.24966049194336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 135.0255012512207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 177.47998237609863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1961}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 151.28421783447266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2639}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 175.21119117736816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3308}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 144.66333389282227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3991}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 102.70571708679199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 124.07565116882324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "Heena Sidhu", "latency_ms": 95.11947631835938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1167}, "3": {"k": 3, "answer": "Heena Sidhu", "latency_ms": 139.20092582702637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1780}, "4": {"k": 4, "answer": "Heena Sidhu", "latency_ms": 121.39081954956055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2417}, "5": {"k": 5, "answer": "Heena Sidhu", "latency_ms": 154.54721450805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3048}, "6": {"k": 6, "answer": "Heena Sidhu", "latency_ms": 144.09661293029785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Chris Bell", "latency_ms": 53.14898490905762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 61.51556968688965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 93.7643051147461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1369}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 83.94098281860352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2007}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 87.18562126159668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2630}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 101.78923606872559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3316}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 105.40318489074707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3947}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.59485054016113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miami Heat", "latency_ms": 117.11263656616211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 71.03323936462402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 78.11856269836426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1850}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 131.9746971130371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2436}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 102.4625301361084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3047}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 114.7618293762207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3614}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "Guarani", "latency_ms": 58.4716796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Paraguayan guaraní (₲)", "latency_ms": 216.76373481750488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "PYG", "latency_ms": 80.76667785644531, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "PYG", "latency_ms": 144.40608024597168, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "PYG", "latency_ms": 119.99845504760742, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 2431}, "5": {"k": 5, "answer": "PYG", "latency_ms": 177.51049995422363, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3069}, "6": {"k": 6, "answer": "PYG", "latency_ms": 135.51759719848633, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3749}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "ketamine", "latency_ms": 45.94016075134277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "benzodiazepines", "latency_ms": 235.1057529449463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 678}, "2": {"k": 2, "answer": "benzodiazepines", "latency_ms": 195.26982307434082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1395}, "3": {"k": 3, "answer": "midazolam", "latency_ms": 124.20105934143066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2079}, "4": {"k": 4, "answer": "midazolam", "latency_ms": 159.72423553466797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2805}, "5": {"k": 5, "answer": "midazolam", "latency_ms": 190.99974632263184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3444}, "6": {"k": 6, "answer": "midazolam", "latency_ms": 125.2901554107666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4124}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 113.56949806213379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "26,000 years", "latency_ms": 177.06966400146484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "26,000 years", "latency_ms": 225.22258758544922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "26,000 years", "latency_ms": 138.89575004577637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1930}, "4": {"k": 4, "answer": "25,772 years", "latency_ms": 198.6377239227295, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "25,772 years", "latency_ms": 274.8904228210449, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "25,772 years", "latency_ms": 162.38641738891602, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3819}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 89.36405181884766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Texas A&M Aggies", "latency_ms": 109.03239250183105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Texas A&M Aggies", "latency_ms": 221.99153900146484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Texas A&M Aggies", "latency_ms": 114.35365676879883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1904}, "4": {"k": 4, "answer": "Texas A&M Aggies", "latency_ms": 154.78181838989258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2525}, "5": {"k": 5, "answer": "Texas A&M Aggies", "latency_ms": 168.9169406890869, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3190}, "6": {"k": 6, "answer": "Texas A&M University", "latency_ms": 130.1412582397461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3810}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and non-renewable", "latency_ms": 124.48763847351074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable and non-renewable", "latency_ms": 129.53567504882812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable or non-renewable", "latency_ms": 136.71374320983887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1447}, "3": {"k": 3, "answer": "renewable and non-renewable", "latency_ms": 143.50128173828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2178}, "4": {"k": 4, "answer": "renewable and non-renewable", "latency_ms": 158.05959701538086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2938}, "5": {"k": 5, "answer": "renewable and non-renewable", "latency_ms": 172.6837158203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3700}, "6": {"k": 6, "answer": "renewable and non-renewable", "latency_ms": 229.46786880493164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4438}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "good luck and prosperity", "latency_ms": 76.27081871032715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "parental devotion", "latency_ms": 86.32349967956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "purity and maternal devotion", "latency_ms": 232.64408111572266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "purity and maternal devotion", "latency_ms": 274.81818199157715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "child-bearer, purity, parental devotion", "latency_ms": 223.74653816223145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2536}, "5": {"k": 5, "answer": "purity, parental devotion, filial piety, child-bringing", "latency_ms": 364.23468589782715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3145}, "6": {"k": 6, "answer": "purity, parental devotion, filial piety, good luck, and child-birth", "latency_ms": 404.9222469329834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3735}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Rohit Sharma", "latency_ms": 114.40205574035645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 74.99337196350098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 97.92876243591309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1203}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 178.2090663909912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 112.74957656860352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2465}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 156.8906307220459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3070}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 191.21527671813965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3714}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 108.51597785949707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals in low concentrations", "latency_ms": 147.40371704101562, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 334.1047763824463, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 1412}, "3": {"k": 3, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 313.16494941711426, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 2074}, "4": {"k": 4, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 636.2078189849854, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 2812}, "5": {"k": 5, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 330.14822006225586, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 3478}, "6": {"k": 6, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 406.47101402282715, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 4169}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 181.26368522644043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 82.93628692626953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "James Coburn", "latency_ms": 80.7037353515625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 105.21101951599121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "James French", "latency_ms": 168.11251640319824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2545}, "5": {"k": 5, "answer": "James French (murderer)", "latency_ms": 286.1976623535156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3173}, "6": {"k": 6, "answer": "James Coburn", "latency_ms": 188.6119842529297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3813}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the opening lead and before the first round of play.", "latency_ms": 169.3723201751709, "em": 0.0, "f1": 0.15384615384615383, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the conclusion of play", "latency_ms": 111.49048805236816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 550}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 182.83748626708984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1132}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 162.51206398010254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1737}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 210.39128303527832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2309}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 145.14565467834473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2915}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 175.09150505065918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3498}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Sri Lanka", "latency_ms": 66.79344177246094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 69.92053985595703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 699}, "2": {"k": 2, "answer": "Sri Lanka", "latency_ms": 154.8914909362793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1395}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 188.21024894714355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2124}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 127.41422653198242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2830}, "5": {"k": 5, "answer": "Afghanistan", "latency_ms": 137.95042037963867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3556}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 123.63409996032715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4290}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.80124855041504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 87.03422546386719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 274.6870517730713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 121.21081352233887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2031}, "4": {"k": 4, "answer": "primary hemostasis, secondary hemostasis, blood clotting (hemostasis)", "latency_ms": 321.5501308441162, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2752}, "5": {"k": 5, "answer": "primary hemostasis, secondary hemostasis, blood clotting (hemostasis)", "latency_ms": 314.9688243865967, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 3449}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 142.0271396636963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4107}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.90095901489258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 85.81757545471191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 118.28351020812988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1354}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 101.71318054199219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2038}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 169.70586776733398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2732}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 126.38568878173828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3440}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 195.61386108398438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4086}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "1989", "latency_ms": 79.93340492248535, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "20 November 1989", "latency_ms": 138.8394832611084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 183.00962448120117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1331}, "3": {"k": 3, "answer": "1989", "latency_ms": 151.91054344177246, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 273.78201484680176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2544}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 196.946382522583, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3211}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 257.554292678833, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3856}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "2016", "latency_ms": 92.45848655700684, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 2016", "latency_ms": 143.83244514465332, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "2016", "latency_ms": 111.59539222717285, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "June 2016", "latency_ms": 136.22093200683594, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "June 2016", "latency_ms": 145.99013328552246, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "2016", "latency_ms": 125.31161308288574, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "23 June 2016", "latency_ms": 187.27612495422363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3761}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 142.06910133361816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Burj Khalifa", "latency_ms": 113.41500282287598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 679}, "2": {"k": 2, "answer": "Burj Khalifa", "latency_ms": 98.07920455932617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1360}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 110.11838912963867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2047}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 107.14244842529297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2688}, "5": {"k": 5, "answer": "Burj Khalifa", "latency_ms": 136.00873947143555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3330}, "6": {"k": 6, "answer": "Burj Khalifa", "latency_ms": 142.2255039215088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 71.9900131225586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 93.0323600769043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 98.82426261901855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 142.90452003479004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1979}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 126.27267837524414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2606}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 172.38688468933105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 211.72237396240234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Montesquieu", "latency_ms": 73.74191284179688, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montesquieu", "latency_ms": 189.45956230163574, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 108.05416107177734, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 125.89240074157715, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 113.95621299743652, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2679}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 120.10073661804199, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3311}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 188.18378448486328, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3938}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Kyler Murray", "latency_ms": 163.28716278076172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Myles Garrett", "latency_ms": 76.10225677490234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Myles Garrett", "latency_ms": 84.1984748840332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Myles Garrett", "latency_ms": 149.35708045959473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Myles Garrett", "latency_ms": 97.6560115814209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2509}, "5": {"k": 5, "answer": "Myles Garrett", "latency_ms": 112.96510696411133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3092}, "6": {"k": 6, "answer": "Myles Garrett", "latency_ms": 115.36574363708496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3668}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 113.90280723571777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2008", "latency_ms": 86.27033233642578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "2007", "latency_ms": 128.8149356842041, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1392}, "3": {"k": 3, "answer": "2007", "latency_ms": 122.84088134765625, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2090}, "4": {"k": 4, "answer": "2007 BS", "latency_ms": 183.67266654968262, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2735}, "5": {"k": 5, "answer": "2007", "latency_ms": 258.08238983154297, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3451}, "6": {"k": 6, "answer": "2007", "latency_ms": 134.67884063720703, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4087}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "Captain John Smith", "latency_ms": 80.04879951477051, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Smith", "latency_ms": 50.84681510925293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 104.51960563659668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "John Smith", "latency_ms": 101.40204429626465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1951}, "4": {"k": 4, "answer": "John Smith", "latency_ms": 85.21103858947754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "John Smith", "latency_ms": 122.13540077209473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3255}, "6": {"k": 6, "answer": "John Smith", "latency_ms": 170.29571533203125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3887}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 97.71513938903809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "parietal cells", "latency_ms": 104.56013679504395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 625}, "2": {"k": 2, "answer": "parietal cells", "latency_ms": 160.01462936401367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "parietal cells", "latency_ms": 108.51097106933594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1803}, "4": {"k": 4, "answer": "parietal cells", "latency_ms": 112.44893074035645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2405}, "5": {"k": 5, "answer": "parietal cells", "latency_ms": 127.08282470703125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3006}, "6": {"k": 6, "answer": "parietal cells", "latency_ms": 129.96840476989746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3672}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "between 2 and 4 a.m.", "latency_ms": 144.93298530578613, "em": 0.0, "f1": 0.20000000000000004, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "second half of the sleep cycle", "latency_ms": 156.50534629821777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 129.97937202453613, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "4 a.m.", "latency_ms": 90.69538116455078, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "second half of the sleep cycle", "latency_ms": 163.79094123840332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2639}, "5": {"k": 5, "answer": "second half of the sleep cycle", "latency_ms": 131.8800449371338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3270}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 124.27449226379395, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3981}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 51.76353454589844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 179.47959899902344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "Idaho", "latency_ms": 59.86952781677246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Idaho", "latency_ms": 121.59490585327148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2005}, "4": {"k": 4, "answer": "Idaho", "latency_ms": 173.08735847473145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2664}, "5": {"k": 5, "answer": "Wyoming", "latency_ms": 147.67098426818848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3288}, "6": {"k": 6, "answer": "Wyoming", "latency_ms": 118.18575859069824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3970}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "1. The Curse of the Black Pearl  \n2. Dead Man's Chest  \n3. At World's End  \n4. On Stranger Tides  \n5. Pirates of the Caribbean: Salazar's Revenge  \n6. Dead Men Tell No Tales  \n7. The Legend of the Lost Gold  \n8. The Curse of the Black Pearl (reboot)  \n9. The Curse of the Black Pearl (sequel)  \n10. The Curse of the Black Pearl (final)", "latency_ms": 1906.5253734588623, "em": 0.0, "f1": 0.17543859649122806, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 199.9685764312744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Pirates of the Caribbean: The Curse of the Black Pearl (2003), Pirates of the Caribbean: Dead Man's Chest (2006), Pirates of the Caribbean: At World's End (2007)", "latency_ms": 808.8207244873047, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Pirates of the Caribbean: The Curse of the Black Pearl (2003), Pirates of the Caribbean: Dead Man's Chest (2006), Pirates of the Caribbean: At World's End (2007)", "latency_ms": 764.9741172790527, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Pirates of the Caribbean: The Curse of the Black Pearl (2003), Pirates of the Caribbean: Dead Man's Chest (2006), Pirates of the Caribbean: At World's End (2007)", "latency_ms": 913.015604019165, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 2603}, "5": {"k": 5, "answer": "Pirates of the Caribbean: The Curse of the Black Pearl (2003), Pirates of the Caribbean: Dead Man's Chest (2006), Pirates of the Caribbean: At World's End (2007)", "latency_ms": 749.5486736297607, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 3245}, "6": {"k": 6, "answer": "Pirates of the Caribbean: The Curse of the Black Pearl (2003), Pirates of the Caribbean: Dead Man's Chest (2006), Pirates of the Caribbean: At World's End (2007), Pirates of the Caribbean: On Stranger Tides (2011), Pirates of the Caribbean: Dead Men Tell No Tales (2017)", "latency_ms": 1278.7790298461914, "em": 0.0, "f1": 0.23255813953488372, "containment": 1.0, "context_chars": 3867}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 57.576656341552734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "modulated", "latency_ms": 56.966543197631836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "modulated", "latency_ms": 111.06157302856445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "modulated", "latency_ms": 77.89850234985352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "modulated", "latency_ms": 85.25514602661133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2519}, "5": {"k": 5, "answer": "modulated", "latency_ms": 101.57227516174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3108}, "6": {"k": 6, "answer": "modulated", "latency_ms": 169.8446273803711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3720}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Roman citizens of certain property thresholds", "latency_ms": 125.59843063354492, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Full Roman citizens (excluding women, slaves, and originally those living outside of Rome)", "latency_ms": 281.89706802368164, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 637}, "2": {"k": 2, "answer": "Full Roman citizens (excluding women, slaves, and originally those living outside of Rome)", "latency_ms": 331.0275077819824, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "full Roman citizens (excluding women, slaves, and children)", "latency_ms": 262.19677925109863, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Roman citizens", "latency_ms": 82.64780044555664, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2680}, "5": {"k": 5, "answer": "adult male Roman citizens", "latency_ms": 191.76912307739258, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3360}, "6": {"k": 6, "answer": "adult male Roman citizens", "latency_ms": 235.5649471282959, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3976}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.89907264709473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 107.24449157714844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 95.1082706451416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 114.35151100158691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1920}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 187.44969367980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2539}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 173.88176918029785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 251.1739730834961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "total blood volume", "latency_ms": 101.80878639221191, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "blood volume", "latency_ms": 86.82775497436523, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "volume of blood", "latency_ms": 77.40402221679688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "volume of blood", "latency_ms": 164.2301082611084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "volume of blood", "latency_ms": 159.65914726257324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "volume of blood", "latency_ms": 188.9634132385254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3211}, "6": {"k": 6, "answer": "volume of blood", "latency_ms": 163.88416290283203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3782}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 72.40152359008789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Icarus", "latency_ms": 134.31644439697266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "Icarus did not fly too close to the sun; Icarus was a mortal. The myth involves Icarus, not a god. There is no Greek god who flew too close to the sun in the provided context. I cannot answer.", "latency_ms": 1079.4503688812256, "em": 0.0, "f1": 0.05882352941176471, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Icarus did not fly too close to the sun; Icarus was a mortal. The myth involves Icarus, not a god. There is no Greek god who flew too close to the sun in the provided context. I cannot answer.", "latency_ms": 1010.8916759490967, "em": 0.0, "f1": 0.05882352941176471, "containment": 1.0, "context_chars": 1837}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 181.196928024292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2409}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 152.21619606018066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3148}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 158.78748893737793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3745}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "1979", "latency_ms": 85.20030975341797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1979", "latency_ms": 131.31380081176758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "1979", "latency_ms": 207.54075050354004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "1979", "latency_ms": 101.7913818359375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "1979", "latency_ms": 110.96692085266113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2482}, "5": {"k": 5, "answer": "1979", "latency_ms": 134.49811935424805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3090}, "6": {"k": 6, "answer": "1979", "latency_ms": 182.8134059906006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3670}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 AM Hong Kong Time", "latency_ms": 122.95293807983398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 124.2818832397461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 149.60861206054688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 101.57084465026855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 139.3105983734131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 193.55440139770508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3243}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 140.63048362731934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3863}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.16209983825684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Carol Merrill, Georgia Satelle, Elaine Klimaszewski, Diane Klimaszewski, Maggie Brown, Julie Hall, Karen LaPierre, Melanie Vincz", "latency_ms": 620.0065612792969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Carol Merrill", "latency_ms": 68.8772201538086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Carol Merrill", "latency_ms": 80.60741424560547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 141.55888557434082, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 214.17927742004395, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 143.27144622802734, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3701}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 118.62874031066895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 292.2053337097168, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 314.99433517456055, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 275.38204193115234, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1859}, "4": {"k": 4, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 425.6722927093506, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2435}, "5": {"k": 5, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 354.51436042785645, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3078}, "6": {"k": 6, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 271.58188819885254, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3711}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 93.9493179321289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$343.4 million", "latency_ms": 167.44494438171387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "more than $1 billion worldwide", "latency_ms": 117.36631393432617, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "over $1.84 billion worldwide", "latency_ms": 176.0258674621582, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "over $1.84 billion worldwide", "latency_ms": 182.6174259185791, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "over $1.84 billion worldwide", "latency_ms": 227.6301383972168, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3208}, "6": {"k": 6, "answer": "over $1.84 billion worldwide", "latency_ms": 209.02752876281738, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3862}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 77.66604423522949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1946", "latency_ms": 130.02991676330566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 107.49363899230957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 107.70082473754883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 125.85806846618652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2560}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 131.35123252868652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3194}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 209.4125747680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark/Norway", "latency_ms": 222.3210334777832, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Denmark", "latency_ms": 99.17998313903809, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "Scandinavia", "latency_ms": 84.37609672546387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1342}, "3": {"k": 3, "answer": "Scandinavia", "latency_ms": 102.51998901367188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1993}, "4": {"k": 4, "answer": "Scandinavian patronymic surname, meaning \"son of Hans\"", "latency_ms": 346.47679328918457, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 2640}, "5": {"k": 5, "answer": "Scandinavia", "latency_ms": 123.29888343811035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3254}, "6": {"k": 6, "answer": "Scandinavian patronymic surname, meaning \"son of Hans\"", "latency_ms": 521.7745304107666, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 3883}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 71.47455215454102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Puritina", "latency_ms": 140.6083106994629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Christmas Tree and Nativity scene", "latency_ms": 174.56436157226562, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Christmas Tree and Nativity scene", "latency_ms": 132.94482231140137, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1919}, "4": {"k": 4, "answer": "Christmas tree and Nativity scene", "latency_ms": 133.99147987365723, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2541}, "5": {"k": 5, "answer": "Nativity scene", "latency_ms": 111.57965660095215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3175}, "6": {"k": 6, "answer": "Christmas tree", "latency_ms": 98.41132164001465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3739}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 82.83782005310059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Swayze", "latency_ms": 64.92185592651367, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 283.4205627441406, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 149.97291564941406, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 193.08853149414062, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2505}, "5": {"k": 5, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 159.14368629455566, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3151}, "6": {"k": 6, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 201.86090469360352, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3813}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Rhode Island", "latency_ms": 63.27176094055176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 222.34082221984863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 744}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 245.08953094482422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1382}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 112.60223388671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2108}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 129.82869148254395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2802}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 191.9097900390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3480}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 179.00443077087402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4145}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1801", "latency_ms": 76.09844207763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "24 May 1854", "latency_ms": 164.7806167602539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "24 May 1854", "latency_ms": 250.95891952514648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "1905", "latency_ms": 137.73751258850098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2047}, "4": {"k": 4, "answer": "1905", "latency_ms": 165.2514934539795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2744}, "5": {"k": 5, "answer": "17th Century", "latency_ms": 169.86536979675293, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3401}, "6": {"k": 6, "answer": "17th Century", "latency_ms": 242.3868179321289, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4062}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier Fernández", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 183.39228630065918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yuzuru Hanyu", "latency_ms": 230.96585273742676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Yuzuru Hanyu", "latency_ms": 144.46449279785156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Yuzuru Hanyu", "latency_ms": 302.54578590393066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1904}, "4": {"k": 4, "answer": "Yuzuru Hanyu", "latency_ms": 286.2367630004883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2655}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 171.74172401428223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3335}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 180.51671981811523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4014}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 118.8654899597168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "password recovery", "latency_ms": 56.23602867126465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "password recovery", "latency_ms": 119.9193000793457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1391}, "3": {"k": 3, "answer": "password recovery for Microsoft Windows", "latency_ms": 152.36973762512207, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1976}, "4": {"k": 4, "answer": "password recovery for Microsoft Windows", "latency_ms": 238.8911247253418, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2569}, "5": {"k": 5, "answer": "password recovery for Microsoft Windows", "latency_ms": 173.71487617492676, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "password recovery for Microsoft Windows", "latency_ms": 204.39863204956055, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3816}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "Eknath Shinde", "latency_ms": 216.4292335510254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "C. Vidyasagar Rao", "latency_ms": 138.21935653686523, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "C. Vidyasagar Rao", "latency_ms": 195.77503204345703, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 239.09473419189453, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 298.80332946777344, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "C. Vidyasagar Rao", "latency_ms": 304.8057556152344, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "C. Vidyasagar Rao", "latency_ms": 224.9610424041748, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3867}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 118.15118789672852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "15", "latency_ms": 64.37492370605469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 603}, "2": {"k": 2, "answer": "15", "latency_ms": 64.7130012512207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "15", "latency_ms": 81.5579891204834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1933}, "4": {"k": 4, "answer": "15", "latency_ms": 146.32081985473633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2565}, "5": {"k": 5, "answer": "15", "latency_ms": 164.1840934753418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3246}, "6": {"k": 6, "answer": "15", "latency_ms": 113.05928230285645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Michael J. Fox", "latency_ms": 82.33261108398438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elisabeth Shue", "latency_ms": 179.97169494628906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Claudia Wells", "latency_ms": 101.66645050048828, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1181}, "3": {"k": 3, "answer": "Claudia Wells", "latency_ms": 178.59339714050293, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "Claudia Wells (first film), Elisabeth Shue (Part II and Part III)", "latency_ms": 392.5623893737793, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2422}, "5": {"k": 5, "answer": "Claudia Wells", "latency_ms": 179.50010299682617, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "Claudia Wells", "latency_ms": 175.7497787475586, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3629}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 35.247802734375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "London, United Kingdom", "latency_ms": 130.41114807128906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 176.82194709777832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 108.98113250732422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 127.38847732543945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2566}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 129.75621223449707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3201}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 221.24695777893066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3850}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The president's chef", "latency_ms": 80.00445365905762, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "White House Executive Chef", "latency_ms": 115.53096771240234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "White House Executive Chef", "latency_ms": 153.4886360168457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "White House Executive Chef", "latency_ms": 173.05517196655273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2038}, "4": {"k": 4, "answer": "White House Executive Chef", "latency_ms": 116.35994911193848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2671}, "5": {"k": 5, "answer": "White House Executive Chef", "latency_ms": 140.81144332885742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "White House Executive Chef", "latency_ms": 132.0638656616211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3875}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 192.23999977111816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 174.93653297424316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 93.28389167785645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 105.2849292755127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1876}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 149.95765686035156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2446}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 206.19869232177734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3019}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 220.6883430480957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3655}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 159.2271327972412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "British Columbia", "latency_ms": 157.08136558532715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "British Columbia", "latency_ms": 82.28063583374023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "British Columbia", "latency_ms": 147.5980281829834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1956}, "4": {"k": 4, "answer": "British Columbia", "latency_ms": 87.62407302856445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2605}, "5": {"k": 5, "answer": "British Columbia", "latency_ms": 104.17366027832031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3275}, "6": {"k": 6, "answer": "British Columbia", "latency_ms": 116.21642112731934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3955}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.25865936279297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 11, 2018", "latency_ms": 159.50632095336914, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "October 11, 2018", "latency_ms": 186.78903579711914, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 281.70156478881836, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 429.51178550720215, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2668}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 287.40954399108887, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3289}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 282.26423263549805, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3934}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Dana Delany", "latency_ms": 75.6220817565918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mary-Kate and Ashley Olsen", "latency_ms": 110.15439033508301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Mary-Kate and Ashley Olsen", "latency_ms": 117.01655387878418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Mary-Kate and Ashley Olsen", "latency_ms": 205.02686500549316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Stephanie Tanner", "latency_ms": 110.94284057617188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "Stephanie Tanner", "latency_ms": 161.57007217407227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "Stephanie Tanner", "latency_ms": 184.64183807373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 70.1754093170166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Millennium Tower", "latency_ms": 86.33756637573242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 175.31371116638184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1345}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 112.76102066040039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2031}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 169.63505744934082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2688}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 224.4274616241455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3347}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 212.95666694641113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4043}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 74.29170608520508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 86.4403247833252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "2015", "latency_ms": 110.34488677978516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "2015", "latency_ms": 148.41771125793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "October 2013", "latency_ms": 160.47906875610352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "October 2013", "latency_ms": 176.67555809020996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3086}, "6": {"k": 6, "answer": "October 2013", "latency_ms": 300.1565933227539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3694}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "T.S. Eliot", "latency_ms": 84.58065986633301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Marshall Harlan", "latency_ms": 136.77048683166504, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "John Marshall Harlan", "latency_ms": 92.43202209472656, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1390}, "3": {"k": 3, "answer": "John Marshall Harlan", "latency_ms": 167.13333129882812, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2093}, "4": {"k": 4, "answer": "John Marshall Harlan", "latency_ms": 212.80193328857422, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2772}, "5": {"k": 5, "answer": "John Marshall Harlan II", "latency_ms": 219.55418586730957, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3453}, "6": {"k": 6, "answer": "John Marshall Harlan II", "latency_ms": 148.12731742858887, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4097}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Chris Berman", "latency_ms": 82.12709426879883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tyrann Mathieu", "latency_ms": 164.99900817871094, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 123.6572265625, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 118.18575859069824, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 220.5793857574463, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2568}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 173.30026626586914, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3203}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 140.13218879699707, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3891}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 108.80899429321289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "6", "latency_ms": 92.06509590148926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "6", "latency_ms": 57.59000778198242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "6", "latency_ms": 139.86945152282715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "6", "latency_ms": 96.20237350463867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2698}, "5": {"k": 5, "answer": "6", "latency_ms": 114.59708213806152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3373}, "6": {"k": 6, "answer": "6", "latency_ms": 138.75818252563477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4022}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Karl Hauser's", "latency_ms": 140.84196090698242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "soldiers' perspective", "latency_ms": 114.20679092407227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "German soldiers' perspective", "latency_ms": 117.48504638671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "young soldiers' perspective", "latency_ms": 105.06677627563477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "German soldiers'", "latency_ms": 117.75779724121094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2548}, "5": {"k": 5, "answer": "young soldiers' perspective", "latency_ms": 227.9531955718994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "young soldiers' perspective", "latency_ms": 238.6767864227295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3779}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris and the Anglin brothers", "latency_ms": 183.2115650177002, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 329.5876979827881, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 668}, "2": {"k": 2, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 297.43146896362305, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1353}, "3": {"k": 3, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 300.07314682006836, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1958}, "4": {"k": 4, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 268.8634395599365, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2580}, "5": {"k": 5, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 369.2493438720703, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3244}, "6": {"k": 6, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 286.5018844604492, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3870}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF", "latency_ms": 164.2005443572998, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF", "latency_ms": 104.72655296325684, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 718}, "2": {"k": 2, "answer": "UNICEF's global programing, with half targeted to domestic causes like Hurricane Katrina aid", "latency_ms": 314.5015239715576, "em": 0.0, "f1": 0.2352941176470588, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "UNICEF's global programing, with half of proceeds in 2005 targeted to Hurricane Katrina victims in the U.S.", "latency_ms": 700.1621723175049, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2142}, "4": {"k": 4, "answer": "UNICEF's global programing, with half of proceeds in 2005 targeted to Hurricane Katrina victims in the U.S.", "latency_ms": 468.2157039642334, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2800}, "5": {"k": 5, "answer": "UNICEF's global programing, with half of proceeds in 2005 targeted to Hurricane Katrina victims in the U.S.", "latency_ms": 494.8453903198242, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 3525}, "6": {"k": 6, "answer": "UNICEF's global programing, with half of proceeds in 2005 targeted to Hurricane Katrina victims in the U.S.", "latency_ms": 686.032772064209, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 4204}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Statue of Liberty's inscription is on the pedestal.", "latency_ms": 272.71103858947754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "edge of the coin", "latency_ms": 77.54707336425781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "on the reverse side of the coin", "latency_ms": 199.662446975708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "on the reverse side of the Presidential $1 coin", "latency_ms": 200.73938369750977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "on the base of the statue of liberty", "latency_ms": 249.97830390930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": "on Liberty Island in New York Harbor in New York City, in the United States", "latency_ms": 363.83652687072754, "em": 0.0, "f1": 0.125, "containment": 0.0, "context_chars": 3141}, "6": {"k": 6, "answer": "on Liberty Island in New York Harbor", "latency_ms": 195.35541534423828, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 3763}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 98.25587272644043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 162.80889511108398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 210.7100486755371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 160.50052642822266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 143.80192756652832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 154.9661159515381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3055}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 218.22690963745117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3727}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "1994", "latency_ms": 274.37615394592285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1997", "latency_ms": 105.96561431884766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 118.98255348205566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 102.65922546386719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "August 22, 1980", "latency_ms": 312.2389316558838, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "August 22, 1980", "latency_ms": 217.12660789489746, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3110}, "6": {"k": 6, "answer": "August 22, 1980", "latency_ms": 442.13008880615234, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3756}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "stone arch bridge", "latency_ms": 63.849687576293945, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "single-leaf, through-truss, rolling bascule bridge", "latency_ms": 216.2458896636963, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Stone Bridge", "latency_ms": 107.89990425109863, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 170.0303554534912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2012}, "4": {"k": 4, "answer": "stone bridge", "latency_ms": 152.2674560546875, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2649}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 125.11897087097168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3316}, "6": {"k": 6, "answer": "historic bridge", "latency_ms": 113.90566825866699, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4002}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The ruler or leader", "latency_ms": 142.42887496948242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "one person", "latency_ms": 63.5223388671875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "one person", "latency_ms": 84.90490913391113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "one person", "latency_ms": 83.58573913574219, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1987}, "4": {"k": 4, "answer": "one person", "latency_ms": 87.60952949523926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2722}, "5": {"k": 5, "answer": "one person", "latency_ms": 119.18473243713379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3392}, "6": {"k": 6, "answer": "one person", "latency_ms": 103.26814651489258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4042}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.95300674438477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "global internationalist ideology", "latency_ms": 224.26176071166992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "global internationalist ideology", "latency_ms": 157.5639247894287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "return to domesticity and increased internationalism", "latency_ms": 154.6797752380371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "global internationalist ideology", "latency_ms": 172.9600429534912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2652}, "5": {"k": 5, "answer": "global internationalist ideology", "latency_ms": 158.5991382598877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3380}, "6": {"k": 6, "answer": "global internationalism", "latency_ms": 173.48003387451172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4035}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "counterclockwise", "latency_ms": 141.5255069732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "counterclockwise", "latency_ms": 86.17758750915527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "counterclockwise", "latency_ms": 126.36899948120117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "counterclockwise", "latency_ms": 189.1622543334961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1733}, "4": {"k": 4, "answer": "counterclockwise", "latency_ms": 125.2903938293457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2318}, "5": {"k": 5, "answer": "counterclockwise", "latency_ms": 124.29594993591309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2889}, "6": {"k": 6, "answer": "counterclockwise", "latency_ms": 149.9314308166504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3564}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Dome", "latency_ms": 86.34638786315918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "dome", "latency_ms": 105.23843765258789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Statue of Freedom", "latency_ms": 104.09832000732422, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1177}, "3": {"k": 3, "answer": "Statue of Freedom", "latency_ms": 91.7670726776123, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "Statue of Freedom", "latency_ms": 177.64878273010254, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2451}, "5": {"k": 5, "answer": "Statue of Freedom", "latency_ms": 198.2738971710205, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3098}, "6": {"k": 6, "answer": "Statue of Freedom", "latency_ms": 160.6903076171875, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3674}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 155.38597106933594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington Wizards", "latency_ms": 109.94744300842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 94.3596363067627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1356}, "3": {"k": 3, "answer": "Washington Wizards", "latency_ms": 99.99251365661621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "Washington Wizards", "latency_ms": 137.74991035461426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "Washington Wizards", "latency_ms": 105.08608818054199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "Washington Wizards", "latency_ms": 149.6434211730957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3709}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.35378837585449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Greatest Royal Rumble", "latency_ms": 252.6249885559082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Mysterio", "latency_ms": 77.74567604064941, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Mysterio", "latency_ms": 93.48893165588379, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "Mysterio", "latency_ms": 98.00338745117188, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2419}, "5": {"k": 5, "answer": "Mysterio", "latency_ms": 153.33962440490723, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3013}, "6": {"k": 6, "answer": "Daniel Bryan", "latency_ms": 164.08085823059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3640}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 59.342145919799805, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake of the Ozarks", "latency_ms": 130.07616996765137, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Lake of the Ozarks", "latency_ms": 105.5455207824707, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Lake Mead", "latency_ms": 92.47422218322754, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Lake Oahe", "latency_ms": 109.91954803466797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2518}, "5": {"k": 5, "answer": "Lake Oahe", "latency_ms": 237.22267150878906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3128}, "6": {"k": 6, "answer": "Lake Oahe", "latency_ms": 172.90997505187988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3746}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Gabbar Is Back", "latency_ms": 84.07926559448242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 145.12324333190918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "Tagore", "latency_ms": 69.79012489318848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 160.18247604370117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "Ramanaa", "latency_ms": 128.69715690612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 123.17895889282227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "Tagore", "latency_ms": 168.77198219299316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3883}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "John Baker", "latency_ms": 53.731441497802734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Geraldine Ferraro", "latency_ms": 89.85376358032227, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 682}, "2": {"k": 2, "answer": "Geraldine Ferraro", "latency_ms": 105.66544532775879, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1385}, "3": {"k": 3, "answer": "Geraldine Ferraro", "latency_ms": 118.98303031921387, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2061}, "4": {"k": 4, "answer": "Geraldine Ferraro", "latency_ms": 243.81732940673828, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2771}, "5": {"k": 5, "answer": "George H. W. Bush", "latency_ms": 247.58124351501465, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3510}, "6": {"k": 6, "answer": "George H. W. Bush", "latency_ms": 180.8462142944336, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 4208}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "Utah", "latency_ms": 92.35763549804688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Town of Groveland", "latency_ms": 236.67550086975098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners, New York", "latency_ms": 217.99063682556152, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Hampton Corners, New York", "latency_ms": 251.44505500793457, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "Hampton Corners, New York", "latency_ms": 266.6025161743164, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Hampton Corners, New York", "latency_ms": 162.42241859436035, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3178}, "6": {"k": 6, "answer": "Hampton Corners, New York", "latency_ms": 288.3615493774414, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3794}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 54.11195755004883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 57.793617248535156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 70.92690467834473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1172}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 81.05659484863281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1729}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 84.98024940490723, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2319}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 106.34183883666992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2918}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 167.0665740966797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3520}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Uttar Pradesh", "latency_ms": 145.39432525634766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.96224403381348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 180.97233772277832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "Meghalaya", "latency_ms": 95.5655574798584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1929}, "4": {"k": 4, "answer": "Meghalaya", "latency_ms": 142.5614356994629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2552}, "5": {"k": 5, "answer": "Meghalaya", "latency_ms": 137.08114624023438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Meghalaya", "latency_ms": 186.04660034179688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3817}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Lucknow", "latency_ms": 53.3599853515625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ludhiana", "latency_ms": 122.92361259460449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 565}, "2": {"k": 2, "answer": "Ludhiana", "latency_ms": 93.69874000549316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Ludhiana", "latency_ms": 102.65278816223145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Ludhiana", "latency_ms": 109.8780632019043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2570}, "5": {"k": 5, "answer": "Kanpur", "latency_ms": 112.11776733398438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3197}, "6": {"k": 6, "answer": "Kanpur", "latency_ms": 125.64802169799805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3778}}}
