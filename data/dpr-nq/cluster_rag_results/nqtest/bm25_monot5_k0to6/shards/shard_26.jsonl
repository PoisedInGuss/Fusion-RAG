{"qid": "-7098436211686405768", "question": "who won the icc under 19 world cup 2018", "gold_answers": ["India", "West Indies"], "shots": {"0": {"k": 0, "answer": "England", "latency_ms": 58.89630317687988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 108.75177383422852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 109.03429985046387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 142.9908275604248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1976}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 167.9832935333252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 208.40764045715332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3297}, "6": {"k": 6, "answer": "India", "latency_ms": 145.57862281799316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3915}}}
{"qid": "5122841983113839364", "question": "when was the jury system abolished in india", "gold_answers": ["1959"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 196.31600379943848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1973", "latency_ms": 201.9810676574707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "1973", "latency_ms": 134.49859619140625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "1973", "latency_ms": 136.63005828857422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "1973", "latency_ms": 218.75905990600586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2489}, "5": {"k": 5, "answer": "1973", "latency_ms": 175.12273788452148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3129}, "6": {"k": 6, "answer": "1973", "latency_ms": 195.77813148498535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3729}}}
{"qid": "-6392030846180659596", "question": "who played morticia in the addams family tv show", "gold_answers": ["Carolyn Sue Jones"], "shots": {"0": {"k": 0, "answer": "Catherine Oxenberg", "latency_ms": 148.43201637268066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Janet Waldo", "latency_ms": 174.01432991027832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Carolyn Jones", "latency_ms": 115.11635780334473, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Carolyn Jones", "latency_ms": 125.74315071105957, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Carolyn Jones", "latency_ms": 152.0977020263672, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "Carolyn Jones", "latency_ms": 147.7375030517578, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3288}, "6": {"k": 6, "answer": "Carolyn Jones", "latency_ms": 179.2144775390625, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3934}}}
{"qid": "8177571930408806343", "question": "how many episodes of the white princess will there be", "gold_answers": ["eight", "8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 177.41918563842773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 155.33208847045898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "8", "latency_ms": 118.03269386291504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1340}, "3": {"k": 3, "answer": "eight", "latency_ms": 69.20623779296875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1975}, "4": {"k": 4, "answer": "eight episodes", "latency_ms": 153.17749977111816, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2609}, "5": {"k": 5, "answer": "8", "latency_ms": 116.72687530517578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3267}, "6": {"k": 6, "answer": "eight", "latency_ms": 182.48510360717773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3899}}}
{"qid": "6581085745347506584", "question": "when was pac man released in the us", "gold_answers": ["October 26 , 1980", "in October 1980", "October 1980"], "shots": {"0": {"k": 0, "answer": "1980", "latency_ms": 146.11053466796875, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "late 1980", "latency_ms": 244.41242218017578, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "October 1980", "latency_ms": 285.57825088500977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1252}, "3": {"k": 3, "answer": "October 1980", "latency_ms": 213.36054801940918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1891}, "4": {"k": 4, "answer": "October 1980", "latency_ms": 331.4790725708008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2518}, "5": {"k": 5, "answer": "October 1980", "latency_ms": 219.54035758972168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3151}, "6": {"k": 6, "answer": "October 1980", "latency_ms": 315.55843353271484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3762}}}
{"qid": "3114053463642113959", "question": "who plays drew's boyfriend on the night shift", "gold_answers": ["Rick"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 97.42021560668945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 112.1056079864502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "Brendan Fehr", "latency_ms": 185.7287883758545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1294}, "3": {"k": 3, "answer": "Majandra Delfino", "latency_ms": 283.0698490142822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1902}, "4": {"k": 4, "answer": "Majandra Delfino", "latency_ms": 178.53045463562012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "Majandra Delfino", "latency_ms": 237.91742324829102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3194}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 189.81242179870605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3920}}}
{"qid": "4533997928552404782", "question": "where is the lost dutchman's mine supposed to be located", "gold_answers": ["in the southwestern United States"], "shots": {"0": {"k": 0, "answer": "Grand Canyon, Arizona", "latency_ms": 130.9826374053955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "latency_ms": 372.3711967468262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "latency_ms": 281.62121772766113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "latency_ms": 304.964542388916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "latency_ms": 345.4914093017578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2502}, "5": {"k": 5, "answer": "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "latency_ms": 325.0436782836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "latency_ms": 416.80908203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "5352272261459028724", "question": "who sang the national anthem at the 2002 super bowl", "gold_answers": ["Mariah Carey"], "shots": {"0": {"k": 0, "answer": "Howie Day", "latency_ms": 95.11733055114746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 159.03520584106445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 214.26153182983398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 266.4022445678711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 112.16425895690918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2449}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 126.35922431945801, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3106}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 131.08515739440918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3751}}}
{"qid": "-5448353169627005671", "question": "where did the last name wallace come from", "gold_answers": ["a Scottish surname"], "shots": {"0": {"k": 0, "answer": "Scots-Irish origin", "latency_ms": 93.68443489074707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nellie Wallace, a turn-of-the-century stage singer", "latency_ms": 227.3082733154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 576}, "2": {"k": 2, "answer": "Donegal in northern Ireland", "latency_ms": 160.78734397888184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 136.87467575073242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1844}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 155.2283763885498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2417}, "5": {"k": 5, "answer": "Donegal in northern Ireland", "latency_ms": 227.75506973266602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3074}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 163.01488876342773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3656}}}
{"qid": "-6282136142651212589", "question": "who made the movie fifty shades of grey", "gold_answers": ["Universal Pictures and Focus Features", "Sam Taylor - Johnson"], "shots": {"0": {"k": 0, "answer": "The movie *Fifty Shades of Grey* was made by the production company **Lionsgate**.  \nAnswer: Lionsgate", "latency_ms": 593.1756496429443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sam Taylor-Johnson", "latency_ms": 217.29016304016113, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "Sam Taylor-Johnson", "latency_ms": 138.78417015075684, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Sam Taylor-Johnson", "latency_ms": 144.4685459136963, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "Sam Taylor-Johnson", "latency_ms": 136.9953155517578, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2671}, "5": {"k": 5, "answer": "Sam Taylor-Johnson", "latency_ms": 141.0386562347412, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3290}, "6": {"k": 6, "answer": "Sam Taylor-Johnson", "latency_ms": 225.25906562805176, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3907}}}
{"qid": "-6860125217421272747", "question": "what are the names of the hunger games", "gold_answers": ["The Hunger Games"], "shots": {"0": {"k": 0, "answer": "The Hunger Games", "latency_ms": 70.05453109741211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Hunger Games, Catching Fire, Mockingjay", "latency_ms": 181.66041374206543, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "The Hunger Games, Catching Fire, Mockingjay", "latency_ms": 304.40568923950195, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1312}, "3": {"k": 3, "answer": "The Hunger Games, Catching Fire, Mockingjay", "latency_ms": 220.24035453796387, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2012}, "4": {"k": 4, "answer": "The Hunger Games, Catching Fire, Mockingjay", "latency_ms": 267.20595359802246, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2662}, "5": {"k": 5, "answer": "The Hunger Games, Catching Fire, Mockingjay", "latency_ms": 267.2455310821533, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3312}, "6": {"k": 6, "answer": "The Hunger Games, Catching Fire, Mockingjay", "latency_ms": 310.5320930480957, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3987}}}
{"qid": "57573855796458704", "question": "what engine is in a holden v8 supercar", "gold_answers": ["V8 - engine"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 156.3560962677002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5-litre V8 engine", "latency_ms": 116.08290672302246, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "5-litre V8 engine", "latency_ms": 193.9370632171631, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "5-litre V8 engine", "latency_ms": 137.38465309143066, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1820}, "4": {"k": 4, "answer": "5-litre V8 engine", "latency_ms": 181.81824684143066, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2435}, "5": {"k": 5, "answer": "5-litre, naturally aspirated V8 engine", "latency_ms": 291.42069816589355, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3097}, "6": {"k": 6, "answer": "5-litre, naturally aspirated V8 engine", "latency_ms": 338.1955623626709, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3771}}}
{"qid": "4575828710313790645", "question": "when did the international space station go into space", "gold_answers": ["1998"], "shots": {"0": {"k": 0, "answer": "1998", "latency_ms": 159.3947410583496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1998", "latency_ms": 128.60703468322754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "1998", "latency_ms": 125.31781196594238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1332}, "3": {"k": 3, "answer": "1998", "latency_ms": 145.91598510742188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2001}, "4": {"k": 4, "answer": "1998", "latency_ms": 206.30621910095215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2710}, "5": {"k": 5, "answer": "1998", "latency_ms": 194.8106288909912, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3459}, "6": {"k": 6, "answer": "1998", "latency_ms": 201.2794017791748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4104}}}
{"qid": "2303585950274205305", "question": "what type of dog was laika the spacedog", "gold_answers": ["mongrel female"], "shots": {"0": {"k": 0, "answer": "Soviet dog", "latency_ms": 98.50525856018066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Soviet dog", "latency_ms": 108.13140869140625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "Russian Spitz", "latency_ms": 118.64829063415527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "East Siberian Laika", "latency_ms": 170.00842094421387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1900}, "4": {"k": 4, "answer": "East Siberian Laika", "latency_ms": 303.570032119751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "East Siberian Laika", "latency_ms": 231.17518424987793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3137}, "6": {"k": 6, "answer": "East Siberian Laika", "latency_ms": 185.09650230407715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3816}}}
{"qid": "-6008777350997007702", "question": "who sang it's a mean old world", "gold_answers": ["T - Bone Walker"], "shots": {"0": {"k": 0, "answer": "The Who", "latency_ms": 55.979251861572266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "T-Bone Walker", "latency_ms": 125.50640106201172, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "T-Bone Walker", "latency_ms": 144.43278312683105, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "T-Bone Walker", "latency_ms": 194.10300254821777, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1907}, "4": {"k": 4, "answer": "T-Bone Walker", "latency_ms": 173.40445518493652, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "T-Bone Walker", "latency_ms": 171.82445526123047, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3129}, "6": {"k": 6, "answer": "T-Bone Walker", "latency_ms": 149.16634559631348, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3704}}}
{"qid": "-467684233955454366", "question": "what are the 4 types of nitrogenous bases", "gold_answers": ["cytosine ( C )", "uracil ( U )", "thymine ( T )", "adenine ( A )", "guanine ( G )"], "shots": {"0": {"k": 0, "answer": "adenine, guanine, cytosine, thymine", "latency_ms": 257.4048042297363, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "adenine, cytosine, guanine, thymine, uracil", "latency_ms": 462.37969398498535, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "adenine, thymine, cytosine, guanine", "latency_ms": 382.27057456970215, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "adenine, thymine, cytosine, guanine", "latency_ms": 412.5182628631592, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "adenine, thymine, cytosine, guanine", "latency_ms": 303.7545680999756, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2651}, "5": {"k": 5, "answer": "adenine, thymine, cytosine, guanine", "latency_ms": 345.90768814086914, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3325}, "6": {"k": 6, "answer": "adenine, thymine, cytosine, uracil", "latency_ms": 425.1589775085449, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3987}}}
{"qid": "8296511137247210518", "question": "what are the toll roads called in mexico", "gold_answers": ["autopistas"], "shots": {"0": {"k": 0, "answer": "carreteras peajes", "latency_ms": 146.11530303955078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Arco Norte", "latency_ms": 95.29471397399902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "Arco Norte, Exterior Mexiquense, Chamapa-La Venta, Periférico, Supervía Poniente", "latency_ms": 680.877685546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Arco Norte, Periférico, Supervía Poniente, Federal Highway 15D", "latency_ms": 613.292932510376, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "autopistas de cuota", "latency_ms": 191.60175323486328, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2675}, "5": {"k": 5, "answer": "autopistas de cuota", "latency_ms": 250.0755786895752, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3281}, "6": {"k": 6, "answer": "autopistas de cuota", "latency_ms": 220.38602828979492, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3949}}}
{"qid": "1854655788853154951", "question": "unsaturated fats are comprised of lipids that contain", "gold_answers": ["at least one double bond", "double bond"], "shots": {"0": {"k": 0, "answer": "double bonds", "latency_ms": 55.21583557128906, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "double bonds", "latency_ms": 85.94250679016113, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "double bonds", "latency_ms": 85.82067489624023, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1357}, "3": {"k": 3, "answer": "double bonds", "latency_ms": 82.7949047088623, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2068}, "4": {"k": 4, "answer": "double bonds", "latency_ms": 154.1750431060791, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2723}, "5": {"k": 5, "answer": "double bonds", "latency_ms": 105.3323745727539, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3446}, "6": {"k": 6, "answer": "double bonds", "latency_ms": 129.45866584777832, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4210}}}
{"qid": "-2015568298234613617", "question": "where did they film ghosts of girlfriends past", "gold_answers": ["Massachusetts"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 92.1168327331543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rhode Island", "latency_ms": 129.98294830322266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "Rhode Island", "latency_ms": 196.49982452392578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Rhode Island", "latency_ms": 112.77246475219727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1936}, "4": {"k": 4, "answer": "Rhode Island and Crane Castle in Ipswich, Ma", "latency_ms": 292.2642230987549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Rhode Island and Crane Castle in Ipswich, Ma", "latency_ms": 371.9911575317383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "Rhode Island and Crane Castle in Ipswich, Ma", "latency_ms": 320.1262950897217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3853}}}
{"qid": "-5411612004022549496", "question": "when does a wrinkle in time come out in canada", "gold_answers": ["March 9 , 2018"], "shots": {"0": {"k": 0, "answer": "2003", "latency_ms": 142.46845245361328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2003", "latency_ms": 130.07116317749023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 679}, "2": {"k": 2, "answer": "April 6, 2018", "latency_ms": 293.8075065612793, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1304}, "3": {"k": 3, "answer": "June 5, 2018", "latency_ms": 328.64904403686523, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1944}, "4": {"k": 4, "answer": "May 10, 2004", "latency_ms": 282.47523307800293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2590}, "5": {"k": 5, "answer": "May 10, 2004", "latency_ms": 382.45654106140137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3243}, "6": {"k": 6, "answer": "May 10, 2004", "latency_ms": 374.4180202484131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3857}}}
{"qid": "-8229490686742200210", "question": "who had created the second bank of the united states", "gold_answers": ["James Madison", "President James Madison"], "shots": {"0": {"k": 0, "answer": "Alexander Hamilton", "latency_ms": 53.01070213317871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "President James Madison", "latency_ms": 111.47475242614746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "William Strickland", "latency_ms": 155.20095825195312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "William Strickland", "latency_ms": 219.79522705078125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1994}, "4": {"k": 4, "answer": "William Strickland", "latency_ms": 133.2111358642578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2637}, "5": {"k": 5, "answer": "William Strickland", "latency_ms": 184.71717834472656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3239}, "6": {"k": 6, "answer": "William Strickland", "latency_ms": 211.2722396850586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3922}}}
{"qid": "3612945562446452821", "question": "when were 7 books removed from the bible", "gold_answers": ["1546"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 92.23055839538574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Martin Luther", "latency_ms": 58.754682540893555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 132.7357292175293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "16th century", "latency_ms": 112.701416015625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1985}, "4": {"k": 4, "answer": "16th century", "latency_ms": 152.76122093200684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "16th century", "latency_ms": 174.47495460510254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3278}, "6": {"k": 6, "answer": "16th century", "latency_ms": 131.55817985534668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3969}}}
{"qid": "-1286841988557529859", "question": "who plays voldemort in harry potter and the philosopher's stone", "gold_answers": ["Ian Hart", "Richard Bremmer"], "shots": {"0": {"k": 0, "answer": "Robert Pattinson", "latency_ms": 150.04634857177734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ian Hart", "latency_ms": 58.652639389038086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Ian Hart", "latency_ms": 117.89536476135254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Ian Hart", "latency_ms": 147.98212051391602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Ian Hart", "latency_ms": 152.81081199645996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2451}, "5": {"k": 5, "answer": "Ian Hart", "latency_ms": 102.08964347839355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3057}, "6": {"k": 6, "answer": "Ian Hart", "latency_ms": 224.94029998779297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3691}}}
{"qid": "-3159460576929919105", "question": "when did the united states start using the death penalty", "gold_answers": ["1608", "the beginning"], "shots": {"0": {"k": 0, "answer": "1790", "latency_ms": 106.75716400146484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 90.96193313598633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "1976", "latency_ms": 129.0111541748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "1976", "latency_ms": 144.9277400970459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1992}, "4": {"k": 4, "answer": "1976", "latency_ms": 201.67207717895508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2655}, "5": {"k": 5, "answer": "1976", "latency_ms": 128.99541854858398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3338}, "6": {"k": 6, "answer": "1976", "latency_ms": 236.8931770324707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4007}}}
{"qid": "6975968195327799749", "question": "when is the last time the us lost the olympics", "gold_answers": ["2018 Pyeongchang"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 187.14475631713867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 84.89370346069336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "1980", "latency_ms": 221.17280960083008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "1980", "latency_ms": 188.57812881469727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "1980", "latency_ms": 126.24216079711914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "1980", "latency_ms": 164.71529006958008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "1980", "latency_ms": 207.7014446258545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3755}}}
{"qid": "-6747120392723244868", "question": "who has the most super bowls in nfl history", "gold_answers": ["The Pittsburgh Steelers", "Pittsburgh Steelers"], "shots": {"0": {"k": 0, "answer": "Super Bowl wins: 7 (Kansas City Chiefs)", "latency_ms": 426.44786834716797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pittsburgh Steelers", "latency_ms": 238.76476287841797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "Pittsburgh Steelers", "latency_ms": 97.9914665222168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Pittsburgh Steelers", "latency_ms": 142.46129989624023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1887}, "4": {"k": 4, "answer": "Pittsburgh Steelers", "latency_ms": 141.13140106201172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2487}, "5": {"k": 5, "answer": "Pittsburgh Steelers", "latency_ms": 175.63724517822266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3089}, "6": {"k": 6, "answer": "Pittsburgh Steelers", "latency_ms": 183.62879753112793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3693}}}
{"qid": "525023656480961403", "question": "when was the immigration act passed in canada", "gold_answers": ["1923"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 132.0202350616455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 22, 1869", "latency_ms": 323.0242729187012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "1869", "latency_ms": 177.4578094482422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1383}, "3": {"k": 3, "answer": "1869", "latency_ms": 211.00902557373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2095}, "4": {"k": 4, "answer": "1869", "latency_ms": 178.95245552062988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2716}, "5": {"k": 5, "answer": "1869", "latency_ms": 196.7935562133789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3367}, "6": {"k": 6, "answer": "1869", "latency_ms": 209.8386287689209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4001}}}
{"qid": "9001153795401557727", "question": "name the cell which is attached to the lateral side of sieve tube", "gold_answers": ["sieve tube elements"], "shots": {"0": {"k": 0, "answer": "Companion cell", "latency_ms": 77.90088653564453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "companion cells", "latency_ms": 111.6790771484375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 720}, "2": {"k": 2, "answer": "companion cell", "latency_ms": 193.4370994567871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "companion cell", "latency_ms": 148.35667610168457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2034}, "4": {"k": 4, "answer": "companion cell", "latency_ms": 164.90483283996582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2656}, "5": {"k": 5, "answer": "companion cell", "latency_ms": 198.88925552368164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3294}, "6": {"k": 6, "answer": "companion cell", "latency_ms": 149.30152893066406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3975}}}
{"qid": "5559492750970935173", "question": "where is final four being held this year", "gold_answers": ["the Alamodome"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 107.6803207397461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 154.1309356689453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 144.1800594329834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 161.5290641784668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1907}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 181.95056915283203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 208.76145362854004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 187.69121170043945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3818}}}
{"qid": "-7778542680482512904", "question": "symbolic interactionism is the basis for which theoretical model", "gold_answers": ["versions of Identity Theory", "role theory", "sociological"], "shots": {"0": {"k": 0, "answer": "symbolic interactionism", "latency_ms": 101.64642333984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "symbolic interactionism", "latency_ms": 119.14396286010742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "role theory", "latency_ms": 102.5388240814209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1403}, "3": {"k": 3, "answer": "role theory and identity theory", "latency_ms": 174.05128479003906, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2208}, "4": {"k": 4, "answer": "role theory", "latency_ms": 134.10329818725586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2930}, "5": {"k": 5, "answer": "role theory, identity theory", "latency_ms": 196.54488563537598, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3716}, "6": {"k": 6, "answer": "role theory, identity theory", "latency_ms": 202.65507698059082, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4461}}}
{"qid": "-2996227699820227347", "question": "who wrote the french declaration of the rights of man and of the citizen", "gold_answers": ["General Lafayette", "Lafayette", "Thomas Jefferson", "Honoré Mirabeau"], "shots": {"0": {"k": 0, "answer": "Marat", "latency_ms": 60.358285903930664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Marie-Jean Hérault de Séchelles", "latency_ms": 312.38722801208496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 682}, "2": {"k": 2, "answer": "Abbé Sieyès and the Marquis de Lafayette", "latency_ms": 339.3068313598633, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Abbé Sieyès, Marquis de Lafayette, Thomas Jefferson, Honoré Mirabeau", "latency_ms": 543.7107086181641, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "Abbé Sieyès, Marquis de Lafayette, Thomas Jefferson, Honoré Mirabeau", "latency_ms": 617.2878742218018, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 2659}, "5": {"k": 5, "answer": "Abbé Sieyès, Marquis de Lafayette, and Thomas Jefferson", "latency_ms": 476.5591621398926, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3310}, "6": {"k": 6, "answer": "Abbé Sieyès, Marquis de Lafayette, and Thomas Jefferson", "latency_ms": 633.7201595306396, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3975}}}
{"qid": "-2774109201029330685", "question": "who kidnapped ben in the deep end of the ocean", "gold_answers": ["celebrity alumna Cecil Lockhart", "Cecil Lockhart", "the celebrity alumna Cecil Lockhart"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 191.81299209594727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cecil Lockhart", "latency_ms": 124.84502792358398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Cecil Lockhart", "latency_ms": 121.9019889831543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1205}, "3": {"k": 3, "answer": "Cecil Lockhart", "latency_ms": 115.19622802734375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Cecil Lockhart", "latency_ms": 221.12226486206055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2497}, "5": {"k": 5, "answer": "Cecil Lockhart", "latency_ms": 177.91175842285156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3126}, "6": {"k": 6, "answer": "Cecil Lockhart", "latency_ms": 206.64429664611816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3690}}}
{"qid": "4005166739248694798", "question": "who wrote hit me baby one more time", "gold_answers": ["Max Martin"], "shots": {"0": {"k": 0, "answer": "Nicki Minaj", "latency_ms": 231.48131370544434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 128.2515525817871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 140.61570167541504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1203}, "3": {"k": 3, "answer": "Max Martin", "latency_ms": 136.23619079589844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1859}, "4": {"k": 4, "answer": "Max Martin", "latency_ms": 136.5823745727539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2509}, "5": {"k": 5, "answer": "Max Martin", "latency_ms": 155.66468238830566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3120}, "6": {"k": 6, "answer": "Max Martin", "latency_ms": 185.45961380004883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3699}}}
{"qid": "-4952146393851562148", "question": "where did remember the titans camp take place", "gold_answers": ["Gettysburg College"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 97.56779670715332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gettysburg College", "latency_ms": 195.74260711669922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Gettysburg College", "latency_ms": 268.90063285827637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1327}, "3": {"k": 3, "answer": "Gettysburg College", "latency_ms": 188.39526176452637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2012}, "4": {"k": 4, "answer": "Gettysburg College", "latency_ms": 273.1916904449463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2630}, "5": {"k": 5, "answer": "Gettysburg College", "latency_ms": 168.24030876159668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3234}, "6": {"k": 6, "answer": "Gettysburg College", "latency_ms": 227.16093063354492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3900}}}
{"qid": "6524766539964714821", "question": "who does the voice of amy on futurama", "gold_answers": ["Lauren Tom"], "shots": {"0": {"k": 0, "answer": "Judy Greer", "latency_ms": 102.83136367797852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lauren Tom", "latency_ms": 146.00157737731934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 644}, "2": {"k": 2, "answer": "Lauren Tom", "latency_ms": 186.63644790649414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1313}, "3": {"k": 3, "answer": "Lauren Tom", "latency_ms": 218.75691413879395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1993}, "4": {"k": 4, "answer": "Lauren Tom", "latency_ms": 180.47118186950684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2599}, "5": {"k": 5, "answer": "Lauren Tom", "latency_ms": 142.90380477905273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3203}, "6": {"k": 6, "answer": "Lauren Tom", "latency_ms": 168.93601417541504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3813}}}
{"qid": "8214065994334584031", "question": "when does the next season of wynonna earp start", "gold_answers": ["2018", "January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 147.19486236572266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2019", "latency_ms": 172.38473892211914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "2019", "latency_ms": 187.45803833007812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "2019", "latency_ms": 222.99933433532715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1800}, "4": {"k": 4, "answer": "2019", "latency_ms": 185.5473518371582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2393}, "5": {"k": 5, "answer": "2019", "latency_ms": 159.25073623657227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3017}, "6": {"k": 6, "answer": "2019", "latency_ms": 196.6254711151123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3668}}}
{"qid": "7161580128369190804", "question": "when did the song push it come out", "gold_answers": ["1987", "March 8 , 1987"], "shots": {"0": {"k": 0, "answer": "1996", "latency_ms": 123.16226959228516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "July 1997", "latency_ms": 214.5555019378662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "April 20, 1998", "latency_ms": 424.46327209472656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "April 20, 1998", "latency_ms": 304.2731285095215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "April 20, 1998", "latency_ms": 278.28454971313477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2495}, "5": {"k": 5, "answer": "April 20, 1998", "latency_ms": 333.07576179504395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3077}, "6": {"k": 6, "answer": "April 20, 1998", "latency_ms": 306.5524101257324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3699}}}
{"qid": "8002956316753524206", "question": "who plays the coach in old spice commercial", "gold_answers": ["Isaiah Amir Mustafa"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 106.97603225708008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dennis Hayden", "latency_ms": 70.23143768310547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "Dennis Hayden", "latency_ms": 112.13254928588867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "Dennis Hayden", "latency_ms": 95.26658058166504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Dennis Hayden", "latency_ms": 143.01371574401855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2593}, "5": {"k": 5, "answer": "Dennis Hayden", "latency_ms": 118.0734634399414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3282}, "6": {"k": 6, "answer": "Dennis Hayden", "latency_ms": 171.33617401123047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3914}}}
{"qid": "-2824167725181792943", "question": "when does the good doctor episode 8 air", "gold_answers": ["November 20 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 113.54708671569824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 110.35418510437012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 176.82909965515137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1201}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.82782936096191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 130.15317916870117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2536}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 178.47561836242676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 187.88695335388184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "-6777951254123103749", "question": "where does the movie road to perdition take place", "gold_answers": ["Chicago", "Rock Island , Illinois"], "shots": {"0": {"k": 0, "answer": "United States, Canada, and Europe", "latency_ms": 233.95442962646484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chicago area", "latency_ms": 132.81559944152832, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "1931, during the Great Depression, in the Chicago area", "latency_ms": 285.0947380065918, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "1931, during the Great Depression, in the Chicago area, including downtown Chicago, Pullman, Evanston, and Geneva, Illinois.", "latency_ms": 730.1890850067139, "em": 0.0, "f1": 0.125, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "1931, during the Great Depression, in the Chicago area, including Pullman, Evanston, and Geneva, Illinois.", "latency_ms": 713.7942314147949, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "1931, during the Great Depression, in the Chicago area, including Pullman, Evanston, and Geneva, Illinois.", "latency_ms": 682.7783584594727, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 3285}, "6": {"k": 6, "answer": "1931, during the Great Depression, in the Chicago area, including Pullman, Evanston, and Geneva, Illinois.", "latency_ms": 635.0283622741699, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 3892}}}
{"qid": "4498859822735171754", "question": "when was the nobel prize for literature first awarded", "gold_answers": ["1901"], "shots": {"0": {"k": 0, "answer": "1901", "latency_ms": 113.50202560424805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1901", "latency_ms": 111.29641532897949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "1901", "latency_ms": 202.04877853393555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1341}, "3": {"k": 3, "answer": "1901", "latency_ms": 127.9294490814209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1998}, "4": {"k": 4, "answer": "1901", "latency_ms": 165.69781303405762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2689}, "5": {"k": 5, "answer": "1901", "latency_ms": 225.32916069030762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3322}, "6": {"k": 6, "answer": "1901", "latency_ms": 286.91673278808594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3984}}}
{"qid": "-5172636572480122331", "question": "when did the subway open in new york", "gold_answers": ["October 27 , 1904", "1904"], "shots": {"0": {"k": 0, "answer": "1904", "latency_ms": 115.10396003723145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1844", "latency_ms": 141.28828048706055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "1844", "latency_ms": 96.6789722442627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "1844", "latency_ms": 144.31357383728027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "1844", "latency_ms": 114.1514778137207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "October 27, 1904", "latency_ms": 306.9581985473633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3236}, "6": {"k": 6, "answer": "October 27, 1904", "latency_ms": 264.9378776550293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3898}}}
{"qid": "-2256325923186334832", "question": "who owns the four seasons hotel in las vegas", "gold_answers": ["MGM Resorts International"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 186.25354766845703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sheldon Adelson", "latency_ms": 90.38114547729492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 179.5027256011963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 109.33208465576172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "Sheldon Adelson", "latency_ms": 211.20166778564453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2466}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 144.62924003601074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 158.94722938537598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3689}}}
{"qid": "-2084810583025911065", "question": "what type of boundary was the mexico earthquake", "gold_answers": ["a subduction zone"], "shots": {"0": {"k": 0, "answer": "convergent boundary", "latency_ms": 113.70348930358887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "convergent boundary", "latency_ms": 133.48937034606934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "convergent boundary", "latency_ms": 176.21445655822754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1336}, "3": {"k": 3, "answer": "convergent boundary", "latency_ms": 211.9741439819336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1997}, "4": {"k": 4, "answer": "convergent boundary", "latency_ms": 172.96147346496582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2656}, "5": {"k": 5, "answer": "convergent boundary", "latency_ms": 193.495512008667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3319}, "6": {"k": 6, "answer": "convergent boundary", "latency_ms": 224.98559951782227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3969}}}
{"qid": "4465854756996740675", "question": "who played michael jackson in jackson 5 movie", "gold_answers": ["Wylie Draper", "Abolade David Olatunde", "Jason Weaver", "Alex Burrall"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 180.73081970214844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 146.5613842010498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 167.29426383972168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 193.66097450256348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "Michael Jackson", "latency_ms": 118.76964569091797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2545}, "5": {"k": 5, "answer": "Michael Jackson", "latency_ms": 106.0948371887207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3199}, "6": {"k": 6, "answer": "Michael Jackson", "latency_ms": 154.16264533996582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3869}}}
{"qid": "8964424634747238850", "question": "who stars in kevin probably save the world", "gold_answers": ["JoAnna Garcia Swisher", "India de Beaufort", "Chloe East", "Dustin Ybarra", "J. August Richards", "Jason Ritter", "Kimberly Hebert Gregory"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 124.62854385375977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kimberly Hebert Gregory", "latency_ms": 214.9679660797119, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 667}, "2": {"k": 2, "answer": "Cristela Alonzo, Kimberly Hebert Gregory", "latency_ms": 468.1663513183594, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Kevin (Probably) Saves the World stars Kevin (Probably) Saves the World.", "latency_ms": 468.34516525268555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1933}, "4": {"k": 4, "answer": "Kevin (Probably) Saves the World stars Kevin (the lead character), his twin sister Amy, and Amy's teenage daughter Reese. The lead role of Kevin was originally played by Cristela Alonzo in the pilot, but was replaced by Kimberly Hebert Gregory.", "latency_ms": 1688.934087753296, "em": 0.0, "f1": 0.15384615384615385, "containment": 1.0, "context_chars": 2601}, "5": {"k": 5, "answer": "Jason Ritter", "latency_ms": 173.80452156066895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Jason Ritter", "latency_ms": 150.5587100982666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3802}}}
{"qid": "2428016859746479878", "question": "how many grams of alcohol in one beer", "gold_answers": ["14 grams", "14", "about 14 grams of alcohol"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 114.98379707336426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "15.2", "latency_ms": 230.48686981201172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "15.2", "latency_ms": 346.82154655456543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1194}, "3": {"k": 3, "answer": "14", "latency_ms": 144.9432373046875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1783}, "4": {"k": 4, "answer": "15.2", "latency_ms": 203.12762260437012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2428}, "5": {"k": 5, "answer": "15.2", "latency_ms": 188.9936923980713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3072}, "6": {"k": 6, "answer": "14", "latency_ms": 135.27488708496094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3664}}}
{"qid": "8616078013378632610", "question": "who said that religion is the opiate of the masses", "gold_answers": ["Karl Marx .", "Karl Marx"], "shots": {"0": {"k": 0, "answer": "Marx", "latency_ms": 163.283109664917, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Karl Marx", "latency_ms": 214.84112739562988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "Karl Marx", "latency_ms": 103.00135612487793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Karl Marx", "latency_ms": 168.48421096801758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1945}, "4": {"k": 4, "answer": "Karl Marx", "latency_ms": 233.45112800598145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2562}, "5": {"k": 5, "answer": "Karl Marx", "latency_ms": 205.1980495452881, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3236}, "6": {"k": 6, "answer": "Karl Marx", "latency_ms": 175.76909065246582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3838}}}
{"qid": "4333514272418210636", "question": "when was the us department of homeland security created", "gold_answers": ["November 25 , 2002"], "shots": {"0": {"k": 0, "answer": "2002", "latency_ms": 115.08584022521973, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "November 2002", "latency_ms": 114.94731903076172, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "November 2002", "latency_ms": 179.4259548187256, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1382}, "3": {"k": 3, "answer": "November 2002", "latency_ms": 153.1074047088623, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2048}, "4": {"k": 4, "answer": "November 25, 2002", "latency_ms": 265.5208110809326, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2759}, "5": {"k": 5, "answer": "November 25, 2002", "latency_ms": 294.7378158569336, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3508}, "6": {"k": 6, "answer": "November 25, 2002", "latency_ms": 325.46401023864746, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4267}}}
{"qid": "6971297271942455076", "question": "in the texas legislature the house has members and the senate has", "gold_answers": ["31 - member Senate", "member"], "shots": {"0": {"k": 0, "answer": "members", "latency_ms": 60.40191650390625, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "150, 31", "latency_ms": 126.05428695678711, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "150 and 31", "latency_ms": 262.04538345336914, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "150 and 31", "latency_ms": 188.57574462890625, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "150 and 31", "latency_ms": 208.65559577941895, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2517}, "5": {"k": 5, "answer": "150 and 31", "latency_ms": 299.36838150024414, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "150 and 31", "latency_ms": 269.64759826660156, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3846}}}
{"qid": "-819500006477510416", "question": "who played marius in the movie les miserables", "gold_answers": ["Eddie Redmayne"], "shots": {"0": {"k": 0, "answer": "Hugh Jackman", "latency_ms": 89.1265869140625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "José Guillermo Cortines", "latency_ms": 154.6039581298828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "Nick Jonas", "latency_ms": 72.0977783203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 177.69527435302734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1869}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 157.97924995422363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2458}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 181.32972717285156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3043}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 187.2732639312744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3612}}}
{"qid": "-1495205296169772734", "question": "green algae is an example of which type of reproduction", "gold_answers": ["alternation of generations", "alternation of generations ."], "shots": {"0": {"k": 0, "answer": "asexual reproduction", "latency_ms": 132.40313529968262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 154.94728088378906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 726}, "2": {"k": 2, "answer": "sexual reproduction", "latency_ms": 70.38664817810059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1398}, "3": {"k": 3, "answer": "asexual and sexual reproduction", "latency_ms": 157.41252899169922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2084}, "4": {"k": 4, "answer": "alternation of generations", "latency_ms": 118.04485321044922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2826}, "5": {"k": 5, "answer": "asexual and sexual reproduction", "latency_ms": 174.05033111572266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3509}, "6": {"k": 6, "answer": "isogamous, oogamous, conjugation", "latency_ms": 375.1845359802246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4148}}}
{"qid": "7926179542568614934", "question": "the winner of the best actor award in the 64th national film festival 2017", "gold_answers": ["Akshay Kumar", "Manoj Joshi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 99.5645523071289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Aamir Khan", "latency_ms": 160.33029556274414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 677}, "2": {"k": 2, "answer": "Aamir Khan", "latency_ms": 97.47862815856934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1332}, "3": {"k": 3, "answer": "Aamir Khan", "latency_ms": 195.3444480895996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2024}, "4": {"k": 4, "answer": "Aamir Khan", "latency_ms": 142.5149440765381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2696}, "5": {"k": 5, "answer": "Aamir Khan", "latency_ms": 158.80441665649414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3336}, "6": {"k": 6, "answer": "Aamir Khan", "latency_ms": 180.97662925720215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3982}}}
{"qid": "721377602050579902", "question": "who won every men's biathlon event in the 2002 winter olympics", "gold_answers": ["Ole Einar Bjørndalen", "Norway"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 81.0692310333252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 147.88365364074707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 143.61238479614258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 183.2573413848877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2025}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 179.2922019958496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2694}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 186.65385246276855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3351}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 199.9351978302002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4021}}}
{"qid": "1742175800641553404", "question": "when did brent barry won the dunk contest", "gold_answers": ["1996"], "shots": {"0": {"k": 0, "answer": "1990", "latency_ms": 110.02802848815918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1996", "latency_ms": 193.7997341156006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 590}, "2": {"k": 2, "answer": "1996", "latency_ms": 144.07014846801758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1198}, "3": {"k": 3, "answer": "1996", "latency_ms": 230.79514503479004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1824}, "4": {"k": 4, "answer": "1996", "latency_ms": 142.472505569458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2485}, "5": {"k": 5, "answer": "1996", "latency_ms": 159.11078453063965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3130}, "6": {"k": 6, "answer": "1996", "latency_ms": 158.13016891479492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3816}}}
{"qid": "-5109121702669039643", "question": "when was the first orca put in captivity", "gold_answers": ["November 1961", "in the 1960s"], "shots": {"0": {"k": 0, "answer": "1911", "latency_ms": 142.11797714233398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1964", "latency_ms": 153.6252498626709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "1964", "latency_ms": 169.25334930419922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "1964", "latency_ms": 170.37534713745117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1944}, "4": {"k": 4, "answer": "November 1961", "latency_ms": 175.32849311828613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2571}, "5": {"k": 5, "answer": "November 1961", "latency_ms": 234.04240608215332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3153}, "6": {"k": 6, "answer": "November 1961", "latency_ms": 245.67914009094238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3797}}}
{"qid": "-962041795410987294", "question": "first day collection of mission china assamese film", "gold_answers": ["₹ 39.97 lakh"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 145.87855339050293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "39.97 lakh", "latency_ms": 189.53800201416016, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "39.97 lakh", "latency_ms": 213.59920501708984, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "39.97 lakh", "latency_ms": 202.12221145629883, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "39.97 lakh", "latency_ms": 201.72882080078125, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "39.97 lakh", "latency_ms": 372.3106384277344, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3220}, "6": {"k": 6, "answer": "39.97 lakh", "latency_ms": 197.6933479309082, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3905}}}
{"qid": "-2968129491710503983", "question": "who are the co hosts on the real", "gold_answers": ["Jeannie Mai", "Tamera Mowry - Housley", "Tamar Braxton", "Loni Love", "Adrienne Houghton"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 125.69642066955566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 148.57959747314453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Saad Haroon and Danish Ali", "latency_ms": 281.5289497375488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Saad Haroon and Danish Ali", "latency_ms": 294.30294036865234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Saad Haroon and Danish Ali", "latency_ms": 265.81358909606934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "Saad Haroon and Danish Ali", "latency_ms": 266.1173343658447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Sharon Caddy and Tanya Prokomenko", "latency_ms": 324.6188163757324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3779}}}
{"qid": "2577505384728133630", "question": "who is the longest serving chief minister in india as on jan 2015", "gold_answers": ["Jyotirindra Basu"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 125.98562240600586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jyoti Basu", "latency_ms": 246.9937801361084, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "Atal Bihari Vajpayee", "latency_ms": 265.9587860107422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1304}, "3": {"k": 3, "answer": "Jyoti Basu", "latency_ms": 172.7283000946045, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Jyoti Basu", "latency_ms": 244.09890174865723, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2539}, "5": {"k": 5, "answer": "Jyoti Basu", "latency_ms": 253.1445026397705, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3193}, "6": {"k": 6, "answer": "Jyoti Basu", "latency_ms": 236.9668483734131, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-2861358222688121748", "question": "most runs ever scored in a mlb inning", "gold_answers": ["18"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 174.64852333068848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 RBI", "latency_ms": 167.74344444274902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "8", "latency_ms": 104.35128211975098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1143}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 198.14085960388184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1777}, "4": {"k": 4, "answer": "8", "latency_ms": 90.35468101501465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2325}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 182.8927993774414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2930}, "6": {"k": 6, "answer": "5", "latency_ms": 102.10919380187988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3526}}}
{"qid": "1624012912518696153", "question": "who brought the idea of castles to england", "gold_answers": ["Norman invaders"], "shots": {"0": {"k": 0, "answer": "William the Conqueror", "latency_ms": 164.85261917114258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "William the Conqueror", "latency_ms": 165.6184196472168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "Ethelred II and his Norman queen Emma", "latency_ms": 339.6413326263428, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "Ethelred II and his Norman queen Emma", "latency_ms": 350.33154487609863, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "Ethelred II and his Norman queen Emma", "latency_ms": 275.0866413116455, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2649}, "5": {"k": 5, "answer": "Ethelred II and his Norman queen Emma", "latency_ms": 348.4013080596924, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 3338}, "6": {"k": 6, "answer": "Ethelred II and his Norman queen Emma", "latency_ms": 409.92188453674316, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 3958}}}
{"qid": "2048375334691290812", "question": "what were the two causes of the dust bowl", "gold_answers": ["severe drought"], "shots": {"0": {"k": 0, "answer": "Dry climate and poor farming practices", "latency_ms": 216.8259620666504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "drought and deep plowing", "latency_ms": 198.58813285827637, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "drought and poor farming practices", "latency_ms": 200.86097717285156, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "severe drought and failure to apply dryland farming methods", "latency_ms": 437.9229545593262, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "severe drought and failure to apply dryland farming methods", "latency_ms": 405.20763397216797, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 2490}, "5": {"k": 5, "answer": "severe drought and failure to apply dryland farming methods", "latency_ms": 484.23218727111816, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3154}, "6": {"k": 6, "answer": "severe drought and failure to apply dryland farming methods", "latency_ms": 338.5281562805176, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3731}}}
{"qid": "-3239096899891702759", "question": "who becomes chief resident on grey's anatomy season 7", "gold_answers": ["Kepner", "April Kepner M.D."], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 162.66965866088867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 173.0365753173828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 729}, "2": {"k": 2, "answer": "April Kirsten", "latency_ms": 168.48516464233398, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1396}, "3": {"k": 3, "answer": "April Kirsten Keppler", "latency_ms": 302.54149436950684, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2133}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 168.7924861907959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2795}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 172.64389991760254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3534}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 167.2358512878418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4223}}}
{"qid": "-1052450681419062019", "question": "who has won the 2017 mens singles mutua madrid open tennis", "gold_answers": ["Rafael Nadal"], "shots": {"0": {"k": 0, "answer": "Novak Djokovic", "latency_ms": 218.6899185180664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 192.98839569091797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 202.53992080688477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 164.06011581420898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 145.34640312194824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2557}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 183.0446720123291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 264.8961544036865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3802}}}
{"qid": "1122374124159656329", "question": "who plays the dad in drake and josh", "gold_answers": ["Jonathan Goldstein"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 261.732816696167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 223.13261032104492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "John Ducey", "latency_ms": 128.0381679534912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1217}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 171.72002792358398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1868}, "4": {"k": 4, "answer": "Walter", "latency_ms": 104.60591316223145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Jonathan Goldstein", "latency_ms": 150.71725845336914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3148}, "6": {"k": 6, "answer": "John Ducey", "latency_ms": 239.03894424438477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3767}}}
{"qid": "-7607131122991447947", "question": "in which country were the two battles of el alamein fought", "gold_answers": ["Egypt"], "shots": {"0": {"k": 0, "answer": "Egypt", "latency_ms": 88.2411003112793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Egypt", "latency_ms": 115.76080322265625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Egypt", "latency_ms": 123.88348579406738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1255}, "3": {"k": 3, "answer": "Egypt", "latency_ms": 69.98658180236816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1868}, "4": {"k": 4, "answer": "Egypt", "latency_ms": 222.14746475219727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2512}, "5": {"k": 5, "answer": "Egypt", "latency_ms": 88.29784393310547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3133}, "6": {"k": 6, "answer": "Egypt", "latency_ms": 108.72626304626465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3786}}}
{"qid": "1917917794187892676", "question": "who gets the most punishments on impractical jokers", "gold_answers": ["Sal"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 123.63791465759277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Joker with the most thumbs down", "latency_ms": 145.57385444641113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "Joker with the most thumbs down", "latency_ms": 227.8590202331543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Sal Salvador", "latency_ms": 95.18671035766602, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1872}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 224.46370124816895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 197.19171524047852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 198.24552536010742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3776}}}
{"qid": "-4933703924077588548", "question": "baga beach is in north or south goa", "gold_answers": ["North", "North Goa"], "shots": {"0": {"k": 0, "answer": "South Goa", "latency_ms": 68.7265396118164, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "north", "latency_ms": 104.86292839050293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 572}, "2": {"k": 2, "answer": "north", "latency_ms": 58.132171630859375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1156}, "3": {"k": 3, "answer": "north", "latency_ms": 69.38695907592773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1765}, "4": {"k": 4, "answer": "north", "latency_ms": 103.38115692138672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2357}, "5": {"k": 5, "answer": "north", "latency_ms": 143.8729763031006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2968}, "6": {"k": 6, "answer": "North Goa", "latency_ms": 105.66186904907227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3595}}}
{"qid": "6933510789136260390", "question": "when was the first case of alzheimer's diagnosed", "gold_answers": ["1901"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 127.29930877685547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1906", "latency_ms": 201.83229446411133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "1906", "latency_ms": 245.20301818847656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1351}, "3": {"k": 3, "answer": "1906", "latency_ms": 254.61578369140625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2039}, "4": {"k": 4, "answer": "1906", "latency_ms": 199.7826099395752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2665}, "5": {"k": 5, "answer": "1906", "latency_ms": 180.0525188446045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3390}, "6": {"k": 6, "answer": "1906", "latency_ms": 223.13618659973145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4056}}}
{"qid": "3595629551292543052", "question": "who wrote the theme to last of the mohicans", "gold_answers": ["Dougie MacLean"], "shots": {"0": {"k": 0, "answer": "James Bond", "latency_ms": 85.83855628967285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dougie MacLean", "latency_ms": 171.4763641357422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Dougie MacLean", "latency_ms": 196.73800468444824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Dougie MacLean", "latency_ms": 202.1324634552002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2015}, "4": {"k": 4, "answer": "Dougie MacLean", "latency_ms": 198.6370086669922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Dougie MacLean", "latency_ms": 244.75646018981934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3331}, "6": {"k": 6, "answer": "Dougie MacLean", "latency_ms": 179.12936210632324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3990}}}
{"qid": "-4804889058718384357", "question": "who was the german leader who signed the treaty of versailles", "gold_answers": ["President Friedrich Ebert", "Gustav Bauer"], "shots": {"0": {"k": 0, "answer": "Wilhelm II", "latency_ms": 94.98453140258789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Otto von Bismarck", "latency_ms": 285.07471084594727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Otto von Bismarck", "latency_ms": 210.2210521697998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Otto von Bismarck", "latency_ms": 182.54685401916504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1973}, "4": {"k": 4, "answer": "Friedrich Ebert", "latency_ms": 218.48440170288086, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2622}, "5": {"k": 5, "answer": "Hermann Müller", "latency_ms": 165.1439666748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3269}, "6": {"k": 6, "answer": "Hermann Müller", "latency_ms": 227.4165153503418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3902}}}
{"qid": "6722449797327374201", "question": "where is fight or flight in the brain", "gold_answers": ["the adrenal medulla"], "shots": {"0": {"k": 0, "answer": "amygdala", "latency_ms": 68.05801391601562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "amygdala", "latency_ms": 200.3762722015381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 731}, "2": {"k": 2, "answer": "amygdala", "latency_ms": 105.42702674865723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1511}, "3": {"k": 3, "answer": "amygdala", "latency_ms": 123.97193908691406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2167}, "4": {"k": 4, "answer": "amygdala", "latency_ms": 131.3173770904541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2871}, "5": {"k": 5, "answer": "amygdala, hypothalamus", "latency_ms": 307.4052333831787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3632}, "6": {"k": 6, "answer": "amygdala", "latency_ms": 218.7364101409912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4308}}}
{"qid": "8409182335460652649", "question": "who played stonewall jackson in gods and generals", "gold_answers": ["Stephen Lang"], "shots": {"0": {"k": 0, "answer": "Dustin Hoffman", "latency_ms": 181.915283203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stephen Lang", "latency_ms": 129.62031364440918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Stephen Lang", "latency_ms": 111.17696762084961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1315}, "3": {"k": 3, "answer": "Stephen Lang", "latency_ms": 113.10958862304688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1956}, "4": {"k": 4, "answer": "Stephen Lang", "latency_ms": 138.14711570739746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2595}, "5": {"k": 5, "answer": "Stephen Lang", "latency_ms": 150.8021354675293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Stephen Lang", "latency_ms": 183.86268615722656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3808}}}
{"qid": "8129226506978989056", "question": "where does the phrase dressed to the nines", "gold_answers": ["Scots in origin"], "shots": {"0": {"k": 0, "answer": "originated in 17th century England", "latency_ms": 453.91058921813965, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Scots origin", "latency_ms": 165.28058052062988, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Scots origin", "latency_ms": 96.15898132324219, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Scots origin", "latency_ms": 122.43342399597168, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "99th Foot", "latency_ms": 163.44881057739258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2502}, "5": {"k": 5, "answer": "Scots origin", "latency_ms": 152.64558792114258, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3121}, "6": {"k": 6, "answer": "Scots origin", "latency_ms": 182.36446380615234, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3771}}}
{"qid": "-2154275263565518616", "question": "what color is the golden gate bridge in san francisco", "gold_answers": ["International Orange", "red", "orange vermilion called international orange"], "shots": {"0": {"k": 0, "answer": "Golden Gate Bridge is red.", "latency_ms": 240.01669883728027, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 106.52947425842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "red", "latency_ms": 58.49647521972656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1275}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 176.87344551086426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 146.82936668395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "blue", "latency_ms": 87.33439445495605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "blue", "latency_ms": 120.97287178039551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3789}}}
{"qid": "7037852711673324115", "question": "what type of car is a g wagon", "gold_answers": ["Mercedes - Benz"], "shots": {"0": {"k": 0, "answer": "Volkswagen Golf", "latency_ms": 178.12442779541016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 148.80824089050293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 550}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 226.04775428771973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1129}, "3": {"k": 3, "answer": "goods wagon", "latency_ms": 86.84039115905762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1777}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 126.72185897827148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2347}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 231.9338321685791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3036}, "6": {"k": 6, "answer": "station wagon", "latency_ms": 108.67190361022949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3657}}}
{"qid": "7732412227546021398", "question": "who sings angel of the morning in deadpool", "gold_answers": ["Juice Newton", "Juice Newton 's"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 136.8873119354248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Peter Griffin", "latency_ms": 114.77947235107422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Emily Blunt", "latency_ms": 172.7883815765381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "Juice Newton", "latency_ms": 143.0361270904541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Juice Newton", "latency_ms": 137.44044303894043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2517}, "5": {"k": 5, "answer": "Juice Newton", "latency_ms": 130.67340850830078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3124}, "6": {"k": 6, "answer": "Juice Newton", "latency_ms": 155.42268753051758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3739}}}
{"qid": "-6068529343782396685", "question": "who did kenny rogers sing mary did you know with", "gold_answers": ["Wynonna Judd"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 132.21287727355957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wynonna Judd", "latency_ms": 190.6149387359619, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 628}, "2": {"k": 2, "answer": "Wynonna Judd", "latency_ms": 191.76793098449707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1276}, "3": {"k": 3, "answer": "Wynonna Judd", "latency_ms": 187.71719932556152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1900}, "4": {"k": 4, "answer": "Wynonna Judd", "latency_ms": 149.04356002807617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2510}, "5": {"k": 5, "answer": "Wynonna Judd", "latency_ms": 193.86529922485352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Wynonna Judd", "latency_ms": 157.8686237335205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3873}}}
{"qid": "-7070472892925791621", "question": "when is the new series of keeping faith starting", "gold_answers": ["13 February 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 162.7829074859619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 92.99612045288086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "12 July 2018", "latency_ms": 220.14689445495605, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "autumn 2018", "latency_ms": 195.91116905212402, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1847}, "4": {"k": 4, "answer": "autumn 2018", "latency_ms": 198.19235801696777, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "autumn 2018", "latency_ms": 202.87132263183594, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "autumn 2018", "latency_ms": 267.2708034515381, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3819}}}
{"qid": "-7951194946868878283", "question": "how many seasons of ray donovan has there been", "gold_answers": ["5"], "shots": {"0": {"k": 0, "answer": "4", "latency_ms": 88.7289047241211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "6", "latency_ms": 50.511837005615234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "6", "latency_ms": 58.49623680114746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "6", "latency_ms": 122.34854698181152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "6", "latency_ms": 153.81741523742676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2533}, "5": {"k": 5, "answer": "6", "latency_ms": 110.81099510192871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3088}, "6": {"k": 6, "answer": "6", "latency_ms": 103.95932197570801, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3694}}}
{"qid": "-7843232313103404498", "question": "what was the united states foreign policy after ww1 started", "gold_answers": ["neutrality"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 158.7069034576416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 112.60652542114258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 130.8131217956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1374}, "3": {"k": 3, "answer": "non-interventionist policies on Europe at the start of World War II", "latency_ms": 468.6136245727539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2057}, "4": {"k": 4, "answer": "non-interventionist policies on Europe at the start of World War II", "latency_ms": 263.44799995422363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2726}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 126.82271003723145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3385}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 147.38941192626953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4031}}}
{"qid": "-8491993331568056625", "question": "when did world war 2 end in the pacific", "gold_answers": ["14 and 15 August 1945", "September 2 , 1945"], "shots": {"0": {"k": 0, "answer": "September 2, 1945", "latency_ms": 270.88403701782227, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "August 15, 1945", "latency_ms": 396.7599868774414, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "September 2, 1945", "latency_ms": 413.94591331481934, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "September 2, 1945", "latency_ms": 299.8321056365967, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "September 2, 1945", "latency_ms": 366.92237854003906, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2492}, "5": {"k": 5, "answer": "September 2, 1945", "latency_ms": 476.09663009643555, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3157}, "6": {"k": 6, "answer": "September 2, 1945", "latency_ms": 249.6335506439209, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3718}}}
{"qid": "-6281263110946016384", "question": "how many seasons of vampire diaries r there", "gold_answers": ["eight", "8"], "shots": {"0": {"k": 0, "answer": "7", "latency_ms": 58.93206596374512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8", "latency_ms": 72.41439819335938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "8", "latency_ms": 106.3380241394043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "8", "latency_ms": 152.47774124145508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1922}, "4": {"k": 4, "answer": "8", "latency_ms": 155.1191806793213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2600}, "5": {"k": 5, "answer": "8", "latency_ms": 198.62842559814453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3239}, "6": {"k": 6, "answer": "8", "latency_ms": 124.72891807556152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3895}}}
{"qid": "-794776326007094837", "question": "what is the legal age for marriage in australia", "gold_answers": ["18"], "shots": {"0": {"k": 0, "answer": "18 years", "latency_ms": 135.92982292175293, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 121.13833427429199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "18 years old", "latency_ms": 152.07457542419434, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1305}, "3": {"k": 3, "answer": "18 years old", "latency_ms": 190.34099578857422, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1942}, "4": {"k": 4, "answer": "18 years old", "latency_ms": 177.98161506652832, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2648}, "5": {"k": 5, "answer": "18 years old", "latency_ms": 144.6981430053711, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3293}, "6": {"k": 6, "answer": "18 years old", "latency_ms": 161.85784339904785, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3990}}}
{"qid": "-525942396749510966", "question": "who played doctor smith in lost in space", "gold_answers": ["Jonathan Harris"], "shots": {"0": {"k": 0, "answer": "Raymond Burr", "latency_ms": 99.43270683288574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parker Posey", "latency_ms": 140.61808586120605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Jonathan Harris", "latency_ms": 143.98860931396484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Jonathan Harris", "latency_ms": 96.53329849243164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1937}, "4": {"k": 4, "answer": "Jonathan Harris", "latency_ms": 156.5072536468506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2585}, "5": {"k": 5, "answer": "Jonathan Harris", "latency_ms": 118.39032173156738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3191}, "6": {"k": 6, "answer": "Jonathan Harris", "latency_ms": 125.46396255493164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3871}}}
{"qid": "-693976483726807411", "question": "when does jo come in grey's anatomy", "gold_answers": ["2012", "July 2012", "season 9"], "shots": {"0": {"k": 0, "answer": "Season 13, Episode 10 \"The Good, the Bad and the Ugly\"", "latency_ms": 547.321081161499, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "February 10, 2017", "latency_ms": 223.44422340393066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 681}, "2": {"k": 2, "answer": "October 22, 2015", "latency_ms": 253.36575508117676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1370}, "3": {"k": 3, "answer": "October 22, 2015", "latency_ms": 282.7725410461426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2031}, "4": {"k": 4, "answer": "October 2, 2014", "latency_ms": 338.35434913635254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2652}, "5": {"k": 5, "answer": "October 2, 2014", "latency_ms": 278.1236171722412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3261}, "6": {"k": 6, "answer": "October 2, 2014", "latency_ms": 225.02923011779785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3909}}}
{"qid": "-449556917090943542", "question": "what is the most common cause of right ventricular heart failure", "gold_answers": ["pulmonary heart disease", "left - sided heart failure"], "shots": {"0": {"k": 0, "answer": "Pulmonary hypertension", "latency_ms": 152.50134468078613, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "left-sided heart failure", "latency_ms": 84.12408828735352, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "left-sided heart failure", "latency_ms": 189.50963020324707, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1399}, "3": {"k": 3, "answer": "left-sided heart failure", "latency_ms": 132.73215293884277, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2043}, "4": {"k": 4, "answer": "left-sided heart failure", "latency_ms": 158.71763229370117, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2753}, "5": {"k": 5, "answer": "left-sided heart failure", "latency_ms": 163.32483291625977, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3465}, "6": {"k": 6, "answer": "left-sided heart failure", "latency_ms": 198.2595920562744, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 4253}}}
{"qid": "-7709514949207095031", "question": "what are the four requirements to establish criminal liability for gross negligence manslaughter", "gold_answers": ["the defendant breached this duty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 78.51362228393555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "duty of care, breach of duty, risk of death, obvious to reasonable prudent person", "latency_ms": 494.6143627166748, "em": 0.0, "f1": 0.11111111111111112, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "duty of care, breach of that duty, risk of death obvious to a reasonable prudent person, death resulting from the breach", "latency_ms": 712.2797966003418, "em": 0.0, "f1": 0.08695652173913043, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "duty of care, breach of duty, risk of death obvious to a reasonable prudent person, death resulting from breach", "latency_ms": 575.7913589477539, "em": 0.0, "f1": 0.0909090909090909, "containment": 0.0, "context_chars": 1996}, "4": {"k": 4, "answer": "duty of care, breach of duty, risk of death obvious to a reasonable person, death resulting from breach", "latency_ms": 696.7349052429199, "em": 0.0, "f1": 0.09523809523809523, "containment": 0.0, "context_chars": 2678}, "5": {"k": 5, "answer": "four stage Adomako Test", "latency_ms": 180.96923828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3307}, "6": {"k": 6, "answer": "four stage Adomako Test", "latency_ms": 231.12106323242188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3971}}}
{"qid": "7397542791834822732", "question": "why dry ether is used in woods reaction", "gold_answers": ["to form a higher alkane"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 194.24200057983398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 149.54543113708496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 164.75868225097656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "to exclude atmospheric moisture", "latency_ms": 126.87039375305176, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1996}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 169.50440406799316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2623}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 127.99334526062012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3290}, "6": {"k": 6, "answer": "to exclude atmospheric moisture and prevent peroxide formation", "latency_ms": 264.88780975341797, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 3949}}}
{"qid": "3384693042822879189", "question": "where was the new pete's dragon filmed", "gold_answers": ["New Zealand"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 109.96460914611816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bay of Plenty, Taupo, Wellington, Rotorua, Tapanui", "latency_ms": 438.6610984802246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "Bay of Plenty, Taupo, Wellington, Rotorua, Tapanui", "latency_ms": 438.33327293395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Bay of Plenty, Taupo, Wellington, Rotorua, Tapanui", "latency_ms": 538.7670993804932, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Bay of Plenty, Taupo, Wellington, Rotorua, Tapanui", "latency_ms": 669.5520877838135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2522}, "5": {"k": 5, "answer": "New Zealand, Wellington, Rotorua, Tapanui", "latency_ms": 356.11891746520996, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3177}, "6": {"k": 6, "answer": "New Zealand, Wellington, Rotorua, Tapanui", "latency_ms": 378.3588409423828, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3813}}}
{"qid": "-6818895183782666995", "question": "is it marley and me or marley and i", "gold_answers": ["Marley & Me"], "shots": {"0": {"k": 0, "answer": "Marley and Me", "latency_ms": 126.43098831176758, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Marley & Me", "latency_ms": 192.77191162109375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 581}, "2": {"k": 2, "answer": "Marley & Me", "latency_ms": 310.24956703186035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "Marley & Me", "latency_ms": 206.99763298034668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1792}, "4": {"k": 4, "answer": "Marley & Me", "latency_ms": 158.9651107788086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2387}, "5": {"k": 5, "answer": "Marley & Me", "latency_ms": 185.31298637390137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2997}, "6": {"k": 6, "answer": "Marley & Me", "latency_ms": 204.48613166809082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3553}}}
{"qid": "-6142762219955413493", "question": "where was a hologram for the king filmed", "gold_answers": ["Egypt", "Berlin", "Berlin and Düsseldorf in Germany", "Morocco", "Düsseldorf in Germany", "Hurghada in Egypt", "Germany"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 200.04916191101074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Morocco, Hurghada, Egypt, Berlin, Düsseldorf, Germany", "latency_ms": 569.7140693664551, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 661}, "2": {"k": 2, "answer": "Morocco, Hurghada in Egypt, Berlin, Düsseldorf in Germany", "latency_ms": 449.30553436279297, "em": 0.0, "f1": 0.6153846153846154, "containment": 1.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Morocco, Hurghada in Egypt, Berlin, Düsseldorf in Germany", "latency_ms": 634.6979141235352, "em": 0.0, "f1": 0.6153846153846154, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "Morocco, Hurghada in Egypt, Berlin, Düsseldorf in Germany", "latency_ms": 575.2103328704834, "em": 0.0, "f1": 0.6153846153846154, "containment": 1.0, "context_chars": 2485}, "5": {"k": 5, "answer": "Morocco, Hurghada in Egypt, Berlin, Düsseldorf in Germany", "latency_ms": 767.4248218536377, "em": 0.0, "f1": 0.6153846153846154, "containment": 1.0, "context_chars": 3081}, "6": {"k": 6, "answer": "Morocco, Hurghada in Egypt, Berlin, Düsseldorf in Germany", "latency_ms": 420.835018157959, "em": 0.0, "f1": 0.6153846153846154, "containment": 1.0, "context_chars": 3700}}}
{"qid": "-1212091124373260265", "question": "who inaugurated 'world teachers' day'", "gold_answers": ["ILO", "UNESCO"], "shots": {"0": {"k": 0, "answer": "UNESCO", "latency_ms": 52.7348518371582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNESCO/ILO", "latency_ms": 166.5034294128418, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 726}, "2": {"k": 2, "answer": "UNESCO/ILO", "latency_ms": 195.74785232543945, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1431}, "3": {"k": 3, "answer": "UNESCO/ILO", "latency_ms": 158.9653491973877, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2117}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 223.47450256347656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2735}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 211.0304832458496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3405}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 175.6131649017334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4025}}}
{"qid": "6402415816213721626", "question": "what kind of animals live in the great victoria desert", "gold_answers": ["sand goanna", "malleefowl", "perentie", "great desert skink", "chestnut - breasted whiteface", "southern marsupial mole", "sandhill dunnart", "dingo", "water - holding frog", "crest - tailed mulgara"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 132.17425346374512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "lizards, small marsupials, southern marsupial mole, Central Ranges taipan", "latency_ms": 606.9698333740234, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 772}, "2": {"k": 2, "answer": "lizards, marsupials, frogs, birds, monitor lizards, dingo, southern marsupial mole", "latency_ms": 785.3214740753174, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1483}, "3": {"k": 3, "answer": "lizards, small marsupials, frogs, birds, dingo, monitor lizards", "latency_ms": 483.37602615356445, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2195}, "4": {"k": 4, "answer": "lizards, small marsupials, frogs, birds, dingo, monitor lizards", "latency_ms": 809.6370697021484, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2847}, "5": {"k": 5, "answer": "lizards, small marsupials, frogs, birds, dingo, perentie, sand goanna, sandhill dunnart, crest-tailed mulgara, great desert skink, southern marsupial mole", "latency_ms": 1597.0070362091064, "em": 0.0, "f1": 0.2727272727272727, "containment": 1.0, "context_chars": 3513}, "6": {"k": 6, "answer": "lizards, marsupials, birds, monitor lizards, dingo, southern marsupial mole, sandhill dunnart, crest-tailed mulgara, great desert skink, Central Ranges taipan, water-holding frog, chestnut-breasted whiteface, malleefowl, perentie, sand goanna", "latency_ms": 2375.9608268737793, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 4201}}}
{"qid": "2570826170217451399", "question": "what is the oath that new citizens take", "gold_answers": ["United States Oath of Allegiance"], "shots": {"0": {"k": 0, "answer": "Oath of Allegiance", "latency_ms": 172.9121208190918, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Oath of Citizenship", "latency_ms": 102.07796096801758, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Oath of citizenship", "latency_ms": 89.47181701660156, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Oath of citizenship", "latency_ms": 164.7341251373291, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "Oath of Citizenship", "latency_ms": 144.31452751159668, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2517}, "5": {"k": 5, "answer": "Oath of Citizenship", "latency_ms": 169.0998077392578, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Oath of Citizenship", "latency_ms": 231.09817504882812, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3739}}}
{"qid": "-2325138904790635180", "question": "active absorption of water from the soil by the root is mainly affected by", "gold_answers": ["ATP", "SURFACE AREA OF ROOTS"], "shots": {"0": {"k": 0, "answer": "root pressure", "latency_ms": 143.5091495513916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "solute concentration and water potential", "latency_ms": 141.25871658325195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "solute concentration and water potential", "latency_ms": 174.93677139282227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "ATP", "latency_ms": 71.8386173248291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1960}, "4": {"k": 4, "answer": "water potential gradient", "latency_ms": 132.27224349975586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2640}, "5": {"k": 5, "answer": "solute concentration and water potential gradient", "latency_ms": 281.71467781066895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3302}, "6": {"k": 6, "answer": "metabolic energy from root respiration", "latency_ms": 254.61959838867188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3983}}}
{"qid": "2499410242916851494", "question": "eukaryotes have how many origins of dna replication", "gold_answers": ["up to 100,000"], "shots": {"0": {"k": 0, "answer": "multiple", "latency_ms": 41.46575927734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "one thousand", "latency_ms": 78.70626449584961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 681}, "2": {"k": 2, "answer": "one thousand", "latency_ms": 64.41164016723633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1334}, "3": {"k": 3, "answer": "one thousand or more", "latency_ms": 108.70504379272461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2053}, "4": {"k": 4, "answer": "one thousand or more", "latency_ms": 148.3166217803955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2794}, "5": {"k": 5, "answer": "one thousand or more", "latency_ms": 216.19701385498047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3515}, "6": {"k": 6, "answer": "one thousand or more", "latency_ms": 153.5179615020752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4156}}}
{"qid": "-873221229677720991", "question": "who played tom hagon in the godfather series", "gold_answers": ["Robert Duvall"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 106.12082481384277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Robert Duvall", "latency_ms": 102.41413116455078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 628}, "2": {"k": 2, "answer": "Robert Duvall", "latency_ms": 198.11081886291504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Robert Duvall", "latency_ms": 128.87310981750488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Robert Duvall", "latency_ms": 149.88970756530762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "Robert Duvall", "latency_ms": 164.7477149963379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3146}, "6": {"k": 6, "answer": "Robert Duvall", "latency_ms": 159.46602821350098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3770}}}
{"qid": "8562240844982075116", "question": "where are alkali metals located on the periodic table", "gold_answers": ["group 1", "in the s - block"], "shots": {"0": {"k": 0, "answer": "Group 1", "latency_ms": 66.0409927368164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "s-block", "latency_ms": 113.55113983154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 688}, "2": {"k": 2, "answer": "s-block of the periodic table", "latency_ms": 194.02718544006348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Group 1", "latency_ms": 155.11274337768555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Group 1", "latency_ms": 175.69994926452637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2573}, "5": {"k": 5, "answer": "Group 1", "latency_ms": 149.15871620178223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3173}, "6": {"k": 6, "answer": "Group 1", "latency_ms": 192.09861755371094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3815}}}
{"qid": "1133135656128481203", "question": "who sings the theme tune to mum on bbc2", "gold_answers": ["Lulu and the Lampshades"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 97.32818603515625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bob Monkhouse", "latency_ms": 155.1353931427002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 150.12049674987793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 196.13099098205566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 171.58842086791992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2517}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 198.23312759399414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 186.38062477111816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3742}}}
