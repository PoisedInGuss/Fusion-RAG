{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Rita Skeeter", "latency_ms": 1235.060691833496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1367.553472518921, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1969.2044258117676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1196}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2316.702365875244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2644.606590270996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3630.873918533325, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3099}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3298.0737686157227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3727}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1266.0548686981201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 1600.684404373169, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 1944.1535472869873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 2474.7841358184814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1950}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 2838.4642601013184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 3066.8861865997314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 3749.190092086792, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3867}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwestern United States and Mexico", "latency_ms": 1643.873691558838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 2674.2658615112305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 3178.0495643615723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 4132.798433303833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 4166.538715362549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 4530.778646469116, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3315}, "6": {"k": 6, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 4987.389087677002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3929}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 1640.564203262329, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rajendra Prasad", "latency_ms": 1621.413230895996, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Dr. Rajendra Prasad", "latency_ms": 2638.9636993408203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1441}, "3": {"k": 3, "answer": "Dr. Rajendra Prasad", "latency_ms": 2796.6718673706055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2126}, "4": {"k": 4, "answer": "Dr. Rajendra Prasad", "latency_ms": 3194.312334060669, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2764}, "5": {"k": 5, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 3847.6052284240723, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3463}, "6": {"k": 6, "answer": "Dr. Rajendra Prasad", "latency_ms": 3383.690357208252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4137}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1294.8970794677734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2037.6720428466797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2627.6543140411377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2578.4435272216797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2929.917573928833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2586}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3607.4752807617188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3277}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3752.64573097229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "2001", "latency_ms": 1313.410997390747, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "April 3, 2009", "latency_ms": 2679.8009872436523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "April 3, 2009", "latency_ms": 2905.724287033081, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "1955", "latency_ms": 3135.0321769714355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "1955", "latency_ms": 2638.563394546509, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "1955", "latency_ms": 3228.3201217651367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3123}, "6": {"k": 6, "answer": "1955", "latency_ms": 4328.592300415039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3781}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1267.3029899597168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wednesday at 8:00 PM", "latency_ms": 2742.5413131713867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1971.942663192749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2587.3610973358154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3798.6843585968018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2739}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3060.9753131866455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3445}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 4045.930862426758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4141}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1259.1784000396729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "not specified in context", "latency_ms": 1407.8254699707031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "after the mid-season finale episode \"Sectionals\"", "latency_ms": 3305.030345916748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "after the mid-season finale episode \"Sectionals\"", "latency_ms": 4139.483451843262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "after the mid-season finale episode \"Sectionals\"", "latency_ms": 3943.0575370788574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2430}, "5": {"k": 5, "answer": "after the mid-season finale episode \"Sectionals\"", "latency_ms": 4670.181512832642, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3053}, "6": {"k": 6, "answer": "after the mid-season finale episode \"Sectionals\"", "latency_ms": 4245.935678482056, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1244.7504997253418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2000.4041194915771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1882.8849792480469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2553.5387992858887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2869.699716567993, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3971.475839614868, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 4296.7469692230225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3792}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana, Cuba", "latency_ms": 1237.8134727478027, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Havana Harbor, Cuba", "latency_ms": 2034.3151092529297, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Havana Harbor, Cuba", "latency_ms": 2199.5701789855957, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Havana Harbor", "latency_ms": 2017.2481536865234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "Havana Harbor", "latency_ms": 2361.8080615997314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2505}, "5": {"k": 5, "answer": "Havana Harbor", "latency_ms": 3064.995050430298, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3132}, "6": {"k": 6, "answer": "Havana Harbor", "latency_ms": 2793.7536239624023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3796}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Shiva", "latency_ms": 894.9434757232666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1621.78373336792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1842.8170680999756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Lord Vasupujya", "latency_ms": 2700.5014419555664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "Vishnu", "latency_ms": 2714.2820358276367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Lord Vasupujya", "latency_ms": 3208.019971847534, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3239}, "6": {"k": 6, "answer": "Lord Vasupujya", "latency_ms": 4389.190196990967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3905}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Belize, Guatemala, Honduras, Nicaragua, Costa Rica", "latency_ms": 2765.6288146972656, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Guatemala, Honduras, Nicaragua, Costa Rica", "latency_ms": 2830.935001373291, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "Panama, Belize, Guatemala, Honduras, Nicaragua", "latency_ms": 3253.800868988037, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1322}, "3": {"k": 3, "answer": "Belize, Guatemala, Honduras, Nicaragua, Panama", "latency_ms": 3652.5332927703857, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2007}, "4": {"k": 4, "answer": "Belize, Guatemala, Honduras, Nicaragua, Panama", "latency_ms": 3808.8903427124023, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2705}, "5": {"k": 5, "answer": "Belize, Guatemala, Honduras, Nicaragua, Panama", "latency_ms": 4425.6346225738525, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3397}, "6": {"k": 6, "answer": "Belize, Guatemala, Honduras, Nicaragua, Panama", "latency_ms": 4871.166944503784, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 4029}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "complex sentence", "latency_ms": 872.5130558013916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "complex sentence", "latency_ms": 1113.3058071136475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "complex sentence", "latency_ms": 1504.0342807769775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1318}, "3": {"k": 3, "answer": "complex sentence", "latency_ms": 1943.1779384613037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1977}, "4": {"k": 4, "answer": "complex sentence", "latency_ms": 2073.326587677002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "complex sentence", "latency_ms": 2365.855932235718, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3371}, "6": {"k": 6, "answer": "complex sentence", "latency_ms": 2581.2952518463135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4067}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "economic systems and trade principles", "latency_ms": 1471.4722633361816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The division of labour, productivity, and free markets", "latency_ms": 2610.5854511260986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "The Wealth of Nations was about the nature and causes of the wealth of nations, including division of labour, productivity, and free markets.", "latency_ms": 6550.311803817749, "em": 0.0, "f1": 0.16666666666666669, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of national wealth, including the division of labor, productivity, and free markets.", "latency_ms": 7377.347469329834, "em": 0.0, "f1": 0.16666666666666669, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "The Wealth of Nations was about the nature and causes of national wealth, including division of labour, productivity, and free markets.", "latency_ms": 6896.533489227295, "em": 0.0, "f1": 0.17391304347826086, "containment": 0.0, "context_chars": 2578}, "5": {"k": 5, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of national wealth, including topics like the division of labour, productivity, and free markets.", "latency_ms": 8458.033084869385, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 3225}, "6": {"k": 6, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of national wealth, including topics like the division of labour, productivity, and free markets.", "latency_ms": 9208.202123641968, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 3841}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1256.277084350586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 10, 2017", "latency_ms": 3238.475561141968, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "August 28, 2018", "latency_ms": 3237.6813888549805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 3561.3274574279785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 4419.558048248291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 4496.424674987793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 4591.199159622192, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3769}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Southern Hemisphere, Eastern Hemisphere, Oceania region", "latency_ms": 2437.284231185913, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "South West Queensland, Australia", "latency_ms": 1568.206548690796, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Oceania", "latency_ms": 1789.1287803649902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1374}, "3": {"k": 3, "answer": "Oceania", "latency_ms": 2111.762523651123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "Oceania", "latency_ms": 2329.202890396118, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2714}, "5": {"k": 5, "answer": "Oceania, Australasia", "latency_ms": 3231.0123443603516, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3367}, "6": {"k": 6, "answer": "Oceania, Australasia", "latency_ms": 3474.0116596221924, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4042}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Padmé Amidala", "latency_ms": 1232.0284843444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1360.0375652313232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1865.4024600982666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "Leia Organa", "latency_ms": 2312.9642009735107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1741}, "4": {"k": 4, "answer": "Leia Organa", "latency_ms": 3071.828603744507, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2312}, "5": {"k": 5, "answer": "Leia Organa", "latency_ms": 2779.553174972534, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2909}, "6": {"k": 6, "answer": "Leia Organa", "latency_ms": 3213.8900756835938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3440}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Ralph Edwards", "latency_ms": 1028.4180641174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1607.3634624481201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Allen Ludden", "latency_ms": 1925.2598285675049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Allen Ludden", "latency_ms": 2198.5220909118652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1779}, "4": {"k": 4, "answer": "Allen Ludden", "latency_ms": 2301.6185760498047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Allen Ludden", "latency_ms": 2862.3883724212646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3017}, "6": {"k": 6, "answer": "Allen Ludden", "latency_ms": 3494.3783283233643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3633}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "mitochondria", "latency_ms": 1072.2401142120361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "mitochondria", "latency_ms": 1305.8762550354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "mitochondria", "latency_ms": 1839.6918773651123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "mitochondria", "latency_ms": 2122.0877170562744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "mitochondria", "latency_ms": 2351.470947265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2693}, "5": {"k": 5, "answer": "mitochondria", "latency_ms": 3177.9136657714844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3377}, "6": {"k": 6, "answer": "mitochondria", "latency_ms": 2846.6713428497314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4111}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1234.490156173706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1375.6909370422363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2031.4693450927734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1402}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2216.6292667388916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2091}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2498.0688095092773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2791}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2774.0867137908936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3484}, "6": {"k": 6, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 4197.511434555054, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4220}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1318.2201385498047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenny Rogers and Dottie West", "latency_ms": 2412.9250049591064, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 590}, "2": {"k": 2, "answer": "Kenny Rogers and Dottie West", "latency_ms": 2635.5910301208496, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Kenny Rogers and Dottie West", "latency_ms": 2877.3295879364014, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1843}, "4": {"k": 4, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3093.7716960906982, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3676.638603210449, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3051}, "6": {"k": 6, "answer": "Kenny Rogers", "latency_ms": 2935.600757598877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3627}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 1033.3592891693115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Three-year-olds", "latency_ms": 1143.9881324768066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 689}, "2": {"k": 2, "answer": "36 months", "latency_ms": 1722.9492664337158, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "36 months", "latency_ms": 2353.8403511047363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1911}, "4": {"k": 4, "answer": "36 months", "latency_ms": 2341.7298793792725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "36 months", "latency_ms": 2231.3785552978516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3077}, "6": {"k": 6, "answer": "36 months", "latency_ms": 2752.0949840545654, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3660}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1236.7660999298096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 760.6973648071289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "three episodes", "latency_ms": 1606.2562465667725, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "three episodes", "latency_ms": 1906.7323207855225, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1963}, "4": {"k": 4, "answer": "three", "latency_ms": 1830.2087783813477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2610}, "5": {"k": 5, "answer": "three", "latency_ms": 2482.708692550659, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3226}, "6": {"k": 6, "answer": "three", "latency_ms": 2347.4254608154297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3842}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Vivien Leigh, Ian McKellen, Sean Astin, Orlando Bloom, Dominic Monaghan, and Billy Boyd", "latency_ms": 5636.37113571167, "em": 0.0, "f1": 0.2352941176470588, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1590.4085636138916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "Elijah Wood", "latency_ms": 1674.0920543670654, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1233}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2457.6327800750732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1886}, "4": {"k": 4, "answer": "Elijah Wood", "latency_ms": 3391.80588722229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2472}, "5": {"k": 5, "answer": "Elijah Wood", "latency_ms": 2860.192060470581, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3146}, "6": {"k": 6, "answer": "Ian Holm", "latency_ms": 4007.9705715179443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3812}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1272.707462310791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1837.7103805541992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2030.468463897705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "frivolous alternative to mainstream electoral parties", "latency_ms": 3084.1808319091797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "a type of party where guests dress up in costumes", "latency_ms": 3818.004608154297, "em": 0.0, "f1": 0.7142857142857143, "containment": 1.0, "context_chars": 2531}, "5": {"k": 5, "answer": "a type of party where guests dress up in costumes", "latency_ms": 4328.8562297821045, "em": 0.0, "f1": 0.7142857142857143, "containment": 1.0, "context_chars": 3207}, "6": {"k": 6, "answer": "a type of party where guests dress up in costumes", "latency_ms": 4225.117444992065, "em": 0.0, "f1": 0.7142857142857143, "containment": 1.0, "context_chars": 3778}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1257.4169635772705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 985.9328269958496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "1", "latency_ms": 1439.9878978729248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "1", "latency_ms": 1815.5403137207031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1902}, "4": {"k": 4, "answer": "1", "latency_ms": 1831.2664031982422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "1", "latency_ms": 2589.3030166625977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3159}, "6": {"k": 6, "answer": "1", "latency_ms": 2683.6206912994385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3782}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "To protect her from the injustices of the world and to fulfill his moral duty.", "latency_ms": 3828.972339630127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "To protect her from Javert and to give her a safe life.", "latency_ms": 4038.698196411133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "To protect her and provide her with a better life.", "latency_ms": 3466.2296772003174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "To protect her and provide her with a better life.", "latency_ms": 3983.2565784454346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "To protect her and provide her with a better life.", "latency_ms": 3928.1959533691406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "To protect her and provide her with a better life.", "latency_ms": 4377.594947814941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3130}, "6": {"k": 6, "answer": "To protect her and give her a better life.", "latency_ms": 4683.851003646851, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3743}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1229.419469833374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "India", "latency_ms": 988.936185836792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 709}, "2": {"k": 2, "answer": "India, Kenya", "latency_ms": 1830.249309539795, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1403}, "3": {"k": 3, "answer": "India, Kenya", "latency_ms": 2064.5673274993896, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "India, Kenya", "latency_ms": 2640.2575969696045, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2743}, "5": {"k": 5, "answer": "India, Kenya, Russia", "latency_ms": 3465.027093887329, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3444}, "6": {"k": 6, "answer": "India, Kenya, Russia", "latency_ms": 3162.0686054229736, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4072}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1230.2427291870117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 4676.114797592163, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 4815.636873245239, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 5130.51176071167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 5314.340591430664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 5903.823614120483, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3441}, "6": {"k": 6, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 5936.310529708862, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4119}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Python", "latency_ms": 639.2414569854736, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kaa is a python.", "latency_ms": 2011.2555027008057, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Kaa is a giant python.", "latency_ms": 2608.4799766540527, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Kaa is a python.", "latency_ms": 3322.079658508301, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1759}, "4": {"k": 4, "answer": "Indian python", "latency_ms": 2050.490617752075, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "Indian python", "latency_ms": 3612.1344566345215, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3021}, "6": {"k": 6, "answer": "Indian python", "latency_ms": 3008.3773136138916, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3717}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "water ice and carbon dioxide ice", "latency_ms": 1671.492576599121, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "water-ice", "latency_ms": 1569.370985031128, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "water-ice", "latency_ms": 1725.2581119537354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "water-ice", "latency_ms": 1657.0026874542236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "water-ice", "latency_ms": 2318.9852237701416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2382}, "5": {"k": 5, "answer": "water-ice", "latency_ms": 2254.866361618042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3042}, "6": {"k": 6, "answer": "water-ice", "latency_ms": 3008.4869861602783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3655}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1219.9606895446777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "second season's conclusion", "latency_ms": 1492.8267002105713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "around page 200 of \"The Awakening\"", "latency_ms": 3439.988851547241, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "end of second season", "latency_ms": 2558.9160919189453, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "end of second season", "latency_ms": 2420.9461212158203, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2379}, "5": {"k": 5, "answer": "end of second season", "latency_ms": 2775.9718894958496, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2941}, "6": {"k": 6, "answer": "end of second season", "latency_ms": 4034.8117351531982, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3525}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1306.2193393707275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1965.0359153747559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "ITV", "latency_ms": 1593.4991836547852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "ITV", "latency_ms": 1941.4596557617188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "BBC Sport", "latency_ms": 2096.27628326416, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2421}, "5": {"k": 5, "answer": "ITV", "latency_ms": 2659.6016883850098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2995}, "6": {"k": 6, "answer": "BBC Sport", "latency_ms": 3174.8580932617188, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3592}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Ward 8", "latency_ms": 1220.249891281128, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northwest Washington, DC", "latency_ms": 2095.791816711426, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "Northwest Washington, DC", "latency_ms": 2224.332094192505, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Northwest Washington, DC", "latency_ms": 2464.9033546447754, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "Northwest Washington, DC", "latency_ms": 3188.875675201416, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2831}, "5": {"k": 5, "answer": "Northwest Washington, DC", "latency_ms": 2956.526279449463, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3507}, "6": {"k": 6, "answer": "Northwest Washington, DC", "latency_ms": 4060.7473850250244, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 4217}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Covenant of Noah", "latency_ms": 1249.685525894165, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noahic", "latency_ms": 1590.4121398925781, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "Noahic", "latency_ms": 1852.8878688812256, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Noahic covenant", "latency_ms": 2291.9912338256836, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "Noahic covenant", "latency_ms": 3118.406057357788, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2431}, "5": {"k": 5, "answer": "Noahic covenant", "latency_ms": 2763.2412910461426, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3042}, "6": {"k": 6, "answer": "Noahic covenant", "latency_ms": 3701.385736465454, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3695}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Lil' Kim", "latency_ms": 1291.799545288086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1382.3981285095215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2016.5951251983643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1150}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2277.64630317688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1721}, "4": {"k": 4, "answer": "singer from the \"Singing the Blues\" episode", "latency_ms": 3912.7118587493896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2354}, "5": {"k": 5, "answer": "Steve Conte", "latency_ms": 2905.0636291503906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2940}, "6": {"k": 6, "answer": "Steve Conte", "latency_ms": 3153.287649154663, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3560}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "Walter Winchell", "latency_ms": 1423.9985942840576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rudy Vallée", "latency_ms": 1923.7027168273926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "Rudy Vallée and Anna King", "latency_ms": 2686.054229736328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "Rudy Vallée, Anna King, Erma Bombeck", "latency_ms": 4084.8419666290283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Rudy Vallée, Anna King, Erma Bombeck", "latency_ms": 4416.176557540894, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2444}, "5": {"k": 5, "answer": "Rudy Vallée, Anna King, Erma Bombeck, Mary Engelbreit", "latency_ms": 6398.612022399902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3079}, "6": {"k": 6, "answer": "Rudy Vallée, Anna King, Erma Bombeck, Mary Engelbreit, Jaye P. Morgan", "latency_ms": 7963.656663894653, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3673}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Florida coast", "latency_ms": 836.1375331878662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Estero Island, Lee County, Florida", "latency_ms": 2398.4477519989014, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Lee County, Florida", "latency_ms": 2024.2643356323242, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Lee County, Florida", "latency_ms": 2565.298318862915, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Lee County, Florida", "latency_ms": 3091.3805961608887, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Lee County, Florida", "latency_ms": 2969.291925430298, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3161}, "6": {"k": 6, "answer": "Southwest Florida, on the Gulf Coast, in Lee County, Florida.", "latency_ms": 6458.4503173828125, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3758}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "2nd", "latency_ms": 833.8363170623779, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1754.1532516479492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 713}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2048.478364944458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2420.609712600708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2578.199863433838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3562.6611709594727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3143}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2988.367795944214, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3736}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mohandas K. Gandhi", "latency_ms": 1437.9827976226807, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jawaharlal Nehru", "latency_ms": 2328.8471698760986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "Pattom A. Thanu Pillai", "latency_ms": 3037.2345447540283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "Lala Ram Prakash Gupta, Pattom A. Thanu Pillai, Surendranath Banerjee", "latency_ms": 6310.202360153198, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2058}, "4": {"k": 4, "answer": "Lala Ram Prakash Gupta, Pattom A. Thanu Pillai, Surendranath Banerjee", "latency_ms": 6269.859075546265, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2766}, "5": {"k": 5, "answer": "Lala Ram Prakash Gupta, Pattom A. Thanu Pillai, Surendranath Banerjee, Mukul Roy", "latency_ms": 7729.8643589019775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3373}, "6": {"k": 6, "answer": "Lala Ram Prakash Gupta, Pattom A. Thanu Pillai, Surendranath Banerjee", "latency_ms": 7191.288948059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4101}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Terry Jones", "latency_ms": 1041.7366027832031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bobby Flay", "latency_ms": 1603.1615734100342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Bobby Flay", "latency_ms": 1848.695993423462, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Bobby Flay", "latency_ms": 2477.9906272888184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Bobby Flay", "latency_ms": 2769.9906826019287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "Bobby Flay", "latency_ms": 3188.0292892456055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3158}, "6": {"k": 6, "answer": "Bobby Flay", "latency_ms": 3744.185209274292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 651.2324810028076, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "codice_22", "latency_ms": 2016.8609619140625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 687}, "2": {"k": 2, "answer": ".java", "latency_ms": 1369.478702545166, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": ".java", "latency_ms": 1241.0883903503418, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": ".class", "latency_ms": 1901.2455940246582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": ".java", "latency_ms": 2218.1601524353027, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": ".java", "latency_ms": 2341.4947986602783, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3911}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 850.8050441741943, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alan Turing", "latency_ms": 1558.9916706085205, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Alan Turing", "latency_ms": 1605.724811553955, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Alan Turing", "latency_ms": 1837.609052658081, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 2045.440912246704, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2519}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 2828.5534381866455, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3187}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 2660.168409347534, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3876}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "To ensure party members vote according to party lines and to maintain party discipline in Congress.", "latency_ms": 3895.979881286621, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ensure members adhere to party policies and vote as directed", "latency_ms": 2589.694023132324, "em": 0.0, "f1": 0.4285714285714285, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "ensure members adhere to party policies and vote as directed", "latency_ms": 3165.9092903137207, "em": 0.0, "f1": 0.4285714285714285, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "Ensure members vote in line with party leadership", "latency_ms": 2680.7305812835693, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "Ensure members vote in line with party leadership", "latency_ms": 3338.865280151367, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "Ensure members vote in line with party leadership", "latency_ms": 3564.6677017211914, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Ensure members vote in line with party leadership", "latency_ms": 3771.5888023376465, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3947}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1240.5643463134766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1993", "latency_ms": 1588.6361598968506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "1973", "latency_ms": 1958.5373401641846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "1973", "latency_ms": 2982.6228618621826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "1973", "latency_ms": 3525.672435760498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "1973", "latency_ms": 3530.2836894989014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3039}, "6": {"k": 6, "answer": "1973", "latency_ms": 3953.4859657287598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3675}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the​ right but not the​ obligation to buy foreign​ currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 1009.9601745605469, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 1408.0970287322998, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 1523.7576961517334, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 1606.7698001861572, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "call option", "latency_ms": 2302.7260303497314, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2702}, "5": {"k": 5, "answer": "call option", "latency_ms": 2662.5657081604004, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "call option", "latency_ms": 2562.9308223724365, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3910}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 1036.9532108306885, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360", "latency_ms": 1593.1816101074219, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360", "latency_ms": 1797.1758842468262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1380}, "3": {"k": 3, "answer": "360", "latency_ms": 2102.8895378112793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2010}, "4": {"k": 4, "answer": "360", "latency_ms": 2980.8349609375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "360", "latency_ms": 3140.5904293060303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3307}, "6": {"k": 6, "answer": "360", "latency_ms": 2758.6982250213623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4001}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1251.0650157928467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 1605.7555675506592, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 2022.4347114562988, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 2332.289218902588, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 2449.6564865112305, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2559}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 3002.7220249176025, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3205}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 4230.103254318237, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3856}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gormé"], "shots": {"0": {"k": 0, "answer": "Antônio Carlos Jobim", "latency_ms": 1618.612289428711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eydie Gormé", "latency_ms": 1781.0132503509521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 580}, "2": {"k": 2, "answer": "Eydie Gormé", "latency_ms": 2046.1821556091309, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Eydie Gormé", "latency_ms": 2753.3514499664307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1787}, "4": {"k": 4, "answer": "Eydie Gormé", "latency_ms": 3290.2281284332275, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2364}, "5": {"k": 5, "answer": "Eydie Gormé", "latency_ms": 3771.583318710327, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2981}, "6": {"k": 6, "answer": "Eydie Gormé", "latency_ms": 3965.1038646698, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3582}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "Justice R. S. Pathak", "latency_ms": 1839.548110961914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "K. K. Usha", "latency_ms": 2268.3463096618652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 519}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2030.47513961792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1132}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2504.274368286133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1756}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2441.389560699463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2317}, "5": {"k": 5, "answer": "Mohan Shantanagoudar", "latency_ms": 3690.875291824341, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2929}, "6": {"k": 6, "answer": "Mohan Shantanagoudar", "latency_ms": 4416.688442230225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3493}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1238.5594844818115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Serena Williams", "latency_ms": 1750.0765323638916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2004.802942276001, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "Roger Federer", "latency_ms": 2244.87042427063, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1851}, "4": {"k": 4, "answer": "Roger Federer", "latency_ms": 2419.0075397491455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2410}, "5": {"k": 5, "answer": "Roger Federer", "latency_ms": 2842.8707122802734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3008}, "6": {"k": 6, "answer": "Roger Federer", "latency_ms": 3281.660556793213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3594}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1239.5002841949463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 778.0418395996094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 1404.5755863189697, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1228}, "3": {"k": 3, "answer": "1", "latency_ms": 1701.6160488128662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "1", "latency_ms": 1830.1970958709717, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2418}, "5": {"k": 5, "answer": "1", "latency_ms": 2579.1423320770264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3054}, "6": {"k": 6, "answer": "1", "latency_ms": 2351.3739109039307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3661}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 1307.4142932891846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2000", "latency_ms": 1582.4453830718994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "1988", "latency_ms": 1869.5509433746338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "2000", "latency_ms": 2463.9105796813965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1826}, "4": {"k": 4, "answer": "2000", "latency_ms": 2641.568899154663, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2351}, "5": {"k": 5, "answer": "2000", "latency_ms": 3353.764295578003, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2965}, "6": {"k": 6, "answer": "2000", "latency_ms": 3347.9981422424316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3565}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "32", "latency_ms": 838.284969329834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1607.1054935455322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "5", "latency_ms": 1412.0798110961914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "5", "latency_ms": 2260.720729827881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "5", "latency_ms": 2146.698236465454, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "5", "latency_ms": 2363.233804702759, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3203}, "6": {"k": 6, "answer": "5", "latency_ms": 3120.605230331421, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3872}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Wallowa County, Oregon", "latency_ms": 1668.8642501831055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 1789.6080017089844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 2208.6827754974365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 2672.795057296753, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 2652.467727661133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2512}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 3397.1660137176514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3163}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 3452.453851699829, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3814}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Corry, Kory, Cory, Kory, Corry", "latency_ms": 3633.852958679199, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Corry, Corye, Korry", "latency_ms": 2747.7352619171143, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1904.3772220611572, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1182}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2516.3285732269287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1783}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2710.5419635772705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2419}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2760.5948448181152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3011}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3834.193468093872, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3596}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1227.5986671447754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roy Rogers", "latency_ms": 964.2081260681152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2031.0447216033936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2298.194646835327, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2407.7043533325195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3342.121124267578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2952.5039196014404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 1029.8712253570557, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 1396.5554237365723, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "159", "latency_ms": 1803.7903308868408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "159", "latency_ms": 2305.7210445404053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "159", "latency_ms": 2483.5474491119385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2708}, "5": {"k": 5, "answer": "159", "latency_ms": 3550.9562492370605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3443}, "6": {"k": 6, "answer": "159", "latency_ms": 2736.5663051605225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4090}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1236.4141941070557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edwin McCain", "latency_ms": 1573.6944675445557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 581}, "2": {"k": 2, "answer": "Edwin McCain", "latency_ms": 1680.5193424224854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1181}, "3": {"k": 3, "answer": "Egan", "latency_ms": 1895.4212665557861, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1701}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3222.275495529175, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2317}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3078.5140991210938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2889}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2974.17950630188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3427}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Ray Allen", "latency_ms": 853.0590534210205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1860.8877658843994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1877.8843879699707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2408.2276821136475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1805}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2769.178867340088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2383}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3197.249174118042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2948}, "6": {"k": 6, "answer": "Adrian Dantley", "latency_ms": 3514.8863792419434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3548}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1234.4589233398438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "right hand", "latency_ms": 940.8893585205078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "right hand", "latency_ms": 1566.2522315979004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1137}, "3": {"k": 3, "answer": "right hand", "latency_ms": 1482.0117950439453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1701}, "4": {"k": 4, "answer": "right hand", "latency_ms": 2066.55216217041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2255}, "5": {"k": 5, "answer": "right hand", "latency_ms": 2295.0010299682617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2857}, "6": {"k": 6, "answer": "right hand ring finger", "latency_ms": 3192.345380783081, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3451}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Pinocchio", "latency_ms": 1066.2124156951904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Donald Duck", "latency_ms": 1086.9295597076416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Donald Duck", "latency_ms": 1564.8534297943115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1293}, "3": {"k": 3, "answer": "Donald Duck", "latency_ms": 1908.9891910552979, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1945}, "4": {"k": 4, "answer": "Donald Duck", "latency_ms": 2056.7257404327393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2597}, "5": {"k": 5, "answer": "Donald Duck", "latency_ms": 3330.2557468414307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3236}, "6": {"k": 6, "answer": "Donald Duck", "latency_ms": 3877.15482711792, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3851}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Waited I cannot answer.", "latency_ms": 1629.1167736053467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sean Astin", "latency_ms": 1606.6889762878418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1919.0423488616943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2480.0968170166016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2807.9891204833984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2470}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2946.4244842529297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3930.4285049438477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3679}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1230.726718902588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2018", "latency_ms": 3167.2468185424805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 3359.6673011779785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1169}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 3526.7233848571777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 3724.532127380371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2404}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 4001.0745525360107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3055}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 4227.827548980713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3661}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles, California", "latency_ms": 1233.7939739227295, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "independently", "latency_ms": 1623.1861114501953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1995.3594207763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2322.7458000183105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3110.5823516845703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2600}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3094.6104526519775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3275.0003337860107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3825}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1246.941089630127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Emma Gilbert", "latency_ms": 1191.5192604064941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Emma Gilbert", "latency_ms": 1662.1778011322021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Emma Gilbert", "latency_ms": 1869.2371845245361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Emma Gilbert", "latency_ms": 2109.344244003296, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2471}, "5": {"k": 5, "answer": "Emma Gilbert", "latency_ms": 2656.177759170532, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3111}, "6": {"k": 6, "answer": "Emma Gilbert", "latency_ms": 3153.783082962036, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3750}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "atmosphere, oceans, soil, living organisms", "latency_ms": 2436.596632003784, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "wood or soil", "latency_ms": 1579.7672271728516, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 705}, "2": {"k": 2, "answer": "in wood or soil", "latency_ms": 2031.1110019683838, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1407}, "3": {"k": 3, "answer": "in plants and other living organisms, and in soils", "latency_ms": 4117.197275161743, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2057}, "4": {"k": 4, "answer": "in plants and other living organisms, soils, and in organic carbon forms", "latency_ms": 4429.479360580444, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2742}, "5": {"k": 5, "answer": "in plants and other living organisms, soils, and as organic carbon in land-living organisms", "latency_ms": 6277.315855026245, "em": 0.0, "f1": 0.35294117647058826, "containment": 1.0, "context_chars": 3462}, "6": {"k": 6, "answer": "in plants, soils, and organic matter of land-living organisms", "latency_ms": 5741.751194000244, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 4116}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1242.9864406585693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Akul Balaji", "latency_ms": 1544.0709590911865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Akul Balaji", "latency_ms": 1944.5855617523193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1324}, "3": {"k": 3, "answer": "Akul Balaji", "latency_ms": 2509.131669998169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "Akul Balaji", "latency_ms": 2963.029384613037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Akul Balaji", "latency_ms": 2996.92702293396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Akul Balaji", "latency_ms": 3841.564655303955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3817}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Tennessee", "latency_ms": 831.7804336547852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jackson County, Missouri", "latency_ms": 1499.582290649414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "Jackson County, Missouri and neighboring Clay County, Missouri", "latency_ms": 3254.584312438965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Jackson County and neighboring Clay County", "latency_ms": 2678.2891750335693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "Jackson County and neighboring Clay County", "latency_ms": 2844.2063331604004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2490}, "5": {"k": 5, "answer": "Jackson County, Missouri; neighboring Clay County; Kanab, Utah", "latency_ms": 5019.695043563843, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3115}, "6": {"k": 6, "answer": "Jackson County, Missouri; neighboring Clay County; Kanab, Utah", "latency_ms": 4994.804859161377, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3730}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1225.433111190796, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1985.9423637390137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2082.1268558502197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1335}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2335.2057933807373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2448.1940269470215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2967.4110412597656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3346.2133407592773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3896}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Starts in the Rocky Mountains, ends in the North Dakota-Minnesota border.", "latency_ms": 3823.380708694458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Starts above Saskatchewan Glacier in Columbia Icefield; ends at Rocky Mountain House", "latency_ms": 3581.076145172119, "em": 0.0, "f1": 0.26666666666666666, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Starts in Canadian Rockies, ends in Hudson Bay", "latency_ms": 3100.926160812378, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "starts at confluence of North and South Saskatchewan Rivers, ends at Saskatchewan River Delta", "latency_ms": 4657.893657684326, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Starts at confluence of North and South Saskatchewan Rivers in central Saskatchewan; ends at Lake Winnipeg.", "latency_ms": 5997.117280960083, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2674}, "5": {"k": 5, "answer": "Starts at confluence of North and South Saskatchewan Rivers in central Saskatchewan; ends at Lake Winnipeg, flowing into Hudson Bay.", "latency_ms": 7429.296016693115, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 3279}, "6": {"k": 6, "answer": "Starts at confluence of North and South Saskatchewan Rivers in central Saskatchewan; ends in Lake Winnipeg.", "latency_ms": 6237.666845321655, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4009}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 840.1756286621094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome, Italy", "latency_ms": 1601.0918617248535, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome, Italy", "latency_ms": 2014.258861541748, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Rome, Italy", "latency_ms": 2863.7166023254395, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1816}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 2517.3027515411377, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2417}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 3203.644275665283, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3068}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 3390.9432888031006, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3755}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1225.0275611877441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1594.2325592041016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2008.5017681121826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "manufacturing company or site", "latency_ms": 2533.412456512451, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "manufacturing company or site", "latency_ms": 2714.545488357544, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2500}, "5": {"k": 5, "answer": "manufacturing company or site", "latency_ms": 3376.331090927124, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3089}, "6": {"k": 6, "answer": "manufacturing company or site", "latency_ms": 3886.2550258636475, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3710}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "ammonia, alcohols, carboxylic acids", "latency_ms": 3077.9407024383545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 2556.4754009246826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 2694.1466331481934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 3334.559917449951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 3351.121187210083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 3621.3645935058594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3212}, "6": {"k": 6, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 4012.962818145752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3812}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1218.602180480957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 1376.8153190612793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "1988", "latency_ms": 1984.4932556152344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "1988", "latency_ms": 2895.8191871643066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1785}, "4": {"k": 4, "answer": "1988", "latency_ms": 2525.6683826446533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2409}, "5": {"k": 5, "answer": "1988", "latency_ms": 2796.83518409729, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3012}, "6": {"k": 6, "answer": "1988", "latency_ms": 3300.050973892212, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3628}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Truco", "latency_ms": 857.3601245880127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tute", "latency_ms": 1131.3741207122803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "Truco", "latency_ms": 1649.390459060669, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1168}, "3": {"k": 3, "answer": "Manille", "latency_ms": 2032.0734977722168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1763}, "4": {"k": 4, "answer": "Manille", "latency_ms": 2240.7805919647217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2363}, "5": {"k": 5, "answer": "Manille", "latency_ms": 3028.1574726104736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2949}, "6": {"k": 6, "answer": "Manille", "latency_ms": 2570.8231925964355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3609}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1287.3361110687256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "60%", "latency_ms": 1392.970323562622, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1993.9918518066406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "5%", "latency_ms": 1904.6049118041992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 3126.11985206604, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 3393.888473510742, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 4477.600812911987, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3724}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1247.544765472412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1371.720552444458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2009.5205307006836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "1971", "latency_ms": 2990.053176879883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "1971", "latency_ms": 2506.5994262695312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2510}, "5": {"k": 5, "answer": "1971", "latency_ms": 2966.262102127075, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3133}, "6": {"k": 6, "answer": "1971", "latency_ms": 3295.521020889282, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3692}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Michael Jackson", "latency_ms": 837.4876976013184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1373.2471466064453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1971.0195064544678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2266.202449798584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2519.454002380371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2790.194511413574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2989.1574382781982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3679}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Lord Baltimore", "latency_ms": 843.4329032897949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cecil Calvert", "latency_ms": 1972.1839427947998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Cecil Calvert", "latency_ms": 2121.1373805999756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1336}, "3": {"k": 3, "answer": "Cecil Calvert", "latency_ms": 2465.8658504486084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Cecil Calvert", "latency_ms": 2913.088083267212, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2617}, "5": {"k": 5, "answer": "Cecil Calvert", "latency_ms": 3275.900363922119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3294}, "6": {"k": 6, "answer": "Cecil Calvert", "latency_ms": 3126.8484592437744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3952}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1297.9381084442139, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiger Woods", "latency_ms": 1366.102933883667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Tiger Woods", "latency_ms": 1800.0414371490479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Tiger Woods", "latency_ms": 2095.3943729400635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Tiger Woods", "latency_ms": 2228.837251663208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Tiger Woods", "latency_ms": 2735.0268363952637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3188}, "6": {"k": 6, "answer": "Tiger Woods", "latency_ms": 3177.5448322296143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3848}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "30 milligrams", "latency_ms": 1238.901138305664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "200 to 500 mg (dry weight)", "latency_ms": 3207.206964492798, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 4027.6997089385986, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "420 mg (dry weight)", "latency_ms": 3414.527654647827, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1930}, "4": {"k": 4, "answer": "420 mg (dry weight)", "latency_ms": 3712.64386177063, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "420 mg (dry weight)", "latency_ms": 3797.7397441864014, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "420 mg (dry weight)", "latency_ms": 4515.189409255981, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3816}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1247.6887702941895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham United", "latency_ms": 1374.4513988494873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 586}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 1824.2683410644531, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1105}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 2072.505235671997, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1685}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 2333.9180946350098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2245}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 2854.0751934051514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2887}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 2738.5504245758057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3467}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1279.3495655059814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1366.8158054351807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 685}, "2": {"k": 2, "answer": "Windsor, Ontario", "latency_ms": 2117.2752380371094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "Windsor, Ontario", "latency_ms": 2561.305046081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1993}, "4": {"k": 4, "answer": "Windsor, Ontario", "latency_ms": 2711.8215560913086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2668}, "5": {"k": 5, "answer": "Windsor, Ontario", "latency_ms": 2983.4272861480713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3361}, "6": {"k": 6, "answer": "Windsor, Ontario", "latency_ms": 3159.337282180786, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4082}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh, Scotland", "latency_ms": 1268.1515216827393, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 1672.989845275879, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 2097.402334213257, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1379}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 2472.848892211914, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2057}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 3330.7220935821533, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 3561.600923538208, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3428}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 2983.949661254883, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4106}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Seth Rollins", "latency_ms": 1247.0557689666748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alexa Bliss", "latency_ms": 1741.0774230957031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1881.1874389648438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2209.843635559082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "Roman Reigns", "latency_ms": 2229.153633117676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2596}, "5": {"k": 5, "answer": "Roman Reigns", "latency_ms": 3324.5632648468018, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3264}, "6": {"k": 6, "answer": "Roman Reigns", "latency_ms": 2783.4315299987793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3881}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1253.9401054382324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Southport, North Carolina", "latency_ms": 1997.9209899902344, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Southport, North Carolina", "latency_ms": 2243.6342239379883, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Southport, North Carolina", "latency_ms": 2506.5765380859375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "Southport, North Carolina", "latency_ms": 2893.439769744873, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2425}, "5": {"k": 5, "answer": "Southport, North Carolina", "latency_ms": 3269.5705890655518, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3028}, "6": {"k": 6, "answer": "Southport, North Carolina", "latency_ms": 3159.6434116363525, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3649}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1268.2933807373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1983.3600521087646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 705}, "2": {"k": 2, "answer": "Sylvia F. Porter", "latency_ms": 2339.6599292755127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Sylvia F. Porter", "latency_ms": 2856.2240600585938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 3600.9504795074463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 3965.797185897827, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3327}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 3915.588617324829, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3932}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 1095.768928527832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 1385.2488994598389, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 735}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 1811.2356662750244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1441}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 2259.612798690796, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2187}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 2245.86820602417, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2881}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 3125.51212310791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3642}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 3073.380947113037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4403}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 641.2267684936523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 978.9044857025146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "Max", "latency_ms": 1408.3209037780762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Max", "latency_ms": 1684.953212738037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1872}, "4": {"k": 4, "answer": "Max", "latency_ms": 1834.3353271484375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Max", "latency_ms": 2762.38751411438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Max", "latency_ms": 2771.8703746795654, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3716}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Sasha Lane", "latency_ms": 1102.3786067962646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1547.3170280456543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2034.003496170044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2301.0122776031494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1935}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2449.1615295410156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3113.354206085205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3156}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3428.5614490509033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3815}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1233.4797382354736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Athletics at the 1900 Summer Olympics – Men's 110 metres hurdles held on July 14, 1900.", "latency_ms": 7396.648168563843, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "The 1900 Summer Olympics in Paris took place.", "latency_ms": 3788.5425090789795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "The 1900 Summer Olympics in Paris took place.", "latency_ms": 4367.899179458618, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "Paris 1900 Summer Olympics, Exposition Universelle, chess tournament", "latency_ms": 5244.8225021362305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2635}, "5": {"k": 5, "answer": "Paris 1900 Olympics, chess tournament, UCI Track Cycling World Championships", "latency_ms": 5633.936166763306, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3326}, "6": {"k": 6, "answer": "Paris 1900 Olympics, chess tournament, track cycling world championships", "latency_ms": 6894.643306732178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4010}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Self-empowerment", "latency_ms": 1420.5355644226074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "empowerment", "latency_ms": 1165.9343242645264, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "empowerment", "latency_ms": 1823.6126899719238, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "self-empowerment", "latency_ms": 2709.3000411987305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "self-empowerment", "latency_ms": 3468.228816986084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "self-empowerment", "latency_ms": 3170.4647541046143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "self-empowerment", "latency_ms": 3760.0550651550293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3787}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 884.9327564239502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "NFL teams", "latency_ms": 961.9874954223633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "NFL teams", "latency_ms": 1600.4211902618408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "NFL teams", "latency_ms": 2409.7654819488525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "NFL teams", "latency_ms": 2290.1926040649414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2451}, "5": {"k": 5, "answer": "NFL teams", "latency_ms": 2695.3213214874268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3069}, "6": {"k": 6, "answer": "NFL teams", "latency_ms": 2552.492141723633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3686}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 1227.9596328735352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1608.8459491729736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2033.6463451385498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1305}, "3": {"k": 3, "answer": "James Marshall", "latency_ms": 2173.910140991211, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "James Marshall", "latency_ms": 2045.1703071594238, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2617}, "5": {"k": 5, "answer": "James Marshall", "latency_ms": 3183.2849979400635, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3191}, "6": {"k": 6, "answer": "James Marshall", "latency_ms": 2933.689832687378, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3743}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "convex mirror", "latency_ms": 1033.445119857788, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "rear-view mirror", "latency_ms": 1167.5996780395508, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "rear-view mirror", "latency_ms": 1762.7923488616943, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "rear-view mirror", "latency_ms": 2455.9385776519775, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "rear-view mirror", "latency_ms": 2335.369348526001, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "rear-view mirror", "latency_ms": 2557.5973987579346, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "rear-view mirror", "latency_ms": 2759.6116065979004, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1278.228759765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1622.5917339324951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2022.5112438201904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1158}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2659.5253944396973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1756}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3004.821538925171, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2372}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2958.5962295532227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3035}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3291.8193340301514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3689}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Andrew Lloyd Webber", "latency_ms": 1288.1104946136475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart", "latency_ms": 1086.759328842163, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 2693.8135623931885, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3237.293481826782, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1952}, "4": {"k": 4, "answer": "Charles Hart, Richard Stilgoe, Mike Batt", "latency_ms": 3860.9282970428467, "em": 0.0, "f1": 0.7272727272727272, "containment": 1.0, "context_chars": 2631}, "5": {"k": 5, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4357.895374298096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3306}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4562.251806259155, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3997}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Central Europe", "latency_ms": 880.3906440734863, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central Germany", "latency_ms": 967.1094417572021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Central Germany (cultural area)", "latency_ms": 2685.6632232666016, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Central Germany (cultural area)", "latency_ms": 2836.34352684021, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Central Germany (cultural area)", "latency_ms": 3046.9539165496826, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Central Germany (cultural area)", "latency_ms": 3403.240203857422, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3288}, "6": {"k": 6, "answer": "Central Germany (cultural area)", "latency_ms": 3829.470634460449, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4016}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "13th to 14th century", "latency_ms": 2246.648073196411, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 1365.4637336730957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "1648–1651", "latency_ms": 3491.018056869507, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "later, more modern period than earlier titles with access to pistols, grenades, and other equipment of the post-medieval era", "latency_ms": 6322.48330116272, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "1648–1651", "latency_ms": 3688.3623600006104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "1648–1651", "latency_ms": 4122.842788696289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "1648–1651", "latency_ms": 4437.583446502686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3902}}}
