{"qid": "5306300389470118812", "question": "what was the religion in persia before islam", "gold_answers": ["the Zoroastrian religion", "Zoroastrian"], "shots": {"0": {"k": 0, "answer": "Zoroastrianism", "latency_ms": 1442.5928592681885, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Zoroastrianism", "latency_ms": 1730.3574085235596, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 637}, "2": {"k": 2, "answer": "Zoroastrianism", "latency_ms": 2322.0348358154297, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Zoroastrianism", "latency_ms": 2714.1289710998535, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1985}, "4": {"k": 4, "answer": "Zoroastrianism", "latency_ms": 3103.935956954956, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2650}, "5": {"k": 5, "answer": "Zoroastrianism", "latency_ms": 5217.400789260864, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3335}, "6": {"k": 6, "answer": "Zoroastrianism", "latency_ms": 5851.945877075195, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3996}}}
{"qid": "4492088526674104172", "question": "why does kerosene oil rise up in the wick of lantern", "gold_answers": ["capillary action"], "shots": {"0": {"k": 0, "answer": "Capillary action", "latency_ms": 3029.805898666382, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "capillary action", "latency_ms": 1860.2521419525146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "capillary action", "latency_ms": 1675.1890182495117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "capillary action", "latency_ms": 2309.079647064209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1876}, "4": {"k": 4, "answer": "capillary action", "latency_ms": 3814.6188259124756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2493}, "5": {"k": 5, "answer": "capillary action", "latency_ms": 2634.3936920166016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3112}, "6": {"k": 6, "answer": "capillary action", "latency_ms": 3737.6532554626465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "-4373262132142058334", "question": "mention the chemical change that proinsulin undergo to be able to act as mature insulin", "gold_answers": ["post translational modification"], "shots": {"0": {"k": 0, "answer": "Proteolytic cleavage", "latency_ms": 3833.3475589752197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "C-peptide cleavage", "latency_ms": 4682.794094085693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "C-peptide cleavage", "latency_ms": 2481.1713695526123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "C-peptide cleavage", "latency_ms": 2613.5780811309814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "C-peptide is cleaved", "latency_ms": 3916.8307781219482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "cleavage of C-peptide", "latency_ms": 5182.384490966797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3306}, "6": {"k": 6, "answer": "cleavage of C-peptide", "latency_ms": 5380.927085876465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3855}}}
{"qid": "-5298560410953979569", "question": "where does the sweetness of fruit come from", "gold_answers": ["Fructose , or fruit sugar", "Fructose"], "shots": {"0": {"k": 0, "answer": "sugars like fructose, glucose, and sucrose", "latency_ms": 2879.244089126587, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "sugars", "latency_ms": 1770.714521408081, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 677}, "2": {"k": 2, "answer": "fruit flavors and natural sweeteners like sugars and fruit pastes", "latency_ms": 3625.1680850982666, "em": 0.0, "f1": 0.14285714285714288, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "fruit flesh and natural sugars", "latency_ms": 2589.5605087280273, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "fruit flesh and natural sugars", "latency_ms": 2653.2678604125977, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2653}, "5": {"k": 5, "answer": "sweet-tasting plant part", "latency_ms": 3479.8455238342285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "sweet-tasting plant part", "latency_ms": 4134.8772048950195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3894}}}
{"qid": "4344648368832551136", "question": "an object that moves around an external axis is said to be", "gold_answers": ["orbit", "revolution or orbital revolution"], "shots": {"0": {"k": 0, "answer": "rotating", "latency_ms": 987.7009391784668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "revolving", "latency_ms": 2445.5957412719727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "revolving", "latency_ms": 1789.40749168396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "revolving", "latency_ms": 1865.0896549224854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "revolving", "latency_ms": 2107.0291996002197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "revolving", "latency_ms": 4710.62970161438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "revolving", "latency_ms": 3180.508852005005, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "-724426540432437711", "question": "what was the name of the plant on little shop of horrors", "gold_answers": ["Audrey II"], "shots": {"0": {"k": 0, "answer": "Audrey II", "latency_ms": 2072.934865951538, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Audrey II", "latency_ms": 1942.202091217041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Audrey II", "latency_ms": 1955.1784992218018, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1244}, "3": {"k": 3, "answer": "Audrey II", "latency_ms": 2036.4418029785156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "Audrey II", "latency_ms": 2747.3154067993164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2538}, "5": {"k": 5, "answer": "Audrey II", "latency_ms": 2909.4483852386475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3191}, "6": {"k": 6, "answer": "Audrey II", "latency_ms": 3078.5717964172363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3833}}}
{"qid": "-5541610970112826260", "question": "who signed the declaration of independence for maryland", "gold_answers": ["Samuel Chase", "Charles Carroll of Carrollton", "Thomas Stone", "William Paca"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1940.307855606079, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 6578.907012939453, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 9042.640924453735, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 1263}, "3": {"k": 3, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 8872.268676757812, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Samuel Chase, William Paca, Thomas Stone, Charles Carroll of Carrollton", "latency_ms": 9089.982509613037, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Samuel Chase, William Paca, Thomas Stone, Charles Carroll of Carrollton", "latency_ms": 8702.770233154297, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3263}, "6": {"k": 6, "answer": "Samuel Chase, William Paca, Thomas Stone, Charles Carroll of Carrollton", "latency_ms": 10459.293603897095, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3926}}}
{"qid": "-86997217831791339", "question": "when does wonder woman come out on blue ray", "gold_answers": ["September 19 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1889.3072605133057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 19, 2017", "latency_ms": 3169.9039936065674, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "September 19, 2017", "latency_ms": 4689.710855484009, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "September 19, 2017", "latency_ms": 8050.7519245147705, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1872}, "4": {"k": 4, "answer": "September 19, 2017", "latency_ms": 5056.632041931152, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "September 19, 2017", "latency_ms": 7236.572027206421, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3144}, "6": {"k": 6, "answer": "September 19, 2017", "latency_ms": 6685.877799987793, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "-8062812506672279762", "question": "what nba team did derrick rose play for", "gold_answers": ["New York Knicks", "Minnesota Timberwolves", "Chicago Bulls", "Cleveland Cavaliers"], "shots": {"0": {"k": 0, "answer": "Chicago Bulls", "latency_ms": 834.6328735351562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Minnesota Timberwolves", "latency_ms": 1792.2303676605225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 630}, "2": {"k": 2, "answer": "Chicago Bulls, Minnesota Timberwolves, Cleveland Cavaliers", "latency_ms": 4854.70724105835, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1238}, "3": {"k": 3, "answer": "Chicago Bulls, Minnesota Timberwolves, Cleveland Cavaliers", "latency_ms": 14102.637529373169, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1808}, "4": {"k": 4, "answer": "Chicago Bulls, Minnesota Timberwolves", "latency_ms": 4151.439905166626, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2463}, "5": {"k": 5, "answer": "Chicago Bulls, Minnesota Timberwolves, Cleveland Cavaliers", "latency_ms": 5650.512218475342, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3066}, "6": {"k": 6, "answer": "Chicago Bulls, Minnesota Timberwolves, Cleveland Cavaliers", "latency_ms": 6526.2956619262695, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3667}}}
{"qid": "7933002036740390435", "question": "where did the term liberal arts come from", "gold_answers": ["the Roman Empire"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 883.5206031799316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roman Empire", "latency_ms": 969.0909385681152, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Roman Empire", "latency_ms": 3867.3834800720215, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1351}, "3": {"k": 3, "answer": "Roman Empire", "latency_ms": 2075.9224891662598, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2046}, "4": {"k": 4, "answer": "Roman Empire", "latency_ms": 2008.559226989746, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2760}, "5": {"k": 5, "answer": "Roman Empire", "latency_ms": 4197.233200073242, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3467}, "6": {"k": 6, "answer": "Roman Empire", "latency_ms": 2928.7092685699463, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4188}}}
{"qid": "-2991400700385487821", "question": "who heads the executive department of west virginia government", "gold_answers": ["the Governor of West Virginia", "the governor of West Virginia", "Jim Justice"], "shots": {"0": {"k": 0, "answer": "Governor of West Virginia", "latency_ms": 4310.690641403198, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "governor", "latency_ms": 1382.019281387329, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "Governor of West Virginia", "latency_ms": 2602.5750637054443, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Governor of West Virginia", "latency_ms": 2506.999731063843, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1911}, "4": {"k": 4, "answer": "Governor of West Virginia", "latency_ms": 2693.4285163879395, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "Governor of West Virginia", "latency_ms": 5001.583576202393, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3308}, "6": {"k": 6, "answer": "Governor of West Virginia", "latency_ms": 4942.457914352417, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4002}}}
{"qid": "-9186689755642837558", "question": "how long is the bridge between new brunswick and prince edward island", "gold_answers": ["12.9 - kilometre"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 3415.7238006591797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1608.565092086792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 686}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2599.1828441619873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3206.4504623413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2032}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 4351.114988327026, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2691}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3151.3755321502686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3279}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3727.398157119751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3940}}}
{"qid": "8029901619424338449", "question": "when did the uk and us become allies", "gold_answers": ["1940", "Since 1940"], "shots": {"0": {"k": 0, "answer": "1941", "latency_ms": 1289.4139289855957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3354.6221256256104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1975.50368309021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2459.254741668701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3243.215799331665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2767.9736614227295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3132}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2963.1779193878174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "4828649525820722736", "question": "who sang the theme song for the man with the golden gun", "gold_answers": ["Lulu"], "shots": {"0": {"k": 0, "answer": "Lulu", "latency_ms": 907.8261852264404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lulu", "latency_ms": 3107.4652671813965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 582}, "2": {"k": 2, "answer": "Lulu", "latency_ms": 1686.7311000823975, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Lulu", "latency_ms": 4348.877429962158, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1810}, "4": {"k": 4, "answer": "Lulu", "latency_ms": 2319.699287414551, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2423}, "5": {"k": 5, "answer": "Lulu", "latency_ms": 3173.116445541382, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3016}, "6": {"k": 6, "answer": "Lulu", "latency_ms": 3207.0045471191406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3686}}}
{"qid": "-7924663090486742985", "question": "american horror story freak show girl kidnapped by clown", "gold_answers": ["Bonnie Lipton"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1455.1913738250732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Twisty", "latency_ms": 1109.7075939178467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "Twisty", "latency_ms": 1598.6697673797607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Twisty", "latency_ms": 1985.4950904846191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Elsa", "latency_ms": 2349.7226238250732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2582}, "5": {"k": 5, "answer": "girl kidnapped by clown", "latency_ms": 5225.872993469238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3202}, "6": {"k": 6, "answer": "Elsa", "latency_ms": 5585.916996002197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3823}}}
{"qid": "-360675773049242516", "question": "the probability of making a type i error when retaining ho at the .05 level of significance is", "gold_answers": ["5 %"], "shots": {"0": {"k": 0, "answer": "0.05", "latency_ms": 3491.3370609283447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0.05", "latency_ms": 1822.1232891082764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "0.05", "latency_ms": 4208.088397979736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1151}, "3": {"k": 3, "answer": "0.05", "latency_ms": 2678.018808364868, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "0.05", "latency_ms": 3025.9697437286377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2354}, "5": {"k": 5, "answer": "0.05", "latency_ms": 2960.939884185791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2946}, "6": {"k": 6, "answer": "0.05", "latency_ms": 4332.714319229126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3538}}}
{"qid": "5819386267283467034", "question": "what year did the us hockey team won the olympics", "gold_answers": ["1960", "1980", "1960 and 1980"], "shots": {"0": {"k": 0, "answer": "1980", "latency_ms": 2957.1056365966797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1960, 1980", "latency_ms": 3202.31294631958, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "1960", "latency_ms": 1901.6509056091309, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1338}, "3": {"k": 3, "answer": "1960", "latency_ms": 4462.956428527832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1935}, "4": {"k": 4, "answer": "1960", "latency_ms": 3124.1726875305176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "1960, 1980", "latency_ms": 5542.152643203735, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3219}, "6": {"k": 6, "answer": "1960, 1980", "latency_ms": 6262.142181396484, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3843}}}
{"qid": "3916394566028297311", "question": "who wrote it's a long long way to pasadena", "gold_answers": ["Harry Vanda", "John Young", "David Hemmings", "George Young"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 4833.568096160889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1602.7452945709229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1864.316701889038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3140.286922454834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 4664.702653884888, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3250.908136367798, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3201}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 6768.342733383179, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3837}}}
{"qid": "-2432292250757146771", "question": "who wrote the song i hate you i love you", "gold_answers": ["Angel Benitez", "Olivia O'Brien", "Garrett Nash"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2233.8039875030518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ne-Yo, StarGate", "latency_ms": 2089.0793800354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Ne-Yo and StarGate", "latency_ms": 2397.5584506988525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Ne-Yo and StarGate", "latency_ms": 2975.5163192749023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1803}, "4": {"k": 4, "answer": "Ne-Yo and StarGate", "latency_ms": 3980.4694652557373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2431}, "5": {"k": 5, "answer": "Ne-Yo, StarGate", "latency_ms": 5337.862968444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3072}, "6": {"k": 6, "answer": "Mina", "latency_ms": 2949.847936630249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3660}}}
{"qid": "2393389448844632496", "question": "what is loihi and where does it originate from", "gold_answers": ["from the Hawaii hotspot"], "shots": {"0": {"k": 0, "answer": "Loihi is a seamount in the Pacific Ocean, originating from the Hawaiian hotspot.", "latency_ms": 4047.0964908599854, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Loihi is Intel's self-learning neuromorphic chip named after the Hawaiian seamount Loihi.", "latency_ms": 6521.928310394287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 723}, "2": {"k": 2, "answer": "Loihi is a submarine volcano in Hawaii; also a name for Intel's neuromorphic chip.", "latency_ms": 9889.748334884644, "em": 0.0, "f1": 0.13333333333333333, "containment": 0.0, "context_chars": 1403}, "3": {"k": 3, "answer": "Loihi is a submarine volcano in Hawaii; originates from the Hawaiian word meaning \"long\"", "latency_ms": 9583.24933052063, "em": 0.0, "f1": 0.26666666666666666, "containment": 0.0, "context_chars": 2072}, "4": {"k": 4, "answer": "Loihi is a seamount in Hawaii, originating from the Hawaiian island chain.", "latency_ms": 7265.780448913574, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 2750}, "5": {"k": 5, "answer": "Loihi is a submarine volcano in Hawaii, originating from the Hawaiian hotspot.", "latency_ms": 6411.80682182312, "em": 0.0, "f1": 0.4615384615384615, "containment": 0.0, "context_chars": 3404}, "6": {"k": 6, "answer": "Loihi is a submarine volcano in Hawaii, originating from the Hawaiian hotspot.", "latency_ms": 6778.075695037842, "em": 0.0, "f1": 0.4615384615384615, "containment": 0.0, "context_chars": 4077}}}
{"qid": "-6677440871585683891", "question": "who rebuilt the temple after the babylonian captivity", "gold_answers": ["Herod"], "shots": {"0": {"k": 0, "answer": "Zerubbabel", "latency_ms": 1270.4248428344727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jewish people", "latency_ms": 3498.927116394043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "Jews who had returned from the Babylonian captivity", "latency_ms": 3216.430902481079, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1171}, "3": {"k": 3, "answer": "Jews who had returned from the Babylonian captivity", "latency_ms": 3828.4876346588135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1822}, "4": {"k": 4, "answer": "Johanan (High Priest)", "latency_ms": 3055.39870262146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "Johanan (High Priest)", "latency_ms": 4015.432834625244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3096}, "6": {"k": 6, "answer": "Cyrus the Great", "latency_ms": 6032.795190811157, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3694}}}
{"qid": "-6750750235985613277", "question": "who was executed for being an american spy during the revolutionary war", "gold_answers": ["Nathan Hale"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1713.0990028381348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nathan Hale", "latency_ms": 1631.9386959075928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Nathan Hale", "latency_ms": 1857.226848602295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Nathan Hale", "latency_ms": 2071.8276500701904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1884}, "4": {"k": 4, "answer": "Nathan Hale", "latency_ms": 4048.922300338745, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Nathan Hale", "latency_ms": 6078.95827293396, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Nathan Hale", "latency_ms": 3391.1960124969482, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3833}}}
{"qid": "8770209312170080158", "question": "who sang the song suddenly with olivia newton john", "gold_answers": ["Cliff Richard"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 4634.744167327881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cliff Richard", "latency_ms": 1718.6353206634521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "Cliff Richard", "latency_ms": 2385.9450817108154, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1270}, "3": {"k": 3, "answer": "Cliff Richard", "latency_ms": 2577.5365829467773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Cliff Richard", "latency_ms": 4611.788034439087, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2542}, "5": {"k": 5, "answer": "Cliff Richard", "latency_ms": 3077.707052230835, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Cliff Richard", "latency_ms": 3864.0289306640625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3808}}}
{"qid": "-180549795106449014", "question": "who is command sergeant major of the army", "gold_answers": ["Daniel A. Dailey"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1284.0871810913086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Daniel A. Dailey", "latency_ms": 1759.685754776001, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 569}, "2": {"k": 2, "answer": "Daniel A. Dailey", "latency_ms": 2236.8814945220947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1137}, "3": {"k": 3, "answer": "Daniel A. Dailey", "latency_ms": 2677.6185035705566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1843}, "4": {"k": 4, "answer": "Daniel A. Dailey", "latency_ms": 2878.0112266540527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2520}, "5": {"k": 5, "answer": "Daniel A. Dailey", "latency_ms": 3631.1581134796143, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3166}, "6": {"k": 6, "answer": "Daniel A. Dailey", "latency_ms": 3885.331392288208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3911}}}
{"qid": "7815138213728640354", "question": "who sings the original windmills of your mind", "gold_answers": ["Noel Harrison"], "shots": {"0": {"k": 0, "answer": "The Kinks", "latency_ms": 1062.7422332763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frank Sinatra", "latency_ms": 1227.5326251983643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "The song \"The Windmills of Your Mind\" was introduced in the film *The Thomas Crown Affair* (1968), and the original version was performed by **Frank Sinatra**. However, based on the provided context, it does not explicitly state who sings the original version. The context mentions a cover by Sting but does not name the original singer.\n\nI cannot answer.", "latency_ms": 17217.849493026733, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Noel Harrison", "latency_ms": 2343.2536125183105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Noel Harrison", "latency_ms": 2299.2382049560547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2570}, "5": {"k": 5, "answer": "Noel Harrison", "latency_ms": 2800.53448677063, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3206}, "6": {"k": 6, "answer": "Noel Harrison", "latency_ms": 3352.240562438965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3812}}}
{"qid": "2098168902147822379", "question": "where will the next summer and winter olympics be held", "gold_answers": ["Beijing", "Tokyo"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1262.6502513885498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Beijing", "latency_ms": 1302.71577835083, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 623}, "2": {"k": 2, "answer": "Beijing", "latency_ms": 2313.129186630249, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2476.0360717773438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "Abu Dhabi, United Arab Emirates (Summer 2019, Winter 2022)", "latency_ms": 6878.7829875946045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2457}, "5": {"k": 5, "answer": "Abu Dhabi, United Arab Emirates (Summer 2019); Beijing, China (Winter 2022)", "latency_ms": 9345.610857009888, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 3128}, "6": {"k": 6, "answer": "Abu Dhabi (Summer 2028), Beijing (Winter 2030)", "latency_ms": 11457.236051559448, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 3804}}}
{"qid": "-1458476052377668874", "question": "when did ole miss beat alabama in football", "gold_answers": ["September 19 , 2015", "October 3 , 1970", "October 27 , 1894", "October 13 , 2001", "October 5 , 1968", "October 4 , 2014", "September 11 , 1976", "October 8 , 1988", "October 18 , 2003", "November 5 , 1910"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 3037.1158123016357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1589.3666744232178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "1988", "latency_ms": 2948.652744293213, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "1988", "latency_ms": 6704.496145248413, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1825}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3259.7720623016357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2438}, "5": {"k": 5, "answer": "2014", "latency_ms": 4212.887287139893, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3073}, "6": {"k": 6, "answer": "1910", "latency_ms": 4055.0992488861084, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3701}}}
{"qid": "-6861734002351236912", "question": "who sang the song how far is heaven", "gold_answers": ["Los Lonely Boys"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1792.616605758667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Moore", "latency_ms": 967.2853946685791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Justin Moore", "latency_ms": 1618.4513568878174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1196}, "3": {"k": 3, "answer": "Justin Moore", "latency_ms": 3212.3284339904785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1785}, "4": {"k": 4, "answer": "Justin Moore", "latency_ms": 2129.476547241211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2374}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3666.647434234619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2973}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 5523.618459701538, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3590}}}
{"qid": "-1722216190521937227", "question": "where are the organ mountains in new mexico", "gold_answers": ["southern New Mexico"], "shots": {"0": {"k": 0, "answer": "Organ Mountains are located in southern New Mexico, near the border with Arizona.", "latency_ms": 3490.589141845703, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "southern New Mexico, east of Las Cruces, Doña Ana County", "latency_ms": 5802.867650985718, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "southern New Mexico, near Las Cruces in Doña Ana County", "latency_ms": 4370.43833732605, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1325}, "3": {"k": 3, "answer": "southern New Mexico, near Las Cruces in Doña Ana County", "latency_ms": 5144.492864608765, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1986}, "4": {"k": 4, "answer": "southern New Mexico, east of Las Cruces, Doña Ana County", "latency_ms": 4960.852146148682, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2643}, "5": {"k": 5, "answer": "southern New Mexico, east of Las Cruces, Doña Ana County", "latency_ms": 7573.855876922607, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3235}, "6": {"k": 6, "answer": "southern New Mexico, east of Las Cruces, Doña Ana County", "latency_ms": 6896.621942520142, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3856}}}
{"qid": "-2717119588239727064", "question": "where are the 10 plagues found in the bible", "gold_answers": ["Book of Exodus", "Exodus"], "shots": {"0": {"k": 0, "answer": "Exodus 7–12", "latency_ms": 1916.271686553955, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Exodus 7–12", "latency_ms": 3203.819513320923, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 570}, "2": {"k": 2, "answer": "Exodus 7–12", "latency_ms": 2587.334394454956, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1238}, "3": {"k": 3, "answer": "Exodus 7–12", "latency_ms": 2915.9960746765137, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Exodus 7–12", "latency_ms": 3477.180004119873, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2465}, "5": {"k": 5, "answer": "Book of Exodus", "latency_ms": 2605.1244735717773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3091}, "6": {"k": 6, "answer": "Book of Exodus", "latency_ms": 5219.502925872803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3739}}}
{"qid": "2988284357714596500", "question": "where are red blood cells made in adults", "gold_answers": ["in the bone marrow"], "shots": {"0": {"k": 0, "answer": "bone marrow", "latency_ms": 3823.3301639556885, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "bone marrow", "latency_ms": 3547.3413467407227, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "red bone marrow", "latency_ms": 1679.098129272461, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "bone marrow", "latency_ms": 2979.0420532226562, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1911}, "4": {"k": 4, "answer": "bone marrow", "latency_ms": 2004.3766498565674, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "bone marrow", "latency_ms": 4880.26237487793, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3245}, "6": {"k": 6, "answer": "bone marrow", "latency_ms": 2761.496067047119, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3887}}}
{"qid": "-4616596799374362422", "question": "who was the pinkerton detective agency's first female detective", "gold_answers": ["Kate Warne"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1238.126516342163, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kate Warne", "latency_ms": 2054.861545562744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Kate Warne", "latency_ms": 2538.907289505005, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1235}, "3": {"k": 3, "answer": "Kate Warne", "latency_ms": 2335.7818126678467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Kate Warne", "latency_ms": 5256.293773651123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2548}, "5": {"k": 5, "answer": "Kate Warne", "latency_ms": 3587.42094039917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3173}, "6": {"k": 6, "answer": "Kate Warne", "latency_ms": 5087.59880065918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3846}}}
{"qid": "-3650291155113659146", "question": "how many episodes are there in modern family", "gold_answers": ["232", "201"], "shots": {"0": {"k": 0, "answer": "216 episodes", "latency_ms": 1273.263931274414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "24 episodes", "latency_ms": 1465.9032821655273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2004.913091659546, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 4587.068796157837, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 5703.587055206299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3203.7789821624756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3043.4348583221436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3768}}}
{"qid": "3381924381590631417", "question": "who built the first temple for god in jerusalem", "gold_answers": ["Solomon"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1439.6088123321533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "King Solomon", "latency_ms": 1188.7764930725098, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "King Solomon", "latency_ms": 1791.8672561645508, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1276}, "3": {"k": 3, "answer": "Josiah", "latency_ms": 1956.3298225402832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1911}, "4": {"k": 4, "answer": "Solomon", "latency_ms": 2087.2514247894287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2471}, "5": {"k": 5, "answer": "Solomon", "latency_ms": 2562.0079040527344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3155}, "6": {"k": 6, "answer": "Solomon", "latency_ms": 3768.3017253875732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3777}}}
{"qid": "-154783694579651082", "question": "what is a dropped pin on google maps for", "gold_answers": ["marks locations", "marks locations in Google Maps"], "shots": {"0": {"k": 0, "answer": "A dropped pin on Google Maps typically indicates a user-created location marker, such as a place of interest, a personal location, or a point of significance. It may also represent a temporary or unofficial location, like a meeting spot or a point of interest not officially listed. Dropped pins are often used for sharing or marking locations with others.", "latency_ms": 22734.612226486206, "em": 0.0, "f1": 0.10714285714285714, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a location", "latency_ms": 1713.3054733276367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "marking a point on a map without obscuring the location", "latency_ms": 7407.410621643066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "a location", "latency_ms": 1443.9527988433838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "a location", "latency_ms": 3131.1097145080566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "a location", "latency_ms": 4082.5343132019043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3039}, "6": {"k": 6, "answer": "a location", "latency_ms": 2748.1329441070557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3715}}}
{"qid": "6915606477668963399", "question": "what do the 3 dots mean in math", "gold_answers": ["the therefore sign", "therefore sign"], "shots": {"0": {"k": 0, "answer": "ellipses", "latency_ms": 2819.577932357788, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1825.510025024414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2971.3923931121826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "therefore", "latency_ms": 2995.9850311279297, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "therefore", "latency_ms": 2077.094793319702, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "derivatives with respect to time", "latency_ms": 4325.061082839966, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3281}, "6": {"k": 6, "answer": "derivatives with respect to time", "latency_ms": 6035.613298416138, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3870}}}
{"qid": "-8366545547296627039", "question": "who wrote the song photograph by ringo starr", "gold_answers": ["Richard Starkey", "George Harrison", "Ringo Starr"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1263.1120681762695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ringo Starr and George Harrison", "latency_ms": 1813.6274814605713, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Ringo Starr and George Harrison", "latency_ms": 8500.833511352539, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "George Harrison", "latency_ms": 2392.047882080078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1957}, "4": {"k": 4, "answer": "Ringo Starr and George Harrison", "latency_ms": 3654.298782348633, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2652}, "5": {"k": 5, "answer": "Ringo Starr and George Harrison", "latency_ms": 5571.7785358428955, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3307}, "6": {"k": 6, "answer": "Ringo Starr and George Harrison", "latency_ms": 4952.695608139038, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3963}}}
{"qid": "-5004457603684974952", "question": "who is playing the halftime show at super bowl 2016", "gold_answers": ["Beyoncé", "Coldplay", "Bruno Mars"], "shots": {"0": {"k": 0, "answer": "Bruno Mars", "latency_ms": 2834.733724594116, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Coldplay", "latency_ms": 3657.2792530059814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "Coldplay", "latency_ms": 1830.9259414672852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Coldplay with Beyoncé and Bruno Mars", "latency_ms": 5558.155298233032, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Coldplay with Beyoncé and Bruno Mars", "latency_ms": 5028.730392456055, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2580}, "5": {"k": 5, "answer": "Coldplay with Beyoncé and Bruno Mars", "latency_ms": 4231.232643127441, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "Coldplay with Beyoncé and Bruno Mars", "latency_ms": 5326.196193695068, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3884}}}
{"qid": "7420920477821898435", "question": "to aru kagaku no railgun s episode 3", "gold_answers": ["Project Radio Noise"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1235.7778549194336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1604.2075157165527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2006.1936378479004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1389}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2663.8219356536865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1980}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 4890.42592048645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2650}, "5": {"k": 5, "answer": "A Certain Scientific Railgun S episode 3", "latency_ms": 6061.637163162231, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3267}, "6": {"k": 6, "answer": "2013", "latency_ms": 4891.12663269043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3872}}}
{"qid": "7478795216476346339", "question": "who won the 2017 sports personality of the year", "gold_answers": ["Mo Farah"], "shots": {"0": {"k": 0, "answer": "Tayler Hill", "latency_ms": 1476.5903949737549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dame Sarah Storey", "latency_ms": 3094.139814376831, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "Dame Sarah Storey", "latency_ms": 4290.572643280029, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2672.438621520996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2456.6307067871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2542}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3718.5287475585938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3122}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3914.6950244903564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3761}}}
{"qid": "7217222058435937287", "question": "where was the world economic forum held this year", "gold_answers": ["Davos"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1444.7686672210693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Baku", "latency_ms": 2820.543050765991, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 4018.6524391174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2557.2307109832764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1971}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 4151.790142059326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2591}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3016.7460441589355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3110.0893020629883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3935}}}
{"qid": "-143054837169120955", "question": "where are the giant redwoods located in california", "gold_answers": ["the coast of northern California", "Del Norte County", "Humboldt County"], "shots": {"0": {"k": 0, "answer": "Redwood National and State Parks", "latency_ms": 1656.996250152588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 5334.054946899414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "Kings Canyon National Park and Giant Sequoia National Monument, Sierra Nevada, California", "latency_ms": 4864.84432220459, "em": 0.0, "f1": 0.125, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Redwood Mountain Grove in Kings Canyon National Park and Giant Sequoia National Monument, California's Sierra Nevada", "latency_ms": 7426.291942596436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Redwood Mountain Grove in Kings Canyon National Park and Giant Sequoia National Monument, California's Sierra Nevada; Big Basin Redwoods State Park in Santa Cruz County; Humboldt Redwoods State Park in southern Humboldt County.", "latency_ms": 13982.925415039062, "em": 0.0, "f1": 0.11428571428571428, "containment": 1.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Redwood Mountain Grove in Kings Canyon National Park and Giant Sequoia National Monument, California's Sierra Nevada; Big Basin Redwoods State Park in Santa Cruz County; Humboldt Redwoods State Park in southern Humboldt County.", "latency_ms": 18163.710117340088, "em": 0.0, "f1": 0.11428571428571428, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Redwood Mountain Grove in Kings Canyon National Park and Giant Sequoia National Monument, California", "latency_ms": 5860.170125961304, "em": 0.0, "f1": 0.11111111111111112, "containment": 0.0, "context_chars": 3832}}}
{"qid": "4892429640540595424", "question": "who has made the most premier league appearances", "gold_answers": ["Gareth Barry"], "shots": {"0": {"k": 0, "answer": "Alan Shearer", "latency_ms": 1154.9954414367676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gareth Barry", "latency_ms": 2028.3217430114746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Gareth Barry", "latency_ms": 1828.2456398010254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Gareth Barry", "latency_ms": 2691.2879943847656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Gareth Barry", "latency_ms": 2395.946502685547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2542}, "5": {"k": 5, "answer": "Gareth Barry", "latency_ms": 5203.203201293945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3203}, "6": {"k": 6, "answer": "Gareth Barry", "latency_ms": 3659.3878269195557, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3858}}}
{"qid": "5533906981191706877", "question": "who was the first chief minister of west bengal", "gold_answers": ["Prafulla Chandra Ghosh"], "shots": {"0": {"k": 0, "answer": "P. C. Bagchi", "latency_ms": 4797.658681869507, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Prafulla Chandra Ghosh", "latency_ms": 2852.0290851593018, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3713.665246963501, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1408}, "3": {"k": 3, "answer": "Prafulla Chandra Ghosh", "latency_ms": 5456.748008728027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2054}, "4": {"k": 4, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3901.9172191619873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2656}, "5": {"k": 5, "answer": "Prafulla Chandra Ghosh", "latency_ms": 5477.8892993927, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "Prafulla Chandra Ghosh", "latency_ms": 6252.626180648804, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4012}}}
{"qid": "8823076125131408628", "question": "who sings got my mind set on you", "gold_answers": ["George Harrison", "James Ray"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2713.5660648345947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2993.9839839935303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3936.8996620178223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1890.0859355926514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1784}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3921.3778972625732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2318}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2794.7282791137695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2971}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3169.574022293091, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3545}}}
{"qid": "9168660859139861094", "question": "two main types of research methods used in psychology", "gold_answers": ["Correlational research", "Descriptive research", "quantitative data", "Quantitative psychological research", "qualitative", "quantitative", "Qualitative psychological research", "Experimental research", "qualitative data"], "shots": {"0": {"k": 0, "answer": "experimental and observational", "latency_ms": 1397.7913856506348, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "qualitative, quantitative", "latency_ms": 1557.645559310913, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 807}, "2": {"k": 2, "answer": "qualitative and quantitative", "latency_ms": 1801.2912273406982, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1554}, "3": {"k": 3, "answer": "qualitative and quantitative", "latency_ms": 2253.3252239227295, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2378}, "4": {"k": 4, "answer": "qualitative and quantitative", "latency_ms": 3630.5530071258545, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3120}, "5": {"k": 5, "answer": "qualitative and quantitative", "latency_ms": 2952.904462814331, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3923}, "6": {"k": 6, "answer": "qualitative and quantitative", "latency_ms": 3241.0342693328857, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4660}}}
{"qid": "-7073063191952855764", "question": "who plays peter in what we do in the shadows", "gold_answers": ["Ben Fransham"], "shots": {"0": {"k": 0, "answer": "Matt Berry", "latency_ms": 859.4460487365723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1781.5468311309814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2094.712972640991, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2306.2353134155273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 4869.07958984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3099.3709564208984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3369.7168827056885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "7901746249864619718", "question": "when does the 14th season of grey's anatomy come out", "gold_answers": ["September 28 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1703.9763927459717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 28, 2017", "latency_ms": 4160.489082336426, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 28, 2017", "latency_ms": 3313.0738735198975, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "September 28, 2017", "latency_ms": 8509.551286697388, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 28, 2017", "latency_ms": 4042.3784255981445, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2701}, "5": {"k": 5, "answer": "September 28, 2017", "latency_ms": 4224.65705871582, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3389}, "6": {"k": 6, "answer": "September 28, 2017", "latency_ms": 7642.379999160767, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4057}}}
{"qid": "-896127746191949637", "question": "when was the first hunger games book published", "gold_answers": ["September 14 , 2008", "2008"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 1282.0563316345215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 14, 2008", "latency_ms": 3316.4565563201904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "September 14, 2008", "latency_ms": 5332.390308380127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1322}, "3": {"k": 3, "answer": "September 14, 2008", "latency_ms": 3744.5647716522217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1996}, "4": {"k": 4, "answer": "September 14, 2008", "latency_ms": 3844.377040863037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2679}, "5": {"k": 5, "answer": "September 14, 2008", "latency_ms": 5503.951787948608, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3304}, "6": {"k": 6, "answer": "September 14, 2008", "latency_ms": 4839.803695678711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3917}}}
{"qid": "8044909700499569711", "question": "how much is the united states in debt to china", "gold_answers": ["$1.06 trillion", "1,200.5"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1562.5202655792236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "10 percent of total U.S. public debt", "latency_ms": 2887.234687805176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "$1.18 trillion", "latency_ms": 3439.7337436676025, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "$1.18 trillion", "latency_ms": 5431.646823883057, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "$1.18 trillion", "latency_ms": 3372.7784156799316, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "$1.18 trillion", "latency_ms": 3629.713535308838, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3199}, "6": {"k": 6, "answer": "$1.18 trillion", "latency_ms": 6351.8218994140625, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3843}}}
{"qid": "-3123234845590594961", "question": "where did the race in grease take place", "gold_answers": ["Thunder Road"], "shots": {"0": {"k": 0, "answer": "California", "latency_ms": 888.9434337615967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles River", "latency_ms": 3266.097068786621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Los Angeles River", "latency_ms": 1736.513376235962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "Los Angeles River", "latency_ms": 2160.5448722839355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Los Angeles River, between the First and", "latency_ms": 3361.4790439605713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Los Angeles River", "latency_ms": 3033.8134765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3141}, "6": {"k": 6, "answer": "Los Angeles River", "latency_ms": 3101.7518043518066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "4326992806019599297", "question": "what is the maximum data rate for the 802.11a standard select one", "gold_answers": ["54 Mbit / s"], "shots": {"0": {"k": 0, "answer": "54 Mbps", "latency_ms": 1041.534662246704, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "54 Mbit/s", "latency_ms": 2870.255470275879, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "54 Mbit/s", "latency_ms": 2768.0795192718506, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "54 Mbit/s", "latency_ms": 2928.614854812622, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1997}, "4": {"k": 4, "answer": "54 Mbit/s", "latency_ms": 5190.650224685669, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "54 Mbit/s", "latency_ms": 4276.942491531372, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "54 Mbit/s", "latency_ms": 4485.53729057312, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3927}}}
{"qid": "6144099837933283715", "question": "a good that can be used in place of another good", "gold_answers": ["A substitute good", "substitute good"], "shots": {"0": {"k": 0, "answer": "substitute good", "latency_ms": 1029.8130512237549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "pickling salt", "latency_ms": 1150.1097679138184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 537}, "2": {"k": 2, "answer": "pickling salt", "latency_ms": 1707.5328826904297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1157}, "3": {"k": 3, "answer": "pickling salt can be used in place of table salt", "latency_ms": 7436.563491821289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1814}, "4": {"k": 4, "answer": "pickling salt", "latency_ms": 3601.043462753296, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2368}, "5": {"k": 5, "answer": "pickling salt can be used in place of table salt", "latency_ms": 6819.251298904419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3048}, "6": {"k": 6, "answer": "pickling salt", "latency_ms": 2966.0511016845703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-4621948696356225060", "question": "where in the bible can i find the lord's prayer", "gold_answers": ["the Gospel of Luke", "the Gospel of Matthew"], "shots": {"0": {"k": 0, "answer": "Matthew 6:9-13", "latency_ms": 3546.7028617858887, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2940.3836727142334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 562}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3909.4557762145996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Matthew 6:9", "latency_ms": 4562.361717224121, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1769}, "4": {"k": 4, "answer": "Matthew 6:9-13", "latency_ms": 5219.400405883789, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2350}, "5": {"k": 5, "answer": "Matthew 6:9-13", "latency_ms": 5327.070236206055, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2985}, "6": {"k": 6, "answer": "Matthew 6:9-13", "latency_ms": 4631.359100341797, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3623}}}
{"qid": "6941993254369956277", "question": "when was the last time nebraska voted democrat", "gold_answers": ["1964"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 1242.8321838378906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1908", "latency_ms": 1384.0258121490479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "1908", "latency_ms": 4445.8465576171875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1397}, "3": {"k": 3, "answer": "1994", "latency_ms": 2713.6642932891846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2129}, "4": {"k": 4, "answer": "1994", "latency_ms": 2547.834873199463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2814}, "5": {"k": 5, "answer": "1994", "latency_ms": 3838.9503955841064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3495}, "6": {"k": 6, "answer": "1994", "latency_ms": 4693.202018737793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4146}}}
{"qid": "-8955197065025093046", "question": "who become the ceo of it wipro company in 2016", "gold_answers": ["Abid Ali Neemuchwala"], "shots": {"0": {"k": 0, "answer": "Arun Sundararajan", "latency_ms": 3639.7342681884766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Abidali Neemuchwala", "latency_ms": 2577.2483348846436, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Abidali Neemuchwala", "latency_ms": 7215.076923370361, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Abidali Neemuchwala", "latency_ms": 6782.970428466797, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2047}, "4": {"k": 4, "answer": "Abidali Neemuchwala", "latency_ms": 4502.28476524353, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2675}, "5": {"k": 5, "answer": "Abidali Neemuchwala", "latency_ms": 4082.4902057647705, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3341}, "6": {"k": 6, "answer": "Abidali Neemuchwala", "latency_ms": 8161.263465881348, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3981}}}
{"qid": "-3010425579521817304", "question": "who does eric end up with in gossip girl", "gold_answers": ["Jenny"], "shots": {"0": {"k": 0, "answer": "Serena", "latency_ms": 3437.570095062256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2051.900625228882, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2732.0282459259033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2280.8587551116943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 5152.253866195679, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2749.3700981140137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 6070.275783538818, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}}}
{"qid": "7264112453286983469", "question": "who plays unis in she's the man", "gold_answers": ["Emily Perkins"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1419.6865558624268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3339.1263484954834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2027.8146266937256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 6317.734003067017, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2678.013324737549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3175.497531890869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 4732.240438461304, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3767}}}
{"qid": "2627695648792729859", "question": "who played booster in jingle all the way", "gold_answers": ["Curtis Armstrong"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1224.2178916931152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1833.9369297027588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 679}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3414.8166179656982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1342}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 5358.697175979614, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2010}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3515.516996383667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2699}, "5": {"k": 5, "answer": "Tim Flattery", "latency_ms": 4674.755096435547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3332}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3429.990291595459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3986}}}
{"qid": "-9169976182548289414", "question": "who is recognized as the founder of islam", "gold_answers": ["the Islamic prophet Muhammad", "Muhammad"], "shots": {"0": {"k": 0, "answer": "Muhammad", "latency_ms": 1329.941987991333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1819.0693855285645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "Muhammad", "latency_ms": 1561.9864463806152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Muhammad", "latency_ms": 2023.6096382141113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1925}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2501.2245178222656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2567}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3496.4332580566406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3193}, "6": {"k": 6, "answer": "Muhammad", "latency_ms": 3146.7723846435547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3813}}}
{"qid": "-6696747560626271522", "question": "who plays emma in air bud world pup", "gold_answers": ["Brittany Paige Bouck"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1318.8002109527588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2810.1751804351807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3480.0007343292236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2267.2557830810547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2512.4151706695557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 4959.714889526367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3169}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3625.28133392334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3794}}}
{"qid": "5871681964137793716", "question": "how old was sasuke when his clan died", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1231.3711643218994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "seven", "latency_ms": 771.8343734741211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "7", "latency_ms": 2831.1259746551514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "7", "latency_ms": 2497.0219135284424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1875}, "4": {"k": 4, "answer": "7", "latency_ms": 4310.884714126587, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "7", "latency_ms": 2530.965566635132, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3145}, "6": {"k": 6, "answer": "7", "latency_ms": 2999.234199523926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3760}}}
{"qid": "8552176802923865025", "question": "where do some of the natural air pollutants come from", "gold_answers": ["wildfires", "Dust", "Vegetation", "Carbon dioxide", "Volcanic activity"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1371.985673904419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "natural sources", "latency_ms": 961.7812633514404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 718}, "2": {"k": 2, "answer": "volcanic eruptions", "latency_ms": 2309.9379539489746, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "volcanic eruptions", "latency_ms": 2292.5641536712646, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2025}, "4": {"k": 4, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity", "latency_ms": 12057.281494140625, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 2776}, "5": {"k": 5, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity", "latency_ms": 8462.692260742188, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 3506}, "6": {"k": 6, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity", "latency_ms": 7330.8210372924805, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 4123}}}
{"qid": "-2630525064809360052", "question": "who is the pastor of new birth missionary baptist church now", "gold_answers": ["Stephen A. Davis"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1226.0496616363525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jamal Bryant", "latency_ms": 1654.515027999878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Jamal Bryant", "latency_ms": 1799.6265888214111, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1353}, "3": {"k": 3, "answer": "Jamal Bryant", "latency_ms": 2421.3147163391113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1990}, "4": {"k": 4, "answer": "Jamal Bryant", "latency_ms": 3155.8589935302734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2621}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3721.146821975708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3286}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3750.8041858673096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3959}}}
{"qid": "6434931911289860123", "question": "who is doing 2018 super bowl half time show", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "Mark Ronson", "latency_ms": 1872.2155094146729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Timberlake", "latency_ms": 1616.7211532592773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "Justin Timberlake", "latency_ms": 2057.490587234497, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Justin Timberlake", "latency_ms": 3426.2161254882812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Justin Timberlake", "latency_ms": 2571.7501640319824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2587}, "5": {"k": 5, "answer": "Justin Timberlake", "latency_ms": 3280.079126358032, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3249}, "6": {"k": 6, "answer": "Justin Timberlake", "latency_ms": 2974.3988513946533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3874}}}
{"qid": "8869318258439148973", "question": "who is playing the halftime show for the superbowl", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 3172.4941730499268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Coldplay", "latency_ms": 1608.689785003662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "Coldplay", "latency_ms": 1791.9471263885498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Coldplay", "latency_ms": 1947.7105140686035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Coldplay, Beyoncé, Bruno Mars", "latency_ms": 4762.549161911011, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2526}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 4961.417198181152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3158}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2937.0152950286865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3819}}}
{"qid": "-8359866474144720253", "question": "who hosted they think it's all over", "gold_answers": ["Des Lynam", "Lee Mack", "comedian Nick Hancock", "Nick Hancock"], "shots": {"0": {"k": 0, "answer": "They Think It's All Over was hosted by Bob Barker.", "latency_ms": 5188.942432403564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alex Riley", "latency_ms": 1089.7927284240723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1946.2306499481201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Alex Riley", "latency_ms": 1846.0936546325684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "Alex Riley", "latency_ms": 3204.9460411071777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "Alex Riley", "latency_ms": 2719.289779663086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3286.6854667663574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3703}}}
{"qid": "-1206653570097564556", "question": "where does the movie proof of life take place", "gold_answers": ["The Republic of Tecala"], "shots": {"0": {"k": 0, "answer": "India", "latency_ms": 636.2128257751465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New Orleans, Louisiana", "latency_ms": 3233.0663204193115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3667.417287826538, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "Leipzig", "latency_ms": 2041.562557220459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "Republic of Tecala", "latency_ms": 2519.1903114318848, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2486}, "5": {"k": 5, "answer": "Republic of Tecala", "latency_ms": 3488.431930541992, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3083}, "6": {"k": 6, "answer": "Republic of Tecala", "latency_ms": 3664.6437644958496, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3728}}}
{"qid": "6144521615402262404", "question": "where does us highway 1 start and end", "gold_answers": ["Fort Kent , Maine", "to Key West , Florida", "Key West , Florida"], "shots": {"0": {"k": 0, "answer": "U.S. Highway 1 starts in Miami, Florida, and ends in Bar Harbor, Maine.", "latency_ms": 4429.344654083252, "em": 0.0, "f1": 0.125, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1873.4166622161865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2265.9945487976074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1217}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2439.6040439605713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1811}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2758.6846351623535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2442}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 4187.744617462158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3758.8374614715576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3823}}}
{"qid": "-8631190913794477985", "question": "who scored the most points in a single game in the nba", "gold_answers": ["Wilt Chamberlain"], "shots": {"0": {"k": 0, "answer": "Wilt Chamberlain", "latency_ms": 1445.5361366271973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wilt Chamberlain", "latency_ms": 1828.012466430664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "Wilt Chamberlain", "latency_ms": 2649.651050567627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1310}, "3": {"k": 3, "answer": "Wilt Chamberlain", "latency_ms": 4722.083568572998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Wilt Chamberlain", "latency_ms": 5352.247476577759, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Wilt Chamberlain", "latency_ms": 5129.550457000732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3083}, "6": {"k": 6, "answer": "Wilt Chamberlain", "latency_ms": 4033.705711364746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3637}}}
{"qid": "199896377614951764", "question": "where is natural gas found in the us", "gold_answers": ["Texas", "Pennsylvania", "Colorado", "New Mexico", "West Virginia", "Arkansas", "Wyoming", "Louisiana"], "shots": {"0": {"k": 0, "answer": "Texas, North Dakota, Wyoming, Pennsylvania, and Utah", "latency_ms": 3241.551160812378, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "offshore from Louisiana, Texas, California, and Alaska", "latency_ms": 4924.587249755859, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 630}, "2": {"k": 2, "answer": "offshore from Louisiana, Texas, California, and Alaska; in shale formations", "latency_ms": 4268.495082855225, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "trapped within shale formations", "latency_ms": 2731.0731410980225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1825}, "4": {"k": 4, "answer": "trapped within shale formations", "latency_ms": 5077.833652496338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2501}, "5": {"k": 5, "answer": "deep underground rock formations or associated with other hydrocarbon reservoirs in coal beds and as methane clathrates", "latency_ms": 7852.582693099976, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "deep underground rock formations, associated with other hydrocarbon reservoirs in coal beds, and as methane clathrates", "latency_ms": 6866.294384002686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3889}}}
{"qid": "8986775680996674901", "question": "when were the first general elections held in independent india", "gold_answers": ["1951 -- 52"], "shots": {"0": {"k": 0, "answer": "15 August 1947", "latency_ms": 4482.533931732178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1952", "latency_ms": 1879.1651725769043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "1952", "latency_ms": 3064.8410320281982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "1952", "latency_ms": 4720.588207244873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1977}, "4": {"k": 4, "answer": "25 October 1951 to 21 February 1952", "latency_ms": 6625.537395477295, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "25 October 1951 to 21 February 1952", "latency_ms": 8312.204360961914, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 3250}, "6": {"k": 6, "answer": "25 October 1951 to 21 February 1952", "latency_ms": 10946.959733963013, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 3884}}}
{"qid": "700604097171850168", "question": "what was the tower of london originally used for", "gold_answers": ["as a royal residence", "a royal residence"], "shots": {"0": {"k": 0, "answer": "Royal palace and fortress", "latency_ms": 1251.0857582092285, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "castle", "latency_ms": 1187.8912448883057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "castle", "latency_ms": 3753.042221069336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "original incidental role of the Tower – as would have been the case for any castle", "latency_ms": 4960.610866546631, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "timber fortification enclosed by a palisade", "latency_ms": 3720.752477645874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "timber fortification enclosed by a palisade", "latency_ms": 4493.7286376953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3097}, "6": {"k": 6, "answer": "timber fortification enclosed by a palisade", "latency_ms": 4992.685556411743, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3720}}}
{"qid": "6745303307988470742", "question": "what type of fuel goes in a zippo", "gold_answers": ["butane", "lighter fluid"], "shots": {"0": {"k": 0, "answer": "Zippo uses lighter fluid or white gas.", "latency_ms": 3604.1150093078613, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "lighter fluid or naphtha", "latency_ms": 2531.996965408325, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "lighter fluid or naphtha", "latency_ms": 2675.2560138702393, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1202}, "3": {"k": 3, "answer": "lighter fluid or naphtha", "latency_ms": 4713.557958602905, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "lighter fluid or naphtha", "latency_ms": 6062.005043029785, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2400}, "5": {"k": 5, "answer": "lighter fluid (naphtha) or butane", "latency_ms": 5177.375793457031, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3039}, "6": {"k": 6, "answer": "lighter fluid or naphtha", "latency_ms": 7978.559255599976, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3677}}}
{"qid": "-2060506905455252030", "question": "first jnanpith award was an autor of which language", "gold_answers": ["Malayalam"], "shots": {"0": {"k": 0, "answer": "Kannada", "latency_ms": 3728.8293838500977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bengali", "latency_ms": 3858.583450317383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 669}, "2": {"k": 2, "answer": "Bengali", "latency_ms": 2228.067636489868, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1332}, "3": {"k": 3, "answer": "Bengali", "latency_ms": 2641.559600830078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1980}, "4": {"k": 4, "answer": "Bengali", "latency_ms": 2592.4503803253174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "Bengali", "latency_ms": 4206.369161605835, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "Bengali", "latency_ms": 5414.876937866211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3990}}}
{"qid": "4738663028303377024", "question": "who played the mad hatter in the batman tv show", "gold_answers": ["Roddy McDowall", "David Wayne", "Benedict Samuel"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1489.3743991851807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3192.9666996002197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 4399.904012680054, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "David Warner", "latency_ms": 2099.8694896698, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Ed Wynn", "latency_ms": 2336.5111351013184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3232.2728633880615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3213}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 4062.6370906829834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3868}}}
{"qid": "-1650946015201779846", "question": "how many cracker barrels in the united states", "gold_answers": ["639", "more than 600"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1236.7963790893555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "645", "latency_ms": 2466.2489891052246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "645", "latency_ms": 4768.442392349243, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "645", "latency_ms": 2335.3471755981445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "645", "latency_ms": 2859.82346534729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2593}, "5": {"k": 5, "answer": "645", "latency_ms": 2800.1208305358887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3218}, "6": {"k": 6, "answer": "645", "latency_ms": 4836.112976074219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3864}}}
{"qid": "-3422350952909582054", "question": "in photosynthesis the carbon in co2 is initially fixed to what molecule", "gold_answers": ["3 - phosphoglycerate"], "shots": {"0": {"k": 0, "answer": "3-phosphoglycerate", "latency_ms": 3424.799919128418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 7424.780368804932, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 712}, "2": {"k": 2, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 7581.270933151245, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1411}, "3": {"k": 3, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 5892.306804656982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2116}, "4": {"k": 4, "answer": "ribulose 1,5-bisphosphate", "latency_ms": 8217.432737350464, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2845}, "5": {"k": 5, "answer": "ribulose 1,5-bisphosphate", "latency_ms": 9294.544458389282, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3553}, "6": {"k": 6, "answer": "ribulose 1,5-bisphosphate", "latency_ms": 7827.331066131592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4269}}}
{"qid": "-2704708103393811482", "question": "who voices randy in f is for family", "gold_answers": ["T.J. Miller"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1401.0226726531982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parker", "latency_ms": 1658.2207679748535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "Parker", "latency_ms": 1404.8898220062256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 4094.9504375457764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1925}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 4558.382987976074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2554}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 5135.703086853027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3607.8813076019287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3688}}}
{"qid": "5482012214308896475", "question": "how many countries does cadbury sell its products", "gold_answers": ["more than 50", "more than 50 countries worldwide"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1290.81392288208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "30", "latency_ms": 1618.7782287597656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "more than fifty", "latency_ms": 2069.629192352295, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1356}, "3": {"k": 3, "answer": "more than fifty", "latency_ms": 3767.4217224121094, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2064}, "4": {"k": 4, "answer": "more than fifty", "latency_ms": 2596.0822105407715, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2698}, "5": {"k": 5, "answer": "more than fifty", "latency_ms": 5083.359718322754, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3397}, "6": {"k": 6, "answer": "more than fifty", "latency_ms": 3352.5550365448, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 4125}}}
{"qid": "-5737509619250561344", "question": "ethiopia flight 961 crashes in to the sea", "gold_answers": ["23 November 1996"], "shots": {"0": {"k": 0, "answer": "1996", "latency_ms": 3523.0183601379395, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indian Ocean", "latency_ms": 1210.1542949676514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "Indian Ocean near The Comoros", "latency_ms": 3373.342990875244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1304}, "3": {"k": 3, "answer": "Indian Ocean near The Comoros", "latency_ms": 5143.197298049927, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1967}, "4": {"k": 4, "answer": "Indian Ocean near The Comoros", "latency_ms": 9408.761978149414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Indian Ocean near The Comoros", "latency_ms": 6090.933322906494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3256}, "6": {"k": 6, "answer": "Indian Ocean near Grande Comore", "latency_ms": 5886.199951171875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3857}}}
{"qid": "-7175456993713717070", "question": "what does istj mean in a personality test", "gold_answers": ["Extroverted Thinking ( Te )", "Extroverted Intuition ( Ne )", "Introverted Feeling ( Fi )", "Introverted Sensing ( Si )"], "shots": {"0": {"k": 0, "answer": "ISTJ", "latency_ms": 2826.143264770508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ISTJ is a personality type in the Myers-Briggs Type Indicator.", "latency_ms": 8594.272375106812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 724}, "2": {"k": 2, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4455.438137054443, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 5867.7849769592285, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2101}, "4": {"k": 4, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 6761.073350906372, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2729}, "5": {"k": 5, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4885.058164596558, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3404}, "6": {"k": 6, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 6359.688997268677, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4115}}}
{"qid": "4437170343606050664", "question": "who does the voice of ash in sing", "gold_answers": ["Scarlett Johansson"], "shots": {"0": {"k": 0, "answer": "John Mulaney", "latency_ms": 1092.5102233886719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ash King", "latency_ms": 1625.4708766937256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Veronica Taylor", "latency_ms": 1860.75758934021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Veronica Taylor", "latency_ms": 2399.6996879577637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Veronica Taylor", "latency_ms": 4964.585781097412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2525}, "5": {"k": 5, "answer": "Veronica Taylor", "latency_ms": 3903.130054473877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "Veronica Taylor", "latency_ms": 5488.606929779053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3662}}}
{"qid": "-8773010039077552394", "question": "who scored the most points in their nba career", "gold_answers": ["Kareem Abdul - Jabbar"], "shots": {"0": {"k": 0, "answer": "Kareem Abdul-Jabbar", "latency_ms": 2230.0069332122803, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1622.0247745513916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2140.1894092559814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1152}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2364.492893218994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1709}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3594.1240787506104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2263}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3615.6814098358154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2868}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 4937.682390213013, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3486}}}
{"qid": "-3278224144622911032", "question": "with a land area of 54 314 square miles where does wisconsin rank among the 50 states", "gold_answers": ["25"], "shots": {"0": {"k": 0, "answer": "10th", "latency_ms": 1307.077407836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1643.1317329406738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1979.210376739502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1178}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2542.098045349121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1793}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3938.2407665252686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2405}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3864.6023273468018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2999}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 4090.449333190918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3592}}}
{"qid": "-3466298422174960041", "question": "who plays charles on have and have nots", "gold_answers": ["Nick Sager", "Nick Sagar"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 3155.762195587158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1629.4541358947754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2060.950994491577, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2730.536699295044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2574.117422103882, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 6164.75772857666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3596.480131149292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3804}}}
{"qid": "1803248910342766083", "question": "who wrote the book my country my life", "gold_answers": ["L.K. Advani"], "shots": {"0": {"k": 0, "answer": "Naomi Klein", "latency_ms": 1337.334156036377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "L. K. Advani", "latency_ms": 2058.9547157287598, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "L. K. Advani", "latency_ms": 2552.9212951660156, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1158}, "3": {"k": 3, "answer": "L. K. Advani", "latency_ms": 5400.799751281738, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1798}, "4": {"k": 4, "answer": "L. K. Advani", "latency_ms": 3075.184106826782, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "L. K. Advani", "latency_ms": 3628.154754638672, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3173}, "6": {"k": 6, "answer": "L. K. Advani", "latency_ms": 4206.215858459473, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3849}}}
{"qid": "-1176280233636154422", "question": "when did the east india company take control of india", "gold_answers": ["1757", "1799", "1612", "in 1757"], "shots": {"0": {"k": 0, "answer": "1757", "latency_ms": 1610.7406616210938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1757", "latency_ms": 1564.0718936920166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "1757", "latency_ms": 2085.8280658721924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1307}, "3": {"k": 3, "answer": "1757", "latency_ms": 3927.337884902954, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1925}, "4": {"k": 4, "answer": "1757", "latency_ms": 4171.913862228394, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2557}, "5": {"k": 5, "answer": "1757", "latency_ms": 6618.4892654418945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3205}, "6": {"k": 6, "answer": "1757", "latency_ms": 3174.3431091308594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3853}}}
{"qid": "5911119091653953181", "question": "where does the water come from to fill lake eyre", "gold_answers": ["Warburton River"], "shots": {"0": {"k": 0, "answer": "rainfall and inflows from surrounding rivers and groundwater", "latency_ms": 3288.3498668670654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "west, Channel Country of Queensland", "latency_ms": 2473.600387573242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "Georgina River", "latency_ms": 1971.8067646026611, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1154}, "3": {"k": 3, "answer": "west, Channel Country of Queensland, Georgina River, Cooper Creek", "latency_ms": 9804.481983184814, "em": 0.0, "f1": 0.1818181818181818, "containment": 0.0, "context_chars": 1775}, "4": {"k": 4, "answer": "west, Channel Country of Queensland, Finke River, Cooper Creek, Georgina River, Diamantina River", "latency_ms": 10698.755979537964, "em": 0.0, "f1": 0.13333333333333336, "containment": 0.0, "context_chars": 2401}, "5": {"k": 5, "answer": "west (Channel Country of Queensland), Finke River, Cooper Creek, Georgina River, Warburton River, and local rain in La Niña years", "latency_ms": 10778.23519706726, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 2998}, "6": {"k": 6, "answer": "west (Channel Country of Queensland), Finke River, Cooper Creek, Georgina River, Warburton River, and local rain in La Niña years", "latency_ms": 9042.726278305054, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 3609}}}
{"qid": "5557104327881436095", "question": "who is the founder of google and when was it founded", "gold_answers": ["1998", "Sergey Brin", "Larry Page and Sergey Brin", "Larry Page"], "shots": {"0": {"k": 0, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 2833.6727619171143, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Larry Page and Sergey Brin; September 15, 1997", "latency_ms": 8677.815437316895, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 676}, "2": {"k": 2, "answer": "Larry Page and Sergey Brin, 1997", "latency_ms": 4432.198286056519, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 1358}, "3": {"k": 3, "answer": "Larry Page and Sergey Brin, 1997", "latency_ms": 4142.315626144409, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Larry Page and Sergey Brin, 1997", "latency_ms": 8007.481575012207, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 2698}, "5": {"k": 5, "answer": "Larry Page and Sergey Brin, 1997", "latency_ms": 7589.733839035034, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 3334}, "6": {"k": 6, "answer": "Larry Page and Sergey Brin, 1997", "latency_ms": 6062.55578994751, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 4003}}}
{"qid": "-1333328812971005142", "question": "who did the dominican republic gain its independence from", "gold_answers": ["Haiti"], "shots": {"0": {"k": 0, "answer": "Spain", "latency_ms": 657.0980548858643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haiti", "latency_ms": 3107.1531772613525, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 725}, "2": {"k": 2, "answer": "Haiti", "latency_ms": 2099.9536514282227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1394}, "3": {"k": 3, "answer": "Haiti", "latency_ms": 2139.4479274749756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2069}, "4": {"k": 4, "answer": "Haiti", "latency_ms": 2272.0019817352295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2783}, "5": {"k": 5, "answer": "Haiti", "latency_ms": 3565.2482509613037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3420}, "6": {"k": 6, "answer": "Haiti", "latency_ms": 3850.4209518432617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4106}}}
{"qid": "1122605495295045742", "question": "how did early humans make use of stones during the prehistoric period", "gold_answers": ["start fires", "hunt", "bury their dead"], "shots": {"0": {"k": 0, "answer": "Chipped and shaped for tools", "latency_ms": 4531.548261642456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "made tools with an edge, a point, or a percussion surface", "latency_ms": 3179.497241973877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "made edge, point, or percussion surface tools", "latency_ms": 5367.977142333984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "made tools with an edge, point, or percussion surface", "latency_ms": 3812.6673698425293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "made implements with an edge, a point, or a percussion surface", "latency_ms": 6213.472127914429, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "made implements with an edge, a point, or a percussion surface", "latency_ms": 6442.05117225647, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3228}, "6": {"k": 6, "answer": "made tools with sharp edges, points, or percussion surfaces; used hand axes; created stone-tipped weapons for hunting; ground food with manos and metates", "latency_ms": 10012.676477432251, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3820}}}
{"qid": "7402184777947527945", "question": "who wrote the text for jeanie with the light brown hair", "gold_answers": ["Stephen Foster"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 3224.24578666687, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stephen Foster", "latency_ms": 1468.625545501709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Stephen Foster", "latency_ms": 2204.594373703003, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1222}, "3": {"k": 3, "answer": "Stephen Foster", "latency_ms": 2118.046283721924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Stephen Foster", "latency_ms": 3396.367073059082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2490}, "5": {"k": 5, "answer": "Stephen Foster", "latency_ms": 2881.5231323242188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3107}, "6": {"k": 6, "answer": "Stephen Foster", "latency_ms": 3282.421827316284, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3752}}}
{"qid": "1656745334095178455", "question": "the basic steps of rational decision making include defining goals and", "gold_answers": ["Implementation of plans / policies"], "shots": {"0": {"k": 0, "answer": "identifying alternatives", "latency_ms": 2370.100498199463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "defining goals and verifying the problem", "latency_ms": 4483.122825622559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 774}, "2": {"k": 2, "answer": "defining goals and problem identification", "latency_ms": 2537.7159118652344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1428}, "3": {"k": 3, "answer": "defining the problem", "latency_ms": 2552.130937576294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2061}, "4": {"k": 4, "answer": "defining goals and identifying problems", "latency_ms": 3287.2629165649414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2713}, "5": {"k": 5, "answer": "defining goals and identifying problem", "latency_ms": 4136.333703994751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3412}, "6": {"k": 6, "answer": "defining goals and identifying problems", "latency_ms": 4107.8314781188965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4068}}}
{"qid": "-216657635823030751", "question": "when was the design period known as art deco", "gold_answers": ["1910 -- 1939"], "shots": {"0": {"k": 0, "answer": "1920s–1930s", "latency_ms": 4823.391437530518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1930s", "latency_ms": 1821.291208267212, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "just before World War I", "latency_ms": 3227.348566055298, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "just before World War I", "latency_ms": 3294.2874431610107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2011}, "4": {"k": 4, "answer": "just before World War I", "latency_ms": 3298.2728481292725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2679}, "5": {"k": 5, "answer": "just before World War I to its heyday in the 1930s", "latency_ms": 6042.518377304077, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "1910 to 1930s", "latency_ms": 8861.973524093628, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3972}}}
{"qid": "250542332339248886", "question": "where does the bob and tom show broadcast from", "gold_answers": ["WFBQ in Indianapolis , Indiana", "Indianapolis , Indiana"], "shots": {"0": {"k": 0, "answer": "Winston-Salem, North Carolina", "latency_ms": 2945.530891418457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indianapolis, Indiana", "latency_ms": 3587.3873233795166, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 2997.5907802581787, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 3485.194444656372, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 4139.390707015991, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2574}, "5": {"k": 5, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 6584.335088729858, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 4847.947597503662, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3777}}}
{"qid": "7610758795954724809", "question": "star wars the clone wars season 3 episode 1", "gold_answers": ["Clone Cadets"], "shots": {"0": {"k": 0, "answer": "\"The Clone Wars\" Season 3, Episode 1: \"The Clone Wars\"", "latency_ms": 11282.576084136963, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2053.4873008728027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "Nightsisters", "latency_ms": 1880.9959888458252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1370}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2725.391387939453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2013}, "4": {"k": 4, "answer": "Nightsisters", "latency_ms": 3577.146053314209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2693}, "5": {"k": 5, "answer": "Nightsisters", "latency_ms": 3839.3077850341797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3333}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 5070.962429046631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3979}}}
{"qid": "2997223939033016160", "question": "what part of brain is responsible for complex thinking", "gold_answers": ["the frontal lobe"], "shots": {"0": {"k": 0, "answer": "prefrontal cortex", "latency_ms": 3086.0776901245117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "frontal lobe", "latency_ms": 3861.039638519287, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 702}, "2": {"k": 2, "answer": "frontal lobe", "latency_ms": 3987.7853393554688, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "cerebral cortex", "latency_ms": 2730.522871017456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "neocortex", "latency_ms": 2907.928466796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2688}, "5": {"k": 5, "answer": "neocortex", "latency_ms": 3869.3761825561523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3385}, "6": {"k": 6, "answer": "cerebral cortex", "latency_ms": 3066.4024353027344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4069}}}
{"qid": "2680196226239522881", "question": "who won the champions league final in 2016", "gold_answers": ["Real Madrid"], "shots": {"0": {"k": 0, "answer": "Real Madrid", "latency_ms": 2287.593126296997, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3653.5942554473877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "Internazionale", "latency_ms": 1870.058536529541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Internazionale", "latency_ms": 2310.307264328003, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1880}, "4": {"k": 4, "answer": "Internazionale", "latency_ms": 4206.111431121826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2536}, "5": {"k": 5, "answer": "Real Madrid", "latency_ms": 2623.389720916748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3169}, "6": {"k": 6, "answer": "Real Madrid", "latency_ms": 3398.9226818084717, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3831}}}
{"qid": "-8458006812258546025", "question": "who has the most gold medals in the winter olympics of all time", "gold_answers": ["Norway"], "shots": {"0": {"k": 0, "answer": "Cross-country skier, Johannes Høsflot Klæbo", "latency_ms": 3556.6587448120117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1628.0179023742676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2082.550287246704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Canada", "latency_ms": 1943.366289138794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1941}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2780.3027629852295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2564}, "5": {"k": 5, "answer": "Marit Bjørgen", "latency_ms": 3841.5541648864746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3175}, "6": {"k": 6, "answer": "Marit Bjørgen", "latency_ms": 3445.321798324585, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3792}}}
