{"qid": "7225402972374213361", "question": "where does sleeping freshmen never lie take place", "gold_answers": ["J.P. Zenger High"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1284.4758033752441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "high school", "latency_ms": 1097.6691246032715, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "United States and Japan", "latency_ms": 1957.3495388031006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1843.6951637268066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2420.3147888183594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2457}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2921.1442470550537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3083}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3348.34361076355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3641}}}
{"qid": "96833482883405603", "question": "where was the witch of blackbird pond published", "gold_answers": ["Houghton Mifflin", "United States", "1958"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1218.1692123413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1958", "latency_ms": 1604.3498516082764, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 625}, "2": {"k": 2, "answer": "1958", "latency_ms": 1926.3725280761719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "1958", "latency_ms": 2511.6653442382812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1919}, "4": {"k": 4, "answer": "1958", "latency_ms": 3085.6282711029053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2586}, "5": {"k": 5, "answer": "1958", "latency_ms": 3486.61470413208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3199}, "6": {"k": 6, "answer": "1958", "latency_ms": 3309.6578121185303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3898}}}
{"qid": "-7179754224203704932", "question": "when was the last time there was a school shooting in canada", "gold_answers": ["January 22 , 2016"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1230.7467460632324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1482.6807975769043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "April 28, 1999", "latency_ms": 3225.327730178833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2550.1248836517334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1988}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2471.832513809204, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2633}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2960.185766220093, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3355}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3778.9604663848877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4062}}}
{"qid": "422507927579350549", "question": "when did the us cut off trade with cuba", "gold_answers": ["1961", "1962"], "shots": {"0": {"k": 0, "answer": "1960", "latency_ms": 1254.7507286071777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3 February 1962", "latency_ms": 2596.259832382202, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "3 February 1962", "latency_ms": 2455.745220184326, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "3 February 1962", "latency_ms": 2909.0607166290283, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1954}, "4": {"k": 4, "answer": "3 February 1962", "latency_ms": 3156.0845375061035, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2667}, "5": {"k": 5, "answer": "February 7, 1962", "latency_ms": 4109.1156005859375, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3285}, "6": {"k": 6, "answer": "February 7, 1962", "latency_ms": 4273.88858795166, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3960}}}
{"qid": "-8251885859273118288", "question": "cast of the movie pride of the marines", "gold_answers": ["John Ridgely", "Rosemary DeCamp as Virginia Pfeiffer", "Dane Clark as Lee Diamond", "Eleanor Parker as Ruth Hartley", "Eleanor Parker", "Rosemary DeCamp", "John Ridgely as Jim Merchant", "Anthony Caruso as Johnny Rivers", "John Garfield", "Ann E. Todd", "John Garfield as Al Schmid", "Anthony Caruso", "Dane Clark", "Ann Doran"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1270.5249786376953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Garfield, Eleanor Parker", "latency_ms": 1815.6306743621826, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "John Garfield, Eleanor Parker", "latency_ms": 2435.084819793701, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1227}, "3": {"k": 3, "answer": "John Garfield, Eleanor Parker", "latency_ms": 2714.2627239227295, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1858}, "4": {"k": 4, "answer": "John Garfield, Eleanor Parker", "latency_ms": 3184.1135025024414, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2506}, "5": {"k": 5, "answer": "John Garfield, Eleanor Parker", "latency_ms": 3650.4039764404297, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3211}, "6": {"k": 6, "answer": "John Garfield, Eleanor Parker, Al Schmid (based on real person), Albert Maltz (writer), Bessie (writer), Martin Borowsky (adapter)", "latency_ms": 10370.923519134521, "em": 0.0, "f1": 0.3478260869565218, "containment": 1.0, "context_chars": 3899}}}
{"qid": "-7733962091461103034", "question": "who wrote how do you do it by gerry and the pacemakers", "gold_answers": ["Mitch Murray"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1263.505220413208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mitch Murray", "latency_ms": 969.1073894500732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 546}, "2": {"k": 2, "answer": "Mitch Murray", "latency_ms": 1580.0166130065918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1160}, "3": {"k": 3, "answer": "Mitch Murray", "latency_ms": 1898.7364768981934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1735}, "4": {"k": 4, "answer": "Mitch Murray", "latency_ms": 2262.418031692505, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2355}, "5": {"k": 5, "answer": "Mitch Murray", "latency_ms": 2794.9235439300537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2938}, "6": {"k": 6, "answer": "Mitch Murray", "latency_ms": 3234.3335151672363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3549}}}
{"qid": "9188359206780164872", "question": "when was the reaper invented by cyrus mccormick", "gold_answers": ["1834", "1837"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1268.9094543457031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1831", "latency_ms": 1380.0675868988037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "1834", "latency_ms": 2051.644802093506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1308}, "3": {"k": 3, "answer": "1831", "latency_ms": 2472.1953868865967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1939}, "4": {"k": 4, "answer": "1831", "latency_ms": 2444.5903301239014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "1831", "latency_ms": 2939.5182132720947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": "1831", "latency_ms": 3829.906463623047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3864}}}
{"qid": "3724356943291190911", "question": "season 2 this is us number of episodes", "gold_answers": ["15", "18", "13"], "shots": {"0": {"k": 0, "answer": "10", "latency_ms": 836.3046646118164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1817.5172805786133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 574}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2074.655771255493, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1232}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2510.925531387329, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1834}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2442.05379486084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2430}, "5": {"k": 5, "answer": "44", "latency_ms": 3451.5998363494873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "44", "latency_ms": 3716.989278793335, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3828}}}
{"qid": "3780798490838700655", "question": "when did seattle slew win the triple crown", "gold_answers": ["in 1977", "1977"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1243.6435222625732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1977", "latency_ms": 1595.2122211456299, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 550}, "2": {"k": 2, "answer": "1977", "latency_ms": 1837.0580673217773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1147}, "3": {"k": 3, "answer": "1977", "latency_ms": 2564.53013420105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1741}, "4": {"k": 4, "answer": "1977", "latency_ms": 2873.2502460479736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2354}, "5": {"k": 5, "answer": "1977", "latency_ms": 2966.6149616241455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2994}, "6": {"k": 6, "answer": "1977", "latency_ms": 3766.585350036621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3612}}}
{"qid": "-6569395974597414012", "question": "who did michigan state play in the rose bowl", "gold_answers": ["Stanford Cardinal"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1227.5714874267578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UCLA Bruins", "latency_ms": 1675.4424571990967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "UCLA Bruins", "latency_ms": 1932.2607517242432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "UCLA Bruins", "latency_ms": 2268.6562538146973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1770}, "4": {"k": 4, "answer": "UCLA Bruins", "latency_ms": 2311.68270111084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2336}, "5": {"k": 5, "answer": "UCLA Bruins", "latency_ms": 2774.8568058013916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2908}, "6": {"k": 6, "answer": "UCLA Bruins, Oregon State Beavers, USC Trojans", "latency_ms": 5766.304016113281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3497}}}
{"qid": "6403936039868410763", "question": "when did teenage mutant ninja turtles come out", "gold_answers": ["1984"], "shots": {"0": {"k": 0, "answer": "1984", "latency_ms": 1278.059959411621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1990", "latency_ms": 1597.1689224243164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "1990", "latency_ms": 1864.7551536560059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1357}, "3": {"k": 3, "answer": "1990", "latency_ms": 2470.5703258514404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2073}, "4": {"k": 4, "answer": "1990", "latency_ms": 2794.240951538086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2707}, "5": {"k": 5, "answer": "1990", "latency_ms": 2996.323347091675, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3334}, "6": {"k": 6, "answer": "1990", "latency_ms": 3897.1166610717773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3978}}}
{"qid": "-8240837250531908357", "question": "when does the team find out prentiss is alive", "gold_answers": ["the season seven premiere", "In the season seven premiere"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1231.7638397216797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "season seven", "latency_ms": 973.4916687011719, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "season seven", "latency_ms": 1600.2318859100342, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "season seven", "latency_ms": 1620.9678649902344, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1743}, "4": {"k": 4, "answer": "season seven", "latency_ms": 2216.7458534240723, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2345}, "5": {"k": 5, "answer": "season seven", "latency_ms": 2356.9421768188477, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2894}, "6": {"k": 6, "answer": "Season seven", "latency_ms": 2564.960241317749, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3470}}}
{"qid": "2134628804733070340", "question": "who won the silver medal in womens figure skating", "gold_answers": ["Evgenia Medvedeva"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1232.5389385223389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rita Trapanese", "latency_ms": 1873.216152191162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "Tenley Albright", "latency_ms": 2080.69109916687, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Tenley Albright", "latency_ms": 2290.6856536865234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1921}, "4": {"k": 4, "answer": "Tenley Albright", "latency_ms": 2469.1741466522217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Tenley Albright", "latency_ms": 3767.4689292907715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Tenley Albright", "latency_ms": 3290.2657985687256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3835}}}
{"qid": "-1769528362781268772", "question": "who lived in jamestown before the arrival of the english", "gold_answers": ["uninhabited"], "shots": {"0": {"k": 0, "answer": "Powhatan Confederacy", "latency_ms": 1426.194429397583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1378.2322406768799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "Powhatan", "latency_ms": 1978.0569076538086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1330}, "3": {"k": 3, "answer": "Powhatan Confederacy", "latency_ms": 2557.967185974121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2018}, "4": {"k": 4, "answer": "Virginia Native Americans, specifically the Powhatan Confederacy", "latency_ms": 3965.5981063842773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2700}, "5": {"k": 5, "answer": "Virginia Native Americans, the Powhatan Confederacy", "latency_ms": 4428.900957107544, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3360}, "6": {"k": 6, "answer": "Virginia Native Americans, the Powhatan Confederacy", "latency_ms": 4678.3740520477295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4054}}}
{"qid": "2632188867909468181", "question": "who is covering the winter olympics in canada", "gold_answers": ["CBC / Radio - Canada", "Rogers Media", "TLN", "Bell Media"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1222.25022315979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Adam van Koeverden", "latency_ms": 1565.1137828826904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Adam van Koeverden", "latency_ms": 2183.516025543213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Adam van Koeverden", "latency_ms": 2504.361867904663, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1976}, "4": {"k": 4, "answer": "Adam van Koeverden", "latency_ms": 2851.346015930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2627}, "5": {"k": 5, "answer": "Todd Brooker", "latency_ms": 2860.3837490081787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "Todd Brooker", "latency_ms": 3712.787389755249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3868}}}
{"qid": "6788315330567276031", "question": "who plays the dad in girl meets world", "gold_answers": ["Ben Savage", "Cory Matthews"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1282.3607921600342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1807.5315952301025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1879.7037601470947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2306.7245483398438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2471.3752269744873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2492}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3078.145742416382, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3109}, "6": {"k": 6, "answer": "Michael Jacobs", "latency_ms": 2570.5599784851074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3758}}}
{"qid": "-8518155586522600846", "question": "who are you in assassin's creed 4", "gold_answers": ["third - person perspective", "an Abstergo agent"], "shots": {"0": {"k": 0, "answer": "Connor Riley", "latency_ms": 839.3452167510986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Desmond Miles", "latency_ms": 1307.23237991333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "Desmond Miles", "latency_ms": 1783.0891609191895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1334}, "3": {"k": 3, "answer": "Desmond Miles", "latency_ms": 2161.1592769622803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Jonathan Hawk", "latency_ms": 2400.1007080078125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2630}, "5": {"k": 5, "answer": "Jonathan Hawk", "latency_ms": 2947.822332382202, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3298}, "6": {"k": 6, "answer": "Jonathan Hawk", "latency_ms": 2543.2372093200684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3968}}}
{"qid": "-5339088518859431071", "question": "who destroyed the first temple and exiled the two tribes of judah to babylon", "gold_answers": ["Nebuchadnezzar"], "shots": {"0": {"k": 0, "answer": "Nebuchadnezzar II", "latency_ms": 2028.977394104004, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nebuchadnezzar II", "latency_ms": 2627.169132232666, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Nebuchadnezzar II", "latency_ms": 2914.2448902130127, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Nebuchadnezzar II", "latency_ms": 3287.6880168914795, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1955}, "4": {"k": 4, "answer": "Nebuchadnezzar II", "latency_ms": 3230.3357124328613, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2655}, "5": {"k": 5, "answer": "Nebuchadnezzar II", "latency_ms": 3983.802556991577, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3282}, "6": {"k": 6, "answer": "Nebuchadnezzar II", "latency_ms": 4174.401044845581, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3939}}}
{"qid": "-1602930054930299018", "question": "where is the white castle that harold and kumar go to", "gold_answers": ["in Cherry Hill"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1241.6837215423584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cherry Hill", "latency_ms": 1150.937795639038, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "Cherry Hill", "latency_ms": 1791.501760482788, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "Cherry Hill", "latency_ms": 2095.561981201172, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "Cherry Hill", "latency_ms": 2322.1468925476074, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2526}, "5": {"k": 5, "answer": "Cherry Hill", "latency_ms": 2575.035333633423, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Cherry Hill", "latency_ms": 3361.333131790161, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3777}}}
{"qid": "4721622231665415813", "question": "when was child benefit paid for the first child", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1946", "latency_ms": 1229.912519454956, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1991", "latency_ms": 1571.4726448059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "1991", "latency_ms": 1941.1664009094238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "1991", "latency_ms": 2408.2894325256348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "1991", "latency_ms": 2481.3125133514404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2611}, "5": {"k": 5, "answer": "1991", "latency_ms": 3246.229648590088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3193}, "6": {"k": 6, "answer": "1991", "latency_ms": 3285.454511642456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3822}}}
{"qid": "243685073103458654", "question": "what was the initial effect of the transition from command to market economies in eastern europe", "gold_answers": ["Inequality of opportunity"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1231.7485809326172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "capital accumulation", "latency_ms": 1435.76979637146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 725}, "2": {"k": 2, "answer": "massive social transformations", "latency_ms": 1982.3358058929443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1381}, "3": {"k": 3, "answer": "massive social transformations, peasants migrated and were converted into city dwelling working class", "latency_ms": 4792.163610458374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2111}, "4": {"k": 4, "answer": "massive social transformations, peasants migrated and were converted into city dwelling working class", "latency_ms": 4696.985960006714, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2782}, "5": {"k": 5, "answer": "massive social transformations, peasants migrated and were converted into city dwelling working class", "latency_ms": 4978.030204772949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3461}, "6": {"k": 6, "answer": "massive social transformations, peasants migrated and were converted into city dwelling working class", "latency_ms": 5172.532320022583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4156}}}
{"qid": "5041227796109703758", "question": "when did linkin park release one more light", "gold_answers": ["May 19 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1263.620376586914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "May 19, 2017", "latency_ms": 3081.0794830322266, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "May 19, 2017", "latency_ms": 3275.913715362549, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "May 19, 2017", "latency_ms": 3514.805316925049, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "May 19, 2017", "latency_ms": 3807.3384761810303, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "May 19, 2017", "latency_ms": 4515.103101730347, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3093}, "6": {"k": 6, "answer": "May 19, 2017", "latency_ms": 4965.655326843262, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3737}}}
{"qid": "-9039792036843684255", "question": "what territory is spain and the united kingdom in a dispute over", "gold_answers": ["Gibraltar"], "shots": {"0": {"k": 0, "answer": "Gibraltar", "latency_ms": 843.595027923584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gibraltar", "latency_ms": 969.2602157592773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Gibraltar", "latency_ms": 1600.4040241241455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1369}, "3": {"k": 3, "answer": "Gibraltar", "latency_ms": 1857.6364517211914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2020}, "4": {"k": 4, "answer": "Gibraltar", "latency_ms": 2413.0189418792725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2714}, "5": {"k": 5, "answer": "Gibraltar", "latency_ms": 2406.1968326568604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3428}, "6": {"k": 6, "answer": "Gibraltar", "latency_ms": 2628.1814575195312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4130}}}
{"qid": "-5962986518182066490", "question": "who has the most green jackets from the masters", "gold_answers": ["Jack Nicklaus ( 6 )", "Nicklaus"], "shots": {"0": {"k": 0, "answer": "Tiger Woods", "latency_ms": 1026.9124507904053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiger Woods", "latency_ms": 1164.6859645843506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "Sam Snead", "latency_ms": 1736.0084056854248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1181}, "3": {"k": 3, "answer": "Jack Nicklaus", "latency_ms": 2031.7223072052002, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1765}, "4": {"k": 4, "answer": "Jack Nicklaus", "latency_ms": 2297.0409393310547, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2348}, "5": {"k": 5, "answer": "Jack Nicklaus", "latency_ms": 2572.1819400787354, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2983}, "6": {"k": 6, "answer": "Jack Nicklaus", "latency_ms": 3649.810791015625, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3579}}}
{"qid": "-4447833523561749340", "question": "who was the first black person to register to vote", "gold_answers": ["Thomas Mundy Peterson"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1236.1009120941162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1366.5401935577393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1972.705364227295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1358}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2295.281410217285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2018}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2450.2875804901123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2683}, "5": {"k": 5, "answer": "George W. Lee", "latency_ms": 3259.6685886383057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3284}, "6": {"k": 6, "answer": "George W. Lee", "latency_ms": 2996.0579872131348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3984}}}
{"qid": "4131432785529318958", "question": "song have i told you lately i love you", "gold_answers": ["Have I Told You Lately"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1224.395751953125, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Van Morrison", "latency_ms": 1144.1686153411865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Scotty Wiseman", "latency_ms": 1891.3905620574951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Scotty Wiseman", "latency_ms": 2311.107873916626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Scotty Wiseman", "latency_ms": 2757.9874992370605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2464}, "5": {"k": 5, "answer": "Scotty Wiseman", "latency_ms": 3463.139772415161, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3064}, "6": {"k": 6, "answer": "Scotty Wiseman", "latency_ms": 3854.977607727051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3663}}}
{"qid": "-716659397149237689", "question": "when did britain set up east indian trading company", "gold_answers": ["31 December 1600"], "shots": {"0": {"k": 0, "answer": "1600", "latency_ms": 1249.1874694824219, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1600", "latency_ms": 1881.1182975769043, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "1600", "latency_ms": 1990.9343719482422, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "1600", "latency_ms": 2817.9824352264404, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "1600", "latency_ms": 2733.715057373047, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2570}, "5": {"k": 5, "answer": "1600", "latency_ms": 3021.451234817505, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3226}, "6": {"k": 6, "answer": "1600", "latency_ms": 2985.8481884002686, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3879}}}
{"qid": "-7583855073136179893", "question": "when did david akers kick the 63 yard field goal", "gold_answers": ["September 9 , 2012"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1273.7576961517334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1935.9052181243896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2001.3744831085205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2503.061532974243, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1780}, "4": {"k": 4, "answer": "The context does not specify the exact date when David Akers kicked the 63-yard field goal. I cannot answer.", "latency_ms": 6933.714866638184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2389}, "5": {"k": 5, "answer": "tied for the longest field goal in NFL history when he kicked a 63-yard field goal with the San Francisco 49ers.", "latency_ms": 8327.346086502075, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2994}, "6": {"k": 6, "answer": "not specified in the context", "latency_ms": 3588.759660720825, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3575}}}
{"qid": "6203839542590166972", "question": "who is the coach of university of kentucky basketball", "gold_answers": ["John Calipari", "John Vincent Calipari"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1234.0202331542969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Joe B. Hall", "latency_ms": 1550.898790359497, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "John Calipari", "latency_ms": 2028.1593799591064, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "John Calipari", "latency_ms": 2517.1797275543213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1925}, "4": {"k": 4, "answer": "John Calipari", "latency_ms": 2794.3766117095947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2532}, "5": {"k": 5, "answer": "John Calipari", "latency_ms": 2960.6223106384277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3524.367570877075, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3882}}}
{"qid": "-163195825366469164", "question": "where does the papillary layer of the skin lie", "gold_answers": ["adjacent to the epidermis"], "shots": {"0": {"k": 0, "answer": "below the epidermis", "latency_ms": 1440.922737121582, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "adjacent to the epidermis", "latency_ms": 1970.8952903747559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 683}, "2": {"k": 2, "answer": "adjacent to the epidermis", "latency_ms": 2601.2916564941406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1393}, "3": {"k": 3, "answer": "adjacent to the epidermis", "latency_ms": 3031.423330307007, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2110}, "4": {"k": 4, "answer": "adjacent to the epidermis", "latency_ms": 3511.108636856079, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2793}, "5": {"k": 5, "answer": "adjacent to the epidermis", "latency_ms": 3903.3377170562744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3453}, "6": {"k": 6, "answer": "adjacent to the epidermis", "latency_ms": 3563.279390335083, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4125}}}
{"qid": "-7984751231760514910", "question": "who has become the new chairman of sebi", "gold_answers": ["Ajay Tyagi"], "shots": {"0": {"k": 0, "answer": "I cannot answer", "latency_ms": 1039.6606922149658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Upendra Kumar Sinha", "latency_ms": 2019.934892654419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "Upendra Kumar Sinha", "latency_ms": 2258.9194774627686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Upendra Kumar Sinha", "latency_ms": 2533.822774887085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "Ajay Tyagi", "latency_ms": 2459.639549255371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2561}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2947.0999240875244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3201}, "6": {"k": 6, "answer": "Ajay Tyagi", "latency_ms": 3868.7191009521484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3822}}}
{"qid": "-3800318726442204745", "question": "how many times has psg won champions league", "gold_answers": ["46"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1264.8882865905762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1846.818447113037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "0", "latency_ms": 1298.6118793487549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2454.648971557617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1778}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2502.666234970093, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2345}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3317.8586959838867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2943}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3265.434980392456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3604}}}
{"qid": "-642255764943734268", "question": "who played santa in the santa clause movies", "gold_answers": ["Tim Allen"], "shots": {"0": {"k": 0, "answer": "Jim Carrey", "latency_ms": 1095.5300331115723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tim Allen", "latency_ms": 1376.4207363128662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 589}, "2": {"k": 2, "answer": "Tim Allen", "latency_ms": 1667.2554016113281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1215}, "3": {"k": 3, "answer": "Tim Allen", "latency_ms": 1893.6781883239746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Tim Allen", "latency_ms": 2104.8638820648193, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2470}, "5": {"k": 5, "answer": "Tim Allen", "latency_ms": 2550.046682357788, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3115}, "6": {"k": 6, "answer": "Tim Allen", "latency_ms": 2938.0197525024414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3745}}}
{"qid": "-8451675676248853811", "question": "how many times have real madrid won the european cup.in paris", "gold_answers": ["twelve"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1310.7919692993164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1856.8389415740967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1996.9396591186523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2551.3241291046143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1833}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2508.6371898651123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2465}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3776.602029800415, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3093}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 4162.4085903167725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3687}}}
{"qid": "-5975200217671466380", "question": "total goals scored by ronaldo in la liga", "gold_answers": ["309"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1230.0081253051758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "100", "latency_ms": 1406.7654609680176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "40", "latency_ms": 1607.4953079223633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1201}, "3": {"k": 3, "answer": "46", "latency_ms": 1890.0516033172607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1787}, "4": {"k": 4, "answer": "252", "latency_ms": 2858.0381870269775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2417}, "5": {"k": 5, "answer": "252", "latency_ms": 2912.9414558410645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3026}, "6": {"k": 6, "answer": "40", "latency_ms": 2533.4649085998535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3635}}}
{"qid": "-1975115150327235272", "question": "when was kudzu introduced to the united states", "gold_answers": ["in 1876", "1876"], "shots": {"0": {"k": 0, "answer": "1893", "latency_ms": 1225.3563404083252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1876", "latency_ms": 1609.4119548797607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "1876", "latency_ms": 2006.7319869995117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1229}, "3": {"k": 3, "answer": "1876", "latency_ms": 2353.165626525879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1875}, "4": {"k": 4, "answer": "1876", "latency_ms": 2450.564384460449, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2526}, "5": {"k": 5, "answer": "1876", "latency_ms": 3780.70330619812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "1876", "latency_ms": 3297.3170280456543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3819}}}
{"qid": "4911813695697896179", "question": "the radiographic term used to describe the dense bone of the socket and septal crest is", "gold_answers": ["the lamina dura", "lamina dura", "alveolar process"], "shots": {"0": {"k": 0, "answer": "alveolar bone", "latency_ms": 1387.2437477111816, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hypodensity", "latency_ms": 1293.6820983886719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 688}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2016.8919563293457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "hypodensity", "latency_ms": 2103.4741401672363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1994}, "4": {"k": 4, "answer": "hypodensity", "latency_ms": 2430.6650161743164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2732}, "5": {"k": 5, "answer": "hypodensity", "latency_ms": 3402.1098613739014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3362}, "6": {"k": 6, "answer": "lamina dura", "latency_ms": 3338.364362716675, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4037}}}
{"qid": "3490824095431420580", "question": "where was the tv show friday night lights filmed", "gold_answers": ["Pflugerville", "Austin"], "shots": {"0": {"k": 0, "answer": "Denton, Texas", "latency_ms": 1241.7051792144775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Boston area, Boston College, Boston University, Tufts University, Gregory Gym at The University of Texas at Austin", "latency_ms": 5564.668655395508, "em": 0.0, "f1": 0.1176470588235294, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "Boston area, Boston College, Boston University, Tufts University, Gregory Gym at The University of Texas at Austin, Temple University", "latency_ms": 6251.990795135498, "em": 0.0, "f1": 0.10526315789473684, "containment": 1.0, "context_chars": 1382}, "3": {"k": 3, "answer": "Boston area, Boston College, Boston University, Tufts University, Gregory Gym at The University of Texas at Austin, Temple University", "latency_ms": 7060.101509094238, "em": 0.0, "f1": 0.10526315789473684, "containment": 1.0, "context_chars": 2024}, "4": {"k": 4, "answer": "Austin and Pflugerville", "latency_ms": 2920.931816101074, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2685}, "5": {"k": 5, "answer": "Austin and Pflugerville", "latency_ms": 3978.7635803222656, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3278}, "6": {"k": 6, "answer": "Austin and Pflugerville", "latency_ms": 3361.6464138031006, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3897}}}
{"qid": "-8363239742768997492", "question": "who led an attack that allowed for american victory at yorktown", "gold_answers": ["George Washington", "Comte de Rochambeau"], "shots": {"0": {"k": 0, "answer": "George Washington", "latency_ms": 832.9150676727295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "George Washington and the Comte de Rochambeau", "latency_ms": 2928.611993789673, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 629}, "2": {"k": 2, "answer": "General George Washington and the Comte de Rochambeau", "latency_ms": 3588.6929035186768, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1325}, "3": {"k": 3, "answer": "General George Washington and the Comte de Rochambeau", "latency_ms": 3877.9282569885254, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1989}, "4": {"k": 4, "answer": "General George Washington and the Comte de Rochambeau", "latency_ms": 4157.9320430755615, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2623}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2788.766384124756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3237}, "6": {"k": 6, "answer": "George Washington and the Comte de Rochambeau", "latency_ms": 4437.684059143066, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3903}}}
{"qid": "8127283608263713430", "question": "what process causes the continents to drift apart how", "gold_answers": ["Continental drift"], "shots": {"0": {"k": 0, "answer": "plate tectonics", "latency_ms": 1433.9516162872314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1876.434087753296, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "centrifugal pseudoforce (Polflucht) or astronomical precession", "latency_ms": 4242.764234542847, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1330}, "3": {"k": 3, "answer": "centrifugal force of the Earth's rotation or astronomical precession", "latency_ms": 4090.731620788574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "mantle convection", "latency_ms": 3125.274181365967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2682}, "5": {"k": 5, "answer": "mantle convection", "latency_ms": 2767.772674560547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3366}, "6": {"k": 6, "answer": "mantle convection", "latency_ms": 3671.459913253784, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4001}}}
{"qid": "-4677464867334464937", "question": "who played in last train from gun hill", "gold_answers": ["Walter Sande", "Brian G. Hutton", "Carolyn Jones", "Ziva Rodann", "Bing Russell", "Val Avery", "Earl Holliman", "Brad Dexter", "Kirk Douglas", "Anthony Quinn"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1302.93869972229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kirk Douglas, Anthony Quinn, Carolyn Jones, Earl Holliman", "latency_ms": 3386.8186473846436, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Kirk Douglas, Anthony Quinn, Carolyn Jones, Earl Holliman, Ziva Rodann", "latency_ms": 4784.959316253662, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1215}, "3": {"k": 3, "answer": "Kirk Douglas, Anthony Quinn, Carolyn Jones, Earl Holliman", "latency_ms": 4106.478691101074, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1802}, "4": {"k": 4, "answer": "Kirk Douglas, Anthony Quinn, Carolyn Jones, Earl Holliman, Ziva Rodann", "latency_ms": 5296.442747116089, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2453}, "5": {"k": 5, "answer": "Kirk Douglas, Anthony Quinn, Carolyn Jones, Earl Holliman, Ziva Rodann", "latency_ms": 6006.731271743774, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3080}, "6": {"k": 6, "answer": "Kirk Douglas, Anthony Quinn, Carolyn Jones, Earl Holliman, Ziva Rodann", "latency_ms": 5830.303430557251, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3676}}}
{"qid": "9104579908306893648", "question": "who is the queen of hearts in alice in wonderland", "gold_answers": ["the primary antagonist"], "shots": {"0": {"k": 0, "answer": "Queen of Hearts", "latency_ms": 1047.764778137207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lewis Carroll", "latency_ms": 1524.2867469787598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Queen of Hearts in Alice's Adventures in Wonderland is a fictional character created by Lewis Carroll.", "latency_ms": 4830.276012420654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Lewis Carroll", "latency_ms": 2406.724452972412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "Mary Elizabeth Heart", "latency_ms": 2905.503273010254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "Mary Elizabeth Heart", "latency_ms": 2581.3632011413574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3181}, "6": {"k": 6, "answer": "Lewis Carroll", "latency_ms": 2593.803644180298, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3839}}}
{"qid": "658101134800391459", "question": "who invented the first computer game in 1962 and what was the name of the game", "gold_answers": ["Spacewar !", "Wayne Wiitanen", "Steve Russell", "Martin Graetz"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1306.9381713867188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Martin Graetz, Stephen Russell, and Wayne Wiitanen invented Spacewar!", "latency_ms": 4009.432792663574, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 676}, "2": {"k": 2, "answer": "Steve Russell, Spacewar!", "latency_ms": 2433.0828189849854, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1362}, "3": {"k": 3, "answer": "Steve Russell, Spacewar!", "latency_ms": 3460.153818130493, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1988}, "4": {"k": 4, "answer": "Steve Russell, Spacewar!", "latency_ms": 2910.223960876465, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2674}, "5": {"k": 5, "answer": "Steve Russell, Spacewar!", "latency_ms": 3353.2347679138184, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3367}, "6": {"k": 6, "answer": "Steve Russell, Spacewar!", "latency_ms": 4136.6705894470215, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 4048}}}
{"qid": "5154394238729460303", "question": "largest state in the us by land mass", "gold_answers": ["Alaska"], "shots": {"0": {"k": 0, "answer": "Alaska", "latency_ms": 886.8682384490967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alaska", "latency_ms": 982.1774959564209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 701}, "2": {"k": 2, "answer": "Alaska", "latency_ms": 1606.9042682647705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1369}, "3": {"k": 3, "answer": "Alaska", "latency_ms": 1949.4264125823975, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1992}, "4": {"k": 4, "answer": "Alaska", "latency_ms": 2061.819553375244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2581}, "5": {"k": 5, "answer": "Alaska", "latency_ms": 2827.6045322418213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3239}, "6": {"k": 6, "answer": "Alaska", "latency_ms": 3355.966567993164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3926}}}
{"qid": "-6371603500131574271", "question": "who sings somebody's watching me with michael jackson", "gold_answers": ["Jermaine Jackson", "Rockwell"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1230.44753074646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rockwell", "latency_ms": 1403.9685726165771, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "Rockwell", "latency_ms": 1600.5480289459229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Rockwell", "latency_ms": 1911.1337661743164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1957}, "4": {"k": 4, "answer": "Rockwell", "latency_ms": 2050.2302646636963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2628}, "5": {"k": 5, "answer": "Rockwell", "latency_ms": 3162.2376441955566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3294}, "6": {"k": 6, "answer": "Jermaine Jackson", "latency_ms": 3503.2782554626465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3942}}}
{"qid": "-89839634525298434", "question": "who played the mom on what's eating gilbert grape", "gold_answers": ["Darlene Cates"], "shots": {"0": {"k": 0, "answer": "Geraldine Page", "latency_ms": 1234.6992492675781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Darlene Cates", "latency_ms": 1616.7833805084229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "Darlene Cates", "latency_ms": 2041.510820388794, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "Darlene Cates", "latency_ms": 2608.6299419403076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1890}, "4": {"k": 4, "answer": "Darlene Cates", "latency_ms": 2484.931230545044, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2596}, "5": {"k": 5, "answer": "Darlene Cates", "latency_ms": 3072.240114212036, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3231}, "6": {"k": 6, "answer": "Darlene Cates", "latency_ms": 3475.7180213928223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3871}}}
{"qid": "4094570070863238215", "question": "when does the second part of vikings season 4 start", "gold_answers": ["November 30 , 2016"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1232.7601909637451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "November 30, 2016", "latency_ms": 2795.056104660034, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "November 30, 2016", "latency_ms": 3236.309289932251, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1263}, "3": {"k": 3, "answer": "November 30, 2016", "latency_ms": 3645.1427936553955, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "November 30, 2016", "latency_ms": 4225.662708282471, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2509}, "5": {"k": 5, "answer": "November 30, 2016", "latency_ms": 4297.448396682739, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "November 30, 2016", "latency_ms": 5015.010595321655, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3762}}}
{"qid": "-1084748809184043293", "question": "when did the us stop trading with japan", "gold_answers": ["1940", "1939"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1301.6974925994873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1592.7164554595947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2014.089584350586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2453.4521102905273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1949}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2442.9776668548584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2614}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3650.5422592163086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3295}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3984.7614765167236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3968}}}
{"qid": "-5869834741419224491", "question": "who gets the golden boot if its a tie", "gold_answers": ["shared"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1258.183479309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "player who played fewer minutes", "latency_ms": 1720.01051902771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "player with most assists", "latency_ms": 1979.3918132781982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "player with more assists (if no penalty goals)", "latency_ms": 3569.425106048584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1801}, "4": {"k": 4, "answer": "player with more assists (if no penalty goals), or fewer minutes played (in some cases)", "latency_ms": 5542.917013168335, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2423}, "5": {"k": 5, "answer": "player with more assists (if no penalty goals), or fewer minutes played (in some cases)", "latency_ms": 5843.126535415649, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3041}, "6": {"k": 6, "answer": "player with more assists (if tied on goals) or fewer minutes played (if tied on goals and assists)", "latency_ms": 7197.45397567749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3617}}}
{"qid": "6792980250224411482", "question": "who is the minister of local government in zimbabwe", "gold_answers": ["Hon July Moyo"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1231.3201427459717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Saviour Kasukuwere", "latency_ms": 1785.6192588806152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 704}, "2": {"k": 2, "answer": "Saviour Kasukuwere", "latency_ms": 2250.3907680511475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1420}, "3": {"k": 3, "answer": "Saviour Kasukuwere", "latency_ms": 2634.772300720215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2099}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2806.3650131225586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2715}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2954.102039337158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3379}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3870.9869384765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3979}}}
{"qid": "4395570541686945657", "question": "who are the dallas cowboys playing on thanksgiving", "gold_answers": ["the Detroit Lions", "Los Angeles Chargers"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1266.4523124694824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dallas Cowboys", "latency_ms": 1495.5780506134033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "Washington Redskins", "latency_ms": 1550.2989292144775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Washington Redskins", "latency_ms": 2153.693437576294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1907}, "4": {"k": 4, "answer": "Washington Redskins", "latency_ms": 2145.383834838867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "Washington Redskins", "latency_ms": 2422.9962825775146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3178}, "6": {"k": 6, "answer": "Washington Redskins", "latency_ms": 2565.2215480804443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3852}}}
{"qid": "6411144351147088389", "question": "who sang i put a spell on you in hocus pocus", "gold_answers": ["Bette Midler"], "shots": {"0": {"k": 0, "answer": "Drew Barrymore", "latency_ms": 1245.6066608428955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bette Midler", "latency_ms": 1601.693868637085, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "Bette Midler and her Harlettes", "latency_ms": 2717.118740081787, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Bette Midler and her Harlettes", "latency_ms": 3425.499439239502, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1909}, "4": {"k": 4, "answer": "Bette Midler and her Harlettes", "latency_ms": 3265.745162963867, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Bette Midler and her Harlettes", "latency_ms": 3795.1934337615967, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3142}, "6": {"k": 6, "answer": "Bette Midler and her Harlettes", "latency_ms": 4544.384002685547, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3666}}}
{"qid": "-6558090229319450246", "question": "what are the roles of international monetary fund", "gold_answers": ["to foster global monetary cooperation", "reduce poverty around the world", "secure financial stability", "foster global monetary cooperation", "facilitate international trade"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1290.877103805542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "foster global monetary cooperation, secure financial stability, facilitate international trade, promote high employment and sustainable economic growth, and reduce poverty around the world.", "latency_ms": 6607.418060302734, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 734}, "2": {"k": 2, "answer": "foster global monetary cooperation, secure financial stability, facilitate international trade, promote high employment and sustainable economic growth, reduce poverty around the world; analyzes economic and financial policies; assesses policy consequences; guides data dissemination standards", "latency_ms": 9752.067565917969, "em": 0.0, "f1": 0.21621621621621626, "containment": 1.0, "context_chars": 1452}, "3": {"k": 3, "answer": "promote global monetary cooperation, secure financial stability, facilitate international trade, promote high employment and sustainable economic growth, reduce poverty, analyze economic and financial policies, assess policy consequences, disseminate economic data, surveil member economies, provide loans during balance of payments difficulties", "latency_ms": 11721.561193466187, "em": 0.0, "f1": 0.13953488372093023, "containment": 1.0, "context_chars": 2209}, "4": {"k": 4, "answer": "promote global monetary cooperation, secure financial stability, facilitate international trade, promote high employment, sustainable economic growth, reduce poverty, analyze economic and financial policies, assess policy consequences, disseminate economic data, surveil member economies, provide loans during balance of payments difficulties", "latency_ms": 12287.654161453247, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 2867}, "5": {"k": 5, "answer": "promote global monetary cooperation, secure financial stability, facilitate international trade, promote high employment and sustainable economic growth, reduce poverty, analyze economic and financial policies, assess policy consequences, disseminate economic data, surveil member economies, provide loans during balance of payments difficulties", "latency_ms": 12765.76042175293, "em": 0.0, "f1": 0.13953488372093023, "containment": 1.0, "context_chars": 3530}, "6": {"k": 6, "answer": "promote global monetary cooperation, secure financial stability, facilitate international trade, promote high employment, sustainable economic growth, reduce poverty, analyze economic policies, assess policy consequences, disseminate economic data, provide loans during balance of payments difficulties, supervise member economies, and improve member country economies.", "latency_ms": 13872.2825050354, "em": 0.0, "f1": 0.13333333333333333, "containment": 1.0, "context_chars": 4194}}}
{"qid": "-628291178392259442", "question": "when was the first star wars film released", "gold_answers": ["May 25 , 1977", "1977"], "shots": {"0": {"k": 0, "answer": "1977", "latency_ms": 1285.691738128662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "May 25, 1977", "latency_ms": 2567.5792694091797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "May 25, 1977", "latency_ms": 3383.8276863098145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1288}, "3": {"k": 3, "answer": "May 25, 1977", "latency_ms": 4128.228187561035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1922}, "4": {"k": 4, "answer": "1977", "latency_ms": 2771.3639736175537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2559}, "5": {"k": 5, "answer": "1977", "latency_ms": 3298.121690750122, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "1977", "latency_ms": 3307.7893257141113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3905}}}
{"qid": "9199587263422732891", "question": "who was the bad guy in silence of the lambs", "gold_answers": ["Buffalo Bill"], "shots": {"0": {"k": 0, "answer": "Buffalo Bill", "latency_ms": 1025.5725383758545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Buffalo Bill", "latency_ms": 1365.2844429016113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Buffalo Bill", "latency_ms": 1808.3882331848145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "Dr. Hannibal Lecter", "latency_ms": 2809.1983795166016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1993}, "4": {"k": 4, "answer": "Dr. Hannibal Lecter", "latency_ms": 2861.445188522339, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2635}, "5": {"k": 5, "answer": "Dr. Hannibal Lecter", "latency_ms": 3349.915027618408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3315}, "6": {"k": 6, "answer": "Dr. Hannibal Lecter", "latency_ms": 3849.879264831543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3938}}}
{"qid": "-507214070235479571", "question": "epidemiologists attempt to explain the link between health and variables such as", "gold_answers": ["biological agents", "disease conditions in defined populations", "alcohol", "chemicals", "smoking", "stress"], "shots": {"0": {"k": 0, "answer": "socioeconomic status, environment, behavior, genetics, and access to healthcare.", "latency_ms": 3647.646188735962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "exposures", "latency_ms": 1706.3686847686768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "friendship", "latency_ms": 1479.975938796997, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "friendship and socioeconomic status", "latency_ms": 2707.9453468322754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1997}, "4": {"k": 4, "answer": "friendship, socioeconomic status, economic inequality", "latency_ms": 3939.260959625244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2742}, "5": {"k": 5, "answer": "socioeconomic status", "latency_ms": 2510.821580886841, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3377}, "6": {"k": 6, "answer": "social status, environment, friendship, socioeconomic status, economic inequality, policies, programmes, interventions", "latency_ms": 6010.951995849609, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4096}}}
{"qid": "5954016886103366248", "question": "when was night at the museum 3 filmed", "gold_answers": ["2014", "London , England", "British Columbia , Canada", "January to May 2014", "from January to May 2014"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1253.9212703704834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1820.7039833068848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1890.1948928833008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "January 27, 2014 to May 2014", "latency_ms": 5218.953609466553, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "January 27, 2014 to May 2014", "latency_ms": 5058.247089385986, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2527}, "5": {"k": 5, "answer": "May 2014", "latency_ms": 3661.52286529541, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3166}, "6": {"k": 6, "answer": "May 2014", "latency_ms": 3688.612699508667, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3803}}}
{"qid": "4492033271398413517", "question": "what mall did they use in back to the future", "gold_answers": ["Puente Hills Mall"], "shots": {"0": {"k": 0, "answer": "Roosevelt Mall", "latency_ms": 1233.2828044891357, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Puente Hills Mall", "latency_ms": 1370.013952255249, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Puente Hills Mall", "latency_ms": 2011.7461681365967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Puente Hills Mall", "latency_ms": 2292.6647663116455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1827}, "4": {"k": 4, "answer": "Puente Hills Mall", "latency_ms": 2995.1729774475098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2440}, "5": {"k": 5, "answer": "Puente Hills Mall", "latency_ms": 2847.377300262451, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3047}, "6": {"k": 6, "answer": "Puente Hills Mall", "latency_ms": 3364.237070083618, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3642}}}
{"qid": "-3719623571078658627", "question": "what does rt mean on a dodge car", "gold_answers": ["Road / Track"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1294.252872467041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "RT means \"Revised Tuning\" on a Dodge Caravan.", "latency_ms": 3814.1252994537354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 682}, "2": {"k": 2, "answer": "RT means \"Revised Tuning\" on a Dodge Caravan, indicating updated styling, content features, and suspension tuning.", "latency_ms": 6105.568885803223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "RT means \"Revised Tuning\" on a Dodge Caravan, indicating updated styling, content features, and suspension tuning.", "latency_ms": 6596.296310424805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2032}, "4": {"k": 4, "answer": "RT means \"Revised Tuning\" on a Dodge Caravan, indicating updated styling, content features, and suspension tuning.", "latency_ms": 7103.0590534210205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2724}, "5": {"k": 5, "answer": "RT means \"Revised Tuning\" on a Dodge Caravan, indicating updated styling, suspension, and features.", "latency_ms": 7868.777513504028, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3336}, "6": {"k": 6, "answer": "RT-platform", "latency_ms": 2873.26717376709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3964}}}
{"qid": "-3436933223479131319", "question": "when did the movie breakfast club come out", "gold_answers": ["February 15 , 1985", "1985"], "shots": {"0": {"k": 0, "answer": "1985", "latency_ms": 1301.9640445709229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "February 1985", "latency_ms": 2035.1626873016357, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "February 1985", "latency_ms": 2429.2731285095215, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "February 1985", "latency_ms": 2869.447708129883, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1924}, "4": {"k": 4, "answer": "1985", "latency_ms": 2454.1587829589844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "1985", "latency_ms": 2977.202892303467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3166}, "6": {"k": 6, "answer": "1985", "latency_ms": 4292.606830596924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3746}}}
{"qid": "-6477588851233520447", "question": "who is the king and queen of the netherlands", "gold_answers": ["Queen Mxima of the Netherlands", "King Willem - Alexander"], "shots": {"0": {"k": 0, "answer": "King Willem-Alexander and Queen Mxima", "latency_ms": 2429.3107986450195, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "King Willem-Alexander and Queen Mxima", "latency_ms": 2829.702615737915, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "King Willem-Alexander and Queen Mxima", "latency_ms": 3122.9310035705566, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 1357}, "3": {"k": 3, "answer": "King Willem-Alexander and Queen Mxima", "latency_ms": 3718.4948921203613, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 2059}, "4": {"k": 4, "answer": "King Willem-Alexander and Queen Mxima", "latency_ms": 4585.168123245239, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 2717}, "5": {"k": 5, "answer": "King Willem-Alexander and Queen Mxima", "latency_ms": 4205.313205718994, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "King Willem-Alexander and Queen Mxima", "latency_ms": 5045.967102050781, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3956}}}
{"qid": "7281701387754006749", "question": "what written material is included in the talmud", "gold_answers": ["the Gemara", "the Mishnah"], "shots": {"0": {"k": 0, "answer": "Babylonian and Jerusalem Talmuds, Mishnah, Talmudic discussions, legal rulings, rabbinic interpretations, aggadic stories, halachic texts", "latency_ms": 7460.74652671814, "em": 0.0, "f1": 0.125, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Baraitot, halachic Midrashim, Tosefta", "latency_ms": 4114.980459213257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "halachic and aggadic material, Baraitot, Midrashim, Tosefta, Targumim", "latency_ms": 6643.68748664856, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "Halakhic and aggadic material, Baraitot, Midrashim, Tosefta, and Talmudic commentaries", "latency_ms": 7638.042449951172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2101}, "4": {"k": 4, "answer": "halakhic and aggadic material, Baraitot, Targumim, Midrashim, Torah commentaries", "latency_ms": 6737.433671951294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2762}, "5": {"k": 5, "answer": "excerpts from Tannaitic literature, Baraitot, halachic and aggadic material, commentaries, and marginal notes like Torah Or, Ein Mishpat Ner Mitzvah, and Masoret ha-Shas", "latency_ms": 11707.772254943848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "Halakhic and aggadic material, Baraitot, Targumim, and excerpts from Midrashim and Tosefta", "latency_ms": 8393.948078155518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4021}}}
{"qid": "2178534208098154067", "question": "what are the value of style guides and style sheet", "gold_answers": ["improve communication"], "shots": {"0": {"k": 0, "answer": "consistency, clarity, efficiency", "latency_ms": 1627.8533935546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "improve communication, ensure consistency, enforce best practices in usage and language composition, visual composition, orthography, and typography", "latency_ms": 5537.44101524353, "em": 0.0, "f1": 0.21052631578947367, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "improve communication, ensure consistency, enforce best practice in usage and language composition, visual composition, orthography, and typography", "latency_ms": 5969.810962677002, "em": 0.0, "f1": 0.21052631578947367, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "improve communication, ensure consistency, enforce best practice in usage and language composition, visual composition, orthography, and typography", "latency_ms": 5907.455921173096, "em": 0.0, "f1": 0.21052631578947367, "containment": 1.0, "context_chars": 1921}, "4": {"k": 4, "answer": "improve communication, ensure consistency, enforce best practice in usage and language composition, visual composition, orthography, and typography", "latency_ms": 6669.905662536621, "em": 0.0, "f1": 0.21052631578947367, "containment": 1.0, "context_chars": 2605}, "5": {"k": 5, "answer": "ensure consistency, improve communication, enforce best practice in usage and language composition, visual composition, orthography, and typography; save time, maintain design uniformity, allow easy design changes", "latency_ms": 9506.528615951538, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 3254}, "6": {"k": 6, "answer": "improve communication, ensure consistency, enforce best practice in usage and language composition, visual composition, orthography and typography, save time, maintain design consistency, separate presentation from content", "latency_ms": 9337.151288986206, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 3957}}}
{"qid": "1915885935757407192", "question": "what is the approximate volume of blood in your body", "gold_answers": ["approximately 5 liters"], "shots": {"0": {"k": 0, "answer": "5 liters", "latency_ms": 858.9255809783936, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5 liters", "latency_ms": 968.6448574066162, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "5 liters", "latency_ms": 1408.616065979004, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "5 liters", "latency_ms": 1860.4977130889893, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "5 liters", "latency_ms": 2394.7341442108154, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "5 liters", "latency_ms": 2384.2639923095703, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3257}, "6": {"k": 6, "answer": "5 liters", "latency_ms": 3547.6205348968506, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3872}}}
{"qid": "-369514098498013661", "question": "what season does bart bass die in gossip girl", "gold_answers": [")"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1232.8646183013916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "first season", "latency_ms": 1348.4017848968506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "third season", "latency_ms": 1578.3617496490479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "third season", "latency_ms": 2031.0337543487549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "third season", "latency_ms": 2054.255485534668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "third season", "latency_ms": 2645.0366973876953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3141}, "6": {"k": 6, "answer": "third season", "latency_ms": 2565.5152797698975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3797}}}
{"qid": "-1116288849470511210", "question": "when did france and belgium invade the ruhr", "gold_answers": ["11 January 1923", "1923", "January 1923"], "shots": {"0": {"k": 0, "answer": "1923", "latency_ms": 1231.5988540649414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1367.0117855072021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2059.741735458374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "11 January 1923", "latency_ms": 4034.5475673675537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "11 January 1923", "latency_ms": 3269.4408893585205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2575}, "5": {"k": 5, "answer": "11 January 1923", "latency_ms": 3916.731834411621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "11 January 1923", "latency_ms": 3886.016368865967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3840}}}
{"qid": "1787430967072848088", "question": "what type of novel is goodbye mr chips", "gold_answers": ["Psychological fiction", "novella"], "shots": {"0": {"k": 0, "answer": "novel about education", "latency_ms": 1289.8120880126953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "novella", "latency_ms": 1355.6723594665527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "novella", "latency_ms": 2161.329507827759, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1268}, "3": {"k": 3, "answer": "novella", "latency_ms": 2181.1468601226807, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1920}, "4": {"k": 4, "answer": "schoolteacher novel", "latency_ms": 2481.987953186035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2570}, "5": {"k": 5, "answer": "schoolteacher novel", "latency_ms": 2950.194835662842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "schoolteacher novel", "latency_ms": 3124.5927810668945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3852}}}
{"qid": "2105265206768647509", "question": "who won the mens figure skating in 2018 olympics", "gold_answers": ["Javier Fernndez", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Gold medalist: Nathan Chen", "latency_ms": 1695.549488067627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nathan Chen", "latency_ms": 1397.9167938232422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 685}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1883.4185600280762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1360}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2632.6446533203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2007}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3059.0806007385254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2655}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3550.1973628997803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3307}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 4165.612697601318, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3936}}}
{"qid": "134587584998146088", "question": "when do you get your dress blues in the army", "gold_answers": ["during initial entry training", "when commissioned"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1226.6597747802734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2020", "latency_ms": 1495.8240985870361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2074.5556354522705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "2020", "latency_ms": 2265.944242477417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "2020", "latency_ms": 2522.784471511841, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "2020", "latency_ms": 2821.0949897766113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3122}, "6": {"k": 6, "answer": "4th-quarter of fiscal year 2010", "latency_ms": 4409.435510635376, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3732}}}
{"qid": "1450599178139755430", "question": "what happened at the 1939 worlds fair in regards to television", "gold_answers": ["Television demonstrations are held"], "shots": {"0": {"k": 0, "answer": "Television demonstrations were showcased.", "latency_ms": 1639.2192840576172, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Television demonstrations and public purchase of television sets", "latency_ms": 2636.0301971435547, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 687}, "2": {"k": 2, "answer": "Television demonstrations and public sales at the fair; first televised opening ceremony with President Roosevelt; public availability of television sets.", "latency_ms": 6056.042432785034, "em": 0.0, "f1": 0.17391304347826086, "containment": 0.0, "context_chars": 1330}, "3": {"k": 3, "answer": "Television was introduced to the public at the 1939 New York World's Fair, with demonstrations at the RCA, General Electric, and Westinghouse pavilions, and President Roosevelt's speech was televised during the opening ceremony.", "latency_ms": 11434.326648712158, "em": 0.0, "f1": 0.12121212121212119, "containment": 0.0, "context_chars": 1955}, "4": {"k": 4, "answer": "Television was introduced to the public at the 1939 New York World's Fair, with demonstrations at the RCA, General Electric, and Westinghouse pavilions. President Roosevelt's speech was televised, and the event marked the first public sale of television sets.", "latency_ms": 13331.071376800537, "em": 0.0, "f1": 0.10526315789473684, "containment": 0.0, "context_chars": 2659}, "5": {"k": 5, "answer": "Television was introduced to the public at the 1939 New York World's Fair, with broadcasts of President Roosevelt's speech and other events, marking the beginning of regularly scheduled television broadcasts in New York City.", "latency_ms": 11246.477365493774, "em": 0.0, "f1": 0.05714285714285714, "containment": 0.0, "context_chars": 3315}, "6": {"k": 6, "answer": "Television was introduced to the public at the 1939 New York World's Fair, with broadcasts of President Roosevelt's speech and other events, marking the beginning of regular television broadcasts in New York City.", "latency_ms": 11184.64732170105, "em": 0.0, "f1": 0.0588235294117647, "containment": 0.0, "context_chars": 3982}}}
{"qid": "7075559602853408649", "question": "when does buffy tell her friends she was in heaven", "gold_answers": ["Something to Sing About"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1249.3553161621094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "After Life (Buffy the Vampire Slayer)", "latency_ms": 2812.6790523529053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "After Life (Buffy the Vampire Slayer)", "latency_ms": 3050.846576690674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "After Life (Buffy the Vampire Slayer)", "latency_ms": 3287.9812717437744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "After Life (Buffy the Vampire Slayer)", "latency_ms": 3681.7140579223633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "After Life (Buffy the Vampire Slayer)", "latency_ms": 4134.148120880127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3083}, "6": {"k": 6, "answer": "several episodes later", "latency_ms": 3512.9456520080566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3667}}}
{"qid": "6709331549884586945", "question": "the recipient of first jnanpith award was an author which language", "gold_answers": ["Malayalam"], "shots": {"0": {"k": 0, "answer": "Kannada", "latency_ms": 1109.3199253082275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bengali", "latency_ms": 1402.3380279541016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "Bengali", "latency_ms": 1818.624496459961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Bengali", "latency_ms": 2314.117431640625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1973}, "4": {"k": 4, "answer": "Bengali", "latency_ms": 2692.856788635254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "Malayalam", "latency_ms": 2783.0631732940674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3272}, "6": {"k": 6, "answer": "Malayalam", "latency_ms": 4423.89988899231, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3912}}}
{"qid": "-5800244801360835363", "question": "criminal minds episode where jj becomes a profiler", "gold_answers": ["The season seven premiere", "season seven premiere"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1284.0147018432617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1590.9359455108643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2032.4811935424805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2294.368267059326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2539.891004562378, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2517}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3018.6924934387207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3276.245594024658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3747}}}
{"qid": "7361909937331900466", "question": "who has played raoul in phantom of the opera", "gold_answers": ["Steve Barton", "Tim Martin Gleason", "Hadley Fraser"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1270.6024646759033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Ball", "latency_ms": 1125.9050369262695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Michael Ball", "latency_ms": 2120.9776401519775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1200}, "3": {"k": 3, "answer": "Michael Ball, Brad Little, Tim Martin Gleason", "latency_ms": 4063.5907649993896, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1817}, "4": {"k": 4, "answer": "Michael Ball, Brad Little, Tim Martin Gleason, Hadley Fraser", "latency_ms": 4533.748149871826, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2497}, "5": {"k": 5, "answer": "Michael Ball, Brad Little, Tim Martin Gleason, Hadley Fraser, Gary Mauer", "latency_ms": 5976.835489273071, "em": 0.0, "f1": 0.42857142857142855, "containment": 1.0, "context_chars": 3114}, "6": {"k": 6, "answer": "Michael Ball, Brad Little, Tim Martin Gleason, Hadley Fraser, Gary Mauer, John Cudia", "latency_ms": 6861.2494468688965, "em": 0.0, "f1": 0.375, "containment": 1.0, "context_chars": 3709}}}
{"qid": "3130297943294617952", "question": "who discovered that neural communication between cells occurs through chemicals", "gold_answers": ["Charles Sherrington"], "shots": {"0": {"k": 0, "answer": "Camillo Golgi", "latency_ms": 1423.9835739135742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1377.0418167114258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 681}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1934.7293376922607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1375}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1899.3520736694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2079}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2655.8830738067627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2776}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2782.7069759368896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3468}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2971.8921184539795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4154}}}
{"qid": "-8188854097093895186", "question": "who has the most ncaa basketball tournament appearances", "gold_answers": ["Kentucky"], "shots": {"0": {"k": 0, "answer": "University of Kansas", "latency_ms": 1034.6198081970215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sean Miller", "latency_ms": 1169.2123413085938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1878.1230449676514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2566.1635398864746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1995}, "4": {"k": 4, "answer": "Indiana Hoosiers", "latency_ms": 2790.022611618042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2702}, "5": {"k": 5, "answer": "Indiana Hoosiers", "latency_ms": 3365.8571243286133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3329}, "6": {"k": 6, "answer": "Indiana Hoosiers", "latency_ms": 3733.677864074707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4005}}}
{"qid": "-3197375005297250079", "question": "which condition would most likely require nutrition delivered through tpn", "gold_answers": ["bowel obstruction", "ulcerative colitis", "gastroschisis", "short bowel syndrome", "high - output fistula", "prolonged diarrhea", "very severe Crohn 's disease"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1237.7805709838867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "bowel obstruction", "latency_ms": 1163.123607635498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 735}, "2": {"k": 2, "answer": "short bowel syndrome", "latency_ms": 1822.619915008545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1488}, "3": {"k": 3, "answer": "short bowel syndrome", "latency_ms": 2111.234426498413, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2183}, "4": {"k": 4, "answer": "short bowel syndrome", "latency_ms": 2510.2579593658447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2929}, "5": {"k": 5, "answer": "short bowel syndrome", "latency_ms": 3569.2784786224365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3625}, "6": {"k": 6, "answer": "short bowel syndrome", "latency_ms": 3238.5993003845215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4346}}}
{"qid": "-1059932910092423631", "question": "today gestalt psychology ideas are part of which branch of psychology", "gold_answers": ["experimental psychology", "Berlin School of experimental psychology"], "shots": {"0": {"k": 0, "answer": "cognitive psychology", "latency_ms": 1035.365343093872, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "neural binding", "latency_ms": 1158.0126285552979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "neural binding", "latency_ms": 1712.2993469238281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1368}, "3": {"k": 3, "answer": "neural binding", "latency_ms": 2048.4654903411865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2075}, "4": {"k": 4, "answer": "neural binding", "latency_ms": 2458.4784507751465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2756}, "5": {"k": 5, "answer": "neural binding", "latency_ms": 2583.278179168701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3444}, "6": {"k": 6, "answer": "cognitive psychology", "latency_ms": 3518.460988998413, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4129}}}
{"qid": "3063199819637642694", "question": "how did long john silver lose his leg in treasure island", "gold_answers": ["in the Royal Navy"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1226.6631126403809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1388.2992267608643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "under \"the immortal Hawke\"", "latency_ms": 2584.639310836792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "under \"the immortal Hawke\"", "latency_ms": 2545.8824634552, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1819}, "4": {"k": 4, "answer": "under \"the immortal Hawke\"", "latency_ms": 3142.1597003936768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2410}, "5": {"k": 5, "answer": "under \"the immortal Hawke\"", "latency_ms": 3457.378387451172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2982}, "6": {"k": 6, "answer": "under \"the immortal Hawke\"", "latency_ms": 3668.370008468628, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3614}}}
{"qid": "-1716244375468450999", "question": "who was the first territorial governor of oklahoma", "gold_answers": ["George Washington Steele"], "shots": {"0": {"k": 0, "answer": "Willard B. Gatewood", "latency_ms": 1636.564016342163, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "George Washington Steele", "latency_ms": 1282.2809219360352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "George Washington Steele", "latency_ms": 1721.4775085449219, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1375}, "3": {"k": 3, "answer": "George Washington Steele", "latency_ms": 2066.4596557617188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2036}, "4": {"k": 4, "answer": "George Washington Steele", "latency_ms": 2275.813341140747, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2744}, "5": {"k": 5, "answer": "George Washington Steele", "latency_ms": 2556.519031524658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3474}, "6": {"k": 6, "answer": "George Washington Steele", "latency_ms": 2798.532724380493, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4149}}}
{"qid": "3124572532765125550", "question": "who did the mavericks beat in the finals", "gold_answers": ["Miami Heat"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1235.027551651001, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1385.9245777130127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1987.2887134552002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 1854.4139862060547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1855}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 2346.4901447296143, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2442}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 2399.301528930664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3041}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 2831.4414024353027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3656}}}
{"qid": "-8179137917755764249", "question": "who is the actor that plays sneaky pete", "gold_answers": ["Giovanni Ribisi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1253.0016899108887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Giovanni Ribisi", "latency_ms": 1765.1584148406982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Giovanni Ribisi", "latency_ms": 2228.762626647949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2463.339328765869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Ethan Embry", "latency_ms": 2445.0137615203857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Ethan Embry", "latency_ms": 3483.2849502563477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3100}, "6": {"k": 6, "answer": "Ethan Embry", "latency_ms": 4154.712915420532, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3760}}}
{"qid": "-488573928094288904", "question": "sequel to a christmas story it runs in the family", "gold_answers": ["My Summer Story"], "shots": {"0": {"k": 0, "answer": "A Christmas Story II", "latency_ms": 1245.7444667816162, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "My Summer Story", "latency_ms": 1369.1530227661133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "1994", "latency_ms": 2016.0365104675293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "1994", "latency_ms": 2370.365619659424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "A Christmas Story 2", "latency_ms": 3536.2374782562256, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "My Summer Story", "latency_ms": 2880.7685375213623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3158}, "6": {"k": 6, "answer": "1994", "latency_ms": 3282.6883792877197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3805}}}
{"qid": "-4649146182478016322", "question": "when did virgin australia (formerly virgin blue) commence flying in australia", "gold_answers": ["November 1999"], "shots": {"0": {"k": 0, "answer": "2007", "latency_ms": 1241.6484355926514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "27 February 2009", "latency_ms": 2391.075372695923, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 698}, "2": {"k": 2, "answer": "27 February 2009", "latency_ms": 2861.2916469573975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1356}, "3": {"k": 3, "answer": "27 February 2009", "latency_ms": 3143.0273056030273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2013}, "4": {"k": 4, "answer": "August 2000", "latency_ms": 3230.703115463257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "27 February 2009", "latency_ms": 3882.9097747802734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3313}, "6": {"k": 6, "answer": "August 2000", "latency_ms": 4670.685052871704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3967}}}
{"qid": "-7386387080002447998", "question": "a political leader during the roman empire was called", "gold_answers": ["emperors"], "shots": {"0": {"k": 0, "answer": "emperor", "latency_ms": 837.4285697937012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "public cult leader", "latency_ms": 1560.9984397888184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Octavian", "latency_ms": 1545.26686668396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "emperor", "latency_ms": 1871.3171482086182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2022}, "4": {"k": 4, "answer": "Octavian", "latency_ms": 2383.7382793426514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2653}, "5": {"k": 5, "answer": "Octavian", "latency_ms": 2511.523723602295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3285}, "6": {"k": 6, "answer": "Octavian", "latency_ms": 2556.9474697113037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3970}}}
{"qid": "6648524536408285205", "question": "what is the first book of percy jackson", "gold_answers": ["The Lightning Thief"], "shots": {"0": {"k": 0, "answer": "The Lightning Thief", "latency_ms": 1038.1062030792236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Percy Jackson & the Olympians", "latency_ms": 2592.942953109741, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "The Lightning Thief", "latency_ms": 1830.470323562622, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1248}, "3": {"k": 3, "answer": "The Lightning Thief", "latency_ms": 2254.1489601135254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1928}, "4": {"k": 4, "answer": "The Lightning Thief", "latency_ms": 2392.39239692688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2547}, "5": {"k": 5, "answer": "The Lightning Thief", "latency_ms": 2927.8106689453125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3187}, "6": {"k": 6, "answer": "The Lightning Thief", "latency_ms": 3063.163995742798, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3828}}}
{"qid": "-8743280518479013381", "question": "who sings the song only in my dreams", "gold_answers": ["Debbie Gibson"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1287.599802017212, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Weezer", "latency_ms": 1321.3558197021484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "Roy Orbison", "latency_ms": 1728.5325527191162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "Weezer", "latency_ms": 2259.160280227661, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1774}, "4": {"k": 4, "answer": "Weezer", "latency_ms": 2331.801652908325, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2406}, "5": {"k": 5, "answer": "Weezer", "latency_ms": 2797.961473464966, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3039}, "6": {"k": 6, "answer": "Weezer", "latency_ms": 2951.3988494873047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3639}}}
{"qid": "8015709437014232395", "question": "where is the capital city of alabama located", "gold_answers": ["Montgomery"], "shots": {"0": {"k": 0, "answer": "Montgomery", "latency_ms": 838.2341861724854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montgomery, Alabama", "latency_ms": 1820.2643394470215, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Montgomery, Alabama", "latency_ms": 1884.993076324463, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Montgomery, Alabama", "latency_ms": 2274.1966247558594, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1995}, "4": {"k": 4, "answer": "Montgomery, Alabama", "latency_ms": 2828.2113075256348, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2705}, "5": {"k": 5, "answer": "Montgomery, Alabama", "latency_ms": 3084.885835647583, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3349}, "6": {"k": 6, "answer": "Montgomery, Alabama", "latency_ms": 3386.4171504974365, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3964}}}
{"qid": "-7741834825578210187", "question": "when was coffee first made into a drink", "gold_answers": ["the 15th century", "15th century"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1295.0961589813232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1829.111099243164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1994.9395656585693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "1511", "latency_ms": 2317.5899982452393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1792}, "4": {"k": 4, "answer": "mid-15th century", "latency_ms": 2898.216724395752, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2391}, "5": {"k": 5, "answer": "middle of the 15th century", "latency_ms": 3953.1819820404053, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2968}, "6": {"k": 6, "answer": "middle of the 15th century", "latency_ms": 3793.339490890503, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3612}}}
{"qid": "5397736648256223057", "question": "when was the last time vancouver had an earthquake", "gold_answers": ["1946"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1228.2578945159912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1825.202226638794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "June 23, 1946", "latency_ms": 3297.93119430542, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1338}, "3": {"k": 3, "answer": "1946", "latency_ms": 2323.4026432037354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2006}, "4": {"k": 4, "answer": "1946", "latency_ms": 2531.0516357421875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2656}, "5": {"k": 5, "answer": "1700", "latency_ms": 3316.941738128662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "1700", "latency_ms": 3341.792345046997, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3919}}}
{"qid": "-2756184966764635962", "question": "when did tim hortons open in the usa", "gold_answers": ["1981"], "shots": {"0": {"k": 0, "answer": "1964", "latency_ms": 1238.5015487670898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Deerfield", "latency_ms": 1349.0254878997803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Deerfield", "latency_ms": 1711.6670608520508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "Deerfield", "latency_ms": 2252.5620460510254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1856}, "4": {"k": 4, "answer": "Deerfield", "latency_ms": 2258.9285373687744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2486}, "5": {"k": 5, "answer": "Deerfield", "latency_ms": 3265.05970954895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3079}, "6": {"k": 6, "answer": "Deerfield", "latency_ms": 3711.075782775879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "6006172994740079617", "question": "who sang the original scooby doo theme song", "gold_answers": ["Larry Marks"], "shots": {"0": {"k": 0, "answer": "Dana Hill", "latency_ms": 1061.5448951721191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roberts", "latency_ms": 1223.332166671753, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "Austin Roberts", "latency_ms": 1568.253993988037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2469.243288040161, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1885}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3122.7033138275146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Austin Roberts", "latency_ms": 2572.6194381713867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3159}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3557.1720600128174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3861}}}
{"qid": "-6197052503812142206", "question": "who has won the most superbowls as a player", "gold_answers": ["Tom Brady", "Charles Haley", "Neal Dahlen", "Bill Belichick"], "shots": {"0": {"k": 0, "answer": "Joe Montana", "latency_ms": 843.9757823944092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1609.2329025268555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2018.535852432251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2380.1183700561523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2839.064836502075, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3279.6812057495117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3141}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2959.4712257385254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3737}}}
{"qid": "1471601930209559051", "question": "who used to present i'm a celebrity now", "gold_answers": ["Ant & Dec"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1254.0404796600342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Laura Whitmore", "latency_ms": 1357.0842742919922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "Joe Swash and Caroline Flack", "latency_ms": 2610.466718673706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Emma Willis and Matt Willis", "latency_ms": 2739.0589714050293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Scarlett Moffatt, Joel Dommett, Joe Swash", "latency_ms": 4657.894611358643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2564}, "5": {"k": 5, "answer": "Holly Willoughby, Declan Donnelly, Scarlett Moffatt, Joel Dommett, Joe Swash", "latency_ms": 6930.620193481445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3187}, "6": {"k": 6, "answer": "Joe Swash", "latency_ms": 3449.7034549713135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3849}}}
{"qid": "5150934530929664244", "question": "who led the conquest of the incas in south america", "gold_answers": ["conquistador Francisco Pizarro", "Francisco Pizarro"], "shots": {"0": {"k": 0, "answer": "Vasco Nez de Balboa", "latency_ms": 2229.044198989868, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tupac Inca", "latency_ms": 1776.0119438171387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Francisco Pizarro, Diego de Almagro, and Hernando de Luque", "latency_ms": 4847.560405731201, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Francisco Pizarro, Diego de Almagro, and Hernando de Luque", "latency_ms": 5294.983625411987, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1934}, "4": {"k": 4, "answer": "Francisco Pizarro, Diego de Almagro, Hernando de Luque", "latency_ms": 5142.768859863281, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2600}, "5": {"k": 5, "answer": "Francisco Pizarro", "latency_ms": 3249.5763301849365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Francisco Pizarro", "latency_ms": 3502.485513687134, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3906}}}
{"qid": "5255969991136559330", "question": "who sings the pokemon theme song season 1", "gold_answers": ["Jason Paige"], "shots": {"0": {"k": 0, "answer": "Yoko Kanno", "latency_ms": 1233.0069541931152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1900.3777503967285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Man de la Parra", "latency_ms": 2413.482904434204, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "Sarah Brightman", "latency_ms": 2075.6468772888184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1819}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2476.764678955078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2379}, "5": {"k": 5, "answer": "Jason Paige", "latency_ms": 3170.926570892334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2989}, "6": {"k": 6, "answer": "Sarah Brightman", "latency_ms": 2849.4861125946045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3648}}}
{"qid": "1376719706403766477", "question": "where was the rise of the planet of the apes filmed", "gold_answers": ["San Francisco , California", "Oahu , Hawaii", "Vancouver , British Columbia"], "shots": {"0": {"k": 0, "answer": "California, USA", "latency_ms": 1056.3139915466309, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Vancouver, British Columbia; San Francisco, California; Oahu, Hawaii", "latency_ms": 3580.1243782043457, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Vancouver, British Columbia; San Francisco, California; Oahu, Hawaii", "latency_ms": 4190.366744995117, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Vancouver, British Columbia; San Francisco, California; Oahu, Hawaii", "latency_ms": 4609.8973751068115, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "Vancouver, British Columbia; San Francisco, California; Oahu, Hawaii", "latency_ms": 5014.731884002686, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 2532}, "5": {"k": 5, "answer": "Vancouver, British Columbia; San Francisco, California; Oahu, Hawaii", "latency_ms": 5449.76019859314, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 3128}, "6": {"k": 6, "answer": "Vancouver, British Columbia; San Francisco, California; Oahu, Hawaii", "latency_ms": 5683.08687210083, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 3708}}}
{"qid": "-8781977407436236434", "question": "where does wild caught sockeye salmon come from", "gold_answers": ["the Northern Pacific Ocean"], "shots": {"0": {"k": 0, "answer": "Pacific Ocean", "latency_ms": 842.0534133911133, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bristol Bay, Alaska; Kamchatka Peninsula, Russian Far East", "latency_ms": 3762.094497680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Bristol Bay, Alaska; Fraser River; Kamchatka Peninsula of the Russian Far East", "latency_ms": 4868.421316146851, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "Bristol Bay, Alaska; Kamchatka Peninsula of the Russian Far East; Fraser River and its tributaries; Snake River; Lake Ozette, Washington", "latency_ms": 8179.123640060425, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "Bristol Bay, Alaska; Fraser River, Canada; Kamchatka Peninsula, Russia; northern Hokkaid, Japan; Canadian Arctic; Siberia; Redfish Lake, Idaho", "latency_ms": 9155.676364898682, "em": 0.0, "f1": 0.09523809523809526, "containment": 0.0, "context_chars": 2608}, "5": {"k": 5, "answer": "Bristol Bay, Alaska; Kamchatka Peninsula, Russian Far East; Fraser River and its tributaries, Canada; Snake River and Lake Ozette, United States; northern Hokkaid Island, Japan; Canadian Arctic; Anadyr River, Siberia; Redfish Lake, Idaho", "latency_ms": 14375.99778175354, "em": 0.0, "f1": 0.05555555555555555, "containment": 0.0, "context_chars": 3301}, "6": {"k": 6, "answer": "Bristol Bay, Alaska; Fraser River; Kamchatka Peninsula; northern Hokkaid Island; Canadian Arctic; Anadyr River; Redfish Lake, Idaho", "latency_ms": 9426.802396774292, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 3935}}}
{"qid": "5898293246250067104", "question": "what is the latest version of microsoft office 2010", "gold_answers": ["14.0. 7182.5000"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1244.5831298828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1613.5902404785156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2114.9230003356934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "Office 2010 SP2", "latency_ms": 3361.3409996032715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1956}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2920.3712940216064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2607}, "5": {"k": 5, "answer": "Service Pack 2", "latency_ms": 2977.5781631469727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3225}, "6": {"k": 6, "answer": "Service Pack 2", "latency_ms": 3733.555316925049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3827}}}
{"qid": "-4565661977175862394", "question": "who added a press room to the white house", "gold_answers": ["Richard Nixon", "President Richard Nixon"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1244.8711395263672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "President Richard Nixon", "latency_ms": 1727.7977466583252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "President Richard Nixon", "latency_ms": 1805.9053421020508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1319}, "3": {"k": 3, "answer": "President Richard Nixon", "latency_ms": 2086.18426322937, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1957}, "4": {"k": 4, "answer": "President Richard Nixon", "latency_ms": 2435.6441497802734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2594}, "5": {"k": 5, "answer": "President Richard Nixon", "latency_ms": 2827.15106010437, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3214}, "6": {"k": 6, "answer": "President Richard Nixon", "latency_ms": 2993.368148803711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3856}}}
