{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 99.70951080322266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 22, 2018", "latency_ms": 356.3506603240967, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "June 21, 2018", "latency_ms": 460.9711170196533, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "June 21, 2018", "latency_ms": 375.1869201660156, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "June 21, 2018", "latency_ms": 459.4697952270508, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "June 21, 2018", "latency_ms": 389.2817497253418, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3106}, "6": {"k": 6, "answer": "June 21, 2018", "latency_ms": 333.32324028015137, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3761}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Ski Jumping, Nordic Combined, Freestyle", "latency_ms": 691.5202140808105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Freestyle skiing", "latency_ms": 94.19584274291992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Freestyle skiing, Cross-country skiing", "latency_ms": 198.52614402770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1487}, "3": {"k": 3, "answer": "Freestyle skiing, Cross-country skiing", "latency_ms": 274.44911003112793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2139}, "4": {"k": 4, "answer": "Freestyle, Alpine, Cross-country, Ski cross", "latency_ms": 387.7217769622803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2771}, "5": {"k": 5, "answer": "Freestyle skiing, Alpine skiing", "latency_ms": 309.94677543640137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3533}, "6": {"k": 6, "answer": "Freestyle skiing, Alpine skiing", "latency_ms": 267.6854133605957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4196}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 147.4478244781494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Aldo Mignone", "latency_ms": 233.4573268890381, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Aldo Mignone", "latency_ms": 312.4380111694336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Aldo Mignone", "latency_ms": 292.12307929992676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Aldo Mignone", "latency_ms": 237.57123947143555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Aldo Mignone", "latency_ms": 283.77771377563477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3064}, "6": {"k": 6, "answer": "Aldo Mignone", "latency_ms": 265.3920650482178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3684}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 197.9813575744629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Denver Broncos", "latency_ms": 130.77330589294434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 661}, "2": {"k": 2, "answer": "Broncos, Bengals", "latency_ms": 191.88594818115234, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Broncos, Bengals, Chargers", "latency_ms": 188.2023811340332, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "Denver Broncos, Cincinnati Bengals, San Diego Chargers", "latency_ms": 329.5173645019531, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Denver Broncos, Cincinnati Bengals, San Diego Chargers, Miami Dolphins", "latency_ms": 537.6250743865967, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3162}, "6": {"k": 6, "answer": "Denver Broncos, Cincinnati Bengals, San Diego Chargers", "latency_ms": 317.5845146179199, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3790}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "1985", "latency_ms": 110.89706420898438, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 December 1985", "latency_ms": 220.93915939331055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 727}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 210.33000946044922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1444}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 363.1398677825928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2083}, "4": {"k": 4, "answer": "8 December 1985", "latency_ms": 176.13816261291504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2891}, "5": {"k": 5, "answer": "8 December 1985", "latency_ms": 196.25449180603027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3592}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 216.59255027770996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4298}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 192.11554527282715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 84.14673805236816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "Spanish moss", "latency_ms": 122.17450141906738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Spanish moss", "latency_ms": 82.83352851867676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Spanish moss", "latency_ms": 120.80836296081543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2605}, "5": {"k": 5, "answer": "Spanish moss", "latency_ms": 120.35417556762695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3206}, "6": {"k": 6, "answer": "Spanish moss", "latency_ms": 105.30424118041992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3839}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "NYHA functional class", "latency_ms": 97.89872169494629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "NYHA Functional Classification", "latency_ms": 112.52307891845703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 730}, "2": {"k": 2, "answer": "New York Heart Association Functional Classification", "latency_ms": 231.39452934265137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1494}, "3": {"k": 3, "answer": "NYHA Functional Classification", "latency_ms": 186.9790554046631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2250}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 212.70251274108887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2897}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 205.70063591003418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3686}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 153.14364433288574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4395}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Dolly Parton", "latency_ms": 99.27701950073242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 112.89548873901367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 141.54696464538574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1158}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 159.423828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 254.37450408935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2462}, "5": {"k": 5, "answer": "Eurythmics", "latency_ms": 167.16885566711426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3079}, "6": {"k": 6, "answer": "Kim Carnes", "latency_ms": 130.83410263061523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3723}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 58.47954750061035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 51.249027252197266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "3", "latency_ms": 57.65247344970703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "3", "latency_ms": 69.45013999938965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "3", "latency_ms": 110.06927490234375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2507}, "5": {"k": 5, "answer": "3", "latency_ms": 120.74804306030273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3130}, "6": {"k": 6, "answer": "3", "latency_ms": 143.27096939086914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3814}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "biscuit", "latency_ms": 133.50248336791992, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biscuit-sized cake", "latency_ms": 119.66848373413086, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "biscuit-sized cake", "latency_ms": 144.8974609375, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "cake", "latency_ms": 80.8258056640625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1764}, "4": {"k": 4, "answer": "a cake", "latency_ms": 87.01372146606445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "a cake", "latency_ms": 166.98074340820312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3040}, "6": {"k": 6, "answer": "a cake", "latency_ms": 130.59306144714355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Seth MacFarlane", "latency_ms": 138.0784511566162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seth MacFarlane", "latency_ms": 155.930757522583, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "Seth MacFarlane", "latency_ms": 195.04332542419434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Seth MacFarlane", "latency_ms": 145.89238166809082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 228.35564613342285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2554}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 256.27732276916504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3178}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 235.21137237548828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3812}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 169.2490577697754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "amphetamines", "latency_ms": 235.41712760925293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "amphetamines", "latency_ms": 162.8553867340088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1289}, "3": {"k": 3, "answer": "amphetamines", "latency_ms": 95.2901840209961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1866}, "4": {"k": 4, "answer": "amphetamines", "latency_ms": 99.72643852233887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2506}, "5": {"k": 5, "answer": "amphetamines", "latency_ms": 194.04339790344238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3114}, "6": {"k": 6, "answer": "amphetamines", "latency_ms": 117.48933792114258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3719}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "19 minutes 38 seconds", "latency_ms": 119.56119537353516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1 week", "latency_ms": 73.50468635559082, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "1 week", "latency_ms": 72.18456268310547, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1169}, "3": {"k": 3, "answer": "1 week", "latency_ms": 111.17839813232422, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1781}, "4": {"k": 4, "answer": "1 week", "latency_ms": 87.19325065612793, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2400}, "5": {"k": 5, "answer": "1 week", "latency_ms": 101.38130187988281, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2973}, "6": {"k": 6, "answer": "1 week", "latency_ms": 123.14343452453613, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3528}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 83.27603340148926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.17832374572754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 148.44989776611328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.65187644958496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 191.46275520324707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 132.18140602111816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3143}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 213.87362480163574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3752}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.31821250915527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 172.6548671722412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 97.20420837402344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 127.45165824890137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 175.4782199859619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2623}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 200.7298469543457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 143.80192756652832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3906}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 79.7123908996582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 115.04292488098145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "1983", "latency_ms": 110.07142066955566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1308}, "3": {"k": 3, "answer": "1983", "latency_ms": 108.78372192382812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1922}, "4": {"k": 4, "answer": "1983", "latency_ms": 113.56902122497559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2597}, "5": {"k": 5, "answer": "1983", "latency_ms": 181.69331550598145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3254}, "6": {"k": 6, "answer": "1983", "latency_ms": 159.57236289978027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3893}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "Linda Purl", "latency_ms": 78.83548736572266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alexz Johnson", "latency_ms": 140.38419723510742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Lisa Dalbello", "latency_ms": 97.48053550720215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Alexz Johnson, Jim McGrath, Jody Colero, Stephen Stohn, Lisa Dalbello, Damhnait Doyle", "latency_ms": 559.0453147888184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Lisa Dalbello", "latency_ms": 159.58523750305176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Lisa Dalbello", "latency_ms": 197.75080680847168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3289}, "6": {"k": 6, "answer": "Lisa Dalbello", "latency_ms": 187.9115104675293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3936}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 102.36024856567383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2002", "latency_ms": 200.7126808166504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 629}, "2": {"k": 2, "answer": "March 15, 2002", "latency_ms": 260.1358890533447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 160.96901893615723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 115.52000045776367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2557}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 200.11091232299805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "2002", "latency_ms": 142.89093017578125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3847}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 118.99232864379883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "master sergeant", "latency_ms": 119.25220489501953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 718}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 116.53852462768555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 110.63861846923828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "master sergeant", "latency_ms": 100.9521484375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2476}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 159.24882888793945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3052}, "6": {"k": 6, "answer": "E8 is the pay grade equivalent to First Sergeant in the United States Marine Corps.", "latency_ms": 396.40188217163086, "em": 0.0, "f1": 0.2666666666666667, "containment": 1.0, "context_chars": 3721}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 183.47620964050293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Richard Stallman", "latency_ms": 139.74261283874512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 697}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 78.81617546081543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1378}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 169.27814483642578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2056}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 117.20490455627441, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2701}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 129.2703151702881, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3340}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 133.96906852722168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3970}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 130.95760345458984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 209.76567268371582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 198.35400581359863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 127.05469131469727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 188.27056884765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Heena Sidhu", "latency_ms": 190.3989315032959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3058}, "6": {"k": 6, "answer": "Heena Sidhu", "latency_ms": 180.2980899810791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3706}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Chris Layton", "latency_ms": 78.7057876586914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 114.45736885070801, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 138.97705078125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 100.09598731994629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 121.20604515075684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2582}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 118.84760856628418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3242}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 123.80409240722656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3880}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 83.37211608886719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miami Heat", "latency_ms": 100.32510757446289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 631}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 95.44587135314941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 95.1681137084961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1849}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 230.424165725708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 197.0534324645996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3059}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 160.15386581420898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3656}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "Guarani", "latency_ms": 77.95476913452148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "guarani (PYG)", "latency_ms": 247.81084060668945, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "PYG", "latency_ms": 116.23072624206543, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "PYG", "latency_ms": 137.91251182556152, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "guaraní (PYG)", "latency_ms": 266.2796974182129, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2431}, "5": {"k": 5, "answer": "guaraní (PYG)", "latency_ms": 304.22401428222656, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3069}, "6": {"k": 6, "answer": "PYG", "latency_ms": 169.6183681488037, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3701}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "ketamine", "latency_ms": 121.94013595581055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "benzodiazepines", "latency_ms": 196.7751979827881, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 678}, "2": {"k": 2, "answer": "midazolam", "latency_ms": 155.51424026489258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1362}, "3": {"k": 3, "answer": "benzodiazepines", "latency_ms": 305.5419921875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2076}, "4": {"k": 4, "answer": "benzodiazepines", "latency_ms": 200.32668113708496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2758}, "5": {"k": 5, "answer": "benzodiazepines", "latency_ms": 189.11218643188477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3473}, "6": {"k": 6, "answer": "benzodiazepines", "latency_ms": 240.06366729736328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4153}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 252.5019645690918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "25,772 years", "latency_ms": 158.80250930786133, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "25,772 years", "latency_ms": 171.42033576965332, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1302}, "3": {"k": 3, "answer": "26,000 years", "latency_ms": 167.1886444091797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1930}, "4": {"k": 4, "answer": "25,772 years", "latency_ms": 236.8927001953125, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "25,772 years", "latency_ms": 254.63128089904785, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3183}, "6": {"k": 6, "answer": "26,000 years", "latency_ms": 318.164587020874, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3864}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 137.23206520080566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Texas A&M Aggies", "latency_ms": 149.89495277404785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Texas A&M", "latency_ms": 104.17032241821289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Texas A&M", "latency_ms": 112.69712448120117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Texas A&M", "latency_ms": 144.77300643920898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2541}, "5": {"k": 5, "answer": "Texas A&M", "latency_ms": 179.43811416625977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3161}, "6": {"k": 6, "answer": "Texas A&M", "latency_ms": 209.55467224121094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3878}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and non-renewable", "latency_ms": 354.0620803833008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable and non-renewable", "latency_ms": 354.62498664855957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable and non-renewable", "latency_ms": 490.33617973327637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1428}, "3": {"k": 3, "answer": "renewable and non-renewable", "latency_ms": 264.55235481262207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2178}, "4": {"k": 4, "answer": "renewable and non-renewable", "latency_ms": 333.7545394897461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2910}, "5": {"k": 5, "answer": "renewable and non-renewable", "latency_ms": 293.83349418640137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3588}, "6": {"k": 6, "answer": "renewable and non-renewable", "latency_ms": 310.0275993347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4288}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "Good luck and happiness", "latency_ms": 160.65502166748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "parental devotion", "latency_ms": 76.26914978027344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "filial piety", "latency_ms": 131.4718723297119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "filial piety and mercy", "latency_ms": 217.67926216125488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "purity and filial piety", "latency_ms": 203.9628028869629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2504}, "5": {"k": 5, "answer": "piety, filial devotion, purity, mercy, good fortune", "latency_ms": 445.6450939178467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3139}, "6": {"k": 6, "answer": "piety, filial values, mercy, purity", "latency_ms": 280.8542251586914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Rohit Sharma", "latency_ms": 103.19757461547852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 145.45512199401855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 117.62046813964844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 161.64422035217285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1887}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 124.3290901184082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 165.44485092163086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 193.99023056030273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3703}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.82516288757324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals in low concentrations", "latency_ms": 266.5727138519287, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 414.9947166442871, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 1412}, "3": {"k": 3, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 555.5779933929443, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 2103}, "4": {"k": 4, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 463.0916118621826, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 2841}, "5": {"k": 5, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 537.1842384338379, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 3568}, "6": {"k": 6, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 725.28076171875, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 4258}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 188.7819766998291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Coburn", "latency_ms": 109.65585708618164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "James Coburn", "latency_ms": 129.55737113952637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1294}, "3": {"k": 3, "answer": "Harold Van Venison", "latency_ms": 266.6323184967041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "Billy Bailey", "latency_ms": 114.41254615783691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Ronald Wolfe", "latency_ms": 189.6367073059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "James French", "latency_ms": 162.75668144226074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the opening lead and before the first trick is played.", "latency_ms": 597.31125831604, "em": 0.0, "f1": 0.15384615384615383, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the conclusion of play", "latency_ms": 190.06872177124023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 550}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 207.49425888061523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1122}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 264.7898197174072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1728}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 249.71652030944824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2310}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 175.39048194885254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2926}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 168.45273971557617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3511}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Sri Lanka", "latency_ms": 66.35737419128418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 111.01913452148438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Sri Lanka", "latency_ms": 116.04642868041992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1395}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 159.84249114990234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2124}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 163.45787048339844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2785}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 183.40325355529785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3509}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 143.95546913146973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4243}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.21695709228516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 110.77761650085449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 248.04139137268066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "hemostasis, inflammation, tissue growth", "latency_ms": 206.59780502319336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2082}, "4": {"k": 4, "answer": "hemostasis, fibrin formation, fibrin cross-linking", "latency_ms": 281.45408630371094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2807}, "5": {"k": 5, "answer": "hemostasis, fibrin formation, fibrinolysis", "latency_ms": 297.93548583984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3521}, "6": {"k": 6, "answer": "hemostasis, inflammation, tissue growth (proliferation), and tissue remodeling (maturation)", "latency_ms": 478.3487319946289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4173}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 125.7486343383789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 139.90187644958496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 161.8025302886963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1374}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 192.66462326049805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2068}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 151.3199806213379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2768}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 158.22434425354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3398}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 170.06897926330566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4044}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "1989", "latency_ms": 126.73425674438477, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "20 November 1989", "latency_ms": 263.44966888427734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 193.1600570678711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 242.98596382141113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1890}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 321.7461109161377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2551}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 237.23244667053223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 219.1476821899414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3861}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "2016", "latency_ms": 115.0662899017334, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "23 June 2016", "latency_ms": 247.36332893371582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "23 June 2016", "latency_ms": 232.62476921081543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1348}, "3": {"k": 3, "answer": "23 June 2016", "latency_ms": 184.9689483642578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2020}, "4": {"k": 4, "answer": "23 June 2016", "latency_ms": 302.166223526001, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2685}, "5": {"k": 5, "answer": "23 June 2016", "latency_ms": 435.7869625091553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3299}, "6": {"k": 6, "answer": "23 June 2016", "latency_ms": 335.3230953216553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3971}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 109.33113098144531, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Burj Khalifa", "latency_ms": 142.6863670349121, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 679}, "2": {"k": 2, "answer": "Burj Khalifa", "latency_ms": 168.11776161193848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1360}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 208.70661735534668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 226.92036628723145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2612}, "5": {"k": 5, "answer": "Burj Khalifa", "latency_ms": 167.5589084625244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3253}, "6": {"k": 6, "answer": "Burj Khalifa", "latency_ms": 242.0668601989746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3944}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 126.39713287353516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jenny Agutter", "latency_ms": 210.3879451751709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Linda Bassett", "latency_ms": 164.1833782196045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 178.4226894378662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 144.53673362731934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 159.0731143951416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3101}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 195.19567489624023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3767}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Montesquieu", "latency_ms": 154.85858917236328, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montesquieu", "latency_ms": 199.7818946838379, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 152.8012752532959, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 154.84881401062012, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2009}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 176.56540870666504, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2690}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 126.81102752685547, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3328}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 229.74419593811035, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3955}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Kyler Murray", "latency_ms": 159.25216674804688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sam Bradford", "latency_ms": 145.36643028259277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Sam Bradford", "latency_ms": 137.91155815124512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Myles Garrett", "latency_ms": 115.63420295715332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Myles Garrett", "latency_ms": 133.66055488586426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2507}, "5": {"k": 5, "answer": "Myles Garrett", "latency_ms": 137.96734809875488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3083}, "6": {"k": 6, "answer": "Myles Garrett", "latency_ms": 150.99549293518066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3743}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 173.93207550048828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2008 BS", "latency_ms": 203.1848430633545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "2008", "latency_ms": 138.09919357299805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "2006", "latency_ms": 232.18369483947754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "2006", "latency_ms": 167.2229766845703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2646}, "5": {"k": 5, "answer": "2006", "latency_ms": 156.41450881958008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3358}, "6": {"k": 6, "answer": "2006", "latency_ms": 159.16872024536133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4016}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 107.42926597595215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Smith", "latency_ms": 75.28448104858398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "John Smith", "latency_ms": 68.47548484802246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "John Smith", "latency_ms": 82.25321769714355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1951}, "4": {"k": 4, "answer": "John Smith", "latency_ms": 132.61723518371582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2627}, "5": {"k": 5, "answer": "John Smith", "latency_ms": 100.58808326721191, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3237}, "6": {"k": 6, "answer": "John Smith", "latency_ms": 155.40647506713867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3921}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 112.21456527709961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "parietal cells", "latency_ms": 131.5915584564209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 625}, "2": {"k": 2, "answer": "parietal cells", "latency_ms": 177.9496669769287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1291}, "3": {"k": 3, "answer": "parietal cells", "latency_ms": 126.66106224060059, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1878}, "4": {"k": 4, "answer": "parietal cells", "latency_ms": 140.53058624267578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2588}, "5": {"k": 5, "answer": "parietal cells", "latency_ms": 126.81818008422852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3257}, "6": {"k": 6, "answer": "parietal cells", "latency_ms": 131.27398490905762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3912}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "between 2 and 4 a.m.", "latency_ms": 212.5401496887207, "em": 0.0, "f1": 0.20000000000000004, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "two hours before the person normally wakes up", "latency_ms": 182.94405937194824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 709}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 91.27664566040039, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1372}, "3": {"k": 3, "answer": "two hours before waking up or around 4 a.m.", "latency_ms": 307.0666790008545, "em": 0.0, "f1": 0.14285714285714285, "containment": 0.0, "context_chars": 2012}, "4": {"k": 4, "answer": "two hours before waking up or around 4 a.m.", "latency_ms": 281.31723403930664, "em": 0.0, "f1": 0.14285714285714285, "containment": 0.0, "context_chars": 2676}, "5": {"k": 5, "answer": "two hours before waking up or around 4 a.m.", "latency_ms": 268.1128978729248, "em": 0.0, "f1": 0.14285714285714285, "containment": 0.0, "context_chars": 3360}, "6": {"k": 6, "answer": "two hours before waking up or around 4 a.m.", "latency_ms": 324.5258331298828, "em": 0.0, "f1": 0.14285714285714285, "containment": 0.0, "context_chars": 4081}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 70.89900970458984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nebraska", "latency_ms": 65.63496589660645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "Idaho", "latency_ms": 85.77251434326172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Idaho", "latency_ms": 101.39298439025879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Idaho", "latency_ms": 90.92259407043457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2603}, "5": {"k": 5, "answer": "Idaho", "latency_ms": 125.72479248046875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3262}, "6": {"k": 6, "answer": "Idaho", "latency_ms": 149.9037742614746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "1. The Curse of the Black Pearl  \n2. Dead Man's Chest  \n3. At World's End  \n4. On Stranger Tides  \n5. Pirates of the Caribbean: Dead Men Tell No Tales", "latency_ms": 947.1750259399414, "em": 0.0, "f1": 0.32258064516129037, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1. The Curse of the Black Pearl (2003)  \n2. At World's End (2007)  \n3. Dead Man's Chest (2006)  \n4. On Stranger Tides (2011)  \n5. Dead Men Tell No Tales (2017)  \n6. (in development, 2018)", "latency_ms": 2281.672477722168, "em": 0.0, "f1": 0.2702702702702703, "containment": 1.0, "context_chars": 667}, "2": {"k": 2, "answer": "1. The Curse of the Black Pearl (2003)  \n2. Dead Man's Chest (2006)  \n3. At World's End (2007)  \n4. On Stranger Tides (2011)  \n5. Dead Men Tell No Tales (2017)  \n6. (upcoming)", "latency_ms": 1634.7405910491943, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "1. The Curse of the Black Pearl (2003)  \n2. Dead Man's Chest (2006)  \n3. At World's End (2007)  \n4. On Stranger Tides (2011)  \n5. Dead Men Tell No Tales (2017)  \n6. (in development)", "latency_ms": 2043.2541370391846, "em": 0.0, "f1": 0.27777777777777773, "containment": 1.0, "context_chars": 1969}, "4": {"k": 4, "answer": "1. The Curse of the Black Pearl  \n2. Dead Man's Chest  \n3. At World's End  \n4. On Stranger Tides  \n5. Dead Men Tell No Tales", "latency_ms": 1250.2682209014893, "em": 0.0, "f1": 0.3571428571428571, "containment": 1.0, "context_chars": 2645}, "5": {"k": 5, "answer": "1. The Curse of the Black Pearl (2003)  \n2. Pirates of the Caribbean: Dead Man's Chest (2006)  \n3. Pirates of the Caribbean: At World's End (2007)  \n4. Pirates of the Caribbean: On Stranger Tides (2011)  \n5. Pirates of the Caribbean: Dead Men Tell No Tales (2017)", "latency_ms": 2584.5797061920166, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3306}, "6": {"k": 6, "answer": "1. The Curse of the Black Pearl (2003)  \n2. Dead Man's Chest (2006)  \n3. At World's End (2007)  \n4. On Stranger Tides (2011)  \n5. Dead Men Tell No Tales (2017)  \n6. (in development, 2018)", "latency_ms": 2155.2748680114746, "em": 0.0, "f1": 0.2702702702702703, "containment": 1.0, "context_chars": 3991}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 66.5445327758789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "progressive tonality", "latency_ms": 90.42906761169434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 691}, "2": {"k": 2, "answer": "modulated", "latency_ms": 135.82491874694824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1303}, "3": {"k": 3, "answer": "modulated", "latency_ms": 82.28063583374023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "modulated", "latency_ms": 133.636474609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "modulated", "latency_ms": 103.28388214111328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3201}, "6": {"k": 6, "answer": "modulated", "latency_ms": 118.89266967773438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3846}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Roman citizens of certain property thresholds", "latency_ms": 139.07241821289062, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Full Roman citizens (excluding women, slaves, and originally those living outside of Rome)", "latency_ms": 592.1692848205566, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 637}, "2": {"k": 2, "answer": "Full Roman citizens (excluding women, slaves, and originally those living outside of Rome)", "latency_ms": 579.9200534820557, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 1296}, "3": {"k": 3, "answer": "Full Roman citizens (excluding women, slaves, and those living outside Rome)", "latency_ms": 583.5974216461182, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 1941}, "4": {"k": 4, "answer": "Men who were citizens and owned a certain amount of real property", "latency_ms": 428.7383556365967, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 2598}, "5": {"k": 5, "answer": "adult male citizens who owned a certain amount of real property", "latency_ms": 335.0484371185303, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 3278}, "6": {"k": 6, "answer": "adult male citizens who owned a certain amount of real property", "latency_ms": 373.14605712890625, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 3977}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 130.55872917175293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 170.4113483428955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 130.22518157958984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 142.76528358459473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1925}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 148.21386337280273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2611}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 164.7777557373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3253}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 160.08710861206055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3894}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "blood volume", "latency_ms": 102.74481773376465, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "blood volume", "latency_ms": 57.84416198730469, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "volume of blood", "latency_ms": 78.58777046203613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1302}, "3": {"k": 3, "answer": "volume of blood", "latency_ms": 164.92962837219238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "volume of blood", "latency_ms": 145.82538604736328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2563}, "5": {"k": 5, "answer": "volume of blood", "latency_ms": 154.160737991333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3260}, "6": {"k": 6, "answer": "volume of blood", "latency_ms": 146.61335945129395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3981}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "Hephaestus", "latency_ms": 143.9211368560791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Icarus", "latency_ms": 108.80088806152344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 587}, "2": {"k": 2, "answer": "Icarus", "latency_ms": 82.45253562927246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "Icarus", "latency_ms": 117.22135543823242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Icarus", "latency_ms": 210.13998985290527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2411}, "5": {"k": 5, "answer": "Phaëton", "latency_ms": 178.34949493408203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3008}, "6": {"k": 6, "answer": "Phaëton", "latency_ms": 184.79084968566895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3645}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "1979", "latency_ms": 211.4272117614746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 16, 1979", "latency_ms": 227.5540828704834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "September 16, 1979", "latency_ms": 292.24133491516113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "September 16, 1979", "latency_ms": 383.4254741668701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1782}, "4": {"k": 4, "answer": "September 16, 1979", "latency_ms": 330.0671577453613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2363}, "5": {"k": 5, "answer": "September 16, 1979", "latency_ms": 548.0446815490723, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2958}, "6": {"k": 6, "answer": "September 16, 1979", "latency_ms": 291.4693355560303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3587}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 AM Hong Kong Time", "latency_ms": 211.56764030456543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 158.57887268066406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "2 April 1986", "latency_ms": 252.73919105529785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1296}, "3": {"k": 3, "answer": "2 April 1986", "latency_ms": 241.09411239624023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "2 April 1986", "latency_ms": 249.284029006958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2588}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 189.57018852233887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 188.45438957214355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3825}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 125.91218948364258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiffany Coyne", "latency_ms": 164.86215591430664, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "Tiffany Coyne", "latency_ms": 207.61966705322266, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1160}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 141.44539833068848, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1744}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 148.90241622924805, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2372}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 180.558443069458, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2986}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 186.8600845336914, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3619}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 98.71530532836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 433.8662624359131, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 498.9633560180664, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 428.0431270599365, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1853}, "4": {"k": 4, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 572.3233222961426, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 383.95118713378906, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3099}, "6": {"k": 6, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 640.2227878570557, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3813}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 165.36307334899902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "over $1.84 billion", "latency_ms": 213.64712715148926, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "over $1.84 billion worldwide initially; over $2 billion in total with 3D re-release", "latency_ms": 783.4086418151855, "em": 0.0, "f1": 0.13333333333333336, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "over $1.84 billion initially; $343.4 million from 3D re-release worldwide", "latency_ms": 697.446346282959, "em": 0.0, "f1": 0.16666666666666669, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "over $1.84 billion initially; more than $2 billion in total with 3D re-release", "latency_ms": 722.9964733123779, "em": 0.0, "f1": 0.13333333333333336, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "over $1.84 billion initially; more than $2 billion in total with 3D re-release", "latency_ms": 673.668384552002, "em": 0.0, "f1": 0.13333333333333336, "containment": 0.0, "context_chars": 3247}, "6": {"k": 6, "answer": "over $1.84 billion worldwide initially; more than $2 billion worldwide during its 3D re-release", "latency_ms": 594.2163467407227, "em": 0.0, "f1": 0.125, "containment": 0.0, "context_chars": 3890}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 130.68509101867676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 150.39348602294922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 231.88352584838867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1304}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 127.44474411010742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1899}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 135.99514961242676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2519}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 174.68953132629395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3152}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 230.03697395324707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark/Norway", "latency_ms": 158.1106185913086, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Denmark", "latency_ms": 97.37634658813477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Norway", "latency_ms": 106.92286491394043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Germany", "latency_ms": 72.16668128967285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "The context does not provide information on the origin of the last name Hansen. I cannot answer.", "latency_ms": 496.143102645874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2559}, "5": {"k": 5, "answer": "The context does not specify the origin of the last name Hansen. I cannot answer.", "latency_ms": 574.7835636138916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "Danish", "latency_ms": 187.15405464172363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3813}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 116.80436134338379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "oplatek", "latency_ms": 107.03206062316895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "Christmas tree", "latency_ms": 85.12425422668457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Christmas tree", "latency_ms": 135.61105728149414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Christmas tree", "latency_ms": 136.3823413848877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Christmas tree", "latency_ms": 155.8852195739746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3193}, "6": {"k": 6, "answer": "Christmas tree", "latency_ms": 184.91840362548828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3790}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 97.52774238586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Swayze", "latency_ms": 109.4355583190918, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Swayze", "latency_ms": 113.2347583770752, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Swayze", "latency_ms": 95.19481658935547, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Swayze", "latency_ms": 212.93878555297852, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Swayze", "latency_ms": 115.2033805847168, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Swayze", "latency_ms": 229.4178009033203, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3767}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Rhode Island", "latency_ms": 132.36141204833984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 123.93975257873535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 744}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 133.83030891418457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1438}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 149.18184280395508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2130}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 176.72276496887207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2735}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 192.19303131103516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3461}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 221.13966941833496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4132}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1801", "latency_ms": 188.89498710632324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1624", "latency_ms": 144.0114974975586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 655}, "2": {"k": 2, "answer": "1624", "latency_ms": 149.46222305297852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1314}, "3": {"k": 3, "answer": "1905", "latency_ms": 146.38042449951172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2009}, "4": {"k": 4, "answer": "1905", "latency_ms": 144.6516513824463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2706}, "5": {"k": 5, "answer": "1905", "latency_ms": 187.11614608764648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3428}, "6": {"k": 6, "answer": "1905", "latency_ms": 223.01626205444336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4096}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier Fernández", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 186.2204074859619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yuzuru Hanyu", "latency_ms": 284.2731475830078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Yuzuru Hanyu", "latency_ms": 159.17372703552246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Yuzuru Hanyu", "latency_ms": 252.98714637756348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Yuzuru Hanyu", "latency_ms": 234.1482639312744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2607}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 290.45891761779785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3275}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 170.64738273620605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3956}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 130.97143173217773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "password recovery", "latency_ms": 63.329219818115234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "password recovery", "latency_ms": 70.34945487976074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1391}, "3": {"k": 3, "answer": "password recovery", "latency_ms": 148.08917045593262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2034}, "4": {"k": 4, "answer": "password recovery", "latency_ms": 86.98654174804688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2714}, "5": {"k": 5, "answer": "password recovery for Microsoft Windows", "latency_ms": 180.29308319091797, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3379}, "6": {"k": 6, "answer": "password recovery for Microsoft Windows", "latency_ms": 170.84407806396484, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3964}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "Eknath Shinde", "latency_ms": 108.42370986938477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "C. Vidyasagar Rao", "latency_ms": 152.15468406677246, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "C. Vidyasagar Rao", "latency_ms": 210.75177192687988, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "Ch. Vidyasagar Rao", "latency_ms": 263.23390007019043, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2058}, "4": {"k": 4, "answer": "Ch. Vidyasagar Rao", "latency_ms": 239.84670639038086, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2686}, "5": {"k": 5, "answer": "Ch. Vidyasagar Rao", "latency_ms": 231.56142234802246, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3326}, "6": {"k": 6, "answer": "Ch. Vidyasagar Rao", "latency_ms": 253.56340408325195, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3955}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 92.18311309814453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "15", "latency_ms": 117.94614791870117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 682}, "2": {"k": 2, "answer": "15", "latency_ms": 110.3982925415039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "KNXV-TV", "latency_ms": 135.87617874145508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "KNXV-TV", "latency_ms": 126.71160697937012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2486}, "5": {"k": 5, "answer": "15", "latency_ms": 103.61719131469727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3118}, "6": {"k": 6, "answer": "KNXV 15", "latency_ms": 219.54917907714844, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3738}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Michael J. Fox", "latency_ms": 79.18500900268555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Claudia Wells", "latency_ms": 84.99908447265625, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Claudia Wells", "latency_ms": 143.56660842895508, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1207}, "3": {"k": 3, "answer": "Claudia Wells", "latency_ms": 108.1387996673584, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 113.05880546569824, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2477}, "5": {"k": 5, "answer": "Claudia Wells", "latency_ms": 127.8839111328125, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "Claudia Wells", "latency_ms": 131.41226768493652, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3693}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 40.8780574798584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "London, United Kingdom", "latency_ms": 115.3709888458252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 108.86454582214355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 108.23297500610352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1913}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 114.85409736633301, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2585}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 130.56111335754395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 143.43500137329102, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3847}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The president's chef", "latency_ms": 144.7732448577881, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "White House Executive Chef", "latency_ms": 85.03341674804688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "White House Executive Chef", "latency_ms": 96.98033332824707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "White House Executive Chef", "latency_ms": 108.64138603210449, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2038}, "4": {"k": 4, "answer": "White House Executive Chef", "latency_ms": 113.17753791809082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2650}, "5": {"k": 5, "answer": "White House Executive Chef", "latency_ms": 128.0357837677002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3311}, "6": {"k": 6, "answer": "White House Executive Chef", "latency_ms": 199.95832443237305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3974}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.77168464660645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 91.23516082763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 98.50120544433594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "B. N. Rao", "latency_ms": 122.3611831665039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1818}, "4": {"k": 4, "answer": "B. N. Rao", "latency_ms": 144.4857120513916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "B. N. Rao", "latency_ms": 189.35298919677734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3111}, "6": {"k": 6, "answer": "B. N. Rao", "latency_ms": 207.8683376312256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 90.40951728820801, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "British Columbia", "latency_ms": 104.92467880249023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "British Columbia", "latency_ms": 103.45244407653809, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "British Columbia", "latency_ms": 103.1494140625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1960}, "4": {"k": 4, "answer": "British Columbia", "latency_ms": 126.31988525390625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "British Columbia", "latency_ms": 128.23987007141113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3229}, "6": {"k": 6, "answer": "British Columbia", "latency_ms": 134.68337059020996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3910}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 83.24337005615234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 11, 2018", "latency_ms": 278.42235565185547, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "October 11, 2018", "latency_ms": 271.75402641296387, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 260.35499572753906, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 265.23542404174805, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 311.5262985229492, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3267}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 298.71249198913574, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3912}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Dana Delany", "latency_ms": 173.5224723815918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 143.9807415008545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 159.21521186828613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 112.58745193481445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 132.61795043945312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 176.33652687072754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3179}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 212.87083625793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3852}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 173.0501651763916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Millennium Tower", "latency_ms": 193.6337947845459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 225.25453567504883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 179.64625358581543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 146.4996337890625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2661}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 167.98830032348633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3357}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 193.11976432800293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4043}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 227.98871994018555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 221.36616706848145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "2014", "latency_ms": 148.10776710510254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1234}, "3": {"k": 3, "answer": "2015", "latency_ms": 122.96485900878906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "2014", "latency_ms": 211.61389350891113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2535}, "5": {"k": 5, "answer": "2014", "latency_ms": 130.781888961792, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3149}, "6": {"k": 6, "answer": "2014", "latency_ms": 205.79791069030762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3807}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "T.S. Eliot", "latency_ms": 145.15280723571777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Marshall Harlan", "latency_ms": 100.14772415161133, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "John Marshall Harlan", "latency_ms": 168.10321807861328, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1390}, "3": {"k": 3, "answer": "John Marshall Harlan", "latency_ms": 170.88842391967773, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2069}, "4": {"k": 4, "answer": "John Marshall Harlan II", "latency_ms": 210.86716651916504, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2750}, "5": {"k": 5, "answer": "John Marshall Harlan II", "latency_ms": 164.9630069732666, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3453}, "6": {"k": 6, "answer": "John Marshall Harlan II", "latency_ms": 190.95945358276367, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4112}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Chris Berman", "latency_ms": 66.92767143249512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tyrann Mathieu", "latency_ms": 138.9636993408203, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 162.04118728637695, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 188.76051902770996, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 206.51555061340332, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2568}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 242.09833145141602, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3181}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 266.2045955657959, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3816}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 143.08810234069824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "6", "latency_ms": 67.7804946899414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "6", "latency_ms": 69.81921195983887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "6", "latency_ms": 155.45201301574707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2042}, "4": {"k": 4, "answer": "6", "latency_ms": 141.80517196655273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2715}, "5": {"k": 5, "answer": "6", "latency_ms": 139.10388946533203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3373}, "6": {"k": 6, "answer": "6", "latency_ms": 169.89827156066895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4016}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul Baumer's", "latency_ms": 177.3970127105713, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "German perspective", "latency_ms": 94.42543983459473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "German perspective", "latency_ms": 135.206937789917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "German infantryman", "latency_ms": 235.17251014709473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "German infantryman's perspective", "latency_ms": 247.7250099182129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "German infantryman's perspective", "latency_ms": 274.2288112640381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "German infantryman", "latency_ms": 267.08102226257324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3798}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris and the Anglin brothers", "latency_ms": 334.40256118774414, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 266.3133144378662, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 320.09124755859375, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1347}, "3": {"k": 3, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 313.37451934814453, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1986}, "4": {"k": 4, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 327.53562927246094, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 329.4055461883545, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3244}, "6": {"k": 6, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 367.9192066192627, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3898}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF", "latency_ms": 82.69405364990234, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF's global programming and domestic causes like Hurricane Katrina victims", "latency_ms": 424.4043827056885, "em": 0.0, "f1": 0.14285714285714288, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "UNICEF's global programming, including domestic causes like Hurricane Katrina aid and therapeutic food for malnourished children.", "latency_ms": 728.9032936096191, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 1350}, "3": {"k": 3, "answer": "UNICEF's global programming, including domestic causes like Hurricane Katrina aid and therapeutic food for malnourished children.", "latency_ms": 830.8839797973633, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 2070}, "4": {"k": 4, "answer": "UNICEF's global programming, including domestic causes like Hurricane Katrina aid and therapeutic food for malnourished children.", "latency_ms": 711.693286895752, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 2800}, "5": {"k": 5, "answer": "UNICEF's global programming, including domestic causes like Hurricane Katrina victims and therapeutic food for severely malnourished children.", "latency_ms": 727.5326251983643, "em": 0.0, "f1": 0.09523809523809523, "containment": 0.0, "context_chars": 3488}, "6": {"k": 6, "answer": "UNICEF's global programming, including domestic causes like Hurricane Katrina aid and therapeutic food for severely malnourished children worldwide.", "latency_ms": 827.1420001983643, "em": 0.0, "f1": 0.0909090909090909, "containment": 0.0, "context_chars": 4114}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Statue of Liberty's inscription is on the pedestal.", "latency_ms": 357.03325271606445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Base", "latency_ms": 77.54325866699219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 128.77321243286133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "base of the Statue of Liberty", "latency_ms": 312.1621608734131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "on the base of the Statue of Liberty", "latency_ms": 279.7119617462158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2578}, "5": {"k": 5, "answer": "on the base of the Statue of Liberty", "latency_ms": 308.9122772216797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "on the base of the Statue of Liberty", "latency_ms": 286.96298599243164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3899}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 159.28030014038086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 187.44969367980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Beijing and Hebei province, China", "latency_ms": 261.87849044799805, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Beijing 2022, then next after that is not specified in context. I cannot answer.", "latency_ms": 738.2230758666992, "em": 0.0, "f1": 0.13333333333333333, "containment": 1.0, "context_chars": 1823}, "4": {"k": 4, "answer": "Beijing 2022, then next after that is not specified in context. I cannot answer.", "latency_ms": 753.9007663726807, "em": 0.0, "f1": 0.13333333333333333, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Beijing 2022, then next after that is not specified in context. I cannot answer.", "latency_ms": 761.4433765411377, "em": 0.0, "f1": 0.13333333333333333, "containment": 1.0, "context_chars": 3180}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 248.41570854187012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3852}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "1994", "latency_ms": 103.87444496154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 124.9537467956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "1997", "latency_ms": 150.4650115966797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "1997", "latency_ms": 159.4870090484619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "1997", "latency_ms": 160.91418266296387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "1997", "latency_ms": 168.9169406890869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": "1997", "latency_ms": 260.3473663330078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3859}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "stone arch bridge", "latency_ms": 99.96390342712402, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "single-leaf, through-truss, rolling bascule bridge", "latency_ms": 398.2505798339844, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "single-leaf, through-truss, rolling bascule bridges", "latency_ms": 405.9128761291504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1379}, "3": {"k": 3, "answer": "pair of railroad single-leaf, through-truss, rolling bascule bridges", "latency_ms": 514.62721824646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2038}, "4": {"k": 4, "answer": "historic bridge", "latency_ms": 167.86479949951172, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2671}, "5": {"k": 5, "answer": "historic bridge", "latency_ms": 118.57008934020996, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3308}, "6": {"k": 6, "answer": "stone bridge", "latency_ms": 160.92181205749512, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3975}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The ruler or leader", "latency_ms": 198.26865196228027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "one person", "latency_ms": 100.34966468811035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "one person", "latency_ms": 129.25243377685547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1345}, "3": {"k": 3, "answer": "one person", "latency_ms": 121.72341346740723, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2018}, "4": {"k": 4, "answer": "one person", "latency_ms": 115.46564102172852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2672}, "5": {"k": 5, "answer": "one person", "latency_ms": 142.19999313354492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3336}, "6": {"k": 6, "answer": "one person", "latency_ms": 115.87667465209961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4005}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 180.27234077453613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "affluence and pride in private property", "latency_ms": 304.3196201324463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 726}, "2": {"k": 2, "answer": "pride in affluence and proprietary attitude toward lawns", "latency_ms": 357.32555389404297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1399}, "3": {"k": 3, "answer": "other-directedness", "latency_ms": 161.0558032989502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2115}, "4": {"k": 4, "answer": "other-directedness", "latency_ms": 125.56886672973633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2743}, "5": {"k": 5, "answer": "other-directedness", "latency_ms": 125.43392181396484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3483}, "6": {"k": 6, "answer": "other-directedness", "latency_ms": 133.66937637329102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4192}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "counterclockwise", "latency_ms": 123.58903884887695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "counterclockwise", "latency_ms": 124.298095703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "counterclockwise", "latency_ms": 162.17589378356934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "counterclockwise", "latency_ms": 141.68334007263184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1770}, "4": {"k": 4, "answer": "counterclockwise", "latency_ms": 232.30481147766113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2344}, "5": {"k": 5, "answer": "counterclockwise", "latency_ms": 160.37726402282715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3019}, "6": {"k": 6, "answer": "counterclockwise", "latency_ms": 169.5876121520996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3590}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Dome", "latency_ms": 88.75274658203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "dome", "latency_ms": 79.57839965820312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Statue of Freedom", "latency_ms": 124.46045875549316, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1177}, "3": {"k": 3, "answer": "Statue of Freedom", "latency_ms": 159.35921669006348, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "Statue of Freedom", "latency_ms": 112.04791069030762, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2367}, "5": {"k": 5, "answer": "Statue of Freedom", "latency_ms": 181.82611465454102, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3022}, "6": {"k": 6, "answer": "Statue of Freedom", "latency_ms": 161.28873825073242, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3682}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 178.09438705444336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 142.7779197692871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "Washington Wizards", "latency_ms": 132.35068321228027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Washington Wizards", "latency_ms": 163.2378101348877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Washington Wizards", "latency_ms": 88.67287635803223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2454}, "5": {"k": 5, "answer": "Washington Wizards", "latency_ms": 125.79512596130371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Washington Wizards", "latency_ms": 132.9023838043213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3773}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 142.87066459655762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chris Benoit", "latency_ms": 118.67928504943848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "Daniel Bryan", "latency_ms": 71.0759162902832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Rey Mysterio", "latency_ms": 190.0308132171631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Rey Mysterio", "latency_ms": 225.2213954925537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2491}, "5": {"k": 5, "answer": "Rey Mysterio", "latency_ms": 257.30013847351074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Rey Mysterio", "latency_ms": 246.0474967956543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3729}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 160.92157363891602, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake of the Ozarks", "latency_ms": 239.25042152404785, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Lake Mead", "latency_ms": 96.52590751647949, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Lake Mead", "latency_ms": 172.4991798400879, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "Lake Mead", "latency_ms": 171.64945602416992, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2438}, "5": {"k": 5, "answer": "Lake Mead", "latency_ms": 121.3076114654541, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3122}, "6": {"k": 6, "answer": "Lake Mead", "latency_ms": 182.70206451416016, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3705}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Gabbar Is Back", "latency_ms": 174.6370792388916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 182.87277221679688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "Tagore", "latency_ms": 191.4350986480713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tagore", "latency_ms": 117.21134185791016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "Tagore", "latency_ms": 119.66514587402344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Tagore", "latency_ms": 119.80438232421875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3134}, "6": {"k": 6, "answer": "Tagore", "latency_ms": 167.10829734802246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3767}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "John Baker", "latency_ms": 88.7141227722168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "George H.W. Bush", "latency_ms": 165.76647758483887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 737}, "2": {"k": 2, "answer": "Geraldine Ferraro", "latency_ms": 177.20580101013184, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1452}, "3": {"k": 3, "answer": "Geraldine Ferraro", "latency_ms": 302.25086212158203, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2141}, "4": {"k": 4, "answer": "Geraldine Ferraro", "latency_ms": 206.07948303222656, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2825}, "5": {"k": 5, "answer": "Geraldine Ferraro", "latency_ms": 287.31608390808105, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3549}, "6": {"k": 6, "answer": "Geraldine Ferraro", "latency_ms": 426.3913631439209, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4311}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "Utah", "latency_ms": 60.04047393798828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Town of Groveland", "latency_ms": 269.3319320678711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners, Town of Groveland", "latency_ms": 387.7110481262207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1263}, "3": {"k": 3, "answer": "Hampton Corners, New York", "latency_ms": 302.1993637084961, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Hampton Corners, New York", "latency_ms": 269.85788345336914, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "Hampton Corners, New York", "latency_ms": 345.4420566558838, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Hampton Corners, New York", "latency_ms": 339.2190933227539, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3842}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 68.49074363708496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 87.5847339630127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 83.15730094909668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 103.4386157989502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 175.1115322113037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2469}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 111.84310913085938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3106}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 174.02052879333496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3673}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Uttar Pradesh", "latency_ms": 128.70478630065918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Meghalaya", "latency_ms": 147.77755737304688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Meghalaya", "latency_ms": 179.20517921447754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Meghalaya", "latency_ms": 116.30964279174805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1953}, "4": {"k": 4, "answer": "Nagaland", "latency_ms": 163.19727897644043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2522}, "5": {"k": 5, "answer": "Nagaland", "latency_ms": 196.28167152404785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "Nagaland", "latency_ms": 227.0658016204834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3848}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Lucknow", "latency_ms": 159.86180305480957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kanpur", "latency_ms": 138.13281059265137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Kanpur", "latency_ms": 134.0336799621582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Kanpur", "latency_ms": 177.61564254760742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1824}, "4": {"k": 4, "answer": "Kanpur", "latency_ms": 132.33470916748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2472}, "5": {"k": 5, "answer": "Kanpur", "latency_ms": 135.91909408569336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3053}, "6": {"k": 6, "answer": "Kanpur", "latency_ms": 145.0514793395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
