{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Rita Skeeter", "latency_ms": 87.08453178405762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 111.12833023071289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 128.65018844604492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 143.94044876098633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1956}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 163.18988800048828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2588}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 183.61902236938477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 143.30196380615234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3824}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 90.82174301147461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 112.30707168579102, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 139.90545272827148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 156.83531761169434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 179.55589294433594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2597}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 188.2479190826416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3219}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 143.6171531677246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3892}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwestern United States and Mexico", "latency_ms": 145.4944610595703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 243.44372749328613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 291.29481315612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 259.72914695739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 287.7969741821289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 354.30073738098145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 278.0613899230957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3932}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 151.19624137878418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dr. Rajendra Prasad", "latency_ms": 231.45747184753418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 743}, "2": {"k": 2, "answer": "Dr. Rajendra Prasad", "latency_ms": 201.30038261413574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1429}, "3": {"k": 3, "answer": "Dr. Rajendra Prasad", "latency_ms": 178.93481254577637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2125}, "4": {"k": 4, "answer": "Dr. Rajendra Prasad", "latency_ms": 172.99556732177734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2814}, "5": {"k": 5, "answer": "Dr. Rajendra Prasad", "latency_ms": 249.66120719909668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3509}, "6": {"k": 6, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 293.2255268096924, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4207}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 100.91447830200195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 96.82798385620117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 126.89614295959473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 107.85579681396484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 157.09686279296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 170.3791618347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3179}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 186.09118461608887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3861}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "2001", "latency_ms": 140.58208465576172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2001", "latency_ms": 89.42818641662598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "2001", "latency_ms": 96.50325775146484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "2001", "latency_ms": 124.78923797607422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1878}, "4": {"k": 4, "answer": "2001", "latency_ms": 141.30926132202148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2536}, "5": {"k": 5, "answer": "June 22, 2001", "latency_ms": 282.6976776123047, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3180}, "6": {"k": 6, "answer": "June 22, 2001", "latency_ms": 341.45498275756836, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3795}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 102.70118713378906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wednesday at 8:00 PM", "latency_ms": 215.7728672027588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 146.53301239013672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 173.2032299041748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 195.05739212036133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2705}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 148.45013618469238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3344}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 144.81258392333984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4040}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.01477813720703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "February 14, 2013", "latency_ms": 166.84198379516602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "February 14, 2013", "latency_ms": 173.88439178466797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "February 14, 2013", "latency_ms": 207.54480361938477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "February 14, 2013", "latency_ms": 278.6421775817871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2648}, "5": {"k": 5, "answer": "January 17, 2012", "latency_ms": 257.77363777160645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3314}, "6": {"k": 6, "answer": "January 17, 2012", "latency_ms": 221.3432788848877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3975}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 78.82928848266602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 92.37432479858398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.53759002685547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.5653305053711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 126.43122673034668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 129.96864318847656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3115}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 144.10138130187988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3815}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana, Cuba", "latency_ms": 79.81371879577637, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Havana harbor, Cuba", "latency_ms": 102.84066200256348, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "Havana Harbor, Cuba", "latency_ms": 109.05909538269043, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Havana Harbor, Cuba", "latency_ms": 120.74017524719238, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1910}, "4": {"k": 4, "answer": "Havana Harbor, Cuba", "latency_ms": 190.35768508911133, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2533}, "5": {"k": 5, "answer": "Havana Harbor, Cuba", "latency_ms": 140.82050323486328, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3164}, "6": {"k": 6, "answer": "Havana Harbor, Cuba", "latency_ms": 144.40655708312988, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3769}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Shiva", "latency_ms": 53.26247215270996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.54119682312012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "Jainism", "latency_ms": 83.40239524841309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1280}, "3": {"k": 3, "answer": "Lord Vasupujya", "latency_ms": 182.40880966186523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1942}, "4": {"k": 4, "answer": "Lord Vasupujya", "latency_ms": 139.70398902893066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Ganesha", "latency_ms": 128.82089614868164, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3221}, "6": {"k": 6, "answer": "Ganesha", "latency_ms": 133.20231437683105, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3870}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Belize, Guatemala, Honduras, Nicaragua, Costa Rica", "latency_ms": 170.9740161895752, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Belize, Guatemala, Honduras, Nicaragua, Panama", "latency_ms": 167.30284690856934, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Belize, Guatemala, Honduras, Nicaragua, Panama", "latency_ms": 174.70812797546387, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1294}, "3": {"k": 3, "answer": "Belize, Guatemala, Honduras, Nicaragua, Panama", "latency_ms": 203.28569412231445, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1901}, "4": {"k": 4, "answer": "Belize, Guatemala, Honduras, Nicaragua, Panama", "latency_ms": 323.7330913543701, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2494}, "5": {"k": 5, "answer": "Belize, Guatemala, Honduras, Nicaragua, Panama", "latency_ms": 355.1340103149414, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Belize, Guatemala, Honduras, Nicaragua, Panama", "latency_ms": 269.00172233581543, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3823}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "compound-complex sentence", "latency_ms": 137.71319389343262, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "complex sentence", "latency_ms": 68.35579872131348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "complex sentence", "latency_ms": 117.20705032348633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1350}, "3": {"k": 3, "answer": "complex sentence", "latency_ms": 150.6519317626953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2037}, "4": {"k": 4, "answer": "complex sentence", "latency_ms": 101.53579711914062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2743}, "5": {"k": 5, "answer": "complex sentence", "latency_ms": 115.63897132873535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3425}, "6": {"k": 6, "answer": "complex sentence", "latency_ms": 102.5245189666748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4084}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "economic systems and trade principles", "latency_ms": 127.23088264465332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The division of labour, productivity, and free markets", "latency_ms": 272.0510959625244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "The Wealth of Nations was about the nature and causes of the wealth of nations, including division of labour, productivity, and free markets.", "latency_ms": 733.1392765045166, "em": 0.0, "f1": 0.16666666666666669, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of national wealth, including the division of labor, productivity, and free markets.", "latency_ms": 699.981689453125, "em": 0.0, "f1": 0.16666666666666669, "containment": 0.0, "context_chars": 2000}, "4": {"k": 4, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of national wealth, including the division of labor, productivity, and free markets.", "latency_ms": 705.0333023071289, "em": 0.0, "f1": 0.16666666666666669, "containment": 0.0, "context_chars": 2681}, "5": {"k": 5, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of national wealth, including the division of labor, productivity, free markets, and the three factors of production: land, labor, and capital.", "latency_ms": 1009.9577903747559, "em": 0.0, "f1": 0.125, "containment": 0.0, "context_chars": 3408}, "6": {"k": 6, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of national wealth, including the division of labor, productivity, free markets, and the three factors of production: land, labor, and capital.", "latency_ms": 1077.7735710144043, "em": 0.0, "f1": 0.125, "containment": 0.0, "context_chars": 4069}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 96.13633155822754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 10, 2017", "latency_ms": 305.3703308105469, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "October 10, 2017", "latency_ms": 239.00818824768066, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 272.88007736206055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "August 23, 2018", "latency_ms": 248.36468696594238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2494}, "5": {"k": 5, "answer": "August 23, 2018", "latency_ms": 276.5040397644043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3109}, "6": {"k": 6, "answer": "August 23, 2018", "latency_ms": 301.868200302124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Southern Hemisphere, Eastern Hemisphere, Oceania region", "latency_ms": 239.66193199157715, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Oceania", "latency_ms": 88.18864822387695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "Southern Hemisphere, Eastern Hemisphere, Oceania region", "latency_ms": 230.03602027893066, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "southern hemisphere, Eastern Hemisphere, Oceania", "latency_ms": 287.4586582183838, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1907}, "4": {"k": 4, "answer": "southern hemisphere, eastern hemisphere, Oceania region", "latency_ms": 351.6039848327637, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 2616}, "5": {"k": 5, "answer": "Southern Hemisphere, Eastern Hemisphere, Oceania region", "latency_ms": 265.52343368530273, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 3248}, "6": {"k": 6, "answer": "Southern Hemisphere, Eastern Hemisphere, Oceania region", "latency_ms": 306.2441349029541, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 3956}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Padmé Amidala", "latency_ms": 145.9503173828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 162.50872611999512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "Leia", "latency_ms": 81.26521110534668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "Princess Leia", "latency_ms": 118.08228492736816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1785}, "4": {"k": 4, "answer": "Leia Organa", "latency_ms": 111.87052726745605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2382}, "5": {"k": 5, "answer": "Princess Leia", "latency_ms": 129.22072410583496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2994}, "6": {"k": 6, "answer": "Callista", "latency_ms": 104.19845581054688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3614}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Ralph Edwards", "latency_ms": 120.00870704650879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Allen Ludden", "latency_ms": 115.3266429901123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "Allen Ludden", "latency_ms": 102.45060920715332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Barry Cryer", "latency_ms": 177.42443084716797, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "Barry Cryer", "latency_ms": 130.65266609191895, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2471}, "5": {"k": 5, "answer": "Barry Cryer", "latency_ms": 142.55213737487793, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3021}, "6": {"k": 6, "answer": "Barry Cryer", "latency_ms": 158.2772731781006, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3654}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "mitochondria", "latency_ms": 99.44581985473633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "mitochondrion", "latency_ms": 172.5637912750244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 707}, "2": {"k": 2, "answer": "mitochondrion", "latency_ms": 155.73430061340332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1366}, "3": {"k": 3, "answer": "mitochondrion", "latency_ms": 151.17502212524414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2064}, "4": {"k": 4, "answer": "mitochondria", "latency_ms": 116.17469787597656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2715}, "5": {"k": 5, "answer": "mitochondria", "latency_ms": 119.65179443359375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3391}, "6": {"k": 6, "answer": "mitochondria", "latency_ms": 144.32859420776367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4070}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 113.99626731872559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 130.3398609161377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "Computer virus, Veriato Log Manager, Spector Pro, Reverse Engineering, Incident Response Manager", "latency_ms": 455.63316345214844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1380}, "3": {"k": 3, "answer": "Incident Response Manager, Veriato Log Manager, Veriato Server Manager, Armitage, Spector Pro", "latency_ms": 498.61979484558105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2097}, "4": {"k": 4, "answer": "Veriato, Armitage, Spector Pro, Incident Response Manager, Computer Forensics Tools", "latency_ms": 467.2839641571045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2806}, "5": {"k": 5, "answer": "Veriato, Armitage, Spector Pro, Incident Response Manager, Metasploit Framework", "latency_ms": 455.4121494293213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3562}, "6": {"k": 6, "answer": "Veriato, Armitage, Spector Pro, Incident Response Manager, ISO/IEC 27000-series standards", "latency_ms": 719.3169593811035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4251}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 124.93443489074707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenny Rogers and Dottie West", "latency_ms": 178.05767059326172, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 590}, "2": {"k": 2, "answer": "Kenny Rogers and Dottie West", "latency_ms": 134.95373725891113, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Kenny Rogers and Dottie West", "latency_ms": 147.70793914794922, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Kenny Rogers and Dottie West", "latency_ms": 217.0724868774414, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "Kenny Rogers", "latency_ms": 116.49465560913086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3082}, "6": {"k": 6, "answer": "Kenny Rogers and Dottie West", "latency_ms": 180.76562881469727, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3663}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 100.31390190124512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2 years old", "latency_ms": 92.15116500854492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 581}, "2": {"k": 2, "answer": "36 months", "latency_ms": 76.74837112426758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1200}, "3": {"k": 3, "answer": "36 months", "latency_ms": 84.5191478729248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "3 years old", "latency_ms": 95.25394439697266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2526}, "5": {"k": 5, "answer": "3 years old", "latency_ms": 100.22401809692383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3129}, "6": {"k": 6, "answer": "3 years old", "latency_ms": 133.38136672973633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3836}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.60932159423828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 57.43575096130371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "three-part", "latency_ms": 64.55516815185547, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "three episodes", "latency_ms": 102.56600379943848, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1947}, "4": {"k": 4, "answer": "three episodes", "latency_ms": 86.05599403381348, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2599}, "5": {"k": 5, "answer": "three episodes", "latency_ms": 129.31156158447266, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3264}, "6": {"k": 6, "answer": "three episodes", "latency_ms": 103.94573211669922, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3904}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Vivien Leigh, Ian McKellen, Sean Astin, Orlando Bloom, Dominic Monaghan, and Billy Boyd", "latency_ms": 564.2766952514648, "em": 0.0, "f1": 0.2352941176470588, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elijah Wood", "latency_ms": 77.66318321228027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "Elijah Wood", "latency_ms": 98.16765785217285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1258}, "3": {"k": 3, "answer": "Elijah Wood, Ian McKellen, Hugo Weaving, Orlando Bloom, Ian Holm", "latency_ms": 570.1453685760498, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1919}, "4": {"k": 4, "answer": "Elijah Wood, Ian McKellen, Hugo Weaving, Orlando Bloom, Ian Holm, Cate Blanchett", "latency_ms": 469.590425491333, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Ian McKellen, Andy Serkis, Hugo Weaving, Elijah Wood, Ian Holm, Christopher Lee, Cate Blanchett, Orlando Bloom", "latency_ms": 464.77270126342773, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3233}, "6": {"k": 6, "answer": "Elijah Wood", "latency_ms": 128.15499305725098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3862}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 78.7816047668457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "fancy dress party", "latency_ms": 83.49466323852539, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "a costume party", "latency_ms": 83.26053619384766, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "a party where guests dress up in costumes", "latency_ms": 274.23572540283203, "em": 0.0, "f1": 0.8333333333333333, "containment": 1.0, "context_chars": 1971}, "4": {"k": 4, "answer": "fancy dress party", "latency_ms": 112.30206489562988, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2647}, "5": {"k": 5, "answer": "fancy dress party", "latency_ms": 126.48725509643555, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3310}, "6": {"k": 6, "answer": "fancy dress party", "latency_ms": 130.74016571044922, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3940}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 148.20337295532227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.23983573913574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.15111351013184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.27279090881348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 175.3695011138916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 133.27503204345703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3225}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 181.46109580993652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3912}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "To protect her from the injustices of the world and to fulfill his sense of moral duty.", "latency_ms": 489.3367290496826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 95.99637985229492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 124.66216087341309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "rescued her and raised her as if she were his own", "latency_ms": 368.44515800476074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "rescued by Jean Valjean, who raises Cosette as if she were his own", "latency_ms": 456.94470405578613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "to rescue and raise her from the Thénardiers' exploitation", "latency_ms": 395.3547477722168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "to rescue and raise her from the Thénardiers' abuse", "latency_ms": 383.1653594970703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3701}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 113.79051208496094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenya", "latency_ms": 57.486772537231445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 688}, "2": {"k": 2, "answer": "Kenya", "latency_ms": 102.9665470123291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1382}, "3": {"k": 3, "answer": "Kenya, India", "latency_ms": 159.00826454162598, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Kenya, India, Norway", "latency_ms": 283.91480445861816, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2788}, "5": {"k": 5, "answer": "Kenya", "latency_ms": 118.22319030761719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3489}, "6": {"k": 6, "answer": "Kenya", "latency_ms": 119.5826530456543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4162}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 78.20653915405273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 403.02371978759766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 345.6118106842041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 394.1481113433838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 559.8232746124268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 430.9051036834717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 516.1092281341553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4130}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Python", "latency_ms": 41.489362716674805, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kaa is a snake.", "latency_ms": 142.47584342956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Kaa is a snake.", "latency_ms": 199.1419792175293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Indian python", "latency_ms": 82.23938941955566, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1830}, "4": {"k": 4, "answer": "Indian python", "latency_ms": 133.74900817871094, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "Indian python", "latency_ms": 134.84883308410645, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3040}, "6": {"k": 6, "answer": "Indian python", "latency_ms": 136.6889476776123, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3650}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "water ice and carbon dioxide ice", "latency_ms": 186.28668785095215, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "water-ice", "latency_ms": 77.37517356872559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "water-ice", "latency_ms": 101.00364685058594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1200}, "3": {"k": 3, "answer": "water-ice", "latency_ms": 102.37598419189453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1776}, "4": {"k": 4, "answer": "water-ice", "latency_ms": 99.3814468383789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2423}, "5": {"k": 5, "answer": "water-ice", "latency_ms": 146.02065086364746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2996}, "6": {"k": 6, "answer": "water-ice", "latency_ms": 165.46273231506348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3644}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 144.29330825805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "when Rebekah causes Matt's truck to drive off Wickery Bridge", "latency_ms": 322.3567008972168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 594}, "2": {"k": 2, "answer": "The Departed (The Vampire Diaries)", "latency_ms": 235.54086685180664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1217}, "3": {"k": 3, "answer": "season four premiere", "latency_ms": 134.52959060668945, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1818}, "4": {"k": 4, "answer": "The Departed (The Vampire Diaries) episode", "latency_ms": 289.48211669921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2382}, "5": {"k": 5, "answer": "The episode's initial airing attracted 2.53 million viewers.", "latency_ms": 358.0310344696045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2999}, "6": {"k": 6, "answer": "The episode's initial airing attracted 2.53 million viewers.", "latency_ms": 506.9704055786133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3599}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 72.41439819335938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 109.39836502075195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "BBC Sport", "latency_ms": 101.86171531677246, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1172}, "3": {"k": 3, "answer": "BBC", "latency_ms": 69.21982765197754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1768}, "4": {"k": 4, "answer": "BBC", "latency_ms": 117.919921875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2392}, "5": {"k": 5, "answer": "BBC", "latency_ms": 89.21003341674805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2976}, "6": {"k": 6, "answer": "BBC", "latency_ms": 155.1344394683838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3568}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Ward 8", "latency_ms": 158.50400924682617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northwest Washington, DC", "latency_ms": 115.37289619445801, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "Northwest Washington, DC", "latency_ms": 127.08330154418945, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Northwest Washington, DC", "latency_ms": 117.78879165649414, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1995}, "4": {"k": 4, "answer": "Northwest Washington, DC", "latency_ms": 125.53930282592773, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2687}, "5": {"k": 5, "answer": "Northwest Washington, DC", "latency_ms": 169.74234580993652, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3299}, "6": {"k": 6, "answer": "Northwest Washington, DC", "latency_ms": 143.82410049438477, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3933}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Covenant of Noah", "latency_ms": 111.95206642150879, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Covenant of Works", "latency_ms": 83.1601619720459, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "Noahic", "latency_ms": 135.04815101623535, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Covenant of Works", "latency_ms": 108.32333564758301, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Covenant of Works", "latency_ms": 112.04171180725098, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2423}, "5": {"k": 5, "answer": "Noahic covenant", "latency_ms": 168.91121864318848, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "Covenant of Works", "latency_ms": 129.61435317993164, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3733}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Lil' Kim", "latency_ms": 159.17420387268066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.47702026367188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 111.74583435058594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "singer from the \"Singing the Blues\" episode", "latency_ms": 229.26735877990723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1807}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 112.04171180725098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2394}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 156.846284866333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2969}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 131.30927085876465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3572}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "Walt Disney", "latency_ms": 66.76268577575684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ray Henderson", "latency_ms": 57.8005313873291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "Ray Henderson", "latency_ms": 70.04952430725098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Ray Henderson", "latency_ms": 82.56769180297852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Ray Henderson", "latency_ms": 86.14325523376465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "Ray Henderson", "latency_ms": 101.70149803161621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Ray Henderson", "latency_ms": 154.4780731201172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3732}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Florida coast", "latency_ms": 54.166555404663086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County, Florida", "latency_ms": 88.56487274169922, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Fort Myers, Florida is located in Lee County, United States.", "latency_ms": 278.12862396240234, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Lee County, Florida", "latency_ms": 111.40251159667969, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Lee County, Florida", "latency_ms": 126.35278701782227, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2529}, "5": {"k": 5, "answer": "Lee County, Florida", "latency_ms": 130.37729263305664, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3176}, "6": {"k": 6, "answer": "Lee County, Florida", "latency_ms": 145.005464553833, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3789}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "2nd", "latency_ms": 116.53423309326172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.5082950592041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.27771377563477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "11th", "latency_ms": 95.33381462097168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "11th", "latency_ms": 99.90310668945312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "11th largest by population", "latency_ms": 156.3427448272705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3079}, "6": {"k": 6, "answer": "11th largest by population", "latency_ms": 250.26750564575195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3698}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mohandas K. Gandhi", "latency_ms": 92.41104125976562, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mahatma Gandhi", "latency_ms": 83.45675468444824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 706}, "2": {"k": 2, "answer": "Mahatma Gandhi", "latency_ms": 96.01640701293945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1429}, "3": {"k": 3, "answer": "Sonia Gandhi", "latency_ms": 95.31235694885254, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2103}, "4": {"k": 4, "answer": "Sonia Gandhi", "latency_ms": 116.37067794799805, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2799}, "5": {"k": 5, "answer": "Sonia Gandhi", "latency_ms": 112.6253604888916, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3509}, "6": {"k": 6, "answer": "Jawaharlal Nehru", "latency_ms": 177.7362823486328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4184}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Terry Jones", "latency_ms": 100.82316398620605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "La Toya Jackson", "latency_ms": 135.61344146728516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 146.5890407562256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1263}, "3": {"k": 3, "answer": "Bobby Flay", "latency_ms": 172.60336875915527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "Bobby Flay", "latency_ms": 113.08431625366211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Bobby Flay", "latency_ms": 129.4717788696289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3086}, "6": {"k": 6, "answer": "Bobby Flay", "latency_ms": 141.6938304901123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3703}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 40.72904586791992, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 44.91829872131348, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": ".java", "latency_ms": 56.738853454589844, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": ".java", "latency_ms": 69.90265846252441, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": ".class", "latency_ms": 73.2417106628418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": ".class", "latency_ms": 87.49794960021973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": ".java", "latency_ms": 91.26496315002441, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 54.46791648864746, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alan Turing", "latency_ms": 63.950300216674805, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Alan Turing", "latency_ms": 105.54909706115723, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1289}, "3": {"k": 3, "answer": "Alan Turing", "latency_ms": 103.60598564147949, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 102.35071182250977, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2530}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 102.07462310791016, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3124}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 132.490873336792, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3756}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "To ensure party members vote according to party lines and to maintain party discipline in Congress.", "latency_ms": 379.7173500061035, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ensure members adhere to party policies and vote as directed", "latency_ms": 160.97474098205566, "em": 0.0, "f1": 0.4285714285714285, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "ensure members vote in line with party leadership", "latency_ms": 174.22866821289062, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "Ensure members vote in line with party leadership", "latency_ms": 238.18659782409668, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "ensure members vote in line with party leadership", "latency_ms": 204.9276828765869, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "Ensure members vote in line with party leadership", "latency_ms": 247.74718284606934, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "ensure members vote in line with party leadership", "latency_ms": 295.74084281921387, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3850}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 147.6445198059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 100.8901596069336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 129.25052642822266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 112.98775672912598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 157.00817108154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 179.34465408325195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3311}, "6": {"k": 6, "answer": "1973", "latency_ms": 188.4756088256836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3866}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the​ right but not the​ obligation to buy foreign​ currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 117.95163154602051, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 72.58272171020508, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 67.14868545532227, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 94.5749282836914, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "call option", "latency_ms": 113.72065544128418, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2700}, "5": {"k": 5, "answer": "call option", "latency_ms": 130.2344799041748, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3357}, "6": {"k": 6, "answer": "call option", "latency_ms": 143.6786651611328, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4005}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 149.04260635375977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360", "latency_ms": 112.49971389770508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360", "latency_ms": 107.28073120117188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1376}, "3": {"k": 3, "answer": "360", "latency_ms": 113.15703392028809, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2070}, "4": {"k": 4, "answer": "360", "latency_ms": 98.34098815917969, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2700}, "5": {"k": 5, "answer": "360", "latency_ms": 161.1182689666748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3342}, "6": {"k": 6, "answer": "360", "latency_ms": 168.45107078552246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3995}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 143.05663108825684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 88.93537521362305, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 96.95672988891602, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 108.7040901184082, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 169.35062408447266, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 147.01056480407715, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3183}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 168.5161590576172, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3835}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gormé"], "shots": {"0": {"k": 0, "answer": "Antônio Carlos Jobim", "latency_ms": 133.83007049560547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eydie Gormé", "latency_ms": 173.2645034790039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 580}, "2": {"k": 2, "answer": "Eydie Gormé", "latency_ms": 153.59020233154297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1156}, "3": {"k": 3, "answer": "Eydie Gormé", "latency_ms": 174.82948303222656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1757}, "4": {"k": 4, "answer": "Eydie Gormé", "latency_ms": 175.858736038208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2334}, "5": {"k": 5, "answer": "Eydie Gormé", "latency_ms": 166.60380363464355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2965}, "6": {"k": 6, "answer": "Eydie Gormé", "latency_ms": 173.0785369873047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3515}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "Justice Markandey Katju", "latency_ms": 139.67466354370117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jasti Chelameswar", "latency_ms": 161.14544868469238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Jasti Chelameswar", "latency_ms": 240.55242538452148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Jasti Chelameswar", "latency_ms": 151.36408805847168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "Jasti Chelameswar", "latency_ms": 214.1129970550537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2481}, "5": {"k": 5, "answer": "Mohan Shantanagoudar", "latency_ms": 267.3163414001465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3093}, "6": {"k": 6, "answer": "Jasti Chelameswar", "latency_ms": 305.3293228149414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3657}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 96.30131721496582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roger Federer", "latency_ms": 103.76524925231934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 635}, "2": {"k": 2, "answer": "Roger Federer", "latency_ms": 119.87733840942383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Roger Federer", "latency_ms": 118.51191520690918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1790}, "4": {"k": 4, "answer": "Roger Federer", "latency_ms": 109.34591293334961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2362}, "5": {"k": 5, "answer": "Roger Federer", "latency_ms": 151.10516548156738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3023}, "6": {"k": 6, "answer": "Roger Federer", "latency_ms": 170.63117027282715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3597}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 158.0955982208252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 52.002668380737305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 644}, "2": {"k": 2, "answer": "1", "latency_ms": 79.59985733032227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1221}, "3": {"k": 3, "answer": "1", "latency_ms": 69.25511360168457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1834}, "4": {"k": 4, "answer": "1", "latency_ms": 86.7764949798584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2444}, "5": {"k": 5, "answer": "1", "latency_ms": 116.99771881103516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3051}, "6": {"k": 6, "answer": "1", "latency_ms": 102.72073745727539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3682}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 114.95423316955566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2016", "latency_ms": 161.66186332702637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "2002", "latency_ms": 140.5313014984131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "2020", "latency_ms": 146.4977264404297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "2020", "latency_ms": 127.88224220275879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "2020", "latency_ms": 144.27876472473145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3240}, "6": {"k": 6, "answer": "2020", "latency_ms": 164.9787425994873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3855}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "32", "latency_ms": 86.43293380737305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 140.87271690368652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 156.83722496032715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "5", "latency_ms": 129.64534759521484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "5", "latency_ms": 88.91940116882324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "5", "latency_ms": 110.42308807373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "5", "latency_ms": 132.22503662109375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3896}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Wallowa County", "latency_ms": 79.04744148254395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 147.4592685699463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 145.51019668579102, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 134.4153881072998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1815}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 191.13612174987793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 209.57159996032715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3082}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 183.23135375976562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3712}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Corry, Kory, Cory", "latency_ms": 185.25052070617676, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 130.5527687072754, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 587}, "2": {"k": 2, "answer": "Cory", "latency_ms": 64.16535377502441, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1188}, "3": {"k": 3, "answer": "Cory", "latency_ms": 107.05065727233887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Corey, Cory", "latency_ms": 124.41515922546387, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2481}, "5": {"k": 5, "answer": "Cory", "latency_ms": 102.19907760620117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3134}, "6": {"k": 6, "answer": "Cory", "latency_ms": 157.00268745422363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3755}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.56528663635254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Misty", "latency_ms": 117.7072525024414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.50516510009766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1374}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 134.95254516601562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 194.81372833251953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2669}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 245.99146842956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3298}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 227.88572311401367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3901}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 81.72249794006348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 75.82807540893555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "159", "latency_ms": 118.87359619140625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "159", "latency_ms": 146.49605751037598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "159", "latency_ms": 165.71879386901855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2732}, "5": {"k": 5, "answer": "159", "latency_ms": 193.78018379211426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3379}, "6": {"k": 6, "answer": "159", "latency_ms": 200.64091682434082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4038}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 112.20884323120117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edwin McCain", "latency_ms": 75.89149475097656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 581}, "2": {"k": 2, "answer": "Egan", "latency_ms": 98.6473560333252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Jingwei", "latency_ms": 142.20166206359863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "Jingwei", "latency_ms": 125.83112716674805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "Egan", "latency_ms": 115.83185195922852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3081}, "6": {"k": 6, "answer": "Jingwei", "latency_ms": 194.96655464172363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3737}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 148.55313301086426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pete Maravich", "latency_ms": 119.81964111328125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Pete Maravich", "latency_ms": 153.81932258605957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 187.30473518371582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 196.83504104614258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2537}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 166.8989658355713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3150}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 159.6519947052002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 88.69314193725586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "right hand", "latency_ms": 57.517051696777344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "right hand", "latency_ms": 110.9015941619873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1154}, "3": {"k": 3, "answer": "right hand ring finger", "latency_ms": 179.44717407226562, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1756}, "4": {"k": 4, "answer": "right hand ring finger", "latency_ms": 162.92953491210938, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2378}, "5": {"k": 5, "answer": "right hand ring finger", "latency_ms": 163.3291244506836, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2972}, "6": {"k": 6, "answer": "right hand ring finger", "latency_ms": 146.67224884033203, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3526}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Pinocchio", "latency_ms": 65.27352333068848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Donald Duck", "latency_ms": 92.11230278015137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Donald Duck", "latency_ms": 92.46206283569336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Donald Duck", "latency_ms": 93.16349029541016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Donald Duck", "latency_ms": 138.47637176513672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Donald Duck", "latency_ms": 168.92004013061523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3205}, "6": {"k": 6, "answer": "Donald Duck", "latency_ms": 194.22125816345215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3857}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Waited I cannot answer.", "latency_ms": 122.08414077758789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Waited. I cannot answer.", "latency_ms": 122.13778495788574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 118.30902099609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 136.16561889648438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1910}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 172.20377922058105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2563}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 213.71793746948242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 196.4404582977295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3875}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 115.67282676696777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2018", "latency_ms": 184.7541332244873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 249.64094161987305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1217}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 302.4921417236328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1847}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 275.82788467407227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2443}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 278.23877334594727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 304.1505813598633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles, California", "latency_ms": 99.44963455200195, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "independently", "latency_ms": 131.92486763000488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 112.81943321228027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1188}, "3": {"k": 3, "answer": "not specified in the context", "latency_ms": 121.1392879486084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "United States", "latency_ms": 86.37046813964844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2500}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 126.92093849182129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3096}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 176.93638801574707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3706}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 106.33420944213867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Emma Gilbert", "latency_ms": 73.76360893249512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 179.17609214782715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 167.68932342529297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1799}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 155.39836883544922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2435}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 143.86773109436035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3006}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 129.2736530303955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3646}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "atmosphere, oceans, soil, living organisms", "latency_ms": 221.59624099731445, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "in the biosphere", "latency_ms": 128.6172866821289, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 700}, "2": {"k": 2, "answer": "in all land-living organisms, both alive and dead, as well as in soils", "latency_ms": 421.9644069671631, "em": 0.0, "f1": 0.125, "containment": 1.0, "context_chars": 1350}, "3": {"k": 3, "answer": "in all land-living organisms, both alive and dead, and in soils", "latency_ms": 359.4551086425781, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 1964}, "4": {"k": 4, "answer": "in all land-living organisms, both alive and dead, and in soils", "latency_ms": 436.07378005981445, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 2601}, "5": {"k": 5, "answer": "in plants and other living organisms, and in soils", "latency_ms": 244.92764472961426, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3308}, "6": {"k": 6, "answer": "in plants and other living organisms, soils, and dead biomass", "latency_ms": 367.37751960754395, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3961}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 143.63503456115723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Akul Balaji", "latency_ms": 159.42716598510742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Akul Balaji", "latency_ms": 114.14289474487305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "Akul Balaji", "latency_ms": 154.65140342712402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Akul Balaji", "latency_ms": 161.25035285949707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Akul Balaji", "latency_ms": 216.01510047912598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Akul Balaji", "latency_ms": 227.75769233703613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3797}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Tennessee", "latency_ms": 53.6346435546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kanab, Utah", "latency_ms": 108.48379135131836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "Lake Powell, Utah", "latency_ms": 95.76940536499023, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Lake Powell, Page, Arizona, Kanab, Utah", "latency_ms": 281.2776565551758, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1929}, "4": {"k": 4, "answer": "Utah, Arizona, Wyoming, Oroville, California", "latency_ms": 319.0112113952637, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2574}, "5": {"k": 5, "answer": "Utah, Arizona, Wyoming, and Oroville, California", "latency_ms": 326.85327529907227, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3201}, "6": {"k": 6, "answer": "Utah, Arizona, Wyoming, Oroville, California", "latency_ms": 302.5529384613037, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3819}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 112.77103424072266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kevin Kline", "latency_ms": 127.1657943725586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Kevin Kline", "latency_ms": 151.4894962310791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1323}, "3": {"k": 3, "answer": "Kevin Kline", "latency_ms": 113.40212821960449, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1957}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 134.66262817382812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 127.33173370361328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3241}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 170.1054573059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3908}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Starts in the Rocky Mountains, ends in the North Dakota-Montana border.", "latency_ms": 343.90997886657715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Starts: confluence of North and South Saskatchewan Rivers in central Saskatchewan; Ends: Lake Winnipeg", "latency_ms": 347.48291969299316, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 708}, "2": {"k": 2, "answer": "Starts in central Saskatchewan (east of Prince Albert), ends in Lake Winnipeg.", "latency_ms": 337.93020248413086, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1438}, "3": {"k": 3, "answer": "Starts: confluence of North and South Saskatchewan Rivers in central Saskatchewan; Ends: Lake Winnipeg", "latency_ms": 389.1925811767578, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 2136}, "4": {"k": 4, "answer": "Starts at confluence of North and South Saskatchewan Rivers near Saskatchewan River Forks; ends in Lake Winnipeg.", "latency_ms": 441.97654724121094, "em": 0.0, "f1": 0.38095238095238093, "containment": 0.0, "context_chars": 2791}, "5": {"k": 5, "answer": "Starts at confluence of North and South Saskatchewan Rivers near Saskatchewan River Forks, ends in Lake Winnipeg.", "latency_ms": 429.31532859802246, "em": 0.0, "f1": 0.38095238095238093, "containment": 0.0, "context_chars": 3435}, "6": {"k": 6, "answer": "Starts at confluence of North and South Saskatchewan Rivers in Saskatchewan River Forks; ends in Lake Winnipeg.", "latency_ms": 482.2385311126709, "em": 0.0, "f1": 0.38095238095238093, "containment": 0.0, "context_chars": 4040}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 103.70159149169922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome, Italy", "latency_ms": 154.86836433410645, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome, Italy", "latency_ms": 181.09440803527832, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Rome, Italy", "latency_ms": 131.7298412322998, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 176.67865753173828, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 241.59812927246094, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3108}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 227.39911079406738, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3743}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 101.37581825256348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "manufacturing company or site", "latency_ms": 131.04557991027832, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "manufacturing company or site", "latency_ms": 155.97963333129883, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "manufacturing company or site", "latency_ms": 203.81569862365723, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "manufacturing company or site", "latency_ms": 179.20970916748047, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2406}, "5": {"k": 5, "answer": "manufacturing company or site", "latency_ms": 177.2592067718506, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2980}, "6": {"k": 6, "answer": "manufacturing company or site", "latency_ms": 172.4374294281006, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3601}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "ammonia, alcohols, carboxylic acids", "latency_ms": 327.91662216186523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 288.4504795074463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 188.2936954498291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 235.83364486694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 276.73959732055664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2596}, "5": {"k": 5, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 226.52173042297363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 216.5689468383789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3885}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.1706314086914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 83.88471603393555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "1988", "latency_ms": 96.42839431762695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1196}, "3": {"k": 3, "answer": "1988", "latency_ms": 107.88369178771973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1799}, "4": {"k": 4, "answer": "1988", "latency_ms": 112.8232479095459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2390}, "5": {"k": 5, "answer": "1988", "latency_ms": 127.43639945983887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3000}, "6": {"k": 6, "answer": "1988", "latency_ms": 141.57485961914062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3619}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Truco", "latency_ms": 53.67588996887207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Manille", "latency_ms": 58.18915367126465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Manille", "latency_ms": 64.77618217468262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Manille", "latency_ms": 105.92055320739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1792}, "4": {"k": 4, "answer": "Manille", "latency_ms": 97.24593162536621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2373}, "5": {"k": 5, "answer": "Manille", "latency_ms": 101.35984420776367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2944}, "6": {"k": 6, "answer": "Manille", "latency_ms": 154.65164184570312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3530}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.1935920715332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5%", "latency_ms": 57.3878288269043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "5%", "latency_ms": 64.12625312805176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "2% to 16%", "latency_ms": 147.27067947387695, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 216.5529727935791, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2458}, "5": {"k": 5, "answer": "5%", "latency_ms": 100.2342700958252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3087}, "6": {"k": 6, "answer": "5%", "latency_ms": 104.01344299316406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3775}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.28133010864258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1975", "latency_ms": 89.60151672363281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "1975", "latency_ms": 96.44150733947754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1185}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.12187194824219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1763}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 112.91170120239258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2388}, "5": {"k": 5, "answer": "1975", "latency_ms": 127.32076644897461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3008}, "6": {"k": 6, "answer": "1975", "latency_ms": 141.29924774169922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3593}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Michael Jackson", "latency_ms": 53.688764572143555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.0047550201416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.72212600708008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.2313060760498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1806}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 113.25311660766602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2421}, "5": {"k": 5, "answer": "Paul Young", "latency_ms": 101.02558135986328, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "Paul Young", "latency_ms": 114.56680297851562, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3662}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Lord Baltimore", "latency_ms": 54.00371551513672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "George Calvert", "latency_ms": 71.43259048461914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "George Calvert", "latency_ms": 83.55069160461426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "George Calvert", "latency_ms": 95.61538696289062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "George Calvert", "latency_ms": 99.83611106872559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2629}, "5": {"k": 5, "answer": "Cecil Calvert", "latency_ms": 210.76107025146484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3323}, "6": {"k": 6, "answer": "Cecil Calvert", "latency_ms": 143.79358291625977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3953}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.56337928771973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiger Woods", "latency_ms": 76.57408714294434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Tiger Woods", "latency_ms": 83.70375633239746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Tiger Woods", "latency_ms": 116.23167991638184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "Tiger Woods", "latency_ms": 133.32557678222656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Tiger Woods", "latency_ms": 187.8645420074463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3115}, "6": {"k": 6, "answer": "Tiger Woods", "latency_ms": 174.03078079223633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3719}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "30 milligrams", "latency_ms": 166.40734672546387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1.31 mg/kg (intravenous) to 1.93 mg/kg (subcutaneous)", "latency_ms": 460.3159427642822, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 341.9153690338135, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 346.85277938842773, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1889}, "4": {"k": 4, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 336.9154930114746, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 364.44973945617676, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 432.34968185424805, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3897}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 171.8125343322754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham United", "latency_ms": 163.4218692779541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 586}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 83.2984447479248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 122.56836891174316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1805}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 133.47935676574707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2397}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 159.78384017944336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2916}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 168.32423210144043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3533}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 146.1188793182373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 161.9880199432373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 114.20869827270508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 124.93109703063965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 141.0207748413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 155.13181686401367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3259}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 180.70435523986816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh, Scotland", "latency_ms": 129.3632984161377, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 143.56422424316406, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 107.42449760437012, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1372}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 155.19404411315918, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2068}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 116.23334884643555, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 126.61361694335938, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3333}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 166.86439514160156, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3984}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Seth Rollins", "latency_ms": 129.27699089050293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 154.49023246765137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 165.34709930419922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Roman Reigns", "latency_ms": 96.02189064025879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Bray Wyatt", "latency_ms": 112.70928382873535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2609}, "5": {"k": 5, "answer": "Bray Wyatt", "latency_ms": 141.05606079101562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3226}, "6": {"k": 6, "answer": "Bray Wyatt", "latency_ms": 152.12416648864746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3897}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 125.76675415039062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Southport, North Carolina", "latency_ms": 122.17998504638672, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Southport, North Carolina", "latency_ms": 155.1978588104248, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Southport, North Carolina", "latency_ms": 141.86978340148926, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Southport, North Carolina", "latency_ms": 210.31665802001953, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Southport, North Carolina", "latency_ms": 163.1019115447998, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Southport, North Carolina", "latency_ms": 178.89690399169922, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3759}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 126.0533332824707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Landon Jones", "latency_ms": 126.59931182861328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "Sylvia F. Porter", "latency_ms": 186.77115440368652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Sylvia F. Porter", "latency_ms": 219.48766708374023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 160.72344779968262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 219.7558879852295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3171}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 214.57505226135254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3846}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 117.20752716064453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 139.00017738342285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 714}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 93.66941452026367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1414}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 96.88878059387207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2151}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 115.24248123168945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2897}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 113.90185356140137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3534}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 152.7693271636963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4176}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 62.94608116149902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 55.298566818237305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "Max", "latency_ms": 57.36947059631348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1247}, "3": {"k": 3, "answer": "Max", "latency_ms": 69.94104385375977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Max", "latency_ms": 74.16915893554688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2452}, "5": {"k": 5, "answer": "Max", "latency_ms": 87.90779113769531, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Max", "latency_ms": 92.45967864990234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3796}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Sasha Lane", "latency_ms": 117.34724044799805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Geneviève Bujold", "latency_ms": 115.04554748535156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 160.57825088500977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.79278182983398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 180.44352531433105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 127.23231315612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 142.3633098602295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3790}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 90.22045135498047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Women beginning to serve in limited military roles in some countries", "latency_ms": 231.4133644104004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Paris 1900 chess tournament, Exposition Universelle", "latency_ms": 274.5234966278076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Paris 1900 chess tournament, World War I not yet started, women beginning limited military roles", "latency_ms": 478.7938594818115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "World War I, Paris 1900 chess tournament, women beginning military roles, U.S. Navy transitioning to steel battleships", "latency_ms": 534.8434448242188, "em": 0.0, "f1": 0.0909090909090909, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "World War I, Boxer Rebellion, Spanish–American War, Exposition Universelle", "latency_ms": 483.70885848999023, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3271}, "6": {"k": 6, "answer": "World War I, Spanish–American War, Boxer Rebellion, Exposition Universelle, rise of steel hulls in navy, women beginning military roles", "latency_ms": 699.9416351318359, "em": 0.0, "f1": 0.19047619047619052, "containment": 1.0, "context_chars": 3863}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "empowerment", "latency_ms": 134.04297828674316, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "empowerment", "latency_ms": 93.45817565917969, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 135.89239120483398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "self-empowerment", "latency_ms": 157.17244148254395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "self-empowerment", "latency_ms": 196.00510597229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2587}, "5": {"k": 5, "answer": "self-empowerment", "latency_ms": 191.55597686767578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "self-empowerment", "latency_ms": 217.5307273864746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3951}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 83.72974395751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "NFL franchises", "latency_ms": 72.77965545654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "NFL franchises", "latency_ms": 72.22771644592285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "NFL franchises", "latency_ms": 110.33177375793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "NFL franchises", "latency_ms": 104.35318946838379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2513}, "5": {"k": 5, "answer": "NFL franchises", "latency_ms": 104.95471954345703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "NFL franchises", "latency_ms": 127.81333923339844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3722}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 90.32845497131348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Marshall", "latency_ms": 103.59430313110352, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "James Marshall", "latency_ms": 103.34587097167969, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "James Marshall", "latency_ms": 101.99379920959473, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": "James Marshall", "latency_ms": 120.26739120483398, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "James Marshall", "latency_ms": 123.00992012023926, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3220}, "6": {"k": 6, "answer": "James Marshall", "latency_ms": 120.91422080993652, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3781}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "convex mirror", "latency_ms": 67.48080253601074, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "rear-view mirror", "latency_ms": 83.16302299499512, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "rear-view mirror", "latency_ms": 134.95612144470215, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "rear-view mirror", "latency_ms": 118.77012252807617, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "rear-view mirror", "latency_ms": 142.87972450256348, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2505}, "5": {"k": 5, "answer": "rear-view mirror", "latency_ms": 166.06569290161133, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3136}, "6": {"k": 6, "answer": "rear-view mirror", "latency_ms": 153.0158519744873, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 98.65403175354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 113.32941055297852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 100.27265548706055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 142.04716682434082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 157.03606605529785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2489}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 180.1469326019287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3139}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 204.9412727355957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3745}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Andrew Lloyd Webber", "latency_ms": 100.88586807250977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart", "latency_ms": 63.005685806274414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 224.761962890625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1227}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 242.39587783813477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1863}, "4": {"k": 4, "answer": "Charles Hart", "latency_ms": 105.96442222595215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2497}, "5": {"k": 5, "answer": "Charles Hart", "latency_ms": 102.52714157104492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3161}, "6": {"k": 6, "answer": "Charles Hart", "latency_ms": 161.75293922424316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3836}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Central Europe", "latency_ms": 54.88276481628418, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northern Europe", "latency_ms": 65.23323059082031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "Central Germany", "latency_ms": 79.89335060119629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Central Germany", "latency_ms": 69.87380981445312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1937}, "4": {"k": 4, "answer": "Central Germany (cultural area)", "latency_ms": 278.5484790802002, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Central Germany (cultural area)", "latency_ms": 320.00279426574707, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3406}, "6": {"k": 6, "answer": "Northern Germany", "latency_ms": 103.66654396057129, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4098}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "13th to 14th century", "latency_ms": 243.3326244354248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 181.67948722839355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "1648–1651", "latency_ms": 283.3576202392578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "1648–1651", "latency_ms": 230.942964553833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "1648–1651", "latency_ms": 275.1178741455078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2648}, "5": {"k": 5, "answer": "1648–1651", "latency_ms": 329.5438289642334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3409}, "6": {"k": 6, "answer": "later, more modern period than earlier titles", "latency_ms": 241.44363403320312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4087}}}
