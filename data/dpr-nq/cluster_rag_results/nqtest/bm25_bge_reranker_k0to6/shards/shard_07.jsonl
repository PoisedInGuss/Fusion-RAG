{"qid": "5306300389470118812", "question": "what was the religion in persia before islam", "gold_answers": ["the Zoroastrian religion", "Zoroastrian"], "shots": {"0": {"k": 0, "answer": "Zoroastrianism", "latency_ms": 90.04712104797363, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Zoroastrianism", "latency_ms": 102.17881202697754, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "Zoroastrianism", "latency_ms": 174.9250888824463, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1284}, "3": {"k": 3, "answer": "Zoroastrianism", "latency_ms": 138.8847827911377, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1994}, "4": {"k": 4, "answer": "Zoroastrianism", "latency_ms": 125.18477439880371, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2653}, "5": {"k": 5, "answer": "Zoroastrianism", "latency_ms": 172.15251922607422, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3338}, "6": {"k": 6, "answer": "Zoroastrianism", "latency_ms": 147.26614952087402, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3993}}}
{"qid": "4492088526674104172", "question": "why does kerosene oil rise up in the wick of lantern", "gold_answers": ["capillary action"], "shots": {"0": {"k": 0, "answer": "Capillary action", "latency_ms": 66.38312339782715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "capillary action", "latency_ms": 117.03705787658691, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 586}, "2": {"k": 2, "answer": "capillary action", "latency_ms": 82.84854888916016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1171}, "3": {"k": 3, "answer": "capillary action", "latency_ms": 119.81511116027832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1826}, "4": {"k": 4, "answer": "capillary action", "latency_ms": 111.78421974182129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2501}, "5": {"k": 5, "answer": "capillary action", "latency_ms": 114.22491073608398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3109}, "6": {"k": 6, "answer": "capillary action", "latency_ms": 149.22451972961426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3728}}}
{"qid": "-4373262132142058334", "question": "mention the chemical change that proinsulin undergo to be able to act as mature insulin", "gold_answers": ["post translational modification"], "shots": {"0": {"k": 0, "answer": "Proteolytic cleavage", "latency_ms": 124.6030330657959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "C-peptide cleavage", "latency_ms": 169.44169998168945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "cleavage of C-peptide", "latency_ms": 122.55144119262695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1357}, "3": {"k": 3, "answer": "cleavage of C-peptide", "latency_ms": 174.912691116333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2047}, "4": {"k": 4, "answer": "cleavage of C-peptide", "latency_ms": 226.38797760009766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2596}, "5": {"k": 5, "answer": "cleavage of C-peptide", "latency_ms": 265.86031913757324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3229}, "6": {"k": 6, "answer": "cleavage of C-peptide", "latency_ms": 229.15983200073242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3933}}}
{"qid": "-5298560410953979569", "question": "where does the sweetness of fruit come from", "gold_answers": ["Fructose , or fruit sugar", "Fructose"], "shots": {"0": {"k": 0, "answer": "sugars like fructose, glucose, and sucrose", "latency_ms": 373.532772064209, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Brazzein in the pulp tissue surrounding the seeds", "latency_ms": 252.7487277984619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 681}, "2": {"k": 2, "answer": "Brazzein is a sweet-tasting protein extracted from the West African fruit of the climbing plant Oubli (Pentadiplandra brazzeana Baillon)", "latency_ms": 782.2444438934326, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "fruit pulp tissue surrounding the seeds in Oubli fruit", "latency_ms": 246.56009674072266, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 2023}, "4": {"k": 4, "answer": "fruit of Synsepalum dulcificum", "latency_ms": 273.3759880065918, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2661}, "5": {"k": 5, "answer": "fruit pulp, seeds, and leaves contain sweet-tasting proteins and compounds like brazzein, miraculin, and sugars", "latency_ms": 663.79714012146, "em": 0.0, "f1": 0.10526315789473685, "containment": 0.0, "context_chars": 3319}, "6": {"k": 6, "answer": "fruit of Pentadiplandra brazzeana", "latency_ms": 342.13995933532715, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3981}}}
{"qid": "4344648368832551136", "question": "an object that moves around an external axis is said to be", "gold_answers": ["orbit", "revolution or orbital revolution"], "shots": {"0": {"k": 0, "answer": "rotating", "latency_ms": 72.69716262817383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "revolving", "latency_ms": 116.84942245483398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "revolving", "latency_ms": 70.39785385131836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "revolving", "latency_ms": 88.10114860534668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1844}, "4": {"k": 4, "answer": "revolving", "latency_ms": 92.89741516113281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "revolving", "latency_ms": 136.0330581665039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3230}, "6": {"k": 6, "answer": "revolving", "latency_ms": 103.95288467407227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3842}}}
{"qid": "-724426540432437711", "question": "what was the name of the plant on little shop of horrors", "gold_answers": ["Audrey II"], "shots": {"0": {"k": 0, "answer": "Audrey II", "latency_ms": 95.57747840881348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Audrey II", "latency_ms": 75.66690444946289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 589}, "2": {"k": 2, "answer": "Audrey II", "latency_ms": 133.41784477233887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Audrey II", "latency_ms": 160.17818450927734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1834}, "4": {"k": 4, "answer": "Audrey II", "latency_ms": 166.75472259521484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2495}, "5": {"k": 5, "answer": "Audrey II", "latency_ms": 114.88652229309082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Audrey II", "latency_ms": 130.41424751281738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3810}}}
{"qid": "-5541610970112826260", "question": "who signed the declaration of independence for maryland", "gold_answers": ["Samuel Chase", "Charles Carroll of Carrollton", "Thomas Stone", "William Paca"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 101.03821754455566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 454.7123908996582, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 704}, "2": {"k": 2, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 413.0253791809082, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 1389}, "3": {"k": 3, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 323.09961318969727, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 2076}, "4": {"k": 4, "answer": "Samuel Chase, William Paca, Thomas Stone, Charles Carroll of Carrollton", "latency_ms": 333.39977264404297, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2793}, "5": {"k": 5, "answer": "Samuel Chase, William Paca, Thomas Stone, Charles Carroll of Carrollton", "latency_ms": 351.22036933898926, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3456}, "6": {"k": 6, "answer": "Samuel Chase, William Paca, Thomas Stone, Charles Carroll of Carrollton", "latency_ms": 368.8054084777832, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4130}}}
{"qid": "-86997217831791339", "question": "when does wonder woman come out on blue ray", "gold_answers": ["September 19 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.71763610839844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 19, 2017", "latency_ms": 221.78292274475098, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "September 19, 2017", "latency_ms": 307.6820373535156, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "September 19, 2017", "latency_ms": 295.7949638366699, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "September 19, 2017", "latency_ms": 267.2920227050781, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2545}, "5": {"k": 5, "answer": "September 19, 2017", "latency_ms": 253.8611888885498, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3182}, "6": {"k": 6, "answer": "September 19, 2017", "latency_ms": 254.17399406433105, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3797}}}
{"qid": "-8062812506672279762", "question": "what nba team did derrick rose play for", "gold_answers": ["New York Knicks", "Minnesota Timberwolves", "Chicago Bulls", "Cleveland Cavaliers"], "shots": {"0": {"k": 0, "answer": "Chicago Bulls", "latency_ms": 72.20053672790527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Minnesota Timberwolves", "latency_ms": 83.6639404296875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 630}, "2": {"k": 2, "answer": "Minnesota Timberwolves", "latency_ms": 95.98898887634277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Minnesota Timberwolves", "latency_ms": 107.78570175170898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Chicago Bulls, Minnesota Timberwolves", "latency_ms": 220.23296356201172, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2520}, "5": {"k": 5, "answer": "Chicago Bulls, Minnesota Timberwolves, New York Knicks, Cleveland Cavaliers", "latency_ms": 290.3172969818115, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3128}, "6": {"k": 6, "answer": "Chicago Bulls, Minnesota Timberwolves, New York Knicks, Cleveland Cavaliers", "latency_ms": 353.3141613006592, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3755}}}
{"qid": "7933002036740390435", "question": "where did the term liberal arts come from", "gold_answers": ["the Roman Empire"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 99.82752799987793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roman Empire", "latency_ms": 89.49422836303711, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Roman Empire", "latency_ms": 83.72116088867188, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Roman Empire", "latency_ms": 110.58187484741211, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2019}, "4": {"k": 4, "answer": "Roman Empire", "latency_ms": 109.83586311340332, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2662}, "5": {"k": 5, "answer": "Roman Empire", "latency_ms": 115.10252952575684, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3353}, "6": {"k": 6, "answer": "Roman Empire", "latency_ms": 121.53077125549316, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4087}}}
{"qid": "-2991400700385487821", "question": "who heads the executive department of west virginia government", "gold_answers": ["the Governor of West Virginia", "the governor of West Virginia", "Jim Justice"], "shots": {"0": {"k": 0, "answer": "Governor of West Virginia", "latency_ms": 109.4968318939209, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "governor", "latency_ms": 74.69630241394043, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "Governor of West Virginia", "latency_ms": 174.09515380859375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Governor of West Virginia", "latency_ms": 154.73437309265137, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1949}, "4": {"k": 4, "answer": "Governor of West Virginia", "latency_ms": 176.2228012084961, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Governor of West Virginia", "latency_ms": 162.68324851989746, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3210}, "6": {"k": 6, "answer": "Governor of West Virginia", "latency_ms": 171.56147956848145, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3842}}}
{"qid": "-9186689755642837558", "question": "how long is the bridge between new brunswick and prince edward island", "gold_answers": ["12.9 - kilometre"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 114.0589714050293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 135.36691665649414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 686}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 160.3982448577881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 176.11002922058105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1933}, "4": {"k": 4, "answer": "Canada's longest fixed-link crossing", "latency_ms": 222.20611572265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2602}, "5": {"k": 5, "answer": "Canada's longest fixed-link crossing", "latency_ms": 192.3205852508545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3289}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 130.2471160888672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3950}}}
{"qid": "8029901619424338449", "question": "when did the uk and us become allies", "gold_answers": ["1940", "Since 1940"], "shots": {"0": {"k": 0, "answer": "1941", "latency_ms": 96.25244140625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 130.07879257202148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 114.94994163513184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 120.79143524169922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 178.1005859375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2695}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 205.69348335266113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3393}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 163.0237102508545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4073}}}
{"qid": "4828649525820722736", "question": "who sang the theme song for the man with the golden gun", "gold_answers": ["Lulu"], "shots": {"0": {"k": 0, "answer": "Lulu", "latency_ms": 59.5247745513916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lulu", "latency_ms": 85.40058135986328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Lulu", "latency_ms": 118.19934844970703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Lulu", "latency_ms": 134.0484619140625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1895}, "4": {"k": 4, "answer": "Lulu", "latency_ms": 151.86166763305664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2545}, "5": {"k": 5, "answer": "Lulu", "latency_ms": 182.9371452331543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3150}, "6": {"k": 6, "answer": "Lulu", "latency_ms": 135.09178161621094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3805}}}
{"qid": "-7924663090486742985", "question": "american horror story freak show girl kidnapped by clown", "gold_answers": ["Bonnie Lipton"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 101.14073753356934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 123.56352806091309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "Twisty", "latency_ms": 92.39959716796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Elsa Mars", "latency_ms": 106.06718063354492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Bette Tattler", "latency_ms": 209.1214656829834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2679}, "5": {"k": 5, "answer": "Bette Tattler", "latency_ms": 194.15044784545898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3314}, "6": {"k": 6, "answer": "Bette Tattler", "latency_ms": 182.06143379211426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3973}}}
{"qid": "-360675773049242516", "question": "the probability of making a type i error when retaining ho at the .05 level of significance is", "gold_answers": ["5 %"], "shots": {"0": {"k": 0, "answer": "0.05", "latency_ms": 102.83517837524414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0.05", "latency_ms": 117.51937866210938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "0.05", "latency_ms": 127.52962112426758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "0.05", "latency_ms": 142.29416847229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "0.05", "latency_ms": 158.34569931030273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2430}, "5": {"k": 5, "answer": "0.05", "latency_ms": 198.12321662902832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3069}, "6": {"k": 6, "answer": "0.05", "latency_ms": 151.42178535461426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3699}}}
{"qid": "5819386267283467034", "question": "what year did the us hockey team won the olympics", "gold_answers": ["1960", "1980", "1960 and 1980"], "shots": {"0": {"k": 0, "answer": "1980", "latency_ms": 113.6934757232666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1980", "latency_ms": 154.44612503051758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "1960, 1980", "latency_ms": 340.0452136993408, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1226}, "3": {"k": 3, "answer": "1960, 1980", "latency_ms": 249.19414520263672, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1887}, "4": {"k": 4, "answer": "1960", "latency_ms": 220.8998203277588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2551}, "5": {"k": 5, "answer": "1960", "latency_ms": 196.68078422546387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "1960", "latency_ms": 230.43322563171387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3772}}}
{"qid": "3916394566028297311", "question": "who wrote it's a long long way to pasadena", "gold_answers": ["Harry Vanda", "John Young", "David Hemmings", "George Young"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 101.29451751708984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 123.45409393310547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 142.81177520751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 158.92457962036133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 190.2308464050293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 199.43881034851074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3208}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 160.42613983154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3853}}}
{"qid": "-2432292250757146771", "question": "who wrote the song i hate you i love you", "gold_answers": ["Angel Benitez", "Olivia O'Brien", "Garrett Nash"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 107.00130462646484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gnash", "latency_ms": 133.9111328125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 572}, "2": {"k": 2, "answer": "Gnash", "latency_ms": 93.82152557373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1147}, "3": {"k": 3, "answer": "Alberto Testa", "latency_ms": 188.5359287261963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1770}, "4": {"k": 4, "answer": "Alberto Testa", "latency_ms": 166.88251495361328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2383}, "5": {"k": 5, "answer": "JB", "latency_ms": 112.57648468017578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3025}, "6": {"k": 6, "answer": "Alberto Testa", "latency_ms": 160.57133674621582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3609}}}
{"qid": "2393389448844632496", "question": "what is loihi and where does it originate from", "gold_answers": ["from the Hawaii hotspot"], "shots": {"0": {"k": 0, "answer": "Loihi is a seamount in the Pacific Ocean, originating from the Hawaiian hotspot.", "latency_ms": 369.3077564239502, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Loihi is a seamount in Hawaii; originates from Hawaiian word meaning \"long\"", "latency_ms": 356.2157154083252, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "Loihi is a seamount in Hawaii named after the Hawaiian word for \"long\"; it originates from the Hawaiian language.", "latency_ms": 502.39038467407227, "em": 0.0, "f1": 0.21052631578947367, "containment": 0.0, "context_chars": 1392}, "3": {"k": 3, "answer": "Loihi is a seamount in Hawaii named after the Hawaiian word meaning \"long\"; it originates from the Hawaiian hotspot.", "latency_ms": 652.8618335723877, "em": 0.0, "f1": 0.3157894736842105, "containment": 0.0, "context_chars": 2064}, "4": {"k": 4, "answer": "Loihi is a seamount in Hawaii named after the Hawaiian word meaning \"long\"; it is also the name of Intel's neuromorphic chip.", "latency_ms": 589.9608135223389, "em": 0.0, "f1": 0.09090909090909091, "containment": 0.0, "context_chars": 2856}, "5": {"k": 5, "answer": "Loihi is a seamount in Hawaii, named after the Hawaiian word meaning \"long\"; it originates from the Hawaiian hotspot.", "latency_ms": 613.457202911377, "em": 0.0, "f1": 0.3157894736842105, "containment": 0.0, "context_chars": 3536}, "6": {"k": 6, "answer": "Loihi is a seamount in Hawaii, named after the Hawaiian word meaning \"long\"; it is also the name of Intel's neuromorphic chip and a bacterium found at a hydrothermal vent on the seamount. Origin: Hawaii.", "latency_ms": 1188.1370544433594, "em": 0.0, "f1": 0.0625, "containment": 0.0, "context_chars": 4190}}}
{"qid": "-6677440871585683891", "question": "who rebuilt the temple after the babylonian captivity", "gold_answers": ["Herod"], "shots": {"0": {"k": 0, "answer": "Zerubbabel", "latency_ms": 129.24909591674805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jews", "latency_ms": 57.749271392822266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "The Israelites", "latency_ms": 129.41956520080566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 175.85372924804688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Jews exiled by Nebuchadnezzar", "latency_ms": 242.05875396728516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2564}, "5": {"k": 5, "answer": "Nehemiah", "latency_ms": 147.51863479614258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3215}, "6": {"k": 6, "answer": "Nehemiah", "latency_ms": 140.40207862854004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3884}}}
{"qid": "-6750750235985613277", "question": "who was executed for being an american spy during the revolutionary war", "gold_answers": ["Nathan Hale"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 89.93959426879883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nathan Hale", "latency_ms": 116.18494987487793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 591}, "2": {"k": 2, "answer": "Nathan Hale", "latency_ms": 149.18208122253418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1210}, "3": {"k": 3, "answer": "Nathan Hale", "latency_ms": 164.8552417755127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1867}, "4": {"k": 4, "answer": "John André", "latency_ms": 103.98483276367188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Nathan Hale", "latency_ms": 127.61092185974121, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3106}, "6": {"k": 6, "answer": "Nathan Hale", "latency_ms": 117.4767017364502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3845}}}
{"qid": "8770209312170080158", "question": "who sang the song suddenly with olivia newton john", "gold_answers": ["Cliff Richard"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 94.71344947814941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cliff Richard", "latency_ms": 76.27725601196289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "Cliff Richard", "latency_ms": 115.16928672790527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1270}, "3": {"k": 3, "answer": "Cliff Richard", "latency_ms": 142.58956909179688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Cliff Richard", "latency_ms": 184.3118667602539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2509}, "5": {"k": 5, "answer": "Cliff Richard", "latency_ms": 154.89745140075684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3169}, "6": {"k": 6, "answer": "Cliff Richard", "latency_ms": 132.1396827697754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3834}}}
{"qid": "-180549795106449014", "question": "who is command sergeant major of the army", "gold_answers": ["Daniel A. Dailey"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.65636253356934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Daniel A. Dailey", "latency_ms": 108.91556739807129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 566}, "2": {"k": 2, "answer": "Daniel A. Dailey", "latency_ms": 143.34607124328613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Daniel A. Dailey", "latency_ms": 121.0641860961914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1783}, "4": {"k": 4, "answer": "Daniel A. Dailey", "latency_ms": 172.23644256591797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2489}, "5": {"k": 5, "answer": "Daniel A. Dailey", "latency_ms": 140.1512622833252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3128}, "6": {"k": 6, "answer": "Daniel A. Dailey", "latency_ms": 193.312406539917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3752}}}
{"qid": "7815138213728640354", "question": "who sings the original windmills of your mind", "gold_answers": ["Noel Harrison"], "shots": {"0": {"k": 0, "answer": "The Kinks", "latency_ms": 67.43407249450684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noel Harrison", "latency_ms": 127.67767906188965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 679}, "2": {"k": 2, "answer": "Noel Harrison", "latency_ms": 83.40740203857422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1284}, "3": {"k": 3, "answer": "Noel Harrison", "latency_ms": 162.34612464904785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1952}, "4": {"k": 4, "answer": "Noel Harrison", "latency_ms": 101.30095481872559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2604}, "5": {"k": 5, "answer": "Noel Harrison", "latency_ms": 117.07043647766113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3266}, "6": {"k": 6, "answer": "Noel Harrison", "latency_ms": 130.41448593139648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3886}}}
{"qid": "2098168902147822379", "question": "where will the next summer and winter olympics be held", "gold_answers": ["Beijing", "Tokyo"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 108.27326774597168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tokyo (Summer 2020), Sapporo and Nagano (Winter)", "latency_ms": 449.1736888885498, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 596}, "2": {"k": 2, "answer": "Tokyo and Beijing", "latency_ms": 166.77546501159668, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1221}, "3": {"k": 3, "answer": "Tokyo (Summer), Beijing (Winter)", "latency_ms": 190.86575508117676, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1841}, "4": {"k": 4, "answer": "Tokyo 2020 (Summer), Beijing 2022 (Winter)", "latency_ms": 436.33294105529785, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 2458}, "5": {"k": 5, "answer": "Tokyo 2020 (Summer), Beijing 2022 (Winter)", "latency_ms": 402.5139808654785, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 3050}, "6": {"k": 6, "answer": "Tokyo 2020 and Beijing 2022", "latency_ms": 360.23783683776855, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3730}}}
{"qid": "-1458476052377668874", "question": "when did ole miss beat alabama in football", "gold_answers": ["September 19 , 2015", "October 3 , 1970", "October 27 , 1894", "October 13 , 2001", "October 5 , 1968", "October 4 , 2014", "September 11 , 1976", "October 8 , 1988", "October 18 , 2003", "November 5 , 1910"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 100.87919235229492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 89.60509300231934, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "1988", "latency_ms": 95.40414810180664, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1216}, "3": {"k": 3, "answer": "1988, 1989", "latency_ms": 186.24138832092285, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1903}, "4": {"k": 4, "answer": "1988, 1989, 1998", "latency_ms": 303.6353588104248, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "1988, 1989, 1998", "latency_ms": 332.45158195495605, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "1988, 1989, 1998", "latency_ms": 297.3058223724365, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3835}}}
{"qid": "-6861734002351236912", "question": "who sang the song how far is heaven", "gold_answers": ["Los Lonely Boys"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 78.88317108154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 135.15567779541016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.45771980285645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1200}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.86693000793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1816}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 113.38043212890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2405}, "5": {"k": 5, "answer": "Justin Moore", "latency_ms": 102.03099250793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2994}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 141.36576652526855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3635}}}
{"qid": "-1722216190521937227", "question": "where are the organ mountains in new mexico", "gold_answers": ["southern New Mexico"], "shots": {"0": {"k": 0, "answer": "Organ Mountains are located in southern New Mexico, near the border with Arizona.", "latency_ms": 286.121129989624, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "southern New Mexico, east of Las Cruces, Doña Ana County", "latency_ms": 308.8381290435791, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "southern New Mexico, east of Las Cruces, in Doña Ana County", "latency_ms": 265.92302322387695, "em": 0.0, "f1": 0.42857142857142855, "containment": 1.0, "context_chars": 1263}, "3": {"k": 3, "answer": "southern New Mexico, east of Las Cruces, Doña Ana County", "latency_ms": 281.79383277893066, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1982}, "4": {"k": 4, "answer": "southern New Mexico, east of Las Cruces, Doña Ana County", "latency_ms": 395.7324028015137, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2574}, "5": {"k": 5, "answer": "southern New Mexico, east of Las Cruces, Doña Ana County", "latency_ms": 447.83568382263184, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3171}, "6": {"k": 6, "answer": "southern New Mexico, east of Las Cruces, Doña Ana County", "latency_ms": 440.10257720947266, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3788}}}
{"qid": "-2717119588239727064", "question": "where are the 10 plagues found in the bible", "gold_answers": ["Book of Exodus", "Exodus"], "shots": {"0": {"k": 0, "answer": "Exodus 7–12", "latency_ms": 250.90289115905762, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Exodus 7–12", "latency_ms": 166.82195663452148, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 570}, "2": {"k": 2, "answer": "Hebrew Bible", "latency_ms": 82.76057243347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Exodus 7-12", "latency_ms": 181.11705780029297, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1787}, "4": {"k": 4, "answer": "Exodus 7-12", "latency_ms": 150.45452117919922, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2399}, "5": {"k": 5, "answer": "Exodus 7–12", "latency_ms": 211.97080612182617, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2949}, "6": {"k": 6, "answer": "Exodus 7–12", "latency_ms": 169.02995109558105, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3524}}}
{"qid": "2988284357714596500", "question": "where are red blood cells made in adults", "gold_answers": ["in the bone marrow"], "shots": {"0": {"k": 0, "answer": "bone marrow", "latency_ms": 53.221702575683594, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "red bone marrow", "latency_ms": 70.46794891357422, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "bone marrow", "latency_ms": 94.04110908508301, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "bone marrow", "latency_ms": 96.35186195373535, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1911}, "4": {"k": 4, "answer": "red bone marrow of large bones", "latency_ms": 171.41366004943848, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 2504}, "5": {"k": 5, "answer": "red bone marrow of large bones", "latency_ms": 173.7823486328125, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 3148}, "6": {"k": 6, "answer": "red bone marrow of large bones", "latency_ms": 238.90042304992676, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 3838}}}
{"qid": "-4616596799374362422", "question": "who was the pinkerton detective agency's first female detective", "gold_answers": ["Kate Warne"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 94.44832801818848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kate Warne", "latency_ms": 79.14066314697266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Kate Warne", "latency_ms": 114.85958099365234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1235}, "3": {"k": 3, "answer": "Kate Warne", "latency_ms": 117.29216575622559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Kate Warne", "latency_ms": 135.1170539855957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2591}, "5": {"k": 5, "answer": "Kate Warne", "latency_ms": 157.62019157409668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Kate Warne", "latency_ms": 171.62203788757324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3841}}}
{"qid": "-3650291155113659146", "question": "how many episodes are there in modern family", "gold_answers": ["232", "201"], "shots": {"0": {"k": 0, "answer": "216 episodes", "latency_ms": 117.58136749267578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "24 episodes", "latency_ms": 76.25484466552734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 112.33782768249512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 102.3561954498291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 113.35587501525879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2464}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 127.06232070922852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3088}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 156.29959106445312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3716}}}
{"qid": "3381924381590631417", "question": "who built the first temple for god in jerusalem", "gold_answers": ["Solomon"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.68807220458984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "King Solomon", "latency_ms": 63.648223876953125, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "King Solomon", "latency_ms": 89.3242359161377, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1296}, "3": {"k": 3, "answer": "King Solomon", "latency_ms": 86.04168891906738, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "King Solomon", "latency_ms": 86.81893348693848, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2602}, "5": {"k": 5, "answer": "Solomon", "latency_ms": 101.39250755310059, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3237}, "6": {"k": 6, "answer": "Solomon", "latency_ms": 104.11238670349121, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3797}}}
{"qid": "-154783694579651082", "question": "what is a dropped pin on google maps for", "gold_answers": ["marks locations", "marks locations in Google Maps"], "shots": {"0": {"k": 0, "answer": "A dropped pin on Google Maps typically indicates a user-created location marker, such as a place of interest, a personal location, or a point of significance. It may also represent a temporary or unofficial location, like a meeting spot or a point of interest not officially listed. Dropped pins are often used for sharing or marking personal or non-commercial locations.", "latency_ms": 1098.4208583831787, "em": 0.0, "f1": 0.10526315789473685, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a location", "latency_ms": 57.164907455444336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "a location", "latency_ms": 64.5899772644043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "a location", "latency_ms": 71.61664962768555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "a location", "latency_ms": 82.5200080871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "a location", "latency_ms": 100.31628608703613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3211}, "6": {"k": 6, "answer": "a location", "latency_ms": 103.72662544250488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "6915606477668963399", "question": "what do the 3 dots mean in math", "gold_answers": ["the therefore sign", "therefore sign"], "shots": {"0": {"k": 0, "answer": "ellipses", "latency_ms": 82.48591423034668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "virtual particle", "latency_ms": 70.65200805664062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 130.767822265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "therefore", "latency_ms": 105.0570011138916, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "therefore", "latency_ms": 95.75152397155762, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "therefore", "latency_ms": 125.23865699768066, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3172}, "6": {"k": 6, "answer": "therefore", "latency_ms": 117.01083183288574, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3844}}}
{"qid": "-8366545547296627039", "question": "who wrote the song photograph by ringo starr", "gold_answers": ["Richard Starkey", "George Harrison", "Ringo Starr"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 143.57686042785645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ringo Starr and George Harrison", "latency_ms": 177.1695613861084, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Ringo Starr and George Harrison", "latency_ms": 160.77709197998047, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "George Harrison", "latency_ms": 82.49211311340332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1985}, "4": {"k": 4, "answer": "George Harrison", "latency_ms": 115.12923240661621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2629}, "5": {"k": 5, "answer": "Ringo Starr and George Harrison", "latency_ms": 198.77099990844727, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3357}, "6": {"k": 6, "answer": "Ringo Starr and George Harrison", "latency_ms": 270.676851272583, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4036}}}
{"qid": "-5004457603684974952", "question": "who is playing the halftime show at super bowl 2016", "gold_answers": ["Beyoncé", "Coldplay", "Bruno Mars"], "shots": {"0": {"k": 0, "answer": "Bruno Mars", "latency_ms": 100.20875930786133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Coldplay", "latency_ms": 84.87963676452637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "Coldplay", "latency_ms": 85.10279655456543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Coldplay", "latency_ms": 84.3806266784668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1958}, "4": {"k": 4, "answer": "Coldplay", "latency_ms": 115.73958396911621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2618}, "5": {"k": 5, "answer": "Coldplay with special guest performers Beyoncé and Bruno Mars", "latency_ms": 298.907995223999, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3252}, "6": {"k": 6, "answer": "Coldplay", "latency_ms": 153.63597869873047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3885}}}
{"qid": "7420920477821898435", "question": "to aru kagaku no railgun s episode 3", "gold_answers": ["Project Radio Noise"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 146.03948593139648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 157.78040885925293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 113.96026611328125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 130.4013729095459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 163.47861289978027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2457}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 164.67642784118652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3012}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 185.69135665893555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "7478795216476346339", "question": "who won the 2017 sports personality of the year", "gold_answers": ["Mo Farah"], "shots": {"0": {"k": 0, "answer": "Tayler Hill", "latency_ms": 132.54094123840332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 121.79303169250488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 113.2192611694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Roger Federer", "latency_ms": 101.21822357177734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Geraint Thomas", "latency_ms": 127.57539749145508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "Geraint Thomas", "latency_ms": 116.69564247131348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Geraint Thomas", "latency_ms": 130.1426887512207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3848}}}
{"qid": "7217222058435937287", "question": "where was the world economic forum held this year", "gold_answers": ["Davos"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.02979850769043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 88.47856521606445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 689}, "2": {"k": 2, "answer": "Davos-Klosters", "latency_ms": 121.71816825866699, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1362}, "3": {"k": 3, "answer": "Davos", "latency_ms": 130.57184219360352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1989}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 112.72454261779785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2674}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 127.20799446105957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3305}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 130.4950714111328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3945}}}
{"qid": "-143054837169120955", "question": "where are the giant redwoods located in california", "gold_answers": ["the coast of northern California", "Del Norte County", "Humboldt County"], "shots": {"0": {"k": 0, "answer": "Redwood National and State Parks", "latency_ms": 105.15546798706055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Humboldt Redwoods State Park", "latency_ms": 164.3831729888916, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 719}, "2": {"k": 2, "answer": "Redwood Mountain Grove, Kings Canyon National Park, Fresno County, California", "latency_ms": 277.09245681762695, "em": 0.0, "f1": 0.16666666666666669, "containment": 0.0, "context_chars": 1331}, "3": {"k": 3, "answer": "Redwood Mountain Grove in Kings Canyon National Park and the Giant Sequoia National Monument, Sierra Nevada, California.", "latency_ms": 420.38989067077637, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "Humboldt Redwoods State Park and Redwood Mountain Grove in Kings Canyon National Park and Giant Sequoia National Monument", "latency_ms": 418.3661937713623, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 2604}, "5": {"k": 5, "answer": "Redwood Mountain Grove in Kings Canyon National Park and Giant Sequoia National Monument, California", "latency_ms": 522.9456424713135, "em": 0.0, "f1": 0.11111111111111112, "containment": 0.0, "context_chars": 3249}, "6": {"k": 6, "answer": "Redwood Mountain Grove in Kings Canyon National Park and Giant Sequoia National Monument, California", "latency_ms": 505.74326515197754, "em": 0.0, "f1": 0.11111111111111112, "containment": 0.0, "context_chars": 3886}}}
{"qid": "4892429640540595424", "question": "who has made the most premier league appearances", "gold_answers": ["Gareth Barry"], "shots": {"0": {"k": 0, "answer": "Alan Shearer", "latency_ms": 130.15413284301758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gareth Barry", "latency_ms": 139.5707130432129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Gareth Barry", "latency_ms": 82.1835994720459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Gareth Barry", "latency_ms": 95.52240371704102, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1841}, "4": {"k": 4, "answer": "Gareth Barry", "latency_ms": 115.29850959777832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2429}, "5": {"k": 5, "answer": "Gareth Barry", "latency_ms": 132.16876983642578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3049}, "6": {"k": 6, "answer": "Gareth Barry", "latency_ms": 123.79217147827148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3636}}}
{"qid": "5533906981191706877", "question": "who was the first chief minister of west bengal", "gold_answers": ["Prafulla Chandra Ghosh"], "shots": {"0": {"k": 0, "answer": "P. C. Bagchi", "latency_ms": 134.21916961669922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Prafulla Chandra Ghosh", "latency_ms": 187.38913536071777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Prafulla Chandra Ghosh", "latency_ms": 209.9435329437256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1408}, "3": {"k": 3, "answer": "Prafulla Chandra Ghosh", "latency_ms": 195.93286514282227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2054}, "4": {"k": 4, "answer": "Prafulla Chandra Ghosh", "latency_ms": 198.64153861999512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2740}, "5": {"k": 5, "answer": "Prafulla Chandra Ghosh", "latency_ms": 183.65812301635742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3469}, "6": {"k": 6, "answer": "Prafulla Chandra Ghosh", "latency_ms": 267.4129009246826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4135}}}
{"qid": "8823076125131408628", "question": "who sings got my mind set on you", "gold_answers": ["George Harrison", "James Ray"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 97.24712371826172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 152.33731269836426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 95.66378593444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.75296592712402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 159.26265716552734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 129.2715072631836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 141.15071296691895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3640}}}
{"qid": "9168660859139861094", "question": "two main types of research methods used in psychology", "gold_answers": ["Correlational research", "Descriptive research", "quantitative data", "Quantitative psychological research", "qualitative", "quantitative", "Qualitative psychological research", "Experimental research", "qualitative data"], "shots": {"0": {"k": 0, "answer": "experimental and observational", "latency_ms": 184.46755409240723, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "qualitative, quantitative", "latency_ms": 174.13830757141113, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 735}, "2": {"k": 2, "answer": "qualitative and quantitative", "latency_ms": 117.2335147857666, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1482}, "3": {"k": 3, "answer": "qualitative and quantitative", "latency_ms": 131.70957565307617, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2285}, "4": {"k": 4, "answer": "qualitative and quantitative", "latency_ms": 159.22880172729492, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3089}, "5": {"k": 5, "answer": "qualitative and quantitative", "latency_ms": 176.20587348937988, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3898}, "6": {"k": 6, "answer": "qualitative and quantitative", "latency_ms": 194.5202350616455, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4640}}}
{"qid": "-7073063191952855764", "question": "who plays peter in what we do in the shadows", "gold_answers": ["Ben Fransham"], "shots": {"0": {"k": 0, "answer": "Matt Berry", "latency_ms": 87.41378784179688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 105.83877563476562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.41027450561523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 124.29261207580566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1911}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 146.9120979309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 173.81715774536133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 192.44980812072754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3859}}}
{"qid": "7901746249864619718", "question": "when does the 14th season of grey's anatomy come out", "gold_answers": ["September 28 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 143.9814567565918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 28, 2017", "latency_ms": 263.3223533630371, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 28, 2017", "latency_ms": 237.24889755249023, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1402}, "3": {"k": 3, "answer": "September 28, 2017", "latency_ms": 283.1149101257324, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 28, 2017", "latency_ms": 302.1245002746582, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2678}, "5": {"k": 5, "answer": "September 28, 2017", "latency_ms": 246.415376663208, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3366}, "6": {"k": 6, "answer": "September 28, 2017", "latency_ms": 282.93538093566895, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3962}}}
{"qid": "-896127746191949637", "question": "when was the first hunger games book published", "gold_answers": ["September 14 , 2008", "2008"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 83.47129821777344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 14, 2008", "latency_ms": 290.8492088317871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "September 14, 2008", "latency_ms": 212.0654582977295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1342}, "3": {"k": 3, "answer": "September 14, 2008", "latency_ms": 185.6546401977539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1941}, "4": {"k": 4, "answer": "September 14, 2008", "latency_ms": 377.37011909484863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2593}, "5": {"k": 5, "answer": "September 14, 2008", "latency_ms": 296.5278625488281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3243}, "6": {"k": 6, "answer": "September 14, 2008", "latency_ms": 260.56361198425293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3914}}}
{"qid": "8044909700499569711", "question": "how much is the united states in debt to china", "gold_answers": ["$1.06 trillion", "1,200.5"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 107.80978202819824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$1.16 trillion", "latency_ms": 201.98297500610352, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "$1.18 trillion", "latency_ms": 187.03961372375488, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "$1.18 trillion", "latency_ms": 219.74492073059082, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "$1.18 trillion", "latency_ms": 175.4298210144043, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "$1.18 trillion", "latency_ms": 231.14871978759766, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3223}, "6": {"k": 6, "answer": "$1.18 trillion", "latency_ms": 284.6717834472656, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3867}}}
{"qid": "-3123234845590594961", "question": "where did the race in grease take place", "gold_answers": ["Thunder Road"], "shots": {"0": {"k": 0, "answer": "California", "latency_ms": 74.61810111999512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles River", "latency_ms": 92.1182632446289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Los Angeles River", "latency_ms": 83.27221870422363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Los Angeles River, between the First and", "latency_ms": 222.98264503479004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1794}, "4": {"k": 4, "answer": "Los Angeles River, between the First and", "latency_ms": 263.2014751434326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2388}, "5": {"k": 5, "answer": "Los Angeles River, between the First and", "latency_ms": 328.98998260498047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3082}, "6": {"k": 6, "answer": "Los Angeles River, between the First and", "latency_ms": 220.46446800231934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3721}}}
{"qid": "4326992806019599297", "question": "what is the maximum data rate for the 802.11a standard select one", "gold_answers": ["54 Mbit / s"], "shots": {"0": {"k": 0, "answer": "54 Mbps", "latency_ms": 95.12877464294434, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "54 Mbit/s", "latency_ms": 101.87649726867676, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "54 Mbit/s", "latency_ms": 156.3091278076172, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "54 Mbit/s", "latency_ms": 172.6527214050293, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1900}, "4": {"k": 4, "answer": "54 Mbit/s", "latency_ms": 142.46797561645508, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2593}, "5": {"k": 5, "answer": "54 Mbit/s", "latency_ms": 208.4808349609375, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3293}, "6": {"k": 6, "answer": "54 Mbit/s", "latency_ms": 171.83494567871094, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3862}}}
{"qid": "6144099837933283715", "question": "a good that can be used in place of another good", "gold_answers": ["A substitute good", "substitute good"], "shots": {"0": {"k": 0, "answer": "substitute good", "latency_ms": 117.74230003356934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.91356468200684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 108.27422142028809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 118.99614334106445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 142.68898963928223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2496}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 160.11476516723633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "pickling salt", "latency_ms": 138.83495330810547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3602}}}
{"qid": "-4621948696356225060", "question": "where in the bible can i find the lord's prayer", "gold_answers": ["the Gospel of Luke", "the Gospel of Matthew"], "shots": {"0": {"k": 0, "answer": "Matthew 6:9-13", "latency_ms": 208.71829986572266, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matthew 6:9", "latency_ms": 175.16279220581055, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 544}, "2": {"k": 2, "answer": "Matthew 6:9", "latency_ms": 125.26869773864746, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1103}, "3": {"k": 3, "answer": "Matthew 6:9-13", "latency_ms": 223.90294075012207, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1684}, "4": {"k": 4, "answer": "Matthew 6:9-13", "latency_ms": 210.56032180786133, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2322}, "5": {"k": 5, "answer": "Matthew 6:9-13", "latency_ms": 284.6403121948242, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2876}, "6": {"k": 6, "answer": "Matthew 6:9-13", "latency_ms": 218.16563606262207, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3448}}}
{"qid": "6941993254369956277", "question": "when was the last time nebraska voted democrat", "gold_answers": ["1964"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 125.31805038452148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 143.1293487548828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "2006", "latency_ms": 211.72595024108887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "2006", "latency_ms": 111.01245880126953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2007}, "4": {"k": 4, "answer": "2006", "latency_ms": 149.40166473388672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2672}, "5": {"k": 5, "answer": "2006", "latency_ms": 149.72972869873047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3323}, "6": {"k": 6, "answer": "2006", "latency_ms": 151.37672424316406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3946}}}
{"qid": "-8955197065025093046", "question": "who become the ceo of it wipro company in 2016", "gold_answers": ["Abid Ali Neemuchwala"], "shots": {"0": {"k": 0, "answer": "Ajay Bhatia", "latency_ms": 142.9297924041748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Abidali Neemuchwala", "latency_ms": 272.41039276123047, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "Abidali Neemuchwala", "latency_ms": 180.61041831970215, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Abidali Neemuchwala", "latency_ms": 248.05784225463867, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "Abidali Neemuchwala", "latency_ms": 262.2494697570801, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Abidali Neemuchwala", "latency_ms": 201.829195022583, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3301}, "6": {"k": 6, "answer": "Abidali Neemuchwala", "latency_ms": 195.3909397125244, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3908}}}
{"qid": "-3010425579521817304", "question": "who does eric end up with in gossip girl", "gold_answers": ["Jenny"], "shots": {"0": {"k": 0, "answer": "Serena", "latency_ms": 53.60293388366699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 143.9533233642578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.62604331970215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 152.89902687072754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1903}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 210.75725555419922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2515}, "5": {"k": 5, "answer": "Jenny", "latency_ms": 164.6866798400879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3100}, "6": {"k": 6, "answer": "Dan Humphrey", "latency_ms": 185.11962890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3737}}}
{"qid": "7264112453286983469", "question": "who plays unis in she's the man", "gold_answers": ["Emily Perkins"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 95.06893157958984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.88829231262207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 125.31185150146484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 155.3030014038086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 125.8387565612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 181.4875602722168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 208.05120468139648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3761}}}
{"qid": "2627695648792729859", "question": "who played booster in jingle all the way", "gold_answers": ["Curtis Armstrong"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.30994033813477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 162.70947456359863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 113.85822296142578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 124.96185302734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 111.62948608398438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2568}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 144.90556716918945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3257}, "6": {"k": 6, "answer": "Tim Flattery", "latency_ms": 131.58369064331055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3938}}}
{"qid": "-9169976182548289414", "question": "who is recognized as the founder of islam", "gold_answers": ["the Islamic prophet Muhammad", "Muhammad"], "shots": {"0": {"k": 0, "answer": "Muhammad", "latency_ms": 54.090023040771484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Muhammad", "latency_ms": 81.50839805603027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 636}, "2": {"k": 2, "answer": "Muhammad", "latency_ms": 82.41534233093262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Muhammad", "latency_ms": 83.36186408996582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Muhammad", "latency_ms": 87.43762969970703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2549}, "5": {"k": 5, "answer": "Muhammad", "latency_ms": 142.62938499450684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Muhammad", "latency_ms": 114.81785774230957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3842}}}
{"qid": "-6696747560626271522", "question": "who plays emma in air bud world pup", "gold_answers": ["Brittany Paige Bouck"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 144.79303359985352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 88.71173858642578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 164.3526554107666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.21032524108887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Chantal Strand", "latency_ms": 132.7953338623047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 160.99977493286133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 176.08046531677246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3872}}}
{"qid": "5871681964137793716", "question": "how old was sasuke when his clan died", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 126.25718116760254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "seven", "latency_ms": 44.58332061767578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "7", "latency_ms": 103.92904281616211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "7", "latency_ms": 68.7403678894043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "7", "latency_ms": 138.838529586792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2479}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 147.2182273864746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3114}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 168.17235946655273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3692}}}
{"qid": "8552176802923865025", "question": "where do some of the natural air pollutants come from", "gold_answers": ["wildfires", "Dust", "Vegetation", "Carbon dioxide", "Volcanic activity"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 114.0131950378418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "volcanic eruptions", "latency_ms": 169.1575050354004, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity", "latency_ms": 564.3260478973389, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 1408}, "3": {"k": 3, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity", "latency_ms": 605.6244373321533, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 2128}, "4": {"k": 4, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity", "latency_ms": 675.2500534057617, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 2745}, "5": {"k": 5, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity", "latency_ms": 689.2807483673096, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 3349}, "6": {"k": 6, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity", "latency_ms": 514.6634578704834, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 4024}}}
{"qid": "-2630525064809360052", "question": "who is the pastor of new birth missionary baptist church now", "gold_answers": ["Stephen A. Davis"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 91.98212623596191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jamal Bryant", "latency_ms": 140.58327674865723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Jamal Bryant", "latency_ms": 83.2211971282959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1353}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 175.88114738464355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2018}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 130.54847717285156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2639}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 174.27682876586914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 168.9589023590088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3907}}}
{"qid": "6434931911289860123", "question": "who is doing 2018 super bowl half time show", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "Mark Ronson", "latency_ms": 77.25358009338379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Timberlake", "latency_ms": 117.13528633117676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "Justin Timberlake", "latency_ms": 132.14588165283203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Justin Timberlake", "latency_ms": 154.66880798339844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Justin Timberlake", "latency_ms": 112.32352256774902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Justin Timberlake", "latency_ms": 135.93506813049316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3237}, "6": {"k": 6, "answer": "Justin Timberlake", "latency_ms": 145.78628540039062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3890}}}
{"qid": "8869318258439148973", "question": "who is playing the halftime show for the superbowl", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 125.00739097595215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Janet Jackson and Justin Timberlake", "latency_ms": 236.83738708496094, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "Katy Perry and Lenny Kravitz", "latency_ms": 247.84374237060547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "Lady Gaga", "latency_ms": 82.50808715820312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1998}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 130.0184726715088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2630}, "5": {"k": 5, "answer": "Lady Gaga", "latency_ms": 118.42608451843262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "Lady Gaga", "latency_ms": 138.15045356750488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3891}}}
{"qid": "-8359866474144720253", "question": "who hosted they think it's all over", "gold_answers": ["Des Lynam", "Lee Mack", "comedian Nick Hancock", "Nick Hancock"], "shots": {"0": {"k": 0, "answer": "They Think It's All Over was hosted by Bob Barker.", "latency_ms": 309.0229034423828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 152.68778800964355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 114.04204368591309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 107.6059341430664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 139.85896110534668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2554}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 127.37917900085449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3179}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 140.60544967651367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3852}}}
{"qid": "-1206653570097564556", "question": "where does the movie proof of life take place", "gold_answers": ["The Republic of Tecala"], "shots": {"0": {"k": 0, "answer": "India", "latency_ms": 40.4202938079834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Republic of Tecala", "latency_ms": 118.31212043762207, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "Republic of Tecala", "latency_ms": 96.07982635498047, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "Republic of Tecala", "latency_ms": 108.45279693603516, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Republic of Tecala", "latency_ms": 160.18438339233398, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "Republic of Tecala", "latency_ms": 127.07757949829102, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3122}, "6": {"k": 6, "answer": "Republic of Tecala", "latency_ms": 130.631685256958, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3719}}}
{"qid": "6144521615402262404", "question": "where does us highway 1 start and end", "gold_answers": ["Fort Kent , Maine", "to Key West , Florida", "Key West , Florida"], "shots": {"0": {"k": 0, "answer": "U.S. Highway 1 starts in Miami, Florida, and ends in Bar Harbor, Maine.", "latency_ms": 371.2456226348877, "em": 0.0, "f1": 0.125, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 109.9083423614502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.09389305114746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Starts at U.S. Route 1 (Ocean Street) in Jacksonville, Florida; ends at Mackinaw City, Michigan.", "latency_ms": 505.3708553314209, "em": 0.0, "f1": 0.1111111111111111, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "Starts in Florida, ends in Michigan", "latency_ms": 227.02646255493164, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 2453}, "5": {"k": 5, "answer": "Starts in Jacksonville, Florida; ends in Mackinaw City, Michigan", "latency_ms": 399.04284477233887, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "Starts in Jacksonville, Florida; ends in Mackinaw City, Michigan", "latency_ms": 414.2909049987793, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 3658}}}
{"qid": "-8631190913794477985", "question": "who scored the most points in a single game in the nba", "gold_answers": ["Wilt Chamberlain"], "shots": {"0": {"k": 0, "answer": "Wilt Chamberlain", "latency_ms": 113.77167701721191, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wilt Chamberlain", "latency_ms": 135.5452537536621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "Wilt Chamberlain", "latency_ms": 147.49717712402344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1317}, "3": {"k": 3, "answer": "Wilt Chamberlain", "latency_ms": 173.67124557495117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1984}, "4": {"k": 4, "answer": "Wilt Chamberlain", "latency_ms": 182.2645664215088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2637}, "5": {"k": 5, "answer": "Wilt Chamberlain", "latency_ms": 147.89342880249023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3239}, "6": {"k": 6, "answer": "Wilt Chamberlain", "latency_ms": 208.5895538330078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3889}}}
{"qid": "199896377614951764", "question": "where is natural gas found in the us", "gold_answers": ["Texas", "Pennsylvania", "Colorado", "New Mexico", "West Virginia", "Arkansas", "Wyoming", "Louisiana"], "shots": {"0": {"k": 0, "answer": "Texas, North Dakota, Wyoming, Pennsylvania, and Utah", "latency_ms": 366.025447845459, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Marcellus Formation in the eastern United States", "latency_ms": 203.94659042358398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Marcellus Formation in Pennsylvania, West Virginia, eastern Ohio, and western New York", "latency_ms": 479.4583320617676, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1238}, "3": {"k": 3, "answer": "Marcellus Formation, Pennsylvania, West Virginia, eastern Ohio, western New York; offshore from Louisiana, Texas, California, and Alaska", "latency_ms": 577.1338939666748, "em": 0.0, "f1": 0.21052631578947367, "containment": 1.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Marcellus Formation, Pennsylvania, West Virginia, eastern Ohio, western New York; offshore from Louisiana, Texas, California, and Alaska; in Kansas (Elm Township)", "latency_ms": 881.3986778259277, "em": 0.0, "f1": 0.17391304347826084, "containment": 1.0, "context_chars": 2546}, "5": {"k": 5, "answer": "Marcellus Formation, Pennsylvania, West Virginia, eastern Ohio, western New York; offshore from Louisiana, Texas, California, and Alaska; in Kansas (Gas City)", "latency_ms": 854.2351722717285, "em": 0.0, "f1": 0.17391304347826084, "containment": 1.0, "context_chars": 3157}, "6": {"k": 6, "answer": "Marcellus Formation, Pennsylvania, West Virginia, eastern Ohio, western New York, offshore Louisiana, Texas, California, Alaska, Trenton Gas Field in Indiana, and northwest Ohio", "latency_ms": 860.3601455688477, "em": 0.0, "f1": 0.16, "containment": 1.0, "context_chars": 3764}}}
{"qid": "8986775680996674901", "question": "when were the first general elections held in independent india", "gold_answers": ["1951 -- 52"], "shots": {"0": {"k": 0, "answer": "15 August 1947", "latency_ms": 165.3754711151123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "January 1952", "latency_ms": 148.82755279541016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "1952", "latency_ms": 168.26295852661133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "1952", "latency_ms": 154.17861938476562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1939}, "4": {"k": 4, "answer": "1952", "latency_ms": 179.08477783203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2587}, "5": {"k": 5, "answer": "25 October 1951 to 21 February 1952", "latency_ms": 451.1065483093262, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 3250}, "6": {"k": 6, "answer": "1951–52", "latency_ms": 285.82310676574707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3915}}}
{"qid": "700604097171850168", "question": "what was the tower of london originally used for", "gold_answers": ["as a royal residence", "a royal residence"], "shots": {"0": {"k": 0, "answer": "Royal palace and fortress", "latency_ms": 156.7974090576172, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Military fortress and royal palace", "latency_ms": 124.84979629516602, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 568}, "2": {"k": 2, "answer": "timber fortification", "latency_ms": 130.4643154144287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "timber fortification enclosed by a palisade", "latency_ms": 283.9808464050293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1842}, "4": {"k": 4, "answer": "timber fortification enclosed by a palisade", "latency_ms": 323.23765754699707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2453}, "5": {"k": 5, "answer": "timber fortification enclosed by a palisade", "latency_ms": 265.4852867126465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3076}, "6": {"k": 6, "answer": "timber fortification enclosed by a palisade", "latency_ms": 207.61609077453613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3660}}}
{"qid": "6745303307988470742", "question": "what type of fuel goes in a zippo", "gold_answers": ["butane", "lighter fluid"], "shots": {"0": {"k": 0, "answer": "Zippo uses light fluid fuel.", "latency_ms": 164.83616828918457, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "lighter fluid or naphtha", "latency_ms": 127.40182876586914, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "lighter fluid or naphtha", "latency_ms": 187.77108192443848, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1202}, "3": {"k": 3, "answer": "naphtha", "latency_ms": 95.2003002166748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "naphtha or butane", "latency_ms": 204.4055461883545, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2473}, "5": {"k": 5, "answer": "naphtha or butane", "latency_ms": 224.84970092773438, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3158}, "6": {"k": 6, "answer": "naphtha or butane", "latency_ms": 208.05621147155762, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3845}}}
{"qid": "-2060506905455252030", "question": "first jnanpith award was an autor of which language", "gold_answers": ["Malayalam"], "shots": {"0": {"k": 0, "answer": "Kannada", "latency_ms": 83.99176597595215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bengali", "latency_ms": 80.7955265045166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 669}, "2": {"k": 2, "answer": "Bengali", "latency_ms": 143.42689514160156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "Konkani", "latency_ms": 98.71411323547363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1993}, "4": {"k": 4, "answer": "Konkani", "latency_ms": 165.44270515441895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2689}, "5": {"k": 5, "answer": "Bengali", "latency_ms": 128.9083957672119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3352}, "6": {"k": 6, "answer": "Bengali", "latency_ms": 199.73015785217285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4011}}}
{"qid": "4738663028303377024", "question": "who played the mad hatter in the batman tv show", "gold_answers": ["Roddy McDowall", "David Wayne", "Benedict Samuel"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 77.94332504272461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Benedict Samuel", "latency_ms": 156.7683219909668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 636}, "2": {"k": 2, "answer": "Benedict Samuel", "latency_ms": 112.13564872741699, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1245}, "3": {"k": 3, "answer": "David Warner", "latency_ms": 83.71281623840332, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1900}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 133.74805450439453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 143.1751251220703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3215}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 159.09528732299805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3870}}}
{"qid": "-1650946015201779846", "question": "how many cracker barrels in the united states", "gold_answers": ["639", "more than 600"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 113.18111419677734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "645", "latency_ms": 126.25718116760254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "645", "latency_ms": 151.56221389770508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "645", "latency_ms": 112.66827583312988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1941}, "4": {"k": 4, "answer": "645", "latency_ms": 121.14453315734863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2608}, "5": {"k": 5, "answer": "645", "latency_ms": 148.78249168395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3233}, "6": {"k": 6, "answer": "645", "latency_ms": 154.21485900878906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3850}}}
{"qid": "-3422350952909582054", "question": "in photosynthesis the carbon in co2 is initially fixed to what molecule", "gold_answers": ["3 - phosphoglycerate"], "shots": {"0": {"k": 0, "answer": "3-phosphoglycerate", "latency_ms": 215.81029891967773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 301.15818977355957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 712}, "2": {"k": 2, "answer": "ribulose 1,5-bisphosphate", "latency_ms": 267.7748203277588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1441}, "3": {"k": 3, "answer": "ribulose 1,5-bisphosphate", "latency_ms": 379.06694412231445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2110}, "4": {"k": 4, "answer": "ribulose 1,5-bisphosphate", "latency_ms": 256.4501762390137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2820}, "5": {"k": 5, "answer": "ribulose-1,5-bisphosphate", "latency_ms": 353.4877300262451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3515}, "6": {"k": 6, "answer": "ribulose 1,5-bisphosphate", "latency_ms": 379.183292388916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4316}}}
{"qid": "-2704708103393811482", "question": "who voices randy in f is for family", "gold_answers": ["T.J. Miller"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 95.65377235412598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parker", "latency_ms": 58.49409103393555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "Parker", "latency_ms": 82.19742774963379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 125.52666664123535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "April Stewart", "latency_ms": 89.76387977600098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2522}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 149.37090873718262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3151}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 141.69025421142578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3804}}}
{"qid": "5482012214308896475", "question": "how many countries does cadbury sell its products", "gold_answers": ["more than 50", "more than 50 countries worldwide"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 130.65385818481445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "more than 50 countries", "latency_ms": 180.3302764892578, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 706}, "2": {"k": 2, "answer": "more than 50 countries", "latency_ms": 191.2229061126709, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 1405}, "3": {"k": 3, "answer": "more than 50 countries", "latency_ms": 151.89433097839355, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 2039}, "4": {"k": 4, "answer": "more than 50 countries", "latency_ms": 189.7587776184082, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 2743}, "5": {"k": 5, "answer": "more than 50 countries", "latency_ms": 189.14031982421875, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 3397}, "6": {"k": 6, "answer": "more than 50 countries", "latency_ms": 281.66675567626953, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 4010}}}
{"qid": "-5737509619250561344", "question": "ethiopia flight 961 crashes in to the sea", "gold_answers": ["23 November 1996"], "shots": {"0": {"k": 0, "answer": "1996", "latency_ms": 148.604154586792, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indian Ocean", "latency_ms": 63.99178504943848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Indian Ocean near Grande Comore, Comoros Islands", "latency_ms": 351.92275047302246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Indian Ocean near Comoros Islands", "latency_ms": 283.679723739624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Indian Ocean near Comoros Islands", "latency_ms": 216.3064479827881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2507}, "5": {"k": 5, "answer": "Mitsamiouli", "latency_ms": 189.8019313812256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "Mitsamiouli", "latency_ms": 207.197904586792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3779}}}
{"qid": "-7175456993713717070", "question": "what does istj mean in a personality test", "gold_answers": ["Extroverted Thinking ( Te )", "Extroverted Intuition ( Ne )", "Introverted Feeling ( Fi )", "Introverted Sensing ( Si )"], "shots": {"0": {"k": 0, "answer": "ISTJ", "latency_ms": 53.65252494812012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ISTJ is a personality type in the Myers-Briggs Type Indicator.", "latency_ms": 367.297887802124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 724}, "2": {"k": 2, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 210.18695831298828, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 302.0622730255127, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2085}, "4": {"k": 4, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 281.6050052642822, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2713}, "5": {"k": 5, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 213.03439140319824, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3424}, "6": {"k": 6, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 270.83325386047363, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4140}}}
{"qid": "4437170343606050664", "question": "who does the voice of ash in sing", "gold_answers": ["Scarlett Johansson"], "shots": {"0": {"k": 0, "answer": "John Mulaney", "latency_ms": 68.1450366973877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Veronica Taylor", "latency_ms": 116.81652069091797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "Veronica Taylor", "latency_ms": 115.27729034423828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "Veronica Taylor", "latency_ms": 116.38355255126953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "Rica Matsumoto", "latency_ms": 207.55982398986816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2484}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 143.42546463012695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3133}, "6": {"k": 6, "answer": "Rica Matsumoto", "latency_ms": 167.0079231262207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3720}}}
{"qid": "-8773010039077552394", "question": "who scored the most points in their nba career", "gold_answers": ["Kareem Abdul - Jabbar"], "shots": {"0": {"k": 0, "answer": "Kareem Abdul-Jabbar", "latency_ms": 153.93781661987305, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Jordan", "latency_ms": 98.77610206604004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 146.87490463256836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "Michael Jordan", "latency_ms": 114.79377746582031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 132.64775276184082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2437}, "5": {"k": 5, "answer": "Michael Jordan", "latency_ms": 158.53500366210938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3014}, "6": {"k": 6, "answer": "Kareem Abdul-Jabbar", "latency_ms": 216.29571914672852, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3668}}}
{"qid": "-3278224144622911032", "question": "with a land area of 54 314 square miles where does wisconsin rank among the 50 states", "gold_answers": ["25"], "shots": {"0": {"k": 0, "answer": "10th", "latency_ms": 65.25492668151855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 124.1607666015625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 140.77377319335938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 157.11069107055664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1760}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 180.5713176727295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2347}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 210.51549911499023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2958}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 158.20813179016113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3557}}}
{"qid": "-3466298422174960041", "question": "who plays charles on have and have nots", "gold_answers": ["Nick Sager", "Nick Sagar"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 89.95437622070312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 111.82308197021484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 127.00867652893066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 142.93861389160156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1899}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 159.3029499053955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 179.901123046875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Peter Parros", "latency_ms": 129.11343574523926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3753}}}
{"qid": "1803248910342766083", "question": "who wrote the book my country my life", "gold_answers": ["L.K. Advani"], "shots": {"0": {"k": 0, "answer": "Nelson Mandela", "latency_ms": 93.6589241027832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "L. K. Advani", "latency_ms": 149.28174018859863, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "L. K. Advani", "latency_ms": 168.0591106414795, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1158}, "3": {"k": 3, "answer": "L. K. Advani", "latency_ms": 290.4703617095947, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1789}, "4": {"k": 4, "answer": "L. K. Advani", "latency_ms": 222.1701145172119, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2455}, "5": {"k": 5, "answer": "L. K. Advani", "latency_ms": 253.57532501220703, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3098}, "6": {"k": 6, "answer": "L. K. Advani", "latency_ms": 293.3311462402344, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3679}}}
{"qid": "-1176280233636154422", "question": "when did the east india company take control of india", "gold_answers": ["1757", "1799", "1612", "in 1757"], "shots": {"0": {"k": 0, "answer": "1757", "latency_ms": 107.17320442199707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1757", "latency_ms": 118.0260181427002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "1695", "latency_ms": 136.86037063598633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1349}, "3": {"k": 3, "answer": "1858", "latency_ms": 160.1102352142334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1967}, "4": {"k": 4, "answer": "1818", "latency_ms": 177.29806900024414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2622}, "5": {"k": 5, "answer": "1818", "latency_ms": 205.76024055480957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3285}, "6": {"k": 6, "answer": "1818", "latency_ms": 148.98943901062012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3920}}}
{"qid": "5911119091653953181", "question": "where does the water come from to fill lake eyre", "gold_answers": ["Warburton River"], "shots": {"0": {"k": 0, "answer": "rainfall and inflows from surrounding rivers and groundwater", "latency_ms": 183.7449073791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "west, Channel Country of Queensland", "latency_ms": 149.4464874267578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "western rivers catchment of the Lake Eyre Drainage basin, including the Channel Country of Queensland, Finke River, Peake Creek, and Neales River", "latency_ms": 687.8957748413086, "em": 0.0, "f1": 0.09090909090909091, "containment": 0.0, "context_chars": 1179}, "3": {"k": 3, "answer": "Warburton River, Channel Country of Queensland, Peake Creek, Neales River, Finke River (via Macumba)", "latency_ms": 515.1910781860352, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 1776}, "4": {"k": 4, "answer": "Warburton River, Finke River via Macumba, Peake Creek, Neales River, and local rain", "latency_ms": 594.0415859222412, "em": 0.0, "f1": 0.2666666666666667, "containment": 1.0, "context_chars": 2407}, "5": {"k": 5, "answer": "Warburton River, Finke River, Cooper Creek, Peake Creek, Neales River, and rainfall", "latency_ms": 638.8323307037354, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 3028}, "6": {"k": 6, "answer": "Warburton River, Finke River, Cooper Creek, Peake Creek, Neales River, Channel Country of Queensland, Eyre Creek, Diamantina, Georgina rivers, local rain", "latency_ms": 955.1887512207031, "em": 0.0, "f1": 0.17391304347826084, "containment": 1.0, "context_chars": 3610}}}
{"qid": "5557104327881436095", "question": "who is the founder of google and when was it founded", "gold_answers": ["1998", "Sergey Brin", "Larry Page and Sergey Brin", "Larry Page"], "shots": {"0": {"k": 0, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 330.1544189453125, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Larry Page and Sergey Brin", "latency_ms": 201.57694816589355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 680}, "2": {"k": 2, "answer": "Larry Page and Sergey Brin; September 4, 1998", "latency_ms": 330.05428314208984, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 1358}, "3": {"k": 3, "answer": "Larry Page and Sergey Brin, September 1998", "latency_ms": 388.0736827850342, "em": 0.0, "f1": 0.8333333333333333, "containment": 1.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Larry Page and Sergey Brin, September 1998", "latency_ms": 342.0412540435791, "em": 0.0, "f1": 0.8333333333333333, "containment": 1.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 414.1838550567627, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 449.79238510131836, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 3946}}}
{"qid": "-1333328812971005142", "question": "who did the dominican republic gain its independence from", "gold_answers": ["Haiti"], "shots": {"0": {"k": 0, "answer": "Spain", "latency_ms": 54.32248115539551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haiti", "latency_ms": 76.05671882629395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 635}, "2": {"k": 2, "answer": "Haiti", "latency_ms": 83.5425853729248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Haiti", "latency_ms": 112.65254020690918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2010}, "4": {"k": 4, "answer": "Haiti", "latency_ms": 104.13503646850586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2696}, "5": {"k": 5, "answer": "Haiti", "latency_ms": 117.12837219238281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3404}, "6": {"k": 6, "answer": "Haiti", "latency_ms": 153.6731719970703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4073}}}
{"qid": "1122605495295045742", "question": "how did early humans make use of stones during the prehistoric period", "gold_answers": ["start fires", "hunt", "bury their dead"], "shots": {"0": {"k": 0, "answer": "Chipped and shaped for tools", "latency_ms": 115.66662788391113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "made tools with an edge, a point, or a percussion surface", "latency_ms": 251.3418197631836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "made implements with an edge, a point, or a percussion surface", "latency_ms": 359.69042778015137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "made implements with an edge, a point, or a percussion surface", "latency_ms": 263.94033432006836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "made implements with an edge, a point, or a percussion surface", "latency_ms": 264.48917388916016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "made implements with an edge, a point, or a percussion surface", "latency_ms": 290.1639938354492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3211}, "6": {"k": 6, "answer": "made implements with an edge, a point, or a percussion surface", "latency_ms": 298.5517978668213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3865}}}
{"qid": "7402184777947527945", "question": "who wrote the text for jeanie with the light brown hair", "gold_answers": ["Stephen Foster"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 145.0052261352539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stephen Foster", "latency_ms": 63.16018104553223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Stephen Foster", "latency_ms": 70.44577598571777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Stephen Foster", "latency_ms": 82.35430717468262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Stephen Foster", "latency_ms": 121.8109130859375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2522}, "5": {"k": 5, "answer": "Stephen Foster", "latency_ms": 125.11253356933594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Stephen Foster", "latency_ms": 115.0054931640625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3844}}}
{"qid": "1656745334095178455", "question": "the basic steps of rational decision making include defining goals and", "gold_answers": ["Implementation of plans / policies"], "shots": {"0": {"k": 0, "answer": "identifying alternatives", "latency_ms": 66.5287971496582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "defining goals and verifying the problem", "latency_ms": 141.60561561584473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 774}, "2": {"k": 2, "answer": "defining goals and problem identification", "latency_ms": 138.15736770629883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1428}, "3": {"k": 3, "answer": "defining goals and problem identification", "latency_ms": 207.1242332458496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2194}, "4": {"k": 4, "answer": "defining goals and information gathering", "latency_ms": 202.0881175994873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2912}, "5": {"k": 5, "answer": "defining goals and information gathering", "latency_ms": 301.3923168182373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3568}, "6": {"k": 6, "answer": "defining goals and problem identification", "latency_ms": 173.2938289642334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4256}}}
{"qid": "-216657635823030751", "question": "when was the design period known as art deco", "gold_answers": ["1910 -- 1939"], "shots": {"0": {"k": 0, "answer": "1920s–1930s", "latency_ms": 231.95195198059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "just before World War I", "latency_ms": 163.38729858398438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "just before World War I", "latency_ms": 157.3648452758789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1362}, "3": {"k": 3, "answer": "1920s through the 1930s", "latency_ms": 365.2369976043701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2065}, "4": {"k": 4, "answer": "1920s through the 1930s", "latency_ms": 519.5467472076416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2695}, "5": {"k": 5, "answer": "1920s through the 1930s", "latency_ms": 314.0146732330322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3358}, "6": {"k": 6, "answer": "1920s through the 1930s", "latency_ms": 346.49062156677246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4026}}}
{"qid": "250542332339248886", "question": "where does the bob and tom show broadcast from", "gold_answers": ["WFBQ in Indianapolis , Indiana", "Indianapolis , Indiana"], "shots": {"0": {"k": 0, "answer": "Winston-Salem, North Carolina", "latency_ms": 186.46979331970215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indianapolis, Indiana", "latency_ms": 89.43843841552734, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 211.23266220092773, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 257.6866149902344, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 313.62128257751465, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2510}, "5": {"k": 5, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 205.366849899292, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3150}, "6": {"k": 6, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 229.48265075683594, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3764}}}
{"qid": "7610758795954724809", "question": "star wars the clone wars season 3 episode 1", "gold_answers": ["Clone Cadets"], "shots": {"0": {"k": 0, "answer": "\"The Clone Wars: Season 3, Episode 1\"", "latency_ms": 223.0842113494873, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nightsisters", "latency_ms": 76.84803009033203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "Nightsisters", "latency_ms": 83.23860168457031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "Nightsisters", "latency_ms": 95.43180465698242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1944}, "4": {"k": 4, "answer": "Nightsisters", "latency_ms": 99.61724281311035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "Nightsisters", "latency_ms": 113.74998092651367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3244}, "6": {"k": 6, "answer": "Nightsisters", "latency_ms": 174.55554008483887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3929}}}
{"qid": "2997223939033016160", "question": "what part of brain is responsible for complex thinking", "gold_answers": ["the frontal lobe"], "shots": {"0": {"k": 0, "answer": "prefrontal cortex", "latency_ms": 78.90558242797852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "cerebral cortex", "latency_ms": 83.22787284851074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "cerebral cortex", "latency_ms": 95.99184989929199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1350}, "3": {"k": 3, "answer": "cerebral cortex", "latency_ms": 107.84125328063965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2063}, "4": {"k": 4, "answer": "cerebral cortex", "latency_ms": 163.78498077392578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2760}, "5": {"k": 5, "answer": "cerebral cortex", "latency_ms": 126.46031379699707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3464}, "6": {"k": 6, "answer": "cerebral cortex", "latency_ms": 130.4473876953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4139}}}
{"qid": "2680196226239522881", "question": "who won the champions league final in 2016", "gold_answers": ["Real Madrid"], "shots": {"0": {"k": 0, "answer": "Real Madrid", "latency_ms": 53.5283088684082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Real Madrid", "latency_ms": 63.854217529296875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Real Madrid", "latency_ms": 70.42694091796875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Real Madrid", "latency_ms": 82.05223083496094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1884}, "4": {"k": 4, "answer": "Real Madrid", "latency_ms": 164.61753845214844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2504}, "5": {"k": 5, "answer": "Real Madrid", "latency_ms": 103.50704193115234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3170}, "6": {"k": 6, "answer": "Real Madrid", "latency_ms": 116.82438850402832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3796}}}
{"qid": "-8458006812258546025", "question": "who has the most gold medals in the winter olympics of all time", "gold_answers": ["Norway"], "shots": {"0": {"k": 0, "answer": "Cross-country skier, Norwegian, with 12 gold medals.", "latency_ms": 208.48941802978516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Norway", "latency_ms": 124.57108497619629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "Norway", "latency_ms": 69.91410255432129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1210}, "3": {"k": 3, "answer": "Canada", "latency_ms": 69.45252418518066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 112.37072944641113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2397}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 126.16848945617676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3110}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 130.82122802734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3716}}}
