{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Rita Skeeter", "latency_ms": 125.27012825012207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 141.6165828704834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 159.58428382873535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1189}, "3": {"k": 3, "answer": "Rita Skeeter", "latency_ms": 124.9384880065918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1804}, "4": {"k": 4, "answer": "Emma Watson", "latency_ms": 102.63752937316895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 125.47183036804199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3041}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 164.6280288696289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3687}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.12063598632812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 113.03472518920898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 107.06853866577148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 107.99098014831543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 164.01982307434082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2422}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 126.4500617980957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2994}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 209.72204208374023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3594}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwestern United States and Mexico", "latency_ms": 145.7984447479248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 190.7055377960205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 240.16451835632324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 319.9937343597412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1902}, "4": {"k": 4, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 308.38823318481445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 266.25776290893555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3213}, "6": {"k": 6, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 453.0067443847656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3866}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 137.27188110351562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Karl Seitz", "latency_ms": 77.90064811706543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Jawaharlal Nehru", "latency_ms": 116.70136451721191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Jawaharlal Nehru", "latency_ms": 227.54549980163574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2011}, "4": {"k": 4, "answer": "Dr. Rajendra Prasad", "latency_ms": 151.02601051330566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2756}, "5": {"k": 5, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 243.5605525970459, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3455}, "6": {"k": 6, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 184.64899063110352, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4101}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 140.67792892456055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 88.6845588684082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.01593017578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 147.6426124572754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 143.54753494262695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2525}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 133.8827610015869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3215}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 190.46926498413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3827}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "2001", "latency_ms": 128.81827354431152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2001", "latency_ms": 148.6506462097168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "2001", "latency_ms": 157.75132179260254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "2001", "latency_ms": 97.8083610534668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "2001", "latency_ms": 131.60395622253418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "2001", "latency_ms": 147.78947830200195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3112}, "6": {"k": 6, "answer": "2001", "latency_ms": 130.76305389404297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3738}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 116.64366722106934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wednesday at 8:00 PM", "latency_ms": 188.61126899719238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.79841995239258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 157.50646591186523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 159.1012477874756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2653}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 150.56490898132324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 178.49969863891602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3894}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 102.31685638427734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 99.58815574645996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "the episode \"Yes/No\"", "latency_ms": 239.8974895477295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 241.61314964294434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1775}, "4": {"k": 4, "answer": "\"Hell-O\"", "latency_ms": 151.22032165527344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2338}, "5": {"k": 5, "answer": "\"Hell-O\"", "latency_ms": 126.49106979370117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2957}, "6": {"k": 6, "answer": "\"Will and Emma try to start a relationship, but after he finds out that she's a virgin, they take a break.\"", "latency_ms": 525.2203941345215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3580}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 128.54790687561035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 145.82276344299316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 168.5469150543213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 111.93227767944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 131.10923767089844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2450}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 157.35602378845215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3058}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 170.74036598205566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3696}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana, Cuba", "latency_ms": 126.83582305908203, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Havana harbor", "latency_ms": 129.67467308044434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "Havana, Cuba", "latency_ms": 160.8293056488037, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Havana Harbor", "latency_ms": 95.1852798461914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1879}, "4": {"k": 4, "answer": "Havana Harbor", "latency_ms": 121.46949768066406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2451}, "5": {"k": 5, "answer": "Havana Harbor", "latency_ms": 112.96248435974121, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3067}, "6": {"k": 6, "answer": "Havana Harbor", "latency_ms": 145.39527893066406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3641}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Shiva", "latency_ms": 77.75068283081055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 99.50709342956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 162.8432273864746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Anant Chaturdashi is not specifically celebrated in honour of a god. It is a festival observed by Jains and Hindus, primarily marking the end of Paryushana for Digambara Jains. The context does not specify a particular deity. \n\nI cannot answer.", "latency_ms": 1289.6013259887695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "Anant Chaturdashi is not specifically celebrated in honour of a single god. It is a festival observed by both Jains and Hindus, with significance in the Jain calendar, particularly as the last day of Paryushana. While it is associated with Jain traditions, it is not primarily dedicated to a specific deity like Vishnu or Shiva. Therefore, based on the context, no specific god is highlighted as the focus of Anant Chaturdashi. \n\nI cannot answer.", "latency_ms": 1615.6818866729736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Anant Chaturdashi is not celebrated in honour of a specific god. It is a festival observed by Jains and Hindus, with significance in the Jain calendar, particularly as the last day of Paryushana. While it is associated with Jain traditions, it is not primarily dedicated to a specific deity like Vishnu or Shiva. The context does not specify a god for which Anant Chaturdashi is celebrated. \n\nI cannot answer.", "latency_ms": 1855.8714389801025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 229.89320755004883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3868}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Belize, Guatemala, Honduras, Nicaragua, Costa Rica", "latency_ms": 192.42429733276367, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 84.42521095275879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 555}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 90.5449390411377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1164}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 96.8787670135498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 140.30146598815918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2447}, "5": {"k": 5, "answer": "Belize, Guatemala", "latency_ms": 128.75699996948242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3107}, "6": {"k": 6, "answer": "Belize, Guatemala, Honduras, Nicaragua, Costa Rica", "latency_ms": 221.67015075683594, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3740}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "compound-complex sentence", "latency_ms": 105.33547401428223, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "complex sentence", "latency_ms": 68.83883476257324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 704}, "2": {"k": 2, "answer": "complex sentence", "latency_ms": 64.39638137817383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1360}, "3": {"k": 3, "answer": "complex sentence", "latency_ms": 71.72513008117676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2042}, "4": {"k": 4, "answer": "complex sentence", "latency_ms": 86.4267349243164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2701}, "5": {"k": 5, "answer": "complex sentence", "latency_ms": 100.25668144226074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3365}, "6": {"k": 6, "answer": "complex sentence", "latency_ms": 103.5299301147461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4053}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "economic systems and trade principles", "latency_ms": 93.50013732910156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The division of labour, productivity, and free markets", "latency_ms": 212.23211288452148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "The Wealth of Nations was about the nature and causes of the wealth of nations, including topics like the division of labour, productivity, and free markets.", "latency_ms": 491.35446548461914, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of the wealth of nations, including topics like the division of labour, productivity, and free markets.", "latency_ms": 565.582275390625, "em": 0.0, "f1": 0.14814814814814817, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of the wealth of nations, including topics like the division of labour, productivity, and free markets.", "latency_ms": 548.3932495117188, "em": 0.0, "f1": 0.14814814814814817, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of the wealth of nations, including topics such as the division of labour, productivity, and free markets.", "latency_ms": 791.358232498169, "em": 0.0, "f1": 0.14285714285714285, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of national wealth, including topics like the division of labour, productivity, and free markets.", "latency_ms": 572.6108551025391, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 3884}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 78.87554168701172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 108.01315307617188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "August 28, 2018", "latency_ms": 185.60004234313965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 239.06779289245605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 256.84428215026855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2414}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 205.73806762695312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3034}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 279.86788749694824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3625}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Southern Hemisphere, Eastern Hemisphere, Oceania region", "latency_ms": 202.8944492340088, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean", "latency_ms": 235.9464168548584, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean", "latency_ms": 403.6581516265869, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1341}, "3": {"k": 3, "answer": "sixth largest country, Oceania", "latency_ms": 285.6476306915283, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2029}, "4": {"k": 4, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean", "latency_ms": 494.1880702972412, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2753}, "5": {"k": 5, "answer": "sixth largest country, Oceania, between the Indian and South Pacific Oceans", "latency_ms": 357.33723640441895, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 3452}, "6": {"k": 6, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean", "latency_ms": 345.30091285705566, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4028}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Padmé Amidala", "latency_ms": 143.56017112731934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Leia", "latency_ms": 58.345794677734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Leia", "latency_ms": 130.7830810546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "Leia", "latency_ms": 85.67285537719727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "Leia", "latency_ms": 85.36314964294434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2435}, "5": {"k": 5, "answer": "Sabi Sebatynee", "latency_ms": 213.06347846984863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3055}, "6": {"k": 6, "answer": "Mara Jade", "latency_ms": 163.62762451171875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3620}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Ralph Edwards", "latency_ms": 115.28515815734863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 154.03342247009277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Barry Cryer", "latency_ms": 176.2223243713379, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1167}, "3": {"k": 3, "answer": "Barry Cryer", "latency_ms": 108.86859893798828, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1717}, "4": {"k": 4, "answer": "Barry Cryer", "latency_ms": 140.6726837158203, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2312}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 145.16305923461914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2905}, "6": {"k": 6, "answer": "Allen Ludden", "latency_ms": 121.62327766418457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3488}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "mitochondria", "latency_ms": 66.37310981750488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "mitochondria", "latency_ms": 118.5922622680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "mitochondria", "latency_ms": 84.24878120422363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1387}, "3": {"k": 3, "answer": "mitochondria", "latency_ms": 130.42020797729492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2044}, "4": {"k": 4, "answer": "mitochondria", "latency_ms": 99.85113143920898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "mitochondrion", "latency_ms": 126.25479698181152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3429}, "6": {"k": 6, "answer": "mitochondrion", "latency_ms": 130.97333908081055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4103}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.30462265014648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 141.18218421936035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 753}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 90.59309959411621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1483}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 98.15764427185059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2186}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 109.74645614624023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2895}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 181.0777187347412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3588}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 127.71940231323242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4332}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.59382438659668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "10cc", "latency_ms": 77.00777053833008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 114.39132690429688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1156}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 125.66280364990234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1740}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 141.4189338684082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2320}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 158.6921215057373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2925}, "6": {"k": 6, "answer": "Dottie West and Kenny Rogers", "latency_ms": 272.7317810058594, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3512}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 105.49664497375488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "36 months", "latency_ms": 97.55444526672363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 601}, "2": {"k": 2, "answer": "36 months", "latency_ms": 93.7948226928711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "36 months", "latency_ms": 99.82728958129883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1765}, "4": {"k": 4, "answer": "36 months", "latency_ms": 101.90606117248535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "36 months", "latency_ms": 99.93481636047363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3064}, "6": {"k": 6, "answer": "36 months", "latency_ms": 113.5859489440918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3657}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 78.98235321044922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "three-part", "latency_ms": 57.69181251525879, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 652}, "2": {"k": 2, "answer": "three-part", "latency_ms": 71.24042510986328, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1268}, "3": {"k": 3, "answer": "three-part", "latency_ms": 103.91831398010254, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "three-part", "latency_ms": 85.662841796875, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2532}, "5": {"k": 5, "answer": "three-part BBC drama", "latency_ms": 128.28540802001953, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3179}, "6": {"k": 6, "answer": "three-part BBC drama", "latency_ms": 129.03833389282227, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3783}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Vivien Leigh, Ian McKellen, Orlando Bloom, Sean Astin, Dominic Monaghan, and Billy Boyd", "latency_ms": 409.15679931640625, "em": 0.0, "f1": 0.2352941176470588, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.52856063842773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 141.90363883972168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Elijah Wood, Ian Holm, Christopher Lee, Hugo Weaving, Cate Blanchett, Orlando Bloom, Andy Serkis", "latency_ms": 470.9506034851074, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 1957}, "4": {"k": 4, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 374.29094314575195, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 2623}, "5": {"k": 5, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 455.72948455810547, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 421.2803840637207, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 3815}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 90.11411666870117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 111.02080345153809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 128.78084182739258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1180}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 142.75336265563965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1773}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 160.48169136047363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2402}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 183.13002586364746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3124}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 157.36746788024902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3753}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 113.74902725219727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 135.78462600708008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 147.98736572265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 176.12004280090332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1875}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 207.7958583831787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2446}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 146.5613842010498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3078}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 160.9640121459961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3649}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "To protect her from the injustices of the world and to fulfill his moral duty.", "latency_ms": 378.232479095459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "To rescue her from being sold and to provide her with a better life.", "latency_ms": 380.784273147583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "To protect her and provide her with a better life.", "latency_ms": 249.03392791748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "To protect her from the Thénardiers' abuse and to give her a better life.", "latency_ms": 563.3177757263184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "To protect her from the Thénardiers' abuse and to give her a better life.", "latency_ms": 351.4702320098877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "To protect her from the Thénardiers' abuse and to give her a better life.", "latency_ms": 404.8795700073242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "To protect her and provide her with a better life after the Thénardiers mistreated her.", "latency_ms": 467.04792976379395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3717}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.44273948669434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.79769325256348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.51613235473633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1391}, "3": {"k": 3, "answer": "China", "latency_ms": 69.50116157531738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "China", "latency_ms": 142.95172691345215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2779}, "5": {"k": 5, "answer": "China", "latency_ms": 88.72270584106445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3516}, "6": {"k": 6, "answer": "China, Russia", "latency_ms": 117.89131164550781, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4217}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 77.38947868347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to consolidate Bantu education and uniformly implement discriminatory educational practices", "latency_ms": 175.51207542419434, "em": 0.0, "f1": 0.13333333333333333, "containment": 0.0, "context_chars": 714}, "2": {"k": 2, "answer": "to consolidate Bantu education so that discriminatory educational practices could be uniformly implemented across South Africa", "latency_ms": 419.11911964416504, "em": 0.0, "f1": 0.09523809523809523, "containment": 0.0, "context_chars": 1413}, "3": {"k": 3, "answer": "to consolidate Bantu education so that discriminatory educational practices could be uniformly implemented across South Africa", "latency_ms": 440.72842597961426, "em": 0.0, "f1": 0.09523809523809523, "containment": 0.0, "context_chars": 2090}, "4": {"k": 4, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 417.5124168395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 473.5455513000488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 447.36647605895996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4022}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Python", "latency_ms": 52.752017974853516, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kaa is a giant python.", "latency_ms": 262.4857425689697, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Kaa is a giant python.", "latency_ms": 179.61573600769043, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Kaa is a snake.", "latency_ms": 192.28219985961914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1783}, "4": {"k": 4, "answer": "Kaa is a snake.", "latency_ms": 199.79119300842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2399}, "5": {"k": 5, "answer": "Kaa is a python.", "latency_ms": 286.3621711730957, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2984}, "6": {"k": 6, "answer": "Kaa is a snake in The Jungle Book.", "latency_ms": 289.12973403930664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3596}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "water ice and carbon dioxide ice", "latency_ms": 201.59363746643066, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "dry ice", "latency_ms": 91.40610694885254, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "dry ice", "latency_ms": 85.27421951293945, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "dry ice", "latency_ms": 152.00257301330566, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "carbon dioxide ice", "latency_ms": 113.55328559875488, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2481}, "5": {"k": 5, "answer": "carbon dioxide ice", "latency_ms": 116.55306816101074, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "water ice mixed with dust", "latency_ms": 197.43633270263672, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3697}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 89.5693302154541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "when Elena opens her eyes in the hospital", "latency_ms": 249.30429458618164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Elena turns into a vampire in the third season of The Vampire Diaries.", "latency_ms": 400.12335777282715, "em": 0.0, "f1": 0.16666666666666669, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "during the last moments of season three", "latency_ms": 232.36918449401855, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1814}, "4": {"k": 4, "answer": "during transition in season four", "latency_ms": 255.32960891723633, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2378}, "5": {"k": 5, "answer": "during transition in season four", "latency_ms": 161.3631248474121, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2940}, "6": {"k": 6, "answer": "during the last moments of season three", "latency_ms": 246.57106399536133, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3519}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 78.35578918457031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 133.09359550476074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "Premier League and Championship teams get first pick in the Third Round Proper.", "latency_ms": 365.17786979675293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "club drawn first", "latency_ms": 95.8559513092041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1789}, "4": {"k": 4, "answer": "Clubs in the Premier League enter the FA Cup in the third round and are drawn randomly out of a hat with the remaining clubs.", "latency_ms": 589.7016525268555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2360}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 191.9271945953369, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2964}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 210.74199676513672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3567}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Ward 8", "latency_ms": 97.1064567565918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington, D.C.", "latency_ms": 144.317626953125, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "Washington, D.C.", "latency_ms": 212.16630935668945, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Washington, D.C.", "latency_ms": 256.5474510192871, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Northwest Washington, DC", "latency_ms": 152.88209915161133, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2653}, "5": {"k": 5, "answer": "Northwest Washington, D.C.", "latency_ms": 246.3550567626953, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3337}, "6": {"k": 6, "answer": "Northwest Washington, D.C.", "latency_ms": 286.2873077392578, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 4073}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Covenant of Noah", "latency_ms": 159.0268611907959, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Covenant of Noah", "latency_ms": 100.09002685546875, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Covenant of Noah", "latency_ms": 84.14244651794434, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 152.0688533782959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 143.2948112487793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2515}, "5": {"k": 5, "answer": "Noahic Covenant", "latency_ms": 138.70692253112793, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "Noahic Covenant", "latency_ms": 130.6631565093994, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3812}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Lil' Kim", "latency_ms": 144.46687698364258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.33611488342285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 165.12513160705566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1187}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.96539688110352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1795}, "4": {"k": 4, "answer": "Cheryl Kennedy, Stephanie de Sykes, Judith Bruce, Lois Lane", "latency_ms": 280.8539867401123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2366}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 161.2403392791748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2945}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 177.9179573059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3548}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "Walt Disney", "latency_ms": 91.29714965820312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 95.91102600097656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 156.4786434173584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1194}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 176.71918869018555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 143.7833309173584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2407}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 125.26988983154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3012}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 205.7490348815918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3625}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Florida coast", "latency_ms": 103.4536361694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County, Florida", "latency_ms": 236.92870140075684, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Lee County, Florida", "latency_ms": 113.19828033447266, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Lee County, Florida", "latency_ms": 125.60844421386719, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Lee County, Florida", "latency_ms": 142.66300201416016, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2529}, "5": {"k": 5, "answer": "Lee County, Florida", "latency_ms": 158.58721733093262, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3149}, "6": {"k": 6, "answer": "Lee County, Florida", "latency_ms": 140.7463550567627, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3746}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "2nd", "latency_ms": 78.1865119934082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2nd most populated country", "latency_ms": 114.64476585388184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "2nd most populated country", "latency_ms": 110.10551452636719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "2nd most populated country in the world", "latency_ms": 276.86429023742676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1797}, "4": {"k": 4, "answer": "second most populated country", "latency_ms": 112.55645751953125, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2453}, "5": {"k": 5, "answer": "second most populated country", "latency_ms": 130.80644607543945, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3117}, "6": {"k": 6, "answer": "2nd most populated country in the world", "latency_ms": 272.3665237426758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3837}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mohandas K. Gandhi", "latency_ms": 142.22168922424316, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mahatma Gandhi", "latency_ms": 147.6883888244629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 694}, "2": {"k": 2, "answer": "Mahatma Gandhi", "latency_ms": 164.6568775177002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1402}, "3": {"k": 3, "answer": "Mahatma Gandhi", "latency_ms": 140.02156257629395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2058}, "4": {"k": 4, "answer": "Mahatma Gandhi", "latency_ms": 153.42950820922852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2732}, "5": {"k": 5, "answer": "Jawaharlal Nehru", "latency_ms": 270.4164981842041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3454}, "6": {"k": 6, "answer": "Gandhi, Nehru, Patel, Rajagopalachari, Tandon, Kripalani, Desai, Bose, Iyengar, Das, Parikh", "latency_ms": 745.1536655426025, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 4189}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Terry Jones", "latency_ms": 65.93585014343262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 139.2838954925537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 97.35918045043945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.46376419067383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 176.71513557434082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 128.53670120239258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3331}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 131.40273094177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3918}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 41.381120681762695, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 48.97809028625488, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": ".java", "latency_ms": 52.45852470397949, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": ".java", "latency_ms": 126.95145606994629, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": ".java", "latency_ms": 69.5948600769043, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": ".java", "latency_ms": 73.43101501464844, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3152}, "6": {"k": 6, "answer": ".java", "latency_ms": 89.23101425170898, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 53.61485481262207, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Poland, then the British", "latency_ms": 109.7707748413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Polish Cipher Bureau", "latency_ms": 96.44865989685059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "Polish Cipher Bureau", "latency_ms": 169.62194442749023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "Polish cryptologists", "latency_ms": 113.16394805908203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "Polish cryptologists", "latency_ms": 126.69873237609863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3252}, "6": {"k": 6, "answer": "Polish cryptologists", "latency_ms": 130.1429271697998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3947}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "To ensure party members vote according to party lines and to maintain party discipline in Congress.", "latency_ms": 293.13039779663086, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to ensure party members vote according to party line and manage party votes in Congress", "latency_ms": 306.7169189453125, "em": 0.0, "f1": 0.31578947368421056, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "Ensure members attend and vote as party leadership desires", "latency_ms": 205.95741271972656, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "ensure party discipline, assign offices, schedule speakers, and ensure adequate party members to win votes", "latency_ms": 413.15245628356934, "em": 0.0, "f1": 0.4210526315789474, "containment": 0.0, "context_chars": 1857}, "4": {"k": 4, "answer": "ensure party discipline, manage voting, assign offices, schedule speakers, and ensure party members vote as desired", "latency_ms": 462.0935916900635, "em": 0.0, "f1": 0.3, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "ensure party discipline, assign offices, schedule speakers, ensure adequate party members for votes", "latency_ms": 444.13042068481445, "em": 0.0, "f1": 0.3529411764705882, "containment": 0.0, "context_chars": 3058}, "6": {"k": 6, "answer": "ensure party discipline, assign offices, schedule speakers, and ensure adequate party members attend and vote as desired", "latency_ms": 420.0706481933594, "em": 0.0, "f1": 0.2857142857142857, "containment": 0.0, "context_chars": 3708}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 89.86401557922363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 130.41377067565918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 609}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 145.14875411987305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 167.83499717712402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 125.51617622375488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2657}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 175.35877227783203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3347}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 176.8629550933838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3996}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the​ right but not the​ obligation to buy foreign​ currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 55.11832237243652, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "call option", "latency_ms": 58.47525596618652, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 90.22140502929688, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 84.19227600097656, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "FX option", "latency_ms": 82.1382999420166, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2690}, "5": {"k": 5, "answer": "FX option", "latency_ms": 87.94879913330078, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3343}, "6": {"k": 6, "answer": "FX option", "latency_ms": 103.2569408416748, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3971}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 99.49159622192383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360", "latency_ms": 96.11105918884277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360", "latency_ms": 162.8243923187256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1380}, "3": {"k": 3, "answer": "1 House of Representatives", "latency_ms": 129.53686714172363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2064}, "4": {"k": 4, "answer": "360", "latency_ms": 134.39011573791504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2764}, "5": {"k": 5, "answer": "360", "latency_ms": 135.77914237976074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3441}, "6": {"k": 6, "answer": "360", "latency_ms": 127.98357009887695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4091}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 129.4114589691162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 154.13641929626465, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 157.7315330505371, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 111.71317100524902, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 130.01370429992676, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2599}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 156.91161155700684, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3278}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 169.13819313049316, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3919}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gormé"], "shots": {"0": {"k": 0, "answer": "Antônio Carlos Jobim", "latency_ms": 215.96717834472656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gormé", "latency_ms": 111.27185821533203, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Eydie Gormé", "latency_ms": 146.68846130371094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1181}, "3": {"k": 3, "answer": "Eydie Gormé", "latency_ms": 150.9265899658203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1757}, "4": {"k": 4, "answer": "Eydie Gormé", "latency_ms": 207.98611640930176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2334}, "5": {"k": 5, "answer": "Eydie Gormé", "latency_ms": 207.3979377746582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2899}, "6": {"k": 6, "answer": "Eydie Gormé", "latency_ms": 282.5479507446289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3496}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "Justice R. S. Pathak", "latency_ms": 182.32035636901855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 87.24021911621094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 180.4804801940918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "Ramachandra Iyer", "latency_ms": 269.03367042541504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 140.52391052246094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2472}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 143.4328556060791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3151}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 153.123140335083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3784}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 142.6260471343994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 84.79857444763184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 164.98064994812012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 189.42523002624512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 129.00805473327637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2518}, "5": {"k": 5, "answer": "Federer, Nadal, Sampras, Djokovic and Emerson", "latency_ms": 485.15796661376953, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3137}, "6": {"k": 6, "answer": "Roger Federer", "latency_ms": 157.11212158203125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3711}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 123.7952709197998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 44.81029510498047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 85.23797988891602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1238}, "3": {"k": 3, "answer": "1", "latency_ms": 70.43194770812988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1858}, "4": {"k": 4, "answer": "1", "latency_ms": 108.82687568664551, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2433}, "5": {"k": 5, "answer": "1", "latency_ms": 87.08763122558594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3032}, "6": {"k": 6, "answer": "1", "latency_ms": 138.20862770080566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3639}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 130.20944595336914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2010", "latency_ms": 154.59275245666504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "2010", "latency_ms": 96.13204002380371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "2010", "latency_ms": 187.849760055542, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1883}, "4": {"k": 4, "answer": "2010", "latency_ms": 112.84470558166504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2487}, "5": {"k": 5, "answer": "2010", "latency_ms": 187.48855590820312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "2010", "latency_ms": 217.01884269714355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3791}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "32", "latency_ms": 98.4182357788086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 175.93836784362793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 109.63821411132812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 159.82723236083984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 209.6703052520752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 263.3845806121826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3137}, "6": {"k": 6, "answer": "16", "latency_ms": 133.47172737121582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3766}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Wallowa County, Oregon", "latency_ms": 161.95988655090332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 135.65444946289062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 158.95414352416992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 220.89767456054688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "Columbia River Gorge, Oregon", "latency_ms": 191.67661666870117, "em": 0.0, "f1": 0.8571428571428571, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "Columbia River Gorge, Oregon", "latency_ms": 187.81137466430664, "em": 0.0, "f1": 0.8571428571428571, "containment": 1.0, "context_chars": 3144}, "6": {"k": 6, "answer": "Columbia River Gorge, Oregon", "latency_ms": 204.76007461547852, "em": 0.0, "f1": 0.8571428571428571, "containment": 1.0, "context_chars": 3795}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Corry, Kory, Cory", "latency_ms": 232.45596885681152, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Corry, Corye, Korry", "latency_ms": 253.1108856201172, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 129.7307014465332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 123.99816513061523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Corey, Corey-Jackson, Elias James Corey", "latency_ms": 234.89046096801758, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2482}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 160.74585914611816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3118}, "6": {"k": 6, "answer": "Corey, Corey-Jackson, Joel Corey, Elias James Corey, Corey Jackson", "latency_ms": 367.9382801055908, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 3750}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.1168212890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Toby Keith", "latency_ms": 76.97391510009766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Toby Keith", "latency_ms": 150.81548690795898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Toby Keith", "latency_ms": 95.58820724487305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Toby Keith", "latency_ms": 100.75640678405762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2440}, "5": {"k": 5, "answer": "Toby Keith", "latency_ms": 114.3183708190918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3102}, "6": {"k": 6, "answer": "Toby Keith", "latency_ms": 199.50103759765625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3677}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 83.35018157958984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 93.14751625061035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "159", "latency_ms": 76.36141777038574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1239}, "3": {"k": 3, "answer": "159", "latency_ms": 95.1848030090332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1888}, "4": {"k": 4, "answer": "159", "latency_ms": 133.75329971313477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2618}, "5": {"k": 5, "answer": "159", "latency_ms": 113.42883110046387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3242}, "6": {"k": 6, "answer": "159", "latency_ms": 117.57612228393555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3913}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 124.86958503723145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.42528343200684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 90.13199806213379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1118}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 142.2133445739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1672}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 108.54887962341309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2243}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 145.71070671081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2838}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 146.8513011932373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3365}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.32472229003906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 117.9196834564209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 111.45639419555664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 110.20874977111816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "Dirk Nowitzki", "latency_ms": 143.33081245422363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2410}, "5": {"k": 5, "answer": "Dirk Nowitzki", "latency_ms": 168.61343383789062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3004}, "6": {"k": 6, "answer": "Dirk Nowitzki", "latency_ms": 219.43998336791992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3590}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 130.6173801422119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "left hand ring finger", "latency_ms": 185.9135627746582, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "right hand", "latency_ms": 87.2812271118164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1137}, "3": {"k": 3, "answer": "right hand", "latency_ms": 88.15264701843262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1691}, "4": {"k": 4, "answer": "right hand ring finger", "latency_ms": 127.34651565551758, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2293}, "5": {"k": 5, "answer": "right hand", "latency_ms": 114.93968963623047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2857}, "6": {"k": 6, "answer": "right hand", "latency_ms": 147.60470390319824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3471}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Pinocchio", "latency_ms": 116.41073226928711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 154.0205478668213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 130.5410861968994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 129.12702560424805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 129.4991970062256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2470}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 150.94971656799316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3100}, "6": {"k": 6, "answer": "Goofy", "latency_ms": 164.1547679901123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3724}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Waited I cannot answer.", "latency_ms": 191.95151329040527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Philip Stone", "latency_ms": 82.49878883361816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "Philip Stone", "latency_ms": 132.11727142333984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1184}, "3": {"k": 3, "answer": "Bernard Hill", "latency_ms": 98.95014762878418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "Bernard Hill", "latency_ms": 116.63627624511719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2403}, "5": {"k": 5, "answer": "Bernard Hill", "latency_ms": 130.9981346130371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2961}, "6": {"k": 6, "answer": "Bernard Hill", "latency_ms": 154.69622611999512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3543}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 158.69498252868652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 143.1574821472168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 132.8439712524414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1404}, "3": {"k": 3, "answer": "I cannot answer", "latency_ms": 97.34535217285156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2021}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 146.43597602844238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2622}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 131.00886344909668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3249}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 164.09969329833984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3863}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles, California", "latency_ms": 127.06327438354492, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 143.32222938537598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 173.8600730895996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1305}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 136.85846328735352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1996}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 195.54448127746582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2635}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 246.25134468078613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3260}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 230.79943656921387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3875}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 96.3444709777832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 118.43538284301758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 547}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 162.7819538116455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1146}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 210.24417877197266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1681}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 147.24135398864746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2299}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 148.1776237487793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2944}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 164.8266315460205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3588}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "atmosphere, oceans, soil, living organisms", "latency_ms": 254.04953956604004, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "plants, animals, dead plant matter", "latency_ms": 187.4675750732422, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "in plants and other living organisms, soils, and as dead plant matter", "latency_ms": 306.9460391998291, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "in plants and other living organisms, and in soils", "latency_ms": 236.79852485656738, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "in plants, soils, and organic matter of land-living organisms", "latency_ms": 411.8216037750244, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 2577}, "5": {"k": 5, "answer": "in plants, soils, and organic matter of land-living organisms", "latency_ms": 358.9949607849121, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 3284}, "6": {"k": 6, "answer": "in plants, soils, and organic matter of land-living organisms", "latency_ms": 333.5549831390381, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 4017}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 130.35869598388672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 116.49036407470703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 115.96035957336426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1187}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 177.98137664794922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1761}, "4": {"k": 4, "answer": "Chandan Shetty", "latency_ms": 131.09898567199707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2373}, "5": {"k": 5, "answer": "Chandan Shetty", "latency_ms": 142.6401138305664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2968}, "6": {"k": 6, "answer": "Chandan Shetty", "latency_ms": 158.40625762939453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3611}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Tennessee", "latency_ms": 81.4821720123291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 139.82272148132324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 161.34119033813477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 176.3772964477539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1866}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 131.26778602600098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 155.5309295654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3126}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 165.1930809020996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3744}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 102.17690467834473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 94.64359283447266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 144.6077823638916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1232}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 176.7120361328125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 193.1614875793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2515}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 143.5859203338623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3048}, "6": {"k": 6, "answer": "Kevin Kline", "latency_ms": 132.1117877960205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3734}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Starts in the Rocky Mountains, ends in the North Dakota-Minnesota border.", "latency_ms": 282.3138236999512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Starts at North Saskatchewan River in Canadian Rockies, ends at Hudson Bay", "latency_ms": 318.5696601867676, "em": 0.0, "f1": 0.2857142857142857, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Starts in central Saskatchewan, east of the Rockies; ends in Lake Winnipeg.", "latency_ms": 313.50040435791016, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 1383}, "3": {"k": 3, "answer": "Starts: confluence of North and South Saskatchewan Rivers in central Saskatchewan; Ends: Lake Winnipeg", "latency_ms": 511.1818313598633, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Starts at Saskatchewan River Forks (confluence of North and South Saskatchewan Rivers), ends in Lake Winnipeg.", "latency_ms": 610.5070114135742, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2737}, "5": {"k": 5, "answer": "Starts at Saskatchewan River Forks (confluence of North and South Saskatchewan Rivers in central Saskatchewan); ends in Lake Winnipeg.", "latency_ms": 676.3389110565186, "em": 0.0, "f1": 0.34782608695652173, "containment": 1.0, "context_chars": 3342}, "6": {"k": 6, "answer": "Starts at Saskatchewan River Forks (confluence of North and South Saskatchewan Rivers in central Saskatchewan); ends in Lake Winnipeg.", "latency_ms": 706.9149017333984, "em": 0.0, "f1": 0.34782608695652173, "containment": 1.0, "context_chars": 4010}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 81.62689208984375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 85.85953712463379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Rome, Italy", "latency_ms": 132.9953670501709, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Rome, Italy", "latency_ms": 109.83824729919434, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1916}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 160.6130599975586, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2547}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 126.88064575195312, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3180}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 192.3811435699463, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3842}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 144.0134048461914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 168.50686073303223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 114.50958251953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 123.55232238769531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1831}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 118.10088157653809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2379}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 143.18299293518066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3002}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 176.25045776367188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3580}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "ammonia, alcohols, carboxylic acids", "latency_ms": 342.4413204193115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ammonia, alcohols, acids", "latency_ms": 185.53423881530762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 226.3641357421875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 242.8724765777588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 264.6970748901367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 207.3676586151123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 238.5733127593994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 89.74313735961914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1989", "latency_ms": 130.14936447143555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "1988", "latency_ms": 142.58098602294922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "1988", "latency_ms": 177.41990089416504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "1988", "latency_ms": 112.48040199279785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2433}, "5": {"k": 5, "answer": "1988", "latency_ms": 165.2240753173828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3031}, "6": {"k": 6, "answer": "1988", "latency_ms": 165.99607467651367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3624}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Truco", "latency_ms": 101.55391693115234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ombre", "latency_ms": 122.40219116210938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "Piquet", "latency_ms": 142.3020362854004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Euchre", "latency_ms": 165.7271385192871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Euchre", "latency_ms": 116.31011962890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Euchre", "latency_ms": 127.65908241271973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2974}, "6": {"k": 6, "answer": "Euchre", "latency_ms": 123.04139137268066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3613}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 78.65381240844727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5%", "latency_ms": 72.40772247314453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "5%", "latency_ms": 65.17314910888672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "5%", "latency_ms": 71.02775573730469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1957}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 192.08621978759766, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2567}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 151.61824226379395, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 217.06581115722656, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3794}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 78.77612113952637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1989", "latency_ms": 146.66271209716797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "1975", "latency_ms": 90.50369262695312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1178}, "3": {"k": 3, "answer": "1975", "latency_ms": 177.24084854125977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1756}, "4": {"k": 4, "answer": "1975", "latency_ms": 112.03980445861816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2368}, "5": {"k": 5, "answer": "1975", "latency_ms": 125.83065032958984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2949}, "6": {"k": 6, "answer": "1975", "latency_ms": 147.86648750305176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3539}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Michael Jackson", "latency_ms": 68.56703758239746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lionel Richie", "latency_ms": 83.892822265625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Lionel Richie", "latency_ms": 125.3502368927002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Lionel Richie", "latency_ms": 142.14062690734863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 158.98847579956055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 180.74369430541992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3239}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 188.09843063354492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3863}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Lord Baltimore", "latency_ms": 59.62419509887695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lord Baltimore", "latency_ms": 72.2038745880127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Sir George Calvert", "latency_ms": 129.7914981842041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Sir George Calvert and Cecil Calvert", "latency_ms": 257.5235366821289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "Sir George Calvert", "latency_ms": 166.9790744781494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "Cecil Calvert, second Lord Baltimore", "latency_ms": 315.3560161590576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3293}, "6": {"k": 6, "answer": "Cecil Calvert, second Lord Baltimore", "latency_ms": 275.49290657043457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3987}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 144.36769485473633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 157.72461891174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 176.4657497406006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Player", "latency_ms": 69.54574584960938, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1826}, "4": {"k": 4, "answer": "Player", "latency_ms": 92.02766418457031, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2438}, "5": {"k": 5, "answer": "Player", "latency_ms": 88.11068534851074, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3088}, "6": {"k": 6, "answer": "Player", "latency_ms": 119.57263946533203, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3738}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "30 milligrams", "latency_ms": 135.8025074005127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1.31 mg/kg (intravenous) to 1.93 mg/kg (subcutaneous)", "latency_ms": 541.4612293243408, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 321.3536739349365, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 404.10661697387695, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1878}, "4": {"k": 4, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 313.8723373413086, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2503}, "5": {"k": 5, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 337.5096321105957, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3147}, "6": {"k": 6, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 394.29712295532227, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3735}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.27346229553223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Bromwich (1931)", "latency_ms": 240.76604843139648, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 83.27984809875488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1166}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 94.33102607727051, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1758}, "4": {"k": 4, "answer": "West Ham United (1980)", "latency_ms": 234.5893383026123, "em": 0.0, "f1": 0.8571428571428571, "containment": 1.0, "context_chars": 2394}, "5": {"k": 5, "answer": "West Ham United (1980)", "latency_ms": 191.9424533843994, "em": 0.0, "f1": 0.8571428571428571, "containment": 1.0, "context_chars": 2939}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 141.11042022705078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3533}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 89.21146392822266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canada, Mexico, Caribbean", "latency_ms": 96.88305854797363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 698}, "2": {"k": 2, "answer": "bootlegged beer", "latency_ms": 91.02010726928711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1393}, "3": {"k": 3, "answer": "beer parlours", "latency_ms": 109.87472534179688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2014}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 124.96066093444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2663}, "5": {"k": 5, "answer": "saloons", "latency_ms": 99.93290901184082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3306}, "6": {"k": 6, "answer": "saloon", "latency_ms": 104.6292781829834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3970}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh, Scotland", "latency_ms": 79.73027229309082, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 90.38138389587402, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 95.61991691589355, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1379}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 174.4842529296875, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2052}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 112.79988288879395, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2718}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 126.39403343200684, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3417}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 131.25014305114746, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4093}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Seth Rollins", "latency_ms": 79.77867126464844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 84.01179313659668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 706}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 165.53139686584473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 107.7871322631836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2062}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 113.30127716064453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2736}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 127.88510322570801, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3396}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 141.36552810668945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4082}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.88929748535156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Boston", "latency_ms": 67.18230247497559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 118.81399154663086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Southport, North Carolina", "latency_ms": 157.44948387145996, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Southport, North Carolina", "latency_ms": 171.7829704284668, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "Southport, North Carolina", "latency_ms": 223.65975379943848, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3045}, "6": {"k": 6, "answer": "Southport, North Carolina", "latency_ms": 207.54146575927734, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3679}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 101.49931907653809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 112.57624626159668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 131.02006912231445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 153.64694595336914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 189.2385482788086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Daily Press", "latency_ms": 165.45367240905762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "Daily Press", "latency_ms": 137.98761367797852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3782}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 87.5997543334961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Franklin D. Roosevelt", "latency_ms": 148.88334274291992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 669}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 140.64979553222656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 141.72935485839844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2012}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 160.3400707244873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2658}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 180.6025505065918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3374}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 162.97650337219238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4111}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 42.52982139587402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 51.10645294189453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "Max", "latency_ms": 74.04708862304688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Max", "latency_ms": 69.96703147888184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1967}, "4": {"k": 4, "answer": "Max", "latency_ms": 110.23855209350586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2615}, "5": {"k": 5, "answer": "Max", "latency_ms": 90.09718894958496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3269}, "6": {"k": 6, "answer": "Max", "latency_ms": 148.0400562286377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3871}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Sasha Lane", "latency_ms": 98.60420227050781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Saskia Grant", "latency_ms": 103.06739807128906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "Saskia Wainwright", "latency_ms": 265.20824432373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Saskia Mulder", "latency_ms": 138.54026794433594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1830}, "4": {"k": 4, "answer": "Saskia Mulder", "latency_ms": 147.8590965270996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2461}, "5": {"k": 5, "answer": "Emily Hampshire", "latency_ms": 99.83634948730469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3048}, "6": {"k": 6, "answer": "Emily Hampshire", "latency_ms": 104.98166084289551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3664}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.47468757629395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Flu pandemic, World War I, nationalism and decolonization, the Cold War and post-Cold War conflicts", "latency_ms": 532.7799320220947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "Flu pandemic, World War I, nationalism, decolonization, nuclear power, space exploration, Cold War", "latency_ms": 475.59309005737305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "Flu pandemic, World War I, nationalism and decolonization, nuclear power and space exploration, Cold War began", "latency_ms": 567.573070526123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "Flu pandemic, World War I, nationalism, decolonization, nuclear power, space exploration, Cold War began", "latency_ms": 653.7060737609863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2466}, "5": {"k": 5, "answer": "Flu pandemic, World War I, nuclear power, space exploration, nationalism, decolonization, Cold War began", "latency_ms": 711.0855579376221, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "Flu pandemic, World War I, nationalism, decolonization, nuclear power, space exploration, Cold War began", "latency_ms": 440.9456253051758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Self-empowerment", "latency_ms": 145.04146575927734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "self-empowerment", "latency_ms": 135.71715354919434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 188.64941596984863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "self-empowerment", "latency_ms": 139.06383514404297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "self-empowerment", "latency_ms": 188.75694274902344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2540}, "5": {"k": 5, "answer": "self-empowerment", "latency_ms": 189.43357467651367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3170}, "6": {"k": 6, "answer": "self-empowerment", "latency_ms": 264.9519443511963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 91.91155433654785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "NFL owners", "latency_ms": 86.87186241149902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "NFL franchises", "latency_ms": 88.1655216217041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "teams", "latency_ms": 58.56895446777344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1828}, "4": {"k": 4, "answer": "NFL franchises", "latency_ms": 103.83820533752441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2427}, "5": {"k": 5, "answer": "NFL franchises", "latency_ms": 100.65817832946777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3074}, "6": {"k": 6, "answer": "NFL franchises", "latency_ms": 104.92944717407227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3678}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 138.39387893676758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 102.05388069152832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Marshall", "latency_ms": 70.73068618774414, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Sutter", "latency_ms": 114.4711971282959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1977}, "4": {"k": 4, "answer": "Sutter", "latency_ms": 105.7887077331543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2639}, "5": {"k": 5, "answer": "Sutter", "latency_ms": 100.12102127075195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3324}, "6": {"k": 6, "answer": "Sutter", "latency_ms": 104.09116744995117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3947}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "convex mirror", "latency_ms": 66.46442413330078, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "rear-view mirror", "latency_ms": 144.4528102874756, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "rear-view mirror", "latency_ms": 77.55279541015625, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "rear-view mirror", "latency_ms": 180.42731285095215, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "rear-view mirror", "latency_ms": 96.47679328918457, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "rear-view mirror", "latency_ms": 113.0671501159668, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3223}, "6": {"k": 6, "answer": "rear-view mirror", "latency_ms": 133.41259956359863, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3821}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 108.99043083190918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 123.3818531036377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 167.05799102783203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1188}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 153.8691520690918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1788}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 166.71442985534668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2404}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 163.98191452026367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3041}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 170.6533432006836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3705}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart", "latency_ms": 82.47232437133789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart and Richard Stilgoe, and additional lyrics by Mike Batt", "latency_ms": 482.8529357910156, "em": 0.0, "f1": 0.625, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 215.057373046875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 263.2148265838623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1844}, "4": {"k": 4, "answer": "Charles Hart, Richard Stilgoe, and Mike Batt", "latency_ms": 379.75454330444336, "em": 0.0, "f1": 0.8333333333333333, "containment": 1.0, "context_chars": 2508}, "5": {"k": 5, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 226.50957107543945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3165}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 234.1465950012207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3840}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Central Europe", "latency_ms": 53.99799346923828, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "German-speaking world", "latency_ms": 127.42114067077637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 699}, "2": {"k": 2, "answer": "German-speaking world", "latency_ms": 146.1958885192871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1383}, "3": {"k": 3, "answer": "German-speaking world", "latency_ms": 95.35837173461914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2014}, "4": {"k": 4, "answer": "Central Germany", "latency_ms": 156.14056587219238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2662}, "5": {"k": 5, "answer": "Germany is not part of a culture region; it is a country with diverse cultural regions within it. I cannot answer.", "latency_ms": 483.201265335083, "em": 0.0, "f1": 0.09523809523809526, "containment": 0.0, "context_chars": 3308}, "6": {"k": 6, "answer": "Central Germany", "latency_ms": 114.12549018859863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4054}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "13th to 14th century", "latency_ms": 293.3964729309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 105.62753677368164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 114.08710479736328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 130.91111183166504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "post-medieval era", "latency_ms": 193.33481788635254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "later, more modern period than earlier titles with access to pistols, grenades, and other equipment of the post-medieval era", "latency_ms": 699.7206211090088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3140}, "6": {"k": 6, "answer": "later, more modern period than earlier titles with access to pistols, grenades, and other equipment of the post-medieval era", "latency_ms": 636.3010406494141, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3791}}}
