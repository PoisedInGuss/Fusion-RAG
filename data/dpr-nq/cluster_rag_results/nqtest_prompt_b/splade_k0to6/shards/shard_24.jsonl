{"qid": "-8185754991042790824", "question": "what is the most fundamental unit of life according to the cell theory", "gold_answers": ["cells"], "shots": {"0": {"k": 0, "answer": "cell", "latency_ms": 131.02078437805176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "cell", "latency_ms": 114.2885684967041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "cell", "latency_ms": 125.63848495483398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "cell", "latency_ms": 61.06901168823242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": "cell", "latency_ms": 71.17199897766113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "cell", "latency_ms": 139.23025131225586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3144}, "6": {"k": 6, "answer": "cell", "latency_ms": 347.54180908203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3771}}}
{"qid": "101283134098691894", "question": "who sings god is great beer is good", "gold_answers": ["Currington"], "shots": {"0": {"k": 0, "answer": "The Wiggles", "latency_ms": 151.139497756958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jones", "latency_ms": 104.33435440063477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "Jones", "latency_ms": 102.56600379943848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Jones", "latency_ms": 99.03478622436523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1793}, "4": {"k": 4, "answer": "Jones", "latency_ms": 74.86820220947266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2396}, "5": {"k": 5, "answer": "Jones and Braddock", "latency_ms": 385.4851722717285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2996}, "6": {"k": 6, "answer": "Billy Currington", "latency_ms": 132.37428665161133, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3620}}}
{"qid": "7536400679989549629", "question": "when did toyota start making cars in the us", "gold_answers": ["by the early 1980s", "1984"], "shots": {"0": {"k": 0, "answer": "1958", "latency_ms": 80.23285865783691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 284.59930419921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "1984", "latency_ms": 244.62890625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1352}, "3": {"k": 3, "answer": "1984", "latency_ms": 275.27904510498047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1987}, "4": {"k": 4, "answer": "1984", "latency_ms": 336.8101119995117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2594}, "5": {"k": 5, "answer": "1984", "latency_ms": 254.65703010559082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3259}, "6": {"k": 6, "answer": "1984", "latency_ms": 303.6508560180664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3892}}}
{"qid": "6051795036343880000", "question": "the art and science of making objects from clay is called", "gold_answers": ["Ceramic art", "Ceramic"], "shots": {"0": {"k": 0, "answer": "ceramics", "latency_ms": 200.29830932617188, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "ceramics", "latency_ms": 89.34664726257324, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 628}, "2": {"k": 2, "answer": "ceramics", "latency_ms": 154.5114517211914, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1298}, "3": {"k": 3, "answer": "ceramic art", "latency_ms": 269.18935775756836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1957}, "4": {"k": 4, "answer": "ceramics", "latency_ms": 157.12809562683105, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2607}, "5": {"k": 5, "answer": "ceramics", "latency_ms": 195.04213333129883, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3257}, "6": {"k": 6, "answer": "ceramics", "latency_ms": 174.78060722351074, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3861}}}
{"qid": "3129545687702582462", "question": "when was the last time michigan basketball won the championship", "gold_answers": ["1989"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 181.37764930725098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1989", "latency_ms": 388.58890533447266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 652}, "2": {"k": 2, "answer": "1989", "latency_ms": 163.5732650756836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1324}, "3": {"k": 3, "answer": "1989", "latency_ms": 351.59969329833984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2011}, "4": {"k": 4, "answer": "1989", "latency_ms": 186.26642227172852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2693}, "5": {"k": 5, "answer": "1989", "latency_ms": 213.46521377563477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3335}, "6": {"k": 6, "answer": "1989", "latency_ms": 253.32903861999512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4015}}}
{"qid": "6073711870457481158", "question": "which state is the richest state in nigeria", "gold_answers": ["Lagos State"], "shots": {"0": {"k": 0, "answer": "Kaduna", "latency_ms": 68.92514228820801, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 161.46278381347656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 126.98197364807129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 176.62787437438965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 260.5013847351074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 296.6642379760742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3162}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 144.39749717712402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3804}}}
{"qid": "-7483795661822231594", "question": "who was the oldest man elected president of usa", "gold_answers": ["Donald Trump", "Ronald Reagan"], "shots": {"0": {"k": 0, "answer": "Donald Trump", "latency_ms": 79.75101470947266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ronald Reagan", "latency_ms": 106.97293281555176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Donald Trump", "latency_ms": 174.89337921142578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Ronald Reagan", "latency_ms": 135.04886627197266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1946}, "4": {"k": 4, "answer": "Ronald Reagan", "latency_ms": 155.81965446472168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2615}, "5": {"k": 5, "answer": "Ronald Reagan", "latency_ms": 261.31701469421387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3275}, "6": {"k": 6, "answer": "Ronald Reagan", "latency_ms": 158.20884704589844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3892}}}
{"qid": "-723195820759181666", "question": "what is the name of the muslim dress", "gold_answers": ["hijab"], "shots": {"0": {"k": 0, "answer": "Abaya", "latency_ms": 107.63001441955566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "burqa or chador", "latency_ms": 151.12566947937012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "burqa or chador", "latency_ms": 251.16872787475586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1323}, "3": {"k": 3, "answer": "burqa or chador", "latency_ms": 277.1940231323242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2008}, "4": {"k": 4, "answer": "burqa", "latency_ms": 133.1958770751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2669}, "5": {"k": 5, "answer": "burqa", "latency_ms": 148.4668254852295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3348}, "6": {"k": 6, "answer": "hijab", "latency_ms": 122.8792667388916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4013}}}
{"qid": "-6586412257386389331", "question": "what is the democracy of the united states", "gold_answers": ["federal republic"], "shots": {"0": {"k": 0, "answer": "Federal republic", "latency_ms": 51.89967155456543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "representative democracy", "latency_ms": 69.0162181854248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "representative democracy", "latency_ms": 136.60192489624023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1335}, "3": {"k": 3, "answer": "Flawed Democracy", "latency_ms": 209.6424102783203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2000}, "4": {"k": 4, "answer": "Flawed Democracy", "latency_ms": 214.70355987548828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2613}, "5": {"k": 5, "answer": "representative democracy", "latency_ms": 171.4470386505127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3336}, "6": {"k": 6, "answer": "Flawed Democracy", "latency_ms": 280.1227569580078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3977}}}
{"qid": "2335218357123640096", "question": "the creation of human beings in the kumulipo happens during which wā or period of creation", "gold_answers": ["the ninth wā", "the ninth", "the ninth wā ,", "In the ninth wā"], "shots": {"0": {"k": 0, "answer": "wā 11", "latency_ms": 140.21873474121094, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ao", "latency_ms": 143.0976390838623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "the first seven wā", "latency_ms": 352.3240089416504, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "The context does not specify which wā or period of creation includes the creation of human beings. I cannot answer.", "latency_ms": 818.5164928436279, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 1784}, "4": {"k": 4, "answer": "The context does not specify which wā or period of creation the creation of human beings occurs in. I cannot answer.", "latency_ms": 870.1145648956299, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 2370}, "5": {"k": 5, "answer": "the period after pō and before ao, specifically in the eighth wā", "latency_ms": 553.4007549285889, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 3004}, "6": {"k": 6, "answer": "the period after the age of pō, signaled by the arrival of light and the gods, when animals change into the first humans.", "latency_ms": 724.3139743804932, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3638}}}
{"qid": "-6057127102520256843", "question": "when did the democratic party change its name", "gold_answers": ["the 1830s"], "shots": {"0": {"k": 0, "answer": "1896", "latency_ms": 485.36109924316406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "22 November 1992", "latency_ms": 593.9013957977295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "22 November 1992", "latency_ms": 296.2653636932373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 134.46378707885742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "22 November 1992", "latency_ms": 279.7665596008301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2596}, "5": {"k": 5, "answer": "22 June 1991", "latency_ms": 425.2910614013672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3264}, "6": {"k": 6, "answer": "22 June 1991", "latency_ms": 482.5117588043213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3929}}}
{"qid": "4876599928758806949", "question": "what percentage of global man-made co2 emissions comes from worldwide aviation", "gold_answers": ["4 percent cumulative effect"], "shots": {"0": {"k": 0, "answer": "2%", "latency_ms": 165.2848720550537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 238.4951114654541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 148.5307216644287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 254.02522087097168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1936}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 277.5704860687256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2613}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 367.9537773132324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3349}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 272.62282371520996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4060}}}
{"qid": "-5504644202857349113", "question": "who won the 7 man elimination chamber match", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Finn Bálor", "latency_ms": 181.68973922729492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 154.40773963928223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 97.75948524475098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1302}, "3": {"k": 3, "answer": "Braun Strowman", "latency_ms": 290.2863025665283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Roman Reigns", "latency_ms": 198.65131378173828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2594}, "5": {"k": 5, "answer": "Roman Reigns", "latency_ms": 280.8833122253418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Roman Reigns", "latency_ms": 129.6374797821045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3916}}}
{"qid": "-5932577781299677613", "question": "when did the royal mint move to wales", "gold_answers": ["17 December 1968", "the 1960s .", "1968", "the 1960s"], "shots": {"0": {"k": 0, "answer": "1967", "latency_ms": 357.2084903717041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1960s", "latency_ms": 153.67627143859863, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "1967", "latency_ms": 328.40633392333984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1200}, "3": {"k": 3, "answer": "1967", "latency_ms": 245.30553817749023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "1967", "latency_ms": 284.1651439666748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2380}, "5": {"k": 5, "answer": "1967", "latency_ms": 199.4035243988037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2958}, "6": {"k": 6, "answer": "1967", "latency_ms": 317.13008880615234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3546}}}
{"qid": "-4479785452076489171", "question": "when did marathon change its name to snickers", "gold_answers": ["19 July 1990"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 477.07486152648926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 244.5368766784668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "1990", "latency_ms": 103.23667526245117, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "1990", "latency_ms": 195.55091857910156, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "1990", "latency_ms": 161.17382049560547, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2597}, "5": {"k": 5, "answer": "1990", "latency_ms": 372.4634647369385, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3205}, "6": {"k": 6, "answer": "1990", "latency_ms": 366.8193817138672, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3836}}}
{"qid": "8163716911432361139", "question": "who sold out jesus for 30 pieces of silver", "gold_answers": ["Judas Iscariot"], "shots": {"0": {"k": 0, "answer": "Judas Iscariot", "latency_ms": 335.9518051147461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Judas Iscariot", "latency_ms": 240.48209190368652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "Judas Iscariot", "latency_ms": 176.06306076049805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Judas Iscariot", "latency_ms": 336.39001846313477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1823}, "4": {"k": 4, "answer": "Judas Iscariot", "latency_ms": 407.2597026824951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "Judas Iscariot", "latency_ms": 519.5741653442383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3055}, "6": {"k": 6, "answer": "Judas Iscariot", "latency_ms": 162.37401962280273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3704}}}
{"qid": "2083919204265709212", "question": "who has the most big ten championships in football", "gold_answers": ["Michigan"], "shots": {"0": {"k": 0, "answer": "Ohio State", "latency_ms": 93.91188621520996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 127.30789184570312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 722}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 229.30335998535156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 265.0125026702881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "USC", "latency_ms": 107.09309577941895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2673}, "5": {"k": 5, "answer": "USC", "latency_ms": 261.6739273071289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3348}, "6": {"k": 6, "answer": "USC", "latency_ms": 168.80083084106445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3977}}}
{"qid": "-5338739549058676323", "question": "a synonym for the content component of communication is", "gold_answers": ["information"], "shots": {"0": {"k": 0, "answer": "message", "latency_ms": 242.89917945861816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "words", "latency_ms": 72.75009155273438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "words", "latency_ms": 72.41940498352051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1488}, "3": {"k": 3, "answer": "message", "latency_ms": 83.07051658630371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2165}, "4": {"k": 4, "answer": "message", "latency_ms": 99.9593734741211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2857}, "5": {"k": 5, "answer": "message", "latency_ms": 207.41534233093262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3535}, "6": {"k": 6, "answer": "message", "latency_ms": 203.78661155700684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4291}}}
{"qid": "1150760456533790667", "question": "the initial unification of upper and lower egypt took place during which period", "gold_answers": ["3000 BC", "c. 3000 BC"], "shots": {"0": {"k": 0, "answer": "Old Kingdom", "latency_ms": 95.56436538696289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Early Dynastic Period", "latency_ms": 150.5131721496582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Early Dynastic Period", "latency_ms": 201.91454887390137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "Early Dynastic Period", "latency_ms": 106.00972175598145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Early Dynastic Period", "latency_ms": 270.39122581481934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2583}, "5": {"k": 5, "answer": "Early Dynastic Period", "latency_ms": 253.7238597869873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3203}, "6": {"k": 6, "answer": "Early Dynastic Period", "latency_ms": 139.13655281066895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3856}}}
{"qid": "5104733125093069374", "question": "where is the new football stadium in atlanta", "gold_answers": ["Mercedes - Benz Stadium"], "shots": {"0": {"k": 0, "answer": "Mercedes-Benz Stadium", "latency_ms": 222.66554832458496, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mercedes-Benz Stadium", "latency_ms": 398.50330352783203, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "Mercedes-Benz Stadium", "latency_ms": 115.61036109924316, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Atlanta, Georgia", "latency_ms": 166.87679290771484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "Atlanta, Georgia", "latency_ms": 164.60037231445312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2607}, "5": {"k": 5, "answer": "Atlanta, Georgia", "latency_ms": 159.7604751586914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3278}, "6": {"k": 6, "answer": "Atlanta, Georgia", "latency_ms": 278.0160903930664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3921}}}
{"qid": "-6449103613087792543", "question": "where do the sharks play in san jose", "gold_answers": ["SAP Center at San Jose", "SAP Center", "the SAP Center"], "shots": {"0": {"k": 0, "answer": "San Jose Earthquakes Stadium", "latency_ms": 461.17448806762695, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "SAP Center at San Jose", "latency_ms": 242.65718460083008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 596}, "2": {"k": 2, "answer": "SAP Center at San Jose", "latency_ms": 305.94849586486816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "SAP Center at San Jose", "latency_ms": 389.4374370574951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "SAP Center at San Jose", "latency_ms": 289.46948051452637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2454}, "5": {"k": 5, "answer": "SAP Center at San Jose", "latency_ms": 340.8246040344238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3057}, "6": {"k": 6, "answer": "SAP Center at San Jose", "latency_ms": 153.9139747619629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3721}}}
{"qid": "-9184252191331338125", "question": "who plays rooster's girlfriend on the ranch", "gold_answers": ["Maggie Lawson", "Megyn Price"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 102.48875617980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Christina Hearn", "latency_ms": 190.45186042785645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 172.00469970703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 204.42557334899902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 324.63741302490234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 167.72031784057617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3105}, "6": {"k": 6, "answer": "Lily St Regis", "latency_ms": 252.09355354309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3727}}}
{"qid": "4064534769148169274", "question": "where was gunsmoke to the last man filmed", "gold_answers": ["Tucson , Arizona"], "shots": {"0": {"k": 0, "answer": "Oklahoma", "latency_ms": 175.50182342529297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 217.4973487854004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 270.17927169799805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1320}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 237.17713356018066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 226.39894485473633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 130.39493560791016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3183}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 256.2415599822998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3779}}}
{"qid": "-5540073670385654363", "question": "where are more than half your bones located", "gold_answers": ["the appendicular skeleton"], "shots": {"0": {"k": 0, "answer": "spine", "latency_ms": 52.87909507751465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 165.9071445465088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 276.0915756225586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 194.84353065490723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 200.38485527038574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "cranium", "latency_ms": 107.85794258117676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3082}, "6": {"k": 6, "answer": "cranium", "latency_ms": 159.51967239379883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3679}}}
{"qid": "2741826828451174428", "question": "when does the champions league round of 16 start", "gold_answers": ["13 February"], "shots": {"0": {"k": 0, "answer": "January 2024", "latency_ms": 153.21874618530273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 231.07552528381348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 296.6420650482178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 132.8275203704834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "February 19–21, 2019", "latency_ms": 268.4609889984131, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "February 19–21, 2019", "latency_ms": 667.7219867706299, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "12 January 2016", "latency_ms": 470.02124786376953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3840}}}
{"qid": "-2389754682537282284", "question": "who was defeated in the french and indian war", "gold_answers": ["Wabanaki Confederacy", "British", "the French", "France"], "shots": {"0": {"k": 0, "answer": "Britain", "latency_ms": 69.60201263427734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "France", "latency_ms": 140.69390296936035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "the French", "latency_ms": 326.7042636871338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1320}, "3": {"k": 3, "answer": "The French were defeated in the French and Indian War.", "latency_ms": 505.9030055999756, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1959}, "4": {"k": 4, "answer": "The French", "latency_ms": 133.29625129699707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2592}, "5": {"k": 5, "answer": "France", "latency_ms": 211.50708198547363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3237}, "6": {"k": 6, "answer": "France", "latency_ms": 258.9917182922363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3849}}}
{"qid": "-1770233019951526566", "question": "who dies in the beginning of deathly hallows part 1", "gold_answers": ["Hedwig", "Mad - Eye Moody"], "shots": {"0": {"k": 0, "answer": "Neville Longbottom", "latency_ms": 158.80918502807617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 168.9150333404541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 332.1220874786377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 109.21168327331543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 113.62910270690918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2522}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 128.01361083984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3120}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 179.0158748626709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3762}}}
{"qid": "-809030720693449714", "question": "when did colour tv come out in uk", "gold_answers": ["1967 / 1969 / 1976", "1967", "July 1 , 1967"], "shots": {"0": {"k": 0, "answer": "1967", "latency_ms": 131.18624687194824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "July 1, 1967", "latency_ms": 220.85976600646973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 698}, "2": {"k": 2, "answer": "July 1, 1967", "latency_ms": 488.9698028564453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1330}, "3": {"k": 3, "answer": "July 1, 1967", "latency_ms": 644.9410915374756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1991}, "4": {"k": 4, "answer": "July 1, 1967", "latency_ms": 759.5632076263428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2686}, "5": {"k": 5, "answer": "July 1, 1967", "latency_ms": 384.1900825500488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3353}, "6": {"k": 6, "answer": "July 1, 1967", "latency_ms": 460.47234535217285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3994}}}
{"qid": "-1569810426787618729", "question": "who wrote the music phantom of the opera", "gold_answers": ["Andrew Lloyd Webber"], "shots": {"0": {"k": 0, "answer": "Andrew Lloyd Webber", "latency_ms": 141.49045944213867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Andrew Lloyd Webber", "latency_ms": 89.50638771057129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Andrew Lloyd Webber", "latency_ms": 209.86318588256836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1341}, "3": {"k": 3, "answer": "Andrew Lloyd Webber", "latency_ms": 279.2673110961914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2001}, "4": {"k": 4, "answer": "Andrew Lloyd Webber", "latency_ms": 108.27779769897461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2620}, "5": {"k": 5, "answer": "Andrew Lloyd Webber", "latency_ms": 289.9467945098877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3295}, "6": {"k": 6, "answer": "Andrew Lloyd Webber", "latency_ms": 152.26984024047852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3931}}}
{"qid": "1925389754206914779", "question": "what is cost of first class mail stamp", "gold_answers": ["49 cents", ". 49", "47 cents"], "shots": {"0": {"k": 0, "answer": "$0.58", "latency_ms": 173.32053184509277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "46 cents", "latency_ms": 157.4232578277588, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "46 cents", "latency_ms": 129.6398639678955, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "49 cents", "latency_ms": 266.0510540008545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "49 cents", "latency_ms": 209.7465991973877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2569}, "5": {"k": 5, "answer": "47 cents", "latency_ms": 141.23201370239258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3190}, "6": {"k": 6, "answer": "47 cents", "latency_ms": 166.05591773986816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3758}}}
{"qid": "-271857377729162108", "question": "hyori bed and breakfast season 2 air date", "gold_answers": ["February 4 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 214.097261428833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 169.7232723236084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 378.04508209228516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 374.875545501709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 354.6452522277832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 297.50704765319824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 258.47506523132324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3782}}}
{"qid": "-5444320457991187484", "question": "who represented the state of tennessee in the scopes trial", "gold_answers": ["William Jennings Bryan"], "shots": {"0": {"k": 0, "answer": "Clarence Darrow", "latency_ms": 167.9387092590332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John T. Raulston", "latency_ms": 181.79059028625488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "John W. Butler", "latency_ms": 96.57955169677734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "William Jennings Bryan", "latency_ms": 130.6283473968506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1928}, "4": {"k": 4, "answer": "John T. Raulston", "latency_ms": 133.98981094360352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "William Jennings Bryan", "latency_ms": 340.7750129699707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3190}, "6": {"k": 6, "answer": "John T. Raulston", "latency_ms": 232.41353034973145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3814}}}
{"qid": "8371386055730091060", "question": "when was the land rover defender first built", "gold_answers": ["1991", "in the 1980s", "1983"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 80.2147388458252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 206.5873146057129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 241.95218086242676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "1947", "latency_ms": 172.3763942718506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1886}, "4": {"k": 4, "answer": "1948", "latency_ms": 227.0967960357666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "1948", "latency_ms": 196.57063484191895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "1948", "latency_ms": 139.4050121307373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3812}}}
{"qid": "-7424780667593320090", "question": "who played the wicked witch in wicked on broadway", "gold_answers": ["Rachel Kelly Tucker"], "shots": {"0": {"k": 0, "answer": "Missy Yager", "latency_ms": 138.37099075317383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 257.57598876953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 172.19877243041992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 215.6362533569336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1910}, "4": {"k": 4, "answer": "Idina Menzel", "latency_ms": 112.60366439819336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2548}, "5": {"k": 5, "answer": "Idina Menzel", "latency_ms": 123.48079681396484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3182}, "6": {"k": 6, "answer": "Idina Menzel", "latency_ms": 191.02764129638672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3892}}}
{"qid": "-311518210106653803", "question": "when did this season of american idol start", "gold_answers": ["March 11 , 2018"], "shots": {"0": {"k": 0, "answer": "2023", "latency_ms": 288.15484046936035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "January 6, 2016", "latency_ms": 262.0236873626709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "January 6, 2016", "latency_ms": 462.74495124816895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "January 6, 2016", "latency_ms": 467.2069549560547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "January 6, 2016", "latency_ms": 464.3375873565674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "January 6, 2016", "latency_ms": 468.48583221435547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "January 6, 2016", "latency_ms": 588.6580944061279, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3760}}}
{"qid": "-5216757121139817585", "question": "what type of artwork was created in the safavid empire", "gold_answers": ["ceramics", "metal", "book", "glass", "gardens", "architecture"], "shots": {"0": {"k": 0, "answer": "Persian miniature paintings", "latency_ms": 194.63062286376953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "painting", "latency_ms": 136.7640495300293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "Safavid painting", "latency_ms": 263.1196975708008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "manuscripts, paintings", "latency_ms": 280.25126457214355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "book and architecture; ceramics, metal, glass, and gardens", "latency_ms": 410.2976322174072, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2483}, "5": {"k": 5, "answer": "book and architecture; ceramics, metal, glass, and gardens", "latency_ms": 648.6425399780273, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3093}, "6": {"k": 6, "answer": "book art, architecture, ceramics, metal, glass, gardens, manuscript illumination, Persian miniature painting", "latency_ms": 525.2604484558105, "em": 0.0, "f1": 0.15384615384615385, "containment": 1.0, "context_chars": 3739}}}
{"qid": "5479417599174868120", "question": "the king of kalinga in the mauryan period was", "gold_answers": ["Ashoka"], "shots": {"0": {"k": 0, "answer": "Vasudeva Kanva", "latency_ms": 355.40103912353516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 349.67660903930664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 209.29336547851562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Ashoka", "latency_ms": 109.81583595275879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1912}, "4": {"k": 4, "answer": "Ashoka", "latency_ms": 172.23739624023438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Ashoka", "latency_ms": 138.19169998168945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3300}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 211.8089199066162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3900}}}
{"qid": "4452310047580638948", "question": "who won the most on who wants to be a millionaire", "gold_answers": ["David Goodman", "Kevin Olmstead"], "shots": {"0": {"k": 0, "answer": "Drew Carey", "latency_ms": 65.23895263671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$500,000", "latency_ms": 183.66646766662598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 738}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 206.8319320678711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1373}, "3": {"k": 3, "answer": "Drew Carey, Rosie O'Donnell, Norm Macdonald, and Chip Esten", "latency_ms": 329.3161392211914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "François Dominic Laramée", "latency_ms": 338.9620780944824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2713}, "5": {"k": 5, "answer": "Hansani Kavindi", "latency_ms": 230.33952713012695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3331}, "6": {"k": 6, "answer": "Michael Shutterly", "latency_ms": 168.08390617370605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3976}}}
{"qid": "1035072243758390653", "question": "who won the battle of britain in ww2", "gold_answers": ["Britain", "British", "the United Kingdom"], "shots": {"0": {"k": 0, "answer": "Britain", "latency_ms": 69.26465034484863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 198.1518268585205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 254.3349266052246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 206.59232139587402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "The United Kingdom won the Battle of Britain in WWII.", "latency_ms": 413.64240646362305, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2545}, "5": {"k": 5, "answer": "The British won the Battle of Britain in WWII.", "latency_ms": 282.5050354003906, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 3180}, "6": {"k": 6, "answer": "The British", "latency_ms": 163.68579864501953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3788}}}
{"qid": "2549898383395112074", "question": "what type of economic system was utilized in the soviet union", "gold_answers": ["communism", "state ownership"], "shots": {"0": {"k": 0, "answer": "Command economy", "latency_ms": 114.50672149658203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "state capitalism", "latency_ms": 65.67096710205078, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "state ownership, centralized administrative planning", "latency_ms": 357.7439785003662, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1384}, "3": {"k": 3, "answer": "state ownership, centralized administrative planning", "latency_ms": 530.3289890289307, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2074}, "4": {"k": 4, "answer": "state ownership, centralized administrative planning", "latency_ms": 699.5017528533936, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2779}, "5": {"k": 5, "answer": "state-owned, centrally planned economy", "latency_ms": 192.6565170288086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3511}, "6": {"k": 6, "answer": "state-owned, centrally planned economy", "latency_ms": 381.7408084869385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4195}}}
{"qid": "4250543960781822078", "question": "when was the last time michigan won the championship", "gold_answers": ["1989"], "shots": {"0": {"k": 0, "answer": "2023", "latency_ms": 101.83548927307129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1989", "latency_ms": 262.4063491821289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 652}, "2": {"k": 2, "answer": "1989", "latency_ms": 101.82690620422363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "1989", "latency_ms": 293.9615249633789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1988}, "4": {"k": 4, "answer": "1989", "latency_ms": 235.67533493041992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2675}, "5": {"k": 5, "answer": "1989", "latency_ms": 247.66850471496582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3357}, "6": {"k": 6, "answer": "1989", "latency_ms": 219.2394733428955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3999}}}
{"qid": "-8250837240532044441", "question": "what is the function of a political action committee (pac)", "gold_answers": ["pools campaign contributions from members"], "shots": {"0": {"k": 0, "answer": "to raise and spend money to influence elections and political campaigns", "latency_ms": 426.3415336608887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pool campaign contributions and donate them to campaigns for or against candidates, ballot initiatives, or legislation.", "latency_ms": 561.1209869384766, "em": 0.0, "f1": 0.19047619047619047, "containment": 0.0, "context_chars": 685}, "2": {"k": 2, "answer": "Pool campaign contributions and donate funds to campaigns for or against candidates, ballot initiatives, or legislation.", "latency_ms": 845.0422286987305, "em": 0.0, "f1": 0.19047619047619047, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "Pool campaign contributions from members and donate those funds to campaigns for or against candidates, ballot initiatives, or legislation.", "latency_ms": 1150.8522033691406, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2136}, "4": {"k": 4, "answer": "Pool campaign contributions from members and donate those funds to campaigns for or against candidates, ballot initiatives, or legislation.", "latency_ms": 1114.4869327545166, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2892}, "5": {"k": 5, "answer": "Pool campaign contributions from members and donate those funds to campaigns for or against candidates, ballot initiatives, or legislation.", "latency_ms": 805.8679103851318, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3580}, "6": {"k": 6, "answer": "pools campaign contributions from members and donates those funds to campaigns for or against candidates, ballot initiatives, or legislation", "latency_ms": 1187.4752044677734, "em": 0.0, "f1": 0.41666666666666674, "containment": 1.0, "context_chars": 4243}}}
{"qid": "-5549349480589170313", "question": "what river is associated with the city of rome", "gold_answers": ["Tiber", "The Tiber"], "shots": {"0": {"k": 0, "answer": "Tiber River", "latency_ms": 63.94815444946289, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiber", "latency_ms": 87.36968040466309, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "Tiber", "latency_ms": 94.61021423339844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1207}, "3": {"k": 3, "answer": "Tiber", "latency_ms": 83.87017250061035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1777}, "4": {"k": 4, "answer": "Tiber", "latency_ms": 359.2064380645752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2405}, "5": {"k": 5, "answer": "Tiber", "latency_ms": 319.9310302734375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3035}, "6": {"k": 6, "answer": "Tiber", "latency_ms": 104.56490516662598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3621}}}
{"qid": "4655709146254117753", "question": "what's the highest point in the us", "gold_answers": ["Mount Whitney"], "shots": {"0": {"k": 0, "answer": "Denali", "latency_ms": 157.3159694671631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 108.06393623352051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 572}, "2": {"k": 2, "answer": "High Point, New Jersey", "latency_ms": 346.3404178619385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1152}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 126.94859504699707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1770}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 256.43134117126465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2344}, "5": {"k": 5, "answer": "Denali", "latency_ms": 130.92684745788574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2962}, "6": {"k": 6, "answer": "Denali", "latency_ms": 172.40118980407715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3570}}}
{"qid": "2191296244632588902", "question": "where did they film season 8 of the walking dead", "gold_answers": ["Georgia"], "shots": {"0": {"k": 0, "answer": "Georgia, Tennessee, and North Carolina", "latency_ms": 152.5101661682129, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Atlanta, Georgia", "latency_ms": 124.15957450866699, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "Atlanta, Georgia", "latency_ms": 137.68744468688965, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Atlanta, Georgia", "latency_ms": 315.68241119384766, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1951}, "4": {"k": 4, "answer": "Atlanta, Georgia", "latency_ms": 153.83124351501465, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2574}, "5": {"k": 5, "answer": "Atlanta, Georgia", "latency_ms": 192.14177131652832, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Atlanta, Georgia", "latency_ms": 255.1281452178955, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3884}}}
{"qid": "7202839397155314666", "question": "how long do former presidents get secret service protection", "gold_answers": ["lifetime", "lifetime protection"], "shots": {"0": {"k": 0, "answer": "Life time", "latency_ms": 120.96858024597168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ten years", "latency_ms": 52.90412902832031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "ten years", "latency_ms": 62.42489814758301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1304}, "3": {"k": 3, "answer": "lifetime", "latency_ms": 232.15103149414062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2028}, "4": {"k": 4, "answer": "lifetime", "latency_ms": 75.33836364746094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2697}, "5": {"k": 5, "answer": "lifetime", "latency_ms": 137.21299171447754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3410}, "6": {"k": 6, "answer": "lifetime", "latency_ms": 98.0381965637207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4075}}}
{"qid": "1714431500025501946", "question": "who is the girl that died in eyes wide shut", "gold_answers": ["Mandy"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 170.29309272766113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jennifer Jason Leigh", "latency_ms": 135.10918617248535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 97.6254940032959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "Mandy", "latency_ms": 179.1248321533203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1794}, "4": {"k": 4, "answer": "Mandy", "latency_ms": 169.41046714782715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2405}, "5": {"k": 5, "answer": "Mandy", "latency_ms": 96.40812873840332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3008}, "6": {"k": 6, "answer": "Mandy", "latency_ms": 120.0566291809082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3600}}}
{"qid": "-6796740151009194942", "question": "where does the last name waller come from", "gold_answers": ["Anglo - Saxon origin"], "shots": {"0": {"k": 0, "answer": "England", "latency_ms": 109.93075370788574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kent", "latency_ms": 140.10143280029297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 688}, "2": {"k": 2, "answer": "Kent", "latency_ms": 63.513994216918945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Kent", "latency_ms": 166.9919490814209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "Kentish family, Groombridge Place", "latency_ms": 542.4675941467285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "Kent", "latency_ms": 177.5534152984619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3249}, "6": {"k": 6, "answer": "Kent", "latency_ms": 298.367977142334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3844}}}
{"qid": "-5096704771829038030", "question": "how many episodes of season 5 of curse of oak island", "gold_answers": ["18"], "shots": {"0": {"k": 0, "answer": "26 episodes", "latency_ms": 240.66925048828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 433.6543083190918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 200.34551620483398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 227.11586952209473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1866}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 307.4328899383545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2496}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 210.99400520324707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3156}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 289.9041175842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3742}}}
{"qid": "-5622212581413495331", "question": "what is a whistle blower suit under the false claims act", "gold_answers": ["qui tam"], "shots": {"0": {"k": 0, "answer": "False Claims Act whistleblower suit", "latency_ms": 411.61131858825684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "qui tam action", "latency_ms": 349.8678207397461, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "a suit filed by a relator under the False Claims Act to recover damages for fraud against the government, often involving pharmaceutical fraud or off-label promotion, with the potential for rewards to the whistleblower.", "latency_ms": 744.6048259735107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "qui tam action", "latency_ms": 239.55130577087402, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2029}, "4": {"k": 4, "answer": "qui tam action", "latency_ms": 171.2026596069336, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "a suit filed by a relator under the False Claims Act to expose fraud against the government, allowing the relator to receive a reward.", "latency_ms": 630.2082538604736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "a suit filed by a relator under the False Claims Act to expose fraud against government programs, allowing the relator to receive a portion of any recovery and enabling the government to pursue litigation against fraudulent entities.", "latency_ms": 1649.9104499816895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4038}}}
{"qid": "-7986594362341759775", "question": "who won the first medal in olympics for india", "gold_answers": ["Norman Pritchard"], "shots": {"0": {"k": 0, "answer": "Dhyan Chand", "latency_ms": 79.55694198608398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Saina Nehwal", "latency_ms": 337.8415107727051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "Saina Nehwal", "latency_ms": 90.09766578674316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Saina Nehwal", "latency_ms": 352.21099853515625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1872}, "4": {"k": 4, "answer": "Khashaba Dadasaheb Jadhav", "latency_ms": 299.1819381713867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2515}, "5": {"k": 5, "answer": "Khashaba Dadasaheb Jadhav", "latency_ms": 781.2323570251465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "Norman Pritchard", "latency_ms": 443.2826042175293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3732}}}
{"qid": "-7779084475859441741", "question": "where did the northernmost land action of the american civil war occur", "gold_answers": ["St. Albans , Vermont"], "shots": {"0": {"k": 0, "answer": "Fort Monroe, Virginia", "latency_ms": 302.3672103881836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "St. Albans, Vermont", "latency_ms": 186.23924255371094, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "St. Albans, Vermont", "latency_ms": 374.9845027923584, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "St. Albans, Vermont", "latency_ms": 411.3740921020508, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "St. Albans, Vermont", "latency_ms": 519.6244716644287, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2551}, "5": {"k": 5, "answer": "St. Albans, Vermont", "latency_ms": 390.41781425476074, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3225}, "6": {"k": 6, "answer": "St. Albans, Vermont", "latency_ms": 337.6457691192627, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3891}}}
{"qid": "1586675134065879913", "question": "what has been the origin of most classical dances of india", "gold_answers": ["the Sanskrit text Natya Shastra", "The Natya Shastra", "Natya Shastra"], "shots": {"0": {"k": 0, "answer": "Hindu religious and cultural traditions", "latency_ms": 291.8589115142822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "varies by dance form; e.g., Kathakali originated in Kerala in the 17th century", "latency_ms": 662.9369258880615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "local traditions and religious performance arts of Hinduism", "latency_ms": 327.29649543762207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1362}, "3": {"k": 3, "answer": "Indian traditions, epics and mythology", "latency_ms": 309.22651290893555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1992}, "4": {"k": 4, "answer": "Indian traditions, epics, and mythology", "latency_ms": 439.66221809387207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2658}, "5": {"k": 5, "answer": "religious art linked to traveling bards, temples and spiritual beliefs", "latency_ms": 452.9411792755127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3290}, "6": {"k": 6, "answer": "Indian traditions, epics, and mythology", "latency_ms": 223.73032569885254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3991}}}
{"qid": "-81929067993816692", "question": "what are the colors of the netherlands flag", "gold_answers": ["red", "blue", "white"], "shots": {"0": {"k": 0, "answer": "Red, white, blue", "latency_ms": 340.9264087677002, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "red, white, blue", "latency_ms": 307.0356845855713, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "red, white, and blue", "latency_ms": 449.24235343933105, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1272}, "3": {"k": 3, "answer": "red, white, and blue", "latency_ms": 136.60192489624023, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1913}, "4": {"k": 4, "answer": "red, white, and blue", "latency_ms": 224.45392608642578, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2552}, "5": {"k": 5, "answer": "red, white, and blue", "latency_ms": 274.4333744049072, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3169}, "6": {"k": 6, "answer": "red, white, and blue", "latency_ms": 258.725643157959, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3812}}}
{"qid": "1760961066899651429", "question": "for complaints of sudden chest pain patients should take a", "gold_answers": ["Aspirin"], "shots": {"0": {"k": 0, "answer": "nitroglycerin tablet", "latency_ms": 103.86919975280762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "focused cardiac ultrasound", "latency_ms": 216.48240089416504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 688}, "2": {"k": 2, "answer": "focused cardiac ultrasound", "latency_ms": 169.74163055419922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "focused cardiac ultrasound", "latency_ms": 138.32521438598633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2056}, "4": {"k": 4, "answer": "emergency ultrasound", "latency_ms": 147.2342014312744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2724}, "5": {"k": 5, "answer": "nitroglycerine", "latency_ms": 132.62176513671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3361}, "6": {"k": 6, "answer": "emergency ultrasound", "latency_ms": 103.62100601196289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3976}}}
{"qid": "8937951134261110938", "question": "where is the majority of phosphorous stored in the environment", "gold_answers": ["minerals", "rocks", "in rocks and minerals"], "shots": {"0": {"k": 0, "answer": "sediments", "latency_ms": 142.47560501098633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 131.2859058380127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 731}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 177.1235466003418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1378}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 107.94377326965332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2013}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 317.88158416748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2633}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 228.0733585357666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "yolks", "latency_ms": 244.73237991333008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3958}}}
{"qid": "-4442420935094556457", "question": "what are the first and second major religions in france", "gold_answers": ["Not religious", "Protestantism", "Islam", "Christianity", "Catholicism"], "shots": {"0": {"k": 0, "answer": "Catholicism, Islam", "latency_ms": 271.9285488128662, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Catholic Church, Islam", "latency_ms": 414.23678398132324, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 707}, "2": {"k": 2, "answer": "Catholic Church, Islam", "latency_ms": 227.33449935913086, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1430}, "3": {"k": 3, "answer": "Catholic Christianity, Islam", "latency_ms": 268.0697441101074, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2089}, "4": {"k": 4, "answer": "Catholic Christianity, Islam", "latency_ms": 456.41136169433594, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2792}, "5": {"k": 5, "answer": "Catholic Christianity, Islam", "latency_ms": 199.4016170501709, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3541}, "6": {"k": 6, "answer": "Catholic Christianity, Islam", "latency_ms": 208.08672904968262, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4228}}}
{"qid": "901318007750137005", "question": "who played sandy's jock boyfriend in grease", "gold_answers": ["Lorenzo Lamas", "John Travolta"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 126.46245956420898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tom  \nI cannot answer.", "latency_ms": 143.73326301574707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 103.72471809387207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "Lorenzo Lamas", "latency_ms": 168.84708404541016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Lorenzo Lamas", "latency_ms": 420.5443859100342, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2590}, "5": {"k": 5, "answer": "Lorenzo Lamas", "latency_ms": 161.5312099456787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3192}, "6": {"k": 6, "answer": "Lorenzo Lamas", "latency_ms": 467.0112133026123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3801}}}
{"qid": "1313603041913512234", "question": "who won the fountain of youth stakes at gulfstream park", "gold_answers": ["Gunnevera"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 121.02413177490234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "News Pending", "latency_ms": 116.45054817199707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Irish War Cry", "latency_ms": 110.17775535583496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "Gunnevera", "latency_ms": 143.9969539642334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1852}, "4": {"k": 4, "answer": "Gunnevera", "latency_ms": 170.41826248168945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2476}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 241.87111854553223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3020}, "6": {"k": 6, "answer": "Promises Fulfilled", "latency_ms": 155.08103370666504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3591}}}
{"qid": "5041926080499682775", "question": "what is the name of the first earthquake early warning system", "gold_answers": ["1991", "The Mexican Seismic Alert System"], "shots": {"0": {"k": 0, "answer": "K-NET", "latency_ms": 139.95838165283203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 137.3751163482666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 743}, "2": {"k": 2, "answer": "Shakealarm", "latency_ms": 75.46424865722656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1398}, "3": {"k": 3, "answer": "Urgent Earthquake Detection and Alarm System (UrEDAS)", "latency_ms": 532.8164100646973, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 2055}, "4": {"k": 4, "answer": "Urgent Earthquake Detection and Alarm System (UrEDAS)", "latency_ms": 532.7708721160889, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 2723}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 257.0011615753174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3445}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 243.1013584136963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4105}}}
{"qid": "5657290829500032975", "question": "who plays gram on the young and the restless", "gold_answers": ["Max Shippee"], "shots": {"0": {"k": 0, "answer": "Jerry O'Connell", "latency_ms": 192.1067237854004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 218.02926063537598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 184.66639518737793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 344.53511238098145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 364.10045623779297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 241.37234687805176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 184.08656120300293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3871}}}
{"qid": "-5777361948264487802", "question": "where was robin hood prince of thieves made", "gold_answers": ["the United Kingdom"], "shots": {"0": {"k": 0, "answer": "USA", "latency_ms": 135.4992389678955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corriganville and Columbia's \"The Bandit of Sherwood Forest\" sets", "latency_ms": 301.01537704467773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "England, France, Wiltshire, Northumberland, Buckinghamshire, Yorkshire, North Yorkshire", "latency_ms": 867.3982620239258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "England and France", "latency_ms": 115.29159545898438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1921}, "4": {"k": 4, "answer": "Cité de Carcassonne, Wardour Castle, Hulne Priory, Burnham Beeches, Aysgarth Falls, Hardraw Force, Sycamore Gap, Seven Sisters, Shepperton Studios", "latency_ms": 2419.6267127990723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2590}, "5": {"k": 5, "answer": "Cité de Carcassonne, Wardour Castle, Hulne Priory, Burnham Beeches, Aysgarth Falls, Hardraw Force, Sycamore Gap, Seven Sisters, Shepperton Studios", "latency_ms": 1166.766881942749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3257}, "6": {"k": 6, "answer": "Cité de Carcassonne, Wardour Castle, Hulne Priory, Burnham Beeches, Aysgarth Falls, Hardraw Force, Sycamore Gap, Seven Sisters, Shepperton Studios", "latency_ms": 987.9322052001953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3907}}}
{"qid": "551104541198591245", "question": "who sang last night on saturday night live", "gold_answers": ["Childish Gambino"], "shots": {"0": {"k": 0, "answer": "John Mulaney", "latency_ms": 64.59808349609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ashlee Simpson", "latency_ms": 127.89273262023926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 105.70430755615234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 209.48505401611328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 133.15677642822266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2554}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 389.44053649902344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3190}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 301.98097229003906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3910}}}
{"qid": "2215178120143119386", "question": "where does the president get authority to issue executive orders", "gold_answers": ["Constitution"], "shots": {"0": {"k": 0, "answer": "Constitution", "latency_ms": 233.95109176635742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Constitution of the Philippines", "latency_ms": 241.52731895446777, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 750}, "2": {"k": 2, "answer": "Constitution or law", "latency_ms": 286.91697120666504, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1403}, "3": {"k": 3, "answer": "Constitution or law", "latency_ms": 364.3646240234375, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2124}, "4": {"k": 4, "answer": "Constitution and/or Acts of Congress", "latency_ms": 408.92720222473145, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2759}, "5": {"k": 5, "answer": "Constitution and/or Acts of Congress", "latency_ms": 216.82429313659668, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3439}, "6": {"k": 6, "answer": "Constitution and/or Acts of Congress", "latency_ms": 240.79203605651855, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 4146}}}
{"qid": "5213391394254852796", "question": "who was originally cast as phoebe on charmed", "gold_answers": ["Lori Rom"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 235.7769012451172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lori Rom", "latency_ms": 67.70443916320801, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "Lori Rom", "latency_ms": 96.61412239074707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "Lori Rom", "latency_ms": 202.47554779052734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Lori Rom", "latency_ms": 159.38854217529297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Lori Rom", "latency_ms": 224.3173122406006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3195}, "6": {"k": 6, "answer": "Lori Rom", "latency_ms": 217.17405319213867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3798}}}
{"qid": "-381301893645124054", "question": "who owns the delano hotel in las vegas", "gold_answers": ["MGM Resorts International"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 148.7140655517578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "MGM Resorts International", "latency_ms": 180.0234317779541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 613}, "2": {"k": 2, "answer": "MGM Resorts International", "latency_ms": 151.40533447265625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 221.30799293518066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "MGM Resorts International", "latency_ms": 283.5063934326172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2487}, "5": {"k": 5, "answer": "MGM Resorts International", "latency_ms": 147.11380004882812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3115}, "6": {"k": 6, "answer": "MGM Resorts International", "latency_ms": 304.68273162841797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3752}}}
{"qid": "-8936544552400860961", "question": "when did the us dollar leave the gold standard", "gold_answers": ["1934", "August 15 , 1971", "October 1976"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 98.81186485290527, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1933", "latency_ms": 84.4278335571289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "1933", "latency_ms": 114.81475830078125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "1933", "latency_ms": 238.6775016784668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2047}, "4": {"k": 4, "answer": "1933", "latency_ms": 298.1860637664795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2683}, "5": {"k": 5, "answer": "April 19, 1933", "latency_ms": 596.0967540740967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3341}, "6": {"k": 6, "answer": "1933", "latency_ms": 246.45709991455078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4005}}}
{"qid": "-1446394904764739888", "question": "who played bailey in the sisterhood of the traveling pants", "gold_answers": ["Jenna Boyd"], "shots": {"0": {"k": 0, "answer": "Morgan Fairchild", "latency_ms": 152.28009223937988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jenna Boyd", "latency_ms": 103.31368446350098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Jenna Boyd", "latency_ms": 218.5842990875244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1304}, "3": {"k": 3, "answer": "Jenna Boyd", "latency_ms": 144.24681663513184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1912}, "4": {"k": 4, "answer": "Jenna Boyd", "latency_ms": 199.27525520324707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2569}, "5": {"k": 5, "answer": "Jenna Boyd", "latency_ms": 208.6172103881836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3213}, "6": {"k": 6, "answer": "Jenna Boyd", "latency_ms": 325.9286880493164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3866}}}
{"qid": "-3431328641910966671", "question": "who has the most followers on the instagram", "gold_answers": ["Instagram 's own account", "Selena Gomez"], "shots": {"0": {"k": 0, "answer": "Instagram does not officially disclose who has the most followers. However, as of the latest available data, **Cristiano Ronaldo** holds the highest number of followers on Instagram among public figures. \n\n**Cristiano Ronaldo**", "latency_ms": 732.3474884033203, "em": 0.0, "f1": 0.060606060606060594, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 88.12236785888672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 724}, "2": {"k": 2, "answer": "Selena Gomez", "latency_ms": 171.23913764953613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1383}, "3": {"k": 3, "answer": "Selena Gomez", "latency_ms": 161.01884841918945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2074}, "4": {"k": 4, "answer": "Selena Gomez", "latency_ms": 305.51695823669434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2715}, "5": {"k": 5, "answer": "Selena Gomez", "latency_ms": 190.17481803894043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3444}, "6": {"k": 6, "answer": "Selena Gomez", "latency_ms": 143.46599578857422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4103}}}
{"qid": "6083242206629579849", "question": "how many national parks are present in india", "gold_answers": ["103"], "shots": {"0": {"k": 0, "answer": "8", "latency_ms": 71.34366035461426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "89", "latency_ms": 86.43817901611328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "103", "latency_ms": 182.57403373718262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1303}, "3": {"k": 3, "answer": "103", "latency_ms": 148.88334274291992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1984}, "4": {"k": 4, "answer": "103", "latency_ms": 291.1994457244873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2621}, "5": {"k": 5, "answer": "103", "latency_ms": 229.2187213897705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "103", "latency_ms": 168.27702522277832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3942}}}
{"qid": "-4974831750077564519", "question": "what is an open university grade 3 pass", "gold_answers": ["55 -- 69 %"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 79.69403266906738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "55–69%", "latency_ms": 281.1882495880127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "55–69%", "latency_ms": 121.36101722717285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "55–69%", "latency_ms": 130.52868843078613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "55–69%", "latency_ms": 194.5934295654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "55–69%", "latency_ms": 196.87509536743164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3252}, "6": {"k": 6, "answer": "55–69%", "latency_ms": 202.43501663208008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3841}}}
{"qid": "5681428027016661807", "question": "what episode of pll does jenna get her sight back", "gold_answers": ["Blood is the New Black", "If These Dolls Could Talk"], "shots": {"0": {"k": 0, "answer": "Episode 107", "latency_ms": 284.23476219177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 332.7779769897461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 580}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 92.2093391418457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 199.74589347839355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1793}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 194.16570663452148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2362}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 215.91663360595703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2979}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 294.1720485687256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3613}}}
{"qid": "-3477735079009921203", "question": "when did they start 3 pointers in basketball", "gold_answers": ["1945", "1961"], "shots": {"0": {"k": 0, "answer": "1979", "latency_ms": 80.80554008483887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1967–68 season", "latency_ms": 198.5921859741211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "1963–64 season", "latency_ms": 227.7543544769287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1360}, "3": {"k": 3, "answer": "1963–64 season", "latency_ms": 433.12597274780273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "1963–64 season", "latency_ms": 350.33726692199707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2587}, "5": {"k": 5, "answer": "1979", "latency_ms": 178.192138671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3172}, "6": {"k": 6, "answer": "1979", "latency_ms": 222.62883186340332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3793}}}
{"qid": "-2369485327238056918", "question": "when will miraculous season 2 episode 11 be released", "gold_answers": ["30 March 2018", "27 October 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 139.94359970092773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 138.88859748840332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 148.70476722717285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 104.72726821899414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1939}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 234.7123622894287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 277.1883010864258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3242}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 256.7281723022461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3910}}}
{"qid": "-7387192194058750655", "question": "how many episodes in season 4 of last ship", "gold_answers": ["10"], "shots": {"0": {"k": 0, "answer": "22 episodes", "latency_ms": 111.60659790039062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "10", "latency_ms": 133.70513916015625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 576}, "2": {"k": 2, "answer": "10", "latency_ms": 149.7790813446045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "10", "latency_ms": 233.05010795593262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1831}, "4": {"k": 4, "answer": "10", "latency_ms": 161.16738319396973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2443}, "5": {"k": 5, "answer": "10", "latency_ms": 183.35223197937012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3073}, "6": {"k": 6, "answer": "10", "latency_ms": 322.15046882629395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3696}}}
{"qid": "-6522981514285898713", "question": "when did the phantom of the opera open", "gold_answers": ["1986", "9 October 1986", "October 1986 :"], "shots": {"0": {"k": 0, "answer": "1875", "latency_ms": 351.1319160461426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "9 March 2010", "latency_ms": 443.56775283813477, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "9 March 2010", "latency_ms": 390.26451110839844, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1305}, "3": {"k": 3, "answer": "November 3, 1989", "latency_ms": 712.6626968383789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1993}, "4": {"k": 4, "answer": "1989", "latency_ms": 239.39108848571777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "November 3, 1989", "latency_ms": 402.3091793060303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3275}, "6": {"k": 6, "answer": "9 March 2010", "latency_ms": 506.5438747406006, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3942}}}
{"qid": "-2535625954029346686", "question": "where does the water from the california aqueduct come from", "gold_answers": ["the Sierra Nevada Mountains", "Sierra Nevada Mountains"], "shots": {"0": {"k": 0, "answer": "Sacramento and San Joaquin Rivers", "latency_ms": 512.4576091766357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Owens River area and Colorado River", "latency_ms": 496.5338706970215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Northern California and the Colorado River", "latency_ms": 450.96278190612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "Northern California and the Colorado River", "latency_ms": 282.3026180267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "Sierra Nevada Mountains and valleys of Northern and Central California", "latency_ms": 574.9750137329102, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2671}, "5": {"k": 5, "answer": "Sierra Nevada Mountains and valleys of Northern and Central California", "latency_ms": 892.1010494232178, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3327}, "6": {"k": 6, "answer": "Sierra Nevada Mountains and valleys of Northern and Central California", "latency_ms": 500.69665908813477, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 4001}}}
{"qid": "45454687663773304", "question": "when did drop it like it's hot release", "gold_answers": ["September 12 , 2004"], "shots": {"0": {"k": 0, "answer": "2013", "latency_ms": 75.84643363952637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2004", "latency_ms": 85.55459976196289, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "2004", "latency_ms": 255.74851036071777, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1207}, "3": {"k": 3, "answer": "2004", "latency_ms": 126.14846229553223, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1822}, "4": {"k": 4, "answer": "2004", "latency_ms": 252.65121459960938, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2436}, "5": {"k": 5, "answer": "2004", "latency_ms": 142.622709274292, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3054}, "6": {"k": 6, "answer": "2004", "latency_ms": 223.5260009765625, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3682}}}
{"qid": "-6426837123523105683", "question": "what are the 5 boroughs of new york city", "gold_answers": ["Manhattan", "Queens", "Brooklyn", "the Bronx", "Staten Island"], "shots": {"0": {"k": 0, "answer": "Brooklyn, Queens, Manhattan, Bronx, Staten Island", "latency_ms": 437.36982345581055, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The five boroughs of New York City are Brooklyn, Queens, Manhattan, Bronx, and Staten Island.", "latency_ms": 1163.3272171020508, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 655}, "2": {"k": 2, "answer": "Brooklyn, Queens, Manhattan, The Bronx, Staten Island", "latency_ms": 427.16002464294434, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Brooklyn, Queens, Manhattan, The Bronx, Staten Island", "latency_ms": 339.07246589660645, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1868}, "4": {"k": 4, "answer": "Manhattan, Brooklyn, Queens, The Bronx, Staten Island", "latency_ms": 456.254243850708, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Manhattan, Brooklyn, Queens, The Bronx, Staten Island", "latency_ms": 227.08368301391602, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Manhattan, Brooklyn, Queens, The Bronx, Staten Island", "latency_ms": 430.9043884277344, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3880}}}
{"qid": "-8473146838282712240", "question": "what is the main industry in the canadian shield", "gold_answers": ["mining"], "shots": {"0": {"k": 0, "answer": "mining", "latency_ms": 53.03049087524414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "forestry, mineral, and hydro-electric resources", "latency_ms": 163.29026222229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 693}, "2": {"k": 2, "answer": "mining", "latency_ms": 93.98841857910156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1325}, "3": {"k": 3, "answer": "mining", "latency_ms": 143.0680751800537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1944}, "4": {"k": 4, "answer": "mining", "latency_ms": 189.42523002624512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2626}, "5": {"k": 5, "answer": "mining", "latency_ms": 300.492525100708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3295}, "6": {"k": 6, "answer": "mining", "latency_ms": 277.5583267211914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3950}}}
{"qid": "3044315244849112225", "question": "what makes a mini bike a mini bike", "gold_answers": ["a miniature motorcycle"], "shots": {"0": {"k": 0, "answer": "small size and lightweight design", "latency_ms": 351.31287574768066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mini125's frame design and polyurethane wheels of 125 mm or 110 mm diameter", "latency_ms": 919.0263748168945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "slick tires on go-cart tracks", "latency_ms": 231.7218780517578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "slick tires on go-cart tracks, much like super-motard or super-moto", "latency_ms": 708.1389427185059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1776}, "4": {"k": 4, "answer": "a miniature motorcycle with two-stroke engines and chain drive", "latency_ms": 437.05177307128906, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2427}, "5": {"k": 5, "answer": "a miniature motorcycle with two-stroke engines and chain drive, often used as pit bikes or for racing on go-cart tracks", "latency_ms": 555.0403594970703, "em": 0.0, "f1": 0.19047619047619052, "containment": 1.0, "context_chars": 3007}, "6": {"k": 6, "answer": "a miniature motorcycle with two-stroke engines and chain drive, typically used in racing or as a pocket bike", "latency_ms": 542.8812503814697, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3621}}}
{"qid": "9191821996395940885", "question": "who plays addison shepherd on grey's anatomy", "gold_answers": ["Kathleen Erin Walsh"], "shots": {"0": {"k": 0, "answer": "Justin Chambers", "latency_ms": 104.1712760925293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kate Walsh", "latency_ms": 87.64219284057617, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 725}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 230.06200790405273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "Kate Walsh", "latency_ms": 168.83039474487305, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2066}, "4": {"k": 4, "answer": "Kate Walsh", "latency_ms": 196.26474380493164, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2702}, "5": {"k": 5, "answer": "Kate Walsh", "latency_ms": 188.53759765625, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3369}, "6": {"k": 6, "answer": "Kate Walsh", "latency_ms": 184.70048904418945, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4079}}}
{"qid": "2380242233996575552", "question": "how long do you have to serve in the israeli military", "gold_answers": ["two years for women"], "shots": {"0": {"k": 0, "answer": "18 months to 3 years", "latency_ms": 244.36092376708984, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Men: 2 years and 8 months; Women: 2 years", "latency_ms": 214.97607231140137, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Men: 36 months; Women: 24 months", "latency_ms": 597.6550579071045, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 1227}, "3": {"k": 3, "answer": "Men: 2 years and 8 months; Women: 2 years", "latency_ms": 296.64134979248047, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Men: 2 years and 8 months; Women: 2 years", "latency_ms": 427.3958206176758, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "Men: 2 years and 8 months; Women: 2 years", "latency_ms": 384.1207027435303, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "Men: 2 years 8 months; Women: 2 years", "latency_ms": 869.1868782043457, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3846}}}
{"qid": "-2392194179245913511", "question": "most polluted city in the world according to world health organization", "gold_answers": ["Zabol"], "shots": {"0": {"k": 0, "answer": "Delhi", "latency_ms": 54.293155670166016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New Delhi", "latency_ms": 85.51955223083496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 716}, "2": {"k": 2, "answer": "New Delhi", "latency_ms": 76.20549201965332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1335}, "3": {"k": 3, "answer": "Delhi", "latency_ms": 122.72310256958008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Delhi", "latency_ms": 88.74678611755371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "Delhi", "latency_ms": 102.74815559387207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3272}, "6": {"k": 6, "answer": "Delhi", "latency_ms": 157.22990036010742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3916}}}
{"qid": "4012602576624292720", "question": "who won the award for best goalkeeper in football world cup 2006", "gold_answers": ["Gianluigi Buffon"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 276.96895599365234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 80.63149452209473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 101.8831729888916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1176}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 113.33346366882324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1796}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 125.51426887512207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2427}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 128.02457809448242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3046}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 236.89031600952148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3675}}}
{"qid": "91605593274493502", "question": "which horse and jockey won the melbourne cup in 2002", "gold_answers": ["Damien Oliver", "Media Puzzle"], "shots": {"0": {"k": 0, "answer": "Maximum Security and Peter Snowden", "latency_ms": 150.71749687194824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 153.4416675567627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Gala Supreme, Frank Reys", "latency_ms": 183.40635299682617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "Brew, Kerrin McEvoy", "latency_ms": 336.00926399230957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Brew, Kerrin McEvoy", "latency_ms": 213.47522735595703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Brew, Kerrin McEvoy", "latency_ms": 387.5441551208496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3178}, "6": {"k": 6, "answer": "Brew, Kerrin McEvoy", "latency_ms": 358.97326469421387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3849}}}
{"qid": "-266038724951254114", "question": "who wrote the song to make you feel my love", "gold_answers": ["Bob Dylan"], "shots": {"0": {"k": 0, "answer": "Kenny Loggins", "latency_ms": 128.9517879486084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bob Dylan", "latency_ms": 230.9548854827881, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 589}, "2": {"k": 2, "answer": "Bob Dylan", "latency_ms": 73.25267791748047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1180}, "3": {"k": 3, "answer": "Bob Dylan", "latency_ms": 196.00534439086914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1792}, "4": {"k": 4, "answer": "Bob Dylan", "latency_ms": 116.8367862701416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2414}, "5": {"k": 5, "answer": "Bob Dylan", "latency_ms": 104.61688041687012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3044}, "6": {"k": 6, "answer": "Bob Dylan", "latency_ms": 105.62634468078613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3634}}}
{"qid": "-7708021254791334132", "question": "what is the origin of the name marvin", "gold_answers": ["Welsh", "the Welsh name Mervyn"], "shots": {"0": {"k": 0, "answer": "Germanic name, from \"mær\" (holy) and \"win\" (prosperity)", "latency_ms": 762.5563144683838, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "originated from \"Commander of Flying Saucer X-2\" in \"The Hasty Hare\" (1952)", "latency_ms": 699.235200881958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "originally named Commander of Flying Saucer X-2 in \"The Hasty Hare\" (1952)", "latency_ms": 1097.4366664886475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "originated in the original shorts as \"Commander of Flying Saucer X-2\" in \"The Hasty Hare\" (1952)", "latency_ms": 998.788595199585, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "originated from \"Commander of Flying Saucer X-2\" in \"The Hasty Hare\" (1952)", "latency_ms": 984.1477870941162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2602}, "5": {"k": 5, "answer": "origin name selected decades later for merchandising interest", "latency_ms": 518.1477069854736, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 3179}, "6": {"k": 6, "answer": "origin name selected decades later for merchandising interest", "latency_ms": 588.8817310333252, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 3765}}}
{"qid": "-5663213976858775002", "question": "who are the nbc olympic ice skating commentators", "gold_answers": ["Chris Vosters", "Tanith White", "Jonny Moseley", "Johnny Weir", "Andrea Joyce", "Luke Van Valin", "Terry Gannon", "Charlie White", "Tara Lipinski"], "shots": {"0": {"k": 0, "answer": "Chris O'Leary, Chris Davidson, and John C. Sullivan", "latency_ms": 333.47463607788086, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Johnny Weir and Lipinski", "latency_ms": 204.8346996307373, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Johnny Weir and Lipinski", "latency_ms": 206.9401741027832, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1300}, "3": {"k": 3, "answer": "Johnny Weir and Scott Lipinski", "latency_ms": 145.0498104095459, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1971}, "4": {"k": 4, "answer": "Terry Gannon, Tara Lipinski, Johnny Weir", "latency_ms": 504.09722328186035, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2642}, "5": {"k": 5, "answer": "Johnny Weir and Tara Lipinski", "latency_ms": 335.7868194580078, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3262}, "6": {"k": 6, "answer": "Johnny Weir and Tara Lipinski", "latency_ms": 388.6094093322754, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3838}}}
{"qid": "-220898254038111873", "question": "where did immigrants enter the us on the west coast", "gold_answers": ["San Francisco Bay", "Angel Island Immigration Station"], "shots": {"0": {"k": 0, "answer": "California", "latency_ms": 98.58870506286621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "California", "latency_ms": 180.6924343109131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 679}, "2": {"k": 2, "answer": "California and other west coast states", "latency_ms": 125.03218650817871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1354}, "3": {"k": 3, "answer": "California and other west coast states", "latency_ms": 161.07964515686035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2023}, "4": {"k": 4, "answer": "California and other west coast states", "latency_ms": 152.6315212249756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2698}, "5": {"k": 5, "answer": "California and other west coast states", "latency_ms": 187.0591640472412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3365}, "6": {"k": 6, "answer": "California and other west coast states", "latency_ms": 506.0594081878662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4021}}}
{"qid": "-8424688964238112177", "question": "how many episodes of sabrina the teenage witch are there", "gold_answers": ["163"], "shots": {"0": {"k": 0, "answer": "110", "latency_ms": 150.66266059875488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "66", "latency_ms": 132.70211219787598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "66 episodes", "latency_ms": 272.92585372924805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "66 episodes", "latency_ms": 131.51812553405762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1869}, "4": {"k": 4, "answer": "66 episodes", "latency_ms": 265.6402587890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "66 episodes", "latency_ms": 221.52209281921387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "66 episodes", "latency_ms": 229.70008850097656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3830}}}
{"qid": "-2339353670444421139", "question": "who was tammy from basketball wives married to", "gold_answers": ["basketball player Kenny Anderson", "Kenny Anderson"], "shots": {"0": {"k": 0, "answer": "Drew \"Drew\" Bledsoe", "latency_ms": 626.7862319946289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 171.3879108428955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.87376022338867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 241.97149276733398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1979}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 234.6174716949463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2626}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 176.4240264892578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3340}, "6": {"k": 6, "answer": "Kenny Anderson", "latency_ms": 206.44354820251465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4029}}}
{"qid": "7300348346327235173", "question": "what is the lead singers name of staind", "gold_answers": ["Aaron Lewis"], "shots": {"0": {"k": 0, "answer": "Nick Long", "latency_ms": 117.41209030151367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Aaron Lewis", "latency_ms": 149.0640640258789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 678}, "2": {"k": 2, "answer": "Aaron Lewis", "latency_ms": 99.05123710632324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1353}, "3": {"k": 3, "answer": "Aaron Lewis", "latency_ms": 133.19015502929688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Aaron Lewis", "latency_ms": 203.6876678466797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2639}, "5": {"k": 5, "answer": "Aaron Lewis", "latency_ms": 198.05002212524414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3276}, "6": {"k": 6, "answer": "Aaron Lewis", "latency_ms": 288.6524200439453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3910}}}
{"qid": "1096973491164113721", "question": "what type of legal system is used in the uk", "gold_answers": ["English law", "Northern Ireland law", "Scots law"], "shots": {"0": {"k": 0, "answer": "Common law system", "latency_ms": 121.42443656921387, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Three legal systems: English (and Welsh) law, Northern Ireland law, and Scots law.", "latency_ms": 421.036958694458, "em": 0.0, "f1": 0.375, "containment": 1.0, "context_chars": 638}, "2": {"k": 2, "answer": "Three distinct legal systems: English law, Northern Ireland law, and Scots law.", "latency_ms": 428.8034439086914, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1304}, "3": {"k": 3, "answer": "Three distinct legal systems: English law, Northern Ireland law, and Scots law.", "latency_ms": 790.6322479248047, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1939}, "4": {"k": 4, "answer": "three distinct systems: English law, Northern Ireland law, and Scots law", "latency_ms": 416.95332527160645, "em": 0.0, "f1": 0.42857142857142855, "containment": 1.0, "context_chars": 2564}, "5": {"k": 5, "answer": "three distinct legal systems: English law, Northern Ireland law, and Scots law", "latency_ms": 621.5395927429199, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "three distinct legal systems: English law, Northern Ireland law, and Scots law", "latency_ms": 693.558931350708, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3864}}}
{"qid": "-4616396511053338139", "question": "when did macbook pro 13 inch come out", "gold_answers": ["June 8 , 2009", "October 2008"], "shots": {"0": {"k": 0, "answer": "2006", "latency_ms": 109.65657234191895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 27, 2016", "latency_ms": 509.78899002075195, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "October 2012", "latency_ms": 125.18739700317383, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "October 23, 2012", "latency_ms": 724.7745990753174, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "October 23, 2012", "latency_ms": 451.2951374053955, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2615}, "5": {"k": 5, "answer": "October 23, 2012", "latency_ms": 420.9859371185303, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3270}, "6": {"k": 6, "answer": "October 23, 2012", "latency_ms": 302.59060859680176, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3907}}}
{"qid": "6453011233363353306", "question": "the heart muscle is stimulated to contract by electrical impulses which are generated where", "gold_answers": ["the sinoatrial node"], "shots": {"0": {"k": 0, "answer": "sinoatrial node", "latency_ms": 113.92521858215332, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "central nervous system", "latency_ms": 115.54145812988281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "sinoatrial node", "latency_ms": 138.91172409057617, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1350}, "3": {"k": 3, "answer": "sinoatrial node", "latency_ms": 462.1903896331787, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "sinoatrial node", "latency_ms": 412.4412536621094, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2674}, "5": {"k": 5, "answer": "sinoatrial node", "latency_ms": 133.5306167602539, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3435}, "6": {"k": 6, "answer": "sinoatrial node", "latency_ms": 140.0747299194336, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4139}}}
{"qid": "6013935156766849636", "question": "who is known as the super fast boy in the series the icredible", "gold_answers": ["Dashiell Robert Parr / Dash"], "shots": {"0": {"k": 0, "answer": "Jack Jr.", "latency_ms": 81.03346824645996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 125.21743774414062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 201.89309120178223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 177.97398567199707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 222.01776504516602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 312.92200088500977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3193}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 289.7307872772217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3808}}}
{"qid": "948189619534195047", "question": "who plays the robot on the orville show", "gold_answers": ["Mark Jackson"], "shots": {"0": {"k": 0, "answer": "Chad L. Coleman", "latency_ms": 196.7170238494873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 161.73434257507324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 138.80157470703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 191.7552947998047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 292.6149368286133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 237.24961280822754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3165}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 383.5883140563965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3834}}}
{"qid": "2484343456230333941", "question": "book series about the end of the world", "gold_answers": ["Left Behind"], "shots": {"0": {"k": 0, "answer": "The Road", "latency_ms": 73.65989685058594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Age of Misrule", "latency_ms": 174.95465278625488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "The Age of Misrule trilogy", "latency_ms": 342.254638671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 112.63704299926758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 394.4394588470459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2532}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 184.9813461303711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "World's End (Chadbourn novel)", "latency_ms": 254.2252540588379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3774}}}
{"qid": "-8853360627511483976", "question": "how many numbers are in the euromillions draw", "gold_answers": ["7"], "shots": {"0": {"k": 0, "answer": "5 main numbers, 2 lucky stars", "latency_ms": 322.75390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "7", "latency_ms": 52.254438400268555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "7", "latency_ms": 142.40217208862305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1233}, "3": {"k": 3, "answer": "7", "latency_ms": 144.36793327331543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1792}, "4": {"k": 4, "answer": "7", "latency_ms": 177.05988883972168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2386}, "5": {"k": 5, "answer": "7", "latency_ms": 160.12096405029297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2996}, "6": {"k": 6, "answer": "7", "latency_ms": 225.33583641052246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3585}}}
