{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "2024", "latency_ms": 106.35018348693848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 21, 2018", "latency_ms": 357.1321964263916, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "June 21, 2018", "latency_ms": 533.2057476043701, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "June 21, 2018", "latency_ms": 179.83365058898926, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1929}, "4": {"k": 4, "answer": "June 21, 2018", "latency_ms": 204.6523094177246, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2611}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 356.65249824523926, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3245}, "6": {"k": 6, "answer": "June 21, 2018", "latency_ms": 822.404146194458, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3822}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Biathlon, Freestyle, Snowboard", "latency_ms": 250.61774253845215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alpine skiing", "latency_ms": 117.1104907989502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Alpine skiing, cross-country skiing", "latency_ms": 240.67139625549316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "Alpine skiing, cross-country skiing", "latency_ms": 562.5758171081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2046}, "4": {"k": 4, "answer": "Alpine skiing, cross-country skiing", "latency_ms": 402.6815891265869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2734}, "5": {"k": 5, "answer": "Alpine skiing, cross-country skiing", "latency_ms": 364.091157913208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3395}, "6": {"k": 6, "answer": "Alpine skiing, cross-country skiing", "latency_ms": 315.692663192749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4125}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "David H. Morrissey", "latency_ms": 309.58056449890137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gino Poletti", "latency_ms": 479.081392288208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Gino Poletti", "latency_ms": 242.53106117248535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Gino Poletti", "latency_ms": 307.21259117126465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2019}, "4": {"k": 4, "answer": "Gino Poletti", "latency_ms": 207.93795585632324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "Gino Poletti", "latency_ms": 280.43389320373535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3267}, "6": {"k": 6, "answer": "Gino Poletti", "latency_ms": 475.1238822937012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3797}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "Pittsburgh Steelers", "latency_ms": 193.97473335266113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Giants, Dallas Cowboys", "latency_ms": 414.17765617370605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "New York Giants, Dallas Cowboys", "latency_ms": 251.2671947479248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "New York Giants, Dallas Cowboys, San Diego Chargers", "latency_ms": 568.2768821716309, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Broncos, Giants, Cowboys", "latency_ms": 403.4848213195801, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2492}, "5": {"k": 5, "answer": "Giants, Cowboys, Broncos, Chargers", "latency_ms": 216.13073348999023, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3080}, "6": {"k": 6, "answer": "Giants, Cowboys, Broncos, Chargers", "latency_ms": 321.0310935974121, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3712}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "1985", "latency_ms": 182.45744705200195, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1985", "latency_ms": 124.55081939697266, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 130.71608543395996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1424}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 204.67495918273926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2144}, "4": {"k": 4, "answer": "8 December 1985", "latency_ms": 406.87012672424316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2861}, "5": {"k": 5, "answer": "8 December 1985", "latency_ms": 305.5589199066162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3619}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 365.85402488708496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4315}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "cypress knees", "latency_ms": 134.23991203308105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spanish moss", "latency_ms": 208.02068710327148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "Spanish moss", "latency_ms": 65.14549255371094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Spanish moss", "latency_ms": 267.6687240600586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1999}, "4": {"k": 4, "answer": "Spanish moss", "latency_ms": 219.9270725250244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2587}, "5": {"k": 5, "answer": "Spanish moss", "latency_ms": 143.07332038879395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3326}, "6": {"k": 6, "answer": "Spanish moss", "latency_ms": 241.77312850952148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3970}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "NYHA Class I-IV", "latency_ms": 317.9786205291748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 163.1157398223877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 762}, "2": {"k": 2, "answer": "shortness of breath and/or angina", "latency_ms": 381.7112445831299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1494}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.8871955871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2250}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 220.32546997070312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2959}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 243.39532852172852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 169.57759857177734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4305}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Dolly Parton", "latency_ms": 93.50728988647461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mike Leeson and Peter Vale", "latency_ms": 174.93176460266113, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 583}, "2": {"k": 2, "answer": "Mike Leeson and Peter Vale", "latency_ms": 222.18656539916992, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1219}, "3": {"k": 3, "answer": "Mike Leeson and Peter Vale", "latency_ms": 287.49656677246094, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "Mike Leeson and Peter Vale", "latency_ms": 394.03343200683594, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2465}, "5": {"k": 5, "answer": "Mike Leeson and Peter Vale", "latency_ms": 237.93268203735352, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3111}, "6": {"k": 6, "answer": "Mike Leeson and Peter Vale", "latency_ms": 172.62601852416992, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3729}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 194.31042671203613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 109.04884338378906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "3", "latency_ms": 59.39817428588867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "3", "latency_ms": 70.22809982299805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1971}, "4": {"k": 4, "answer": "3", "latency_ms": 189.69488143920898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2611}, "5": {"k": 5, "answer": "3", "latency_ms": 91.16601943969727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "3", "latency_ms": 89.15877342224121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3934}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "biscuit", "latency_ms": 149.71160888671875, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biscuit-sized cake", "latency_ms": 122.32041358947754, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "cake", "latency_ms": 86.15660667419434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "cake", "latency_ms": 89.71452713012695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1764}, "4": {"k": 4, "answer": "cake", "latency_ms": 110.29386520385742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2405}, "5": {"k": 5, "answer": "cake", "latency_ms": 133.6665153503418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2986}, "6": {"k": 6, "answer": "a cake", "latency_ms": 134.76300239562988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3608}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Dan Castellaneta", "latency_ms": 88.89055252075195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seth MacFarlane", "latency_ms": 451.016902923584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "Seth MacFarlane", "latency_ms": 102.55765914916992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "Seth MacFarlane", "latency_ms": 299.18766021728516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1979}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 316.5724277496338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2652}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 269.66238021850586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3293}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 316.74933433532715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3995}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "cocaine", "latency_ms": 68.29714775085449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "amphetamines", "latency_ms": 166.14699363708496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "amphetamines", "latency_ms": 160.45141220092773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1186}, "3": {"k": 3, "answer": "amphetamines/diet pills", "latency_ms": 474.2107391357422, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1866}, "4": {"k": 4, "answer": "amphetamines", "latency_ms": 151.99542045593262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2474}, "5": {"k": 5, "answer": "amphetamines", "latency_ms": 198.5607147216797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3116}, "6": {"k": 6, "answer": "amphetamines", "latency_ms": 407.642126083374, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3735}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "19 minutes 38 seconds", "latency_ms": 374.3782043457031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 137.57586479187012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 95.73936462402344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1169}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 203.42421531677246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 185.469388961792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2434}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 290.696382522583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3053}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 358.1197261810303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3635}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "London, UK", "latency_ms": 226.18556022644043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yushan, China", "latency_ms": 217.03720092773438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 245.00226974487305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 115.58938026428223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1857}, "4": {"k": 4, "answer": "Yushan, China", "latency_ms": 397.935152053833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2432}, "5": {"k": 5, "answer": "Yushan, China", "latency_ms": 287.84966468811035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3034}, "6": {"k": 6, "answer": "Preston Guild Hall in Preston, England", "latency_ms": 286.82398796081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3663}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "Joshua \"JT\" Williams", "latency_ms": 205.1701545715332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Thad Luckinbill", "latency_ms": 432.2218894958496, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "Thad Luckinbill", "latency_ms": 328.18150520324707, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Thad Luckinbill", "latency_ms": 164.15667533874512, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Thad Luckinbill", "latency_ms": 258.36825370788574, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2537}, "5": {"k": 5, "answer": "Thad Luckinbill", "latency_ms": 191.38050079345703, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "Thad Luckinbill", "latency_ms": 204.66947555541992, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3745}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1973", "latency_ms": 306.89311027526855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1973", "latency_ms": 139.0972137451172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "1983", "latency_ms": 188.79246711730957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1362}, "3": {"k": 3, "answer": "1973", "latency_ms": 351.50790214538574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1945}, "4": {"k": 4, "answer": "1973", "latency_ms": 132.0641040802002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2604}, "5": {"k": 5, "answer": "1973", "latency_ms": 347.1243381500244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3256}, "6": {"k": 6, "answer": "1983", "latency_ms": 336.06505393981934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3940}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "Lori Michaels", "latency_ms": 135.31875610351562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dave Ogilvie, Anthony Valcic, Jakalope, Damhnait Doyle, in-show band", "latency_ms": 792.7193641662598, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Dave Ogilvie, Anthony Valcic, Jakalope, Damhnait Doyle, Alexz Johnson", "latency_ms": 645.6115245819092, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Dave Ogilvie, Anthony Valcic, Jakalope, Damhnait Doyle, Alexz Johnson, Lisa Dalbello, in-show band", "latency_ms": 856.0962677001953, "em": 0.0, "f1": 0.14285714285714288, "containment": 1.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Dave Ogilvie, Anthony Valcic, Damhnait Doyle, Alexz Johnson, Lisa Dalbello, Jakalope", "latency_ms": 701.1985778808594, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Dave Ogilvie, Anthony Valcic, Damhnait Doyle, Alexz Johnson, Lisa Dalbello, Jakalope", "latency_ms": 816.7276382446289, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 3268}, "6": {"k": 6, "answer": "Dave Ogilvie, Anthony Valcic, Damhnait Doyle, Alexz Johnson, Lisa Dalbello, Jakalope", "latency_ms": 579.67209815979, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 3989}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "2.6 million years ago", "latency_ms": 156.10861778259277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 134.75275039672852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 196.00772857666016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 303.9090633392334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1818}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 312.16883659362793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2449}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 151.4301300048828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3106}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 317.4738883972168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3759}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "E-8 in the Marine Corps is a rank of Colonel.", "latency_ms": 381.5913200378418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 123.26574325561523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "E-8 in the Marine Corps is a rank with two ranks per pay grade, typically holding command-oriented responsibilities as a First Sergeant or Sergeant Major.", "latency_ms": 1212.4214172363281, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Master Sergeant", "latency_ms": 76.58505439758301, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2029}, "4": {"k": 4, "answer": "Senior Master Sergeant", "latency_ms": 101.78565979003906, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2651}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 260.7548236846924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3272}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 230.22198677062988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3838}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 68.84646415710449, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 79.97632026672363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "Brewster Kahle", "latency_ms": 315.5820369720459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "Brewster Kahle", "latency_ms": 262.1009349822998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "Werner Koch", "latency_ms": 152.39286422729492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Werner Koch", "latency_ms": 229.1395664215088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 224.32446479797363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3975}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 185.58359146118164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Heena Sidhu", "latency_ms": 237.34140396118164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 580}, "2": {"k": 2, "answer": "Heena Sidhu", "latency_ms": 144.34003829956055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Heena Sidhu", "latency_ms": 161.4394187927246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1805}, "4": {"k": 4, "answer": "Heena Sidhu", "latency_ms": 251.9838809967041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2418}, "5": {"k": 5, "answer": "Heena Sidhu", "latency_ms": 194.8850154876709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3022}, "6": {"k": 6, "answer": "Heena Sidhu", "latency_ms": 265.8190727233887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3659}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Chris Layton", "latency_ms": 168.56956481933594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 55.661678314208984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 71.14028930664062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 250.86069107055664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1901}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 203.37748527526855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2526}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 221.4651107788086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3155}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 175.14634132385254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3831}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "Miami Heat", "latency_ms": 74.06020164489746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miami Heat", "latency_ms": 121.06037139892578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 83.45413208007812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 206.79831504821777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 131.03866577148438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2461}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 129.53948974609375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3047}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 206.77709579467773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3636}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "Guarani", "latency_ms": 136.5640163421631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "guarani (PYG)", "latency_ms": 281.2473773956299, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "guarani (PYG)", "latency_ms": 276.9598960876465, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "PYG", "latency_ms": 86.14921569824219, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "1 Euro = 6,767 Guaraníes", "latency_ms": 695.523738861084, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2477}, "5": {"k": 5, "answer": "1 Euro = 6,767 Guaraníes", "latency_ms": 837.2864723205566, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 3046}, "6": {"k": 6, "answer": "PYG", "latency_ms": 182.06357955932617, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3683}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "ketamine", "latency_ms": 78.65023612976074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a drug with amnesic properties used in dentistry is not specified in the context. I cannot answer.", "latency_ms": 1129.9359798431396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "benzodiazepines", "latency_ms": 491.6653633117676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1474}, "3": {"k": 3, "answer": "midazolam", "latency_ms": 371.7303276062012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2158}, "4": {"k": 4, "answer": "midazolam", "latency_ms": 161.94629669189453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2825}, "5": {"k": 5, "answer": "midazolam", "latency_ms": 269.5047855377197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3551}, "6": {"k": 6, "answer": "midazolam", "latency_ms": 145.9181308746338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4261}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 288.1274223327637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "26,000 years", "latency_ms": 344.0229892730713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "26,000 years", "latency_ms": 285.92467308044434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1278}, "3": {"k": 3, "answer": "26,000 years", "latency_ms": 392.8661346435547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1859}, "4": {"k": 4, "answer": "25,800 years", "latency_ms": 460.73198318481445, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2495}, "5": {"k": 5, "answer": "25,800 years", "latency_ms": 307.3592185974121, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3061}, "6": {"k": 6, "answer": "25,800 years", "latency_ms": 268.70012283325195, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3691}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 180.2222728729248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Texas A&M", "latency_ms": 167.01269149780273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "Texas A&M", "latency_ms": 105.80086708068848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Texas A&M", "latency_ms": 180.13358116149902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1904}, "4": {"k": 4, "answer": "Texas A&M Aggies", "latency_ms": 159.42716598510742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2569}, "5": {"k": 5, "answer": "Texas A&M", "latency_ms": 265.3799057006836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3193}, "6": {"k": 6, "answer": "Texas A&M", "latency_ms": 206.24899864196777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3814}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and non-renewable", "latency_ms": 185.5478286743164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable and non-renewable", "latency_ms": 655.6837558746338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable or non-renewable", "latency_ms": 189.9580955505371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1447}, "3": {"k": 3, "answer": "renewable and non-renewable", "latency_ms": 145.85256576538086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2153}, "4": {"k": 4, "answer": "renewable and non-renewable", "latency_ms": 207.40485191345215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2951}, "5": {"k": 5, "answer": "renewable and non-renewable", "latency_ms": 330.7368755340576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3598}, "6": {"k": 6, "answer": "renewable and non-renewable", "latency_ms": 402.53329277038574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4358}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "Good luck and prosperity", "latency_ms": 297.05095291137695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "babies", "latency_ms": 70.13463973999023, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "purity and motherhood", "latency_ms": 277.0426273345947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1314}, "3": {"k": 3, "answer": "purity and harmony; child-bringing myth", "latency_ms": 247.78294563293457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "purity, parental devotion, harmony, and peace", "latency_ms": 409.470796585083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2589}, "5": {"k": 5, "answer": "purity, harmony, and child-birth", "latency_ms": 389.56761360168457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "purity, harmony, and maternal devotion", "latency_ms": 350.47030448913574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3786}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Rohit Sharma", "latency_ms": 330.20615577697754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 232.28168487548828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 306.2129020690918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 253.4928321838379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "558", "latency_ms": 129.0452480316162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2490}, "5": {"k": 5, "answer": "Virat Kohli", "latency_ms": 151.43394470214844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 167.25993156433105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3714}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "killing of microorganisms by low concentrations of metals", "latency_ms": 193.38107109069824, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals in low concentrations", "latency_ms": 288.0246639251709, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 792.8884029388428, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 1412}, "3": {"k": 3, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 428.1659126281738, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 2103}, "4": {"k": 4, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 499.24683570861816, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 2891}, "5": {"k": 5, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations.", "latency_ms": 696.786642074585, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 3553}, "6": {"k": 6, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations.", "latency_ms": 872.3456859588623, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 4280}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "2006", "latency_ms": 203.216552734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 80.42621612548828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "James Coburn", "latency_ms": 100.67009925842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Anthony Allen Shore", "latency_ms": 127.13909149169922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "Anthony Allen Shore", "latency_ms": 114.09306526184082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2454}, "5": {"k": 5, "answer": "Anthony Allen Shore", "latency_ms": 257.8449249267578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3056}, "6": {"k": 6, "answer": "Anthony Allen Shore", "latency_ms": 282.33909606933594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3657}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the opening lead and before the first round is played.", "latency_ms": 342.7257537841797, "em": 0.0, "f1": 0.15384615384615383, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "when they hold two \"touching honors\" (or \"adjacent honors\") they will play the higher one first", "latency_ms": 405.34019470214844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 580}, "2": {"k": 2, "answer": "when they hold two \"touching honors\" (or \"adjacent honors\") they will play the higher one first", "latency_ms": 467.98133850097656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1185}, "3": {"k": 3, "answer": "when they hold two \"touching honors\" (or \"adjacent honors\") they will play the higher one first.", "latency_ms": 744.3923950195312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 110.00275611877441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2413}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 170.9733009338379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2985}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 176.74732208251953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3563}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Sri Lanka", "latency_ms": 88.98782730102539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 127.82001495361328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 699}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 157.44638442993164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1428}, "3": {"k": 3, "answer": "Afghanistan", "latency_ms": 239.7010326385498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2145}, "4": {"k": 4, "answer": "Afghanistan", "latency_ms": 199.94401931762695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2841}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 306.6520690917969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3649}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 185.4252815246582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4368}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "Vascular spasm, platelet plug formation, coagulation", "latency_ms": 584.683895111084, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "initiation, amplification, propagation", "latency_ms": 231.19235038757324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 91.78662300109863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "initiation, amplification, propagation", "latency_ms": 422.3964214324951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2026}, "4": {"k": 4, "answer": "Initiation, amplification, propagation", "latency_ms": 281.1470031738281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2695}, "5": {"k": 5, "answer": "Initiation, amplification, propagation", "latency_ms": 283.4787368774414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3307}, "6": {"k": 6, "answer": "initiation, amplification, propagation", "latency_ms": 181.87642097473145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3993}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "Jesse McCartney", "latency_ms": 65.72103500366211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 157.2415828704834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 698}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 239.21775817871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1390}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 208.30059051513672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2074}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 217.99707412719727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2736}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 297.67870903015137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3366}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 309.57770347595215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3992}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "1989", "latency_ms": 167.39630699157715, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "20 November 1989", "latency_ms": 259.6280574798584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 428.04431915283203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 548.1564998626709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1974}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 530.1985740661621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2684}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 205.33394813537598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3325}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 394.2532539367676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3989}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "2016", "latency_ms": 97.76520729064941, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "29 March 2017", "latency_ms": 396.76427841186523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "23 June 2016", "latency_ms": 328.03821563720703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "23 June 2016", "latency_ms": 429.98433113098145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "23 June 2016", "latency_ms": 330.54041862487793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "23 June 2016", "latency_ms": 387.81142234802246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3131}, "6": {"k": 6, "answer": "23 June 2016", "latency_ms": 417.5395965576172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3803}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 240.80348014831543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Burj Khalifa", "latency_ms": 179.29410934448242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 679}, "2": {"k": 2, "answer": "Burj Khalifa", "latency_ms": 197.20220565795898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 287.548303604126, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 252.14052200317383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2643}, "5": {"k": 5, "answer": "Burj Khalifa", "latency_ms": 237.95509338378906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3270}, "6": {"k": 6, "answer": "Burj Khalifa", "latency_ms": 367.79165267944336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3957}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 100.0220775604248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 181.60605430603027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 206.2222957611084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1324}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 192.34943389892578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 388.47947120666504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2582}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 265.03610610961914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 202.47817039489746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3850}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Baron de Montesquieu", "latency_ms": 412.7218723297119, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montesquieu", "latency_ms": 81.88319206237793, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 88.00983428955078, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 157.7920913696289, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2070}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 279.155969619751, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2746}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 246.6866970062256, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3378}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 316.59531593322754, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4016}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Kyler Murray", "latency_ms": 153.7647247314453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mike Williams", "latency_ms": 83.43052864074707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Myles Garrett", "latency_ms": 135.7860565185547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1232}, "3": {"k": 3, "answer": "Myles Garrett", "latency_ms": 119.78483200073242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Myles Garrett", "latency_ms": 155.3170680999756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2515}, "5": {"k": 5, "answer": "Myles Garrett", "latency_ms": 199.59163665771484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3144}, "6": {"k": 6, "answer": "Myles Garrett", "latency_ms": 244.1399097442627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3720}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 123.62480163574219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2008 BS", "latency_ms": 178.14326286315918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "2008", "latency_ms": 224.87783432006836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "2008", "latency_ms": 128.50427627563477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "2008", "latency_ms": 211.4579677581787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2677}, "5": {"k": 5, "answer": "2008", "latency_ms": 139.36519622802734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3318}, "6": {"k": 6, "answer": "2008", "latency_ms": 303.4651279449463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3976}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "Captain John Smith", "latency_ms": 343.66559982299805, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Smith", "latency_ms": 82.89337158203125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "John Smith", "latency_ms": 73.12917709350586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "John Smith", "latency_ms": 83.20331573486328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2039}, "4": {"k": 4, "answer": "John Smith", "latency_ms": 123.28815460205078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2719}, "5": {"k": 5, "answer": "John Smith", "latency_ms": 199.89562034606934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3345}, "6": {"k": 6, "answer": "John Smith", "latency_ms": 137.01939582824707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3998}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "distal convoluted tubule", "latency_ms": 332.79967308044434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "stomach fundus region", "latency_ms": 224.30992126464844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "parietal cells of the gastric mucosa", "latency_ms": 164.18719291687012, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "parietal cells of the gastric mucosa", "latency_ms": 463.74058723449707, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1853}, "4": {"k": 4, "answer": "parietal cells of the gastric mucosa", "latency_ms": 167.23895072937012, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2526}, "5": {"k": 5, "answer": "parietal cells of the gastric mucosa", "latency_ms": 560.2693557739258, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3113}, "6": {"k": 6, "answer": "parietal cells of the gastric mucosa", "latency_ms": 364.78734016418457, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3748}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "early morning hours, typically between 2 and 4 a.m.", "latency_ms": 962.3231887817383, "em": 0.0, "f1": 0.14285714285714285, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "second half of the sleep cycle", "latency_ms": 137.26067543029785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "second half of the sleep cycle", "latency_ms": 474.49326515197754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1302}, "3": {"k": 3, "answer": "4 a.m.", "latency_ms": 159.23595428466797, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "4 a.m.", "latency_ms": 111.77635192871094, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2621}, "5": {"k": 5, "answer": "4 a.m.", "latency_ms": 313.3535385131836, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3294}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 266.8607234954834, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3946}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 54.0463924407959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Idaho", "latency_ms": 127.95853614807129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 592}, "2": {"k": 2, "answer": "Idaho", "latency_ms": 115.78941345214844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Idaho", "latency_ms": 111.40179634094238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Idaho", "latency_ms": 83.84275436401367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2573}, "5": {"k": 5, "answer": "Idaho", "latency_ms": 129.3478012084961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3246}, "6": {"k": 6, "answer": "Idaho", "latency_ms": 250.23865699768066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3905}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "1. The Curse of the Black Pearl  \n2. Dead Man's Chest  \n3. At World's End  \n4. On Stranger Tides  \n5. Dead Men Tell No Tales", "latency_ms": 1243.5448169708252, "em": 0.0, "f1": 0.3571428571428571, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 81.56085014343262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 129.41288948059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "1. Pirates of the Caribbean (2003)  \n2. Pirates of the Caribbean: The Curse of the Black Pearl (2003)  \n3. Pirates of the Caribbean: At World's End (2007)  \n4. Pirates of the Caribbean: On Stranger Tides (2011)  \n5. Pirates of the Caribbean: Dead Men Tell No Tales (2017)", "latency_ms": 2539.748191833496, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1962}, "4": {"k": 4, "answer": "1. Pirates of the Caribbean (theme park ride)  \n2. Pirates of the Caribbean (video game, 2003)  \n3. Pirates of the Caribbean (film series, starting 2003)", "latency_ms": 1174.8251914978027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "1. Pirates of the Caribbean (video game)  \n2. Pirates of the Caribbean (film series)  \n3. Pirates of the Caribbean (theme park ride)", "latency_ms": 1149.993658065796, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3206}, "6": {"k": 6, "answer": "1. Pirates of the Caribbean (2003), 2. Dead Man's Chest (2006), 3. At World's End (2007), 4. On Stranger Tides (2011), 5. Dead Men Tell No Tales (2017)", "latency_ms": 2419.6012020111084, "em": 0.0, "f1": 0.3125, "containment": 1.0, "context_chars": 3852}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 186.14554405212402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "changed key", "latency_ms": 104.42042350769043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "modulated", "latency_ms": 171.74601554870605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "modulated", "latency_ms": 197.71122932434082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "modulated", "latency_ms": 87.35084533691406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2515}, "5": {"k": 5, "answer": "modulated", "latency_ms": 210.91508865356445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "modulated", "latency_ms": 221.1461067199707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3810}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Roman citizens of certain property classes", "latency_ms": 200.33812522888184, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Only free male citizens", "latency_ms": 147.82166481018066, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 614}, "2": {"k": 2, "answer": "eligible voters", "latency_ms": 83.39667320251465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "eligible voters", "latency_ms": 89.47515487670898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Eligible voters, including those outside the city once allowed to vote, and rural market participants.", "latency_ms": 383.4705352783203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2626}, "5": {"k": 5, "answer": "Roman citizens", "latency_ms": 178.96223068237305, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3325}, "6": {"k": 6, "answer": "Roman citizens", "latency_ms": 184.0500831604004, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3978}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 225.12102127075195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 113.4176254272461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 197.15213775634766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "9 April 2019", "latency_ms": 292.77777671813965, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2163}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 164.72887992858887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2865}, "5": {"k": 5, "answer": "9 April 2019", "latency_ms": 339.5371437072754, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3523}, "6": {"k": 6, "answer": "9 April 2019", "latency_ms": 262.4838352203369, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4115}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "blood volume", "latency_ms": 54.84294891357422, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "blood volume", "latency_ms": 138.12613487243652, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "volume of blood", "latency_ms": 147.1273899078369, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "volume of blood", "latency_ms": 174.1313934326172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "mass of blood or volume of blood", "latency_ms": 191.0994052886963, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2470}, "5": {"k": 5, "answer": "volume of blood or mass of blood", "latency_ms": 359.4391345977783, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3136}, "6": {"k": 6, "answer": "volume of blood or mass of blood", "latency_ms": 205.2149772644043, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3751}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 332.66305923461914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 242.9659366607666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 92.3001766204834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1217}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 150.52437782287598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 113.05618286132812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2492}, "5": {"k": 5, "answer": "Icarus", "latency_ms": 163.35678100585938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3142}, "6": {"k": 6, "answer": "Icarus", "latency_ms": 253.41129302978516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3763}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "1979", "latency_ms": 78.60660552978516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1980", "latency_ms": 90.17682075500488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "1980", "latency_ms": 97.13268280029297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "1979", "latency_ms": 318.4490203857422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1875}, "4": {"k": 4, "answer": "1979", "latency_ms": 297.25027084350586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2455}, "5": {"k": 5, "answer": "September 16, 1979", "latency_ms": 492.3241138458252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3072}, "6": {"k": 6, "answer": "September 16, 1979", "latency_ms": 345.58653831481934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3722}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 AM Hong Kong Time", "latency_ms": 243.71004104614258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "9:30 AM", "latency_ms": 357.1908473968506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "9:30 AM", "latency_ms": 180.72795867919922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "9:30 AM", "latency_ms": 347.35727310180664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "9:30 AM", "latency_ms": 187.0744228363037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "9:15 AM", "latency_ms": 223.41156005859375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3206}, "6": {"k": 6, "answer": "9:15 AM", "latency_ms": 306.8196773529053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3841}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "Monty Hall", "latency_ms": 183.72225761413574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Carol Merrill, Georgia Satelle, Elaine Klimaszewski, Diane Klimaszewski, Maggie Brown, Julie Hall, Karen LaPierre, Melanie Vincz", "latency_ms": 954.9529552459717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Carol Merrill", "latency_ms": 128.16333770751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 157.0110321044922, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 145.5831527709961, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2451}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 225.39520263671875, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3027}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 144.75679397583008, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3621}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "Atlanta Braves, New York Mets", "latency_ms": 340.895414352417, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 142.42792129516602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 247.16424942016602, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1278}, "3": {"k": 3, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 317.8424835205078, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1911}, "4": {"k": 4, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 220.289945602417, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2522}, "5": {"k": 5, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 306.715726852417, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3152}, "6": {"k": 6, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 347.3315238952637, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3728}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "$2.2 billion", "latency_ms": 231.60552978515625, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$2.187 billion", "latency_ms": 282.1216583251953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 649}, "2": {"k": 2, "answer": "$2.187 billion", "latency_ms": 131.58082962036133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1293}, "3": {"k": 3, "answer": "$2.187 billion", "latency_ms": 293.95151138305664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1919}, "4": {"k": 4, "answer": "$2.187 billion", "latency_ms": 359.1349124908447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "$2.187 billion", "latency_ms": 238.602876663208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3253}, "6": {"k": 6, "answer": "$2.187 billion", "latency_ms": 178.15041542053223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3911}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "December 25", "latency_ms": 153.36155891418457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 142.8518295288086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 138.20648193359375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "December 20, 1946", "latency_ms": 216.48740768432617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1958}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 164.73627090454102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2589}, "5": {"k": 5, "answer": "21 January 2013", "latency_ms": 491.38474464416504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "21 January 2013", "latency_ms": 551.4461994171143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3790}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark/Norway", "latency_ms": 154.05821800231934, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Denmark", "latency_ms": 139.69993591308594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "Scandinavia", "latency_ms": 202.4552822113037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1342}, "3": {"k": 3, "answer": "Scandinavia", "latency_ms": 216.16148948669434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1993}, "4": {"k": 4, "answer": "Scandinavian patronymic surname, meaning \"son of Hans\"", "latency_ms": 447.76177406311035, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 2685}, "5": {"k": 5, "answer": "Scandinavian patronymic surname, meaning \"son of Hans\"", "latency_ms": 617.1631813049316, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 3278}, "6": {"k": 6, "answer": "Scandinavian patronymic surname, meaning \"son of Hans\"", "latency_ms": 385.4343891143799, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 3886}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "papai noel", "latency_ms": 350.28743743896484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Puritina", "latency_ms": 393.5272693634033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Puritina", "latency_ms": 246.7975616455078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "Puritina", "latency_ms": 299.8840808868408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "Puritina", "latency_ms": 160.13216972351074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2613}, "5": {"k": 5, "answer": "Puritina", "latency_ms": 248.46315383911133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3281}, "6": {"k": 6, "answer": "Puritina", "latency_ms": 131.62541389465332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3910}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "Linda Ronstadt", "latency_ms": 142.59648323059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 342.5455093383789, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 305.2976131439209, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 337.34798431396484, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 439.73636627197266, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2491}, "5": {"k": 5, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 390.05446434020996, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3116}, "6": {"k": 6, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 594.8996543884277, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3748}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Rhode Island", "latency_ms": 58.06303024291992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles, New Jersey", "latency_ms": 383.9991092681885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Los Angeles, New Jersey", "latency_ms": 187.7434253692627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Los Angeles, Pittsburgh, New Jersey", "latency_ms": 555.7830333709717, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1903}, "4": {"k": 4, "answer": "Los Angeles, Pittsburgh, New Jersey", "latency_ms": 406.56161308288574, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2507}, "5": {"k": 5, "answer": "Los Angeles, Pittsburgh, New Jersey", "latency_ms": 434.0553283691406, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3120}, "6": {"k": 6, "answer": "Los Angeles, Pittsburgh, New Jersey", "latency_ms": 493.6184883117676, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3729}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1827", "latency_ms": 172.03450202941895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 211.35234832763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "24 May 1854", "latency_ms": 137.56990432739258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 134.81688499450684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "1885", "latency_ms": 381.7882537841797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2627}, "5": {"k": 5, "answer": "1885", "latency_ms": 297.135591506958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3282}, "6": {"k": 6, "answer": "1885", "latency_ms": 210.97850799560547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3979}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier Fernández", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Yuzuru Hanyu", "latency_ms": 218.18065643310547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yuzuru Hanyu", "latency_ms": 312.9303455352783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Yuzuru Hanyu", "latency_ms": 536.3013744354248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Yuzuru Hanyu", "latency_ms": 224.92218017578125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1939}, "4": {"k": 4, "answer": "Yuzuru Hanyu", "latency_ms": 211.0588550567627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2591}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 201.6129493713379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3235}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 307.0862293243408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3905}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "Cain and Abel is a network scanning and password cracking tool used for ethical hacking and penetration testing.", "latency_ms": 712.4650478363037, "em": 0.0, "f1": 0.10526315789473684, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "password recovery", "latency_ms": 88.1650447845459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "password recovery", "latency_ms": 69.43750381469727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1391}, "3": {"k": 3, "answer": "password recovery for Microsoft Windows", "latency_ms": 229.2611598968506, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1976}, "4": {"k": 4, "answer": "recovering passwords using methods such as network packet sniffing, dictionary attacks, brute force, and cryptanalysis attacks", "latency_ms": 716.3231372833252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "recovering passwords using methods such as network packet sniffing, dictionary attacks, brute force, and cryptanalysis attacks", "latency_ms": 771.2998390197754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3166}, "6": {"k": 6, "answer": "password recovery for Microsoft Windows", "latency_ms": 140.75350761413574, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3777}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "Eknath Shinde", "latency_ms": 260.2660655975342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "C. Vidyasagar Rao", "latency_ms": 390.00940322875977, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "C. Vidyasagar Rao", "latency_ms": 153.4252166748047, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1307}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 154.49929237365723, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 395.8156108856201, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2577}, "5": {"k": 5, "answer": "C. Vidyasagar Rao", "latency_ms": 288.158655166626, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3212}, "6": {"k": 6, "answer": "C. Vidyasagar Rao", "latency_ms": 525.2258777618408, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3866}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "ABC 50.1", "latency_ms": 132.91335105895996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "KTVK", "latency_ms": 152.16970443725586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "15", "latency_ms": 119.49706077575684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1348}, "3": {"k": 3, "answer": "15", "latency_ms": 156.6915512084961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1980}, "4": {"k": 4, "answer": "15", "latency_ms": 146.52371406555176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2639}, "5": {"k": 5, "answer": "15", "latency_ms": 99.8070240020752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3326}, "6": {"k": 6, "answer": "15", "latency_ms": 147.5679874420166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3972}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Michael J. Fox", "latency_ms": 86.11249923706055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elisabeth Shue", "latency_ms": 94.41590309143066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Claudia Wells", "latency_ms": 92.75674819946289, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "Claudia Wells", "latency_ms": 174.41034317016602, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1814}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 179.71205711364746, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2413}, "5": {"k": 5, "answer": "Claudia Wells", "latency_ms": 139.8463249206543, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3044}, "6": {"k": 6, "answer": "Claudia Wells", "latency_ms": 295.66383361816406, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3629}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London, United Kingdom", "latency_ms": 498.3174800872803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "London, United Kingdom", "latency_ms": 114.52484130859375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 94.10548210144043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 110.18228530883789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1912}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 189.6970272064209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2537}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 144.48976516723633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3143}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 256.2265396118164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3808}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The First Lady or designated chef", "latency_ms": 340.5282497406006, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 87.13436126708984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 93.89638900756836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 209.1524600982666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1869}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 338.6049270629883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2517}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 181.24032020568848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 185.5754852294922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "Justice M. H. Beg", "latency_ms": 588.8333320617676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 228.5747528076172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 571}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 129.3957233428955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 194.1695213317871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1827}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 408.83755683898926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2462}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 228.10697555541992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3115}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 227.65207290649414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3753}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "Canada", "latency_ms": 65.31524658203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "British Columbia", "latency_ms": 96.9536304473877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "British Columbia", "latency_ms": 71.86388969421387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "British Columbia", "latency_ms": 131.94990158081055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1991}, "4": {"k": 4, "answer": "British Columbia", "latency_ms": 89.23912048339844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2646}, "5": {"k": 5, "answer": "Aldergrove, British Columbia", "latency_ms": 443.12119483947754, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3331}, "6": {"k": 6, "answer": "British Columbia", "latency_ms": 196.37346267700195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3948}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 187.7431869506836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 11, 2018", "latency_ms": 489.5057678222656, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "October 11, 2018", "latency_ms": 416.1362648010254, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 361.2630367279053, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1952}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 258.4545612335205, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2661}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 209.6078395843506, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3311}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 738.7604713439941, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3943}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Dana Delany", "latency_ms": 190.78373908996582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dana Plato", "latency_ms": 101.26566886901855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "Dana Snyder", "latency_ms": 142.6100730895996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "D.J.", "latency_ms": 198.2121467590332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "Stephanie Tanner", "latency_ms": 135.12206077575684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "Stephanie Tanner", "latency_ms": 213.6838436126709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3150}, "6": {"k": 6, "answer": "Mary-Kate Olsen", "latency_ms": 345.0760841369629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3786}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.17873764038086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Millennium Tower", "latency_ms": 190.20676612854004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 249.78280067443848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1307}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 186.2351894378662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 255.39255142211914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2661}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 331.29334449768066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3347}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 158.49733352661133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3994}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 284.8532199859619, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 202.79479026794434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "2014", "latency_ms": 274.416446685791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1221}, "3": {"k": 3, "answer": "January 11, 2014", "latency_ms": 628.4947395324707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1857}, "4": {"k": 4, "answer": "January 11, 2014", "latency_ms": 534.5993041992188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2484}, "5": {"k": 5, "answer": "January 11, 2014", "latency_ms": 313.2634162902832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3112}, "6": {"k": 6, "answer": "January 11, 2014", "latency_ms": 398.2837200164795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3796}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "T.S. Eliot", "latency_ms": 103.05261611938477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Marshall Harlan", "latency_ms": 215.95287322998047, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "John Marshall Harlan", "latency_ms": 144.32287216186523, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1399}, "3": {"k": 3, "answer": "John Marshall Harlan", "latency_ms": 109.22455787658691, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2093}, "4": {"k": 4, "answer": "John Marshall Harlan", "latency_ms": 276.40843391418457, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2772}, "5": {"k": 5, "answer": "John Marshall Harlan", "latency_ms": 188.5848045349121, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "John Marshall Harlan", "latency_ms": 375.0576972961426, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4038}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Chris Berman", "latency_ms": 71.1057186126709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tyrann Mathieu", "latency_ms": 194.67949867248535, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 162.1384620666504, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 215.65890312194824, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 260.8311176300049, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 462.5210762023926, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 137.85529136657715, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3841}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "100 episodes", "latency_ms": 75.70266723632812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "six episodes", "latency_ms": 57.12389945983887, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "six episodes", "latency_ms": 174.03244972229004, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "six episodes", "latency_ms": 163.31148147583008, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1991}, "4": {"k": 4, "answer": "six episodes", "latency_ms": 119.28629875183105, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2666}, "5": {"k": 5, "answer": "6", "latency_ms": 153.090238571167, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3315}, "6": {"k": 6, "answer": "6", "latency_ms": 184.24510955810547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3923}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul Baumer's", "latency_ms": 76.0955810546875, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Paul Baumer's perspective", "latency_ms": 143.32270622253418, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 585}, "2": {"k": 2, "answer": "Paul Bäumer's perspective", "latency_ms": 230.02123832702637, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "young soldiers' perspective", "latency_ms": 198.96578788757324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "young soldiers' perspective", "latency_ms": 161.8673801422119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "young soldiers' perspective", "latency_ms": 327.1007537841797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3137}, "6": {"k": 6, "answer": "German infantryman", "latency_ms": 225.05474090576172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3782}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris and the Anglin brothers (Sundberg) — but only Frank Morris is confirmed to have escaped.  \nFrank Morris", "latency_ms": 726.6473770141602, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Paul Scott", "latency_ms": 133.28218460083008, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "John Paul Scott", "latency_ms": 230.29780387878418, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "John Paul Scott", "latency_ms": 182.22594261169434, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "John Paul Scott", "latency_ms": 166.1989688873291, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2539}, "5": {"k": 5, "answer": "John Paul Scott", "latency_ms": 169.56019401550293, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "John Paul Scott", "latency_ms": 328.48048210144043, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3826}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF programs worldwide", "latency_ms": 111.30285263061523, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF", "latency_ms": 77.03113555908203, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 723}, "2": {"k": 2, "answer": "UNICEF", "latency_ms": 189.9566650390625, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1453}, "3": {"k": 3, "answer": "UNICEF", "latency_ms": 194.00906562805176, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2142}, "4": {"k": 4, "answer": "UNICEF", "latency_ms": 274.8064994812012, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2862}, "5": {"k": 5, "answer": "UNICEF", "latency_ms": 219.95186805725098, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3550}, "6": {"k": 6, "answer": "UNICEF's global programing, with half of proceeds targeted to domestic causes like Hurricane Katrina aid.", "latency_ms": 744.4162368774414, "em": 0.0, "f1": 0.2105263157894737, "containment": 0.0, "context_chars": 4244}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Statue's base in New York Harbor", "latency_ms": 170.74227333068848, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 82.17287063598633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "At the top of the staircase in the Court of Honor is a statue of Lady Columbia, also known as Lady Liberty, or Justice. Here she is reported to represent all grieving mothers. She stands on the bow of a ship holding a laurel branch. The inscription below the statue, taken from Abraham Lincoln's letter to Mrs. Bixby, reads:", "latency_ms": 2386.176347732544, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 259.2587471008301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "on the base of the statue, below the statue, taken from Abraham Lincoln's letter to Mrs. Bixby", "latency_ms": 973.4587669372559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2466}, "5": {"k": 5, "answer": "on the base of the statue, below the statue, taken from Abraham Lincoln's letter to Mrs. Bixby", "latency_ms": 754.7333240509033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "on a plaque in the museum in its base", "latency_ms": 269.15478706359863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3789}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "2026 Milano-Cortina, 2030 Beijing", "latency_ms": 374.1161823272705, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 201.44367218017578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "Beijing and Paris (not a winter Olympics) — I cannot answer.", "latency_ms": 736.2651824951172, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Beijing and Hebei province, China", "latency_ms": 294.5859432220459, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1928}, "4": {"k": 4, "answer": "Beijing and Hebei province, China", "latency_ms": 526.2572765350342, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2530}, "5": {"k": 5, "answer": "Beijing and Hebei province, China", "latency_ms": 503.38268280029297, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3182}, "6": {"k": 6, "answer": "Beijing and Nagano", "latency_ms": 266.2649154663086, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3854}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "1994", "latency_ms": 206.86745643615723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "August 22, 1980", "latency_ms": 450.82569122314453, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "August 22, 1980", "latency_ms": 404.4756889343262, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "August 22, 1980", "latency_ms": 459.3510627746582, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "August 22, 1980", "latency_ms": 602.9386520385742, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "August 22, 1980", "latency_ms": 657.8757762908936, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3105}, "6": {"k": 6, "answer": "August 22, 1980", "latency_ms": 427.7164936065674, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3737}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "Stone arch bridge", "latency_ms": 129.0285587310791, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "historic bridge", "latency_ms": 108.0172061920166, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "historic bridge", "latency_ms": 132.06148147583008, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "historic bridge", "latency_ms": 186.5687370300293, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 144.4106101989746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "historic bridge", "latency_ms": 100.36349296569824, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3237}, "6": {"k": 6, "answer": "historic bridge", "latency_ms": 263.07153701782227, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3915}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The ruler or ruling party", "latency_ms": 88.69743347167969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "one person", "latency_ms": 57.31606483459473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "one person", "latency_ms": 130.1705837249756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1323}, "3": {"k": 3, "answer": "one person", "latency_ms": 121.42467498779297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1987}, "4": {"k": 4, "answer": "one person", "latency_ms": 268.0015563964844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2657}, "5": {"k": 5, "answer": "one person", "latency_ms": 136.3823413848877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3392}, "6": {"k": 6, "answer": "one person or a political party", "latency_ms": 261.28363609313965, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4003}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "Consumerism", "latency_ms": 53.68161201477051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "vitality and energy, convinced of the superiority of their own culture", "latency_ms": 445.59240341186523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "vitality and energy, convinced of the superiority of their own culture", "latency_ms": 659.1870784759521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "vitality and energy, convinced of the superiority of their own culture", "latency_ms": 467.93460845947266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2013}, "4": {"k": 4, "answer": "vitality and energy, convinced of the superiority of their own culture", "latency_ms": 400.9826183319092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2725}, "5": {"k": 5, "answer": "optimism and prosperity", "latency_ms": 124.4664192199707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3352}, "6": {"k": 6, "answer": "optimism and belief in technocratic solutions", "latency_ms": 332.43489265441895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4027}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "Counterclockwise (as viewed from above the North Pole)", "latency_ms": 308.40253829956055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 142.67325401306152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "counterclockwise", "latency_ms": 163.0837917327881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "counterclockwise", "latency_ms": 203.95827293395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1896}, "4": {"k": 4, "answer": "counterclockwise", "latency_ms": 308.38966369628906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "prograde", "latency_ms": 231.98390007019043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3144}, "6": {"k": 6, "answer": "prograde", "latency_ms": 227.18381881713867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3741}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Dome", "latency_ms": 210.23845672607422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "dome", "latency_ms": 118.65401268005371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "dome", "latency_ms": 78.92155647277832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Statue of Freedom", "latency_ms": 244.86637115478516, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "Statue of Freedom", "latency_ms": 210.49022674560547, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "Statue of Freedom", "latency_ms": 156.0664176940918, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "Statue of Freedom", "latency_ms": 340.7557010650635, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3752}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "Los Angeles Lakers", "latency_ms": 184.57937240600586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington Wizards", "latency_ms": 242.25282669067383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 273.32329750061035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 241.5480613708496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1869}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 221.30608558654785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Washington Wizards", "latency_ms": 99.73740577697754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Washington Wizards", "latency_ms": 311.85317039489746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3685}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "Steve Austin", "latency_ms": 117.38157272338867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Greatest Royal Rumble", "latency_ms": 349.41673278808594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Del Rio", "latency_ms": 203.6123275756836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Mysterio", "latency_ms": 345.090389251709, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "Mysterio", "latency_ms": 130.01179695129395, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2402}, "5": {"k": 5, "answer": "Daniel Bryan", "latency_ms": 116.99986457824707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3029}, "6": {"k": 6, "answer": "Daniel Bryan", "latency_ms": 178.83753776550293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3654}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 159.515380859375, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Glen Canyon Lake", "latency_ms": 90.69657325744629, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "Glen Canyon Lake", "latency_ms": 188.5535717010498, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "Lake Mead", "latency_ms": 266.2324905395508, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "Lake Mead", "latency_ms": 106.93788528442383, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2433}, "5": {"k": 5, "answer": "Lake Mead", "latency_ms": 151.55029296875, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3052}, "6": {"k": 6, "answer": "Lake Mead", "latency_ms": 126.0690689086914, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3682}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Gabbar Is Back (2023) is a remake of the Telugu movie \"Gabbar Singh\" (2012).", "latency_ms": 863.8601303100586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 81.72416687011719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 182.55329132080078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 207.550048828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 387.44521141052246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 292.0255661010742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3217}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 385.29324531555176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3869}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "John Baker", "latency_ms": 223.0520248413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ferraro", "latency_ms": 216.87865257263184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 722}, "2": {"k": 2, "answer": "Geraldine Ferraro", "latency_ms": 287.26696968078613, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1414}, "3": {"k": 3, "answer": "Geraldine Ferraro", "latency_ms": 466.69936180114746, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2103}, "4": {"k": 4, "answer": "Geraldine Ferraro", "latency_ms": 205.413818359375, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2842}, "5": {"k": 5, "answer": "Geraldine Ferraro", "latency_ms": 161.89169883728027, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3526}, "6": {"k": 6, "answer": "Geraldine Ferraro", "latency_ms": 419.04258728027344, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4206}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "Utah", "latency_ms": 132.18188285827637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Town of Groveland", "latency_ms": 527.5096893310547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners, New York", "latency_ms": 411.5121364593506, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Hampton Corners", "latency_ms": 383.0394744873047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "Hampton Corners", "latency_ms": 261.8083953857422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2479}, "5": {"k": 5, "answer": "Hampton Corners, New York", "latency_ms": 277.3258686065674, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3088}, "6": {"k": 6, "answer": "Hampton Corners, New York", "latency_ms": 506.5579414367676, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3746}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 45.435190200805664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 155.71188926696777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 105.93938827514648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1204}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 83.7864875793457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1844}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 179.57258224487305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 171.61917686462402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3021}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 231.62031173706055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3611}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Uttar Pradesh", "latency_ms": 277.7097225189209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Meghalaya", "latency_ms": 180.41300773620605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Meghalaya", "latency_ms": 227.81634330749512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1327}, "3": {"k": 3, "answer": "Meghalaya", "latency_ms": 98.30498695373535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1950}, "4": {"k": 4, "answer": "Meghalaya", "latency_ms": 114.74609375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Meghalaya", "latency_ms": 244.537353515625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3208}, "6": {"k": 6, "answer": "Meghalaya", "latency_ms": 227.69927978515625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3804}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Lucknow", "latency_ms": 54.6565055847168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 88.58776092529297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 117.28072166442871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1371}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 216.7496681213379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1993}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 181.68187141418457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2678}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 324.30410385131836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3311}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 278.3019542694092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3916}}}
