{"qid": "-3320993703958028468", "question": "what color pages in the emergency response guidebook (erg) list compounds by name", "gold_answers": ["blue"], "shots": {"0": {"k": 0, "answer": "Blue", "latency_ms": 81.45642280578613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 243.79801750183105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "blue", "latency_ms": 57.44576454162598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1441}, "3": {"k": 3, "answer": "blue", "latency_ms": 142.5647735595703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2221}, "4": {"k": 4, "answer": "blue", "latency_ms": 352.47087478637695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2995}, "5": {"k": 5, "answer": "blue", "latency_ms": 337.62240409851074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3661}, "6": {"k": 6, "answer": "blue", "latency_ms": 94.66862678527832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4352}}}
{"qid": "7026548049572374691", "question": "who developed the concept of total quality management", "gold_answers": ["W. Edwards Deming"], "shots": {"0": {"k": 0, "answer": "Joseph M. Juran", "latency_ms": 379.49299812316895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "W. Edwards Deming", "latency_ms": 331.0859203338623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "W. Edwards Deming", "latency_ms": 384.446382522583, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1310}, "3": {"k": 3, "answer": "W. Edwards Deming", "latency_ms": 231.69565200805664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1963}, "4": {"k": 4, "answer": "W. Edwards Deming", "latency_ms": 234.53593254089355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2684}, "5": {"k": 5, "answer": "W. Edwards Deming", "latency_ms": 318.483829498291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3402}, "6": {"k": 6, "answer": "W. Edwards Deming", "latency_ms": 606.7287921905518, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4071}}}
{"qid": "4617755372912487064", "question": "last world series that didn't go 7 games", "gold_answers": ["2015"], "shots": {"0": {"k": 0, "answer": "2004", "latency_ms": 118.97587776184082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2006", "latency_ms": 101.67336463928223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "2014", "latency_ms": 126.87063217163086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1209}, "3": {"k": 3, "answer": "2014 World Series", "latency_ms": 606.0965061187744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1795}, "4": {"k": 4, "answer": "2014 World Series", "latency_ms": 208.92739295959473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2416}, "5": {"k": 5, "answer": "2014", "latency_ms": 277.67324447631836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3030}, "6": {"k": 6, "answer": "2014", "latency_ms": 288.9249324798584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3625}}}
{"qid": "8453604009134928493", "question": "this inventor co-created the film fred ott’s sneeze", "gold_answers": ["Edison", "Fred Ott"], "shots": {"0": {"k": 0, "answer": "George Eastman", "latency_ms": 132.69662857055664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Thomas Edison", "latency_ms": 61.9049072265625, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "Thomas Edison", "latency_ms": 69.12446022033691, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Thomas Edison", "latency_ms": 417.1004295349121, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1844}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 330.2028179168701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2443}, "5": {"k": 5, "answer": "Thomas Edison", "latency_ms": 322.70193099975586, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3070}, "6": {"k": 6, "answer": "Thomas Edison", "latency_ms": 192.76738166809082, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3686}}}
{"qid": "-3407490342806384733", "question": "who sings what the world needs now in boss baby", "gold_answers": ["Hans Zimmer", "Steve Mazzaro", "Missi Hale"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 111.08922958374023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 143.23091506958008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 220.15953063964844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1310}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 179.11934852600098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1971}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 215.75689315795898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2551}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 461.3065719604492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3217}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 293.0316925048828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3856}}}
{"qid": "-442417708560275755", "question": "who won the most medals at the 2014 winter olympics", "gold_answers": ["Russia (", "Russia"], "shots": {"0": {"k": 0, "answer": "Canada", "latency_ms": 132.5972080230713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 145.12085914611816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 278.6061763763428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "Janica Kostelić", "latency_ms": 287.8882884979248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 231.49490356445312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 127.02012062072754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3288}, "6": {"k": 6, "answer": "Ireen Wüst", "latency_ms": 237.27059364318848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3916}}}
{"qid": "-7627363632917466497", "question": "who determines the rules of the us house and us senate", "gold_answers": ["United States Senate", "The Senate"], "shots": {"0": {"k": 0, "answer": "Rules of the U.S. House and Senate are determined by the respective chambers themselves through their rules committees and floor procedures.", "latency_ms": 429.4769763946533, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "House: Rules Committee; Senate: Senate Majority Leader", "latency_ms": 272.4437713623047, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "House: Rules Committee and full House; Senate: Senate Majority Leader and Senate Rules Committee", "latency_ms": 616.631031036377, "em": 0.0, "f1": 0.13333333333333333, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "House: Rules Committee and Clerk of the House; Senate: Senate Majority Leader and Senate Rules Committee", "latency_ms": 790.2979850769043, "em": 0.0, "f1": 0.125, "containment": 0.0, "context_chars": 2031}, "4": {"k": 4, "answer": "House: Rules Committee and full House; Senate: Standing Rules committee", "latency_ms": 615.5734062194824, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 2745}, "5": {"k": 5, "answer": "House: Rules Committee and full House; Senate: Standing Rules committee", "latency_ms": 534.088134765625, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 3391}, "6": {"k": 6, "answer": "House: Rules Committee and full House; Senate: Standing Rules committee", "latency_ms": 694.2729949951172, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 3976}}}
{"qid": "70640340064871933", "question": "who won britain's next top model 2016", "gold_answers": ["Chloe Keenan"], "shots": {"0": {"k": 0, "answer": "Lily Hargreaves", "latency_ms": 294.94714736938477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 259.68098640441895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 311.3715648651123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 173.60615730285645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 327.1369934082031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 243.64376068115234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3253}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 337.13340759277344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3846}}}
{"qid": "4884658732028049316", "question": "when did las vegas become a gambling town", "gold_answers": ["In 1931", "1931"], "shots": {"0": {"k": 0, "answer": "1931", "latency_ms": 201.9209861755371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1950s", "latency_ms": 145.06864547729492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "1931", "latency_ms": 174.0396022796631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1291}, "3": {"k": 3, "answer": "1931", "latency_ms": 415.8949851989746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1930}, "4": {"k": 4, "answer": "1931", "latency_ms": 231.50944709777832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2532}, "5": {"k": 5, "answer": "1931", "latency_ms": 223.7863540649414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3110}, "6": {"k": 6, "answer": "1931", "latency_ms": 297.1456050872803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3724}}}
{"qid": "-5107559781320376096", "question": "who is the highest paid baseball player in the major leagues", "gold_answers": ["Alex Rodriguez", "Clayton Kershaw"], "shots": {"0": {"k": 0, "answer": "Teoscar Hernández", "latency_ms": 234.23075675964355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mickey Mantle", "latency_ms": 172.0726490020752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Mickey Mantle", "latency_ms": 328.1898498535156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 177.8244972229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1872}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 150.44116973876953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2485}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 269.7334289550781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3097}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 273.97990226745605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3666}}}
{"qid": "5890866538303894370", "question": "list the seven gifts of the holy spirit", "gold_answers": ["wisdom", "understanding", "fear", "piety", "counsel", "knowledge", "fear of the Lord", "fortitude"], "shots": {"0": {"k": 0, "answer": "Wisdom, Understanding, Counsel, Fortitude, Knowledge, Piety, Fear of the Lord", "latency_ms": 990.2474880218506, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spirit of Wisdom; Spirit of Understanding; Spirit of Counsel; Spirit of Strength; Spirit of Knowledge; Spirit of Godliness; Spirit of Holy Fear", "latency_ms": 1306.7703247070312, "em": 0.0, "f1": 0.16, "containment": 1.0, "context_chars": 625}, "2": {"k": 2, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, fear of the Lord", "latency_ms": 291.83149337768555, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1289}, "3": {"k": 3, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "latency_ms": 1162.325382232666, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1969}, "4": {"k": 4, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, fear of the Lord", "latency_ms": 799.1416454315186, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2630}, "5": {"k": 5, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, fear of the Lord", "latency_ms": 873.619794845581, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3288}, "6": {"k": 6, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "latency_ms": 1241.7197227478027, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3949}}}
{"qid": "4870961414505835033", "question": "where is beijing located on the world map", "gold_answers": ["in northern China", "northern China"], "shots": {"0": {"k": 0, "answer": "East Asia", "latency_ms": 207.19361305236816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "39° 27' to 41° 03' N, 115° 25' to 117° 30' E", "latency_ms": 1069.1554546356201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "39° 27' to 41° 03' N, 115° 25' to 117° 30' E", "latency_ms": 1581.221342086792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "northeastern China, at the northern tip of the North China Plain, near the meeting point of the Xishan and Yanshan mountain ranges", "latency_ms": 813.8241767883301, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 1982}, "4": {"k": 4, "answer": "northeastern China, at the northern tip of the North China Plain, near the meeting point of the Xishan and Yanshan mountain ranges", "latency_ms": 958.7962627410889, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "northeastern China, at the northern tip of the North China Plain, near the meeting point of the Xishan and Yanshan mountain ranges", "latency_ms": 1067.791223526001, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 3230}, "6": {"k": 6, "answer": "northeastern China, at the northern tip of the North China Plain, near the meeting point of the Xishan and Yanshan mountain ranges", "latency_ms": 1228.3220291137695, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 3895}}}
{"qid": "-9151459252301477194", "question": "when did the legal drinking age changed to 21", "gold_answers": ["October 1986", "By mid-1988"], "shots": {"0": {"k": 0, "answer": "1984", "latency_ms": 71.26784324645996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1984", "latency_ms": 237.7629280090332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "1986", "latency_ms": 96.70138359069824, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "1986", "latency_ms": 105.69047927856445, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1967}, "4": {"k": 4, "answer": "1984", "latency_ms": 243.51763725280762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2593}, "5": {"k": 5, "answer": "1984", "latency_ms": 121.17815017700195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3240}, "6": {"k": 6, "answer": "1984", "latency_ms": 259.2275142669678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3881}}}
{"qid": "333763277804609492", "question": "a player that can shoot pass or dribble is considered to be", "gold_answers": ["Triple threat"], "shots": {"0": {"k": 0, "answer": "all-around player", "latency_ms": 71.28286361694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "versatile", "latency_ms": 141.2367820739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "elite offensive player", "latency_ms": 139.01948928833008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "elite offensive player", "latency_ms": 268.7726020812988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "a complete modern day advanced playmaker", "latency_ms": 438.1279945373535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "a complete modern day advanced playmaker", "latency_ms": 190.5343532562256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3116}, "6": {"k": 6, "answer": "a complete modern day advanced playmaker", "latency_ms": 196.213960647583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3750}}}
{"qid": "-938578705122215845", "question": "where does the spinal cord become cauda equina", "gold_answers": ["the conus medullaris", "L1 or L2"], "shots": {"0": {"k": 0, "answer": "L1 vertebra", "latency_ms": 313.43746185302734, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "T12 to L3", "latency_ms": 159.77787971496582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "conus medullaris", "latency_ms": 109.87520217895508, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "L3", "latency_ms": 152.18281745910645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1833}, "4": {"k": 4, "answer": "L3", "latency_ms": 113.19613456726074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "L3", "latency_ms": 126.80220603942871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3100}, "6": {"k": 6, "answer": "L3", "latency_ms": 237.46633529663086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3717}}}
{"qid": "-8834996069938989383", "question": "when did clifford the big red dog first air on tv", "gold_answers": ["September 4 , 2000"], "shots": {"0": {"k": 0, "answer": "1994", "latency_ms": 216.2344455718994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 4, 2000", "latency_ms": 308.08568000793457, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "September 4, 2000", "latency_ms": 331.4478397369385, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "September 4, 2000", "latency_ms": 348.91486167907715, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1977}, "4": {"k": 4, "answer": "September 4, 2000", "latency_ms": 297.14322090148926, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2664}, "5": {"k": 5, "answer": "September 4, 2000", "latency_ms": 189.63098526000977, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3321}, "6": {"k": 6, "answer": "September 4, 2000", "latency_ms": 305.18078804016113, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3966}}}
{"qid": "-2953491529624297458", "question": "when was the last time kentucky won ncaa", "gold_answers": ["2012"], "shots": {"0": {"k": 0, "answer": "2023", "latency_ms": 194.19264793395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2014", "latency_ms": 169.78001594543457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "2014", "latency_ms": 276.3662338256836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "2014", "latency_ms": 190.46974182128906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "2014", "latency_ms": 294.9483394622803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2635}, "5": {"k": 5, "answer": "2014", "latency_ms": 224.992036819458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3301}, "6": {"k": 6, "answer": "2014", "latency_ms": 329.30541038513184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3965}}}
{"qid": "1967531558485427303", "question": "what was guantanamo bay before it was a prison", "gold_answers": ["Guantanamo Bay Naval Base"], "shots": {"0": {"k": 0, "answer": "U.S. naval base", "latency_ms": 115.96393585205078, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "United States Navy's base", "latency_ms": 281.9681167602539, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 748}, "2": {"k": 2, "answer": "United States Navy's base", "latency_ms": 253.74293327331543, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1423}, "3": {"k": 3, "answer": "Puerto Grande", "latency_ms": 298.0351448059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Puerto Grande", "latency_ms": 115.82398414611816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2788}, "5": {"k": 5, "answer": "Coaling and naval station", "latency_ms": 360.21924018859863, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3445}, "6": {"k": 6, "answer": "Coaling and naval station", "latency_ms": 418.6713695526123, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 4067}}}
{"qid": "1265966537878407180", "question": "who was the 19th c. artist who was both painter and graphic designer", "gold_answers": ["René Georges Hermann - Paul"], "shots": {"0": {"k": 0, "answer": "James Abbott McNeill Whistler", "latency_ms": 113.92903327941895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.8292064666748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 98.01912307739258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Henri Matisse", "latency_ms": 228.23405265808105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 307.68418312072754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2633}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 406.17895126342773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3305}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 134.87815856933594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3996}}}
{"qid": "6301453363028517703", "question": "what is dj's boyfriends name on full house", "gold_answers": ["Steven `` Steve '' Hale", "rich kid Nelson", "Viper", "Steve Hale"], "shots": {"0": {"k": 0, "answer": "D.J.'s boyfriend's name on Full House is **Jenny**.", "latency_ms": 234.9536418914795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Steve Hale", "latency_ms": 98.62899780273438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "Steve Hale", "latency_ms": 102.4167537689209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1354}, "3": {"k": 3, "answer": "Steve Hale", "latency_ms": 122.58529663085938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1941}, "4": {"k": 4, "answer": "Steve Hale", "latency_ms": 107.89847373962402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2599}, "5": {"k": 5, "answer": "Steve Hale", "latency_ms": 104.47478294372559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3219}, "6": {"k": 6, "answer": "Steve Hale", "latency_ms": 128.73053550720215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3845}}}
{"qid": "3826862253571581938", "question": "who plays brad pitt's daughter in moneyball", "gold_answers": ["Kerris Lilla Dorsey"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 216.3097858428955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 150.58088302612305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "Kerris Dorsey", "latency_ms": 215.8346176147461, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Kerris Dorsey", "latency_ms": 177.42204666137695, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Kerris Dorsey", "latency_ms": 182.1579933166504, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Kerris Dorsey", "latency_ms": 212.69869804382324, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "Kerris Dorsey", "latency_ms": 260.76316833496094, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3804}}}
{"qid": "254065856937943955", "question": "who won season 2 of real chance of love", "gold_answers": ["Jackie DaFonseca", "Kamille Leai", "Hot Wings", "Doll"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 208.6923122406006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ahmad Givens (Real) and Kamal", "latency_ms": 590.5032157897949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 272.31717109680176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 256.35766983032227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 269.0417766571045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2472}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 121.54269218444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3059}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 164.87407684326172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3693}}}
{"qid": "-953849400724466906", "question": "where did huntington's disease get its name", "gold_answers": ["the physician George Huntington"], "shots": {"0": {"k": 0, "answer": "Dr. George Huntington", "latency_ms": 131.4985752105713, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huntington's disease got its name from George Huntington, who first described the disease in 1872.", "latency_ms": 829.2338848114014, "em": 0.0, "f1": 0.2352941176470588, "containment": 0.0, "context_chars": 719}, "2": {"k": 2, "answer": "George Huntington", "latency_ms": 154.47664260864258, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1393}, "3": {"k": 3, "answer": "George Huntington", "latency_ms": 191.86854362487793, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2021}, "4": {"k": 4, "answer": "George Huntington", "latency_ms": 283.66684913635254, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2656}, "5": {"k": 5, "answer": "George Huntington", "latency_ms": 195.8153247833252, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3348}, "6": {"k": 6, "answer": "George Huntington", "latency_ms": 154.9813747406006, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4038}}}
{"qid": "664126784032076855", "question": "which nfl coach has the most superbowl rings", "gold_answers": ["Bill Belichick"], "shots": {"0": {"k": 0, "answer": "Bill Belichick", "latency_ms": 114.25566673278809, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bill Belichick", "latency_ms": 257.1451663970947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "Bill Belichick", "latency_ms": 187.5762939453125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1221}, "3": {"k": 3, "answer": "Bill Belichick", "latency_ms": 274.874210357666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1880}, "4": {"k": 4, "answer": "Bill Belichick", "latency_ms": 103.09076309204102, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2481}, "5": {"k": 5, "answer": "Bill Belichick", "latency_ms": 215.43192863464355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3046}, "6": {"k": 6, "answer": "Bill Belichick", "latency_ms": 116.2714958190918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3633}}}
{"qid": "-5407234157766859145", "question": "turkey stuffed with a duck stuffed with a chicken", "gold_answers": ["Turducken"], "shots": {"0": {"k": 0, "answer": "Turkey", "latency_ms": 40.71450233459473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 103.02495956420898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 594}, "2": {"k": 2, "answer": "turducken", "latency_ms": 99.46870803833008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1210}, "3": {"k": 3, "answer": "turducken", "latency_ms": 126.47771835327148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1813}, "4": {"k": 4, "answer": "turducken", "latency_ms": 414.874792098999, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2452}, "5": {"k": 5, "answer": "turducken", "latency_ms": 139.357328414917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3087}, "6": {"k": 6, "answer": "turducken", "latency_ms": 250.0777244567871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3716}}}
{"qid": "2884966474182044344", "question": "who won the first season of america's got talent", "gold_answers": ["Bianca Ryan"], "shots": {"0": {"k": 0, "answer": "David Letterman", "latency_ms": 160.26735305786133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bianca Ryan", "latency_ms": 313.6451244354248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "Bianca Ryan", "latency_ms": 224.6248722076416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1210}, "3": {"k": 3, "answer": "Bianca Ryan", "latency_ms": 228.38258743286133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1863}, "4": {"k": 4, "answer": "Bianca Ryan", "latency_ms": 285.34674644470215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2540}, "5": {"k": 5, "answer": "Bianca Ryan", "latency_ms": 278.9266109466553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3157}, "6": {"k": 6, "answer": "Bianca Ryan", "latency_ms": 271.63076400756836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3810}}}
{"qid": "-4485639916525374363", "question": "how many books are in the one piece series", "gold_answers": ["more than 80", "83"], "shots": {"0": {"k": 0, "answer": "1000+", "latency_ms": 229.07638549804688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 149.49345588684082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 225.2371311187744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "89", "latency_ms": 230.26657104492188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1982}, "4": {"k": 4, "answer": "89", "latency_ms": 295.6209182739258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "89", "latency_ms": 433.7599277496338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3202}, "6": {"k": 6, "answer": "89", "latency_ms": 233.58392715454102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3826}}}
{"qid": "-5315423524940108616", "question": "where are the winter olympic games being held this year", "gold_answers": ["Pyeongchang County , South Korea"], "shots": {"0": {"k": 0, "answer": "2022 Winter Olympics were held in Beijing, China.", "latency_ms": 220.24273872375488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 86.78555488586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "Beijing and neighboring Hebei province, China", "latency_ms": 264.7421360015869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 310.3630542755127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 329.4332027435303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 205.3673267364502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3148}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 144.4535255432129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3779}}}
{"qid": "-5061370765188535062", "question": "how many quarterbacks have a receiving touchdown in the superbowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "12", "latency_ms": 153.22232246398926, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 130.25212287902832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "17", "latency_ms": 125.9300708770752, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1203}, "3": {"k": 3, "answer": "17", "latency_ms": 135.4348659515381, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1810}, "4": {"k": 4, "answer": "17", "latency_ms": 89.23196792602539, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2389}, "5": {"k": 5, "answer": "17", "latency_ms": 185.6708526611328, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2961}, "6": {"k": 6, "answer": "17", "latency_ms": 170.59016227722168, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3587}}}
{"qid": "-346866783760651662", "question": "when did ga state get a football team", "gold_answers": ["2010"], "shots": {"0": {"k": 0, "answer": "1933", "latency_ms": 145.93863487243652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 98.49882125854492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 687}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 148.4060287475586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 253.30662727355957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2012}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 212.38303184509277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2718}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 120.8200454711914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3332}, "6": {"k": 6, "answer": "1990", "latency_ms": 181.80322647094727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3987}}}
{"qid": "1627235089487061878", "question": "when does the first nba basketball game start", "gold_answers": ["October 17 , 2017"], "shots": {"0": {"k": 0, "answer": "October 23, 2023", "latency_ms": 462.5377655029297, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "November 1, 1946", "latency_ms": 447.7236270904541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "November 1, 1946", "latency_ms": 151.07274055480957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "November 1, 1946", "latency_ms": 167.54603385925293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1879}, "4": {"k": 4, "answer": "November 1, 1946", "latency_ms": 267.38667488098145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2515}, "5": {"k": 5, "answer": "November 1, 1946", "latency_ms": 397.22180366516113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "November 1, 1946", "latency_ms": 200.26397705078125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3802}}}
{"qid": "6217752837777787594", "question": "who plays heather in beauty and the beast", "gold_answers": ["Nicole Gale Anderson"], "shots": {"0": {"k": 0, "answer": "Linda Hamilton", "latency_ms": 126.82676315307617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 214.9674892425537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 210.66832542419434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 272.94135093688965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 146.6357707977295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2588}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 186.1107349395752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3283}, "6": {"k": 6, "answer": "Nicole Gale Anderson", "latency_ms": 221.93312644958496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3892}}}
{"qid": "7368254478874801356", "question": "who is the head of the department of homeland security 2017", "gold_answers": ["Kirstjen Nielsen"], "shots": {"0": {"k": 0, "answer": "John F. Kelly", "latency_ms": 176.64408683776855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kirstjen Nielsen", "latency_ms": 174.12781715393066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Kirstjen Nielsen", "latency_ms": 272.95541763305664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1342}, "3": {"k": 3, "answer": "Kirstjen Nielsen", "latency_ms": 347.49770164489746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "Kirstjen Nielsen", "latency_ms": 234.1146469116211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2779}, "5": {"k": 5, "answer": "Kirstjen Nielsen", "latency_ms": 302.4482727050781, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3409}, "6": {"k": 6, "answer": "Kirstjen Nielsen", "latency_ms": 273.1926441192627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4045}}}
{"qid": "5009255319596563516", "question": "who has the most gold gloves at shortstop", "gold_answers": ["Ozzie Smith"], "shots": {"0": {"k": 0, "answer": "Joe DiMaggio", "latency_ms": 252.33769416809082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ozzie Smith", "latency_ms": 337.0780944824219, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Ozzie Smith", "latency_ms": 223.9842414855957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1221}, "3": {"k": 3, "answer": "Ozzie Smith", "latency_ms": 319.26894187927246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1825}, "4": {"k": 4, "answer": "Ozzie Smith", "latency_ms": 390.5329704284668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2454}, "5": {"k": 5, "answer": "Ozzie Smith", "latency_ms": 134.18126106262207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3061}, "6": {"k": 6, "answer": "Omar Vizquel", "latency_ms": 294.68441009521484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3660}}}
{"qid": "7785057168624776860", "question": "who wore number 7 for the green bay packers", "gold_answers": ["Don Majkowski", "Quarterback Don Majkowski"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 106.55593872070312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 129.7130584716797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 153.8376808166504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Donald Driver", "latency_ms": 144.04559135437012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 227.48875617980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2393}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 270.42222023010254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3005}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 157.9897403717041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3604}}}
{"qid": "-908463397631188227", "question": "how long did the democrats control the house and senate", "gold_answers": ["57 yrs", "35 yrs"], "shots": {"0": {"k": 0, "answer": "2006–2010", "latency_ms": 306.6127300262451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "House: 1980–1994, 2006–present; Senate: 1980–1980, 2009–present", "latency_ms": 1506.570816040039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "House: 35 years; Senate: 16 years", "latency_ms": 203.0644416809082, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1343}, "3": {"k": 3, "answer": "1932–1980 (House); 1932–1980 (Senate)", "latency_ms": 998.9681243896484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1995}, "4": {"k": 4, "answer": "35 years (Senate), 12 years (House)", "latency_ms": 614.9280071258545, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2660}, "5": {"k": 5, "answer": "12 years (House), 16 years (Senate)", "latency_ms": 675.377368927002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3344}, "6": {"k": 6, "answer": "1932–1938", "latency_ms": 605.5397987365723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4017}}}
{"qid": "-7344570058818349307", "question": "who can be called a man of god", "gold_answers": ["prophets", "beloved religious leaders"], "shots": {"0": {"k": 0, "answer": "A person who lives according to God's teachings and values.", "latency_ms": 184.0353012084961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 110.05592346191406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 561}, "2": {"k": 2, "answer": "righteous man", "latency_ms": 189.51773643493652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "righteous man", "latency_ms": 116.47725105285645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1736}, "4": {"k": 4, "answer": "a righteous man", "latency_ms": 238.7716770172119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2305}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 220.60060501098633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2914}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 142.90165901184082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3480}}}
{"qid": "-5255735265739582707", "question": "a system of fortifications along france's border", "gold_answers": ["Maginot Line", "The Maginot Line"], "shots": {"0": {"k": 0, "answer": "Maginot Line", "latency_ms": 79.70237731933594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Séré de Rivières system", "latency_ms": 379.6045780181885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "Maginot Line", "latency_ms": 168.7636375427246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1337}, "3": {"k": 3, "answer": "Maginot Line", "latency_ms": 272.38965034484863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2009}, "4": {"k": 4, "answer": "Maginot Line", "latency_ms": 264.9204730987549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2676}, "5": {"k": 5, "answer": "Séré de Rivières system", "latency_ms": 284.84296798706055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3371}, "6": {"k": 6, "answer": "Séré de Rivières system", "latency_ms": 449.8167037963867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4005}}}
{"qid": "-521349963474269802", "question": "who wrote ain't living long like this", "gold_answers": ["Rodney Crowell"], "shots": {"0": {"k": 0, "answer": "Luther Vandross", "latency_ms": 105.87739944458008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rodney Crowell", "latency_ms": 114.43471908569336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "Rodney Crowell", "latency_ms": 143.93162727355957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Rodney Crowell", "latency_ms": 161.27347946166992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1974}, "4": {"k": 4, "answer": "Rodney Crowell", "latency_ms": 283.3433151245117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2656}, "5": {"k": 5, "answer": "Rodney Crowell", "latency_ms": 331.4168453216553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3246}, "6": {"k": 6, "answer": "Rodney Crowell", "latency_ms": 269.61445808410645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3829}}}
{"qid": "-7607504458781868831", "question": "what is the name of the skin between your nostrils", "gold_answers": ["the nasal septum", "septum"], "shots": {"0": {"k": 0, "answer": "nasal septum", "latency_ms": 126.21259689331055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "nasal bridge", "latency_ms": 231.3833236694336, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 609}, "2": {"k": 2, "answer": "philtrum", "latency_ms": 145.37811279296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "philtrum", "latency_ms": 95.05677223205566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "philtrum", "latency_ms": 157.98473358154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2421}, "5": {"k": 5, "answer": "philtrum", "latency_ms": 197.84975051879883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "philtrum", "latency_ms": 188.4758472442627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3661}}}
{"qid": "-1142715461435497032", "question": "what is the biggest town in west virginia", "gold_answers": ["Charleston"], "shots": {"0": {"k": 0, "answer": "Charleston", "latency_ms": 121.70243263244629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 90.27695655822754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 295.3145503997803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "Martinsburg", "latency_ms": 353.5876274108887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 289.9610996246338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "Martinsburg", "latency_ms": 148.3142375946045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3168}, "6": {"k": 6, "answer": "Morgantown", "latency_ms": 244.80843544006348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3850}}}
{"qid": "-3617986561170614700", "question": "when does monday night raw come on hulu", "gold_answers": ["the following day"], "shots": {"0": {"k": 0, "answer": "Monday Night Raw airs on Hulu at 8:00 PM ET.", "latency_ms": 603.6570072174072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the following day", "latency_ms": 91.31503105163574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "the following day", "latency_ms": 173.97332191467285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1157}, "3": {"k": 3, "answer": "the following day", "latency_ms": 200.67739486694336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1785}, "4": {"k": 4, "answer": "the following day as a condensed 90 minute version", "latency_ms": 318.2201385498047, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2341}, "5": {"k": 5, "answer": "the following day", "latency_ms": 205.40165901184082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3001}, "6": {"k": 6, "answer": "the following day as a condensed 90 minute version is available, not the full version as shown the previous night on the USA Network.", "latency_ms": 984.9328994750977, "em": 0.0, "f1": 0.19047619047619052, "containment": 1.0, "context_chars": 3656}}}
{"qid": "-7768138227276540998", "question": "who become ceo of wipro company in 2016", "gold_answers": ["Abid Ali Neemuchwala"], "shots": {"0": {"k": 0, "answer": "S. Gopalakrishnan", "latency_ms": 111.97972297668457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Abidali Neemuchwala", "latency_ms": 136.48271560668945, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Abidali Neemuchwala", "latency_ms": 337.7985954284668, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Abidali Neemuchwala", "latency_ms": 569.760799407959, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1991}, "4": {"k": 4, "answer": "Abidali Neemuchwala", "latency_ms": 293.1396961212158, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2672}, "5": {"k": 5, "answer": "Abidali Neemuchwala", "latency_ms": 335.53552627563477, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3338}, "6": {"k": 6, "answer": "Abidali Neemuchwala", "latency_ms": 247.98893928527832, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3932}}}
{"qid": "-145926233057232882", "question": "what is the breakdown product formed when one phosphate group is removed from atp", "gold_answers": ["adenosine diphosphate ( ADP )"], "shots": {"0": {"k": 0, "answer": "ADP", "latency_ms": 146.9576358795166, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ADP", "latency_ms": 87.4323844909668, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 734}, "2": {"k": 2, "answer": "ADP", "latency_ms": 114.3035888671875, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1415}, "3": {"k": 3, "answer": "ADP", "latency_ms": 118.3784008026123, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2038}, "4": {"k": 4, "answer": "ADP", "latency_ms": 157.1948528289795, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2743}, "5": {"k": 5, "answer": "ADP", "latency_ms": 142.5337791442871, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3423}, "6": {"k": 6, "answer": "ADP", "latency_ms": 185.7147216796875, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4199}}}
{"qid": "-2520765213268223500", "question": "ahana from dil sambhal ja zara real name", "gold_answers": ["Smriti Kalra"], "shots": {"0": {"k": 0, "answer": "Alisha Sharma", "latency_ms": 135.35785675048828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ahana", "latency_ms": 63.82393836975098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 133.1329345703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 156.2952995300293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1824}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 249.58181381225586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2437}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 144.06132698059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3072}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 213.4089469909668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3697}}}
{"qid": "-7267574651947029426", "question": "to transplant a nucleus from one cell to another cell a scientist would use", "gold_answers": ["somatic cell nuclear transfer"], "shots": {"0": {"k": 0, "answer": "nuclear transfer", "latency_ms": 66.84994697570801, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "somatic cell nuclear transfer", "latency_ms": 145.58672904968262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 649}, "2": {"k": 2, "answer": "somatic cell nuclear transfer", "latency_ms": 103.84202003479004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1282}, "3": {"k": 3, "answer": "somatic cell nuclear transfer", "latency_ms": 116.44697189331055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1904}, "4": {"k": 4, "answer": "somatic cell nuclear transfer", "latency_ms": 180.58276176452637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2518}, "5": {"k": 5, "answer": "somatic cell nuclear transfer", "latency_ms": 333.0647945404053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3130}, "6": {"k": 6, "answer": "nuclear transfer", "latency_ms": 137.237548828125, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3765}}}
{"qid": "3840901317699168424", "question": "what does a bull shark tooth look like", "gold_answers": ["needle - like teeth", "needle - like"], "shots": {"0": {"k": 0, "answer": "Pointed, sharp, and serrated", "latency_ms": 260.84399223327637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 88.09900283813477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 97.12791442871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 158.7386131286621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1779}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 317.3654079437256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2435}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 173.38156700134277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3088}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 176.17058753967285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "-1163524811252371834", "question": "who played the girl in my two dads", "gold_answers": ["Staci Keanan"], "shots": {"0": {"k": 0, "answer": "Morgan Freeman", "latency_ms": 179.2929172515869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Keanan", "latency_ms": 118.56460571289062, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "Keanan", "latency_ms": 167.89603233337402, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Staci Keanan", "latency_ms": 257.0152282714844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1863}, "4": {"k": 4, "answer": "Emma Samms", "latency_ms": 121.1240291595459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2484}, "5": {"k": 5, "answer": "Emma Samms", "latency_ms": 132.02548027038574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "Nicole Bradford (Keanan)", "latency_ms": 218.6429500579834, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3761}}}
{"qid": "-8152430794227425375", "question": "what type of planet is neptune known as", "gold_answers": ["ice giants", "giant"], "shots": {"0": {"k": 0, "answer": "ice giant", "latency_ms": 63.81487846374512, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "ice giant", "latency_ms": 81.71367645263672, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "ice giant", "latency_ms": 76.89166069030762, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1199}, "3": {"k": 3, "answer": "ice giant", "latency_ms": 82.34143257141113, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1807}, "4": {"k": 4, "answer": "ice giant", "latency_ms": 195.6474781036377, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2437}, "5": {"k": 5, "answer": "ice giant", "latency_ms": 156.57591819763184, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3086}, "6": {"k": 6, "answer": "ice giant", "latency_ms": 160.4316234588623, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3733}}}
{"qid": "-5738106146117683016", "question": "when do love and hip hop new york come back on", "gold_answers": ["November 13 , 2017", "October 30 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 148.15783500671387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 30, 2017", "latency_ms": 309.7867965698242, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "November 26, 2018", "latency_ms": 334.46216583251953, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "November 26, 2018", "latency_ms": 489.1970157623291, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "November 26, 2018", "latency_ms": 282.34291076660156, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2439}, "5": {"k": 5, "answer": "November 26, 2018", "latency_ms": 467.98205375671387, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3066}, "6": {"k": 6, "answer": "November 26, 2018", "latency_ms": 459.05613899230957, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3647}}}
{"qid": "-3970079294139411862", "question": "how many gallons of water in the gulf of mexico", "gold_answers": ["660 quadrillion US gallons"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 242.35248565673828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "660 quadrillion US gallons", "latency_ms": 481.19544982910156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "660 quadrillion US gallons", "latency_ms": 280.531644821167, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1324}, "3": {"k": 3, "answer": "660 quadrillion US gallons", "latency_ms": 465.85583686828613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1931}, "4": {"k": 4, "answer": "660 quadrillion US gallons", "latency_ms": 293.0724620819092, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2564}, "5": {"k": 5, "answer": "660 quadrillion US gallons", "latency_ms": 165.24696350097656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3232}, "6": {"k": 6, "answer": "2.5 million km³ or 600,000 cu mi", "latency_ms": 612.602710723877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3830}}}
{"qid": "810772972080024175", "question": "anastomosis between the epididymis and the vas deferens", "gold_answers": ["Vasoepididymostomy"], "shots": {"0": {"k": 0, "answer": "ampullary anastomosis", "latency_ms": 322.02911376953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 160.9485149383545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "vasoepididymostomy", "latency_ms": 142.2595977783203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1342}, "3": {"k": 3, "answer": "vasoepididymostomy", "latency_ms": 589.2715454101562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2024}, "4": {"k": 4, "answer": "vasoepididymostomy", "latency_ms": 296.88215255737305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2629}, "5": {"k": 5, "answer": "vasoepididymostomy", "latency_ms": 324.3703842163086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3329}, "6": {"k": 6, "answer": "vasoepididymostomy", "latency_ms": 375.26893615722656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4082}}}
{"qid": "-4044344454441564632", "question": "who is given credit for inventing the aqua lung", "gold_answers": ["Jacques Cousteau", "Émile Gagnan", "engineer Émile Gagnan"], "shots": {"0": {"k": 0, "answer": "Jacques Cousteau", "latency_ms": 214.33496475219727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Émile Gagnan and Jacques Cousteau", "latency_ms": 316.5783882141113, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 691}, "2": {"k": 2, "answer": "Émile Gagnan and Jacques Cousteau", "latency_ms": 417.1445369720459, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1359}, "3": {"k": 3, "answer": "Émile Gagnan and Jacques Cousteau", "latency_ms": 365.6332492828369, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2051}, "4": {"k": 4, "answer": "Émile Gagnan and Jacques Cousteau", "latency_ms": 256.61683082580566, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2709}, "5": {"k": 5, "answer": "Émile Gagnan and Jacques Cousteau", "latency_ms": 675.835132598877, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3384}, "6": {"k": 6, "answer": "Émile Gagnan and Jacques Cousteau", "latency_ms": 405.09986877441406, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4061}}}
{"qid": "950913319015411203", "question": "where did the name huey helicopter come from", "gold_answers": ["originally designated HU - 1"], "shots": {"0": {"k": 0, "answer": "Huey came from \"Huey,\" a nickname for \"Huey,\" a name given to the helicopter by its pilot, who liked the sound of it. The official name was the UH-1 Iroquois, but it was commonly called the Huey.", "latency_ms": 1845.3373908996582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "HU-1 designation", "latency_ms": 146.38447761535645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "HU-1 designation", "latency_ms": 133.96835327148438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "HU-1 designation", "latency_ms": 160.93778610229492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2051}, "4": {"k": 4, "answer": "HU-1 designation", "latency_ms": 328.9313316345215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2715}, "5": {"k": 5, "answer": "HU-1 designation", "latency_ms": 132.22169876098633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3339}, "6": {"k": 6, "answer": "HU-1 designation", "latency_ms": 317.74258613586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4005}}}
{"qid": "-6762183708006311163", "question": "when did dragon ball super tournament of power start", "gold_answers": ["February 19 , 2017"], "shots": {"0": {"k": 0, "answer": "2018", "latency_ms": 175.39310455322266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 225.45409202575684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 149.12176132202148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 199.12075996398926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 361.6008758544922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2611}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 150.44450759887695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3253}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 357.88846015930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3923}}}
{"qid": "7143040220722532389", "question": "when was it was not death for i stood up published", "gold_answers": ["1890", "1891"], "shots": {"0": {"k": 0, "answer": "1998", "latency_ms": 234.16590690612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 477.9520034790039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 223.06060791015625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1332}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 280.20310401916504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2012}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 172.62005805969238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 125.71358680725098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3244}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 148.70095252990723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3864}}}
{"qid": "-5748368670037082784", "question": "what is the definition of the name thomas", "gold_answers": ["twin", "`` twin ''"], "shots": {"0": {"k": 0, "answer": "Male given name of Hebrew origin, meaning \"twin\" or \"town\"", "latency_ms": 620.140790939331, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "A byname meaning 'twin' of Biblical origin from Aramaic תאומא \"t'om'a\"", "latency_ms": 568.2106018066406, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "twin", "latency_ms": 208.68539810180664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1246}, "3": {"k": 3, "answer": "twin", "latency_ms": 180.9368133544922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1910}, "4": {"k": 4, "answer": "twin", "latency_ms": 98.42038154602051, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2544}, "5": {"k": 5, "answer": "twin", "latency_ms": 150.60806274414062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3131}, "6": {"k": 6, "answer": "twin", "latency_ms": 354.42566871643066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3725}}}
{"qid": "8190949321615211886", "question": "actress who plays penelope garcia on criminal minds", "gold_answers": ["Kirsten Simone Vangsness"], "shots": {"0": {"k": 0, "answer": "Megan Fox", "latency_ms": 124.02153015136719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kirsten Vangsness", "latency_ms": 204.23507690429688, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 681}, "2": {"k": 2, "answer": "Kirsten Vangsness", "latency_ms": 157.27591514587402, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1307}, "3": {"k": 3, "answer": "Kirsten Vangsness", "latency_ms": 283.68210792541504, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Kirsten Vangsness", "latency_ms": 155.1949977874756, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2728}, "5": {"k": 5, "answer": "Kirsten Vangsness", "latency_ms": 423.1576919555664, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3390}, "6": {"k": 6, "answer": "Kirsten Vangsness", "latency_ms": 330.3847312927246, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4002}}}
{"qid": "-9203958203595622889", "question": "who is president of india in present time", "gold_answers": ["Ram Nath Kovind"], "shots": {"0": {"k": 0, "answer": "Narendra Modi", "latency_ms": 337.59236335754395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 104.4156551361084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Ram Nath Kovind", "latency_ms": 106.39047622680664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1207}, "3": {"k": 3, "answer": "Ram Nath Kovind", "latency_ms": 111.63139343261719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1805}, "4": {"k": 4, "answer": "Ram Nath Kovind", "latency_ms": 134.88411903381348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "Ram Nath Kovind", "latency_ms": 126.46818161010742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3112}, "6": {"k": 6, "answer": "Ram Nath Kovind", "latency_ms": 128.47352027893066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3770}}}
{"qid": "-2349691009719617713", "question": "why did kevin can't wait wife leave the show", "gold_answers": ["creative reasons"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.80225372314453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 86.96985244750977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 137.0072364807129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 142.72713661193848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1804}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 124.8323917388916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2436}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 238.7256622314453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3048}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 385.41436195373535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3648}}}
{"qid": "1442521968114516256", "question": "when did season 4 of glee come out", "gold_answers": ["September 13 , 2012"], "shots": {"0": {"k": 0, "answer": "2012", "latency_ms": 195.3597068786621, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 13, 2012", "latency_ms": 190.86599349975586, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "September 13, 2012", "latency_ms": 333.38451385498047, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1304}, "3": {"k": 3, "answer": "September 13, 2012", "latency_ms": 253.89432907104492, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "September 13, 2012", "latency_ms": 345.3967571258545, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2509}, "5": {"k": 5, "answer": "September 13, 2012", "latency_ms": 417.1128273010254, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3098}, "6": {"k": 6, "answer": "September 13, 2012", "latency_ms": 259.8845958709717, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3712}}}
{"qid": "4920082918364942541", "question": "who were the major countries involved in the cold war", "gold_answers": ["the Soviet Union", "the United States"], "shots": {"0": {"k": 0, "answer": "USA, USSR, UK, France, China, Canada, West Germany, East Germany", "latency_ms": 606.3826084136963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "United States and Soviet Union", "latency_ms": 233.9918613433838, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Soviet Union, United States, Great Britain, NATO, Warsaw Pact", "latency_ms": 370.53370475769043, "em": 0.0, "f1": 0.3636363636363636, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "United States, Soviet Union", "latency_ms": 210.27898788452148, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "United States, Soviet Union", "latency_ms": 218.34087371826172, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2600}, "5": {"k": 5, "answer": "United States, Soviet Union", "latency_ms": 204.5896053314209, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3250}, "6": {"k": 6, "answer": "United States, Soviet Union", "latency_ms": 357.280969619751, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3944}}}
{"qid": "2607341085762662184", "question": "what is the main use of the eiffel tower in modern times", "gold_answers": ["visited paid monument", "paid monument"], "shots": {"0": {"k": 0, "answer": "Tourist attraction", "latency_ms": 138.47684860229492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "iconic visual element", "latency_ms": 186.8746280670166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "symbol of Paris or the city in popular culture", "latency_ms": 312.42966651916504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1165}, "3": {"k": 3, "answer": "symbol of Paris and the city in popular culture", "latency_ms": 335.1881504058838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1804}, "4": {"k": 4, "answer": "global cultural icon of France", "latency_ms": 331.9590091705322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2407}, "5": {"k": 5, "answer": "global cultural icon of France and one of the most recognisable structures in the world", "latency_ms": 615.6573295593262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2979}, "6": {"k": 6, "answer": "global cultural icon of France", "latency_ms": 136.59024238586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3566}}}
{"qid": "3221048264431718328", "question": "sweet leavened bread prepared for easter in romania", "gold_answers": ["Cozonac", "Kozunak"], "shots": {"0": {"k": 0, "answer": "Pâine de Paște", "latency_ms": 406.07261657714844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "cozonac", "latency_ms": 122.69139289855957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "pască", "latency_ms": 170.792818069458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "cozonac", "latency_ms": 263.0915641784668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1935}, "4": {"k": 4, "answer": "cozonac", "latency_ms": 173.08306694030762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2604}, "5": {"k": 5, "answer": "cozonac", "latency_ms": 142.23933219909668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3271}, "6": {"k": 6, "answer": "cozonac", "latency_ms": 256.17432594299316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3943}}}
{"qid": "-5864856625806411702", "question": "chief ministers of tamil nadu mentioned on wikipedia", "gold_answers": ["Tanguturi Prakasam", "Ramakrishna Ranga Rao", "Janaki Ramachandran", "O. Panneerselvam", "Raja of Panagal", "O.P. Ramaswamy Reddiyar", "P.S. Kumaraswamy Raja", "C. Rajagopalachari", "B. Munuswamy Naidu", "A. Subbarayalu Reddiar", "K. Palaniswami", "P.T. Rajan", "M. Karunanidhi", "C.N. Annadurai", "V.R. Nedunchezhiyan", "J. Jayalalithaa", "Kurma Venkata Reddy Naidu", "M.G. Ramachandran", "P. Subbarayan"], "shots": {"0": {"k": 0, "answer": "J. Jayalalithaa, M. Karunanidhi, Edappadi K. Palaniswami, O. Panneerselvam, A. G. K. M. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S", "latency_ms": 8090.511798858643, "em": 0.0, "f1": 0.03305785123966942, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 156.09335899353027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "Edappadi K. Palanisamy, Panneerselvam", "latency_ms": 281.77690505981445, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1357}, "3": {"k": 3, "answer": "Edappadi K. Palanisamy", "latency_ms": 506.52146339416504, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2005}, "4": {"k": 4, "answer": "Edappadi K. Palanisamy", "latency_ms": 452.2528648376465, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2740}, "5": {"k": 5, "answer": "M. Karunanidhi, Jayalalithaa, Edappadi K. Palanisamy", "latency_ms": 523.310661315918, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3461}, "6": {"k": 6, "answer": "M. Karunanidhi, Jayalalithaa, Edappadi K. Palanisamy", "latency_ms": 748.659610748291, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4099}}}
{"qid": "-6145868466021183224", "question": "who played solomon in little house on the prairie", "gold_answers": ["Todd Bridges"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 269.70672607421875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 181.39004707336426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 122.23935127258301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 149.15823936462402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 126.80935859680176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2494}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 165.8329963684082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3086}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 274.41883087158203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3732}}}
{"qid": "-3573392112612030278", "question": "who got the first arjun award in athletics", "gold_answers": ["Gurbachan Singh Randhawa"], "shots": {"0": {"k": 0, "answer": "K. M. S. Nair", "latency_ms": 132.96055793762207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bhogeswar Baruah", "latency_ms": 277.68564224243164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 594}, "2": {"k": 2, "answer": "Bhogeswar Baruah", "latency_ms": 154.2806625366211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 144.32048797607422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1770}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 166.3990020751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2377}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 189.4083023071289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2969}, "6": {"k": 6, "answer": "Bhogeswar Baruah", "latency_ms": 218.95694732666016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3549}}}
{"qid": "-8209571805051987276", "question": "what is the genus of a bald eagle", "gold_answers": ["Haliaeetus"], "shots": {"0": {"k": 0, "answer": "Haliaeetus", "latency_ms": 79.3154239654541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haliaeetus", "latency_ms": 84.50627326965332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 635}, "2": {"k": 2, "answer": "Haliaeetus", "latency_ms": 97.05686569213867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "Haliaeetus", "latency_ms": 178.94816398620605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1976}, "4": {"k": 4, "answer": "Haliaeetus", "latency_ms": 254.65917587280273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2560}, "5": {"k": 5, "answer": "Haliaeetus", "latency_ms": 160.4900360107422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3241}, "6": {"k": 6, "answer": "Haliaeetus", "latency_ms": 218.75429153442383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3883}}}
{"qid": "7062924428870783818", "question": "who directed the best years of our lives", "gold_answers": ["William Wyler"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 122.53069877624512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "William Wyler", "latency_ms": 165.25721549987793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 688}, "2": {"k": 2, "answer": "William Wyler", "latency_ms": 274.4622230529785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1341}, "3": {"k": 3, "answer": "William Wyler", "latency_ms": 111.40322685241699, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1986}, "4": {"k": 4, "answer": "William Wyler", "latency_ms": 219.1166877746582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2624}, "5": {"k": 5, "answer": "William Wyler", "latency_ms": 115.47398567199707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3275}, "6": {"k": 6, "answer": "William Wyler", "latency_ms": 158.70952606201172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3923}}}
{"qid": "6882831655380911332", "question": "which british city is farthest from the sea", "gold_answers": ["Coton in the Elms"], "shots": {"0": {"k": 0, "answer": "Birmingham", "latency_ms": 66.99728965759277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 187.98589706420898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Church Flatts Farm", "latency_ms": 164.30330276489258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "Coton in the Elms", "latency_ms": 137.95757293701172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1790}, "4": {"k": 4, "answer": "Coton in the Elms", "latency_ms": 149.8100757598877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2352}, "5": {"k": 5, "answer": "Coton in the Elms", "latency_ms": 332.25035667419434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2969}, "6": {"k": 6, "answer": "Coton in the Elms", "latency_ms": 202.78263092041016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3536}}}
{"qid": "7895715200373578920", "question": "how many characters are present in icd-10 codes", "gold_answers": ["7"], "shots": {"0": {"k": 0, "answer": "7", "latency_ms": 41.28718376159668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "7", "latency_ms": 57.23381042480469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "7", "latency_ms": 60.00852584838867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1213}, "3": {"k": 3, "answer": "3, 4, 5, 6, or 7", "latency_ms": 257.7939033508301, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1865}, "4": {"k": 4, "answer": "3, 4, 5, 6, or 7", "latency_ms": 359.40051078796387, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 2520}, "5": {"k": 5, "answer": "3, 4, 5, 6, or 7", "latency_ms": 413.6972427368164, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 3167}, "6": {"k": 6, "answer": "7", "latency_ms": 170.31407356262207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3903}}}
{"qid": "-8464536395541330825", "question": "which layer of the meninges is connected to the brain", "gold_answers": ["pia mater", "The pia mater"], "shots": {"0": {"k": 0, "answer": "dura mater", "latency_ms": 67.86918640136719, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "pia mater", "latency_ms": 164.08181190490723, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 628}, "2": {"k": 2, "answer": "inner meningeal layer", "latency_ms": 133.96120071411133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1280}, "3": {"k": 3, "answer": "pia mater", "latency_ms": 131.32214546203613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1869}, "4": {"k": 4, "answer": "pia mater", "latency_ms": 118.4234619140625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2494}, "5": {"k": 5, "answer": "pia mater", "latency_ms": 115.35930633544922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3115}, "6": {"k": 6, "answer": "pia mater", "latency_ms": 118.4232234954834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3719}}}
{"qid": "-4392475526001139368", "question": "who was first governor general of british india", "gold_answers": ["Warren Hastings", "Louis Mountbatten"], "shots": {"0": {"k": 0, "answer": "Lord Cornwallis", "latency_ms": 214.03193473815918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lord William Bentinck", "latency_ms": 147.80688285827637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Lord William Bentinck", "latency_ms": 416.58711433410645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1373}, "3": {"k": 3, "answer": "Lord William Bentinck", "latency_ms": 188.08531761169434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2057}, "4": {"k": 4, "answer": "Lord William Bentinck", "latency_ms": 270.8010673522949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2660}, "5": {"k": 5, "answer": "Lord William Bentinck", "latency_ms": 165.73071479797363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3308}, "6": {"k": 6, "answer": "Lord William Bentinck", "latency_ms": 156.47554397583008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3978}}}
{"qid": "-4487724214437405890", "question": "where is the heart of palm on a palm tree", "gold_answers": ["the center core", "the inner core", "growing bud", "inner core and growing bud"], "shots": {"0": {"k": 0, "answer": "It is not on a palm tree.", "latency_ms": 406.7819118499756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "inner core and growing bud", "latency_ms": 111.47856712341309, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "inner core and growing bud of certain palm trees", "latency_ms": 431.4863681793213, "em": 0.0, "f1": 0.7142857142857143, "containment": 1.0, "context_chars": 1279}, "3": {"k": 3, "answer": "inner core and growing bud", "latency_ms": 344.00415420532227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1887}, "4": {"k": 4, "answer": "inner core and growing bud of certain palm trees", "latency_ms": 534.4812870025635, "em": 0.0, "f1": 0.7142857142857143, "containment": 1.0, "context_chars": 2531}, "5": {"k": 5, "answer": "inner core and growing bud of certain palm trees", "latency_ms": 403.7168025970459, "em": 0.0, "f1": 0.7142857142857143, "containment": 1.0, "context_chars": 3142}, "6": {"k": 6, "answer": "inner core and growing bud", "latency_ms": 323.74119758605957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3751}}}
{"qid": "-6162933554898709661", "question": "which player won the pga championship by the most shots", "gold_answers": ["Rory McIlroy"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 84.29813385009766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 211.9002342224121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 559}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 277.50110626220703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 298.7940311431885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1796}, "4": {"k": 4, "answer": "Brooks Koepka", "latency_ms": 200.33884048461914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2407}, "5": {"k": 5, "answer": "Brooks Koepka", "latency_ms": 262.63427734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3057}, "6": {"k": 6, "answer": "Brooks Koepka", "latency_ms": 383.88633728027344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3683}}}
{"qid": "-1342189058950802702", "question": "who made the poppies at tower of london", "gold_answers": ["Tom Piper", "stage designer Tom Piper", "Paul Cummins"], "shots": {"0": {"k": 0, "answer": "The Royal British Legion", "latency_ms": 75.54817199707031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 80.10220527648926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 208.71901512145996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1178}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 270.54357528686523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1777}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 176.65696144104004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2432}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 210.64233779907227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3071}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 134.48691368103027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3670}}}
{"qid": "-6531366728667964971", "question": "what is the inner core of the earth made from", "gold_answers": ["some other elements", "iron -- nickel alloy", "an iron -- nickel alloy"], "shots": {"0": {"k": 0, "answer": "Iron and nickel", "latency_ms": 139.50300216674805, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "iron–nickel alloy and some other elements", "latency_ms": 475.30579566955566, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 585}, "2": {"k": 2, "answer": "iron–nickel alloy and some other elements", "latency_ms": 187.70170211791992, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1164}, "3": {"k": 3, "answer": "iron–nickel alloy and some other elements", "latency_ms": 358.7043285369873, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1816}, "4": {"k": 4, "answer": "iron–nickel alloy and some other elements", "latency_ms": 228.18589210510254, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2459}, "5": {"k": 5, "answer": "iron–nickel alloy and some other elements", "latency_ms": 424.3195056915283, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3059}, "6": {"k": 6, "answer": "iron–nickel alloy", "latency_ms": 332.4761390686035, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3696}}}
{"qid": "608136254238749812", "question": "where did the british army launch a successful invasion in 1776", "gold_answers": ["Long Island", "New York"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 132.87043571472168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Manhattan", "latency_ms": 71.97165489196777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 722}, "2": {"k": 2, "answer": "New Jersey", "latency_ms": 135.15925407409668, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1381}, "3": {"k": 3, "answer": "New Jersey", "latency_ms": 234.24625396728516, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2080}, "4": {"k": 4, "answer": "New Jersey", "latency_ms": 167.15264320373535, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2755}, "5": {"k": 5, "answer": "New Jersey", "latency_ms": 102.17571258544922, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3444}, "6": {"k": 6, "answer": "New Jersey", "latency_ms": 244.29821968078613, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4127}}}
{"qid": "-4049786002203271572", "question": "who wrote the guitar solo in beat it", "gold_answers": ["Eddie Van Halen"], "shots": {"0": {"k": 0, "answer": "Eddie Van Halen", "latency_ms": 296.3085174560547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eddie Van Halen", "latency_ms": 268.0692672729492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 625}, "2": {"k": 2, "answer": "Eddie Van Halen", "latency_ms": 139.34946060180664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Eddie Van Halen", "latency_ms": 226.52196884155273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "Eddie Van Halen", "latency_ms": 303.99155616760254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2430}, "5": {"k": 5, "answer": "Eddie Van Halen", "latency_ms": 225.02994537353516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3074}, "6": {"k": 6, "answer": "Eddie Van Halen", "latency_ms": 198.4539031982422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3687}}}
{"qid": "-2033893527164697325", "question": "who was the first executive president of guyana", "gold_answers": ["Forbes Burnham", "Arthur Chung"], "shots": {"0": {"k": 0, "answer": "Burns G. Phillips", "latency_ms": 203.08685302734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Forbes Burnham", "latency_ms": 97.91254997253418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 679}, "2": {"k": 2, "answer": "Forbes Burnham", "latency_ms": 151.60226821899414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Forbes Burnham", "latency_ms": 128.77440452575684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Forbes Burnham", "latency_ms": 164.87479209899902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2542}, "5": {"k": 5, "answer": "Forbes Burnham", "latency_ms": 248.32534790039062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3225}, "6": {"k": 6, "answer": "Forbes Burnham", "latency_ms": 293.2760715484619, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3907}}}
{"qid": "-7555953957057409422", "question": "who plays sven in the santa clarita diet", "gold_answers": ["Leo Howard"], "shots": {"0": {"k": 0, "answer": "Ethan Hawke", "latency_ms": 89.60890769958496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 139.96291160583496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 98.62828254699707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1414}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 184.88764762878418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 112.49184608459473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2717}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 126.9369125366211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3387}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 190.57941436767578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3993}}}
{"qid": "4639443563976072562", "question": "term limits for house of representatives and senate", "gold_answers": ["Unlimited six - year terms", "Unlimited two - year terms"], "shots": {"0": {"k": 0, "answer": "House: 2 term limits; Senate: no term limits", "latency_ms": 194.59962844848633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "two six-year terms for Senate, six two-year terms for House", "latency_ms": 471.74811363220215, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "two six-year terms for Senate, six two-year terms for House", "latency_ms": 312.5569820404053, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Michigan: House limited to three two-year terms; Senate term limits not specified in context.", "latency_ms": 792.1991348266602, "em": 0.0, "f1": 0.11111111111111112, "containment": 0.0, "context_chars": 2015}, "4": {"k": 4, "answer": "Michigan: three two-year terms", "latency_ms": 402.9114246368408, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2663}, "5": {"k": 5, "answer": "House: three two-year terms; Senate: two four-year terms", "latency_ms": 246.10376358032227, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3326}, "6": {"k": 6, "answer": "House: three two-year terms; Senate: no term limit", "latency_ms": 756.2706470489502, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 3938}}}
{"qid": "-7264742768431676142", "question": "who hosted and won the inagural world cup", "gold_answers": ["Uruguay"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 297.81317710876465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Uruguay", "latency_ms": 293.26558113098145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Uruguay", "latency_ms": 67.21735000610352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1190}, "3": {"k": 3, "answer": "Uruguay", "latency_ms": 125.42200088500977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1798}, "4": {"k": 4, "answer": "Uruguay", "latency_ms": 105.1936149597168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2463}, "5": {"k": 5, "answer": "Uruguay", "latency_ms": 104.38060760498047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3096}, "6": {"k": 6, "answer": "Uruguay", "latency_ms": 377.02298164367676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3680}}}
{"qid": "-755777782301038229", "question": "iupac name of element with atomic number 107", "gold_answers": ["Bohrium", "bohrium"], "shots": {"0": {"k": 0, "answer": "Bohrium", "latency_ms": 110.66579818725586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "bohrium", "latency_ms": 212.92543411254883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "bohrium", "latency_ms": 259.29951667785645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1330}, "3": {"k": 3, "answer": "unnilseptium", "latency_ms": 162.3086929321289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "bohrium", "latency_ms": 292.45495796203613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2646}, "5": {"k": 5, "answer": "bohrium", "latency_ms": 166.84246063232422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3275}, "6": {"k": 6, "answer": "bohrium", "latency_ms": 146.96502685546875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3977}}}
{"qid": "-564063817056958231", "question": "when does boomer find out she a cylon", "gold_answers": ["Kobol 's Last Gleaming"], "shots": {"0": {"k": 0, "answer": "Season 4, Episode 13 \"The Long Way Home\"", "latency_ms": 263.230562210083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "episode \"Downloaded\"", "latency_ms": 93.05381774902344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "episode \"Downloaded\"", "latency_ms": 205.3840160369873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1240}, "3": {"k": 3, "answer": "episode \"Downloaded\"", "latency_ms": 247.44796752929688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "episode \"Downloaded\"", "latency_ms": 299.6826171875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2442}, "5": {"k": 5, "answer": "episode \"Downloaded\"", "latency_ms": 195.88899612426758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3048}, "6": {"k": 6, "answer": "episode \"Downloaded\"", "latency_ms": 145.11656761169434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3681}}}
{"qid": "2010294071842366580", "question": "who wrote the treasure of the sierra madre", "gold_answers": ["B. Traven", "bilingual German author B. Traven"], "shots": {"0": {"k": 0, "answer": "John Steinbeck", "latency_ms": 67.11912155151367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "B. Traven", "latency_ms": 141.68810844421387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "B. Traven", "latency_ms": 234.59124565124512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "B. Traven", "latency_ms": 110.29314994812012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1872}, "4": {"k": 4, "answer": "B. Traven", "latency_ms": 403.4562110900879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2515}, "5": {"k": 5, "answer": "B. Traven", "latency_ms": 250.67448616027832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3237}, "6": {"k": 6, "answer": "B. Traven", "latency_ms": 167.6483154296875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3872}}}
{"qid": "-838090964585984539", "question": "what was the name of darth vader star destroyer", "gold_answers": ["Devastator", "the Devastator"], "shots": {"0": {"k": 0, "answer": "Devastator", "latency_ms": 219.71559524536133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Executor", "latency_ms": 51.93066596984863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "Darth Vader's Star Destroyer", "latency_ms": 360.231876373291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1411}, "3": {"k": 3, "answer": "Darth Vader's Star Destroyer", "latency_ms": 382.97271728515625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2130}, "4": {"k": 4, "answer": "Darth Vader's Star Destroyer", "latency_ms": 499.1624355316162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2825}, "5": {"k": 5, "answer": "Darth Vader's Star Destroyer", "latency_ms": 419.74759101867676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3518}, "6": {"k": 6, "answer": "Darth Vader's Star Destroyer", "latency_ms": 524.9936580657959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4221}}}
{"qid": "5980486301760893723", "question": "what is the female lion called in lion king", "gold_answers": ["Nala"], "shots": {"0": {"k": 0, "answer": "Nala", "latency_ms": 152.55975723266602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nala", "latency_ms": 183.9311122894287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "Nala", "latency_ms": 143.78833770751953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Nala", "latency_ms": 89.39599990844727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1969}, "4": {"k": 4, "answer": "Nala", "latency_ms": 204.61201667785645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Nala", "latency_ms": 170.1037883758545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3150}, "6": {"k": 6, "answer": "Nala", "latency_ms": 278.1057357788086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3769}}}
{"qid": "8551231508158823921", "question": "how many seasons are in star wars the clone wars", "gold_answers": ["6"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 52.24323272705078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "7", "latency_ms": 261.66486740112305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "3 seasons", "latency_ms": 87.67890930175781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "7", "latency_ms": 68.50886344909668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1977}, "4": {"k": 4, "answer": "7", "latency_ms": 191.07317924499512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2596}, "5": {"k": 5, "answer": "7 seasons", "latency_ms": 241.06240272521973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3271}, "6": {"k": 6, "answer": "7", "latency_ms": 103.6386489868164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3952}}}
{"qid": "-4664207169377167173", "question": "who sings gone gone gone she been gone so long", "gold_answers": ["Chilliwack"], "shots": {"0": {"k": 0, "answer": "Lil Wayne", "latency_ms": 201.97534561157227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dixie Chicks", "latency_ms": 336.09557151794434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 224.8704433441162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1167}, "3": {"k": 3, "answer": "Lefty Frizzell", "latency_ms": 213.33885192871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1799}, "4": {"k": 4, "answer": "Lefty Frizzell", "latency_ms": 409.15608406066895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2414}, "5": {"k": 5, "answer": "Lefty Frizzell", "latency_ms": 197.52979278564453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Lefty Frizzell", "latency_ms": 206.49433135986328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3706}}}
{"qid": "-7605852330002608395", "question": "what does the air gap do on a dishwasher", "gold_answers": ["backflow prevention"], "shots": {"0": {"k": 0, "answer": "Prevents water from entering the drain during operation", "latency_ms": 253.0684471130371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "prevents drain water from backing up into the dishwasher", "latency_ms": 370.67627906799316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "prevents drain water from backing up into the dishwasher", "latency_ms": 338.1226062774658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1216}, "3": {"k": 3, "answer": "prevents drain water from backing up into the dishwasher", "latency_ms": 354.39014434814453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1792}, "4": {"k": 4, "answer": "prevents drain water from backing up into the dishwasher and contaminating dishes", "latency_ms": 280.7016372680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2390}, "5": {"k": 5, "answer": "prevents drain water from backing up into the dishwasher and contaminating dishes", "latency_ms": 383.94737243652344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3046}, "6": {"k": 6, "answer": "prevents drain water from backing up into the dishwasher, possibly contaminating dishes", "latency_ms": 473.9038944244385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3703}}}
{"qid": "1447779709231013547", "question": "who does bryce dallas howard play in the grinch", "gold_answers": ["Surprised Who"], "shots": {"0": {"k": 0, "answer": "Maxwell \"Max\" Grinch", "latency_ms": 271.3940143585205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 188.02165985107422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 230.01527786254883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 296.45395278930664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1957}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 215.79670906066895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2551}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 242.4478530883789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3193}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 293.66302490234375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3819}}}
{"qid": "2494339783007699672", "question": "where does dividends go on cash flow statement", "gold_answers": ["the financing activities section"], "shots": {"0": {"k": 0, "answer": "cash from financing activities", "latency_ms": 148.09489250183105, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "operating or investing activities", "latency_ms": 207.2925567626953, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 714}, "2": {"k": 2, "answer": "operating activities or investing activities", "latency_ms": 120.05114555358887, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "operating activities", "latency_ms": 84.09929275512695, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "financing activities", "latency_ms": 259.9329948425293, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2588}, "5": {"k": 5, "answer": "financing activities", "latency_ms": 164.7169589996338, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3267}, "6": {"k": 6, "answer": "financing activities", "latency_ms": 131.96492195129395, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3844}}}
{"qid": "-6195495799282225761", "question": "what is the 180 degree line of longitude called", "gold_answers": ["antimeridian", "180th meridian or antimeridian", "180th meridian"], "shots": {"0": {"k": 0, "answer": "Antimeridian", "latency_ms": 171.1740493774414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "180th meridian", "latency_ms": 111.20200157165527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 635}, "2": {"k": 2, "answer": "180th meridian", "latency_ms": 121.93036079406738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1255}, "3": {"k": 3, "answer": "180th meridian", "latency_ms": 214.79320526123047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1958}, "4": {"k": 4, "answer": "180th meridian", "latency_ms": 291.9347286224365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2649}, "5": {"k": 5, "answer": "180th meridian", "latency_ms": 261.8684768676758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3263}, "6": {"k": 6, "answer": "180th meridian", "latency_ms": 325.27709007263184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3858}}}
{"qid": "-4512601929982486528", "question": "north carolina delegate to the second continental congress", "gold_answers": ["Timothy Bloodworth", "John B. Ashe", "William Blount"], "shots": {"0": {"k": 0, "answer": "William Hooper", "latency_ms": 65.86933135986328, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "William Hooper, Joseph Hewes, Richard Caswell", "latency_ms": 345.32737731933594, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "William Hooper", "latency_ms": 348.10471534729004, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1376}, "3": {"k": 3, "answer": "William Hooper", "latency_ms": 134.38773155212402, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2031}, "4": {"k": 4, "answer": "William Hooper", "latency_ms": 160.62450408935547, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "William Hooper", "latency_ms": 224.74002838134766, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3390}, "6": {"k": 6, "answer": "Joseph Hewes, William Hooper, John Penn", "latency_ms": 375.96750259399414, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 4087}}}
{"qid": "-2808093071562767910", "question": "who played the face in the a team", "gold_answers": ["Dirk Benedict"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 179.02064323425293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tim Dunigan (pilot), Dirk Benedict (main role)", "latency_ms": 554.4881820678711, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 583}, "2": {"k": 2, "answer": "Dirk Benedict", "latency_ms": 209.94234085083008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1198}, "3": {"k": 3, "answer": "Dirk Benedict", "latency_ms": 227.2970676422119, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Dirk Benedict", "latency_ms": 190.12880325317383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2502}, "5": {"k": 5, "answer": "Dirk Benedict", "latency_ms": 152.7719497680664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3099}, "6": {"k": 6, "answer": "Dirk Benedict", "latency_ms": 140.02132415771484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3734}}}
{"qid": "7119887147544272496", "question": "when did the last volcano erupt in iceland", "gold_answers": ["2010"], "shots": {"0": {"k": 0, "answer": "2023", "latency_ms": 153.79786491394043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2004", "latency_ms": 157.54222869873047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "2004", "latency_ms": 380.19752502441406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1217}, "3": {"k": 3, "answer": "2011", "latency_ms": 199.76329803466797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1856}, "4": {"k": 4, "answer": "26 February 2000", "latency_ms": 422.63293266296387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "26 February 2000", "latency_ms": 256.11400604248047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "26 February 2000", "latency_ms": 489.69388008117676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3680}}}
{"qid": "-7102729436138036180", "question": "when are you considered under the poverty line", "gold_answers": ["US $11,770"], "shots": {"0": {"k": 0, "answer": "varies by country and year", "latency_ms": 292.30237007141113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2002", "latency_ms": 140.36870002746582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "2002", "latency_ms": 163.36750984191895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "when income is less than $1.90 per day per head (PPP)", "latency_ms": 843.9667224884033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "2002 survey", "latency_ms": 215.32845497131348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2535}, "5": {"k": 5, "answer": "when income falls below the poverty threshold", "latency_ms": 259.2906951904297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3182}, "6": {"k": 6, "answer": "when income falls below the poverty threshold", "latency_ms": 162.00852394104004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3906}}}
{"qid": "-8391680223788694572", "question": "who wrote if i were a boy reba or beyonce", "gold_answers": ["BC Jean", "Toby Gad"], "shots": {"0": {"k": 0, "answer": "Reba McEntire", "latency_ms": 176.99098587036133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "BC Jean", "latency_ms": 120.24331092834473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "BC Jean", "latency_ms": 242.7818775177002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "BC Jean", "latency_ms": 183.26640129089355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1799}, "4": {"k": 4, "answer": "BC Jean", "latency_ms": 150.252103805542, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2373}, "5": {"k": 5, "answer": "BC Jean", "latency_ms": 156.45575523376465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3053}, "6": {"k": 6, "answer": "BC Jean", "latency_ms": 169.04139518737793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3616}}}
{"qid": "-6785327703850595221", "question": "who has climbed mount everest the number of times", "gold_answers": ["Kami Rita Sherpa", "Phurba Tashi Sherpa", "Apa Sherpa"], "shots": {"0": {"k": 0, "answer": "As of 2023, the record for the most ascents of Mount Everest is held by **Reinhold Messner** and **Edmund Hillary**, but the current record holder for the most climbs is **Phurba Tashi**, with **12 ascents**. However, the most frequently cited record is **12 times**. \n\nFinal answer: **12**", "latency_ms": 2758.6772441864014, "em": 0.0, "f1": 0.08888888888888889, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "21 times", "latency_ms": 129.23741340637207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 562}, "2": {"k": 2, "answer": "21 times", "latency_ms": 211.92336082458496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1180}, "3": {"k": 3, "answer": "21 times", "latency_ms": 214.7960662841797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1802}, "4": {"k": 4, "answer": "Apa Sherpa (21 times)", "latency_ms": 524.7559547424316, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2443}, "5": {"k": 5, "answer": "Apa Sherpa", "latency_ms": 257.66611099243164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3089}, "6": {"k": 6, "answer": "Apa Sherpa", "latency_ms": 478.6217212677002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3688}}}
