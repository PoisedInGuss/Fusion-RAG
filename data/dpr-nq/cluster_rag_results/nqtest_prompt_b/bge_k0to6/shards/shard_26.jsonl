{"qid": "-7098436211686405768", "question": "who won the icc under 19 world cup 2018", "gold_answers": ["India", "West Indies"], "shots": {"0": {"k": 0, "answer": "England", "latency_ms": 199.65457916259766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "India", "latency_ms": 48.2633113861084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "India", "latency_ms": 87.2955322265625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1288}, "3": {"k": 3, "answer": "India", "latency_ms": 290.58146476745605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "India", "latency_ms": 138.95845413208008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2552}, "5": {"k": 5, "answer": "India", "latency_ms": 157.4685573577881, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3218}, "6": {"k": 6, "answer": "India", "latency_ms": 205.2006721496582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3879}}}
{"qid": "5122841983113839364", "question": "when was the jury system abolished in india", "gold_answers": ["1959"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 174.8816967010498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1973", "latency_ms": 179.3508529663086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "1973", "latency_ms": 172.0750331878662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1189}, "3": {"k": 3, "answer": "1973", "latency_ms": 114.50457572937012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1827}, "4": {"k": 4, "answer": "1973", "latency_ms": 229.96044158935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "1973", "latency_ms": 338.3762836456299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3140}, "6": {"k": 6, "answer": "1973", "latency_ms": 174.96585845947266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3787}}}
{"qid": "-6392030846180659596", "question": "who played morticia in the addams family tv show", "gold_answers": ["Carolyn Sue Jones"], "shots": {"0": {"k": 0, "answer": "Cindy Williams", "latency_ms": 66.62106513977051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ellie Harvie", "latency_ms": 195.1305866241455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Ellie Harvie", "latency_ms": 192.98577308654785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1294}, "3": {"k": 3, "answer": "Carolyn Jones", "latency_ms": 244.767427444458, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Carolyn Jones", "latency_ms": 102.9052734375, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": "Carolyn Jones", "latency_ms": 114.52937126159668, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3176}, "6": {"k": 6, "answer": "Carolyn Jones", "latency_ms": 236.0835075378418, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3832}}}
{"qid": "8177571930408806343", "question": "how many episodes of the white princess will there be", "gold_answers": ["eight", "8"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 160.74061393737793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 132.88450241088867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.47870063781738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1314}, "3": {"k": 3, "answer": "eight episodes", "latency_ms": 213.43564987182617, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1981}, "4": {"k": 4, "answer": "8", "latency_ms": 87.6612663269043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2615}, "5": {"k": 5, "answer": "8", "latency_ms": 181.15472793579102, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "8", "latency_ms": 141.59512519836426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3848}}}
{"qid": "6581085745347506584", "question": "when was pac man released in the us", "gold_answers": ["October 26 , 1980", "in October 1980", "October 1980"], "shots": {"0": {"k": 0, "answer": "1980", "latency_ms": 154.2186737060547, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 197.04675674438477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "1980", "latency_ms": 313.5073184967041, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "October 1980", "latency_ms": 240.1900291442871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1858}, "4": {"k": 4, "answer": "October 1980", "latency_ms": 205.18231391906738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2461}, "5": {"k": 5, "answer": "October 1980", "latency_ms": 152.4035930633545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3087}, "6": {"k": 6, "answer": "October 1980", "latency_ms": 518.1193351745605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3722}}}
{"qid": "3114053463642113959", "question": "who plays drew's boyfriend on the night shift", "gold_answers": ["Rick"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 103.32989692687988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 114.98713493347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 229.68029975891113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 201.28273963928223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 138.2145881652832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2568}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 185.16993522644043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 370.1589107513428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3822}}}
{"qid": "4533997928552404782", "question": "where is the lost dutchman's mine supposed to be located", "gold_answers": ["in the southwestern United States"], "shots": {"0": {"k": 0, "answer": "Arizona", "latency_ms": 34.702301025390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "latency_ms": 443.5727596282959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "latency_ms": 547.074556350708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "latency_ms": 293.71070861816406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "latency_ms": 449.64098930358887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2494}, "5": {"k": 5, "answer": "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "latency_ms": 288.9218330383301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3115}, "6": {"k": 6, "answer": "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "latency_ms": 643.0623531341553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3714}}}
{"qid": "5352272261459028724", "question": "who sang the national anthem at the 2002 super bowl", "gold_answers": ["Mariah Carey"], "shots": {"0": {"k": 0, "answer": "Howie Mandel", "latency_ms": 198.8656520843506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dixie Chicks", "latency_ms": 255.01656532287598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "The context does not specify who sang the national anthem at the 2002 Super Bowl. I cannot answer.", "latency_ms": 1074.1326808929443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 179.96668815612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Barry Manilow, Yolanda Adams, James Ingram, Wynonna Judd, and Patti LaBelle", "latency_ms": 1217.50807762146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2633}, "5": {"k": 5, "answer": "Barry Manilow, Yolanda Adams, James Ingram, Wynonna Judd, and Patti LaBelle", "latency_ms": 598.5062122344971, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "Barry Manilow, Yolanda Adams, James Ingram, Wynonna Judd, and Patti LaBelle", "latency_ms": 950.6826400756836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3888}}}
{"qid": "-5448353169627005671", "question": "where did the last name wallace come from", "gold_answers": ["a Scottish surname"], "shots": {"0": {"k": 0, "answer": "Scottish Gaelic origin", "latency_ms": 417.48952865600586, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Scottish surname derived from Anglo-Norman French \"waleis\"", "latency_ms": 386.4719867706299, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "Scottish surname derived from Anglo-Norman French \"waleis\"", "latency_ms": 581.9244384765625, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "Scottish surname derived from Anglo-Norman French \"waleis\", meaning \"foreigner\" or \"Welshman\"", "latency_ms": 1001.9869804382324, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "Scottish surname derived from Anglo-Norman French \"waleis\", meaning \"foreigner\" or \"Welshman\"", "latency_ms": 907.8516960144043, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 2606}, "5": {"k": 5, "answer": "Anglo-Norman French \"waleis\", Old English \"wylisc\" meaning \"foreigner\" or \"Welshman\"", "latency_ms": 844.3994522094727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Scottish surname derived from Anglo-Norman French \"waleis\", meaning \"foreigner\" or \"Welshman\"", "latency_ms": 720.5407619476318, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 3830}}}
{"qid": "-6282136142651212589", "question": "who made the movie fifty shades of grey", "gold_answers": ["Universal Pictures and Focus Features", "Sam Taylor - Johnson"], "shots": {"0": {"k": 0, "answer": "The movie *Fifty Shades of Grey* was made by **The Weinstein Company**.", "latency_ms": 746.5519905090332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sam Taylor-Johnson", "latency_ms": 109.69424247741699, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "Sam Taylor-Johnson", "latency_ms": 345.29781341552734, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Sam Taylor-Johnson", "latency_ms": 169.61193084716797, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "Sam Taylor-Johnson", "latency_ms": 233.992338180542, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Sam Taylor-Johnson", "latency_ms": 234.23290252685547, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3275}, "6": {"k": 6, "answer": "Sam Taylor-Johnson", "latency_ms": 229.52508926391602, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3958}}}
{"qid": "-6860125217421272747", "question": "what are the names of the hunger games", "gold_answers": ["The Hunger Games"], "shots": {"0": {"k": 0, "answer": "Catching Fire, Mockingjay", "latency_ms": 451.3716697692871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Hunger Games", "latency_ms": 221.17900848388672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 586}, "2": {"k": 2, "answer": "The Hunger Games", "latency_ms": 264.0111446380615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1236}, "3": {"k": 3, "answer": "The Hunger Games, Catching Fire, Mockingjay", "latency_ms": 649.0895748138428, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "The Hunger Games, Catching Fire, Mockingjay", "latency_ms": 563.2023811340332, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2560}, "5": {"k": 5, "answer": "The Hunger Games, Catching Fire, Mockingjay", "latency_ms": 217.79465675354004, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "The Hunger Games, Catching Fire, Mockingjay", "latency_ms": 480.71885108947754, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3876}}}
{"qid": "57573855796458704", "question": "what engine is in a holden v8 supercar", "gold_answers": ["V8 - engine"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 78.97257804870605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Holden V8 engine", "latency_ms": 167.0095920562744, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "Holden 308 V8 engine", "latency_ms": 433.43091011047363, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "5.0-litre, naturally aspirated V8-engine with electronic fuel injection", "latency_ms": 262.10999488830566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "5.0-litre, naturally aspirated V8 engine", "latency_ms": 351.00388526916504, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "5.0-litre, naturally aspirated V8 engine", "latency_ms": 355.16953468322754, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3129}, "6": {"k": 6, "answer": "5.0-litre, naturally aspirated V8-engine", "latency_ms": 455.0282955169678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3711}}}
{"qid": "4575828710313790645", "question": "when did the international space station go into space", "gold_answers": ["1998"], "shots": {"0": {"k": 0, "answer": "1998", "latency_ms": 176.5279769897461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1998", "latency_ms": 227.62465476989746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "November 20, 1998", "latency_ms": 340.8536911010742, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1312}, "3": {"k": 3, "answer": "November 20, 1998", "latency_ms": 528.95188331604, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2034}, "4": {"k": 4, "answer": "November 20, 1998", "latency_ms": 310.59908866882324, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2640}, "5": {"k": 5, "answer": "November 20, 1998", "latency_ms": 476.46021842956543, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3256}, "6": {"k": 6, "answer": "November 20, 1998", "latency_ms": 217.65398979187012, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3904}}}
{"qid": "2303585950274205305", "question": "what type of dog was laika the spacedog", "gold_answers": ["mongrel female"], "shots": {"0": {"k": 0, "answer": "Soviet space dog", "latency_ms": 167.62828826904297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "stray dog", "latency_ms": 121.97136878967285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 571}, "2": {"k": 2, "answer": "Russian Spitz", "latency_ms": 176.83649063110352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "Russian Spitz", "latency_ms": 127.8231143951416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1869}, "4": {"k": 4, "answer": "part-Samoyed terrier", "latency_ms": 216.9177532196045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2510}, "5": {"k": 5, "answer": "mongrel or part-Samoyed terrier", "latency_ms": 606.5528392791748, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3208}, "6": {"k": 6, "answer": "mongrel", "latency_ms": 187.5441074371338, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3816}}}
{"qid": "-6008777350997007702", "question": "who sang it's a mean old world", "gold_answers": ["T - Bone Walker"], "shots": {"0": {"k": 0, "answer": "Tommy Roe", "latency_ms": 168.49517822265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "T-Bone Walker", "latency_ms": 251.51944160461426, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "T-Bone Walker", "latency_ms": 292.8426265716553, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1263}, "3": {"k": 3, "answer": "T-Bone Walker", "latency_ms": 312.0584487915039, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "T-Bone Walker", "latency_ms": 171.41485214233398, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "T-Bone Walker", "latency_ms": 340.00635147094727, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "T-Bone Walker", "latency_ms": 306.07104301452637, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3844}}}
{"qid": "-467684233955454366", "question": "what are the 4 types of nitrogenous bases", "gold_answers": ["cytosine ( C )", "uracil ( U )", "thymine ( T )", "adenine ( A )", "guanine ( G )"], "shots": {"0": {"k": 0, "answer": "Adenine, Guanine, Cytosine, Thymine", "latency_ms": 526.423454284668, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "adenine, guanine, cytosine, thymine", "latency_ms": 372.894287109375, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 687}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 179.5647144317627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1400}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 242.26069450378418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2005}, "4": {"k": 4, "answer": "adenine, guanine, cytosine, thymine, uracil", "latency_ms": 696.2502002716064, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 2679}, "5": {"k": 5, "answer": "adenine, guanine, cytosine, thymine", "latency_ms": 513.3626461029053, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3328}, "6": {"k": 6, "answer": "adenine, guanine, cytosine, thymine", "latency_ms": 620.927095413208, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4004}}}
{"qid": "8296511137247210518", "question": "what are the toll roads called in mexico", "gold_answers": ["autopistas"], "shots": {"0": {"k": 0, "answer": "Toll roads in Mexico are called \"carreteras con peaje\".", "latency_ms": 700.6244659423828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Autopistas", "latency_ms": 125.55837631225586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "Autopistas", "latency_ms": 120.5446720123291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1353}, "3": {"k": 3, "answer": "Autopistas", "latency_ms": 241.19281768798828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2025}, "4": {"k": 4, "answer": "Autopistas", "latency_ms": 221.17137908935547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2735}, "5": {"k": 5, "answer": "autopistas de cuota", "latency_ms": 268.0785655975342, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3373}, "6": {"k": 6, "answer": "autopistas de cuota", "latency_ms": 348.5560417175293, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4007}}}
{"qid": "1854655788853154951", "question": "unsaturated fats are comprised of lipids that contain", "gold_answers": ["at least one double bond", "double bond"], "shots": {"0": {"k": 0, "answer": "double bonds", "latency_ms": 226.51314735412598, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "double bonds", "latency_ms": 88.31000328063965, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "at least one double bond within the fatty acid chain", "latency_ms": 310.2130889892578, "em": 0.0, "f1": 0.7142857142857143, "containment": 1.0, "context_chars": 1320}, "3": {"k": 3, "answer": "at least one double bond within the fatty acid chain", "latency_ms": 471.4772701263428, "em": 0.0, "f1": 0.7142857142857143, "containment": 1.0, "context_chars": 2031}, "4": {"k": 4, "answer": "at least one double bond within the fatty acid chain", "latency_ms": 515.592098236084, "em": 0.0, "f1": 0.7142857142857143, "containment": 1.0, "context_chars": 2754}, "5": {"k": 5, "answer": "at least one double bond within the fatty acid chain", "latency_ms": 540.7910346984863, "em": 0.0, "f1": 0.7142857142857143, "containment": 1.0, "context_chars": 3420}, "6": {"k": 6, "answer": "double bonds", "latency_ms": 104.60209846496582, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4075}}}
{"qid": "-2015568298234613617", "question": "where did they film ghosts of girlfriends past", "gold_answers": ["Massachusetts"], "shots": {"0": {"k": 0, "answer": "Canada", "latency_ms": 41.15486145019531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ipswich, Massachusetts", "latency_ms": 93.81556510925293, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "Castle Hill (Ipswich, Massachusetts)", "latency_ms": 296.15092277526855, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1284}, "3": {"k": 3, "answer": "Castle Hill (Ipswich, Massachusetts)", "latency_ms": 226.77183151245117, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1858}, "4": {"k": 4, "answer": "Ipswich, Massachusetts", "latency_ms": 140.62833786010742, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2477}, "5": {"k": 5, "answer": "Castle Hill (Ipswich, Massachusetts)", "latency_ms": 473.308801651001, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3152}, "6": {"k": 6, "answer": "Ipswich, Massachusetts", "latency_ms": 262.4928951263428, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3793}}}
{"qid": "-5411612004022549496", "question": "when does a wrinkle in time come out in canada", "gold_answers": ["March 9 , 2018"], "shots": {"0": {"k": 0, "answer": "2003", "latency_ms": 196.60210609436035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 209.72847938537598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "March 9, 2018", "latency_ms": 222.31268882751465, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "March 9, 2018", "latency_ms": 445.9860324859619, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "March 9, 2018", "latency_ms": 333.9226245880127, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2537}, "5": {"k": 5, "answer": "March 9, 2018", "latency_ms": 337.1856212615967, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3136}, "6": {"k": 6, "answer": "March 9, 2018", "latency_ms": 696.8774795532227, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3782}}}
{"qid": "-8229490686742200210", "question": "who had created the second bank of the united states", "gold_answers": ["James Madison", "President James Madison"], "shots": {"0": {"k": 0, "answer": "Alexander Hamilton", "latency_ms": 217.09847450256348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "President James Madison", "latency_ms": 69.58532333374023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "President James Madison", "latency_ms": 232.3474884033203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1343}, "3": {"k": 3, "answer": "James Madison", "latency_ms": 301.03397369384766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2034}, "4": {"k": 4, "answer": "James Madison", "latency_ms": 242.80071258544922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2679}, "5": {"k": 5, "answer": "James Madison", "latency_ms": 186.35058403015137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3310}, "6": {"k": 6, "answer": "James Madison", "latency_ms": 162.09959983825684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3935}}}
{"qid": "3612945562446452821", "question": "when were 7 books removed from the bible", "gold_answers": ["1546"], "shots": {"0": {"k": 0, "answer": "16th century", "latency_ms": 307.77621269226074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 354.1679382324219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "1800s", "latency_ms": 296.8611717224121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "1800s", "latency_ms": 273.3120918273926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 170.24827003479004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2588}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 122.40409851074219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3194}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 244.04644966125488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3821}}}
{"qid": "-1286841988557529859", "question": "who plays voldemort in harry potter and the philosopher's stone", "gold_answers": ["Ian Hart", "Richard Bremmer"], "shots": {"0": {"k": 0, "answer": "Robert Pattinson", "latency_ms": 137.21013069152832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Richard Bremmer", "latency_ms": 276.0460376739502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "Richard Bremmer", "latency_ms": 277.7140140533447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Ralph Fiennes", "latency_ms": 163.85793685913086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Ian Hart", "latency_ms": 260.2095603942871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Ian Hart", "latency_ms": 103.75809669494629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3167}, "6": {"k": 6, "answer": "Ralph Fiennes", "latency_ms": 362.4234199523926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3845}}}
{"qid": "-3159460576929919105", "question": "when did the united states start using the death penalty", "gold_answers": ["1608", "the beginning"], "shots": {"0": {"k": 0, "answer": "1790", "latency_ms": 167.86575317382812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1608", "latency_ms": 274.28340911865234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "1608", "latency_ms": 120.05376815795898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1293}, "3": {"k": 3, "answer": "1608", "latency_ms": 191.84637069702148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1956}, "4": {"k": 4, "answer": "1608", "latency_ms": 321.5506076812744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2632}, "5": {"k": 5, "answer": "1608", "latency_ms": 307.5432777404785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3293}, "6": {"k": 6, "answer": "1608", "latency_ms": 171.80848121643066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "6975968195327799749", "question": "when is the last time the us lost the olympics", "gold_answers": ["2018 Pyeongchang"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 111.58633232116699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1956", "latency_ms": 131.3307285308838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 144.64664459228516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "1980", "latency_ms": 215.7294750213623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 173.74300956726074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "1980", "latency_ms": 332.6525688171387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3150}, "6": {"k": 6, "answer": "1980", "latency_ms": 149.20616149902344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3788}}}
{"qid": "-6747120392723244868", "question": "who has the most super bowls in nfl history", "gold_answers": ["The Pittsburgh Steelers", "Pittsburgh Steelers"], "shots": {"0": {"k": 0, "answer": "Pittsburgh Steelers", "latency_ms": 160.29691696166992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pittsburgh Steelers", "latency_ms": 147.98569679260254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "Pittsburgh Steelers", "latency_ms": 191.9267177581787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Pittsburgh Steelers", "latency_ms": 102.62560844421387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1876}, "4": {"k": 4, "answer": "Pittsburgh Steelers", "latency_ms": 140.55991172790527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2535}, "5": {"k": 5, "answer": "Pittsburgh Steelers", "latency_ms": 333.0056667327881, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3145}, "6": {"k": 6, "answer": "Pittsburgh Steelers", "latency_ms": 196.81549072265625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3814}}}
{"qid": "525023656480961403", "question": "when was the immigration act passed in canada", "gold_answers": ["1923"], "shots": {"0": {"k": 0, "answer": "1967", "latency_ms": 139.84155654907227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1976", "latency_ms": 262.71939277648926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "1869", "latency_ms": 320.12081146240234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "1869", "latency_ms": 257.7402591705322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "1869", "latency_ms": 255.70368766784668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2746}, "5": {"k": 5, "answer": "1869", "latency_ms": 283.1132411956787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3485}, "6": {"k": 6, "answer": "1869", "latency_ms": 373.443603515625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4119}}}
{"qid": "9001153795401557727", "question": "name the cell which is attached to the lateral side of sieve tube", "gold_answers": ["sieve tube elements"], "shots": {"0": {"k": 0, "answer": "Companion cell", "latency_ms": 131.6354274749756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "companion cells", "latency_ms": 132.51423835754395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "companion cells", "latency_ms": 358.55650901794434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "companion cell", "latency_ms": 253.35168838500977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "companion cell", "latency_ms": 247.36428260803223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2650}, "5": {"k": 5, "answer": "companion cell", "latency_ms": 182.43169784545898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3372}, "6": {"k": 6, "answer": "companion cell", "latency_ms": 305.70149421691895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3993}}}
{"qid": "5559492750970935173", "question": "where is final four being held this year", "gold_answers": ["the Alamodome"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 152.15229988098145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2021", "latency_ms": 261.3799571990967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "2021", "latency_ms": 240.5378818511963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1303}, "3": {"k": 3, "answer": "New Orleans", "latency_ms": 104.89630699157715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1968}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 196.03443145751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2562}, "5": {"k": 5, "answer": "2021", "latency_ms": 343.0144786834717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3212}, "6": {"k": 6, "answer": "2021", "latency_ms": 163.64002227783203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3838}}}
{"qid": "-7778542680482512904", "question": "symbolic interactionism is the basis for which theoretical model", "gold_answers": ["versions of Identity Theory", "role theory", "sociological"], "shots": {"0": {"k": 0, "answer": "symbolic interactionism", "latency_ms": 78.5667896270752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "symbolic interactionism", "latency_ms": 236.22441291809082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 743}, "2": {"k": 2, "answer": "symbolic interactionism", "latency_ms": 179.35609817504883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1548}, "3": {"k": 3, "answer": "symbolic interactionism", "latency_ms": 106.81009292602539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2248}, "4": {"k": 4, "answer": "symbolic interactionism", "latency_ms": 188.6603832244873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2945}, "5": {"k": 5, "answer": "role theory", "latency_ms": 205.33323287963867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3672}, "6": {"k": 6, "answer": "symbolic interactionism", "latency_ms": 149.4920253753662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4391}}}
{"qid": "-2996227699820227347", "question": "who wrote the french declaration of the rights of man and of the citizen", "gold_answers": ["General Lafayette", "Lafayette", "Thomas Jefferson", "Honoré Mirabeau"], "shots": {"0": {"k": 0, "answer": "Marie-Jean-Antoine Caritat, Comte de Condorcet", "latency_ms": 538.2835865020752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Abbé Sieyès and the Marquis de Lafayette", "latency_ms": 518.0494785308838, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Abbé Sieyès, Marquis de Lafayette, Thomas Jefferson, Honoré Mirabeau", "latency_ms": 684.2484474182129, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1313}, "3": {"k": 3, "answer": "Abbé Sieyès, Marquis de Lafayette, Thomas Jefferson, Honoré Mirabeau", "latency_ms": 577.0862102508545, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "Abbé Sieyès, Marquis de Lafayette, Thomas Jefferson", "latency_ms": 724.7118949890137, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2659}, "5": {"k": 5, "answer": "Abbé Sieyès, Marquis de Lafayette, Thomas Jefferson", "latency_ms": 459.991455078125, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3324}, "6": {"k": 6, "answer": "Abbé Sieyès, Marquis de Lafayette, Thomas Jefferson", "latency_ms": 605.3712368011475, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3975}}}
{"qid": "-2774109201029330685", "question": "who kidnapped ben in the deep end of the ocean", "gold_answers": ["celebrity alumna Cecil Lockhart", "Cecil Lockhart", "the celebrity alumna Cecil Lockhart"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 256.5269470214844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 217.7422046661377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 211.86327934265137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 149.62339401245117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1828}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 108.84881019592285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "mentally unstable woman who was a high school teacher", "latency_ms": 335.08777618408203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3051}, "6": {"k": 6, "answer": "Cecil Lockhart", "latency_ms": 344.96355056762695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3661}}}
{"qid": "4005166739248694798", "question": "who wrote hit me baby one more time", "gold_answers": ["Max Martin"], "shots": {"0": {"k": 0, "answer": "Nicki Minaj", "latency_ms": 105.19623756408691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 376.9381046295166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "Max Martin, Denniz Pop, and Rami Yacoub", "latency_ms": 525.8359909057617, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Max Martin", "latency_ms": 130.13696670532227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1814}, "4": {"k": 4, "answer": "Max Martin", "latency_ms": 151.36456489562988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2422}, "5": {"k": 5, "answer": "Max Martin", "latency_ms": 171.3430881500244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3009}, "6": {"k": 6, "answer": "Max Martin", "latency_ms": 305.9422969818115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3622}}}
{"qid": "-4952146393851562148", "question": "where did remember the titans camp take place", "gold_answers": ["Gettysburg College"], "shots": {"0": {"k": 0, "answer": "Virginia", "latency_ms": 111.8311882019043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gettysburg College", "latency_ms": 305.3162097930908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Gettysburg College", "latency_ms": 112.11633682250977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Gettysburg College", "latency_ms": 355.18455505371094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1900}, "4": {"k": 4, "answer": "Gettysburg College", "latency_ms": 275.10714530944824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2509}, "5": {"k": 5, "answer": "Gettysburg College", "latency_ms": 224.45082664489746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3194}, "6": {"k": 6, "answer": "Gettysburg College", "latency_ms": 354.42519187927246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3880}}}
{"qid": "6524766539964714821", "question": "who does the voice of amy on futurama", "gold_answers": ["Lauren Tom"], "shots": {"0": {"k": 0, "answer": "Tress MacNeille", "latency_ms": 309.8466396331787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lauren Tom", "latency_ms": 100.01468658447266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 644}, "2": {"k": 2, "answer": "Lauren Tom", "latency_ms": 84.84029769897461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1276}, "3": {"k": 3, "answer": "Lauren Tom", "latency_ms": 170.29237747192383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Lauren Tom", "latency_ms": 161.63015365600586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2564}, "5": {"k": 5, "answer": "Lauren Tom", "latency_ms": 306.61678314208984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3170}, "6": {"k": 6, "answer": "Lauren Tom", "latency_ms": 137.59231567382812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3780}}}
{"qid": "8214065994334584031", "question": "when does the next season of wynonna earp start", "gold_answers": ["2018", "January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "2024", "latency_ms": 254.61816787719727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2019", "latency_ms": 151.88217163085938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "2019", "latency_ms": 272.25565910339355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "2019", "latency_ms": 255.17725944519043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "2019", "latency_ms": 160.33554077148438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2446}, "5": {"k": 5, "answer": "2019", "latency_ms": 379.5335292816162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3012}, "6": {"k": 6, "answer": "2019", "latency_ms": 265.31982421875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3605}}}
{"qid": "7161580128369190804", "question": "when did the song push it come out", "gold_answers": ["1987", "March 8 , 1987"], "shots": {"0": {"k": 0, "answer": "1996", "latency_ms": 103.57880592346191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1987", "latency_ms": 194.25010681152344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 592}, "2": {"k": 2, "answer": "1987", "latency_ms": 196.79760932922363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1196}, "3": {"k": 3, "answer": "1987", "latency_ms": 213.01674842834473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1805}, "4": {"k": 4, "answer": "1987", "latency_ms": 144.49453353881836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2351}, "5": {"k": 5, "answer": "1987", "latency_ms": 220.45493125915527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2989}, "6": {"k": 6, "answer": "1987", "latency_ms": 210.7555866241455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3634}}}
{"qid": "8002956316753524206", "question": "who plays the coach in old spice commercial", "gold_answers": ["Isaiah Amir Mustafa"], "shots": {"0": {"k": 0, "answer": "Unser coach", "latency_ms": 122.47800827026367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Steven Ogg", "latency_ms": 117.2630786895752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "Terry Crews", "latency_ms": 105.8042049407959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 189.7721290588379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1991}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 183.6836338043213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2636}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 198.08268547058105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3283}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 152.79626846313477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4030}}}
{"qid": "-2824167725181792943", "question": "when does the good doctor episode 8 air", "gold_answers": ["November 20 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.42579078674316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 125.26965141296387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 183.29501152038574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 109.7872257232666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 161.51165962219238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 177.21319198608398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 143.36919784545898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3710}}}
{"qid": "-6777951254123103749", "question": "where does the movie road to perdition take place", "gold_answers": ["Chicago", "Rock Island , Illinois"], "shots": {"0": {"k": 0, "answer": "United States and Canada", "latency_ms": 78.3236026763916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chicago area", "latency_ms": 132.21025466918945, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "1931, during the Great Depression, in the Chicago area", "latency_ms": 437.02077865600586, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 1228}, "3": {"k": 3, "answer": "1931, during the Great Depression, in the Chicago area", "latency_ms": 257.7695846557617, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 1893}, "4": {"k": 4, "answer": "1931, during the Great Depression, in the Chicago area", "latency_ms": 456.9108486175537, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 2508}, "5": {"k": 5, "answer": "1931, during the Great Depression, in the Chicago area, Illinois", "latency_ms": 400.21634101867676, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3158}, "6": {"k": 6, "answer": "1931, during the Great Depression, in Chicago and Rock Island, Illinois", "latency_ms": 434.9637031555176, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3825}}}
{"qid": "4498859822735171754", "question": "when was the nobel prize for literature first awarded", "gold_answers": ["1901"], "shots": {"0": {"k": 0, "answer": "1901", "latency_ms": 102.24556922912598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1901", "latency_ms": 98.07872772216797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 631}, "2": {"k": 2, "answer": "1901", "latency_ms": 185.54425239562988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1283}, "3": {"k": 3, "answer": "1901", "latency_ms": 254.20761108398438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1974}, "4": {"k": 4, "answer": "1901", "latency_ms": 143.81933212280273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2591}, "5": {"k": 5, "answer": "1901", "latency_ms": 227.53643989562988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "1901", "latency_ms": 144.77205276489258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3884}}}
{"qid": "-5172636572480122331", "question": "when did the subway open in new york", "gold_answers": ["October 27 , 1904", "1904"], "shots": {"0": {"k": 0, "answer": "1904", "latency_ms": 328.4454345703125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 10, 1932", "latency_ms": 243.44110488891602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "September 10, 1932", "latency_ms": 323.5769271850586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "September 10, 1932", "latency_ms": 192.69561767578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1941}, "4": {"k": 4, "answer": "October 27, 1904", "latency_ms": 359.03310775756836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2585}, "5": {"k": 5, "answer": "October 27, 1904", "latency_ms": 237.82730102539062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3237}, "6": {"k": 6, "answer": "October 27, 1904", "latency_ms": 639.7101879119873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3896}}}
{"qid": "-2256325923186334832", "question": "who owns the four seasons hotel in las vegas", "gold_answers": ["MGM Resorts International"], "shots": {"0": {"k": 0, "answer": "Marriott International", "latency_ms": 132.65037536621094, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bill Gates and Prince Al-Waleed bin Talal", "latency_ms": 625.1962184906006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 97.77069091796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1357}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 275.43163299560547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "MGM Resorts International", "latency_ms": 196.10238075256348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Mandalay Bay owns the Four Seasons Hotel in Las Vegas.", "latency_ms": 432.34992027282715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3243}, "6": {"k": 6, "answer": "Four Seasons Hotel is independently operated within the Mandalay Bay tower, which is owned by MGM Resorts International. However, the Four Seasons Hotel in Las Vegas is not directly owned by MGM Resorts International. The Four Seasons Hotel in Las Vegas is operated independently by Four Seasons Hotels and Resorts. The ownership of the Four Seasons Hotel in Las Vegas is through Four Seasons Hotels and Resorts, which is jointly owned by Cascade Investment, Kingdom Holding Company, and Triples Holdings. Therefore, the owner is Four Seasons Hotels and Resorts.\n\nFour Seasons Hotels and Resorts", "latency_ms": 3009.593963623047, "em": 0.0, "f1": 0.06593406593406592, "containment": 1.0, "context_chars": 3883}}}
{"qid": "-2084810583025911065", "question": "what type of boundary was the mexico earthquake", "gold_answers": ["a subduction zone"], "shots": {"0": {"k": 0, "answer": "convergent boundary", "latency_ms": 101.6080379486084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "convergent boundary", "latency_ms": 118.08276176452637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "convergent boundary", "latency_ms": 144.0284252166748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "convergent boundary", "latency_ms": 339.0636444091797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2048}, "4": {"k": 4, "answer": "convergent boundary", "latency_ms": 208.20283889770508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2683}, "5": {"k": 5, "answer": "convergent boundary", "latency_ms": 130.21206855773926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3305}, "6": {"k": 6, "answer": "convergent boundary", "latency_ms": 170.8846092224121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3933}}}
{"qid": "4465854756996740675", "question": "who played michael jackson in jackson 5 movie", "gold_answers": ["Wylie Draper", "Abolade David Olatunde", "Jason Weaver", "Alex Burrall"], "shots": {"0": {"k": 0, "answer": "Jordan Fisher", "latency_ms": 167.6013469696045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 117.18344688415527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 98.5865592956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 295.66454887390137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 263.7312412261963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2542}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 173.62380027770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3261}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 303.4656047821045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "8964424634747238850", "question": "who stars in kevin probably save the world", "gold_answers": ["JoAnna Garcia Swisher", "India de Beaufort", "Chloe East", "Dustin Ybarra", "J. August Richards", "Jason Ritter", "Kimberly Hebert Gregory"], "shots": {"0": {"k": 0, "answer": "Kevin Hart", "latency_ms": 152.65679359436035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 265.3520107269287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "Cristela Alonzo, Kimberly Hebert Gregory", "latency_ms": 420.2449321746826, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 1317}, "3": {"k": 3, "answer": "Kevin (Probably) Saves the World stars Kevin (probably) Saves the World.", "latency_ms": 406.2161445617676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1985}, "4": {"k": 4, "answer": "Cristela Alonzo (initially), Kimberly Hebert Gregory (later)", "latency_ms": 991.0378456115723, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Cristela Alonzo (initially), Kimberly Hebert Gregory (later)", "latency_ms": 475.6448268890381, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3261}, "6": {"k": 6, "answer": "Cristela Alonzo (initially), Kimberly Hebert Gregory (later)", "latency_ms": 711.1997604370117, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3881}}}
{"qid": "2428016859746479878", "question": "how many grams of alcohol in one beer", "gold_answers": ["14 grams", "14", "about 14 grams of alcohol"], "shots": {"0": {"k": 0, "answer": "14 grams", "latency_ms": 190.80543518066406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 191.6494369506836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "15.2", "latency_ms": 171.60415649414062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1203}, "3": {"k": 3, "answer": "14", "latency_ms": 164.66569900512695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1792}, "4": {"k": 4, "answer": "15.2", "latency_ms": 114.94159698486328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2382}, "5": {"k": 5, "answer": "15.2", "latency_ms": 132.12943077087402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3027}, "6": {"k": 6, "answer": "15.2", "latency_ms": 280.55763244628906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3611}}}
{"qid": "8616078013378632610", "question": "who said that religion is the opiate of the masses", "gold_answers": ["Karl Marx .", "Karl Marx"], "shots": {"0": {"k": 0, "answer": "Karl Marx", "latency_ms": 123.45576286315918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Karl Marx", "latency_ms": 76.42769813537598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "Karl Marx", "latency_ms": 258.6069107055664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1325}, "3": {"k": 3, "answer": "Karl Marx", "latency_ms": 142.1194076538086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1961}, "4": {"k": 4, "answer": "Karl Marx", "latency_ms": 186.71774864196777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2668}, "5": {"k": 5, "answer": "Karl Marx", "latency_ms": 115.38410186767578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3295}, "6": {"k": 6, "answer": "Karl Marx", "latency_ms": 129.06789779663086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3905}}}
{"qid": "4333514272418210636", "question": "when was the us department of homeland security created", "gold_answers": ["November 25 , 2002"], "shots": {"0": {"k": 0, "answer": "2002", "latency_ms": 141.50094985961914, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "November 25, 2002", "latency_ms": 497.84135818481445, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 747}, "2": {"k": 2, "answer": "November 25, 2002", "latency_ms": 195.56379318237305, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1458}, "3": {"k": 3, "answer": "November 25, 2002", "latency_ms": 255.24091720581055, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2150}, "4": {"k": 4, "answer": "November 25, 2002", "latency_ms": 466.95590019226074, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2816}, "5": {"k": 5, "answer": "November 25, 2002", "latency_ms": 288.3772850036621, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3508}, "6": {"k": 6, "answer": "November 25, 2002", "latency_ms": 302.2885322570801, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4238}}}
{"qid": "6971297271942455076", "question": "in the texas legislature the house has members and the senate has", "gold_answers": ["31 - member Senate", "member"], "shots": {"0": {"k": 0, "answer": "members", "latency_ms": 65.73319435119629, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "31 members", "latency_ms": 83.7550163269043, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 607}, "2": {"k": 2, "answer": "150 and 31", "latency_ms": 245.3770637512207, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "150 and 31", "latency_ms": 310.06574630737305, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1876}, "4": {"k": 4, "answer": "150 members and 31 members", "latency_ms": 451.9467353820801, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 2517}, "5": {"k": 5, "answer": "150 members and 31 members", "latency_ms": 324.97429847717285, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "150 and 31", "latency_ms": 305.6633472442627, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3821}}}
{"qid": "-819500006477510416", "question": "who played marius in the movie les miserables", "gold_answers": ["Eddie Redmayne"], "shots": {"0": {"k": 0, "answer": "Hugh Jackman", "latency_ms": 61.15102767944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 191.16950035095215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 113.54684829711914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Eddie Redmayne", "latency_ms": 178.59697341918945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "Eddie Redmayne", "latency_ms": 292.3142910003662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2646}, "5": {"k": 5, "answer": "Eddie Redmayne", "latency_ms": 364.7611141204834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3306}, "6": {"k": 6, "answer": "Eddie Redmayne", "latency_ms": 207.56912231445312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3959}}}
{"qid": "-1495205296169772734", "question": "green algae is an example of which type of reproduction", "gold_answers": ["alternation of generations", "alternation of generations ."], "shots": {"0": {"k": 0, "answer": "asexual reproduction", "latency_ms": 91.70842170715332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 125.40173530578613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "conjugation", "latency_ms": 378.5691261291504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1342}, "3": {"k": 3, "answer": "sexual reproduction", "latency_ms": 86.4565372467041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2070}, "4": {"k": 4, "answer": "alternation of generations", "latency_ms": 114.49527740478516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2819}, "5": {"k": 5, "answer": "alternation of generations", "latency_ms": 203.72581481933594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3561}, "6": {"k": 6, "answer": "alternation of generations", "latency_ms": 357.26380348205566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4200}}}
{"qid": "7926179542568614934", "question": "the winner of the best actor award in the 64th national film festival 2017", "gold_answers": ["Akshay Kumar", "Manoj Joshi"], "shots": {"0": {"k": 0, "answer": "Rajkumar Hirani", "latency_ms": 269.55151557922363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 274.2919921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 714}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 267.03643798828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1337}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 202.7137279510498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1957}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 174.95107650756836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2597}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 261.6536617279053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3289}, "6": {"k": 6, "answer": "Akshay Kumar", "latency_ms": 146.8198299407959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3977}}}
{"qid": "721377602050579902", "question": "who won every men's biathlon event in the 2002 winter olympics", "gold_answers": ["Ole Einar Bjørndalen", "Norway"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 105.21054267883301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 166.94903373718262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 242.59090423583984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 169.13604736328125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 151.84807777404785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2650}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 220.8576202392578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3315}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 447.9944705963135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3966}}}
{"qid": "1742175800641553404", "question": "when did brent barry won the dunk contest", "gold_answers": ["1996"], "shots": {"0": {"k": 0, "answer": "1990", "latency_ms": 100.50034523010254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1996", "latency_ms": 105.62348365783691, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "1996", "latency_ms": 158.10155868530273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1198}, "3": {"k": 3, "answer": "1996", "latency_ms": 142.1191692352295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1780}, "4": {"k": 4, "answer": "1996", "latency_ms": 113.73329162597656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2368}, "5": {"k": 5, "answer": "1996", "latency_ms": 192.16489791870117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3029}, "6": {"k": 6, "answer": "1996", "latency_ms": 198.5626220703125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3674}}}
{"qid": "-5109121702669039643", "question": "when was the first orca put in captivity", "gold_answers": ["November 1961", "in the 1960s"], "shots": {"0": {"k": 0, "answer": "1911", "latency_ms": 285.07161140441895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1964", "latency_ms": 139.8301124572754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "November 1961", "latency_ms": 123.84176254272461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "November 1961", "latency_ms": 348.2484817504883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1971}, "4": {"k": 4, "answer": "November 1961", "latency_ms": 297.6949214935303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2612}, "5": {"k": 5, "answer": "1961", "latency_ms": 243.29829216003418, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "1961", "latency_ms": 185.46652793884277, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3851}}}
{"qid": "-962041795410987294", "question": "first day collection of mission china assamese film", "gold_answers": ["₹ 39.97 lakh"], "shots": {"0": {"k": 0, "answer": "100 crore", "latency_ms": 79.6043872833252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "39.97 lakh", "latency_ms": 257.648229598999, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "39.97 lakh", "latency_ms": 120.54252624511719, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "39.97 lakh", "latency_ms": 132.84945487976074, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "39.97 lakh", "latency_ms": 148.52499961853027, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2659}, "5": {"k": 5, "answer": "39.97 lakh", "latency_ms": 301.79309844970703, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3330}, "6": {"k": 6, "answer": "39.97 lakh", "latency_ms": 211.1215591430664, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3975}}}
{"qid": "-2968129491710503983", "question": "who are the co hosts on the real", "gold_answers": ["Jeannie Mai", "Tamera Mowry - Housley", "Tamar Braxton", "Loni Love", "Adrienne Houghton"], "shots": {"0": {"k": 0, "answer": "Chris Harrison and Jennifer Lopez", "latency_ms": 111.77706718444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 193.50361824035645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 129.63366508483887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 195.6491470336914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 185.52589416503906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 130.74493408203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3245}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 239.90464210510254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3932}}}
{"qid": "2577505384728133630", "question": "who is the longest serving chief minister in india as on jan 2015", "gold_answers": ["Jyotirindra Basu"], "shots": {"0": {"k": 0, "answer": "Chandra Shekhar (as on Jan 2015, though not correct; correct answer is: **N. Chandrababu Naidu** — longest serving as of Jan 2015 in a state, but not national; actual longest-serving Chief Minister in India as of Jan 2015 is **K. Karunakaran** — no, incorrect)\n\nCorrect answer: **Chandra Shekhar** — no, he was a PM.\n\nCorrect answer: **N. Chandrababu Naidu** — served multiple terms in Andhra Pradesh.\n\nBut the longest-serving Chief Minister in India as of January 2015 is:\n\n**K. Karunakaran** — no.\n\nActually, the longest-serving Chief Minister in India as of January 2015 is:\n\n**M. Karunanidhi** — served multiple terms in Tamil Nadu.\n\nFinal correct answer: **M. Karunanidhi** — yes, he was the longest-serving Chief Minister in India as of January 2015.\n\nAnswer: **M. Karunanidhi**", "latency_ms": 7087.346315383911, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sheila Dikshit", "latency_ms": 290.8637523651123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Sheila Dikshit", "latency_ms": 287.7459526062012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Sheila Dikshit", "latency_ms": 250.24938583374023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "Sheila Dikshit", "latency_ms": 495.9673881530762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2560}, "5": {"k": 5, "answer": "Sheila Dikshit", "latency_ms": 190.17887115478516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3166}, "6": {"k": 6, "answer": "Atal Bihari Vajpayee", "latency_ms": 325.6244659423828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3832}}}
{"qid": "-2861358222688121748", "question": "most runs ever scored in a mlb inning", "gold_answers": ["18"], "shots": {"0": {"k": 0, "answer": "25", "latency_ms": 93.36018562316895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "18", "latency_ms": 100.50082206726074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "18", "latency_ms": 112.34831809997559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1156}, "3": {"k": 3, "answer": "18", "latency_ms": 107.16438293457031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1731}, "4": {"k": 4, "answer": "18", "latency_ms": 112.19048500061035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2333}, "5": {"k": 5, "answer": "18", "latency_ms": 229.11858558654785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2897}, "6": {"k": 6, "answer": "18", "latency_ms": 157.54413604736328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3479}}}
{"qid": "1624012912518696153", "question": "who brought the idea of castles to england", "gold_answers": ["Norman invaders"], "shots": {"0": {"k": 0, "answer": "William the Conqueror", "latency_ms": 515.756368637085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "William the Conqueror", "latency_ms": 239.1676902770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "Normans", "latency_ms": 93.36376190185547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1296}, "3": {"k": 3, "answer": "Norman invaders", "latency_ms": 244.33422088623047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2028}, "4": {"k": 4, "answer": "William the Conqueror", "latency_ms": 349.7166633605957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2620}, "5": {"k": 5, "answer": "Normans", "latency_ms": 202.76165008544922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3289}, "6": {"k": 6, "answer": "Normans", "latency_ms": 217.6799774169922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3905}}}
{"qid": "2048375334691290812", "question": "what were the two causes of the dust bowl", "gold_answers": ["severe drought"], "shots": {"0": {"k": 0, "answer": "Dry climate, poor farming practices", "latency_ms": 208.67919921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "severe drought and failure to apply dryland farming methods", "latency_ms": 426.2070655822754, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "drought and poor farming practices", "latency_ms": 254.02092933654785, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "severe drought and failure to apply dryland farming methods", "latency_ms": 322.6039409637451, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "severe drought and poor farming practices", "latency_ms": 319.19360160827637, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2494}, "5": {"k": 5, "answer": "severe drought and poor farming practices", "latency_ms": 238.00158500671387, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3191}, "6": {"k": 6, "answer": "severe drought and poor farming practices", "latency_ms": 329.3778896331787, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3774}}}
{"qid": "-3239096899891702759", "question": "who becomes chief resident on grey's anatomy season 7", "gold_answers": ["Kepner", "April Kepner M.D."], "shots": {"0": {"k": 0, "answer": "Alex Karev", "latency_ms": 112.78367042541504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "April Kepner", "latency_ms": 153.54537963867188, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "April Kepner", "latency_ms": 110.28504371643066, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1228}, "3": {"k": 3, "answer": "April Kepner", "latency_ms": 164.5069122314453, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1959}, "4": {"k": 4, "answer": "April Kepner", "latency_ms": 166.3339138031006, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2608}, "5": {"k": 5, "answer": "April Kepner", "latency_ms": 200.03652572631836, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3297}, "6": {"k": 6, "answer": "April Kepner", "latency_ms": 304.0025234222412, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3946}}}
{"qid": "-1052450681419062019", "question": "who has won the 2017 mens singles mutua madrid open tennis", "gold_answers": ["Rafael Nadal"], "shots": {"0": {"k": 0, "answer": "Novak Djokovic", "latency_ms": 126.99270248413086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 90.32940864562988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 121.12808227539062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 184.01312828063965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1788}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 245.80907821655273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2421}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 235.87536811828613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3050}, "6": {"k": 6, "answer": "Rafael Nadal", "latency_ms": 249.50504302978516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3680}}}
{"qid": "1122374124159656329", "question": "who plays the dad in drake and josh", "gold_answers": ["Jonathan Goldstein"], "shots": {"0": {"k": 0, "answer": "Jerry O'Connell", "latency_ms": 345.55578231811523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Josh Peck", "latency_ms": 130.33103942871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "Josh Peck", "latency_ms": 279.73389625549316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Josh Peck", "latency_ms": 192.8715705871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 207.59057998657227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 321.14124298095703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3176}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 374.544620513916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3775}}}
{"qid": "-7607131122991447947", "question": "in which country were the two battles of el alamein fought", "gold_answers": ["Egypt"], "shots": {"0": {"k": 0, "answer": "Egypt", "latency_ms": 75.15692710876465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Egypt", "latency_ms": 114.0432357788086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Egypt", "latency_ms": 88.03081512451172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1255}, "3": {"k": 3, "answer": "Egypt", "latency_ms": 144.2098617553711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1889}, "4": {"k": 4, "answer": "Egypt", "latency_ms": 75.99472999572754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2504}, "5": {"k": 5, "answer": "Egypt", "latency_ms": 148.726224899292, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Egypt", "latency_ms": 93.83225440979004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3734}}}
{"qid": "1917917794187892676", "question": "who gets the most punishments on impractical jokers", "gold_answers": ["Sal"], "shots": {"0": {"k": 0, "answer": "Drew", "latency_ms": 53.661346435546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 206.3758373260498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 274.91164207458496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 134.66215133666992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 348.33478927612305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2520}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 192.5487518310547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3126}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 306.72335624694824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3734}}}
{"qid": "-4933703924077588548", "question": "baga beach is in north or south goa", "gold_answers": ["North", "North Goa"], "shots": {"0": {"k": 0, "answer": "South Goa", "latency_ms": 83.42766761779785, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "north", "latency_ms": 45.92275619506836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 572}, "2": {"k": 2, "answer": "North Goa", "latency_ms": 108.01196098327637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1164}, "3": {"k": 3, "answer": "North Goa", "latency_ms": 153.17392349243164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1791}, "4": {"k": 4, "answer": "North Goa", "latency_ms": 133.76569747924805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2375}, "5": {"k": 5, "answer": "North Goa", "latency_ms": 321.31266593933105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3021}, "6": {"k": 6, "answer": "North Goa", "latency_ms": 109.33661460876465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3622}}}
{"qid": "6933510789136260390", "question": "when was the first case of alzheimer's diagnosed", "gold_answers": ["1901"], "shots": {"0": {"k": 0, "answer": "1906", "latency_ms": 167.1273708343506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1906", "latency_ms": 132.9636573791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "1906", "latency_ms": 249.86720085144043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "1906", "latency_ms": 190.20342826843262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1899}, "4": {"k": 4, "answer": "1907", "latency_ms": 128.1280517578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": "1906", "latency_ms": 277.7862548828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3290}, "6": {"k": 6, "answer": "1906", "latency_ms": 143.64862442016602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4032}}}
{"qid": "3595629551292543052", "question": "who wrote the theme to last of the mohicans", "gold_answers": ["Dougie MacLean"], "shots": {"0": {"k": 0, "answer": "James Horner", "latency_ms": 79.86760139465332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Trevor Jones", "latency_ms": 328.2928466796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "Dougie MacLean", "latency_ms": 302.83141136169434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "Dougie MacLean", "latency_ms": 314.8963451385498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1942}, "4": {"k": 4, "answer": "Dougie MacLean", "latency_ms": 104.9959659576416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Dougie MacLean", "latency_ms": 273.42700958251953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3218}, "6": {"k": 6, "answer": "Dougie MacLean", "latency_ms": 227.21338272094727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3863}}}
{"qid": "-4804889058718384357", "question": "who was the german leader who signed the treaty of versailles", "gold_answers": ["President Friedrich Ebert", "Gustav Bauer"], "shots": {"0": {"k": 0, "answer": "Wilhelm Cuno", "latency_ms": 179.8567771911621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "German leadership as a whole signed the Treaty of Versailles; no single individual is specified in the context. I cannot answer.", "latency_ms": 808.3293437957764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Gustav Bauer", "latency_ms": 213.96207809448242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1270}, "3": {"k": 3, "answer": "Gustav Bauer", "latency_ms": 183.43305587768555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1958}, "4": {"k": 4, "answer": "Gustav Bauer", "latency_ms": 318.3412551879883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2630}, "5": {"k": 5, "answer": "Matthias Erzberger", "latency_ms": 457.3204517364502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3278}, "6": {"k": 6, "answer": "Gustav Bauer", "latency_ms": 310.960054397583, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3887}}}
{"qid": "6722449797327374201", "question": "where is fight or flight in the brain", "gold_answers": ["the adrenal medulla"], "shots": {"0": {"k": 0, "answer": "amygdala", "latency_ms": 149.21069145202637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hypothalamus", "latency_ms": 188.61126899719238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "hypothalamus, amygdalae, brainstem", "latency_ms": 510.2970600128174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1333}, "3": {"k": 3, "answer": "hypothalamus, amygdalae, brainstem", "latency_ms": 515.9904956817627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2016}, "4": {"k": 4, "answer": "hypothalamus, amygdalae, brainstem", "latency_ms": 279.66976165771484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2672}, "5": {"k": 5, "answer": "hypothalamus, amygdala, brainstem", "latency_ms": 383.6712837219238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3393}, "6": {"k": 6, "answer": "hypothalamus, amygdala, limbic system", "latency_ms": 240.8292293548584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4026}}}
{"qid": "8409182335460652649", "question": "who played stonewall jackson in gods and generals", "gold_answers": ["Stephen Lang"], "shots": {"0": {"k": 0, "answer": "Dennis Quaid", "latency_ms": 129.39763069152832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 321.4404582977295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "Stephen Lang", "latency_ms": 132.52830505371094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Stephen Lang", "latency_ms": 149.90901947021484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1952}, "4": {"k": 4, "answer": "Stephen Lang", "latency_ms": 320.76478004455566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2544}, "5": {"k": 5, "answer": "Stephen Lang", "latency_ms": 167.27876663208008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3164}, "6": {"k": 6, "answer": "Stephen Lang", "latency_ms": 388.9729976654053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3803}}}
{"qid": "8129226506978989056", "question": "where does the phrase dressed to the nines", "gold_answers": ["Scots in origin"], "shots": {"0": {"k": 0, "answer": "means wearing something very fancy or elaborate.", "latency_ms": 533.2646369934082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Scots origin", "latency_ms": 80.1689624786377, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Scots origin", "latency_ms": 123.27933311462402, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "Scots origin", "latency_ms": 119.51923370361328, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "Scots origin", "latency_ms": 111.4664077758789, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "Scots origin", "latency_ms": 330.90972900390625, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3048}, "6": {"k": 6, "answer": "Scots origin", "latency_ms": 197.20458984375, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3667}}}
{"qid": "-2154275263565518616", "question": "what color is the golden gate bridge in san francisco", "gold_answers": ["International Orange", "red", "orange vermilion called international orange"], "shots": {"0": {"k": 0, "answer": "Golden yellow", "latency_ms": 271.2886333465576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Orange", "latency_ms": 40.85993766784668, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "international orange", "latency_ms": 292.73319244384766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1303}, "3": {"k": 3, "answer": "international orange", "latency_ms": 98.88386726379395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1911}, "4": {"k": 4, "answer": "international orange", "latency_ms": 122.53499031066895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2568}, "5": {"k": 5, "answer": "international orange", "latency_ms": 121.57893180847168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3194}, "6": {"k": 6, "answer": "international orange", "latency_ms": 252.0425319671631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3828}}}
{"qid": "7037852711673324115", "question": "what type of car is a g wagon", "gold_answers": ["Mercedes - Benz"], "shots": {"0": {"k": 0, "answer": "Volkswagen Touareg", "latency_ms": 95.60036659240723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "G-Class", "latency_ms": 85.13665199279785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 726}, "2": {"k": 2, "answer": "G 500 wagon", "latency_ms": 245.97406387329102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "G-Class SUV", "latency_ms": 232.79094696044922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2051}, "4": {"k": 4, "answer": "mid-size four-wheel drive luxury SUV", "latency_ms": 196.88916206359863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2717}, "5": {"k": 5, "answer": "G-Class luxury SUV", "latency_ms": 150.72917938232422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3410}, "6": {"k": 6, "answer": "G-Wagen (cross country vehicle)", "latency_ms": 303.0245304107666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4078}}}
{"qid": "7732412227546021398", "question": "who sings angel of the morning in deadpool", "gold_answers": ["Juice Newton", "Juice Newton 's"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 90.22307395935059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Peter Griffin", "latency_ms": 122.70975112915039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Juice Newton", "latency_ms": 185.7924461364746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1284}, "3": {"k": 3, "answer": "Juice Newton", "latency_ms": 168.49136352539062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Juice Newton", "latency_ms": 148.6837863922119, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2536}, "5": {"k": 5, "answer": "Juice Newton", "latency_ms": 315.6411647796631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3167}, "6": {"k": 6, "answer": "Juice Newton", "latency_ms": 326.16543769836426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3807}}}
{"qid": "-6068529343782396685", "question": "who did kenny rogers sing mary did you know with", "gold_answers": ["Wynonna Judd"], "shots": {"0": {"k": 0, "answer": "Dolly Parton", "latency_ms": 171.5688705444336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wynonna Judd", "latency_ms": 151.17263793945312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "Wynonna Judd", "latency_ms": 188.51613998413086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Wynonna Judd", "latency_ms": 216.48693084716797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Wynonna Judd", "latency_ms": 271.24977111816406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Wynonna Judd", "latency_ms": 252.12430953979492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3224}, "6": {"k": 6, "answer": "Wynonna Judd", "latency_ms": 250.5793571472168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3827}}}
{"qid": "-7070472892925791621", "question": "when is the new series of keeping faith starting", "gold_answers": ["13 February 2018"], "shots": {"0": {"k": 0, "answer": "2023", "latency_ms": 173.0823516845703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "autumn 2018", "latency_ms": 297.7747917175293, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "this autumn", "latency_ms": 217.1611785888672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "autumn 2018", "latency_ms": 314.44835662841797, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "10 July 2018", "latency_ms": 204.423189163208, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2489}, "5": {"k": 5, "answer": "10 July 2018", "latency_ms": 342.1955108642578, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3105}, "6": {"k": 6, "answer": "10 July 2018", "latency_ms": 290.114164352417, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3777}}}
{"qid": "-7951194946868878283", "question": "how many seasons of ray donovan has there been", "gold_answers": ["5"], "shots": {"0": {"k": 0, "answer": "4", "latency_ms": 40.24505615234375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.25867080688477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 98.01340103149414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 288.2993221282959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1833}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 130.82051277160645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2502}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 203.59444618225098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3136}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 391.95752143859863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3779}}}
{"qid": "-7843232313103404498", "question": "what was the united states foreign policy after ww1 started", "gold_answers": ["neutrality"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 390.655517578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neutrality", "latency_ms": 179.42285537719727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 677}, "2": {"k": 2, "answer": "neutrality", "latency_ms": 301.44524574279785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1328}, "3": {"k": 3, "answer": "neutrality", "latency_ms": 101.0887622833252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1975}, "4": {"k": 4, "answer": "neutrality, but with strong support for Britain and China under Roosevelt", "latency_ms": 534.8126888275146, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 2666}, "5": {"k": 5, "answer": "neutrality", "latency_ms": 298.9778518676758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3394}, "6": {"k": 6, "answer": "neutrality, but with strong support for Britain and China under Roosevelt", "latency_ms": 433.6259365081787, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 4015}}}
{"qid": "-8491993331568056625", "question": "when did world war 2 end in the pacific", "gold_answers": ["14 and 15 August 1945", "September 2 , 1945"], "shots": {"0": {"k": 0, "answer": "September 2, 1945", "latency_ms": 477.3092269897461, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "14 and 15 August 1945", "latency_ms": 233.107328414917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 588}, "2": {"k": 2, "answer": "14 and 15 August 1945", "latency_ms": 599.689245223999, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1177}, "3": {"k": 3, "answer": "14 August 1945", "latency_ms": 350.0490188598633, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 1797}, "4": {"k": 4, "answer": "15 August 1945", "latency_ms": 405.0271511077881, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 2507}, "5": {"k": 5, "answer": "15 August 1945", "latency_ms": 171.72837257385254, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 3122}, "6": {"k": 6, "answer": "15 August 1945", "latency_ms": 346.3549613952637, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 3718}}}
{"qid": "-6281263110946016384", "question": "how many seasons of vampire diaries r there", "gold_answers": ["eight", "8"], "shots": {"0": {"k": 0, "answer": "8", "latency_ms": 107.14173316955566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "8", "latency_ms": 47.16777801513672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 628}, "2": {"k": 2, "answer": "8", "latency_ms": 57.76572227478027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1258}, "3": {"k": 3, "answer": "8", "latency_ms": 167.16647148132324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1894}, "4": {"k": 4, "answer": "8", "latency_ms": 255.1581859588623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2532}, "5": {"k": 5, "answer": "8", "latency_ms": 93.82200241088867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3118}, "6": {"k": 6, "answer": "8", "latency_ms": 181.06365203857422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3757}}}
{"qid": "-794776326007094837", "question": "what is the legal age for marriage in australia", "gold_answers": ["18"], "shots": {"0": {"k": 0, "answer": "18 years", "latency_ms": 103.99961471557617, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 165.1599407196045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "16 years old (with court authorisation)", "latency_ms": 172.26743698120117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "16 years old", "latency_ms": 180.34124374389648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "18 years", "latency_ms": 259.052038192749, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2542}, "5": {"k": 5, "answer": "18 years", "latency_ms": 165.22860527038574, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3160}, "6": {"k": 6, "answer": "18 years", "latency_ms": 227.1742820739746, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3756}}}
{"qid": "-525942396749510966", "question": "who played doctor smith in lost in space", "gold_answers": ["Jonathan Harris"], "shots": {"0": {"k": 0, "answer": "Raymond A. Palmer", "latency_ms": 207.0600986480713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jonathan Harris", "latency_ms": 81.90250396728516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Jonathan Harris", "latency_ms": 184.04245376586914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Parker Posey", "latency_ms": 235.28766632080078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1976}, "4": {"k": 4, "answer": "Jonathan Harris", "latency_ms": 173.8741397857666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Jonathan Harris", "latency_ms": 155.81083297729492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3255}, "6": {"k": 6, "answer": "Jonathan Harris", "latency_ms": 200.23345947265625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3883}}}
{"qid": "-693976483726807411", "question": "when does jo come in grey's anatomy", "gold_answers": ["2012", "July 2012", "season 9"], "shots": {"0": {"k": 0, "answer": "Season 13, Episode 10 \"The One with the Fake Heart\"", "latency_ms": 704.6246528625488, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "February 10, 2017", "latency_ms": 504.1658878326416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 681}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 145.13707160949707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "February 10, 2017", "latency_ms": 354.9797534942627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1885}, "4": {"k": 4, "answer": "season 9", "latency_ms": 121.43754959106445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2532}, "5": {"k": 5, "answer": "season 9", "latency_ms": 123.80743026733398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3168}, "6": {"k": 6, "answer": "season 9", "latency_ms": 126.3279914855957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3820}}}
{"qid": "-449556917090943542", "question": "what is the most common cause of right ventricular heart failure", "gold_answers": ["pulmonary heart disease", "left - sided heart failure"], "shots": {"0": {"k": 0, "answer": "Pulmonary hypertension", "latency_ms": 100.31700134277344, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "pulmonary heart disease (cor pulmonale)", "latency_ms": 257.82299041748047, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 748}, "2": {"k": 2, "answer": "pulmonary heart disease (cor pulmonale)", "latency_ms": 178.80702018737793, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 1453}, "3": {"k": 3, "answer": "left-sided heart failure", "latency_ms": 120.28217315673828, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2104}, "4": {"k": 4, "answer": "left-sided heart failure", "latency_ms": 213.00864219665527, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2776}, "5": {"k": 5, "answer": "left-sided heart failure", "latency_ms": 126.04737281799316, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3513}, "6": {"k": 6, "answer": "left-sided heart failure", "latency_ms": 127.41303443908691, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 4282}}}
{"qid": "-7709514949207095031", "question": "what are the four requirements to establish criminal liability for gross negligence manslaughter", "gold_answers": ["the defendant breached this duty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 143.89538764953613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "duty of care, breach of duty, risk of death, obvious to reasonable prudent person", "latency_ms": 511.3255977630615, "em": 0.0, "f1": 0.11111111111111112, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "four stage Adomako Test", "latency_ms": 357.5093746185303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "four stage Adomako Test", "latency_ms": 163.6362075805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1929}, "4": {"k": 4, "answer": "four stage Adomako Test", "latency_ms": 162.3055934906006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2630}, "5": {"k": 5, "answer": "duty of care, breach of that duty, risk of death obvious to a reasonable prudent person, reprehensible breach of duty care", "latency_ms": 668.1959629058838, "em": 0.0, "f1": 0.08333333333333334, "containment": 0.0, "context_chars": 3321}, "6": {"k": 6, "answer": "four stage Adomako Test", "latency_ms": 298.44069480895996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3960}}}
{"qid": "7397542791834822732", "question": "why dry ether is used in woods reaction", "gold_answers": ["to form a higher alkane"], "shots": {"0": {"k": 0, "answer": "To avoid moisture and side reactions", "latency_ms": 327.06165313720703, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 113.75689506530762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 114.65287208557129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "to prevent peroxide formation", "latency_ms": 227.59246826171875, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 133.97932052612305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2596}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 183.9618682861328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 154.48665618896484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3789}}}
{"qid": "3384693042822879189", "question": "where was the new pete's dragon filmed", "gold_answers": ["New Zealand"], "shots": {"0": {"k": 0, "answer": "California", "latency_ms": 63.94076347351074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bay of Plenty, Taupo, Wellington, Rotorua, Tapanui", "latency_ms": 242.71726608276367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "Bay of Plenty, Taupo, Wellington, Rotorua, Tapanui", "latency_ms": 378.1294822692871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Bay of Plenty, Taupo, Wellington, Rotorua, Tapanui", "latency_ms": 362.3015880584717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Bay of Plenty, Taupo, Wellington, Rotorua, Tapanui", "latency_ms": 380.8608055114746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2450}, "5": {"k": 5, "answer": "Bay of Plenty, Taupo, Wellington, Rotorua, Tapanui", "latency_ms": 411.776065826416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3099}, "6": {"k": 6, "answer": "Bay of Plenty, Taupo, Wellington, Rotorua, Tapanui", "latency_ms": 726.2153625488281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "-6818895183782666995", "question": "is it marley and me or marley and i", "gold_answers": ["Marley & Me"], "shots": {"0": {"k": 0, "answer": "Marley and Me", "latency_ms": 164.63232040405273, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 240.1559352874756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 98.40726852416992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Marley and I", "latency_ms": 171.27037048339844, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1887}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 231.23908042907715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2505}, "5": {"k": 5, "answer": "Marley and I", "latency_ms": 341.7961597442627, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 323.90475273132324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-6142762219955413493", "question": "where was a hologram for the king filmed", "gold_answers": ["Egypt", "Berlin", "Berlin and Düsseldorf in Germany", "Morocco", "Düsseldorf in Germany", "Hurghada in Egypt", "Germany"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 163.70058059692383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Morocco, Hurghada, Egypt, Berlin, Düsseldorf, Germany", "latency_ms": 315.0601387023926, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 661}, "2": {"k": 2, "answer": "Morocco, Hurghada in Egypt, Berlin, Düsseldorf in Germany", "latency_ms": 310.819149017334, "em": 0.0, "f1": 0.6153846153846154, "containment": 1.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Morocco, Hurghada (Egypt), Berlin, Düsseldorf (Germany)", "latency_ms": 521.6798782348633, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 1959}, "4": {"k": 4, "answer": "Morocco, Hurghada in Egypt, Berlin, Düsseldorf in Germany", "latency_ms": 519.7310447692871, "em": 0.0, "f1": 0.6153846153846154, "containment": 1.0, "context_chars": 2569}, "5": {"k": 5, "answer": "Morocco, Hurghada (Egypt), Berlin, Düsseldorf (Germany)", "latency_ms": 426.76568031311035, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3158}, "6": {"k": 6, "answer": "Morocco, Hurghada, Egypt, Berlin, Düsseldorf, Germany", "latency_ms": 355.5612564086914, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3742}}}
{"qid": "-1212091124373260265", "question": "who inaugurated 'world teachers' day'", "gold_answers": ["ILO", "UNESCO"], "shots": {"0": {"k": 0, "answer": "UNESCO", "latency_ms": 171.16904258728027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNESCO/ILO", "latency_ms": 273.09322357177734, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 726}, "2": {"k": 2, "answer": "UNESCO/ILO", "latency_ms": 160.03990173339844, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1431}, "3": {"k": 3, "answer": "UNESCO/ILO", "latency_ms": 116.39046669006348, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2115}, "4": {"k": 4, "answer": "UNESCO/ILO", "latency_ms": 113.29936981201172, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2801}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 199.20587539672852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3485}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 220.64566612243652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4091}}}
{"qid": "6402415816213721626", "question": "what kind of animals live in the great victoria desert", "gold_answers": ["sand goanna", "malleefowl", "perentie", "great desert skink", "chestnut - breasted whiteface", "southern marsupial mole", "sandhill dunnart", "dingo", "water - holding frog", "crest - tailed mulgara"], "shots": {"0": {"k": 0, "answer": "Marsupials, reptiles, and birds", "latency_ms": 314.9549961090088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "frogs, birds, dingos, perentie, sand goanna", "latency_ms": 570.7211494445801, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 709}, "2": {"k": 2, "answer": "frogs, birds, predators (dingo, monitor lizards), lizards (great desert skink, Central Ranges taipan), small marsupials (sandhill dunnart, crest-tailed mulgara), southern marsupial mole", "latency_ms": 1181.2756061553955, "em": 0.0, "f1": 0.24000000000000005, "containment": 1.0, "context_chars": 1483}, "3": {"k": 3, "answer": "frogs, birds, lizards, marsupials, dingo, monitor lizards, southern marsupial mole", "latency_ms": 788.898229598999, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2135}, "4": {"k": 4, "answer": "frogs, birds (chestnut-breasted whiteface, malleefowl), dingoes, perentie, sand goanna, lizards (great desert skink, Central Ranges taipan), small marsupials (sandhill dunnart, crest-tailed mulgara), southern marsupial mole", "latency_ms": 1870.100498199463, "em": 0.0, "f1": 0.21428571428571425, "containment": 1.0, "context_chars": 2847}, "5": {"k": 5, "answer": "frogs, birds, dingo, perentie, sand goanna, great desert skink, Central Ranges taipan, sandhill dunnart, crest-tailed mulgara, southern marsupial mole", "latency_ms": 1332.5672149658203, "em": 0.0, "f1": 0.2727272727272727, "containment": 1.0, "context_chars": 3513}, "6": {"k": 6, "answer": "frogs, birds (chestnut-breasted whiteface, malleefowl), dingoes, perentie, sand goanna, great desert skink, Central Ranges taipan, sandhill dunnart, crest-tailed mulgara, southern marsupial mole", "latency_ms": 1427.5312423706055, "em": 0.0, "f1": 0.24000000000000005, "containment": 1.0, "context_chars": 4206}}}
{"qid": "2570826170217451399", "question": "what is the oath that new citizens take", "gold_answers": ["United States Oath of Allegiance"], "shots": {"0": {"k": 0, "answer": "Oath of Allegiance", "latency_ms": 232.10978507995605, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Oath of Citizenship", "latency_ms": 166.7001247406006, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Oath of citizenship", "latency_ms": 91.4924144744873, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "Oath of Allegiance", "latency_ms": 121.8407154083252, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Oath of Allegiance", "latency_ms": 387.3751163482666, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 2568}, "5": {"k": 5, "answer": "Oath of Allegiance", "latency_ms": 166.3532257080078, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Oath of Allegiance", "latency_ms": 244.70186233520508, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 3831}}}
{"qid": "-2325138904790635180", "question": "active absorption of water from the soil by the root is mainly affected by", "gold_answers": ["ATP", "SURFACE AREA OF ROOTS"], "shots": {"0": {"k": 0, "answer": "root pressure", "latency_ms": 67.00944900512695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ATP", "latency_ms": 82.25822448730469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 652}, "2": {"k": 2, "answer": "D.P.D. (suction pressure)", "latency_ms": 211.73858642578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1314}, "3": {"k": 3, "answer": "solute concentration and water potential gradient", "latency_ms": 148.38743209838867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1946}, "4": {"k": 4, "answer": "solute concentration and water potential gradient", "latency_ms": 209.0606689453125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2622}, "5": {"k": 5, "answer": "energy from respiration", "latency_ms": 198.1806755065918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3303}, "6": {"k": 6, "answer": "water potential gradient", "latency_ms": 300.62079429626465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3983}}}
{"qid": "2499410242916851494", "question": "eukaryotes have how many origins of dna replication", "gold_answers": ["up to 100,000"], "shots": {"0": {"k": 0, "answer": "multiple", "latency_ms": 70.62673568725586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "one thousand", "latency_ms": 66.7266845703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 681}, "2": {"k": 2, "answer": "one thousand", "latency_ms": 72.9990005493164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1402}, "3": {"k": 3, "answer": "one thousand", "latency_ms": 82.78155326843262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2055}, "4": {"k": 4, "answer": "one thousand", "latency_ms": 132.58790969848633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2762}, "5": {"k": 5, "answer": "one thousand", "latency_ms": 126.4183521270752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3451}, "6": {"k": 6, "answer": "one thousand or more", "latency_ms": 154.2508602142334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4128}}}
{"qid": "-873221229677720991", "question": "who played tom hagon in the godfather series", "gold_answers": ["Robert Duvall"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 198.7473964691162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 108.95824432373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "Robert Duvall", "latency_ms": 134.05847549438477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1323}, "3": {"k": 3, "answer": "Robert Duvall", "latency_ms": 185.07647514343262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1994}, "4": {"k": 4, "answer": "Robert Duvall", "latency_ms": 333.179235458374, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Robert Duvall", "latency_ms": 160.6886386871338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3310}, "6": {"k": 6, "answer": "Robert Duvall", "latency_ms": 220.66926956176758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3913}}}
{"qid": "8562240844982075116", "question": "where are alkali metals located on the periodic table", "gold_answers": ["group 1", "in the s - block"], "shots": {"0": {"k": 0, "answer": "Group 1", "latency_ms": 147.99165725708008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "s-block", "latency_ms": 134.30333137512207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 688}, "2": {"k": 2, "answer": "s-block, group 1", "latency_ms": 176.22661590576172, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1330}, "3": {"k": 3, "answer": "Group 1", "latency_ms": 423.473596572876, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1974}, "4": {"k": 4, "answer": "Group 1", "latency_ms": 165.787935256958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2608}, "5": {"k": 5, "answer": "Group 1", "latency_ms": 286.2379550933838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3256}, "6": {"k": 6, "answer": "Group 1", "latency_ms": 284.1453552246094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3906}}}
{"qid": "1133135656128481203", "question": "who sings the theme tune to mum on bbc2", "gold_answers": ["Lulu and the Lampshades"], "shots": {"0": {"k": 0, "answer": "Julie Walters", "latency_ms": 116.85967445373535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 158.46681594848633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 223.8903045654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 191.80917739868164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 265.28286933898926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2444}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 215.09337425231934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 190.0942325592041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3765}}}
