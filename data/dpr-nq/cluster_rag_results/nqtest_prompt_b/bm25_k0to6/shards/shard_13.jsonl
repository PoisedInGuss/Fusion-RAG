{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Rita Skeeter", "latency_ms": 75.39844512939453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 81.52961730957031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 295.71008682250977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 145.34378051757812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 234.09461975097656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2602}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 214.2651081085205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3243}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 198.00567626953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3875}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Minnie Riperton", "latency_ms": 211.77339553833008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 197.22366333007812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 216.57657623291016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 110.60667037963867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 182.52921104431152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2533}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 309.4339370727539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 275.9075164794922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3853}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwestern United States and Mexico", "latency_ms": 236.541748046875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 303.91764640808105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 400.62427520751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1310}, "3": {"k": 3, "answer": "deserts of the southwestern United States, Mexico, and Central America", "latency_ms": 264.24360275268555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2042}, "4": {"k": 4, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 185.35590171813965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2677}, "5": {"k": 5, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 294.2981719970703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3326}, "6": {"k": 6, "answer": "southwestern United States, Mexico, and Central America", "latency_ms": 270.5528736114502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3971}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 170.40061950683594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Karl Seitz", "latency_ms": 147.2170352935791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Karl Seitz", "latency_ms": 325.6063461303711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1382}, "3": {"k": 3, "answer": "Karl Seitz", "latency_ms": 134.0780258178711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2096}, "4": {"k": 4, "answer": "Karl Seitz", "latency_ms": 114.3796443939209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2753}, "5": {"k": 5, "answer": "Muhammad Ali Jinnah", "latency_ms": 291.888952255249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3439}, "6": {"k": 6, "answer": "Karl Seitz", "latency_ms": 141.40748977661133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4065}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 178.56144905090332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 278.40328216552734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 497.26343154907227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 261.72828674316406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 407.52720832824707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 183.35890769958496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 283.8902473449707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3889}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "2001", "latency_ms": 295.9909439086914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 84.9447250366211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 699}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 281.02898597717285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1331}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 220.8704948425293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "2001", "latency_ms": 135.545015335083, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2593}, "5": {"k": 5, "answer": "2001", "latency_ms": 151.05485916137695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3212}, "6": {"k": 6, "answer": "2001", "latency_ms": 186.04373931884766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3891}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "2018", "latency_ms": 141.7386531829834, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wednesday at 8:00 PM", "latency_ms": 130.74660301208496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Wednesday at 8:00 PM", "latency_ms": 296.71335220336914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1378}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 409.1041088104248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2043}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 122.88165092468262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2682}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 127.24733352661133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3345}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 271.3449001312256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3948}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 4, Episode 10 \"The First Time\"", "latency_ms": 243.70288848876953, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 168.20788383483887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 275.36654472351074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 109.8172664642334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2007}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 223.36125373840332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Hell-O", "latency_ms": 263.9577388763428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3187}, "6": {"k": 6, "answer": "Hell-O", "latency_ms": 178.0538558959961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3794}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 248.56233596801758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 344.56562995910645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 246.04058265686035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 168.29514503479004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 179.66461181640625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 338.08135986328125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 288.85817527770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3926}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana, Cuba", "latency_ms": 222.78332710266113, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Havana harbor", "latency_ms": 261.51585578918457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "Havana harbor", "latency_ms": 277.36496925354004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Havana Harbor", "latency_ms": 271.12817764282227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Havana Harbor", "latency_ms": 266.08920097351074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2640}, "5": {"k": 5, "answer": "Havana Harbor", "latency_ms": 229.94422912597656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3214}, "6": {"k": 6, "answer": "Havana Harbor", "latency_ms": 251.3883113861084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3838}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Shiva", "latency_ms": 75.12903213500977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 236.96637153625488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 157.79757499694824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Lord Vasupujya", "latency_ms": 121.86288833618164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "Lord Vasupujya", "latency_ms": 302.1419048309326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2502}, "5": {"k": 5, "answer": "Anant Chaturdashi is not celebrated in honour of a specific god. The context mentions Lord Vasupujya attaining moksha on this day, but does not state that the festival is celebrated in honour of a god. I cannot answer.", "latency_ms": 1220.6778526306152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Lord Vasupujya", "latency_ms": 337.63933181762695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3869}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Belize, Guatemala, Honduras, Nicaragua, Costa Rica", "latency_ms": 629.4882297515869, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Honduras, Nicaragua", "latency_ms": 198.45867156982422, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 696}, "2": {"k": 2, "answer": "Honduras", "latency_ms": 108.86693000793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Honduras, Nicaragua", "latency_ms": 273.68927001953125, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1912}, "4": {"k": 4, "answer": "Honduras, Nicaragua, Costa Rica", "latency_ms": 401.49927139282227, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2478}, "5": {"k": 5, "answer": "Honduras, Nicaragua, Costa Rica, Panama", "latency_ms": 308.2413673400879, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3110}, "6": {"k": 6, "answer": "Honduras, Nicaragua, Costa Rica, Panama", "latency_ms": 405.29656410217285, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3764}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "complex sentence", "latency_ms": 70.11151313781738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "complex sentence", "latency_ms": 60.18853187561035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "complex sentence", "latency_ms": 123.72207641601562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "complex sentence", "latency_ms": 165.8320426940918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2008}, "4": {"k": 4, "answer": "complex sentence", "latency_ms": 111.80901527404785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2672}, "5": {"k": 5, "answer": "complex sentence", "latency_ms": 274.10316467285156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3356}, "6": {"k": 6, "answer": "complex sentence", "latency_ms": 192.82269477844238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4062}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "economic systems and trade principles", "latency_ms": 297.532320022583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The division of labour, productivity, and free markets", "latency_ms": 373.29888343811035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "The division of labour, productivity, and free markets.", "latency_ms": 655.2286148071289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1337}, "3": {"k": 3, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of the wealth of nations, including topics such as the division of labour, productivity, and free markets.", "latency_ms": 1330.7008743286133, "em": 0.0, "f1": 0.14285714285714285, "containment": 0.0, "context_chars": 1989}, "4": {"k": 4, "answer": "The division of labour, productivity, and free markets.", "latency_ms": 527.7161598205566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2670}, "5": {"k": 5, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of national wealth, including topics like the division of labour, productivity, and free markets.", "latency_ms": 1342.677116394043, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 3356}, "6": {"k": 6, "answer": "The book \"The Wealth of Nations\" is about the nature and causes of national wealth, including topics like the division of labour, productivity, and free markets.", "latency_ms": 1302.1204471588135, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 3972}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "2024", "latency_ms": 412.3685359954834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 132.52758979797363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 314.5160675048828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 187.3335838317871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 210.49737930297852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 295.67503929138184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3131}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 436.4016056060791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3757}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Southern Hemisphere, Eastern Hemisphere, Oceania region", "latency_ms": 440.9351348876953, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Oceania, Australasia", "latency_ms": 336.38978004455566, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "Oceania", "latency_ms": 117.64264106750488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1345}, "3": {"k": 3, "answer": "Southern Hemisphere, Eastern Hemisphere, Oceania region", "latency_ms": 329.5769691467285, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1998}, "4": {"k": 4, "answer": "Southern Hemisphere, Eastern Hemisphere, Oceania region", "latency_ms": 668.318510055542, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 2721}, "5": {"k": 5, "answer": "Southern Hemisphere, Eastern Hemisphere, Oceania region", "latency_ms": 527.7304649353027, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 3450}, "6": {"k": 6, "answer": "Southern Hemisphere, Eastern Hemisphere, Oceania region", "latency_ms": 873.9290237426758, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 4184}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Padmé Amidala", "latency_ms": 100.4936695098877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 193.64380836486816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 534}, "2": {"k": 2, "answer": "Padmé Amidala", "latency_ms": 162.62507438659668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1121}, "3": {"k": 3, "answer": "Mara Jade", "latency_ms": 181.715726852417, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1751}, "4": {"k": 4, "answer": "Leia Organa", "latency_ms": 231.40311241149902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2322}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 259.3362331390381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2967}, "6": {"k": 6, "answer": "Leia Organa", "latency_ms": 399.48058128356934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3558}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Ralph Edwards", "latency_ms": 136.69443130493164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Barry Cryer", "latency_ms": 101.0138988494873, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 548}, "2": {"k": 2, "answer": "Barry Cryer", "latency_ms": 168.82967948913574, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1098}, "3": {"k": 3, "answer": "Barry Cryer", "latency_ms": 131.03365898132324, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1711}, "4": {"k": 4, "answer": "Allen Ludden", "latency_ms": 188.54355812072754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2327}, "5": {"k": 5, "answer": "Barry Cryer", "latency_ms": 318.9370632171631, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2920}, "6": {"k": 6, "answer": "Jack Barry", "latency_ms": 270.24340629577637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3568}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "mitochondria", "latency_ms": 252.72536277770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "mitochondria", "latency_ms": 93.6424732208252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 728}, "2": {"k": 2, "answer": "mitochondrion", "latency_ms": 94.99359130859375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1438}, "3": {"k": 3, "answer": "mitochondrion", "latency_ms": 137.47930526733398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2097}, "4": {"k": 4, "answer": "mitochondrion", "latency_ms": 145.70140838623047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2776}, "5": {"k": 5, "answer": "mitochondria", "latency_ms": 242.5529956817627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3452}, "6": {"k": 6, "answer": "mitochondria", "latency_ms": 214.61129188537598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4245}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Risk assessment, access control, encryption, intrusion detection, employee training", "latency_ms": 193.27521324157715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 156.11672401428223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 163.3467674255371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 267.0910358428955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2066}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 181.08010292053223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2775}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 123.75235557556152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3489}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 125.99062919616699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4232}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "The Human League", "latency_ms": 159.30557250976562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 237.9128932952881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 226.16338729858398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 357.0585250854492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 219.04921531677246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 170.15671730041504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3067}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 257.465124130249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3666}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 225.18181800842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "five to seven years", "latency_ms": 243.30639839172363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "five to seven years", "latency_ms": 176.88918113708496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "five to seven years old", "latency_ms": 110.9781265258789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1703}, "4": {"k": 4, "answer": "five to seven years old", "latency_ms": 173.50172996520996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2352}, "5": {"k": 5, "answer": "five to seven years", "latency_ms": 150.4068374633789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3015}, "6": {"k": 6, "answer": "five to seven years", "latency_ms": 397.30095863342285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3700}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "100", "latency_ms": 127.56156921386719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "three", "latency_ms": 148.19955825805664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "three episodes", "latency_ms": 97.4428653717041, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "3", "latency_ms": 69.2441463470459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "3", "latency_ms": 97.7640151977539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": "3", "latency_ms": 164.5946502685547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "3", "latency_ms": 98.40917587280273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3891}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Vivien Leigh, Ian McKellen, Orlando Bloom, Sean Astin, Dominic Monaghan, and Billy Boyd", "latency_ms": 487.31255531311035, "em": 0.0, "f1": 0.2352941176470588, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 179.0621280670166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 249.5901584625244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1331}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 196.86651229858398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 372.8330135345459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2604}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 175.3103733062744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "Elijah Wood", "latency_ms": 128.922700881958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3863}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Wearing costumes for a party or event, often for fun or celebration.", "latency_ms": 418.2934761047363, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 257.2958469390869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 219.8348045349121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "party fashion, leisure and entertainment products", "latency_ms": 315.1841163635254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1952}, "4": {"k": 4, "answer": "masked balls of the 18th century period", "latency_ms": 451.3065814971924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "masked balls of the 18th century period", "latency_ms": 460.4971408843994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3152}, "6": {"k": 6, "answer": "tradition traced to masked balls of the 18th century period", "latency_ms": 352.44226455688477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3774}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 47.41477966308594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 54.00443077087402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "1", "latency_ms": 135.1916790008545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "1", "latency_ms": 77.77690887451172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "1", "latency_ms": 121.27351760864258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "1", "latency_ms": 198.09818267822266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3184}, "6": {"k": 6, "answer": "1", "latency_ms": 146.88682556152344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3840}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "To save her from being taken by the authorities and to protect her from suffering.", "latency_ms": 736.929178237915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "To rescue her from M. Thénardier and save her from a life of hardship and exploitation.", "latency_ms": 1017.3630714416504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "To protect her and provide her with a better life.", "latency_ms": 358.42275619506836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "To save Cosette from abuse by the Thénardiers.", "latency_ms": 292.1159267425537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1781}, "4": {"k": 4, "answer": "To protect Cosette from the Thénardiers' abuse and to provide her with a safe and loving home.", "latency_ms": 962.4006748199463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2420}, "5": {"k": 5, "answer": "To protect Cosette from the Thénardiers' abuse and to provide her with a safe and loving home.", "latency_ms": 1311.159610748291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3077}, "6": {"k": 6, "answer": "To save Cosette from abuse by the Thénardiers and to provide her with a safe and loving home.", "latency_ms": 572.8781223297119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3730}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, France, Zambia, Angola, South Africa, Brazil, Russia, United States, Nigeria, Tanzania, Rwanda, Uganda, Zambia, Kenya, Ethiopia, South Africa, India, Japan, Germany, Italy, United Kingdom, Canada, Australia, South Korea, Saudi Arabia, United Arab Emirates, Egypt, Algeria, Nigeria, Ghana, Senegal, Mali, Sudan, Ethiopia, Kenya, Tanzania, Uganda, Rwanda, Burundi, Zambia, Zimbabwe, Malawi, Mozambique, Namibia, Botswana, Lesotho, Eswatini, Zimbabwe, South Africa, Nigeria, Ghana, Senegal, Mali, Sudan, Ethiopia, Kenya, Tanzania, Uganda, Rwanda, Burundi, Zambia, Zimbabwe, Malawi, Mozambique, Namibia, Botswana, Lesotho, Eswatini", "latency_ms": 4913.168907165527, "em": 0.0, "f1": 0.05, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 237.26606369018555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "Kenya", "latency_ms": 87.91780471801758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Kenya", "latency_ms": 116.7459487915039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2000}, "4": {"k": 4, "answer": "Kenya", "latency_ms": 93.36376190185547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2685}, "5": {"k": 5, "answer": "Kenya", "latency_ms": 96.76957130432129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3425}, "6": {"k": 6, "answer": "Kenya", "latency_ms": 189.86058235168457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4082}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "To provide a controlled, inferior education that prepared Black South Africans for low-level labor and maintained racial hierarchy.", "latency_ms": 319.4293975830078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to consolidate Bantu education so that discriminatory educational practices could be uniformly implemented across South Africa.", "latency_ms": 611.1910343170166, "em": 0.0, "f1": 0.09523809523809523, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "to consolidate Bantu education so that discriminatory educational practices could be uniformly implemented across South Africa", "latency_ms": 887.9349231719971, "em": 0.0, "f1": 0.09523809523809523, "containment": 0.0, "context_chars": 1413}, "3": {"k": 3, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 296.28515243530273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to consolidate Bantu education so that discriminatory educational practices could be uniformly implemented across South Africa", "latency_ms": 358.8552474975586, "em": 0.0, "f1": 0.09523809523809523, "containment": 0.0, "context_chars": 2764}, "5": {"k": 5, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 474.5464324951172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3440}, "6": {"k": 6, "answer": "to ensure that blacks would have only just enough education to work as unskilled laborers", "latency_ms": 715.9900665283203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4117}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Python", "latency_ms": 89.22863006591797, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kaa is a snake.", "latency_ms": 493.3476448059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "Kaa is a snake.", "latency_ms": 423.9344596862793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Kaa is a snake.", "latency_ms": 497.8480339050293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1780}, "4": {"k": 4, "answer": "python", "latency_ms": 78.81903648376465, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2403}, "5": {"k": 5, "answer": "python", "latency_ms": 90.91353416442871, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3028}, "6": {"k": 6, "answer": "Kaa is a python.", "latency_ms": 354.4771671295166, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3724}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "water ice and carbon dioxide ice", "latency_ms": 108.76727104187012, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 138.86785507202148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 572}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 197.79133796691895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1152}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 115.7536506652832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1799}, "4": {"k": 4, "answer": "ice", "latency_ms": 149.86777305603027, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2448}, "5": {"k": 5, "answer": "ice", "latency_ms": 153.3675193786621, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3108}, "6": {"k": 6, "answer": "ice", "latency_ms": 130.9363842010498, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3733}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 1, Episode 4", "latency_ms": 157.13739395141602, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "second season's conclusion", "latency_ms": 221.32325172424316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "around page 200 of \"The Awakening\"", "latency_ms": 453.88054847717285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "end of second season", "latency_ms": 112.25295066833496, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1921}, "4": {"k": 4, "answer": "end of second season", "latency_ms": 142.88902282714844, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2605}, "5": {"k": 5, "answer": "near the end of the second season", "latency_ms": 372.5244998931885, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "end of second season", "latency_ms": 254.96745109558105, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3918}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 226.7475128173828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ITV", "latency_ms": 120.3467845916748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "ITV", "latency_ms": 366.8186664581299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1182}, "3": {"k": 3, "answer": "ITV", "latency_ms": 143.98789405822754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1748}, "4": {"k": 4, "answer": "BBC Sport", "latency_ms": 82.99469947814941, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2331}, "5": {"k": 5, "answer": "ITV", "latency_ms": 140.14434814453125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2905}, "6": {"k": 6, "answer": "ITV", "latency_ms": 276.89647674560547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3542}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Ward 8", "latency_ms": 176.8660545349121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 215.22235870361328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Washington, DC", "latency_ms": 203.75847816467285, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "Washington, DC", "latency_ms": 265.3625011444092, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Washington, DC", "latency_ms": 368.7419891357422, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Washington, DC", "latency_ms": 119.7957992553711, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "Washington, DC", "latency_ms": 219.73013877868652, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3900}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Covenant of Noah", "latency_ms": 195.96314430236816, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Covenant of Noah", "latency_ms": 279.07681465148926, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Covenant of Abraham", "latency_ms": 284.3022346496582, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Mosaic covenant", "latency_ms": 170.34387588500977, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1929}, "4": {"k": 4, "answer": "Mosaic covenant", "latency_ms": 133.41307640075684, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2539}, "5": {"k": 5, "answer": "Mosaic covenant", "latency_ms": 169.7671413421631, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Mosaic covenant", "latency_ms": 189.01562690734863, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3869}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Toni Braxton", "latency_ms": 222.8384017944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 255.86938858032227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 366.9710159301758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 199.32055473327637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 264.0974521636963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 235.4750633239746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 179.1222095489502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3827}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "W. C. Fields", "latency_ms": 269.92297172546387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 252.39968299865723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 397.446870803833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 173.51007461547852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 248.89779090881348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 152.0528793334961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3128}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 156.4631462097168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3750}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 144.06633377075195, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Estero Island, Lee County, Florida", "latency_ms": 472.3546504974365, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Fort Myers Beach, Florida", "latency_ms": 319.9429512023926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Fort Myers Beach, Florida", "latency_ms": 387.55083084106445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "Fort Myers, Florida is located in Lee County, United States.", "latency_ms": 678.2567501068115, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2587}, "5": {"k": 5, "answer": "Fort Myers, Florida is located in Lee County, Florida, United States.", "latency_ms": 543.1866645812988, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 3210}, "6": {"k": 6, "answer": "Fort Myers, Florida is located in Lee County, Florida, United States.", "latency_ms": 709.3122005462646, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 3832}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "2nd", "latency_ms": 105.9260368347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 137.67075538635254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 253.2482147216797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1317}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 180.2041530609131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 190.92726707458496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "1st", "latency_ms": 271.14057540893555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3204}, "6": {"k": 6, "answer": "1st", "latency_ms": 170.56941986083984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3800}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 88.3173942565918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Subhas Chandra Bose", "latency_ms": 200.64425468444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Surendranath Banerjee", "latency_ms": 591.1545753479004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1323}, "3": {"k": 3, "answer": "Surendranath Banerjee", "latency_ms": 279.59370613098145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1980}, "4": {"k": 4, "answer": "Pranab Mukherjee", "latency_ms": 200.68860054016113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "Y. S. Jaganmohan Reddy", "latency_ms": 442.78478622436523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3342}, "6": {"k": 6, "answer": "Surendranath Banerjee", "latency_ms": 427.60658264160156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4070}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Terry Jones", "latency_ms": 134.45377349853516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 203.97067070007324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 325.49548149108887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 204.345703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1942}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 127.45356559753418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 184.12089347839355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3166}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 236.38248443603516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3777}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 34.483909606933594, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 85.50477027893066, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": ".java", "latency_ms": 59.16857719421387, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": ".java", "latency_ms": 251.44267082214355, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2009}, "4": {"k": 4, "answer": ".java", "latency_ms": 74.59640502929688, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2656}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 338.08398246765137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3294}, "6": {"k": 6, "answer": ".java", "latency_ms": 222.79119491577148, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3891}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 99.89094734191895, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alan Turing", "latency_ms": 96.95315361022949, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Alan Turing", "latency_ms": 161.87381744384766, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Alan Turing", "latency_ms": 114.63522911071777, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1935}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 111.24110221862793, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2563}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 306.12969398498535, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3219}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 100.555419921875, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3849}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "To ensure party members vote according to party leadership.", "latency_ms": 318.83931159973145, "em": 0.0, "f1": 0.4615384615384615, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "assist majority or minority leader", "latency_ms": 217.05365180969238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "assist in maintaining party discipline and coordinating votes", "latency_ms": 357.1128845214844, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "assist party leaders in maintaining party discipline and ensuring party members vote according to party lines during votes", "latency_ms": 750.2624988555908, "em": 0.0, "f1": 0.27272727272727276, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "ensures party members vote along party lines and helps maintain party discipline during votes", "latency_ms": 736.4840507507324, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "Enforce party discipline, ensure members vote along party lines, and coordinate party strategy in Congress.", "latency_ms": 695.9095001220703, "em": 0.0, "f1": 0.31578947368421056, "containment": 0.0, "context_chars": 3277}, "6": {"k": 6, "answer": "Enforce party discipline, coordinate votes, and influence members to vote along party lines.", "latency_ms": 683.2401752471924, "em": 0.0, "f1": 0.3529411764705882, "containment": 0.0, "context_chars": 3883}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 248.43692779541016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1993", "latency_ms": 99.24483299255371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "1993", "latency_ms": 270.38025856018066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "1993", "latency_ms": 181.05626106262207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 181.3819408416748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2513}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 417.1164035797119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3137}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 360.28456687927246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the​ right but not the​ obligation to buy foreign​ currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 191.08319282531738, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 103.94597053527832, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 96.30203247070312, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 312.35384941101074, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 217.86093711853027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2694}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 427.2911548614502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3386}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 227.32925415039062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4003}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 132.71808624267578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 130.83648681640625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 698}, "2": {"k": 2, "answer": "360", "latency_ms": 220.94392776489258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1421}, "3": {"k": 3, "answer": "360", "latency_ms": 254.91595268249512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2114}, "4": {"k": 4, "answer": "360", "latency_ms": 203.2175064086914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2776}, "5": {"k": 5, "answer": "360", "latency_ms": 243.99614334106445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3435}, "6": {"k": 6, "answer": "360", "latency_ms": 286.53478622436523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4134}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 149.9652862548828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 290.8809185028076, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 410.9053611755371, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 246.185302734375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1939}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 173.10452461242676, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 185.31250953674316, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 308.1851005554199, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3909}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gormé"], "shots": {"0": {"k": 0, "answer": "Bobby \"Blue\" Bland", "latency_ms": 428.19929122924805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "George Seifert, Jack Mac Ferland", "latency_ms": 475.71825981140137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Eydie Gormé", "latency_ms": 268.9332962036133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Eydie Gormé", "latency_ms": 205.4581642150879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1787}, "4": {"k": 4, "answer": "Eydie Gormé", "latency_ms": 249.5715618133545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2388}, "5": {"k": 5, "answer": "Eydie Gormé", "latency_ms": 220.7045555114746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2965}, "6": {"k": 6, "answer": "Eydie Gormé", "latency_ms": 241.96600914001465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3566}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "Justice R. C. Lahoti", "latency_ms": 195.723295211792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 165.84396362304688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "Mohan Shantanagoudar", "latency_ms": 389.1918659210205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "K. M. Joseph", "latency_ms": 140.75040817260742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "Mohan Shantanagoudar", "latency_ms": 375.3170967102051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "Mohan Shantanagoudar", "latency_ms": 367.0387268066406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3042}, "6": {"k": 6, "answer": "K. M. Joseph", "latency_ms": 332.89051055908203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3653}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "Novak Djokovic", "latency_ms": 261.35969161987305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 142.58694648742676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 114.54224586486816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 252.11668014526367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1773}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 161.64851188659668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2388}, "5": {"k": 5, "answer": "Ken Rosewall", "latency_ms": 182.49917030334473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2967}, "6": {"k": 6, "answer": "Ken Rosewall", "latency_ms": 227.94032096862793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3554}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "5", "latency_ms": 107.00798034667969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 92.5297737121582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 581}, "2": {"k": 2, "answer": "1", "latency_ms": 107.18274116516113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "1", "latency_ms": 185.37259101867676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "1", "latency_ms": 102.63276100158691, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2469}, "5": {"k": 5, "answer": "1", "latency_ms": 88.89961242675781, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3062}, "6": {"k": 6, "answer": "1", "latency_ms": 126.59406661987305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3644}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 79.84161376953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2000", "latency_ms": 175.92310905456543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "1988", "latency_ms": 232.82933235168457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "1988", "latency_ms": 361.5999221801758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2014}, "4": {"k": 4, "answer": "1988", "latency_ms": 147.08352088928223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2636}, "5": {"k": 5, "answer": "2000", "latency_ms": 198.18902015686035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3319}, "6": {"k": 6, "answer": "1988", "latency_ms": 314.0847682952881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4003}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "32", "latency_ms": 121.22702598571777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 144.84214782714844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 158.83612632751465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 325.8171081542969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 206.21299743652344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "1", "latency_ms": 244.41981315612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3165}, "6": {"k": 6, "answer": "1", "latency_ms": 152.19688415527344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3830}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Wallowa County, Oregon", "latency_ms": 393.2666778564453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 111.6800308227539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 108.89911651611328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 166.5964126586914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 269.12927627563477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2566}, "5": {"k": 5, "answer": "Columbia River Gorge, Oregon", "latency_ms": 218.39261054992676, "em": 0.0, "f1": 0.8571428571428571, "containment": 1.0, "context_chars": 3217}, "6": {"k": 6, "answer": "Mount Hood National Forest", "latency_ms": 271.7874050140381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3848}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Corry, Kory, Cory, Koorie, Coary", "latency_ms": 579.8845291137695, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey", "latency_ms": 79.29658889770508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 571}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 351.3672351837158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1134}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 230.04555702209473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1819}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 179.14438247680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2507}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 307.97839164733887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3130}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 336.80009841918945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3715}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Linda Ronstadt", "latency_ms": 244.62532997131348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roy Rogers", "latency_ms": 173.1276512145996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 159.3780517578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "Charley Willis", "latency_ms": 293.4598922729492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 402.7884006500244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2451}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 459.9123001098633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3085}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 249.5729923248291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 235.79931259155273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "60", "latency_ms": 66.5121078491211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "60", "latency_ms": 118.18242073059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "159", "latency_ms": 169.53682899475098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1891}, "4": {"k": 4, "answer": "159", "latency_ms": 240.8761978149414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2534}, "5": {"k": 5, "answer": "159", "latency_ms": 224.79915618896484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3177}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 255.25736808776855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3816}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Tommy Emmanuel", "latency_ms": 66.25962257385254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 184.7841739654541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 561}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 140.00844955444336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 222.0480442047119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1785}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 275.22993087768555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2381}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 341.48168563842773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2981}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 356.7960262298584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3562}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Stephen Curry", "latency_ms": 155.68113327026367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wilt Chamberlain", "latency_ms": 200.15716552734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Adrian Dantley", "latency_ms": 126.78742408752441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "Wilt Chamberlain", "latency_ms": 108.20341110229492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "Wilt Chamberlain", "latency_ms": 113.97528648376465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2545}, "5": {"k": 5, "answer": "Wilt Chamberlain", "latency_ms": 153.86033058166504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 217.8056240081787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3742}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 163.6638641357422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 147.80330657958984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 150.83885192871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 328.5965919494629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1920}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 340.8687114715576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2455}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 197.50452041625977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3057}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 193.1593418121338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3711}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Pinocchio", "latency_ms": 152.85325050354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 257.293701171875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 179.25667762756348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 364.87483978271484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1956}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 148.26416969299316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2653}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 187.78705596923828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 305.06443977355957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3918}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Waited (no, that's incorrect)  \nCorrect answer: Sean Astin  \nNo, that's incorrect.  \nCorrect answer: John Rhys-Davies  \nNo, that's incorrect.  \nCorrect answer: Ian McKellen  \nNo, that's incorrect.  \nCorrect answer: Sir Ian McKellen played King Théoden in The Lord of the Rings.  \nFinal correct answer: Sir Ian McKellen  \nBut wait — Sir Ian McKellen played Aragorn, not Théoden.  \nCorrect answer: Sir Anthony Hopkins? No.  \nCorrect answer: Sir William Hurt? No.  \nCorrect answer: Sir Derek Jacobi? No.  \nCorrect answer: Sir John Rhys-Davies played Gimli.  \nCorrect answer: Sir Sean Astin played Meriadoc Brandybuck.  \nCorrect answer: Sir Peter Jackson directed.  \nCorrect answer: Théoden was played by...  \nFinal correct answer: Sir Anthony Hopkins? No.  \nCorrect answer: Sir Ian McKellen? No.  \nCorrect answer: Sir John Rhys-Davies? No.  \nCorrect answer: Sir Bernard Hill? No.  \nCorrect answer: Sir William S. Hart? No.  \nCorrect answer: Sir William Hurt? No.  \nCorrect answer:", "latency_ms": 7861.0711097717285, "em": 0.0, "f1": 0.02857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sean Astin", "latency_ms": 121.61731719970703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 404.2215347290039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 204.88262176513672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 225.43048858642578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2557}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 289.7634506225586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3191}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 311.9947910308838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3789}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "2023", "latency_ms": 320.52016258239746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 161.085844039917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 206.01749420166016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 191.15233421325684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 178.0996322631836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2404}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 302.3967742919922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3055}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 383.5427761077881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3689}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles, California", "latency_ms": 134.49478149414062, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 301.59711837768555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 539}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 303.26342582702637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 169.62599754333496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1847}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 145.74480056762695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2489}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 204.742431640625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3141}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 232.19776153564453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3751}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 196.22087478637695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 116.10245704650879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 164.33215141296387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 381.7284107208252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 150.2821445465088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Emma Gilbert", "latency_ms": 123.37493896484375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3108}, "6": {"k": 6, "answer": "Emma Gilbert", "latency_ms": 186.2804889678955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3747}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "atmosphere, oceans, soil, living organisms", "latency_ms": 484.2672348022461, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "wood or soil", "latency_ms": 72.62539863586426, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 705}, "2": {"k": 2, "answer": "wood, soil, dissolved carbon", "latency_ms": 264.1160488128662, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1425}, "3": {"k": 3, "answer": "plants, soil, wood, organic matter", "latency_ms": 157.68861770629883, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2048}, "4": {"k": 4, "answer": "plants, soil, wood, organic matter", "latency_ms": 503.87120246887207, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2759}, "5": {"k": 5, "answer": "in wood or soil", "latency_ms": 249.6318817138672, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3428}, "6": {"k": 6, "answer": "plants, soil, wood, organic matter", "latency_ms": 373.8999366760254, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 4095}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "Sneha Ullal", "latency_ms": 207.64565467834473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shruti", "latency_ms": 77.36420631408691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Chandan Shetty", "latency_ms": 98.10447692871094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Shruti", "latency_ms": 178.68542671203613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1824}, "4": {"k": 4, "answer": "Chandan Shetty", "latency_ms": 355.7403087615967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2427}, "5": {"k": 5, "answer": "Chandan Shetty", "latency_ms": 205.92021942138672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3070}, "6": {"k": 6, "answer": "Chandan Shetty", "latency_ms": 189.92090225219727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3713}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Tennessee", "latency_ms": 224.32899475097656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 86.61842346191406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 148.39863777160645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 196.84481620788574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 329.2515277862549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 177.33407020568848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3124}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 198.6243724822998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3728}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 228.74975204467773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 164.7794246673584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 159.65604782104492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 414.0620231628418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 107.24592208862305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 208.15658569335938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3028}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 219.5122241973877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3621}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Starts in the Rocky Mountains, ends in the North Dakota-Montana border.", "latency_ms": 510.01739501953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Starts at North Saskatchewan River in Canadian Rockies, ends at Hudson Bay", "latency_ms": 467.67306327819824, "em": 0.0, "f1": 0.2857142857142857, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Starts at North Saskatchewan River; ends at Hudson Bay", "latency_ms": 284.2693328857422, "em": 0.0, "f1": 0.3636363636363636, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "Starts at confluence of North Saskatchewan River and Howse River/Mistaya River in Canadian Rockies; ends at Hudson Bay.", "latency_ms": 793.6420440673828, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Starts at the confluence of the North Saskatchewan River and the South Saskatchewan River in Saskatchewan River Forks; ends at Hudson Bay.", "latency_ms": 771.1257934570312, "em": 0.0, "f1": 0.34782608695652173, "containment": 0.0, "context_chars": 2557}, "5": {"k": 5, "answer": "Starts at confluence of North Saskatchewan River and Saskatchewan River Forks; ends at Hudson Bay.", "latency_ms": 839.5946025848389, "em": 0.0, "f1": 0.4210526315789474, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Starts at confluence of North Saskatchewan River and another major river; ends at Hudson Bay", "latency_ms": 397.2465991973877, "em": 0.0, "f1": 0.2352941176470588, "containment": 0.0, "context_chars": 3754}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 51.31983757019043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome, Italy", "latency_ms": 409.50942039489746, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome, Italy", "latency_ms": 302.1061420440674, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Rome, Italy", "latency_ms": 103.26004028320312, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1954}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 109.76815223693848, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2583}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 155.6849479675293, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3146}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 296.0784435272217, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3862}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "M number refers to the glass's capacity in milliliters.", "latency_ms": 573.7581253051758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 85.88814735412598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 183.8057041168213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1280}, "3": {"k": 3, "answer": "the manufacturing company or site", "latency_ms": 216.31741523742676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1927}, "4": {"k": 4, "answer": "the manufacturing company or site", "latency_ms": 416.19062423706055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2500}, "5": {"k": 5, "answer": "the manufacturing company or site", "latency_ms": 210.34479141235352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "manufacturing company or site", "latency_ms": 398.0672359466553, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3770}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "ammonia, alcohols, carboxylic acids", "latency_ms": 556.9479465484619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "alcohol, ammonia, and many organic compounds with O-H, N-H, or F-H groups", "latency_ms": 915.5070781707764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "hydrogen sulfide", "latency_ms": 138.4594440460205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1356}, "3": {"k": 3, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 185.8537197113037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2025}, "4": {"k": 4, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 477.60009765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 352.977991104126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 370.9406852722168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3829}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "1988", "latency_ms": 71.36893272399902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1985", "latency_ms": 309.2069625854492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "1988", "latency_ms": 277.76479721069336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "1988", "latency_ms": 182.18755722045898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1824}, "4": {"k": 4, "answer": "1988", "latency_ms": 317.0289993286133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2427}, "5": {"k": 5, "answer": "1988", "latency_ms": 148.63848686218262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3038}, "6": {"k": 6, "answer": "1988", "latency_ms": 156.205415725708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3645}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Truco", "latency_ms": 66.11442565917969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 173.81000518798828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Truco", "latency_ms": 72.07417488098145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Manille", "latency_ms": 180.65786361694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1857}, "4": {"k": 4, "answer": "Manille", "latency_ms": 149.19757843017578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "Manille", "latency_ms": 242.36273765563965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3061}, "6": {"k": 6, "answer": "Manille", "latency_ms": 170.32146453857422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3685}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2%", "latency_ms": 54.255008697509766, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5%", "latency_ms": 87.40782737731934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "5%", "latency_ms": 57.62743949890137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1317}, "3": {"k": 3, "answer": "5%", "latency_ms": 69.53668594360352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2022}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 254.63509559631348, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2632}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 235.44549942016602, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3257}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 343.31440925598145, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3904}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "2018", "latency_ms": 88.72556686401367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 153.3656120300293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "1975", "latency_ms": 285.5079174041748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1200}, "3": {"k": 3, "answer": "1975", "latency_ms": 103.62744331359863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1854}, "4": {"k": 4, "answer": "1975", "latency_ms": 109.9393367767334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2458}, "5": {"k": 5, "answer": "1975", "latency_ms": 219.32291984558105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3128}, "6": {"k": 6, "answer": "1975", "latency_ms": 266.2687301635742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3740}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Michael Jackson", "latency_ms": 179.89492416381836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 168.78128051757812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 164.09850120544434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 205.7211399078369, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1844}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 134.0656280517578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2518}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 166.60547256469727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3151}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 174.73769187927246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Lord Baltimore", "latency_ms": 79.74529266357422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "William Stone", "latency_ms": 113.97027969360352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "William Stone", "latency_ms": 113.69943618774414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "William Stone", "latency_ms": 134.67907905578613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1956}, "4": {"k": 4, "answer": "William Stone", "latency_ms": 82.19385147094727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "William Stone and Cecilius Calvert", "latency_ms": 173.7987995147705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3324}, "6": {"k": 6, "answer": "William Stone", "latency_ms": 112.9755973815918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4035}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Tiger Woods", "latency_ms": 67.70157814025879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 140.9473419189453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 98.32763671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 144.44780349731445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Tiger Woods", "latency_ms": 171.86927795410156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "Tiger Woods", "latency_ms": 216.5658473968506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3172}, "6": {"k": 6, "answer": "Tiger Woods", "latency_ms": 328.21083068847656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3842}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "100 milliliters", "latency_ms": 104.46405410766602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 172.1038818359375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 688}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 189.3322467803955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 270.0238227844238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 108.673095703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2642}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 394.1664695739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 392.5909996032715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3888}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Barnsley 2003", "latency_ms": 146.61455154418945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sunderland", "latency_ms": 170.43137550354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 558}, "2": {"k": 2, "answer": "West Bromwich (1931)", "latency_ms": 441.272497177124, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1138}, "3": {"k": 3, "answer": "Sunderland", "latency_ms": 266.5829658508301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1730}, "4": {"k": 4, "answer": "Sunderland", "latency_ms": 214.05315399169922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2340}, "5": {"k": 5, "answer": "West Bromwich (1931)", "latency_ms": 309.54551696777344, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2982}, "6": {"k": 6, "answer": "Sunderland", "latency_ms": 206.1307430267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3574}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 162.09959983825684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 84.46431159973145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 216.5818214416504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1343}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 341.33028984069824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2066}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 186.9363784790039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2742}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 349.29513931274414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3426}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 255.4471492767334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4160}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh, Scotland", "latency_ms": 79.47063446044922, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh", "latency_ms": 140.72203636169434, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "Edinburgh Festival Fringe", "latency_ms": 172.73283004760742, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1356}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 235.46648025512695, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 268.3835029602051, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 350.01492500305176, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3359}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 303.94601821899414, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3999}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Braun Strowman", "latency_ms": 146.7113494873047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 306.31470680236816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 88.92297744750977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 231.24051094055176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2030}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 180.03296852111816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2707}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 168.8368320465088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3338}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 597.9130268096924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3952}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Florida", "latency_ms": 186.69557571411133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haven", "latency_ms": 57.250022888183594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Southport, North Carolina", "latency_ms": 187.32166290283203, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Southport, North Carolina", "latency_ms": 199.16534423828125, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1902}, "4": {"k": 4, "answer": "Southport, North Carolina", "latency_ms": 179.29506301879883, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "Southport, North Carolina", "latency_ms": 304.2325973510742, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "Southport, North Carolina", "latency_ms": 283.311128616333, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "David Owen", "latency_ms": 55.909156799316406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 169.21210289001465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 705}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 108.75225067138672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 293.7746047973633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1990}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 261.86466217041016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2599}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 253.70335578918457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 247.56455421447754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3932}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 102.59199142456055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 77.34060287475586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 703}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 169.24214363098145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1440}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 199.69701766967773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2145}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 93.82128715515137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2887}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 179.54611778259277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3615}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 213.9437198638916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4337}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 58.41779708862305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 54.8555850982666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "Max", "latency_ms": 97.99933433532715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1244}, "3": {"k": 3, "answer": "Max", "latency_ms": 224.06935691833496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Max", "latency_ms": 75.83856582641602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2519}, "5": {"k": 5, "answer": "Max", "latency_ms": 143.27645301818848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "Max", "latency_ms": 102.85639762878418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3742}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Sasha Lane", "latency_ms": 112.92672157287598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 90.78502655029297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 171.5540885925293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 113.89994621276855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1914}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 254.6248435974121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2514}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 185.62912940979004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3160}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 169.13127899169922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3869}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "Industrialization, imperialism, and the rise of global powers", "latency_ms": 281.9077968597412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spanish–American War, acquisition of Hawaii and the Philippines", "latency_ms": 172.4252700805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "German Navy expansion via the 1900 Naval Law, Spanish–American War, acquisition of Hawaii and Philippines", "latency_ms": 715.2650356292725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Spanish–American War, acquisition of Hawaii and the Philippines, 1900 Naval Law in Germany", "latency_ms": 662.2498035430908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1880}, "4": {"k": 4, "answer": "Spanish–American War, acquisition of Hawaii and Philippines, German Navy expansion via 1900 Naval Law, stagnation in Corps Rhenania Heidelberg, Al Jackson's early major league season", "latency_ms": 1752.7437210083008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "Spanish–American War, acquisition of Hawaii and Philippines, German Navy expansion via 1900 Naval Law, industrial growth, First World War (beginning), steel manufacturing, naval technology transition, rise of ocean-going battleships, man-power constraints in German Navy, industrial heritage and steel production", "latency_ms": 1037.8427505493164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "Spanish–American War, acquisition of Hawaii and Philippines, German Navy expansion via 1900 Naval Law, World's Congress of Representative Women, Bertha Palmer appointed U.S. Commissioner at Paris Exposition, industrial and social changes in steel manufacturing, rise of seacoast defense and naval technology, isolation of Corps Rhenania Heidelberg after 1900", "latency_ms": 2823.774814605713, "em": 0.0, "f1": 0.03773584905660377, "containment": 0.0, "context_chars": 3848}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Self-empowerment and confidence", "latency_ms": 149.25575256347656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "empowerment", "latency_ms": 158.76364707946777, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "empowerment", "latency_ms": 86.1978530883789, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1370}, "3": {"k": 3, "answer": "empowerment", "latency_ms": 267.0331001281738, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2041}, "4": {"k": 4, "answer": "self-empowerment", "latency_ms": 402.7559757232666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2654}, "5": {"k": 5, "answer": "self-empowerment", "latency_ms": 145.18070220947266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3272}, "6": {"k": 6, "answer": "self-empowerment", "latency_ms": 323.9274024963379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3854}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams", "latency_ms": 126.02543830871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "NFL teams", "latency_ms": 103.0123233795166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "NFL teams", "latency_ms": 71.50053977966309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "NFL teams", "latency_ms": 83.50753784179688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "NFL teams", "latency_ms": 86.83967590332031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "NFL teams", "latency_ms": 169.60859298706055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3118}, "6": {"k": 6, "answer": "NFL teams", "latency_ms": 223.38247299194336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3730}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 95.10445594787598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "one of the sailors", "latency_ms": 212.21446990966797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 216.91632270812988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 319.5524215698242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 178.7886619567871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2562}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 127.19225883483887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Sutter", "latency_ms": 140.5014991760254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3813}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex mirror", "latency_ms": 167.00434684753418, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "rear-view mirror", "latency_ms": 281.01253509521484, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "rear-view mirror", "latency_ms": 124.21679496765137, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "rear-view mirror", "latency_ms": 156.08739852905273, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1879}, "4": {"k": 4, "answer": "rear-view mirror", "latency_ms": 158.89334678649902, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "rear-view mirror", "latency_ms": 248.48508834838867, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "rear-view mirror", "latency_ms": 239.5479679107666, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "10 medals", "latency_ms": 344.1433906555176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 81.39824867248535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 177.92963981628418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 109.09175872802734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 284.8482131958008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2612}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 297.51062393188477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3340}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 312.90435791015625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3938}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart", "latency_ms": 148.88644218444824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ken Hill", "latency_ms": 200.6063461303711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 669}, "2": {"k": 2, "answer": "Ken Hill", "latency_ms": 97.61929512023926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "Ken Hill (1976 musical), Charles Hart (1986 musical)", "latency_ms": 663.8083457946777, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2023}, "4": {"k": 4, "answer": "Ken Hill, Charles Hart", "latency_ms": 209.11622047424316, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2687}, "5": {"k": 5, "answer": "Ken Hill, Charles Hart", "latency_ms": 259.1571807861328, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3303}, "6": {"k": 6, "answer": "Ken Hill, Charles Hart", "latency_ms": 379.5332908630371, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3962}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Central Europe", "latency_ms": 99.82180595397949, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central Germany", "latency_ms": 83.09364318847656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Central Germany (cultural area)", "latency_ms": 361.814022064209, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1357}, "3": {"k": 3, "answer": "Central Germany (cultural area)", "latency_ms": 215.4848575592041, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Central Germany (cultural area)", "latency_ms": 295.67456245422363, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2757}, "5": {"k": 5, "answer": "Central Germany (cultural area)", "latency_ms": 277.4937152862549, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3406}, "6": {"k": 6, "answer": "Central Germany", "latency_ms": 125.65398216247559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4051}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "13th century", "latency_ms": 115.9367561340332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 239.41755294799805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 133.652925491333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 195.84918022155762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "post-medieval era", "latency_ms": 452.84366607666016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "post-medieval era", "latency_ms": 157.88674354553223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3260}, "6": {"k": 6, "answer": "post-medieval era", "latency_ms": 159.66224670410156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
