{"qid": "-3320993703958028468", "question": "what color pages in the emergency response guidebook (erg) list compounds by name", "gold_answers": ["blue"], "shots": {"0": {"k": 0, "answer": "Blue", "latency_ms": 41.5949821472168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 133.19993019104004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "blue", "latency_ms": 57.387351989746094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1441}, "3": {"k": 3, "answer": "blue", "latency_ms": 113.37995529174805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2221}, "4": {"k": 4, "answer": "white", "latency_ms": 151.39412879943848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2927}, "5": {"k": 5, "answer": "white", "latency_ms": 87.59593963623047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3701}, "6": {"k": 6, "answer": "white", "latency_ms": 116.61505699157715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4392}}}
{"qid": "7026548049572374691", "question": "who developed the concept of total quality management", "gold_answers": ["W. Edwards Deming"], "shots": {"0": {"k": 0, "answer": "Joseph M. Juran", "latency_ms": 308.9334964752197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Armand V. Feigenbaum", "latency_ms": 132.25603103637695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 708}, "2": {"k": 2, "answer": "Armand V. Feigenbaum", "latency_ms": 389.49108123779297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1373}, "3": {"k": 3, "answer": "Armand V. Feigenbaum", "latency_ms": 492.5987720489502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2035}, "4": {"k": 4, "answer": "Armand V. Feigenbaum", "latency_ms": 194.91887092590332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2708}, "5": {"k": 5, "answer": "Armand V. Feigenbaum", "latency_ms": 530.419111251831, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3365}, "6": {"k": 6, "answer": "Armand V. Feigenbaum", "latency_ms": 303.33852767944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3992}}}
{"qid": "4617755372912487064", "question": "last world series that didn't go 7 games", "gold_answers": ["2015"], "shots": {"0": {"k": 0, "answer": "2004", "latency_ms": 179.80623245239258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 292.3567295074463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 549}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 288.3591651916504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1104}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 255.47361373901367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1670}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 142.9917812347412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2289}, "5": {"k": 5, "answer": "1956 World Series", "latency_ms": 464.2598628997803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2884}, "6": {"k": 6, "answer": "1956 World Series", "latency_ms": 367.3107624053955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3451}}}
{"qid": "8453604009134928493", "question": "this inventor co-created the film fred ott’s sneeze", "gold_answers": ["Edison", "Fred Ott"], "shots": {"0": {"k": 0, "answer": "George Eastman", "latency_ms": 245.6812858581543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Thomas Edison", "latency_ms": 120.18561363220215, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Thomas Edison", "latency_ms": 195.97649574279785, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Thomas Edison", "latency_ms": 173.91419410705566, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Thomas Edison", "latency_ms": 195.46055793762207, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2457}, "5": {"k": 5, "answer": "Thomas Edison", "latency_ms": 188.2002353668213, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3070}, "6": {"k": 6, "answer": "Thomas Edison", "latency_ms": 223.6790657043457, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3711}}}
{"qid": "-3407490342806384733", "question": "who sings what the world needs now in boss baby", "gold_answers": ["Hans Zimmer", "Steve Mazzaro", "Missi Hale"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 213.11473846435547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "No one sings \"What the World Needs Now Is Love\" in *The Boss Baby*. The song is not featured in the film. I cannot answer.", "latency_ms": 1432.9617023468018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 143.60356330871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 144.61541175842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1869}, "4": {"k": 4, "answer": "Tim", "latency_ms": 122.42507934570312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2428}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 456.9988250732422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3051}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 246.7801570892334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3653}}}
{"qid": "-442417708560275755", "question": "who won the most medals at the 2014 winter olympics", "gold_answers": ["Russia (", "Russia"], "shots": {"0": {"k": 0, "answer": "Canada", "latency_ms": 60.19186973571777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sweden", "latency_ms": 155.94744682312012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 103.0271053314209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "France", "latency_ms": 161.36837005615234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1939}, "4": {"k": 4, "answer": "France", "latency_ms": 76.6143798828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2557}, "5": {"k": 5, "answer": "France", "latency_ms": 175.18377304077148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3184}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 272.1524238586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3873}}}
{"qid": "-7627363632917466497", "question": "who determines the rules of the us house and us senate", "gold_answers": ["United States Senate", "The Senate"], "shots": {"0": {"k": 0, "answer": "Rules of the U.S. House and Senate are determined by the respective chambers themselves through their rules committees and floor procedures.", "latency_ms": 654.3266773223877, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "US Senate determines its own rules; US House determines its own rules.", "latency_ms": 560.9598159790039, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "Each House may determine the rules of its proceedings", "latency_ms": 576.5304565429688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "House: Rules Committee; Senate: Senate itself", "latency_ms": 591.3786888122559, "em": 0.0, "f1": 0.2857142857142857, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "US House: Rules Committee; US Senate: Senate Committee on Rules and Administration", "latency_ms": 778.2981395721436, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 2655}, "5": {"k": 5, "answer": "Each House may determine the rules of its proceedings.", "latency_ms": 211.6718292236328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3339}, "6": {"k": 6, "answer": "Each House may determine the rules of its proceedings", "latency_ms": 288.6049747467041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4017}}}
{"qid": "70640340064871933", "question": "who won britain's next top model 2016", "gold_answers": ["Chloe Keenan"], "shots": {"0": {"k": 0, "answer": "Lily Hargreaves", "latency_ms": 100.0361442565918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chloe Keenan", "latency_ms": 85.77275276184082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 644}, "2": {"k": 2, "answer": "Chloe Keenan", "latency_ms": 214.33615684509277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1325}, "3": {"k": 3, "answer": "Chloe Keenan", "latency_ms": 129.76908683776855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1969}, "4": {"k": 4, "answer": "Chloe Keenan", "latency_ms": 183.09378623962402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2680}, "5": {"k": 5, "answer": "Chloe Keenan", "latency_ms": 370.6347942352295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3362}, "6": {"k": 6, "answer": "Chloe Keenan", "latency_ms": 450.6826400756836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4008}}}
{"qid": "4884658732028049316", "question": "when did las vegas become a gambling town", "gold_answers": ["In 1931", "1931"], "shots": {"0": {"k": 0, "answer": "1931", "latency_ms": 81.1319351196289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1931", "latency_ms": 85.3266716003418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "1931", "latency_ms": 185.32133102416992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1291}, "3": {"k": 3, "answer": "1931", "latency_ms": 251.47247314453125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1930}, "4": {"k": 4, "answer": "1931", "latency_ms": 231.3985824584961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2621}, "5": {"k": 5, "answer": "1931", "latency_ms": 148.6353874206543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3260}, "6": {"k": 6, "answer": "1931", "latency_ms": 276.0007381439209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3901}}}
{"qid": "-5107559781320376096", "question": "who is the highest paid baseball player in the major leagues", "gold_answers": ["Alex Rodriguez", "Clayton Kershaw"], "shots": {"0": {"k": 0, "answer": "Teoscar Hernández", "latency_ms": 375.31065940856934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 306.4310550689697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 236.90009117126465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1216}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 252.29382514953613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 254.90951538085938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2448}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 265.6059265136719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3032}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 227.42581367492676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3630}}}
{"qid": "5890866538303894370", "question": "list the seven gifts of the holy spirit", "gold_answers": ["wisdom", "understanding", "fear", "piety", "counsel", "knowledge", "fear of the Lord", "fortitude"], "shots": {"0": {"k": 0, "answer": "Wisdom, Understanding, Counsel, Fortitude, Knowledge, Piety, Fear of the Lord", "latency_ms": 502.26330757141113, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, fear of the Lord", "latency_ms": 517.7803039550781, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "latency_ms": 919.9728965759277, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1342}, "3": {"k": 3, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "latency_ms": 532.6855182647705, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1969}, "4": {"k": 4, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "latency_ms": 987.0452880859375, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2627}, "5": {"k": 5, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "latency_ms": 773.949146270752, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3288}, "6": {"k": 6, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "latency_ms": 674.7596263885498, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3949}}}
{"qid": "4870961414505835033", "question": "where is beijing located on the world map", "gold_answers": ["in northern China", "northern China"], "shots": {"0": {"k": 0, "answer": "East Asia", "latency_ms": 106.94336891174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "East Asia", "latency_ms": 90.86847305297852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "East Asia", "latency_ms": 126.8002986907959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "East Asia", "latency_ms": 109.4827651977539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "East Asia", "latency_ms": 87.61358261108398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "eastern Asia", "latency_ms": 158.7827205657959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "East Asia", "latency_ms": 106.02474212646484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3829}}}
{"qid": "-9151459252301477194", "question": "when did the legal drinking age changed to 21", "gold_answers": ["October 1986", "By mid-1988"], "shots": {"0": {"k": 0, "answer": "1984", "latency_ms": 177.1531105041504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1986", "latency_ms": 153.39946746826172, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "1986", "latency_ms": 384.34505462646484, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "1986", "latency_ms": 175.25911331176758, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1880}, "4": {"k": 4, "answer": "1986", "latency_ms": 266.1299705505371, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2613}, "5": {"k": 5, "answer": "1986", "latency_ms": 216.05324745178223, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "1984", "latency_ms": 196.5506076812744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3868}}}
{"qid": "333763277804609492", "question": "a player that can shoot pass or dribble is considered to be", "gold_answers": ["Triple threat"], "shots": {"0": {"k": 0, "answer": "all-around player", "latency_ms": 139.7552490234375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a valid player", "latency_ms": 113.4958267211914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 551}, "2": {"k": 2, "answer": "a roll ball player", "latency_ms": 90.48724174499512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1132}, "3": {"k": 3, "answer": "basketball player", "latency_ms": 119.53043937683105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1751}, "4": {"k": 4, "answer": "in possession of the ball", "latency_ms": 127.05135345458984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2323}, "5": {"k": 5, "answer": "in control", "latency_ms": 99.76387023925781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2886}, "6": {"k": 6, "answer": "in control", "latency_ms": 135.18834114074707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3485}}}
{"qid": "-938578705122215845", "question": "where does the spinal cord become cauda equina", "gold_answers": ["the conus medullaris", "L1 or L2"], "shots": {"0": {"k": 0, "answer": "L1 vertebra", "latency_ms": 114.62974548339844, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "inferior to the conus medullaris", "latency_ms": 361.59515380859375, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 631}, "2": {"k": 2, "answer": "below the conus medullaris", "latency_ms": 374.8438358306885, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "conus medullaris", "latency_ms": 196.26784324645996, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "below the conus medullaris", "latency_ms": 426.971435546875, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2500}, "5": {"k": 5, "answer": "L3", "latency_ms": 122.01499938964844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3100}, "6": {"k": 6, "answer": "L3", "latency_ms": 231.81843757629395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3735}}}
{"qid": "-8834996069938989383", "question": "when did clifford the big red dog first air on tv", "gold_answers": ["September 4 , 2000"], "shots": {"0": {"k": 0, "answer": "1994", "latency_ms": 202.32033729553223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 4, 2000", "latency_ms": 220.96633911132812, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "September 4, 2000", "latency_ms": 359.76481437683105, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "September 4, 2000", "latency_ms": 504.37116622924805, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1977}, "4": {"k": 4, "answer": "September 4, 2000", "latency_ms": 427.14810371398926, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "September 4, 2000", "latency_ms": 490.1738166809082, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3270}, "6": {"k": 6, "answer": "September 4, 2000", "latency_ms": 240.06199836730957, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4006}}}
{"qid": "-2953491529624297458", "question": "when was the last time kentucky won ncaa", "gold_answers": ["2012"], "shots": {"0": {"k": 0, "answer": "2023", "latency_ms": 210.10327339172363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 154.19721603393555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "1975", "latency_ms": 108.4451675415039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "1975", "latency_ms": 253.3411979675293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "1975", "latency_ms": 296.1156368255615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "1975", "latency_ms": 219.8784351348877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3380}, "6": {"k": 6, "answer": "1975", "latency_ms": 178.01213264465332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4047}}}
{"qid": "1967531558485427303", "question": "what was guantanamo bay before it was a prison", "gold_answers": ["Guantanamo Bay Naval Base"], "shots": {"0": {"k": 0, "answer": "U.S. naval base", "latency_ms": 122.13349342346191, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Naval Base", "latency_ms": 290.7989025115967, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "Naval Base", "latency_ms": 142.4272060394287, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Naval Base", "latency_ms": 146.97599411010742, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2066}, "4": {"k": 4, "answer": "Naval Base", "latency_ms": 231.27079010009766, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2755}, "5": {"k": 5, "answer": "Coaling and Naval station", "latency_ms": 410.68172454833984, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3385}, "6": {"k": 6, "answer": "Coaling and Naval station", "latency_ms": 159.7890853881836, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 4026}}}
{"qid": "1265966537878407180", "question": "who was the 19th c. artist who was both painter and graphic designer", "gold_answers": ["René Georges Hermann - Paul"], "shots": {"0": {"k": 0, "answer": "James Abbott McNeill Whistler", "latency_ms": 411.84329986572266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Karl Postl", "latency_ms": 185.12511253356934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "Karl Postl", "latency_ms": 113.29364776611328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "Karl Postl", "latency_ms": 132.8752040863037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "Karl Postl", "latency_ms": 176.84173583984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2517}, "5": {"k": 5, "answer": "Karl Postl", "latency_ms": 152.49085426330566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3183}, "6": {"k": 6, "answer": "Karl Postl", "latency_ms": 249.90081787109375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3865}}}
{"qid": "6301453363028517703", "question": "what is dj's boyfriends name on full house", "gold_answers": ["Steven `` Steve '' Hale", "rich kid Nelson", "Viper", "Steve Hale"], "shots": {"0": {"k": 0, "answer": "D.J.'s boyfriend's name on Full House is **Eric**.", "latency_ms": 770.6429958343506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Steve Hale", "latency_ms": 149.2447853088379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 631}, "2": {"k": 2, "answer": "Steve Hale", "latency_ms": 178.9095401763916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Steve Hale", "latency_ms": 170.1943874359131, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1903}, "4": {"k": 4, "answer": "Steve Hale", "latency_ms": 98.30975532531738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2519}, "5": {"k": 5, "answer": "Nelson Burkhard", "latency_ms": 329.99253273010254, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3162}, "6": {"k": 6, "answer": "Nelson Burkhard", "latency_ms": 239.7773265838623, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3761}}}
{"qid": "3826862253571581938", "question": "who plays brad pitt's daughter in moneyball", "gold_answers": ["Kerris Lilla Dorsey"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 163.33770751953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kerris Dorsey", "latency_ms": 225.44479370117188, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "Kerris Dorsey", "latency_ms": 371.6294765472412, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Kerris Dorsey", "latency_ms": 161.34285926818848, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1904}, "4": {"k": 4, "answer": "Kerris Dorsey", "latency_ms": 263.974666595459, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2530}, "5": {"k": 5, "answer": "Kerris Dorsey", "latency_ms": 192.3081874847412, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Kerris Dorsey", "latency_ms": 339.0352725982666, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3806}}}
{"qid": "254065856937943955", "question": "who won season 2 of real chance of love", "gold_answers": ["Jackie DaFonseca", "Kamille Leai", "Hot Wings", "Doll"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 273.543119430542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 250.1676082611084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "Team 2 (EES)", "latency_ms": 375.95653533935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "EES (Exotic Endangered Species)", "latency_ms": 610.9185218811035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1878}, "4": {"k": 4, "answer": "EES (Exotic Endangered Species)", "latency_ms": 509.1097354888916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "EES (Exotic Endangered Species)", "latency_ms": 195.36972045898438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "Impeaches won the challenge and won dates in season 2 of Real Chance of Love.", "latency_ms": 735.5985641479492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3733}}}
{"qid": "-953849400724466906", "question": "where did huntington's disease get its name", "gold_answers": ["the physician George Huntington"], "shots": {"0": {"k": 0, "answer": "Dr. George Huntington", "latency_ms": 79.87737655639648, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "George Huntington", "latency_ms": 122.46298789978027, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "George Huntington", "latency_ms": 172.81079292297363, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1347}, "3": {"k": 3, "answer": "George Huntington", "latency_ms": 193.55297088623047, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1994}, "4": {"k": 4, "answer": "George Huntington", "latency_ms": 227.3550033569336, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2668}, "5": {"k": 5, "answer": "George Huntington", "latency_ms": 167.27614402770996, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3360}, "6": {"k": 6, "answer": "George Huntington", "latency_ms": 262.56299018859863, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3985}}}
{"qid": "664126784032076855", "question": "which nfl coach has the most superbowl rings", "gold_answers": ["Bill Belichick"], "shots": {"0": {"k": 0, "answer": "Bill Belichick", "latency_ms": 116.5626049041748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bill Belichick", "latency_ms": 119.0330982208252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "Bill Belichick", "latency_ms": 98.29521179199219, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1222}, "3": {"k": 3, "answer": "Bill Belichick", "latency_ms": 95.33548355102539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1811}, "4": {"k": 4, "answer": "Bill Belichick", "latency_ms": 97.55802154541016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2412}, "5": {"k": 5, "answer": "Bill Belichick", "latency_ms": 121.42300605773926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3028}, "6": {"k": 6, "answer": "Bill Belichick", "latency_ms": 188.84968757629395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3685}}}
{"qid": "-5407234157766859145", "question": "turkey stuffed with a duck stuffed with a chicken", "gold_answers": ["Turducken"], "shots": {"0": {"k": 0, "answer": "Turkey", "latency_ms": 40.14778137207031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "turducken", "latency_ms": 136.2318992614746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 614}, "2": {"k": 2, "answer": "turducken", "latency_ms": 309.6158504486084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1210}, "3": {"k": 3, "answer": "turducken", "latency_ms": 137.17341423034668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1849}, "4": {"k": 4, "answer": "turducken", "latency_ms": 187.7448558807373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2478}, "5": {"k": 5, "answer": "turducken", "latency_ms": 146.5322971343994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3113}, "6": {"k": 6, "answer": "turducken", "latency_ms": 129.20022010803223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3767}}}
{"qid": "2884966474182044344", "question": "who won the first season of america's got talent", "gold_answers": ["Bianca Ryan"], "shots": {"0": {"k": 0, "answer": "David Letterman", "latency_ms": 67.76118278503418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bianca Ryan", "latency_ms": 361.39631271362305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "Bianca Ryan", "latency_ms": 171.68855667114258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1273}, "3": {"k": 3, "answer": "Bianca Ryan", "latency_ms": 201.43365859985352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1929}, "4": {"k": 4, "answer": "Bianca Ryan", "latency_ms": 275.67148208618164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "Bianca Ryan", "latency_ms": 340.53826332092285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Bianca Ryan", "latency_ms": 248.95858764648438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3823}}}
{"qid": "-4485639916525374363", "question": "how many books are in the one piece series", "gold_answers": ["more than 80", "83"], "shots": {"0": {"k": 0, "answer": "1000+", "latency_ms": 191.53809547424316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 90.45267105102539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 213.05394172668457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1320}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 109.16543006896973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1907}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 171.04578018188477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2574}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 219.90323066711426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3211}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 262.61234283447266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3894}}}
{"qid": "-5315423524940108616", "question": "where are the winter olympic games being held this year", "gold_answers": ["Pyeongchang County , South Korea"], "shots": {"0": {"k": 0, "answer": "2022 Winter Olympics: Beijing, China", "latency_ms": 487.9333972930908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Beijing and Hebei province, China", "latency_ms": 346.5461730957031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 134.0646743774414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 130.4023265838623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1868}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 246.1540699005127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2509}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 285.2466106414795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3152}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 487.8215789794922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3803}}}
{"qid": "-5061370765188535062", "question": "how many quarterbacks have a receiving touchdown in the superbowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "12", "latency_ms": 103.11198234558105, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 107.26499557495117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 291.32866859436035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 185.40143966674805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 352.125883102417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2515}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 321.7947483062744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3142}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 391.2386894226074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3825}}}
{"qid": "-346866783760651662", "question": "when did ga state get a football team", "gold_answers": ["2010"], "shots": {"0": {"k": 0, "answer": "1933", "latency_ms": 248.34108352661133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 247.14422225952148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 351.6697883605957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 262.4235153198242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1939}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 319.4289207458496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2630}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 293.2407855987549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3254}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 189.83793258666992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3855}}}
{"qid": "1627235089487061878", "question": "when does the first nba basketball game start", "gold_answers": ["October 17 , 2017"], "shots": {"0": {"k": 0, "answer": "October 23, 2023", "latency_ms": 334.9728584289551, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 184.4959259033203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "March 2, 1951", "latency_ms": 280.9133529663086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "March 2, 1951", "latency_ms": 470.77250480651855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 136.2783908843994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2614}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 126.88612937927246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3237}, "6": {"k": 6, "answer": "1947", "latency_ms": 193.40825080871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3906}}}
{"qid": "6217752837777787594", "question": "who plays heather in beauty and the beast", "gold_answers": ["Nicole Gale Anderson"], "shots": {"0": {"k": 0, "answer": "Linda Hamilton", "latency_ms": 195.98674774169922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nicole Gale Anderson", "latency_ms": 276.34668350219727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 701}, "2": {"k": 2, "answer": "Nicole Gale Anderson", "latency_ms": 258.4853172302246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "Nicole Gale Anderson", "latency_ms": 341.2806987762451, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Nicole Gale Anderson", "latency_ms": 198.84443283081055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2681}, "5": {"k": 5, "answer": "Nicole Gale Anderson", "latency_ms": 289.3106937408447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3318}, "6": {"k": 6, "answer": "Nicole Gale Anderson", "latency_ms": 325.41847229003906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3948}}}
{"qid": "7368254478874801356", "question": "who is the head of the department of homeland security 2017", "gold_answers": ["Kirstjen Nielsen"], "shots": {"0": {"k": 0, "answer": "John F. Kelly", "latency_ms": 294.96097564697266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John F. Kelly", "latency_ms": 189.46480751037598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "John F. Kelly", "latency_ms": 215.80147743225098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "John F. Kelly", "latency_ms": 351.52697563171387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2083}, "4": {"k": 4, "answer": "John F. Kelly", "latency_ms": 277.64415740966797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2804}, "5": {"k": 5, "answer": "Kirstjen Nielsen", "latency_ms": 188.981294631958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3455}, "6": {"k": 6, "answer": "Kirstjen Nielsen", "latency_ms": 373.28314781188965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4168}}}
{"qid": "5009255319596563516", "question": "who has the most gold gloves at shortstop", "gold_answers": ["Ozzie Smith"], "shots": {"0": {"k": 0, "answer": "Manny Ramirez", "latency_ms": 84.18583869934082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ozzie Smith", "latency_ms": 117.16985702514648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Ozzie Smith", "latency_ms": 96.19355201721191, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1226}, "3": {"k": 3, "answer": "Ozzie Smith", "latency_ms": 304.92377281188965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1876}, "4": {"k": 4, "answer": "Omar Vizquel", "latency_ms": 160.5241298675537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2472}, "5": {"k": 5, "answer": "Ozzie Smith", "latency_ms": 271.6104984283447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3035}, "6": {"k": 6, "answer": "Omar Vizquel", "latency_ms": 372.39646911621094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3639}}}
{"qid": "7785057168624776860", "question": "who wore number 7 for the green bay packers", "gold_answers": ["Don Majkowski", "Quarterback Don Majkowski"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 213.50550651550293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 147.38774299621582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 250.99563598632812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 252.83145904541016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 180.79113960266113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2522}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 199.34773445129395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 247.7271556854248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3750}}}
{"qid": "-908463397631188227", "question": "how long did the democrats control the house and senate", "gold_answers": ["57 yrs", "35 yrs"], "shots": {"0": {"k": 0, "answer": "2006–2010", "latency_ms": 256.7005157470703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1932", "latency_ms": 260.88786125183105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "12 years (House) and until 1980 (Senate)", "latency_ms": 244.66919898986816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1322}, "3": {"k": 3, "answer": "12 years", "latency_ms": 195.90520858764648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "1932 to 1938", "latency_ms": 204.62274551391602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2627}, "5": {"k": 5, "answer": "1930 to 1994 (House); most of that period (Senate)", "latency_ms": 614.1707897186279, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3332}, "6": {"k": 6, "answer": "1930 to 1994 (House); most of that period (Senate)", "latency_ms": 520.8816528320312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3994}}}
{"qid": "-7344570058818349307", "question": "who can be called a man of god", "gold_answers": ["prophets", "beloved religious leaders"], "shots": {"0": {"k": 0, "answer": "A person who lives according to God's teachings and values.", "latency_ms": 385.7605457305908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Choi Kang-ta", "latency_ms": 309.0977668762207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 561}, "2": {"k": 2, "answer": "Choi Kang-ta", "latency_ms": 249.07493591308594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1127}, "3": {"k": 3, "answer": "Song Il-gook", "latency_ms": 112.08820343017578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1765}, "4": {"k": 4, "answer": "A man called God", "latency_ms": 266.53170585632324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2343}, "5": {"k": 5, "answer": "A man called God (2010 South Korean television series)", "latency_ms": 477.01478004455566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2965}, "6": {"k": 6, "answer": "Song Il-gook", "latency_ms": 223.03462028503418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3595}}}
{"qid": "-5255735265739582707", "question": "a system of fortifications along france's border", "gold_answers": ["Maginot Line", "The Maginot Line"], "shots": {"0": {"k": 0, "answer": "Maginot Line", "latency_ms": 148.03385734558105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Séré de Rivières system", "latency_ms": 200.25038719177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "Séré de Rivières system", "latency_ms": 236.30261421203613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "Séré de Rivières system", "latency_ms": 387.7544403076172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "Séré de Rivières system", "latency_ms": 383.5563659667969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2654}, "5": {"k": 5, "answer": "Séré de Rivières system", "latency_ms": 168.90478134155273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3307}, "6": {"k": 6, "answer": "Séré de Rivières system", "latency_ms": 317.180871963501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3965}}}
{"qid": "-521349963474269802", "question": "who wrote ain't living long like this", "gold_answers": ["Rodney Crowell"], "shots": {"0": {"k": 0, "answer": "Luther Vandross", "latency_ms": 103.35659980773926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rodney Crowell", "latency_ms": 323.047399520874, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "Rodney Crowell", "latency_ms": 165.82274436950684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1339}, "3": {"k": 3, "answer": "Rodney Crowell", "latency_ms": 406.6319465637207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1949}, "4": {"k": 4, "answer": "Rodney Crowell", "latency_ms": 267.92383193969727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2545}, "5": {"k": 5, "answer": "Rodney Crowell", "latency_ms": 245.70775032043457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3201}, "6": {"k": 6, "answer": "Rodney Crowell", "latency_ms": 283.341646194458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3815}}}
{"qid": "-7607504458781868831", "question": "what is the name of the skin between your nostrils", "gold_answers": ["the nasal septum", "septum"], "shots": {"0": {"k": 0, "answer": "nasal septum", "latency_ms": 212.45479583740234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "curtain of skin", "latency_ms": 312.0846748352051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "curtain of skin", "latency_ms": 144.68026161193848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "skirt-shaped curtain of skin", "latency_ms": 193.25995445251465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "skirt-shaped curtain of skin", "latency_ms": 137.31145858764648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2485}, "5": {"k": 5, "answer": "curtain of skin", "latency_ms": 304.63266372680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3078}, "6": {"k": 6, "answer": "skirt-shaped curtain of skin", "latency_ms": 240.3271198272705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3702}}}
{"qid": "-1142715461435497032", "question": "what is the biggest town in west virginia", "gold_answers": ["Charleston"], "shots": {"0": {"k": 0, "answer": "Charleston", "latency_ms": 179.2006492614746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 109.91597175598145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 126.8775463104248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1200}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 267.5611972808838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1847}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 163.72966766357422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2484}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 260.3416442871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3111}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 208.82463455200195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3721}}}
{"qid": "-3617986561170614700", "question": "when does monday night raw come on hulu", "gold_answers": ["the following day"], "shots": {"0": {"k": 0, "answer": "Monday Night Raw airs on Hulu at 8:00 PM ET.", "latency_ms": 578.6547660827637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 152.73189544677734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 554}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 247.95174598693848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "the following day", "latency_ms": 228.6355495452881, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1802}, "4": {"k": 4, "answer": "the following day", "latency_ms": 149.74284172058105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2488}, "5": {"k": 5, "answer": "every Wednesday", "latency_ms": 119.95196342468262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "every Wednesday", "latency_ms": 158.95748138427734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3823}}}
{"qid": "-7768138227276540998", "question": "who become ceo of wipro company in 2016", "gold_answers": ["Abid Ali Neemuchwala"], "shots": {"0": {"k": 0, "answer": "S. Gopalakrishnan", "latency_ms": 285.1526737213135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Abidali Neemuchwala", "latency_ms": 199.16725158691406, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Abidali Neemuchwala", "latency_ms": 402.4195671081543, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Abidali Neemuchwala", "latency_ms": 501.3866424560547, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2047}, "4": {"k": 4, "answer": "Abidali Neemuchwala", "latency_ms": 671.703577041626, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2675}, "5": {"k": 5, "answer": "Abidali Neemuchwala", "latency_ms": 331.80785179138184, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3341}, "6": {"k": 6, "answer": "Abidali Neemuchwala", "latency_ms": 532.1109294891357, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3981}}}
{"qid": "-145926233057232882", "question": "what is the breakdown product formed when one phosphate group is removed from atp", "gold_answers": ["adenosine diphosphate ( ADP )"], "shots": {"0": {"k": 0, "answer": "ADP", "latency_ms": 59.04078483581543, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ADP", "latency_ms": 120.24831771850586, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 774}, "2": {"k": 2, "answer": "ADP", "latency_ms": 160.12167930603027, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1479}, "3": {"k": 3, "answer": "ADP", "latency_ms": 134.29999351501465, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2215}, "4": {"k": 4, "answer": "ADP", "latency_ms": 112.98370361328125, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2886}, "5": {"k": 5, "answer": "ADP", "latency_ms": 209.12408828735352, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3568}, "6": {"k": 6, "answer": "ADP", "latency_ms": 356.72807693481445, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4249}}}
{"qid": "-2520765213268223500", "question": "ahana from dil sambhal ja zara real name", "gold_answers": ["Smriti Kalra"], "shots": {"0": {"k": 0, "answer": "Aruna Singh", "latency_ms": 182.13653564453125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ahana", "latency_ms": 86.83252334594727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 95.55459022521973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 192.77524948120117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1826}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 156.92377090454102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2378}, "5": {"k": 5, "answer": "Smiriti Kalra", "latency_ms": 336.18807792663574, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3013}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 345.6263542175293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3611}}}
{"qid": "-7267574651947029426", "question": "to transplant a nucleus from one cell to another cell a scientist would use", "gold_answers": ["somatic cell nuclear transfer"], "shots": {"0": {"k": 0, "answer": "nuclear transfer", "latency_ms": 285.72821617126465, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "somatic cell nuclear transfer", "latency_ms": 239.77065086364746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "somatic cell nuclear transfer (SCNT)", "latency_ms": 358.43610763549805, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 1320}, "3": {"k": 3, "answer": "somatic cell nuclear transfer", "latency_ms": 249.2232322692871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1936}, "4": {"k": 4, "answer": "somatic cell nuclear transfer", "latency_ms": 248.57711791992188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2554}, "5": {"k": 5, "answer": "somatic cell nuclear transfer", "latency_ms": 390.00868797302246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3217}, "6": {"k": 6, "answer": "somatic cell nuclear transfer", "latency_ms": 514.7466659545898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3886}}}
{"qid": "3840901317699168424", "question": "what does a bull shark tooth look like", "gold_answers": ["needle - like teeth", "needle - like"], "shots": {"0": {"k": 0, "answer": "Pointed, sharp, and serrated", "latency_ms": 471.85349464416504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "needle-like", "latency_ms": 71.89750671386719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "Pointed lower teeth with triangular upper teeth", "latency_ms": 435.9757900238037, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "pointed lower with triangular upper teeth", "latency_ms": 248.73900413513184, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Pointed lower teeth with triangular upper teeth", "latency_ms": 204.96749877929688, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2580}, "5": {"k": 5, "answer": "pointed lower with triangular upper teeth", "latency_ms": 232.26261138916016, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 270.56026458740234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3925}}}
{"qid": "-1163524811252371834", "question": "who played the girl in my two dads", "gold_answers": ["Staci Keanan"], "shots": {"0": {"k": 0, "answer": "Morgan Freeman", "latency_ms": 261.3551616668701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amy Hathaway", "latency_ms": 169.15273666381836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "Amy Hathaway", "latency_ms": 201.03907585144043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Amy Hathaway", "latency_ms": 90.28911590576172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1903}, "4": {"k": 4, "answer": "Amy Hathaway", "latency_ms": 344.5706367492676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2501}, "5": {"k": 5, "answer": "Amy Hathaway", "latency_ms": 185.45770645141602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3094}, "6": {"k": 6, "answer": "Amy Hathaway", "latency_ms": 168.87378692626953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3681}}}
{"qid": "-8152430794227425375", "question": "what type of planet is neptune known as", "gold_answers": ["ice giants", "giant"], "shots": {"0": {"k": 0, "answer": "ice giant", "latency_ms": 78.13453674316406, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "gas giant", "latency_ms": 205.75380325317383, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 589}, "2": {"k": 2, "answer": "dwarf planet", "latency_ms": 202.0857334136963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1164}, "3": {"k": 3, "answer": "ice giant", "latency_ms": 171.2512969970703, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1790}, "4": {"k": 4, "answer": "ice giant", "latency_ms": 178.74836921691895, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2420}, "5": {"k": 5, "answer": "ice giant", "latency_ms": 240.72909355163574, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3109}, "6": {"k": 6, "answer": "ice giant", "latency_ms": 247.63965606689453, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3756}}}
{"qid": "-5738106146117683016", "question": "when do love and hip hop new york come back on", "gold_answers": ["November 13 , 2017", "October 30 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 122.84278869628906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 30, 2017", "latency_ms": 420.2890396118164, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "October 30, 2017", "latency_ms": 485.21900177001953, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1194}, "3": {"k": 3, "answer": "November 26, 2018", "latency_ms": 303.3328056335449, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1828}, "4": {"k": 4, "answer": "November 26, 2018", "latency_ms": 395.75958251953125, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2455}, "5": {"k": 5, "answer": "November 26, 2018", "latency_ms": 363.8346195220947, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3123}, "6": {"k": 6, "answer": "November 26, 2018", "latency_ms": 499.5908737182617, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3735}}}
{"qid": "-3970079294139411862", "question": "how many gallons of water in the gulf of mexico", "gold_answers": ["660 quadrillion US gallons"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 164.7934913635254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "660 quadrillion US gallons", "latency_ms": 269.8845863342285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "660 quadrillion US gallons", "latency_ms": 334.1667652130127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1258}, "3": {"k": 3, "answer": "643 million gallons", "latency_ms": 375.2098083496094, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1920}, "4": {"k": 4, "answer": "2.5 million km³ or 600,000 cu mi (550 quadrillion Imperial gallons, 660 quadrillion US gallons)", "latency_ms": 689.7578239440918, "em": 0.0, "f1": 0.4210526315789474, "containment": 1.0, "context_chars": 2541}, "5": {"k": 5, "answer": "2,500 quadrillion gallons", "latency_ms": 255.99956512451172, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3166}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 257.9813003540039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3836}}}
{"qid": "810772972080024175", "question": "anastomosis between the epididymis and the vas deferens", "gold_answers": ["Vasoepididymostomy"], "shots": {"0": {"k": 0, "answer": "ampullary anastomosis", "latency_ms": 181.1513900756836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "vasoepididymostomy", "latency_ms": 188.89117240905762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 691}, "2": {"k": 2, "answer": "vasoepididymostomy", "latency_ms": 308.04944038391113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1296}, "3": {"k": 3, "answer": "vasoepididymostomy", "latency_ms": 181.07867240905762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1947}, "4": {"k": 4, "answer": "vasoepididymostomy", "latency_ms": 381.3929557800293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2623}, "5": {"k": 5, "answer": "vasoepididymostomy", "latency_ms": 738.166093826294, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3304}, "6": {"k": 6, "answer": "vasoepididymostomy", "latency_ms": 830.4159641265869, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4057}}}
{"qid": "-4044344454441564632", "question": "who is given credit for inventing the aqua lung", "gold_answers": ["Jacques Cousteau", "Émile Gagnan", "engineer Émile Gagnan"], "shots": {"0": {"k": 0, "answer": "Jacques Cousteau", "latency_ms": 131.6976547241211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yves le Prieur", "latency_ms": 274.88064765930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "Émile Gagnan and Jacques Cousteau", "latency_ms": 202.43215560913086, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1349}, "3": {"k": 3, "answer": "Émile Gagnan and Jacques Cousteau", "latency_ms": 386.51490211486816, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2041}, "4": {"k": 4, "answer": "Émile Gagnan and Jacques Cousteau", "latency_ms": 504.47940826416016, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2666}, "5": {"k": 5, "answer": "Émile Gagnan and Jacques Cousteau", "latency_ms": 738.4085655212402, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3323}, "6": {"k": 6, "answer": "Émile Gagnan and Jacques Cousteau", "latency_ms": 380.39422035217285, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4022}}}
{"qid": "950913319015411203", "question": "where did the name huey helicopter come from", "gold_answers": ["originally designated HU - 1"], "shots": {"0": {"k": 0, "answer": "Huey came from \"Huey,\" a nickname for \"Huey,\" a name given to the helicopter by U.S. Army personnel during the Vietnam War. The name was derived from the nickname \"Huey\" for the helicopter's model, the UH-1 Iroquois. The name \"Huey\" was a phonetic shortening of \"Huey,\" a name popularized by the 1950s and 1960s, and was used by soldiers to refer to the aircraft. The official name of the helicopter is the UH-1 Iroquois, but it became widely known as the \"Huey.\" The name \"Huey\" was not derived from a specific person or event, but rather from the soldiers' informal use of the name. The name \"Huey\" was used to refer to the helicopter, and it became a common term in military and popular culture. The name \"Huey\" was not derived from a specific person or event, but rather from the soldiers' informal use of the name. The name \"Huey\" was used to refer to the helicopter, and it became a common term in military and popular culture. The name", "latency_ms": 7062.320232391357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "HU-1 designation", "latency_ms": 136.55400276184082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "HU-1 designation", "latency_ms": 322.04723358154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1376}, "3": {"k": 3, "answer": "HU-1 designation", "latency_ms": 243.3469295501709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2040}, "4": {"k": 4, "answer": "HU-1 designation", "latency_ms": 284.88659858703613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2664}, "5": {"k": 5, "answer": "HU-1 designation", "latency_ms": 310.7304573059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3339}, "6": {"k": 6, "answer": "HU-1 designation", "latency_ms": 259.1845989227295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3974}}}
{"qid": "-6762183708006311163", "question": "when did dragon ball super tournament of power start", "gold_answers": ["February 19 , 2017"], "shots": {"0": {"k": 0, "answer": "2018", "latency_ms": 158.6592197418213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 92.16976165771484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 246.22535705566406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 309.0786933898926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 183.9747428894043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2478}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 308.66122245788574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3114}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 268.4602737426758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3750}}}
{"qid": "7143040220722532389", "question": "when was it was not death for i stood up published", "gold_answers": ["1890", "1891"], "shots": {"0": {"k": 0, "answer": "1998", "latency_ms": 107.72180557250977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 83.90474319458008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 570}, "2": {"k": 2, "answer": "8 October 2013", "latency_ms": 408.18309783935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1152}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 109.52115058898926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1747}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 286.4408493041992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2427}, "5": {"k": 5, "answer": "8 October 2013", "latency_ms": 367.5076961517334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3078}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 347.05352783203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3668}}}
{"qid": "-5748368670037082784", "question": "what is the definition of the name thomas", "gold_answers": ["twin", "`` twin ''"], "shots": {"0": {"k": 0, "answer": "Male given name of Hebrew origin, meaning \"twin\" or \"town\"", "latency_ms": 537.0917320251465, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 221.1010456085205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "Vague and yet distinguished; belongs to three or four persons in antiquity, none of any great importance.", "latency_ms": 659.390926361084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 293.20716857910156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2013}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 162.6274585723877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2699}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 125.15568733215332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3388}, "6": {"k": 6, "answer": "vague and yet distinguished; conveys no definite suggestion", "latency_ms": 235.00967025756836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3999}}}
{"qid": "8190949321615211886", "question": "actress who plays penelope garcia on criminal minds", "gold_answers": ["Kirsten Simone Vangsness"], "shots": {"0": {"k": 0, "answer": "Jade Weller", "latency_ms": 128.10635566711426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kirsten Vangsness", "latency_ms": 175.89497566223145, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "Kirsten Vangsness", "latency_ms": 123.81553649902344, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1307}, "3": {"k": 3, "answer": "Kirsten Vangsness", "latency_ms": 136.07168197631836, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "Kirsten Vangsness", "latency_ms": 182.8596591949463, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2731}, "5": {"k": 5, "answer": "Kirsten Vangsness", "latency_ms": 264.67084884643555, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3371}, "6": {"k": 6, "answer": "Kirsten Vangsness", "latency_ms": 319.3976879119873, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3983}}}
{"qid": "-9203958203595622889", "question": "who is president of india in present time", "gold_answers": ["Ram Nath Kovind"], "shots": {"0": {"k": 0, "answer": "Narendra Modi", "latency_ms": 133.10766220092773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 320.9717273712158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 219.09856796264648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1320}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 139.38403129577637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 231.46986961364746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 248.58999252319336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3237}, "6": {"k": 6, "answer": "Ram Nath Kovind", "latency_ms": 279.05821800231934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3837}}}
{"qid": "-2349691009719617713", "question": "why did kevin can't wait wife leave the show", "gold_answers": ["creative reasons"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 312.4866485595703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 251.85871124267578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 228.7425994873047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 98.99306297302246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1804}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 162.88304328918457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2423}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 300.5635738372803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3048}, "6": {"k": 6, "answer": "Erinn Hayes' character Donna died; no specific cause given.", "latency_ms": 556.2441349029541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3661}}}
{"qid": "1442521968114516256", "question": "when did season 4 of glee come out", "gold_answers": ["September 13 , 2012"], "shots": {"0": {"k": 0, "answer": "2012", "latency_ms": 75.72770118713379, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 13, 2012", "latency_ms": 522.0675468444824, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "September 13, 2012", "latency_ms": 740.9594058990479, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1304}, "3": {"k": 3, "answer": "September 13, 2012", "latency_ms": 249.57680702209473, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "September 13, 2012", "latency_ms": 344.20013427734375, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "September 13, 2012", "latency_ms": 268.85437965393066, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3191}, "6": {"k": 6, "answer": "September 13, 2012", "latency_ms": 280.99966049194336, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3843}}}
{"qid": "4920082918364942541", "question": "who were the major countries involved in the cold war", "gold_answers": ["the Soviet Union", "the United States"], "shots": {"0": {"k": 0, "answer": "USA, USSR, UK, France, China, Canada, West Germany, East Germany", "latency_ms": 618.6213493347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "United States, Soviet Union, United Kingdom, China, France, Germany, Japan, Canada, Italy, Turkey, India, Brazil, Egypt, Iran, South Africa, North Korea, South Korea", "latency_ms": 845.3261852264404, "em": 0.0, "f1": 0.16, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "USA, USSR, NATO, Warsaw Pact", "latency_ms": 458.06288719177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "USA, USSR, NATO, Warsaw Pact", "latency_ms": 573.3792781829834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "United States, Soviet Union, NATO, Warsaw Pact", "latency_ms": 548.4440326690674, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 2606}, "5": {"k": 5, "answer": "United States, Soviet Union, Great Britain, France, Germany, NATO, Warsaw Pact", "latency_ms": 622.1706867218018, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 3277}, "6": {"k": 6, "answer": "United States, Soviet Union, Great Britain, France, Germany, NATO, Warsaw Pact", "latency_ms": 546.8320846557617, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 3956}}}
{"qid": "2607341085762662184", "question": "what is the main use of the eiffel tower in modern times", "gold_answers": ["visited paid monument", "paid monument"], "shots": {"0": {"k": 0, "answer": "Tourist attraction", "latency_ms": 118.9873218536377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "symbol of Paris and the city in popular culture", "latency_ms": 570.2650547027588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "radio and digital television signals transmission", "latency_ms": 248.68464469909668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1216}, "3": {"k": 3, "answer": "radio and digital television signals transmission", "latency_ms": 363.56163024902344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1788}, "4": {"k": 4, "answer": "radio and digital television signals transmission", "latency_ms": 468.41931343078613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2400}, "5": {"k": 5, "answer": "radio and digital television signals transmission", "latency_ms": 144.98114585876465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "radio and digital television signals transmission", "latency_ms": 181.30135536193848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3681}}}
{"qid": "3221048264431718328", "question": "sweet leavened bread prepared for easter in romania", "gold_answers": ["Cozonac", "Kozunak"], "shots": {"0": {"k": 0, "answer": "Pâine de Paște", "latency_ms": 228.03974151611328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cozonac", "latency_ms": 220.6137180328369, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 123.07953834533691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "cozonac", "latency_ms": 260.8785629272461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1964}, "4": {"k": 4, "answer": "cozonac", "latency_ms": 177.19101905822754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2604}, "5": {"k": 5, "answer": "Pasca", "latency_ms": 179.12650108337402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3271}, "6": {"k": 6, "answer": "Pasca", "latency_ms": 202.0118236541748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3940}}}
{"qid": "-5864856625806411702", "question": "chief ministers of tamil nadu mentioned on wikipedia", "gold_answers": ["Tanguturi Prakasam", "Ramakrishna Ranga Rao", "Janaki Ramachandran", "O. Panneerselvam", "Raja of Panagal", "O.P. Ramaswamy Reddiyar", "P.S. Kumaraswamy Raja", "C. Rajagopalachari", "B. Munuswamy Naidu", "A. Subbarayalu Reddiar", "K. Palaniswami", "P.T. Rajan", "M. Karunanidhi", "C.N. Annadurai", "V.R. Nedunchezhiyan", "J. Jayalalithaa", "Kurma Venkata Reddy Naidu", "M.G. Ramachandran", "P. Subbarayan"], "shots": {"0": {"k": 0, "answer": "J. Jayalalithaa, M. Karunanidhi, Edappadi K. Palaniswami, O. Panneerselvam, A. G. K. M. S. R. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R", "latency_ms": 7653.611183166504, "em": 0.0, "f1": 0.03305785123966942, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 212.55230903625488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "M. Karunanidhi, Jayalalithaa, K. Anbazhagan, R. Venkataraman, R. M. Veerappan, G. K. Moopanar, T. T. V. Dhinakaran, La Ganesan", "latency_ms": 2167.008876800537, "em": 0.0, "f1": 0.19047619047619052, "containment": 1.0, "context_chars": 1382}, "3": {"k": 3, "answer": "M. Karunanidhi, J. Jayalalithaa, M. G. Ramachandran", "latency_ms": 814.4867420196533, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "M. Karunanidhi, Jayalalithaa, M. G. Ramachandran", "latency_ms": 773.2253074645996, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2651}, "5": {"k": 5, "answer": "M. Karunanidhi, J. Jayalalithaa, M. G. Ramachandran", "latency_ms": 1000.6585121154785, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3310}, "6": {"k": 6, "answer": "M. Karunanidhi, J. Jayalalithaa, M. G. Ramachandran, Edappadi K. Palanisamy", "latency_ms": 1320.6799030303955, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 4006}}}
{"qid": "-6145868466021183224", "question": "who played solomon in little house on the prairie", "gold_answers": ["Todd Bridges"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 164.19672966003418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 123.76093864440918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 111.30189895629883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1182}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 266.5870189666748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 238.46697807312012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2494}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 152.06551551818848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3173}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 318.90010833740234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3811}}}
{"qid": "-3573392112612030278", "question": "who got the first arjun award in athletics", "gold_answers": ["Gurbachan Singh Randhawa"], "shots": {"0": {"k": 0, "answer": "K. M. S. S. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R. S. R.", "latency_ms": 7189.177751541138, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 118.12663078308105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 131.38651847839355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1414}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 231.3523292541504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2014}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 380.6331157684326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2695}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 177.7651309967041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3278}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 223.66690635681152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3901}}}
{"qid": "-8209571805051987276", "question": "what is the genus of a bald eagle", "gold_answers": ["Haliaeetus"], "shots": {"0": {"k": 0, "answer": "Haliaeetus", "latency_ms": 236.1907958984375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haliaeetus", "latency_ms": 289.08562660217285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 635}, "2": {"k": 2, "answer": "Haliaeetus", "latency_ms": 283.9159965515137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Haliaeetus", "latency_ms": 149.28722381591797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Haliaeetus", "latency_ms": 394.58513259887695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2566}, "5": {"k": 5, "answer": "Haliaeetus", "latency_ms": 228.47723960876465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "Haliaeetus", "latency_ms": 436.47027015686035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3885}}}
{"qid": "7062924428870783818", "question": "who directed the best years of our lives", "gold_answers": ["William Wyler"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 122.73430824279785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "William Wyler", "latency_ms": 154.69074249267578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "William Wyler", "latency_ms": 222.26834297180176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "William Wyler", "latency_ms": 180.21225929260254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1871}, "4": {"k": 4, "answer": "William Wyler", "latency_ms": 214.4920825958252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2504}, "5": {"k": 5, "answer": "William Wyler", "latency_ms": 368.6051368713379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3188}, "6": {"k": 6, "answer": "William Wyler", "latency_ms": 249.7868537902832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3777}}}
{"qid": "6882831655380911332", "question": "which british city is farthest from the sea", "gold_answers": ["Coton in the Elms"], "shots": {"0": {"k": 0, "answer": "Birmingham", "latency_ms": 86.71689033508301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Meriden", "latency_ms": 89.31350708007812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 101.30167007446289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 160.83812713623047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Meriden", "latency_ms": 90.69180488586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2504}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 268.6724662780762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 200.06918907165527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3781}}}
{"qid": "7895715200373578920", "question": "how many characters are present in icd-10 codes", "gold_answers": ["7"], "shots": {"0": {"k": 0, "answer": "7", "latency_ms": 41.182518005371094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "7", "latency_ms": 129.12607192993164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "7", "latency_ms": 284.7623825073242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1279}, "3": {"k": 3, "answer": "7", "latency_ms": 71.64311408996582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2015}, "4": {"k": 4, "answer": "7", "latency_ms": 199.8586654663086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2601}, "5": {"k": 5, "answer": "7", "latency_ms": 123.53038787841797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3256}, "6": {"k": 6, "answer": "7", "latency_ms": 104.82311248779297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3894}}}
{"qid": "-8464536395541330825", "question": "which layer of the meninges is connected to the brain", "gold_answers": ["pia mater", "The pia mater"], "shots": {"0": {"k": 0, "answer": "dura mater", "latency_ms": 72.0360279083252, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "pia mater", "latency_ms": 142.09628105163574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 697}, "2": {"k": 2, "answer": "pia mater", "latency_ms": 265.2609348297119, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "pia mater", "latency_ms": 253.0832290649414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1929}, "4": {"k": 4, "answer": "pia mater", "latency_ms": 323.3215808868408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2532}, "5": {"k": 5, "answer": "pia mater", "latency_ms": 441.53833389282227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3184}, "6": {"k": 6, "answer": "pia mater", "latency_ms": 328.5560607910156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3791}}}
{"qid": "-4392475526001139368", "question": "who was first governor general of british india", "gold_answers": ["Warren Hastings", "Louis Mountbatten"], "shots": {"0": {"k": 0, "answer": "Lord Cornwallis", "latency_ms": 100.56495666503906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Warren Hastings", "latency_ms": 226.29261016845703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 652}, "2": {"k": 2, "answer": "Lord William Bentinck", "latency_ms": 418.84875297546387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1350}, "3": {"k": 3, "answer": "Lord William Bentinck", "latency_ms": 151.04126930236816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "Lord William Bentinck", "latency_ms": 346.00090980529785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2697}, "5": {"k": 5, "answer": "Lord William Bentinck", "latency_ms": 212.1748924255371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3346}, "6": {"k": 6, "answer": "Lord William Bentinck", "latency_ms": 266.54720306396484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4016}}}
{"qid": "-4487724214437405890", "question": "where is the heart of palm on a palm tree", "gold_answers": ["the center core", "the inner core", "growing bud", "inner core and growing bud"], "shots": {"0": {"k": 0, "answer": "It is not on a palm tree.", "latency_ms": 320.7533359527588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "inner core and growing bud", "latency_ms": 103.23929786682129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "inner core and growing bud", "latency_ms": 393.91255378723145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "inner core and growing bud", "latency_ms": 171.59152030944824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1888}, "4": {"k": 4, "answer": "inner core and growing bud", "latency_ms": 473.0343818664551, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2583}, "5": {"k": 5, "answer": "inner core and growing bud of certain palm trees", "latency_ms": 304.87513542175293, "em": 0.0, "f1": 0.7142857142857143, "containment": 1.0, "context_chars": 3261}, "6": {"k": 6, "answer": "inner core and growing bud", "latency_ms": 327.6021480560303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3881}}}
{"qid": "-6162933554898709661", "question": "which player won the pga championship by the most shots", "gold_answers": ["Rory McIlroy"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 102.90908813476562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack Nicklaus", "latency_ms": 96.99296951293945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "Jack Nicklaus", "latency_ms": 128.88169288635254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1145}, "3": {"k": 3, "answer": "Jack Nicklaus", "latency_ms": 279.71529960632324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Jack Nicklaus", "latency_ms": 305.44447898864746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2343}, "5": {"k": 5, "answer": "Jack Nicklaus", "latency_ms": 151.4151096343994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2922}, "6": {"k": 6, "answer": "Jack Nicklaus", "latency_ms": 149.2018699645996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3533}}}
{"qid": "-1342189058950802702", "question": "who made the poppies at tower of london", "gold_answers": ["Tom Piper", "stage designer Tom Piper", "Paul Cummins"], "shots": {"0": {"k": 0, "answer": "The Royal British Legion", "latency_ms": 76.8136978149414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Paul Cummins", "latency_ms": 199.22614097595215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 631}, "2": {"k": 2, "answer": "Paul Cummins", "latency_ms": 162.40453720092773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1296}, "3": {"k": 3, "answer": "Paul Cummins and Johnson Tiles", "latency_ms": 248.66628646850586, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1980}, "4": {"k": 4, "answer": "Paul Cummins", "latency_ms": 323.2693672180176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2583}, "5": {"k": 5, "answer": "Paul Cummins", "latency_ms": 169.28863525390625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3205}, "6": {"k": 6, "answer": "Paul Cummins", "latency_ms": 215.72136878967285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3844}}}
{"qid": "-6531366728667964971", "question": "what is the inner core of the earth made from", "gold_answers": ["some other elements", "iron -- nickel alloy", "an iron -- nickel alloy"], "shots": {"0": {"k": 0, "answer": "Iron and nickel", "latency_ms": 230.49235343933105, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "iron–nickel alloy and some other elements", "latency_ms": 547.2121238708496, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 585}, "2": {"k": 2, "answer": "iron-nickel alloy", "latency_ms": 309.37981605529785, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "iron–nickel alloy", "latency_ms": 130.10501861572266, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1807}, "4": {"k": 4, "answer": "iron–nickel alloy", "latency_ms": 269.47641372680664, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2444}, "5": {"k": 5, "answer": "iron–nickel alloy", "latency_ms": 133.3785057067871, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3052}, "6": {"k": 6, "answer": "iron–nickel alloy", "latency_ms": 141.13283157348633, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3657}}}
{"qid": "608136254238749812", "question": "where did the british army launch a successful invasion in 1776", "gold_answers": ["Long Island", "New York"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 129.1816234588623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 150.91323852539062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "New York City", "latency_ms": 165.41552543640137, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1389}, "3": {"k": 3, "answer": "New Jersey", "latency_ms": 224.91121292114258, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2053}, "4": {"k": 4, "answer": "New Jersey", "latency_ms": 206.27689361572266, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2706}, "5": {"k": 5, "answer": "New Jersey", "latency_ms": 106.44984245300293, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3355}, "6": {"k": 6, "answer": "New Jersey", "latency_ms": 198.13823699951172, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4001}}}
{"qid": "-4049786002203271572", "question": "who wrote the guitar solo in beat it", "gold_answers": ["Eddie Van Halen"], "shots": {"0": {"k": 0, "answer": "Eddie Van Halen", "latency_ms": 249.00555610656738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Mayer", "latency_ms": 56.793212890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 534}, "2": {"k": 2, "answer": "Eddie Van Halen", "latency_ms": 103.76858711242676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1162}, "3": {"k": 3, "answer": "Eddie Van Halen", "latency_ms": 122.51806259155273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1910}, "4": {"k": 4, "answer": "Eddie Van Halen", "latency_ms": 187.544584274292, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2490}, "5": {"k": 5, "answer": "Eddie Van Halen", "latency_ms": 387.8037929534912, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3055}, "6": {"k": 6, "answer": "Eddie Van Halen", "latency_ms": 392.8961753845215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3780}}}
{"qid": "-2033893527164697325", "question": "who was the first executive president of guyana", "gold_answers": ["Forbes Burnham", "Arthur Chung"], "shots": {"0": {"k": 0, "answer": "Burns G. Phillips", "latency_ms": 238.11674118041992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Arthur Chung", "latency_ms": 61.22946739196777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 589}, "2": {"k": 2, "answer": "Forbes Burnham", "latency_ms": 164.08085823059082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1270}, "3": {"k": 3, "answer": "Forbes Burnham", "latency_ms": 254.7144889831543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Forbes Burnham", "latency_ms": 179.78191375732422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2494}, "5": {"k": 5, "answer": "Forbes Burnham", "latency_ms": 213.80949020385742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Forbes Burnham", "latency_ms": 255.570650100708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3830}}}
{"qid": "-7555953957057409422", "question": "who plays sven in the santa clarita diet", "gold_answers": ["Leo Howard"], "shots": {"0": {"k": 0, "answer": "Ethan Hawke", "latency_ms": 91.16005897521973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 302.976131439209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 115.97132682800293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1414}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 262.47382164001465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2077}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 106.91523551940918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2781}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 214.6918773651123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3415}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 312.1321201324463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4103}}}
{"qid": "4639443563976072562", "question": "term limits for house of representatives and senate", "gold_answers": ["Unlimited six - year terms", "Unlimited two - year terms"], "shots": {"0": {"k": 0, "answer": "House: 2 term limits; Senate: no term limits", "latency_ms": 503.41200828552246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "three two-year terms (six years) for Representatives; two four-year terms (eight years) for Senators", "latency_ms": 482.4051856994629, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "House: no term limits; Senate: two four-year terms and one two-year term each decade (staggered)", "latency_ms": 589.5483493804932, "em": 0.0, "f1": 0.2105263157894737, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "Indiana: no term limits", "latency_ms": 202.57139205932617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1991}, "4": {"k": 4, "answer": "two two-year terms (six years) for Representatives; two four-year terms (eight years) for Senators", "latency_ms": 366.3039207458496, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2654}, "5": {"k": 5, "answer": "Indiana: no limits; Michigan: House—3 two-year terms, Senate—2 four-year terms; Arkansas: 3 two-year terms (Rep), 2 four-year terms (Sen), obviated by 2014 amendment; Illinois: House—2-year terms, no limits; Senate—staggered 2-4-4, 4-2-4, or 4-4-2 terms.", "latency_ms": 2971.5542793273926, "em": 0.0, "f1": 0.05263157894736842, "containment": 0.0, "context_chars": 3297}, "6": {"k": 6, "answer": "Arizona: House - 4 consecutive terms (8 years); Senate - no term limits specified in context.", "latency_ms": 515.8915519714355, "em": 0.0, "f1": 0.11111111111111112, "containment": 0.0, "context_chars": 3964}}}
{"qid": "-7264742768431676142", "question": "who hosted and won the inagural world cup", "gold_answers": ["Uruguay"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 142.13871955871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 141.82591438293457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "Sweden hosted, Brazil won", "latency_ms": 179.33225631713867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 151.2753963470459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1820}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 118.63303184509277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2376}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 223.47569465637207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3001}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 171.8428134918213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3626}}}
{"qid": "-755777782301038229", "question": "iupac name of element with atomic number 107", "gold_answers": ["Bohrium", "bohrium"], "shots": {"0": {"k": 0, "answer": "Bohrium", "latency_ms": 143.90087127685547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "unnilseptium", "latency_ms": 169.79217529296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "bohrium", "latency_ms": 105.07893562316895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1303}, "3": {"k": 3, "answer": "bohrium", "latency_ms": 127.9151439666748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1963}, "4": {"k": 4, "answer": "bohrium", "latency_ms": 198.99845123291016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2653}, "5": {"k": 5, "answer": "bohrium", "latency_ms": 233.57772827148438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3315}, "6": {"k": 6, "answer": "bohrium", "latency_ms": 194.14639472961426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3976}}}
{"qid": "-564063817056958231", "question": "when does boomer find out she a cylon", "gold_answers": ["Kobol 's Last Gleaming"], "shots": {"0": {"k": 0, "answer": "Season 4, Episode 10 \"The Long Way Home\"", "latency_ms": 683.0358505249023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "when she finds the word Cylon written on her mirror", "latency_ms": 522.3050117492676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "when Boomer finds the word Cylon written on her mirror", "latency_ms": 304.32939529418945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Flesh and Bone", "latency_ms": 156.6476821899414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "Flesh and Bone", "latency_ms": 367.0072555541992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2486}, "5": {"k": 5, "answer": "Flesh and Bone (Battlestar Galactica)", "latency_ms": 487.26773262023926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Flesh and Bone", "latency_ms": 199.4473934173584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "2010294071842366580", "question": "who wrote the treasure of the sierra madre", "gold_answers": ["B. Traven", "bilingual German author B. Traven"], "shots": {"0": {"k": 0, "answer": "John Steinbeck", "latency_ms": 66.48755073547363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "B. Traven", "latency_ms": 120.00441551208496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "B. Traven", "latency_ms": 195.59073448181152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1252}, "3": {"k": 3, "answer": "B. Traven", "latency_ms": 109.58409309387207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "B. Traven", "latency_ms": 148.6203670501709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2503}, "5": {"k": 5, "answer": "B. Traven", "latency_ms": 166.0165786743164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3106}, "6": {"k": 6, "answer": "B. Traven", "latency_ms": 279.7045707702637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3741}}}
{"qid": "-838090964585984539", "question": "what was the name of darth vader star destroyer", "gold_answers": ["Devastator", "the Devastator"], "shots": {"0": {"k": 0, "answer": "Devastator", "latency_ms": 203.12094688415527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Executor", "latency_ms": 119.74430084228516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "Darth Vader's Star Destroyer", "latency_ms": 472.4106788635254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1411}, "3": {"k": 3, "answer": "Darth Vader's Star Destroyer", "latency_ms": 230.6520938873291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2104}, "4": {"k": 4, "answer": "Darth Vader's Star Destroyer", "latency_ms": 429.9592971801758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2751}, "5": {"k": 5, "answer": "Executor", "latency_ms": 179.16464805603027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3393}, "6": {"k": 6, "answer": "Executor", "latency_ms": 276.5183448791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4086}}}
{"qid": "5980486301760893723", "question": "what is the female lion called in lion king", "gold_answers": ["Nala"], "shots": {"0": {"k": 0, "answer": "Nala", "latency_ms": 87.2957706451416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nala", "latency_ms": 120.32723426818848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 683}, "2": {"k": 2, "answer": "Nala", "latency_ms": 75.27518272399902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1380}, "3": {"k": 3, "answer": "Nala", "latency_ms": 243.4384822845459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2014}, "4": {"k": 4, "answer": "Nala", "latency_ms": 122.91431427001953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "Nala", "latency_ms": 174.70884323120117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3238}, "6": {"k": 6, "answer": "Nala", "latency_ms": 106.3227653503418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3935}}}
{"qid": "8551231508158823921", "question": "how many seasons are in star wars the clone wars", "gold_answers": ["6"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 39.92867469787598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "three seasons", "latency_ms": 73.2564926147461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "3", "latency_ms": 121.74606323242188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1353}, "3": {"k": 3, "answer": "3", "latency_ms": 71.6087818145752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2000}, "4": {"k": 4, "answer": "7", "latency_ms": 76.57647132873535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2697}, "5": {"k": 5, "answer": "7", "latency_ms": 100.80885887145996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3340}, "6": {"k": 6, "answer": "6", "latency_ms": 159.4104766845703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3992}}}
{"qid": "-4664207169377167173", "question": "who sings gone gone gone she been gone so long", "gold_answers": ["Chilliwack"], "shots": {"0": {"k": 0, "answer": "Lil Wayne", "latency_ms": 116.33968353271484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 328.20987701416016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 115.60440063476562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 181.5347671508789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1833}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 186.52725219726562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2443}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 259.3810558319092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 223.94299507141113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3592}}}
{"qid": "-7605852330002608395", "question": "what does the air gap do on a dishwasher", "gold_answers": ["backflow prevention"], "shots": {"0": {"k": 0, "answer": "Prevents water from entering the drain during operation", "latency_ms": 432.5134754180908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "prevents drain water from backing up into the dishwasher", "latency_ms": 153.97930145263672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "prevents drain water from backing up into the dishwasher", "latency_ms": 363.22593688964844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1216}, "3": {"k": 3, "answer": "prevents drain water from backing up into the dishwasher", "latency_ms": 591.5234088897705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1792}, "4": {"k": 4, "answer": "prevents drain water from backing up into the dishwasher and contaminating dishes", "latency_ms": 781.8288803100586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2448}, "5": {"k": 5, "answer": "prevents drain water from backing up into the dishwasher and contaminating dishes", "latency_ms": 782.9480171203613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3046}, "6": {"k": 6, "answer": "prevents drain water from backing up into the dishwasher, possibly contaminating dishes", "latency_ms": 402.74691581726074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3702}}}
{"qid": "1447779709231013547", "question": "who does bryce dallas howard play in the grinch", "gold_answers": ["Surprised Who"], "shots": {"0": {"k": 0, "answer": "Maxwell \"Max\" Grinch", "latency_ms": 317.36278533935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 385.1637840270996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 273.8068103790283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1317}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 322.9391574859619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 288.3477210998535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2587}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 132.82537460327148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 192.66009330749512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3844}}}
{"qid": "2494339783007699672", "question": "where does dividends go on cash flow statement", "gold_answers": ["the financing activities section"], "shots": {"0": {"k": 0, "answer": "cash from financing activities", "latency_ms": 334.84888076782227, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "investing activities", "latency_ms": 96.45891189575195, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 677}, "2": {"k": 2, "answer": "operating activities", "latency_ms": 81.88557624816895, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1393}, "3": {"k": 3, "answer": "operating activities", "latency_ms": 158.3552360534668, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1994}, "4": {"k": 4, "answer": "operating activities", "latency_ms": 121.05178833007812, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2608}, "5": {"k": 5, "answer": "investing activities", "latency_ms": 252.24804878234863, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3291}, "6": {"k": 6, "answer": "operating activities", "latency_ms": 378.8001537322998, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3868}}}
{"qid": "-6195495799282225761", "question": "what is the 180 degree line of longitude called", "gold_answers": ["antimeridian", "180th meridian or antimeridian", "180th meridian"], "shots": {"0": {"k": 0, "answer": "Antimeridian", "latency_ms": 185.07814407348633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "180th meridian", "latency_ms": 405.165433883667, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "180th meridian", "latency_ms": 227.8308868408203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1264}, "3": {"k": 3, "answer": "180th meridian", "latency_ms": 349.49183464050293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "180th meridian", "latency_ms": 301.98121070861816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2547}, "5": {"k": 5, "answer": "180th meridian", "latency_ms": 361.4492416381836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3151}, "6": {"k": 6, "answer": "180th meridian", "latency_ms": 564.5847320556641, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3825}}}
{"qid": "-4512601929982486528", "question": "north carolina delegate to the second continental congress", "gold_answers": ["Timothy Bloodworth", "John B. Ashe", "William Blount"], "shots": {"0": {"k": 0, "answer": "William Hooper", "latency_ms": 250.03671646118164, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "William Hooper, Joseph Hewes, Richard Caswell", "latency_ms": 282.21917152404785, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "Joseph Hewes, William Hooper, John Penn", "latency_ms": 286.86022758483887, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1356}, "3": {"k": 3, "answer": "Joseph Hewes, William Hooper, John Penn", "latency_ms": 179.76951599121094, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "Joseph Hewes, William Hooper, John Penn", "latency_ms": 642.5881385803223, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2673}, "5": {"k": 5, "answer": "Joseph Hewes, William Hooper, John Penn", "latency_ms": 206.05039596557617, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3371}, "6": {"k": 6, "answer": "Joseph Hewes, William Hooper, John Penn", "latency_ms": 476.14240646362305, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 4040}}}
{"qid": "-2808093071562767910", "question": "who played the face in the a team", "gold_answers": ["Dirk Benedict"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 104.68912124633789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 172.50585556030273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 175.76217651367188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 134.13214683532715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1779}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 269.03438568115234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 434.42511558532715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3043}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 230.23557662963867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3624}}}
{"qid": "7119887147544272496", "question": "when did the last volcano erupt in iceland", "gold_answers": ["2010"], "shots": {"0": {"k": 0, "answer": "2023", "latency_ms": 269.1178321838379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2004", "latency_ms": 165.04788398742676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "2011", "latency_ms": 110.20064353942871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "2011", "latency_ms": 310.02283096313477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1886}, "4": {"k": 4, "answer": "2011", "latency_ms": 328.80640029907227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2486}, "5": {"k": 5, "answer": "1910", "latency_ms": 358.8519096374512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "2011", "latency_ms": 172.44791984558105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3808}}}
{"qid": "-7102729436138036180", "question": "when are you considered under the poverty line", "gold_answers": ["US $11,770"], "shots": {"0": {"k": 0, "answer": "varies by country and year", "latency_ms": 201.4482021331787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "when income is below the threshold for basic needs", "latency_ms": 258.3739757537842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Rs 32 a day in rural areas and Rs 47 in towns and cities", "latency_ms": 650.7110595703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1224}, "3": {"k": 3, "answer": "less than $1.90 per day per head (PPP)", "latency_ms": 543.6253547668457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "below the absolute poverty line or below the relative poverty line, depending on the threshold and income level", "latency_ms": 917.4163341522217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2526}, "5": {"k": 5, "answer": "when income is below the established threshold for basic needs", "latency_ms": 457.74054527282715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3131}, "6": {"k": 6, "answer": "when income is below the established poverty threshold, such as $1.90 per day (PPP) or specific national levels like Rs 32/day in rural India and Rs 47/day in urban areas", "latency_ms": 1767.3683166503906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-8391680223788694572", "question": "who wrote if i were a boy reba or beyonce", "gold_answers": ["BC Jean", "Toby Gad"], "shots": {"0": {"k": 0, "answer": "Reba McEntire", "latency_ms": 121.62971496582031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "BC Jean", "latency_ms": 110.75401306152344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "BC Jean and Toby Gad", "latency_ms": 106.86206817626953, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1179}, "3": {"k": 3, "answer": "BC Jean and Toby Gad", "latency_ms": 320.80578804016113, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "BC Jean and Toby Gad", "latency_ms": 246.232271194458, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2460}, "5": {"k": 5, "answer": "BC Jean and Toby Gad", "latency_ms": 189.3305778503418, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3140}, "6": {"k": 6, "answer": "BC Jean and Toby Gad", "latency_ms": 151.0145664215088, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3751}}}
{"qid": "-6785327703850595221", "question": "who has climbed mount everest the number of times", "gold_answers": ["Kami Rita Sherpa", "Phurba Tashi Sherpa", "Apa Sherpa"], "shots": {"0": {"k": 0, "answer": "As of 2023, the record for the most ascents of Mount Everest is held by **Reinhold Messner**, with **12 ascents**. However, the current record holder for the most successful ascents (including both summits and descents) is **Pemba Dorji**, with **12 ascents**. But the most widely recognized record for the most climbs is **Sangay Dorji** with **12 ascents**. \n\nHowever, the most accurate and verified record as of 2023 is **Sangay Dorji** with **12 ascents**.\n\nFinal answer: **Sangay Dorji**", "latency_ms": 4193.950653076172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ang Rita", "latency_ms": 73.38976860046387, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "Ang Dorje Sherpa", "latency_ms": 171.45705223083496, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1175}, "3": {"k": 3, "answer": "Ang Dorje Sherpa", "latency_ms": 118.26848983764648, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1782}, "4": {"k": 4, "answer": "Ang Dorje Sherpa", "latency_ms": 141.6182518005371, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2378}, "5": {"k": 5, "answer": "Kami Rita Sherpa", "latency_ms": 162.7650260925293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2923}, "6": {"k": 6, "answer": "Kami Rita Sherpa", "latency_ms": 328.1128406524658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3503}}}
