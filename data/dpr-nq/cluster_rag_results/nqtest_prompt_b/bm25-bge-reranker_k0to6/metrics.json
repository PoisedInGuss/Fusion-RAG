{
  "dataset": "nq_test",
  "retriever": "BM25-BGE-Reranker",
  "rag_variant": "BM25-BGE-Reranker_PromptB_k0to6",
  "num_examples": 3610,
  "shots": {
    "0": {
      "n": 3610,
      "em": 0.1371191135734072,
      "f1": 0.22339093680199124,
      "containment": 0.18725761772853186,
      "latency_ms": 236.00084517471018,
      "context_chars": 0.0
    },
    "1": {
      "n": 3610,
      "em": 0.314404432132964,
      "f1": 0.41263697273091104,
      "containment": 0.36454293628808865,
      "latency_ms": 215.3606017870916,
      "context_chars": 641.1407202216067
    },
    "2": {
      "n": 3610,
      "em": 0.3301939058171745,
      "f1": 0.4382263255364088,
      "containment": 0.3975069252077562,
      "latency_ms": 238.25555323233564,
      "context_chars": 1283.5855955678671
    },
    "3": {
      "n": 3610,
      "em": 0.3346260387811634,
      "f1": 0.4447832337450493,
      "containment": 0.403601108033241,
      "latency_ms": 259.63579102566365,
      "context_chars": 1926.6451523545707
    },
    "4": {
      "n": 3610,
      "em": 0.32936288088642657,
      "f1": 0.4433377849032559,
      "containment": 0.40470914127423824,
      "latency_ms": 280.19541643993347,
      "context_chars": 2569.3850415512466
    },
    "5": {
      "n": 3610,
      "em": 0.33130193905817173,
      "f1": 0.44553980829750267,
      "containment": 0.40969529085872575,
      "latency_ms": 297.8892640063637,
      "context_chars": 3212.6362880886427
    },
    "6": {
      "n": 3610,
      "em": 0.33213296398891967,
      "f1": 0.4471435956108428,
      "containment": 0.4121883656509695,
      "latency_ms": 315.22486057968354,
      "context_chars": 3855.1861495844873
    }
  }
}