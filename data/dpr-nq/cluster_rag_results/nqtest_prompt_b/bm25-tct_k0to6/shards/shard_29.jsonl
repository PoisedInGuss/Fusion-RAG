{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "2024", "latency_ms": 73.09508323669434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 167.59324073791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "June 22, 2018", "latency_ms": 476.0260581970215, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "June 22, 2018", "latency_ms": 465.5282497406006, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "June 22, 2018", "latency_ms": 446.16222381591797, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 371.5379238128662, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "June 22, 2018", "latency_ms": 456.8164348602295, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3802}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Biathlon, Freestyle, Snowboard", "latency_ms": 619.4567680358887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alpine skiing", "latency_ms": 126.0380744934082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 302.34622955322266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 517.7922248840332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 401.4127254486084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 392.69471168518066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "Alpine, Freestyle, Cross-country", "latency_ms": 314.8801326751709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3922}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "David H. Morrissey", "latency_ms": 241.64795875549316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gino Poletti", "latency_ms": 262.25996017456055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Gino Poletti", "latency_ms": 167.88434982299805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Gino Poletti", "latency_ms": 394.68860626220703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 324.07641410827637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2560}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 162.0481014251709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 341.7091369628906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3824}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "Pittsburgh Steelers", "latency_ms": 248.56829643249512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Giants", "latency_ms": 94.94900703430176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 551}, "2": {"k": 2, "answer": "Giants", "latency_ms": 104.35009002685547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1156}, "3": {"k": 3, "answer": "Giants, Broncos, Rams", "latency_ms": 168.07889938354492, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1711}, "4": {"k": 4, "answer": "Giants, Broncos, Rams, Denver Broncos", "latency_ms": 363.7535572052002, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2294}, "5": {"k": 5, "answer": "Giants, Broncos, Bengals", "latency_ms": 365.1282787322998, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2888}, "6": {"k": 6, "answer": "Giants, Broncos, Bengals", "latency_ms": 355.74865341186523, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3442}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "1985", "latency_ms": 174.41582679748535, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 December 1985", "latency_ms": 223.36888313293457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 727}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 448.383092880249, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1447}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 279.8638343811035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2143}, "4": {"k": 4, "answer": "8 December 1985", "latency_ms": 448.65870475769043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2840}, "5": {"k": 5, "answer": "8 December 1985", "latency_ms": 377.51269340515137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3557}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 545.0494289398193, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4258}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "cypress knees", "latency_ms": 106.89234733581543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 173.56610298156738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 122.1156120300293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1381}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 227.67972946166992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2092}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 363.62528800964355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2735}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 343.2202339172363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3346}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 403.6827087402344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3996}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "NYHA Class I-IV", "latency_ms": 178.4040927886963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 80.90806007385254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 762}, "2": {"k": 2, "answer": "shortness of breath and/or angina", "latency_ms": 261.2414360046387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1494}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 184.37623977661133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2250}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 284.8401069641113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2959}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 239.0756607055664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 132.04240798950195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4342}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Dolly Parton", "latency_ms": 78.70960235595703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 285.94136238098145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 261.3818645477295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 175.1558780670166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 406.2063694000244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2447}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 196.5787410736084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 378.1323432922363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3635}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 53.52330207824707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 216.6159152984619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "3", "latency_ms": 52.43062973022461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "3", "latency_ms": 70.0829029083252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "3", "latency_ms": 131.14571571350098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2466}, "5": {"k": 5, "answer": "3", "latency_ms": 159.82842445373535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "3", "latency_ms": 279.857873916626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3661}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "biscuit", "latency_ms": 275.99644660949707, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biscuit-sized cake", "latency_ms": 106.86159133911133, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "cake", "latency_ms": 87.01539039611816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "cake", "latency_ms": 119.37117576599121, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1764}, "4": {"k": 4, "answer": "a cake", "latency_ms": 177.1218776702881, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "a cake", "latency_ms": 103.77979278564453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3040}, "6": {"k": 6, "answer": "cake", "latency_ms": 220.292329788208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Dan Castellaneta", "latency_ms": 216.60375595092773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seth MacFarlane", "latency_ms": 101.81427001953125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "Seth MacFarlane", "latency_ms": 183.31575393676758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "Seth MacFarlane", "latency_ms": 254.6710968017578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 231.99129104614258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 154.93154525756836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3190}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 422.4674701690674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3857}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "cocaine", "latency_ms": 99.27868843078613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 119.61889266967773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 215.76857566833496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 358.43372344970703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 127.48908996582031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 124.1598129272461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3135}, "6": {"k": 6, "answer": "diet pills", "latency_ms": 398.09298515319824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3712}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "19 minutes 38 seconds", "latency_ms": 171.63658142089844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 90.30795097351074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 571}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 113.3260726928711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1153}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 415.94505310058594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1779}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 189.85915184020996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2373}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 391.345739364624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2928}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 230.66163063049316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3520}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "United Kingdom", "latency_ms": 96.62199020385742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 99.54214096069336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 166.91231727600098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 332.66425132751465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1900}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 254.8534870147705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2517}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 218.11485290527344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3197}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 316.79272651672363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3841}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "Joshua \"JT\" Williams", "latency_ms": 200.0737190246582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 428.3425807952881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 95.5350399017334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 266.62659645080566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1868}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 139.43719863891602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 467.27609634399414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 184.36336517333984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3746}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1973", "latency_ms": 246.6738224029541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 114.99214172363281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 151.9908905029297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "1986", "latency_ms": 127.66647338867188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "1986", "latency_ms": 131.7451000213623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "1986", "latency_ms": 267.23670959472656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3208}, "6": {"k": 6, "answer": "1986", "latency_ms": 354.24327850341797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3832}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "Lori Michaels", "latency_ms": 66.9867992401123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alexz Johnson", "latency_ms": 162.80341148376465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Alexz Johnson, Jakalope, Damhnait Doyle, in-show band", "latency_ms": 546.0100173950195, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Alexz Johnson, Jakalope, Damhnait Doyle, in-show band", "latency_ms": 366.3947582244873, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Alexz Johnson", "latency_ms": 173.83909225463867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2608}, "5": {"k": 5, "answer": "Jim McGrath (composer), lyrics by Jody Colero and Stephen Stohn; performed by Lisa Dalbello with children's choir (early seasons), Damhnait Doyle (season 8), Jakalope (seasons 4–7), Alexz Johnson (seasons 13–14)", "latency_ms": 1856.5282821655273, "em": 0.0, "f1": 0.06451612903225806, "containment": 1.0, "context_chars": 3259}, "6": {"k": 6, "answer": "Jim McGrath (composer), with lyrics by Jody Colero and Stephen Stohn; performed by Lisa Dalbello and children's choir in early seasons; later performed by various artists including Alexz Johnson, Damhnait Doyle, and Jakalope.", "latency_ms": 2078.864336013794, "em": 0.0, "f1": 0.05882352941176471, "containment": 1.0, "context_chars": 3906}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "2.6 million years ago", "latency_ms": 170.11427879333496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 million years ago", "latency_ms": 260.0593566894531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "360 million years ago", "latency_ms": 239.22395706176758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "360 million years ago", "latency_ms": 369.1568374633789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1920}, "4": {"k": 4, "answer": "360 million years ago", "latency_ms": 249.20010566711426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 235.39352416992188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3206}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 435.2903366088867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3826}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "E-8 in the Marine Corps is a rank of Colonel.", "latency_ms": 662.5006198883057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 157.5629711151123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 275.27332305908203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 173.19130897521973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1991}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 150.72083473205566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2718}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 159.3945026397705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3336}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 130.34391403198242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4052}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 66.72120094299316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "GNU project", "latency_ms": 221.6639518737793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 172.89495468139648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 95.55959701538086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1999}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 252.6535987854004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 132.76100158691406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3296}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 192.99864768981934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3928}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 174.696683883667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 270.8625793457031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 162.05358505249023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1180}, "3": {"k": 3, "answer": "Martina Veloso", "latency_ms": 264.45698738098145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1777}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 136.3048553466797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2314}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 203.78756523132324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2918}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 201.24125480651855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3517}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Chris Tomlinson", "latency_ms": 193.64047050476074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 78.26471328735352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 223.6769199371338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 77.6064395904541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1992}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 146.72255516052246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2678}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 136.02638244628906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3316}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 314.94998931884766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3959}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "Miami Heat", "latency_ms": 119.47011947631836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 84.56206321716309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 176.99861526489258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 86.75813674926758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 124.3586540222168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2450}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 110.61668395996094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3025}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 258.69083404541016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3652}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "Guarani", "latency_ms": 145.43581008911133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 176.2998104095459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Paraguayan peso", "latency_ms": 100.7392406463623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "guaraní", "latency_ms": 230.89218139648438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1885}, "4": {"k": 4, "answer": "guaraní", "latency_ms": 286.8390083312988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2454}, "5": {"k": 5, "answer": "guaraní", "latency_ms": 209.5925807952881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "guaraní", "latency_ms": 160.5973243713379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3749}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "ketamine", "latency_ms": 55.05871772766113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "amnesic properties", "latency_ms": 84.00511741638184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "benzodiazepine", "latency_ms": 254.2428970336914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1445}, "3": {"k": 3, "answer": "remifentanil", "latency_ms": 162.97650337219238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2125}, "4": {"k": 4, "answer": "remifentanil", "latency_ms": 252.46453285217285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2805}, "5": {"k": 5, "answer": "remifentanil", "latency_ms": 299.4372844696045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3491}, "6": {"k": 6, "answer": "remifentanil", "latency_ms": 194.33355331420898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4171}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 314.4214153289795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "26,000 years", "latency_ms": 192.95072555541992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "26,000 years", "latency_ms": 343.59192848205566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1207}, "3": {"k": 3, "answer": "25,772 years", "latency_ms": 389.93310928344727, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "25,772 years", "latency_ms": 318.21656227111816, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2481}, "5": {"k": 5, "answer": "25,772 years", "latency_ms": 199.7964382171631, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "25,772 years", "latency_ms": 429.0006160736084, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3729}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 88.64855766296387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.54024314880371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Texas A&M", "latency_ms": 114.50386047363281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Texas A&M", "latency_ms": 330.17778396606445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1904}, "4": {"k": 4, "answer": "Texas A&M", "latency_ms": 169.0502166748047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Texas A&M University", "latency_ms": 343.05882453918457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Texas A&M University", "latency_ms": 295.90320587158203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3748}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and non-renewable", "latency_ms": 123.86226654052734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable and non-renewable", "latency_ms": 197.69835472106934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable or non-renewable", "latency_ms": 142.6239013671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1447}, "3": {"k": 3, "answer": "renewable or non-renewable", "latency_ms": 154.9055576324463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2177}, "4": {"k": 4, "answer": "renewable and non-renewable", "latency_ms": 194.66519355773926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2828}, "5": {"k": 5, "answer": "renewable or non-renewable", "latency_ms": 413.05065155029297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3469}, "6": {"k": 6, "answer": "renewable and non-renewable", "latency_ms": 454.3302059173584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4200}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "Good luck and prosperity", "latency_ms": 101.58538818359375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "parental devotion", "latency_ms": 301.6824722290039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "parental devotion", "latency_ms": 82.37600326538086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "parental devotion", "latency_ms": 189.4392967224121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "maternal symbols, purity, kindness, parental devotion", "latency_ms": 699.1872787475586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2459}, "5": {"k": 5, "answer": "purity, maternal devotion, and child-birth", "latency_ms": 361.588716506958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3065}, "6": {"k": 6, "answer": "mercy, parental devotion, purity, good luck, child-bringing", "latency_ms": 583.7769508361816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3706}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Rohit Sharma", "latency_ms": 75.77347755432129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 81.06708526611328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 193.36676597595215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 107.82217979431152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 212.5394344329834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 215.21520614624023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3144}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 159.71684455871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3769}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "killing of microorganisms by low concentrations of metals", "latency_ms": 390.8374309539795, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals", "latency_ms": 388.46755027770996, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 797.5561618804932, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 1412}, "3": {"k": 3, "answer": "the biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 892.0605182647705, "em": 0.0, "f1": 0.4705882352941176, "containment": 0.0, "context_chars": 2081}, "4": {"k": 4, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 770.9329128265381, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 2746}, "5": {"k": 5, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 708.4903717041016, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 3407}, "6": {"k": 6, "answer": "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "latency_ms": 854.2845249176025, "em": 0.0, "f1": 0.4705882352941176, "containment": 1.0, "context_chars": 4072}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "2006", "latency_ms": 156.85176849365234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 232.53417015075684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 187.2732639312744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 177.21104621887207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1904}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 268.0094242095947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Walter LaGrand", "latency_ms": 174.28231239318848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3136}, "6": {"k": 6, "answer": "Walter LaGrand", "latency_ms": 267.9905891418457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the opening lead and before the first trick is played.", "latency_ms": 286.13972663879395, "em": 0.0, "f1": 0.15384615384615383, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the conclusion of play", "latency_ms": 96.5273380279541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 550}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 270.2016830444336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1156}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 139.05572891235352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1797}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 291.3055419921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2367}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 194.71383094787598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2949}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 174.5765209197998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3567}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Sri Lanka", "latency_ms": 130.52797317504883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 84.91969108581543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 699}, "2": {"k": 2, "answer": "Sri Lanka", "latency_ms": 180.82594871520996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Afghanistan", "latency_ms": 165.1298999786377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2076}, "4": {"k": 4, "answer": "Afghanistan", "latency_ms": 125.38480758666992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2735}, "5": {"k": 5, "answer": "Afghanistan", "latency_ms": 210.8902931213379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3469}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 212.93902397155762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4195}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "Vascular spasm, platelet plug formation, coagulation", "latency_ms": 342.4818515777588, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 255.15270233154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 159.7738265991211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 144.12713050842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 306.27942085266113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2607}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 209.44809913635254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3321}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 218.37759017944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4055}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "Jesse McCartney", "latency_ms": 64.7435188293457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 90.7447338104248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 199.2020606994629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1354}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 324.0964412689209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2062}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 257.31968879699707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2695}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 236.6323471069336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3389}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 321.4113712310791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4021}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "1989", "latency_ms": 202.84438133239746, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1989", "latency_ms": 317.5945281982422, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 182.45291709899902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1313}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 199.16367530822754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1931}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 221.0395336151123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2637}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 370.26119232177734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3277}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 339.51640129089355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3945}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "2016", "latency_ms": 138.26751708984375, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2016", "latency_ms": 107.56349563598633, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "2016", "latency_ms": 103.09076309204102, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "2016", "latency_ms": 320.1782703399658, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "2016", "latency_ms": 106.32967948913574, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2581}, "5": {"k": 5, "answer": "June 2016", "latency_ms": 266.6516304016113, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3170}, "6": {"k": 6, "answer": "2016", "latency_ms": 164.00408744812012, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3751}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 165.22789001464844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 97.05781936645508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 324.326753616333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 251.08599662780762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 171.13041877746582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2644}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 275.03061294555664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3256}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 301.3303279876709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3973}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 243.83831024169922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 295.0479984283447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 296.9393730163574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 171.38242721557617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 206.8462371826172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 191.9853687286377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3101}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 285.48598289489746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Baron de Montesquieu", "latency_ms": 274.1069793701172, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montesquieu", "latency_ms": 218.67847442626953, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 128.88550758361816, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 132.38859176635742, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 248.14510345458984, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2621}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 267.40336418151855, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3230}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 202.24857330322266, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3906}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Kyler Murray", "latency_ms": 163.81430625915527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 215.29912948608398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 288.09237480163574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 180.64522743225098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 286.1979007720947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 151.95465087890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3116}, "6": {"k": 6, "answer": "Kevin King", "latency_ms": 105.6215763092041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3666}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 78.43708992004395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 107.83076286315918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "2008", "latency_ms": 164.76702690124512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "2008", "latency_ms": 176.2521266937256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1980}, "4": {"k": 4, "answer": "2008", "latency_ms": 141.2341594696045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "2008", "latency_ms": 186.1133575439453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3332}, "6": {"k": 6, "answer": "2008", "latency_ms": 257.0469379425049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3999}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "Captain John Smith", "latency_ms": 206.62331581115723, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 198.17042350769043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 111.35315895080566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 171.93222045898438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 233.06012153625488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2637}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 127.72154808044434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3295}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 268.815279006958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3979}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "parietal cells", "latency_ms": 269.8030471801758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "stomach", "latency_ms": 152.41193771362305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "parietal cells", "latency_ms": 218.76287460327148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "parietal cells", "latency_ms": 190.1693344116211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1803}, "4": {"k": 4, "answer": "parietal cells", "latency_ms": 278.9959907531738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2404}, "5": {"k": 5, "answer": "parietal cells", "latency_ms": 124.68147277832031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3055}, "6": {"k": 6, "answer": "parietal cells", "latency_ms": 224.4579792022705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3670}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "early morning, before waking", "latency_ms": 263.4871006011963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "4 a.m.", "latency_ms": 248.98242950439453, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 145.035982131958, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "second half of the sleep cycle", "latency_ms": 151.59988403320312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "4 a.m.", "latency_ms": 143.8138484954834, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2606}, "5": {"k": 5, "answer": "4 a.m.", "latency_ms": 303.67064476013184, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3317}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 127.07281112670898, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4053}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 78.83334159851074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 115.79322814941406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 266.8442726135254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 107.70344734191895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 157.44423866271973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2640}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 128.66544723510742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3264}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 342.1773910522461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3900}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "1. The Curse of the Black Pearl  \n2. Dead Man's Chest  \n3. At World's End  \n4. On Stranger Tides  \n5. Dead Men Tell No Tales", "latency_ms": 1261.6593837738037, "em": 0.0, "f1": 0.3571428571428571, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 110.87179183959961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 200.8686065673828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 323.976993560791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Pirates of the Caribbean: The Curse of the Black Pearl (2003), Pirates of the Caribbean: Dead Man's Chest (2006), Pirates of the Caribbean: At World's End (2007), Pirates of the Caribbean: On Stranger Tides (2011), Pirates of the Caribbean: Dead Men Tell No Tales (2017)", "latency_ms": 2293.016195297241, "em": 0.0, "f1": 0.23255813953488372, "containment": 1.0, "context_chars": 2550}, "5": {"k": 5, "answer": "The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales", "latency_ms": 813.697099685669, "em": 0.0, "f1": 0.43478260869565216, "containment": 1.0, "context_chars": 3159}, "6": {"k": 6, "answer": "The Pirate of the Caribbean films in order: The Curse of the Black Pearl (2003), Dead Man's Chest (2006), At World's End (2007), On Stranger Tides (2011), Dead Men Tell No Tales (2017).", "latency_ms": 1884.9108219146729, "em": 0.0, "f1": 0.29411764705882354, "containment": 1.0, "context_chars": 3820}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 150.1460075378418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "changed key", "latency_ms": 97.60522842407227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "changed key", "latency_ms": 67.48175621032715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1171}, "3": {"k": 3, "answer": "changed key", "latency_ms": 223.71578216552734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1761}, "4": {"k": 4, "answer": "modulated", "latency_ms": 122.53713607788086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "modulated", "latency_ms": 142.00997352600098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3037}, "6": {"k": 6, "answer": "modulated", "latency_ms": 279.6130180358887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3649}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Roman citizens of certain property thresholds", "latency_ms": 284.00373458862305, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 217.21577644348145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "a minority of Romans", "latency_ms": 309.83662605285645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Roman citizens", "latency_ms": 118.0105209350586, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1994}, "4": {"k": 4, "answer": "Roman citizens", "latency_ms": 146.68774604797363, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2700}, "5": {"k": 5, "answer": "Full Roman citizens", "latency_ms": 332.80253410339355, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3339}, "6": {"k": 6, "answer": "Full Roman citizens", "latency_ms": 227.90932655334473, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4014}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.33299446105957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 142.5607204437256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 229.94399070739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 269.21749114990234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 187.0582103729248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2542}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 221.2831974029541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 263.64660263061523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3809}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "blood volume", "latency_ms": 105.82518577575684, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "blood volume", "latency_ms": 56.097984313964844, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "blood volume", "latency_ms": 65.04034996032715, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "blood volume", "latency_ms": 119.93551254272461, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1849}, "4": {"k": 4, "answer": "volume of blood", "latency_ms": 293.96653175354004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2539}, "5": {"k": 5, "answer": "volume of blood", "latency_ms": 214.19334411621094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3203}, "6": {"k": 6, "answer": "volume of blood", "latency_ms": 287.9188060760498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3800}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 94.1152572631836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 190.80734252929688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 268.92781257629395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 262.4092102050781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 122.95365333557129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2393}, "5": {"k": 5, "answer": "Phaethon", "latency_ms": 366.793155670166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "Phaethon", "latency_ms": 125.55766105651855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3630}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "1979", "latency_ms": 150.35605430603027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1979", "latency_ms": 81.69078826904297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "1979", "latency_ms": 178.4992218017578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "1979", "latency_ms": 362.4992370605469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "1979", "latency_ms": 220.01957893371582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2551}, "5": {"k": 5, "answer": "1979", "latency_ms": 124.62401390075684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3159}, "6": {"k": 6, "answer": "1979", "latency_ms": 164.59393501281738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3727}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 AM Hong Kong Time", "latency_ms": 257.7998638153076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 86.86971664428711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 109.65633392333984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 178.79223823547363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 229.66432571411133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2627}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 124.68862533569336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3296}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 181.70976638793945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3927}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "Jackie Mason", "latency_ms": 102.32973098754883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 265.993595123291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "Tiffany Coyne", "latency_ms": 93.41907501220703, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 106.14705085754395, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 174.6511459350586, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2449}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 156.294584274292, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3031}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 303.27510833740234, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3658}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "Atlanta Braves, New York Mets", "latency_ms": 192.4915313720703, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Atlanta Braves", "latency_ms": 99.06172752380371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Atlanta Braves", "latency_ms": 100.37779808044434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Atlanta Braves", "latency_ms": 143.1722640991211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1861}, "4": {"k": 4, "answer": "New York Yankees, Atlanta Braves", "latency_ms": 298.19226264953613, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 2437}, "5": {"k": 5, "answer": "New York Yankees, Atlanta Braves", "latency_ms": 197.5419521331787, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 3043}, "6": {"k": 6, "answer": "New York Yankees, Atlanta Braves", "latency_ms": 174.52645301818848, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 3676}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "$2.2 billion", "latency_ms": 330.93833923339844, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$343.4 million", "latency_ms": 252.7937889099121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "$1.84 billion", "latency_ms": 303.5087585449219, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "over $2 billion worldwide", "latency_ms": 119.9185848236084, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "over $2 billion worldwide", "latency_ms": 250.3070831298828, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "over $1.84 billion worldwide", "latency_ms": 274.28722381591797, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "over $1.84 billion worldwide", "latency_ms": 520.4761028289795, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3794}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "December 25", "latency_ms": 397.6919651031494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 210.3404998779297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 233.42657089233398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 158.64014625549316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 266.86739921569824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2496}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 216.33315086364746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 364.79973793029785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3718}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark/Norway", "latency_ms": 122.86591529846191, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "mother's home village", "latency_ms": 200.61445236206055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "mother's home village", "latency_ms": 251.52945518493652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "mother's home village", "latency_ms": 119.16494369506836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "mother's home village", "latency_ms": 247.26557731628418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2513}, "5": {"k": 5, "answer": "mother's home village", "latency_ms": 195.51539421081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "mother's home village", "latency_ms": 287.16373443603516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 218.11795234680176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Christmas tree and Nativity scene", "latency_ms": 105.5901050567627, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Christmas Tree and Nativity scene", "latency_ms": 117.92635917663574, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Christmas tree", "latency_ms": 294.79408264160156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Christmas tree", "latency_ms": 104.0349006652832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Christmas tree and Nativity scene", "latency_ms": 148.45681190490723, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Christmas tree", "latency_ms": 201.15947723388672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3845}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "Linda Ronstadt", "latency_ms": 127.06851959228516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 87.2955322265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 129.80008125305176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 206.41565322875977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Swayze", "latency_ms": 197.310209274292, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Swayze", "latency_ms": 118.82853507995605, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3213}, "6": {"k": 6, "answer": "Swayze", "latency_ms": 201.4310359954834, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3819}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Rhode Island", "latency_ms": 129.364013671875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 236.1595630645752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 257.65037536621094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 99.40624237060547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 153.95760536193848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2589}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 215.14487266540527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3214}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 176.71966552734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3876}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1827", "latency_ms": 283.57553482055664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "24 May 1854", "latency_ms": 126.3282299041748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "24 May 1854", "latency_ms": 393.5413360595703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "24 May 1854", "latency_ms": 336.4839553833008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1994}, "4": {"k": 4, "answer": "24 May 1854", "latency_ms": 183.90679359436035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "First Parliament, 1854", "latency_ms": 535.595178604126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3243}, "6": {"k": 6, "answer": "24 May 1854", "latency_ms": 325.5898952484131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3911}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier Fernández", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Yuzuru Hanyu", "latency_ms": 281.9366455078125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 218.78981590270996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 126.36995315551758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 115.3256893157959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2059}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 113.52181434631348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2810}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 174.346923828125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3439}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 375.8878707885742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4120}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "Cain and Abel is a network scanning and password cracking tool used for ethical hacking and penetration testing.", "latency_ms": 869.2870140075684, "em": 0.0, "f1": 0.10526315789473684, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "password recovery", "latency_ms": 67.10982322692871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "password recovery", "latency_ms": 130.28669357299805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1391}, "3": {"k": 3, "answer": "password recovery for Microsoft Windows", "latency_ms": 128.57913970947266, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2024}, "4": {"k": 4, "answer": "recovering passwords using methods such as network packet sniffing, dictionary attacks, brute force, and cryptanalysis attacks", "latency_ms": 542.2666072845459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2617}, "5": {"k": 5, "answer": "recovering passwords using methods such as network packet sniffing, dictionary attacks, brute force, and cryptanalysis attacks", "latency_ms": 749.6559619903564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "recover passwords using methods such as network packet sniffing, dictionary attacks, brute force, and cryptanalysis attacks", "latency_ms": 464.9512767791748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3819}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "Eknath Shinde", "latency_ms": 291.1877632141113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 254.81200218200684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "S. M. Krishna", "latency_ms": 157.88602828979492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 301.5453815460205, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 196.6080665588379, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2642}, "5": {"k": 5, "answer": "C. Vidyasagar Rao", "latency_ms": 165.89760780334473, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "C. Vidyasagar Rao", "latency_ms": 289.3359661102295, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3931}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "ABC 50.1", "latency_ms": 104.07447814941406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 132.38143920898438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 308.98332595825195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 374.2108345031738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "15", "latency_ms": 88.77730369567871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2570}, "5": {"k": 5, "answer": "15", "latency_ms": 185.577392578125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "15", "latency_ms": 140.6562328338623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3897}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Michael J. Fox", "latency_ms": 80.91282844543457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elisabeth Shue", "latency_ms": 189.5577907562256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Elisabeth Shue", "latency_ms": 320.31822204589844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "Claudia Wells initially played Jennifer Parker in \"Back to the Future\", but she declined due to personal issues. Elisabeth Shue replaced her in \"Back to the Future Part II\" and \"Part III\". Therefore, the answer is: Claudia Wells and Elisabeth Shue.", "latency_ms": 1429.0075302124023, "em": 0.0, "f1": 0.0975609756097561, "containment": 0.0, "context_chars": 1798}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 235.42332649230957, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2397}, "5": {"k": 5, "answer": "Claudia Wells (first film), Elisabeth Shue (Part II and III)", "latency_ms": 756.5603256225586, "em": 0.0, "f1": 0.30769230769230765, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "Claudia Wells (first film), Elisabeth Shue (Part II and Part III)", "latency_ms": 525.0000953674316, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3631}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London, UK", "latency_ms": 158.08939933776855, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "London", "latency_ms": 81.84051513671875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 125.34499168395996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 172.70135879516602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 252.01058387756348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 289.8530960083008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3160}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 149.2941379547119, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3809}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The First Lady or designated chef", "latency_ms": 150.69341659545898, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "White House Executive Chef", "latency_ms": 233.27898979187012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "White House Executive Chef", "latency_ms": 240.79060554504395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1369}, "3": {"k": 3, "answer": "White House Executive Chef", "latency_ms": 233.07251930236816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2045}, "4": {"k": 4, "answer": "White House Executive Chef", "latency_ms": 180.33266067504883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2708}, "5": {"k": 5, "answer": "White House Executive Chef", "latency_ms": 187.61205673217773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3377}, "6": {"k": 6, "answer": "White House Executive Chef", "latency_ms": 159.01899337768555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3956}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "Justice M. H. Beg", "latency_ms": 228.35397720336914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 236.60922050476074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 99.78795051574707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 184.76176261901855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 112.19429969787598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 128.68928909301758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3197}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 391.4754390716553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "Canada", "latency_ms": 60.11700630187988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Larchmont, New York", "latency_ms": 210.31951904296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 258.41522216796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 305.8512210845947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 265.98048210144043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2610}, "5": {"k": 5, "answer": "British Columbia", "latency_ms": 104.1111946105957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3268}, "6": {"k": 6, "answer": "British Columbia", "latency_ms": 186.478853225708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3895}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 291.48292541503906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 236.54437065124512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 132.12037086486816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 653.3057689666748, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1876}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 492.11692810058594, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 450.14166831970215, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 412.0163917541504, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3830}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Dana Delany", "latency_ms": 187.2870922088623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stephanie", "latency_ms": 87.02969551086426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Stephanie", "latency_ms": 87.71181106567383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Stephanie", "latency_ms": 219.55204010009766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "Stephanie", "latency_ms": 138.72241973876953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2526}, "5": {"k": 5, "answer": "Stephanie", "latency_ms": 197.2064971923828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 215.0130271911621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 165.1308536529541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Millennium Tower", "latency_ms": 85.51788330078125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 267.6429748535156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1361}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 287.8684997558594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2008}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 359.4241142272949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2703}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 162.91546821594238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3328}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 138.61680030822754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3988}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 81.20036125183105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 89.64014053344727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "2014", "latency_ms": 114.38393592834473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "2014", "latency_ms": 215.77882766723633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1820}, "4": {"k": 4, "answer": "2014", "latency_ms": 129.96602058410645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2449}, "5": {"k": 5, "answer": "2014", "latency_ms": 379.98390197753906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3029}, "6": {"k": 6, "answer": "2014", "latency_ms": 407.63044357299805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3731}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "T.S. Eliot", "latency_ms": 283.5538387298584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 373.80170822143555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 693}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 99.61318969726562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 108.75701904296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 113.20328712463379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2663}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 148.7112045288086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3333}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 169.33393478393555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4032}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Chris Berman", "latency_ms": 194.75317001342773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 284.8496437072754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 347.7299213409424, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 364.581823348999, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 362.16020584106445, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 424.2730140686035, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 151.40819549560547, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3837}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "100 episodes", "latency_ms": 395.8930969238281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "6", "latency_ms": 67.86727905273438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 705}, "2": {"k": 2, "answer": "6", "latency_ms": 73.87351989746094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "6 episodes", "latency_ms": 100.95930099487305, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1973}, "4": {"k": 4, "answer": "6", "latency_ms": 115.17477035522461, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2646}, "5": {"k": 5, "answer": "6", "latency_ms": 84.3961238861084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3304}, "6": {"k": 6, "answer": "6", "latency_ms": 133.62836837768555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3979}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul Baumer's", "latency_ms": 190.08994102478027, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "German soldiers' perspective", "latency_ms": 87.72492408752441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "German soldiers' perspective", "latency_ms": 95.80230712890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "German soldiers' perspective", "latency_ms": 106.57072067260742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "German soldiers' perspective", "latency_ms": 165.53950309753418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2564}, "5": {"k": 5, "answer": "German soldiers' perspective", "latency_ms": 135.21289825439453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3204}, "6": {"k": 6, "answer": "German soldiers' perspective", "latency_ms": 281.22591972351074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3844}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris and the Anglin brothers (Sundberg) — but only Frank Morris is confirmed to have escaped.  \nFrank Morris", "latency_ms": 438.4877681732178, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 446.7806816101074, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 683}, "2": {"k": 2, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 277.47488021850586, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1339}, "3": {"k": 3, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 398.8826274871826, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 274.1825580596924, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2619}, "5": {"k": 5, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 621.0124492645264, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3224}, "6": {"k": 6, "answer": "Frank Morris, John Anglin, and Clarence Anglin", "latency_ms": 766.9217586517334, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3892}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF programs worldwide", "latency_ms": 128.1907558441162, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF's global programming and domestic causes like Hurricane Katrina victims", "latency_ms": 237.0893955230713, "em": 0.0, "f1": 0.14285714285714288, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "UNICEF's global programing, with half of proceeds in 2005 targeted to Hurricane Katrina victims in the U.S.", "latency_ms": 1018.4714794158936, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 1417}, "3": {"k": 3, "answer": "UNICEF's global programing, with half of proceeds in 2005 targeted to Hurricane Katrina victims in the U.S.", "latency_ms": 981.4155101776123, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2137}, "4": {"k": 4, "answer": "UNICEF's global programming, with half of proceeds in 2005 targeted to Hurricane Katrina victims in the U.S.", "latency_ms": 972.874641418457, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 2808}, "5": {"k": 5, "answer": "UNICEF's global programing, with half of proceeds in 2005 targeted to Hurricane Katrina victims in the U.S.", "latency_ms": 764.491081237793, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 3538}, "6": {"k": 6, "answer": "UNICEF's global programming, with half of proceeds in 2005 targeted to Hurricane Katrina victims in the U.S.", "latency_ms": 1016.6571140289307, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 4217}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Statue's base in New York Harbor", "latency_ms": 752.3839473724365, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 113.47627639770508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 210.28685569763184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 181.97989463806152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 304.06665802001953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "on the pedestal of the statue of liberty", "latency_ms": 187.17312812805176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 241.44649505615234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3882}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "2026 Milano-Cortina, 2030 Beijing", "latency_ms": 545.9132194519043, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.39409255981445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "Beijing, 2022", "latency_ms": 142.6372528076172, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1183}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 147.02987670898438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1785}, "4": {"k": 4, "answer": "Beijing 2022, next Winter Olympics not specified in context. I cannot answer.", "latency_ms": 754.5478343963623, "em": 0.0, "f1": 0.15384615384615385, "containment": 1.0, "context_chars": 2423}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 231.03094100952148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 174.65758323669434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3712}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "1984", "latency_ms": 295.38846015930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1997", "latency_ms": 195.55997848510742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 201.07650756835938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "1997", "latency_ms": 110.7492446899414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 275.8667469024658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 200.00767707824707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 158.29968452453613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3865}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "Stone arch bridge", "latency_ms": 147.0804214477539, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "stone arch bridge", "latency_ms": 90.83175659179688, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 271.3286876678467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 118.82233619689941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1970}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 274.616003036499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2650}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 125.53834915161133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 128.4492015838623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3922}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The ruler or ruling party", "latency_ms": 88.27662467956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "one person", "latency_ms": 57.68942832946777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "one person", "latency_ms": 99.8835563659668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "one person", "latency_ms": 131.2253475189209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1987}, "4": {"k": 4, "answer": "one person", "latency_ms": 88.59920501708984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2671}, "5": {"k": 5, "answer": "one person", "latency_ms": 101.13739967346191, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3321}, "6": {"k": 6, "answer": "one person", "latency_ms": 104.04562950134277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3955}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "Consumerism", "latency_ms": 107.99789428710938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 85.24870872497559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 197.59392738342285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "return to domesticity", "latency_ms": 110.08453369140625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "return to domesticity", "latency_ms": 157.83286094665527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "prosperity and consumerism", "latency_ms": 528.3699035644531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "prosperity and suburban growth", "latency_ms": 435.5454444885254, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3945}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "Counterclockwise (as viewed from above the North Pole)", "latency_ms": 466.4173126220703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "counterclockwise", "latency_ms": 242.94805526733398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "counterclockwise", "latency_ms": 157.00745582580566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1180}, "3": {"k": 3, "answer": "counterclockwise", "latency_ms": 207.7338695526123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1748}, "4": {"k": 4, "answer": "counterclockwise", "latency_ms": 166.7938232421875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2293}, "5": {"k": 5, "answer": "counterclockwise", "latency_ms": 383.2850456237793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2864}, "6": {"k": 6, "answer": "counterclockwise", "latency_ms": 232.40303993225098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3478}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Dome", "latency_ms": 63.0035400390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Statue of Liberty I cannot answer", "latency_ms": 254.5008659362793, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 263.2277011871338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 151.87597274780273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "Statue of Freedom", "latency_ms": 345.58629989624023, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "Statue of Freedom", "latency_ms": 225.51321983337402, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3285}, "6": {"k": 6, "answer": "Statue of Freedom", "latency_ms": 159.47365760803223, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3928}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "Los Angeles Lakers", "latency_ms": 140.63334465026855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington Wizards", "latency_ms": 135.91408729553223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 333.2822322845459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 351.22203826904297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 322.7498531341553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2501}, "5": {"k": 5, "answer": "Washington Wizards", "latency_ms": 184.12184715270996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3105}, "6": {"k": 6, "answer": "Washington Wizards", "latency_ms": 285.6612205505371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3777}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "Steve Austin", "latency_ms": 55.22871017456055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Greatest Royal Rumble", "latency_ms": 287.5196933746338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 281.2154293060303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Mysterio", "latency_ms": 156.39758110046387, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Mysterio", "latency_ms": 219.47574615478516, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2454}, "5": {"k": 5, "answer": "Mysterio", "latency_ms": 117.21587181091309, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3107}, "6": {"k": 6, "answer": "Mysterio", "latency_ms": 118.96133422851562, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3708}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 359.12370681762695, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake of the Ozarks", "latency_ms": 204.19955253601074, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Lake of the Ozarks", "latency_ms": 152.40073204040527, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "Lake Mead", "latency_ms": 256.6492557525635, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Lake Mead", "latency_ms": 126.35445594787598, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2387}, "5": {"k": 5, "answer": "Lake Mead", "latency_ms": 117.41757392883301, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2959}, "6": {"k": 6, "answer": "Lake Mead", "latency_ms": 174.8371124267578, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3536}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Gabbar Is Back (2023) is a remake of the Telugu movie *Gundamma Katha* (2016).", "latency_ms": 853.9333343505859, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 86.18593215942383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "Tagore", "latency_ms": 84.78498458862305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tagore", "latency_ms": 122.5740909576416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1847}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 244.07005310058594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 303.1795024871826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3134}, "6": {"k": 6, "answer": "Tagore", "latency_ms": 227.80656814575195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3745}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "John Baker", "latency_ms": 193.12477111816406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "George H. W. Bush", "latency_ms": 172.83082008361816, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "Walter Mondale", "latency_ms": 241.6532039642334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "Walter Mondale", "latency_ms": 146.64721488952637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2073}, "4": {"k": 4, "answer": "George H. W. Bush", "latency_ms": 510.88500022888184, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2776}, "5": {"k": 5, "answer": "George H. W. Bush", "latency_ms": 273.6201286315918, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3479}, "6": {"k": 6, "answer": "George H. W. Bush", "latency_ms": 402.71687507629395, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 4204}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "Utah", "latency_ms": 92.32091903686523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Town of Groveland", "latency_ms": 639.1892433166504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners", "latency_ms": 177.08325386047363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Hampton Corners, New York", "latency_ms": 235.54682731628418, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "Hampton Corners, New York", "latency_ms": 339.7057056427002, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Hampton Corners, New York", "latency_ms": 389.77909088134766, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Hampton Corners, New York", "latency_ms": 310.3036880493164, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3723}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 104.29716110229492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 57.7692985534668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 81.85410499572754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1172}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 207.98373222351074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1818}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 174.59368705749512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2449}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 150.4819393157959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3090}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 105.02028465270996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3647}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Uttar Pradesh", "latency_ms": 240.86809158325195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 93.53351593017578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 265.75756072998047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 200.68097114562988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 155.9593677520752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 237.74361610412598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 352.74481773376465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3733}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Lucknow", "latency_ms": 162.3396873474121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 264.44005966186523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 97.05734252929688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 187.40034103393555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1936}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 157.3185920715332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 252.41494178771973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 241.64462089538574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3876}}}
