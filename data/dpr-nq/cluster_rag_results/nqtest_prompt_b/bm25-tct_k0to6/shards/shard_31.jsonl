{"qid": "-3320993703958028468", "question": "what color pages in the emergency response guidebook (erg) list compounds by name", "gold_answers": ["blue"], "shots": {"0": {"k": 0, "answer": "Blue", "latency_ms": 98.84405136108398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 227.76436805725098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 778}, "2": {"k": 2, "answer": "blue", "latency_ms": 126.8606185913086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1504}, "3": {"k": 3, "answer": "blue", "latency_ms": 74.15008544921875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2221}, "4": {"k": 4, "answer": "blue", "latency_ms": 157.01723098754883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2887}, "5": {"k": 5, "answer": "blue", "latency_ms": 82.78346061706543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3661}, "6": {"k": 6, "answer": "blue", "latency_ms": 103.68180274963379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4367}}}
{"qid": "7026548049572374691", "question": "who developed the concept of total quality management", "gold_answers": ["W. Edwards Deming"], "shots": {"0": {"k": 0, "answer": "Joseph M. Juran", "latency_ms": 187.9894733428955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Armand V. Feigenbaum and Kaoru Ishikawa", "latency_ms": 531.2273502349854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "Armand V. Feigenbaum and Kaoru Ishikawa", "latency_ms": 435.15849113464355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1380}, "3": {"k": 3, "answer": "M. Juran", "latency_ms": 274.397611618042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2082}, "4": {"k": 4, "answer": "M. Juran", "latency_ms": 268.94187927246094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2803}, "5": {"k": 5, "answer": "M. Juran", "latency_ms": 180.9093952178955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3514}, "6": {"k": 6, "answer": "M. Juran", "latency_ms": 181.4131736755371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4181}}}
{"qid": "4617755372912487064", "question": "last world series that didn't go 7 games", "gold_answers": ["2015"], "shots": {"0": {"k": 0, "answer": "2004", "latency_ms": 76.89189910888672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 81.46286010742188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 530}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 194.12589073181152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1081}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 113.27528953552246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1693}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 324.42235946655273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2263}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 132.34877586364746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2860}, "6": {"k": 6, "answer": "1991", "latency_ms": 185.79578399658203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3455}}}
{"qid": "8453604009134928493", "question": "this inventor co-created the film fred ott’s sneeze", "gold_answers": ["Edison", "Fred Ott"], "shots": {"0": {"k": 0, "answer": "George Eastman", "latency_ms": 68.15147399902344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "William K.L. Dickson", "latency_ms": 309.41033363342285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "William K.L. Dickson", "latency_ms": 271.12293243408203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "William K.L. Dickson", "latency_ms": 188.06719779968262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1844}, "4": {"k": 4, "answer": "William K.L. Dickson", "latency_ms": 284.67440605163574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2443}, "5": {"k": 5, "answer": "William K.L. Dickson", "latency_ms": 322.29089736938477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3070}, "6": {"k": 6, "answer": "William K.L. Dickson", "latency_ms": 460.1094722747803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3695}}}
{"qid": "-3407490342806384733", "question": "who sings what the world needs now in boss baby", "gold_answers": ["Hans Zimmer", "Steve Mazzaro", "Missi Hale"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 171.01621627807617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "No one sings \"What the World Needs Now Is Love\" in *The Boss Baby*. The song is not featured in the film. I cannot answer.", "latency_ms": 702.4672031402588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 412.705659866333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1216}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 120.57256698608398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1826}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 243.98517608642578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 196.03395462036133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3075}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 201.26891136169434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3634}}}
{"qid": "-442417708560275755", "question": "who won the most medals at the 2014 winter olympics", "gold_answers": ["Russia (", "Russia"], "shots": {"0": {"k": 0, "answer": "Canada", "latency_ms": 103.08837890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "France", "latency_ms": 93.49632263183594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 96.53210639953613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "United States", "latency_ms": 82.52358436584473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1910}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 159.8036289215088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2539}, "5": {"k": 5, "answer": "Ole Einar Bjørndalen", "latency_ms": 375.058650970459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3122}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 209.98668670654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3740}}}
{"qid": "-7627363632917466497", "question": "who determines the rules of the us house and us senate", "gold_answers": ["United States Senate", "The Senate"], "shots": {"0": {"k": 0, "answer": "Rules of the U.S. House and Senate are determined by the respective chambers themselves through their rules committees and floor procedures.", "latency_ms": 753.1373500823975, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "House Committee on Rules determines rules for US House; Senate Committee on Rules and Administration determines rules for US Senate.", "latency_ms": 385.61367988586426, "em": 0.0, "f1": 0.09523809523809523, "containment": 0.0, "context_chars": 721}, "2": {"k": 2, "answer": "House: Rules Committee; Senate: Rules and Administration Committee", "latency_ms": 172.90639877319336, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 1367}, "3": {"k": 3, "answer": "House: Rules Committee; Senate: Committee on Rules and Administration", "latency_ms": 358.6914539337158, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2025}, "4": {"k": 4, "answer": "House: Rules Committee; Senate: Committee on Rules and Administration", "latency_ms": 351.30977630615234, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2726}, "5": {"k": 5, "answer": "House: Rules Committee; Senate: Committee on Rules and Administration", "latency_ms": 507.5035095214844, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 3410}, "6": {"k": 6, "answer": "Each House may determine the rules of its proceedings", "latency_ms": 422.1055507659912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4070}}}
{"qid": "70640340064871933", "question": "who won britain's next top model 2016", "gold_answers": ["Chloe Keenan"], "shots": {"0": {"k": 0, "answer": "Lily Hargreaves", "latency_ms": 185.98651885986328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 130.16891479492188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 162.2183322906494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 241.03379249572754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1946}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 295.3517436981201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2639}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 288.8684272766113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3267}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 142.09747314453125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3928}}}
{"qid": "4884658732028049316", "question": "when did las vegas become a gambling town", "gold_answers": ["In 1931", "1931"], "shots": {"0": {"k": 0, "answer": "1931", "latency_ms": 151.17478370666504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1950s", "latency_ms": 219.27165985107422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "1931", "latency_ms": 94.8781967163086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "1931", "latency_ms": 163.24734687805176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1930}, "4": {"k": 4, "answer": "1931", "latency_ms": 145.77698707580566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2569}, "5": {"k": 5, "answer": "1931", "latency_ms": 183.54225158691406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3260}, "6": {"k": 6, "answer": "1931", "latency_ms": 158.5068702697754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3838}}}
{"qid": "-5107559781320376096", "question": "who is the highest paid baseball player in the major leagues", "gold_answers": ["Alex Rodriguez", "Clayton Kershaw"], "shots": {"0": {"k": 0, "answer": "Teoscar Hernández", "latency_ms": 242.69771575927734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 157.41753578186035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 193.4795379638672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1431}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 112.4868392944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2072}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 113.10982704162598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2762}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 258.2054138183594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3358}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 194.11754608154297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4004}}}
{"qid": "5890866538303894370", "question": "list the seven gifts of the holy spirit", "gold_answers": ["wisdom", "understanding", "fear", "piety", "counsel", "knowledge", "fear of the Lord", "fortitude"], "shots": {"0": {"k": 0, "answer": "Wisdom, Understanding, Counsel, Fortitude, Knowledge, Piety, Fear of the Lord", "latency_ms": 419.31891441345215, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, fear of the Lord", "latency_ms": 756.4620971679688, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "latency_ms": 380.94091415405273, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1342}, "3": {"k": 3, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "latency_ms": 572.2019672393799, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2000}, "4": {"k": 4, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, fear of the Lord", "latency_ms": 744.0192699432373, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2627}, "5": {"k": 5, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, fear of the Lord", "latency_ms": 798.3286380767822, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3285}, "6": {"k": 6, "answer": "wisdom, understanding, counsel, fortitude, knowledge, piety, fear of the Lord", "latency_ms": 695.6241130828857, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3945}}}
{"qid": "4870961414505835033", "question": "where is beijing located on the world map", "gold_answers": ["in northern China", "northern China"], "shots": {"0": {"k": 0, "answer": "East Asia", "latency_ms": 120.69892883300781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "northeastern China", "latency_ms": 453.17792892456055, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "northeastern China", "latency_ms": 374.94874000549316, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "Northeastern Asia", "latency_ms": 266.0253047943115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1879}, "4": {"k": 4, "answer": "Northeastern Asia", "latency_ms": 434.22889709472656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2481}, "5": {"k": 5, "answer": "northeastern China", "latency_ms": 149.53851699829102, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3131}, "6": {"k": 6, "answer": "East Asia", "latency_ms": 256.0415267944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3783}}}
{"qid": "-9151459252301477194", "question": "when did the legal drinking age changed to 21", "gold_answers": ["October 1986", "By mid-1988"], "shots": {"0": {"k": 0, "answer": "1984", "latency_ms": 181.77103996276855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 136.98148727416992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 688}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 97.97477722167969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1351}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 145.44153213500977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1980}, "4": {"k": 4, "answer": "Not even a year later", "latency_ms": 449.25975799560547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2635}, "5": {"k": 5, "answer": "short after the passage of the National Minimum Drinking Age Act", "latency_ms": 219.89798545837402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3224}, "6": {"k": 6, "answer": "after the passage of the National Minimum Drinking Age Act", "latency_ms": 253.4031867980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "333763277804609492", "question": "a player that can shoot pass or dribble is considered to be", "gold_answers": ["Triple threat"], "shots": {"0": {"k": 0, "answer": "all-around player", "latency_ms": 197.7853775024414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a valid player", "latency_ms": 310.37354469299316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 551}, "2": {"k": 2, "answer": "a player that can shoot, pass, or dribble is considered to be a versatile player.", "latency_ms": 538.5215282440186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1114}, "3": {"k": 3, "answer": "a player that can shoot, pass, or dribble is considered to be a versatile player.", "latency_ms": 510.2355480194092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1713}, "4": {"k": 4, "answer": "dynamic player", "latency_ms": 140.63715934753418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2285}, "5": {"k": 5, "answer": "a dynamic player", "latency_ms": 200.87742805480957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2898}, "6": {"k": 6, "answer": "a dynamic player", "latency_ms": 163.39945793151855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3479}}}
{"qid": "-938578705122215845", "question": "where does the spinal cord become cauda equina", "gold_answers": ["the conus medullaris", "L1 or L2"], "shots": {"0": {"k": 0, "answer": "L1 vertebra", "latency_ms": 296.39482498168945, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "T12 to L3", "latency_ms": 148.93627166748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "Lumbar cistern", "latency_ms": 269.0589427947998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "L3", "latency_ms": 114.71247673034668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1847}, "4": {"k": 4, "answer": "L3", "latency_ms": 165.0683879852295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "L3", "latency_ms": 185.5940818786621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3109}, "6": {"k": 6, "answer": "L3", "latency_ms": 160.89773178100586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3729}}}
{"qid": "-8834996069938989383", "question": "when did clifford the big red dog first air on tv", "gold_answers": ["September 4 , 2000"], "shots": {"0": {"k": 0, "answer": "1994", "latency_ms": 151.66711807250977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 4, 2000", "latency_ms": 149.0771770477295, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "September 4, 2000", "latency_ms": 257.8399181365967, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "September 4, 2000", "latency_ms": 307.34848976135254, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2007}, "4": {"k": 4, "answer": "September 4, 2000", "latency_ms": 172.8827953338623, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2694}, "5": {"k": 5, "answer": "September 4, 2000", "latency_ms": 452.301025390625, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3260}, "6": {"k": 6, "answer": "September 4, 2000", "latency_ms": 376.4801025390625, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3913}}}
{"qid": "-2953491529624297458", "question": "when was the last time kentucky won ncaa", "gold_answers": ["2012"], "shots": {"0": {"k": 0, "answer": "2023", "latency_ms": 260.5290412902832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 119.81201171875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "1949", "latency_ms": 132.0040225982666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1323}, "3": {"k": 3, "answer": "1949", "latency_ms": 125.61345100402832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2025}, "4": {"k": 4, "answer": "1958", "latency_ms": 284.41715240478516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2692}, "5": {"k": 5, "answer": "1958", "latency_ms": 417.5102710723877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3376}, "6": {"k": 6, "answer": "1986", "latency_ms": 307.09338188171387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3997}}}
{"qid": "1967531558485427303", "question": "what was guantanamo bay before it was a prison", "gold_answers": ["Guantanamo Bay Naval Base"], "shots": {"0": {"k": 0, "answer": "U.S. naval base", "latency_ms": 226.4711856842041, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Naval Base", "latency_ms": 230.07965087890625, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "United States Navy's base", "latency_ms": 135.10704040527344, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1423}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 246.56367301940918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2115}, "4": {"k": 4, "answer": "Naval Base", "latency_ms": 404.27207946777344, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2745}, "5": {"k": 5, "answer": "Naval Base", "latency_ms": 198.64225387573242, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3434}, "6": {"k": 6, "answer": "Naval Base", "latency_ms": 295.9575653076172, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 4135}}}
{"qid": "1265966537878407180", "question": "who was the 19th c. artist who was both painter and graphic designer", "gold_answers": ["René Georges Hermann - Paul"], "shots": {"0": {"k": 0, "answer": "James Abbott McNeill Whistler", "latency_ms": 190.77062606811523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 102.39481925964355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 136.9798183441162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "William Morris", "latency_ms": 82.81779289245605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1973}, "4": {"k": 4, "answer": "William Morris", "latency_ms": 86.74883842468262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2621}, "5": {"k": 5, "answer": "Walter Crane", "latency_ms": 204.00428771972656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3287}, "6": {"k": 6, "answer": "William Morris", "latency_ms": 276.6304016113281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4061}}}
{"qid": "6301453363028517703", "question": "what is dj's boyfriends name on full house", "gold_answers": ["Steven `` Steve '' Hale", "rich kid Nelson", "Viper", "Steve Hale"], "shots": {"0": {"k": 0, "answer": "D.J.'s boyfriend's name on Full House is **Jenny**.", "latency_ms": 636.2752914428711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 171.69952392578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 352.679967880249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 113.25955390930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "Steve Hale", "latency_ms": 89.49017524719238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2500}, "5": {"k": 5, "answer": "Steve Hale", "latency_ms": 117.1119213104248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3075}, "6": {"k": 6, "answer": "Steve Hale", "latency_ms": 139.3146514892578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3604}}}
{"qid": "3826862253571581938", "question": "who plays brad pitt's daughter in moneyball", "gold_answers": ["Kerris Lilla Dorsey"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 104.08663749694824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 143.18060874938965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 128.65805625915527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 110.02111434936523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1869}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 235.34774780273438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2502}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 351.6502380371094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3128}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 197.49879837036133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3743}}}
{"qid": "254065856937943955", "question": "who won season 2 of real chance of love", "gold_answers": ["Jackie DaFonseca", "Kamille Leai", "Hot Wings", "Doll"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.07049560546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ahmad Givens (Real) and Kamal", "latency_ms": 400.7382392883301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 261.59167289733887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 147.39394187927246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 339.3075466156006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2488}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 242.28549003601074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3141}, "6": {"k": 6, "answer": "Doll and Hot Wings", "latency_ms": 296.63538932800293, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3770}}}
{"qid": "-953849400724466906", "question": "where did huntington's disease get its name", "gold_answers": ["the physician George Huntington"], "shots": {"0": {"k": 0, "answer": "Dr. George Huntington", "latency_ms": 80.97624778747559, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "George Huntington", "latency_ms": 138.4594440460205, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "George Huntington", "latency_ms": 91.7823314666748, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "George Huntington", "latency_ms": 229.14385795593262, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2021}, "4": {"k": 4, "answer": "George Huntington", "latency_ms": 290.7230854034424, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2765}, "5": {"k": 5, "answer": "George Huntington", "latency_ms": 125.08368492126465, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3496}, "6": {"k": 6, "answer": "George Huntington", "latency_ms": 148.2412815093994, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4255}}}
{"qid": "664126784032076855", "question": "which nfl coach has the most superbowl rings", "gold_answers": ["Bill Belichick"], "shots": {"0": {"k": 0, "answer": "Bill Belichick", "latency_ms": 107.35630989074707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 317.7499771118164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "John Madden", "latency_ms": 57.48271942138672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1224}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 256.57153129577637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "Haley", "latency_ms": 87.94975280761719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2458}, "5": {"k": 5, "answer": "Haley", "latency_ms": 99.55310821533203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3102}, "6": {"k": 6, "answer": "Bill Belichick", "latency_ms": 495.5160617828369, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3703}}}
{"qid": "-5407234157766859145", "question": "turkey stuffed with a duck stuffed with a chicken", "gold_answers": ["Turducken"], "shots": {"0": {"k": 0, "answer": "Turkey", "latency_ms": 261.86466217041016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 184.7379207611084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 150.68912506103516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 215.78431129455566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1833}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 193.89033317565918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2444}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 144.72365379333496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3089}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 229.14481163024902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3743}}}
{"qid": "2884966474182044344", "question": "who won the first season of america's got talent", "gold_answers": ["Bianca Ryan"], "shots": {"0": {"k": 0, "answer": "David Letterman", "latency_ms": 248.2590675354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bianca Ryan", "latency_ms": 102.10752487182617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "Bianca Ryan", "latency_ms": 170.35794258117676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Bianca Ryan", "latency_ms": 107.17535018920898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Bianca Ryan", "latency_ms": 324.2499828338623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2498}, "5": {"k": 5, "answer": "Bianca Ryan", "latency_ms": 251.94215774536133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3157}, "6": {"k": 6, "answer": "Bianca Ryan", "latency_ms": 262.36724853515625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3762}}}
{"qid": "-4485639916525374363", "question": "how many books are in the one piece series", "gold_answers": ["more than 80", "83"], "shots": {"0": {"k": 0, "answer": "1000+", "latency_ms": 92.95821189880371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 85.06298065185547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 283.6611270904541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1320}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 151.91221237182617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1907}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 217.4391746520996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2507}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 146.82841300964355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3132}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 462.70155906677246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3741}}}
{"qid": "-5315423524940108616", "question": "where are the winter olympic games being held this year", "gold_answers": ["Pyeongchang County , South Korea"], "shots": {"0": {"k": 0, "answer": "2022 Winter Olympics: Beijing, China", "latency_ms": 431.05363845825195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 196.78449630737305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 441.65492057800293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1314}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 210.3900909423828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1974}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 175.0483512878418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 315.68288803100586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3245}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 214.8888111114502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3863}}}
{"qid": "-5061370765188535062", "question": "how many quarterbacks have a receiving touchdown in the superbowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "12", "latency_ms": 62.177181243896484, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 138.73028755187988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 429.7754764556885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 93.34063529968262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1834}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 176.78499221801758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 212.20993995666504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3090}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 186.3260269165039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3784}}}
{"qid": "-346866783760651662", "question": "when did ga state get a football team", "gold_answers": ["2010"], "shots": {"0": {"k": 0, "answer": "1933", "latency_ms": 109.64679718017578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 120.3622817993164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 144.61398124694824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 129.87685203552246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1833}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 233.36458206176758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2460}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 147.71485328674316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3121}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 226.1970043182373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3800}}}
{"qid": "1627235089487061878", "question": "when does the first nba basketball game start", "gold_answers": ["October 17 , 2017"], "shots": {"0": {"k": 0, "answer": "October 23, 2023", "latency_ms": 189.59283828735352, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 159.9295139312744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 728}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 103.82628440856934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1413}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 233.0796718597412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2069}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 166.0606861114502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2702}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 129.1518211364746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3305}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 164.38746452331543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3940}}}
{"qid": "6217752837777787594", "question": "who plays heather in beauty and the beast", "gold_answers": ["Nicole Gale Anderson"], "shots": {"0": {"k": 0, "answer": "Lily James", "latency_ms": 156.8281650543213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 115.88358879089355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 594}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 219.92802619934082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 161.87262535095215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 253.13997268676758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2530}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 359.6172332763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3160}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 155.03931045532227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3777}}}
{"qid": "7368254478874801356", "question": "who is the head of the department of homeland security 2017", "gold_answers": ["Kirstjen Nielsen"], "shots": {"0": {"k": 0, "answer": "John F. Kelly", "latency_ms": 306.32472038269043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John F. Kelly", "latency_ms": 192.4269199371338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 711}, "2": {"k": 2, "answer": "Kirstjen Nielsen", "latency_ms": 229.37321662902832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1432}, "3": {"k": 3, "answer": "Kirstjen Nielsen", "latency_ms": 304.0909767150879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2157}, "4": {"k": 4, "answer": "Kirstjen Nielsen", "latency_ms": 183.6533546447754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2865}, "5": {"k": 5, "answer": "Kirstjen Nielsen", "latency_ms": 222.84340858459473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3528}, "6": {"k": 6, "answer": "Kirstjen Nielsen", "latency_ms": 162.83869743347168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4201}}}
{"qid": "5009255319596563516", "question": "who has the most gold gloves at shortstop", "gold_answers": ["Ozzie Smith"], "shots": {"0": {"k": 0, "answer": "Joe DiMaggio", "latency_ms": 78.78684997558594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ozzie Smith", "latency_ms": 174.94702339172363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Ozzie Smith", "latency_ms": 182.39092826843262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Ozzie Smith", "latency_ms": 276.1523723602295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1794}, "4": {"k": 4, "answer": "Ozzie Smith", "latency_ms": 130.73182106018066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2390}, "5": {"k": 5, "answer": "Ozzie Smith", "latency_ms": 222.2762107849121, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3018}, "6": {"k": 6, "answer": "Luis Aparicio", "latency_ms": 365.2620315551758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3617}}}
{"qid": "7785057168624776860", "question": "who wore number 7 for the green bay packers", "gold_answers": ["Don Majkowski", "Quarterback Don Majkowski"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 236.72842979431152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 123.7800121307373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 198.7018585205078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 222.55396842956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1815}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 198.57072830200195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2479}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 173.07543754577637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3121}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 208.31584930419922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3742}}}
{"qid": "-908463397631188227", "question": "how long did the democrats control the house and senate", "gold_answers": ["57 yrs", "35 yrs"], "shots": {"0": {"k": 0, "answer": "2006–2010", "latency_ms": 149.7969627380371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "House: 1980–1994, 2006–present; Senate: 1980–1980, 2009–present", "latency_ms": 1264.568567276001, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "12 years", "latency_ms": 213.50431442260742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1349}, "3": {"k": 3, "answer": "12 years", "latency_ms": 96.0841178894043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2098}, "4": {"k": 4, "answer": "from 1930 until 1994", "latency_ms": 603.4548282623291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2803}, "5": {"k": 5, "answer": "from 1930 until 1994", "latency_ms": 464.30444717407227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3468}, "6": {"k": 6, "answer": "from 1930 until 1994", "latency_ms": 790.9188270568848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4130}}}
{"qid": "-7344570058818349307", "question": "who can be called a man of god", "gold_answers": ["prophets", "beloved religious leaders"], "shots": {"0": {"k": 0, "answer": "A person who lives according to God's teachings and values.", "latency_ms": 378.98707389831543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a righteous man", "latency_ms": 118.80612373352051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "a righteous man", "latency_ms": 209.3498706817627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1198}, "3": {"k": 3, "answer": "a righteous man", "latency_ms": 104.37726974487305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1764}, "4": {"k": 4, "answer": "a righteous man", "latency_ms": 99.56741333007812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2325}, "5": {"k": 5, "answer": "a righteous man", "latency_ms": 253.65495681762695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2858}, "6": {"k": 6, "answer": "a righteous man", "latency_ms": 216.54319763183594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3442}}}
{"qid": "-5255735265739582707", "question": "a system of fortifications along france's border", "gold_answers": ["Maginot Line", "The Maginot Line"], "shots": {"0": {"k": 0, "answer": "Maginot Line", "latency_ms": 83.44411849975586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 166.3055419921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 688}, "2": {"k": 2, "answer": "Séré de Rivières system", "latency_ms": 574.1491317749023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1362}, "3": {"k": 3, "answer": "Séré de Rivières system", "latency_ms": 245.28765678405762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2064}, "4": {"k": 4, "answer": "Alpine Line", "latency_ms": 212.36443519592285, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2693}, "5": {"k": 5, "answer": "Alpine Line", "latency_ms": 355.8471202850342, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3318}, "6": {"k": 6, "answer": "Maginot Line", "latency_ms": 339.569091796875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3988}}}
{"qid": "-521349963474269802", "question": "who wrote ain't living long like this", "gold_answers": ["Rodney Crowell"], "shots": {"0": {"k": 0, "answer": "John Lennon", "latency_ms": 268.2323455810547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rodney Crowell", "latency_ms": 104.01010513305664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "Rodney Crowell", "latency_ms": 191.36738777160645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1246}, "3": {"k": 3, "answer": "Rodney Crowell", "latency_ms": 208.7078094482422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1856}, "4": {"k": 4, "answer": "Rodney Crowell", "latency_ms": 234.2855930328369, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2469}, "5": {"k": 5, "answer": "Rodney Crowell", "latency_ms": 219.77663040161133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Rodney Crowell", "latency_ms": 299.40104484558105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3814}}}
{"qid": "-7607504458781868831", "question": "what is the name of the skin between your nostrils", "gold_answers": ["the nasal septum", "septum"], "shots": {"0": {"k": 0, "answer": "nasal septum", "latency_ms": 379.8949718475342, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "curtain of skin", "latency_ms": 88.84882926940918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "curtain of skin", "latency_ms": 331.36940002441406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1181}, "3": {"k": 3, "answer": "curtain of skin", "latency_ms": 143.82362365722656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1793}, "4": {"k": 4, "answer": "curtain of skin", "latency_ms": 288.15197944641113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2416}, "5": {"k": 5, "answer": "curtain of skin", "latency_ms": 237.54596710205078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3040}, "6": {"k": 6, "answer": "curtain of skin", "latency_ms": 243.90268325805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3696}}}
{"qid": "-1142715461435497032", "question": "what is the biggest town in west virginia", "gold_answers": ["Charleston"], "shots": {"0": {"k": 0, "answer": "Charleston", "latency_ms": 73.45724105834961, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 207.8554630279541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 215.98458290100098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 269.95086669921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 230.81374168395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2402}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 377.16197967529297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 301.78070068359375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "-3617986561170614700", "question": "when does monday night raw come on hulu", "gold_answers": ["the following day"], "shots": {"0": {"k": 0, "answer": "Monday Night Raw airs on Hulu at 8:00 PM ET.", "latency_ms": 485.87512969970703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the following day", "latency_ms": 125.50902366638184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "the following day", "latency_ms": 79.88977432250977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1151}, "3": {"k": 3, "answer": "the following day", "latency_ms": 276.20935440063477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1762}, "4": {"k": 4, "answer": "the following day as a condensed 90 minute version", "latency_ms": 314.2569065093994, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2324}, "5": {"k": 5, "answer": "the following day as a condensed 90 minute version", "latency_ms": 208.66727828979492, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2923}, "6": {"k": 6, "answer": "the following day as a condensed 90 minute version", "latency_ms": 297.30677604675293, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3497}}}
{"qid": "-7768138227276540998", "question": "who become ceo of wipro company in 2016", "gold_answers": ["Abid Ali Neemuchwala"], "shots": {"0": {"k": 0, "answer": "S. Gopalakrishnan", "latency_ms": 641.7007446289062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wipro CEO in 2016: [Name not provided in context]", "latency_ms": 727.1571159362793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 682}, "2": {"k": 2, "answer": "Abidali Neemuchwala", "latency_ms": 268.39566230773926, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1310}, "3": {"k": 3, "answer": "Abidali Neemuchwala", "latency_ms": 333.33683013916016, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "Abidali Neemuchwala", "latency_ms": 451.4164924621582, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2610}, "5": {"k": 5, "answer": "Abidali Neemuchwala", "latency_ms": 438.2646083831787, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3199}, "6": {"k": 6, "answer": "Abidali Neemuchwala", "latency_ms": 346.4977741241455, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3839}}}
{"qid": "-145926233057232882", "question": "what is the breakdown product formed when one phosphate group is removed from atp", "gold_answers": ["adenosine diphosphate ( ADP )"], "shots": {"0": {"k": 0, "answer": "ADP", "latency_ms": 155.7750701904297, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ADP", "latency_ms": 59.748172760009766, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 669}, "2": {"k": 2, "answer": "ADP", "latency_ms": 89.26892280578613, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1374}, "3": {"k": 3, "answer": "ADP", "latency_ms": 120.16153335571289, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "ADP", "latency_ms": 133.95023345947266, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2736}, "5": {"k": 5, "answer": "adenosine diphosphate (ADP)", "latency_ms": 547.5704669952393, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3422}, "6": {"k": 6, "answer": "adenosine diphosphate (ADP)", "latency_ms": 292.7687168121338, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4111}}}
{"qid": "-2520765213268223500", "question": "ahana from dil sambhal ja zara real name", "gold_answers": ["Smriti Kalra"], "shots": {"0": {"k": 0, "answer": "Alisha Sharma", "latency_ms": 246.30022048950195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ahana", "latency_ms": 226.46641731262207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 203.30429077148438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 262.88509368896484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1826}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 323.519229888916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2451}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 221.5290069580078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3086}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 177.7341365814209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3684}}}
{"qid": "-7267574651947029426", "question": "to transplant a nucleus from one cell to another cell a scientist would use", "gold_answers": ["somatic cell nuclear transfer"], "shots": {"0": {"k": 0, "answer": "nuclear transfer", "latency_ms": 99.5790958404541, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "somatic cell nuclear transfer", "latency_ms": 95.43728828430176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 667}, "2": {"k": 2, "answer": "somatic cell nuclear transfer", "latency_ms": 100.34394264221191, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1354}, "3": {"k": 3, "answer": "somatic cell nuclear transfer", "latency_ms": 177.36554145812988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2005}, "4": {"k": 4, "answer": "somatic cell nuclear transfer", "latency_ms": 343.7018394470215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2627}, "5": {"k": 5, "answer": "somatic cell nuclear transfer", "latency_ms": 302.14548110961914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3263}, "6": {"k": 6, "answer": "somatic cell nuclear transfer", "latency_ms": 228.7604808807373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3939}}}
{"qid": "3840901317699168424", "question": "what does a bull shark tooth look like", "gold_answers": ["needle - like teeth", "needle - like"], "shots": {"0": {"k": 0, "answer": "Pointed, sharp, and serrated", "latency_ms": 128.7689208984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 143.01705360412598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "pointed lower teeth with triangular upper teeth", "latency_ms": 359.0044975280762, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "pointed lower teeth with triangular upper teeth", "latency_ms": 178.50470542907715, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "pointed lower teeth with triangular upper teeth", "latency_ms": 475.9058952331543, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "pointed lower teeth with triangular upper teeth", "latency_ms": 289.93868827819824, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 3039}, "6": {"k": 6, "answer": "pointed lower teeth with triangular upper teeth", "latency_ms": 179.99744415283203, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 3725}}}
{"qid": "-1163524811252371834", "question": "who played the girl in my two dads", "gold_answers": ["Staci Keanan"], "shots": {"0": {"k": 0, "answer": "Morgan Freeman", "latency_ms": 134.50980186462402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amy Hathaway", "latency_ms": 184.8921775817871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "Amy Hathaway", "latency_ms": 127.17032432556152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Amy Hathaway", "latency_ms": 193.42470169067383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1771}, "4": {"k": 4, "answer": "Amy Hathaway", "latency_ms": 178.9724826812744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "Amy Hathaway", "latency_ms": 282.2387218475342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3059}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 238.22402954101562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3634}}}
{"qid": "-8152430794227425375", "question": "what type of planet is neptune known as", "gold_answers": ["ice giants", "giant"], "shots": {"0": {"k": 0, "answer": "ice giant", "latency_ms": 97.35798835754395, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "giant planet", "latency_ms": 159.00087356567383, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 573}, "2": {"k": 2, "answer": "giant planet", "latency_ms": 179.86726760864258, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1167}, "3": {"k": 3, "answer": "giant planet", "latency_ms": 179.1095733642578, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1808}, "4": {"k": 4, "answer": "giant planet", "latency_ms": 122.01714515686035, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2384}, "5": {"k": 5, "answer": "giant planet", "latency_ms": 118.1643009185791, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3007}, "6": {"k": 6, "answer": "ice giant", "latency_ms": 303.4238815307617, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3633}}}
{"qid": "-5738106146117683016", "question": "when do love and hip hop new york come back on", "gold_answers": ["November 13 , 2017", "October 30 , 2017"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 132.68566131591797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 28, 2013", "latency_ms": 297.6231575012207, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "October 28, 2013", "latency_ms": 226.0572910308838, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "November 21, 2016", "latency_ms": 388.3368968963623, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "November 21, 2016", "latency_ms": 383.4078311920166, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2466}, "5": {"k": 5, "answer": "December 14, 2015", "latency_ms": 552.3409843444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3129}, "6": {"k": 6, "answer": "December 14, 2015", "latency_ms": 276.98469161987305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3683}}}
{"qid": "-3970079294139411862", "question": "how many gallons of water in the gulf of mexico", "gold_answers": ["660 quadrillion US gallons"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 80.27434349060059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "660 quadrillion US gallons", "latency_ms": 129.37664985656738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "660 quadrillion US gallons", "latency_ms": 363.8343811035156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1258}, "3": {"k": 3, "answer": "660 quadrillion US gallons", "latency_ms": 153.2156467437744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "660 quadrillion US gallons", "latency_ms": 146.73852920532227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2535}, "5": {"k": 5, "answer": "2,500 quadrillion gallons", "latency_ms": 199.20039176940918, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "660 quadrillion US gallons", "latency_ms": 317.59119033813477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3814}}}
{"qid": "810772972080024175", "question": "anastomosis between the epididymis and the vas deferens", "gold_answers": ["Vasoepididymostomy"], "shots": {"0": {"k": 0, "answer": "ampullary anastomosis", "latency_ms": 281.7196846008301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 242.6314353942871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 398.8156318664551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 292.27304458618164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1935}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 149.99151229858398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2547}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 211.42983436584473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 207.47137069702148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3801}}}
{"qid": "-4044344454441564632", "question": "who is given credit for inventing the aqua lung", "gold_answers": ["Jacques Cousteau", "Émile Gagnan", "engineer Émile Gagnan"], "shots": {"0": {"k": 0, "answer": "Jacques Cousteau", "latency_ms": 413.09547424316406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jacques-Yves Cousteau and Émile Gagnan", "latency_ms": 325.35409927368164, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 638}, "2": {"k": 2, "answer": "Jacques-Yves Cousteau and Émile Gagnan", "latency_ms": 694.3717002868652, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Jacques-Yves Cousteau and Émile Gagnan", "latency_ms": 834.057092666626, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Jacques-Yves Cousteau and Émile Gagnan", "latency_ms": 539.8068428039551, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2591}, "5": {"k": 5, "answer": "Jacques-Yves Cousteau and Émile Gagnan", "latency_ms": 510.75291633605957, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3194}, "6": {"k": 6, "answer": "Jacques-Yves Cousteau and Émile Gagnan", "latency_ms": 460.56056022644043, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3876}}}
{"qid": "950913319015411203", "question": "where did the name huey helicopter come from", "gold_answers": ["originally designated HU - 1"], "shots": {"0": {"k": 0, "answer": "Huey came from \"Huey,\" a nickname for \"Huey,\" a name given to the helicopter by U.S. Army personnel during the Vietnam War, derived from the name of the helicopter's manufacturer, Bell, and the model designation H-13. The name \"Huey\" was popularized by the U.S. military and became widely used in media and public discourse. The name was not officially derived from a person's name but from the model designation and military slang. The name \"Huey\" was used to refer to the Bell UH-1 Iroquois helicopter. The name \"Huey\" was derived from the model designation \"H-13\" and the nickname \"Huey\" given by U.S. Army personnel during the Vietnam War. The name \"Huey\" was not derived from a person's name but from the model designation and military slang. The name \"Huey\" was used to refer to the Bell UH-1 Iroquois helicopter. The name \"Huey\" was derived from the model designation \"H-13\" and the nickname \"Huey\" given by U.S. Army personnel during the Vietnam War. The name \"H", "latency_ms": 8435.13011932373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "HU-1 designation", "latency_ms": 145.12252807617188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "HU-1 designation", "latency_ms": 196.07090950012207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1351}, "3": {"k": 3, "answer": "HU-1 designation", "latency_ms": 248.63910675048828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "HU-1 designation", "latency_ms": 374.24755096435547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2621}, "5": {"k": 5, "answer": "HU-1 designation", "latency_ms": 491.75572395324707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3285}, "6": {"k": 6, "answer": "HU-1 designation", "latency_ms": 217.37289428710938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3960}}}
{"qid": "-6762183708006311163", "question": "when did dragon ball super tournament of power start", "gold_answers": ["February 19 , 2017"], "shots": {"0": {"k": 0, "answer": "2018", "latency_ms": 193.81260871887207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 160.1393222808838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 173.43544960021973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 252.9623508453369, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 164.59393501281738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2553}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 182.88636207580566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3181}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 325.24895668029785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3817}}}
{"qid": "7143040220722532389", "question": "when was it was not death for i stood up published", "gold_answers": ["1890", "1891"], "shots": {"0": {"k": 0, "answer": "1968", "latency_ms": 171.0498332977295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 392.24839210510254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 152.64391899108887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 143.5558795928955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 276.88097953796387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 410.6252193450928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3089}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 226.58109664916992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3697}}}
{"qid": "-5748368670037082784", "question": "what is the definition of the name thomas", "gold_answers": ["twin", "`` twin ''"], "shots": {"0": {"k": 0, "answer": "Masculine given name of Hebrew origin, meaning \"twin\" or \"town\"", "latency_ms": 403.77330780029297, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 80.23238182067871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 92.58508682250977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1341}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 233.06703567504883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2041}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 357.5887680053711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2750}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 266.72911643981934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3398}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 228.743314743042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4009}}}
{"qid": "8190949321615211886", "question": "actress who plays penelope garcia on criminal minds", "gold_answers": ["Kirsten Simone Vangsness"], "shots": {"0": {"k": 0, "answer": "Megan Fox", "latency_ms": 99.32446479797363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kirsten Vangsness", "latency_ms": 159.61575508117676, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "Kirsten Vangsness", "latency_ms": 263.3359432220459, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "Kirsten Vangsness", "latency_ms": 279.8421382904053, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Kirsten Vangsness", "latency_ms": 202.5010585784912, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2485}, "5": {"k": 5, "answer": "Kirsten Vangsness", "latency_ms": 458.7984085083008, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3109}, "6": {"k": 6, "answer": "Kirsten Vangsness", "latency_ms": 544.3189144134521, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3741}}}
{"qid": "-9203958203595622889", "question": "who is president of india in present time", "gold_answers": ["Ram Nath Kovind"], "shots": {"0": {"k": 0, "answer": "Narendra Modi", "latency_ms": 81.54106140136719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Droupadi Murmu", "latency_ms": 384.169340133667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 165.85206985473633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 96.73500061035156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 109.62557792663574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2519}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 159.72018241882324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3118}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 127.2892951965332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3768}}}
{"qid": "-2349691009719617713", "question": "why did kevin can't wait wife leave the show", "gold_answers": ["creative reasons"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 348.93798828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 257.9841613769531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 254.3201446533203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Hayes' character was killed off to make room for Remini.", "latency_ms": 863.994836807251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "Hayes' character was killed off to make room for Remini.", "latency_ms": 596.6475009918213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2430}, "5": {"k": 5, "answer": "Hayes' character was killed off before season two began to make room for Remini.", "latency_ms": 713.7680053710938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3054}, "6": {"k": 6, "answer": "Hayes' character was killed off to make room for Remini.", "latency_ms": 346.9521999359131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3698}}}
{"qid": "1442521968114516256", "question": "when did season 4 of glee come out", "gold_answers": ["September 13 , 2012"], "shots": {"0": {"k": 0, "answer": "2012", "latency_ms": 148.04458618164062, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 13, 2012", "latency_ms": 372.5888729095459, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "September 13, 2012", "latency_ms": 347.3176956176758, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1310}, "3": {"k": 3, "answer": "September 13, 2012", "latency_ms": 355.1907539367676, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "September 13, 2012", "latency_ms": 488.1463050842285, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2603}, "5": {"k": 5, "answer": "September 13, 2012", "latency_ms": 271.89087867736816, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3238}, "6": {"k": 6, "answer": "September 13, 2012", "latency_ms": 319.7479248046875, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3835}}}
{"qid": "4920082918364942541", "question": "who were the major countries involved in the cold war", "gold_answers": ["the Soviet Union", "the United States"], "shots": {"0": {"k": 0, "answer": "USA, USSR, UK, France, China, Canada, West Germany, East Germany", "latency_ms": 268.50056648254395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "United States, Canada, Soviet Union", "latency_ms": 117.23160743713379, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "United States and Soviet Union", "latency_ms": 359.68852043151855, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "United States and Soviet Union", "latency_ms": 122.6499080657959, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "United States, Soviet Union, Great Britain", "latency_ms": 164.86835479736328, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2603}, "5": {"k": 5, "answer": "United States and Soviet Union", "latency_ms": 227.29754447937012, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3256}, "6": {"k": 6, "answer": "United States, Soviet Union, United Kingdom, Canada", "latency_ms": 214.91575241088867, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3934}}}
{"qid": "2607341085762662184", "question": "what is the main use of the eiffel tower in modern times", "gold_answers": ["visited paid monument", "paid monument"], "shots": {"0": {"k": 0, "answer": "Tourist attraction", "latency_ms": 276.34215354919434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "symbol of Paris and the city in popular culture", "latency_ms": 384.5782279968262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "symbol of Paris or the city in popular culture", "latency_ms": 730.506420135498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1165}, "3": {"k": 3, "answer": "symbol of Paris and a well-known visual element in fiction", "latency_ms": 457.60512351989746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1737}, "4": {"k": 4, "answer": "symbol of Paris and a well-known visual element in fiction", "latency_ms": 402.52065658569336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2376}, "5": {"k": 5, "answer": "symbol of Paris and a prominent visual element in fiction and media", "latency_ms": 511.02614402770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3038}, "6": {"k": 6, "answer": "iconic symbol of Paris and a frequent element in fiction and media", "latency_ms": 438.0373954772949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3630}}}
{"qid": "3221048264431718328", "question": "sweet leavened bread prepared for easter in romania", "gold_answers": ["Cozonac", "Kozunak"], "shots": {"0": {"k": 0, "answer": "Pâine de Paște", "latency_ms": 385.3955268859863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 208.75883102416992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 241.96887016296387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 243.76606941223145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "pască", "latency_ms": 263.77224922180176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2600}, "5": {"k": 5, "answer": "pască", "latency_ms": 108.48426818847656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3193}, "6": {"k": 6, "answer": "Pasca", "latency_ms": 186.82551383972168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3860}}}
{"qid": "-5864856625806411702", "question": "chief ministers of tamil nadu mentioned on wikipedia", "gold_answers": ["Tanguturi Prakasam", "Ramakrishna Ranga Rao", "Janaki Ramachandran", "O. Panneerselvam", "Raja of Panagal", "O.P. Ramaswamy Reddiyar", "P.S. Kumaraswamy Raja", "C. Rajagopalachari", "B. Munuswamy Naidu", "A. Subbarayalu Reddiar", "K. Palaniswami", "P.T. Rajan", "M. Karunanidhi", "C.N. Annadurai", "V.R. Nedunchezhiyan", "J. Jayalalithaa", "Kurma Venkata Reddy Naidu", "M.G. Ramachandran", "P. Subbarayan"], "shots": {"0": {"k": 0, "answer": "J. Jayalalithaa, M. Karunanidhi, Edappadi K. Palaniswami, O. Panneerselvam, A. G. K. M. S. R. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M. S. R. M", "latency_ms": 8550.639152526855, "em": 0.0, "f1": 0.03305785123966942, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 160.9787940979004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "Edappadi K. Palanisamy, Panneerselvam", "latency_ms": 418.03526878356934, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1357}, "3": {"k": 3, "answer": "Edappadi K. Palanisamy", "latency_ms": 327.54063606262207, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2005}, "4": {"k": 4, "answer": "Edappadi K. Palanisamy", "latency_ms": 471.3578224182129, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2658}, "5": {"k": 5, "answer": "Edappadi K. Palanisamy", "latency_ms": 457.1523666381836, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3393}, "6": {"k": 6, "answer": "Edappadi K. Palanisamy", "latency_ms": 316.739559173584, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4031}}}
{"qid": "-6145868466021183224", "question": "who played solomon in little house on the prairie", "gold_answers": ["Todd Bridges"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 282.451868057251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 145.57933807373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 685}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 208.59646797180176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1314}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 281.5887928009033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 126.6334056854248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 199.53346252441406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3263}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 212.890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3907}}}
{"qid": "-3573392112612030278", "question": "who got the first arjun award in athletics", "gold_answers": ["Gurbachan Singh Randhawa"], "shots": {"0": {"k": 0, "answer": "K. M. S. Rama Rao", "latency_ms": 313.7674331665039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 261.66391372680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 677}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 134.4010829925537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 468.0483341217041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 108.30879211425781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 175.2617359161377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 278.03564071655273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3707}}}
{"qid": "-8209571805051987276", "question": "what is the genus of a bald eagle", "gold_answers": ["Haliaeetus"], "shots": {"0": {"k": 0, "answer": "Haliaeetus", "latency_ms": 229.96139526367188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haliaeetus", "latency_ms": 284.76738929748535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "Haliaeetus", "latency_ms": 150.9683132171631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Haliaeetus", "latency_ms": 352.32067108154297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Haliaeetus", "latency_ms": 246.75226211547852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2601}, "5": {"k": 5, "answer": "Haliaeetus", "latency_ms": 301.00250244140625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3266}, "6": {"k": 6, "answer": "Haliaeetus", "latency_ms": 297.5506782531738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3920}}}
{"qid": "7062924428870783818", "question": "who directed the best years of our lives", "gold_answers": ["William Wyler"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 139.64247703552246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "William Wyler", "latency_ms": 71.06494903564453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 636}, "2": {"k": 2, "answer": "William Wyler", "latency_ms": 221.82559967041016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "William Wyler", "latency_ms": 171.22149467468262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "William Wyler", "latency_ms": 167.8030490875244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2503}, "5": {"k": 5, "answer": "William Wyler", "latency_ms": 131.8075656890869, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3119}, "6": {"k": 6, "answer": "William Wyler", "latency_ms": 154.9055576324463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3709}}}
{"qid": "6882831655380911332", "question": "which british city is farthest from the sea", "gold_answers": ["Coton in the Elms"], "shots": {"0": {"k": 0, "answer": "Birmingham", "latency_ms": 136.17277145385742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Meriden", "latency_ms": 100.44074058532715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 374.16648864746094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Morton, Derbyshire", "latency_ms": 404.34885025024414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 117.68937110900879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2542}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 458.03070068359375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3137}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 262.2814178466797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3796}}}
{"qid": "7895715200373578920", "question": "how many characters are present in icd-10 codes", "gold_answers": ["7"], "shots": {"0": {"k": 0, "answer": "7", "latency_ms": 100.61240196228027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 213.3004665374756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "7", "latency_ms": 88.9122486114502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1389}, "3": {"k": 3, "answer": "7", "latency_ms": 70.27888298034668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2018}, "4": {"k": 4, "answer": "7", "latency_ms": 207.655668258667, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2656}, "5": {"k": 5, "answer": "ICD-10 codes vary in length; ICD-10-CM has over 70,000 codes, but specific character count not provided. I cannot answer.", "latency_ms": 1544.9292659759521, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3305}, "6": {"k": 6, "answer": "7", "latency_ms": 106.95123672485352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3982}}}
{"qid": "-8464536395541330825", "question": "which layer of the meninges is connected to the brain", "gold_answers": ["pia mater", "The pia mater"], "shots": {"0": {"k": 0, "answer": "dura mater", "latency_ms": 87.65625953674316, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "pia mater", "latency_ms": 143.20039749145508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 587}, "2": {"k": 2, "answer": "pia mater", "latency_ms": 83.68229866027832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1217}, "3": {"k": 3, "answer": "pia mater", "latency_ms": 220.33333778381348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1869}, "4": {"k": 4, "answer": "pia mater", "latency_ms": 260.90550422668457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2476}, "5": {"k": 5, "answer": "pia mater", "latency_ms": 316.2710666656494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3075}, "6": {"k": 6, "answer": "pia mater", "latency_ms": 269.4258689880371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3720}}}
{"qid": "-4392475526001139368", "question": "who was first governor general of british india", "gold_answers": ["Warren Hastings", "Louis Mountbatten"], "shots": {"0": {"k": 0, "answer": "Lord Cornwallis", "latency_ms": 141.33548736572266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Warren Hastings", "latency_ms": 112.29753494262695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 675}, "2": {"k": 2, "answer": "Warren Hastings", "latency_ms": 102.25105285644531, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1359}, "3": {"k": 3, "answer": "Lord William Bentinck", "latency_ms": 119.6599006652832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2057}, "4": {"k": 4, "answer": "Lord William Bentinck", "latency_ms": 160.5527400970459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2720}, "5": {"k": 5, "answer": "Lord William Bentinck", "latency_ms": 358.3822250366211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3401}, "6": {"k": 6, "answer": "Lord William Bentinck", "latency_ms": 384.34696197509766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4097}}}
{"qid": "-4487724214437405890", "question": "where is the heart of palm on a palm tree", "gold_answers": ["the center core", "the inner core", "growing bud", "inner core and growing bud"], "shots": {"0": {"k": 0, "answer": "It is not on a palm tree.", "latency_ms": 296.4763641357422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "center core", "latency_ms": 58.66265296936035, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "center core or heart of palm", "latency_ms": 391.8602466583252, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "inner core and growing bud", "latency_ms": 148.43249320983887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1888}, "4": {"k": 4, "answer": "inner core and growing bud", "latency_ms": 240.34452438354492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "inner core and growing bud", "latency_ms": 142.55714416503906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3058}, "6": {"k": 6, "answer": "inner core and growing bud", "latency_ms": 230.02243041992188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3664}}}
{"qid": "-6162933554898709661", "question": "which player won the pga championship by the most shots", "gold_answers": ["Rory McIlroy"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 112.42032051086426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack Nicklaus", "latency_ms": 138.43035697937012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 137.9868984222412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "Jack Nicklaus", "latency_ms": 132.9972743988037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "Jack Nicklaus", "latency_ms": 124.6328353881836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2395}, "5": {"k": 5, "answer": "Jack Nicklaus", "latency_ms": 210.1724147796631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2978}, "6": {"k": 6, "answer": "Jack Nicklaus", "latency_ms": 138.74125480651855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3645}}}
{"qid": "-1342189058950802702", "question": "who made the poppies at tower of london", "gold_answers": ["Tom Piper", "stage designer Tom Piper", "Paul Cummins"], "shots": {"0": {"k": 0, "answer": "The Royal British Legion", "latency_ms": 185.58549880981445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 133.9402198791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 110.53991317749023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1189}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 227.8304100036621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1788}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 425.9054660797119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2422}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 226.98020935058594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3026}, "6": {"k": 6, "answer": "Cummins's ceramics works in Derbyshire and Johnson Tiles in Tunstall, Stoke-on-Trent", "latency_ms": 668.6747074127197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3710}}}
{"qid": "-6531366728667964971", "question": "what is the inner core of the earth made from", "gold_answers": ["some other elements", "iron -- nickel alloy", "an iron -- nickel alloy"], "shots": {"0": {"k": 0, "answer": "Iron and nickel", "latency_ms": 151.8990993499756, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "iron–nickel alloy and some other elements", "latency_ms": 306.8103790283203, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 577}, "2": {"k": 2, "answer": "iron–nickel alloy and some other elements", "latency_ms": 156.07261657714844, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1159}, "3": {"k": 3, "answer": "iron–nickel alloy and some other elements", "latency_ms": 454.0388584136963, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1763}, "4": {"k": 4, "answer": "iron–nickel alloy and some other elements", "latency_ms": 276.3988971710205, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2350}, "5": {"k": 5, "answer": "iron–nickel alloy and some other elements", "latency_ms": 308.8362216949463, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2946}, "6": {"k": 6, "answer": "iron–nickel alloy and some other elements", "latency_ms": 315.7212734222412, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3578}}}
{"qid": "608136254238749812", "question": "where did the british army launch a successful invasion in 1776", "gold_answers": ["Long Island", "New York"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 250.90384483337402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 396.15535736083984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 703}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 130.4783821105957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1356}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 213.3798599243164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Savannah", "latency_ms": 299.1199493408203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2728}, "5": {"k": 5, "answer": "Savannah", "latency_ms": 270.6308364868164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3366}, "6": {"k": 6, "answer": "Savannah", "latency_ms": 121.3521957397461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4079}}}
{"qid": "-4049786002203271572", "question": "who wrote the guitar solo in beat it", "gold_answers": ["Eddie Van Halen"], "shots": {"0": {"k": 0, "answer": "Eddie Van Halen", "latency_ms": 88.22512626647949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Mayer", "latency_ms": 59.7689151763916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 534}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 100.66509246826172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1099}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 207.93581008911133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1723}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 190.05680084228516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2375}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 294.57855224609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3010}, "6": {"k": 6, "answer": "Eddie Van Halen", "latency_ms": 160.36152839660645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3638}}}
{"qid": "-2033893527164697325", "question": "who was the first executive president of guyana", "gold_answers": ["Forbes Burnham", "Arthur Chung"], "shots": {"0": {"k": 0, "answer": "Burns G. Phillips", "latency_ms": 89.3392562866211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Forbes Burnham", "latency_ms": 174.05390739440918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 679}, "2": {"k": 2, "answer": "Forbes Burnham", "latency_ms": 389.77527618408203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Forbes Burnham", "latency_ms": 367.2640323638916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1999}, "4": {"k": 4, "answer": "Forbes Burnham", "latency_ms": 174.60083961486816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2658}, "5": {"k": 5, "answer": "Forbes Burnham", "latency_ms": 228.41691970825195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3330}, "6": {"k": 6, "answer": "Forbes Burnham", "latency_ms": 429.049015045166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3947}}}
{"qid": "-7555953957057409422", "question": "who plays sven in the santa clarita diet", "gold_answers": ["Leo Howard"], "shots": {"0": {"k": 0, "answer": "Ethan Suplee", "latency_ms": 213.76657485961914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 192.0027732849121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 705}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 198.12679290771484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 109.31801795959473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2037}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 371.0658550262451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2655}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 121.36530876159668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3358}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 225.86989402770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3983}}}
{"qid": "4639443563976072562", "question": "term limits for house of representatives and senate", "gold_answers": ["Unlimited six - year terms", "Unlimited two - year terms"], "shots": {"0": {"k": 0, "answer": "House: 2 term limits; Senate: no term limits", "latency_ms": 832.2324752807617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "calls for term limits", "latency_ms": 388.70882987976074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "no term limits", "latency_ms": 137.76445388793945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Michigan: three two-year terms; Washington: no term limits", "latency_ms": 617.3570156097412, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 1991}, "4": {"k": 4, "answer": "Oklahoma: 12 years total service; Michigan: 3 two-year terms; Washington: no term limits", "latency_ms": 1011.587381362915, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "Michigan: House - 3 two-year terms, Senate - 2 four-year terms; Oklahoma: total of 12 years in both houses; Washington: no term limits", "latency_ms": 1930.7525157928467, "em": 0.0, "f1": 0.08, "containment": 0.0, "context_chars": 3351}, "6": {"k": 6, "answer": "Michigan: House - 3 two-year terms, Senate - 2 four-year terms; Oklahoma: total of 12 years in both houses; Washington: no term limits", "latency_ms": 1282.6504707336426, "em": 0.0, "f1": 0.08, "containment": 0.0, "context_chars": 4014}}}
{"qid": "-7264742768431676142", "question": "who hosted and won the inagural world cup", "gold_answers": ["Uruguay"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 345.8130359649658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 283.0033302307129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 188.70162963867188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1138}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 176.3601303100586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1722}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 274.4157314300537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2321}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 191.03598594665527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2932}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 404.1719436645508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3527}}}
{"qid": "-755777782301038229", "question": "iupac name of element with atomic number 107", "gold_answers": ["Bohrium", "bohrium"], "shots": {"0": {"k": 0, "answer": "Bohrium", "latency_ms": 67.65508651733398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bohrium", "latency_ms": 76.79462432861328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Bh", "latency_ms": 71.63333892822266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1339}, "3": {"k": 3, "answer": "ununseptium", "latency_ms": 121.69194221496582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2004}, "4": {"k": 4, "answer": "ununennium", "latency_ms": 414.3557548522949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2658}, "5": {"k": 5, "answer": "ununennium", "latency_ms": 368.55006217956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3295}, "6": {"k": 6, "answer": "ununennium", "latency_ms": 233.82043838500977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3974}}}
{"qid": "-564063817056958231", "question": "when does boomer find out she a cylon", "gold_answers": ["Kobol 's Last Gleaming"], "shots": {"0": {"k": 0, "answer": "Season 4, Episode 13 \"The Long Way Home\"", "latency_ms": 491.01901054382324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 171.41127586364746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "when Baltar's Cylon detector reveals that Boomer is indeed a Cylon", "latency_ms": 820.9536075592041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "saved his life on Caprica", "latency_ms": 172.1322536468506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "saved his life on Caprica", "latency_ms": 135.94841957092285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2500}, "5": {"k": 5, "answer": "saved his life on Caprica", "latency_ms": 294.1699028015137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "Flesh and Bone (Battlestar Galactica)", "latency_ms": 246.01459503173828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3727}}}
{"qid": "2010294071842366580", "question": "who wrote the treasure of the sierra madre", "gold_answers": ["B. Traven", "bilingual German author B. Traven"], "shots": {"0": {"k": 0, "answer": "John Steinbeck", "latency_ms": 63.87138366699219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "B. Traven", "latency_ms": 115.38195610046387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "B. Traven", "latency_ms": 289.22152519226074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1252}, "3": {"k": 3, "answer": "B. Traven", "latency_ms": 353.26504707336426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "B. Traven", "latency_ms": 271.1794376373291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2539}, "5": {"k": 5, "answer": "B. Traven", "latency_ms": 209.73730087280273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3116}, "6": {"k": 6, "answer": "B. Traven", "latency_ms": 207.53884315490723, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3765}}}
{"qid": "-838090964585984539", "question": "what was the name of darth vader star destroyer", "gold_answers": ["Devastator", "the Devastator"], "shots": {"0": {"k": 0, "answer": "Devastator", "latency_ms": 296.69785499572754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 293.29895973205566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Star Destroyer", "latency_ms": 126.48701667785645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 363.4350299835205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 162.02402114868164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 178.27630043029785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3193}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 141.71814918518066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3842}}}
{"qid": "5980486301760893723", "question": "what is the female lion called in lion king", "gold_answers": ["Nala"], "shots": {"0": {"k": 0, "answer": "Nala", "latency_ms": 131.6547393798828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nala", "latency_ms": 153.25331687927246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 568}, "2": {"k": 2, "answer": "Leo II", "latency_ms": 121.61374092102051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1141}, "3": {"k": 3, "answer": "Simba", "latency_ms": 146.03161811828613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1658}, "4": {"k": 4, "answer": "Nala", "latency_ms": 121.98138236999512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2231}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 282.5355529785156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2865}, "6": {"k": 6, "answer": "lioness", "latency_ms": 200.6204128265381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3490}}}
{"qid": "8551231508158823921", "question": "how many seasons are in star wars the clone wars", "gold_answers": ["6"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 92.6668643951416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "6", "latency_ms": 47.18184471130371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "6", "latency_ms": 59.93223190307617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1369}, "3": {"k": 3, "answer": "6", "latency_ms": 227.43749618530273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2072}, "4": {"k": 4, "answer": "6", "latency_ms": 76.89118385314941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2705}, "5": {"k": 5, "answer": "6", "latency_ms": 97.12004661560059, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3359}, "6": {"k": 6, "answer": "6", "latency_ms": 130.54299354553223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4034}}}
{"qid": "-4664207169377167173", "question": "who sings gone gone gone she been gone so long", "gold_answers": ["Chilliwack"], "shots": {"0": {"k": 0, "answer": "Lil Wayne", "latency_ms": 152.4505615234375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 121.15597724914551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 522}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 253.65972518920898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1118}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 277.15063095092773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1788}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 443.6311721801758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2376}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 152.754545211792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2974}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 225.1913547515869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3581}}}
{"qid": "-7605852330002608395", "question": "what does the air gap do on a dishwasher", "gold_answers": ["backflow prevention"], "shots": {"0": {"k": 0, "answer": "prevents water from entering the drain during operation", "latency_ms": 156.56638145446777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "prevents backflow", "latency_ms": 118.56603622436523, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "prevents backflow of sink water into the dishwasher", "latency_ms": 578.4130096435547, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1216}, "3": {"k": 3, "answer": "prevents backflow of sink water into the dishwasher", "latency_ms": 395.0796127319336, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1792}, "4": {"k": 4, "answer": "prevents sink water from backing up into the dishwasher", "latency_ms": 381.6709518432617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2390}, "5": {"k": 5, "answer": "prevents sink water from backing up into the dishwasher", "latency_ms": 418.0631637573242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3073}, "6": {"k": 6, "answer": "prevents sink water from backing up into the dishwasher", "latency_ms": 426.67436599731445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3746}}}
{"qid": "1447779709231013547", "question": "who does bryce dallas howard play in the grinch", "gold_answers": ["Surprised Who"], "shots": {"0": {"k": 0, "answer": "Maxwell \"Max\" Grinch", "latency_ms": 203.12881469726562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 107.51056671142578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 170.5946922302246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 260.8225345611572, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1876}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 160.84575653076172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2485}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 350.38018226623535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3073}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 303.19976806640625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3669}}}
{"qid": "2494339783007699672", "question": "where does dividends go on cash flow statement", "gold_answers": ["the financing activities section"], "shots": {"0": {"k": 0, "answer": "cash from financing activities", "latency_ms": 81.2673568725586, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "financing activities", "latency_ms": 123.75187873840332, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "financing activities", "latency_ms": 78.7813663482666, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "financing activities", "latency_ms": 82.08990097045898, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "financing activities", "latency_ms": 312.0722770690918, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2610}, "5": {"k": 5, "answer": "financing activities", "latency_ms": 285.2034568786621, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3303}, "6": {"k": 6, "answer": "financing activities", "latency_ms": 118.1950569152832, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3989}}}
{"qid": "-6195495799282225761", "question": "what is the 180 degree line of longitude called", "gold_answers": ["antimeridian", "180th meridian or antimeridian", "180th meridian"], "shots": {"0": {"k": 0, "answer": "Antimeridian", "latency_ms": 71.78330421447754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "180th meridian", "latency_ms": 327.64172554016113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 635}, "2": {"k": 2, "answer": "180th meridian", "latency_ms": 398.282527923584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "180° longitude line is called the International Date Line.", "latency_ms": 301.6989231109619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "180° longitude line is called the International Date Line.", "latency_ms": 460.31975746154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2515}, "5": {"k": 5, "answer": "180th meridian", "latency_ms": 445.36399841308594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3135}, "6": {"k": 6, "answer": "180th meridian", "latency_ms": 324.7489929199219, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3783}}}
{"qid": "-4512601929982486528", "question": "north carolina delegate to the second continental congress", "gold_answers": ["Timothy Bloodworth", "John B. Ashe", "William Blount"], "shots": {"0": {"k": 0, "answer": "William Hooper", "latency_ms": 143.3098316192627, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "William Hooper, Joseph Hewes, Richard Caswell", "latency_ms": 281.68392181396484, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "William Hooper", "latency_ms": 152.70519256591797, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1358}, "3": {"k": 3, "answer": "William Hooper, Joseph Hewes, Richard Caswell", "latency_ms": 458.2192897796631, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2056}, "4": {"k": 4, "answer": "William Hooper", "latency_ms": 177.90961265563965, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2711}, "5": {"k": 5, "answer": "William Hooper", "latency_ms": 355.5176258087158, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3397}, "6": {"k": 6, "answer": "William Hooper", "latency_ms": 139.49012756347656, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4019}}}
{"qid": "-2808093071562767910", "question": "who played the face in the a team", "gold_answers": ["Dirk Benedict"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 109.95197296142578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "centre", "latency_ms": 41.31889343261719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 174.20578002929688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 208.98985862731934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 162.21284866333008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2538}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 254.34207916259766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3145}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 341.5036201477051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3689}}}
{"qid": "7119887147544272496", "question": "when did the last volcano erupt in iceland", "gold_answers": ["2010"], "shots": {"0": {"k": 0, "answer": "2023", "latency_ms": 239.47739601135254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "21 May 2011", "latency_ms": 287.5807285308838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "21 May 2011", "latency_ms": 214.9028778076172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "21 May 2011", "latency_ms": 513.850212097168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1988}, "4": {"k": 4, "answer": "21 May 2011", "latency_ms": 563.6277198791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2690}, "5": {"k": 5, "answer": "2011", "latency_ms": 179.68106269836426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3318}, "6": {"k": 6, "answer": "2011", "latency_ms": 303.1141757965088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4006}}}
{"qid": "-7102729436138036180", "question": "when are you considered under the poverty line", "gold_answers": ["US $11,770"], "shots": {"0": {"k": 0, "answer": "varies by country and year", "latency_ms": 308.7649345397949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "when household income falls below the poverty threshold depending on employment status", "latency_ms": 462.7814292907715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "when household income falls below the poverty threshold", "latency_ms": 359.26103591918945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "when income falls below the established poverty threshold", "latency_ms": 203.34935188293457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "when household income falls below the poverty threshold", "latency_ms": 266.3590908050537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "when household income falls below the poverty threshold", "latency_ms": 239.70746994018555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3157}, "6": {"k": 6, "answer": "when household income falls below the official poverty threshold, which is based on a fixed food basket and does not account for other essential needs like housing, health care, and education", "latency_ms": 886.9619369506836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3758}}}
{"qid": "-8391680223788694572", "question": "who wrote if i were a boy reba or beyonce", "gold_answers": ["BC Jean", "Toby Gad"], "shots": {"0": {"k": 0, "answer": "Reba McEntire", "latency_ms": 133.58569145202637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "BC Jean", "latency_ms": 95.1998233795166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "BC Jean", "latency_ms": 261.9307041168213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "BC Jean and Toby Gad", "latency_ms": 371.34766578674316, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1842}, "4": {"k": 4, "answer": "BC Jean and Toby Gad", "latency_ms": 366.36924743652344, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2441}, "5": {"k": 5, "answer": "BC Jean and Toby Gad", "latency_ms": 433.24756622314453, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3053}, "6": {"k": 6, "answer": "BC Jean and Toby Gad", "latency_ms": 138.18836212158203, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3664}}}
{"qid": "-6785327703850595221", "question": "who has climbed mount everest the number of times", "gold_answers": ["Kami Rita Sherpa", "Phurba Tashi Sherpa", "Apa Sherpa"], "shots": {"0": {"k": 0, "answer": "As of 2023, the record for the most ascents of Mount Everest is held by **Reinhold Messner** and **Edmund Hillary**, but the current record holder for the most climbs is **Phurba Tashi**, with **12 ascents**. However, the most frequently cited record is **12 times**. \n\nFinal answer: **12**", "latency_ms": 1741.2796020507812, "em": 0.0, "f1": 0.08888888888888889, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 213.24563026428223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 243.3638572692871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "The context does not specify who has climbed Mount Everest the number of times. I cannot answer.", "latency_ms": 864.6636009216309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "The context does not specify who has climbed Mount Everest the number of times. I cannot answer.", "latency_ms": 496.990442276001, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2587}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 145.14708518981934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3194}, "6": {"k": 6, "answer": "Ed Viesturs", "latency_ms": 236.33861541748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3835}}}
