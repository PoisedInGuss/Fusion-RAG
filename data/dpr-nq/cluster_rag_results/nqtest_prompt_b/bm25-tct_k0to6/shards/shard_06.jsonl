{"qid": "7225402972374213361", "question": "where does sleeping freshmen never lie take place", "gold_answers": ["J.P. Zenger High"], "shots": {"0": {"k": 0, "answer": "The story \"Sleeping Freshmen Never Lie\" takes place in a fictional setting, specifically at a college or university, though the exact location is not specified. The narrative is set in a general academic environment, emphasizing the theme of truth among students. Therefore, the answer is: a college or university.", "latency_ms": 2691.669464111328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "high school", "latency_ms": 143.88608932495117, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "high school", "latency_ms": 64.8956298828125, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "high school", "latency_ms": 84.40566062927246, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "high school", "latency_ms": 115.0670051574707, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2577}, "5": {"k": 5, "answer": "high school", "latency_ms": 208.29272270202637, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3178}, "6": {"k": 6, "answer": "high school", "latency_ms": 119.70162391662598, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3770}}}
{"qid": "96833482883405603", "question": "where was the witch of blackbird pond published", "gold_answers": ["Houghton Mifflin", "United States", "1958"], "shots": {"0": {"k": 0, "answer": "1950", "latency_ms": 80.13248443603516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1958", "latency_ms": 182.861328125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "1958", "latency_ms": 169.93999481201172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "1958", "latency_ms": 284.578800201416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1934}, "4": {"k": 4, "answer": "1958", "latency_ms": 259.1390609741211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2523}, "5": {"k": 5, "answer": "1958", "latency_ms": 386.2571716308594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3135}, "6": {"k": 6, "answer": "1958", "latency_ms": 456.5157890319824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3841}}}
{"qid": "-7179754224203704932", "question": "when was the last time there was a school shooting in canada", "gold_answers": ["January 22 , 2016"], "shots": {"0": {"k": 0, "answer": "2023", "latency_ms": 73.88162612915039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 216.76373481750488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 323.3819007873535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1279}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 134.53316688537598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "2018 Danforth shooting", "latency_ms": 500.2551078796387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2593}, "5": {"k": 5, "answer": "2018 Danforth shooting", "latency_ms": 480.50999641418457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "2018 Danforth shooting", "latency_ms": 484.1876029968262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3875}}}
{"qid": "422507927579350549", "question": "when did the us cut off trade with cuba", "gold_answers": ["1961", "1962"], "shots": {"0": {"k": 0, "answer": "1960", "latency_ms": 373.71039390563965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3 February 1962", "latency_ms": 235.59236526489258, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "3 February 1962", "latency_ms": 385.6959342956543, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1345}, "3": {"k": 3, "answer": "3 February 1962", "latency_ms": 442.57164001464844, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2020}, "4": {"k": 4, "answer": "3 February 1962", "latency_ms": 429.29768562316895, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2696}, "5": {"k": 5, "answer": "3 February 1962", "latency_ms": 186.2962245941162, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3365}, "6": {"k": 6, "answer": "3 February 1962", "latency_ms": 397.4721431732178, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4013}}}
{"qid": "-8251885859273118288", "question": "cast of the movie pride of the marines", "gold_answers": ["John Ridgely", "Rosemary DeCamp as Virginia Pfeiffer", "Dane Clark as Lee Diamond", "Eleanor Parker as Ruth Hartley", "Eleanor Parker", "Rosemary DeCamp", "John Ridgely as Jim Merchant", "Anthony Caruso as Johnny Rivers", "John Garfield", "Ann E. Todd", "John Garfield as Al Schmid", "Anthony Caruso", "Dane Clark", "Ann Doran"], "shots": {"0": {"k": 0, "answer": "John Wayne, Robert Ryan, Robert Wagner, James Whitmore, Robert C. Bruce, John Agar, Robert J. Wilke, James B. Stewart, Robert H. Harris, John L. Hudson, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J. Hargrove, John R. Hargrove, Robert J.", "latency_ms": 5872.82133102417, "em": 0.0, "f1": 0.016806722689075633, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Garfield, Eleanor Parker", "latency_ms": 407.46450424194336, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "John Garfield, Eleanor Parker", "latency_ms": 128.1290054321289, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1227}, "3": {"k": 3, "answer": "John Garfield, Eleanor Parker", "latency_ms": 242.5210475921631, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1887}, "4": {"k": 4, "answer": "John Garfield, Eleanor Parker", "latency_ms": 195.9695816040039, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2535}, "5": {"k": 5, "answer": "John Garfield, Eleanor Parker", "latency_ms": 377.4070739746094, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3163}, "6": {"k": 6, "answer": "John Garfield, Eleanor Parker", "latency_ms": 313.3864402770996, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3804}}}
{"qid": "-7733962091461103034", "question": "who wrote how do you do it by gerry and the pacemakers", "gold_answers": ["Mitch Murray"], "shots": {"0": {"k": 0, "answer": "Gerry and the Pacemakers did not write \"How Do You Do It\" — it was written by **Bobby G.** (Bobby G. G. Smith).", "latency_ms": 1053.8702011108398, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mitch Murray", "latency_ms": 56.1518669128418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 546}, "2": {"k": 2, "answer": "Mitch Murray", "latency_ms": 67.9006576538086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1160}, "3": {"k": 3, "answer": "Mitch Murray", "latency_ms": 150.0568389892578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1780}, "4": {"k": 4, "answer": "Mitch Murray", "latency_ms": 130.91707229614258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2406}, "5": {"k": 5, "answer": "Mitch Murray", "latency_ms": 169.3098545074463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2981}, "6": {"k": 6, "answer": "Mitch Murray", "latency_ms": 243.03412437438965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3564}}}
{"qid": "9188359206780164872", "question": "when was the reaper invented by cyrus mccormick", "gold_answers": ["1834", "1837"], "shots": {"0": {"k": 0, "answer": "1831", "latency_ms": 326.9221782684326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1830s", "latency_ms": 197.32213020324707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "1830s", "latency_ms": 425.4324436187744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1342}, "3": {"k": 3, "answer": "1831", "latency_ms": 176.65886878967285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "1831", "latency_ms": 159.75499153137207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2609}, "5": {"k": 5, "answer": "1831", "latency_ms": 205.25836944580078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3240}, "6": {"k": 6, "answer": "1831", "latency_ms": 255.7969093322754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3831}}}
{"qid": "3724356943291190911", "question": "season 2 this is us number of episodes", "gold_answers": ["15", "18", "13"], "shots": {"0": {"k": 0, "answer": "10", "latency_ms": 124.78494644165039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 85.30783653259277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "13", "latency_ms": 162.97411918640137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1308}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 364.40563201904297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 250.38719177246094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2660}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 264.209508895874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3334}, "6": {"k": 6, "answer": "13", "latency_ms": 295.1338291168213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3967}}}
{"qid": "3780798490838700655", "question": "when did seattle slew win the triple crown", "gold_answers": ["in 1977", "1977"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 188.86113166809082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1977", "latency_ms": 107.64622688293457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 550}, "2": {"k": 2, "answer": "1977", "latency_ms": 372.15685844421387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1164}, "3": {"k": 3, "answer": "1977", "latency_ms": 224.95222091674805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1756}, "4": {"k": 4, "answer": "1977", "latency_ms": 138.24796676635742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2344}, "5": {"k": 5, "answer": "1977", "latency_ms": 199.38015937805176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2955}, "6": {"k": 6, "answer": "1977", "latency_ms": 363.6341094970703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3555}}}
{"qid": "-6569395974597414012", "question": "who did michigan state play in the rose bowl", "gold_answers": ["Stanford Cardinal"], "shots": {"0": {"k": 0, "answer": "Ohio State", "latency_ms": 199.23806190490723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UCLA Bruins", "latency_ms": 234.69877243041992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "UCLA Bruins", "latency_ms": 110.87512969970703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "UCLA Bruins", "latency_ms": 176.06210708618164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1769}, "4": {"k": 4, "answer": "UCLA Bruins", "latency_ms": 223.01602363586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2335}, "5": {"k": 5, "answer": "UCLA", "latency_ms": 242.91539192199707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2924}, "6": {"k": 6, "answer": "UCLA", "latency_ms": 230.36432266235352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3539}}}
{"qid": "6403936039868410763", "question": "when did teenage mutant ninja turtles come out", "gold_answers": ["1984"], "shots": {"0": {"k": 0, "answer": "1984", "latency_ms": 95.49474716186523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2013", "latency_ms": 299.5798587799072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "1984", "latency_ms": 380.07211685180664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1379}, "3": {"k": 3, "answer": "1987", "latency_ms": 410.88271141052246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2055}, "4": {"k": 4, "answer": "1984", "latency_ms": 115.8285140991211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2710}, "5": {"k": 5, "answer": "1984", "latency_ms": 151.47113800048828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3353}, "6": {"k": 6, "answer": "1984", "latency_ms": 274.34635162353516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4053}}}
{"qid": "-8240837250531908357", "question": "when does the team find out prentiss is alive", "gold_answers": ["the season seven premiere", "In the season seven premiere"], "shots": {"0": {"k": 0, "answer": "Season 4, Episode 10 \"The Truth\"", "latency_ms": 403.23328971862793, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "season seven", "latency_ms": 73.8074779510498, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "season seven", "latency_ms": 143.24569702148438, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1165}, "3": {"k": 3, "answer": "season seven", "latency_ms": 255.91444969177246, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1714}, "4": {"k": 4, "answer": "season seven", "latency_ms": 226.39107704162598, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2292}, "5": {"k": 5, "answer": "season seven", "latency_ms": 192.6443576812744, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2868}, "6": {"k": 6, "answer": "season seven", "latency_ms": 126.75046920776367, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3480}}}
{"qid": "2134628804733070340", "question": "who won the silver medal in womens figure skating", "gold_answers": ["Evgenia Medvedeva"], "shots": {"0": {"k": 0, "answer": "Medina Tornado", "latency_ms": 288.5546684265137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 295.9315776824951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 380.4044723510742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 325.21653175354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 119.11487579345703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "Barbara Ann Roles", "latency_ms": 161.91601753234863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Barbara Ann Roles", "latency_ms": 265.1331424713135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3871}}}
{"qid": "-1769528362781268772", "question": "who lived in jamestown before the arrival of the english", "gold_answers": ["uninhabited"], "shots": {"0": {"k": 0, "answer": "Powhatan Confederacy", "latency_ms": 354.2211055755615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Virginia Indian tribes", "latency_ms": 72.509765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Virginia Indian tribes", "latency_ms": 278.2714366912842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1323}, "3": {"k": 3, "answer": "Virginia Indian tribes", "latency_ms": 136.10410690307617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Virginia Indian tribes", "latency_ms": 179.75950241088867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2587}, "5": {"k": 5, "answer": "Powhatan Confederacy", "latency_ms": 431.5650463104248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3243}, "6": {"k": 6, "answer": "Powhatan Confederacy", "latency_ms": 525.8851051330566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3968}}}
{"qid": "2632188867909468181", "question": "who is covering the winter olympics in canada", "gold_answers": ["CBC / Radio - Canada", "Rogers Media", "TLN", "Bell Media"], "shots": {"0": {"k": 0, "answer": "CBC News", "latency_ms": 190.5968189239502, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 77.92234420776367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 92.72289276123047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 105.80730438232422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1958}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 132.3561668395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2608}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 259.765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3238}, "6": {"k": 6, "answer": "Brendan Connor", "latency_ms": 220.70980072021484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3892}}}
{"qid": "6788315330567276031", "question": "who plays the dad in girl meets world", "gold_answers": ["Ben Savage", "Cory Matthews"], "shots": {"0": {"k": 0, "answer": "Jerry O'Connell", "latency_ms": 355.67378997802734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 239.79544639587402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 183.99953842163086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 359.1799736022949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1796}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 360.17370223999023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2356}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 256.88648223876953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2950}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 279.9570560455322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3585}}}
{"qid": "-8518155586522600846", "question": "who are you in assassin's creed 4", "gold_answers": ["third - person perspective", "an Abstergo agent"], "shots": {"0": {"k": 0, "answer": "Haytham Kenway", "latency_ms": 147.9513645172119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Desmond Miles", "latency_ms": 195.18375396728516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "Desmond Miles", "latency_ms": 87.99862861633301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1342}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 251.72781944274902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2004}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 333.40978622436523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2678}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 287.11581230163574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3347}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 252.31170654296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4031}}}
{"qid": "-5339088518859431071", "question": "who destroyed the first temple and exiled the two tribes of judah to babylon", "gold_answers": ["Nebuchadnezzar"], "shots": {"0": {"k": 0, "answer": "Nebuchadnezzar II", "latency_ms": 351.7928123474121, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Babylonian army", "latency_ms": 236.71865463256836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Nebuchadnezzar II", "latency_ms": 189.3777847290039, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Nebuchadnezzar II", "latency_ms": 431.4136505126953, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1872}, "4": {"k": 4, "answer": "Nebuchadnezzar II", "latency_ms": 385.75243949890137, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2547}, "5": {"k": 5, "answer": "Nebuchadnezzar II", "latency_ms": 408.55860710144043, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3206}, "6": {"k": 6, "answer": "Nebuchadnezzar II", "latency_ms": 249.70293045043945, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3828}}}
{"qid": "-1602930054930299018", "question": "where is the white castle that harold and kumar go to", "gold_answers": ["in Cherry Hill"], "shots": {"0": {"k": 0, "answer": "California", "latency_ms": 58.846235275268555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "White Castle", "latency_ms": 212.30101585388184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "White Castle (specific location not mentioned in context)", "latency_ms": 219.18416023254395, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "White Castle", "latency_ms": 80.71231842041016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1824}, "4": {"k": 4, "answer": "Cherry Hill", "latency_ms": 110.02135276794434, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "Cherry Hill", "latency_ms": 240.1120662689209, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3032}, "6": {"k": 6, "answer": "Cherry Hill", "latency_ms": 246.2480068206787, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3680}}}
{"qid": "4721622231665415813", "question": "when was child benefit paid for the first child", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1946", "latency_ms": 71.44880294799805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 110.9468936920166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 179.77285385131836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 137.63761520385742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": "£1/week", "latency_ms": 160.56275367736816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2603}, "5": {"k": 5, "answer": "£1/week", "latency_ms": 160.64143180847168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 252.14362144470215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3787}}}
{"qid": "243685073103458654", "question": "what was the initial effect of the transition from command to market economies in eastern europe", "gold_answers": ["Inequality of opportunity"], "shots": {"0": {"k": 0, "answer": "economic stagnation", "latency_ms": 214.97178077697754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "economic crisis", "latency_ms": 57.48558044433594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 693}, "2": {"k": 2, "answer": "economic crisis", "latency_ms": 63.87972831726074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1383}, "3": {"k": 3, "answer": "economic crisis", "latency_ms": 81.65335655212402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "economic crisis", "latency_ms": 88.74654769897461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2776}, "5": {"k": 5, "answer": "economic crisis", "latency_ms": 134.71412658691406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3516}, "6": {"k": 6, "answer": "economic crisis", "latency_ms": 149.12772178649902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4237}}}
{"qid": "5041227796109703758", "question": "when did linkin park release one more light", "gold_answers": ["May 19 , 2017"], "shots": {"0": {"k": 0, "answer": "2016", "latency_ms": 251.77836418151855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "May 19, 2017", "latency_ms": 304.45122718811035, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "May 19, 2017", "latency_ms": 177.3829460144043, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "May 19, 2017", "latency_ms": 432.10649490356445, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "May 19, 2017", "latency_ms": 365.17882347106934, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2419}, "5": {"k": 5, "answer": "May 19, 2017", "latency_ms": 309.7188472747803, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3012}, "6": {"k": 6, "answer": "May 19, 2017", "latency_ms": 461.8685245513916, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3638}}}
{"qid": "-9039792036843684255", "question": "what territory is spain and the united kingdom in a dispute over", "gold_answers": ["Gibraltar"], "shots": {"0": {"k": 0, "answer": "Gibraltar", "latency_ms": 56.40554428100586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gibraltar", "latency_ms": 91.08686447143555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Gibraltar", "latency_ms": 85.83498001098633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1350}, "3": {"k": 3, "answer": "Gibraltar", "latency_ms": 83.04333686828613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2035}, "4": {"k": 4, "answer": "Gibraltar", "latency_ms": 86.33065223693848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Gibraltar", "latency_ms": 127.8238296508789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3387}, "6": {"k": 6, "answer": "Gibraltar", "latency_ms": 151.02815628051758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4143}}}
{"qid": "-5962986518182066490", "question": "who has the most green jackets from the masters", "gold_answers": ["Jack Nicklaus ( 6 )", "Nicklaus"], "shots": {"0": {"k": 0, "answer": "Tiger Woods", "latency_ms": 123.28052520751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sam Snead", "latency_ms": 99.57695007324219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 131.0281753540039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 309.6163272857666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 285.3872776031494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2533}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 129.96864318847656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3126}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 354.97593879699707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3810}}}
{"qid": "-4447833523561749340", "question": "who was the first black person to register to vote", "gold_answers": ["Thomas Mundy Peterson"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 77.65340805053711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 300.42481422424316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 299.61228370666504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 227.7829647064209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 225.87060928344727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 236.73653602600098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3286}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 314.6216869354248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3952}}}
{"qid": "4131432785529318958", "question": "song have i told you lately i love you", "gold_answers": ["Have I Told You Lately"], "shots": {"0": {"k": 0, "answer": "Beyoncé", "latency_ms": 118.66188049316406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Scotty Wiseman", "latency_ms": 324.44095611572266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Scotty Wiseman", "latency_ms": 229.10499572753906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Scotty Wiseman", "latency_ms": 163.47146034240723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "Scotty Wiseman", "latency_ms": 196.96736335754395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2464}, "5": {"k": 5, "answer": "Scotty Wiseman", "latency_ms": 130.86199760437012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "Scotty Wiseman", "latency_ms": 278.32865715026855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3659}}}
{"qid": "-716659397149237689", "question": "when did britain set up east indian trading company", "gold_answers": ["31 December 1600"], "shots": {"0": {"k": 0, "answer": "1600", "latency_ms": 207.93652534484863, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1600", "latency_ms": 206.38132095336914, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "1600", "latency_ms": 341.71605110168457, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "1600", "latency_ms": 289.34216499328613, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "1600", "latency_ms": 363.6326789855957, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "1600", "latency_ms": 172.59454727172852, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3282}, "6": {"k": 6, "answer": "1600", "latency_ms": 241.00065231323242, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3935}}}
{"qid": "-7583855073136179893", "question": "when did david akers kick the 63 yard field goal", "gold_answers": ["September 9 , 2012"], "shots": {"0": {"k": 0, "answer": "2007", "latency_ms": 109.18331146240234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 107.05018043518066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 162.3220443725586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1187}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 146.42643928527832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1765}, "4": {"k": 4, "answer": "record not specified in context", "latency_ms": 126.97887420654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2363}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 183.4862232208252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2926}, "6": {"k": 6, "answer": "with the San Francisco 49ers", "latency_ms": 367.10476875305176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3535}}}
{"qid": "6203839542590166972", "question": "who is the coach of university of kentucky basketball", "gold_answers": ["John Calipari", "John Vincent Calipari"], "shots": {"0": {"k": 0, "answer": "Shaka Smart", "latency_ms": 80.61718940734863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matthew Mitchell", "latency_ms": 227.37550735473633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 733}, "2": {"k": 2, "answer": "Matthew Mitchell", "latency_ms": 253.5238265991211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1509}, "3": {"k": 3, "answer": "Matthew Mitchell (women's team)  \nBilly Gillispie (men's team)", "latency_ms": 302.1588325500488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2207}, "4": {"k": 4, "answer": "Matthew Mitchell (women's), John Calipari (men's)", "latency_ms": 842.8137302398682, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2885}, "5": {"k": 5, "answer": "John Calipari (men's) / Matthew Mitchell (women's)", "latency_ms": 755.260705947876, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3563}, "6": {"k": 6, "answer": "John Calipari", "latency_ms": 270.79081535339355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4228}}}
{"qid": "-163195825366469164", "question": "where does the papillary layer of the skin lie", "gold_answers": ["adjacent to the epidermis"], "shots": {"0": {"k": 0, "answer": "below the epidermis", "latency_ms": 335.8762264251709, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "between the epidermis and subcutaneous tissue", "latency_ms": 371.5784549713135, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "adjacent to the epidermis", "latency_ms": 388.3168697357178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1400}, "3": {"k": 3, "answer": "adjacent to the epidermis", "latency_ms": 387.5553607940674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2060}, "4": {"k": 4, "answer": "adjacent to the epidermis", "latency_ms": 250.0019073486328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2770}, "5": {"k": 5, "answer": "adjacent to the epidermis", "latency_ms": 253.7829875946045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3385}, "6": {"k": 6, "answer": "adjacent to the epidermis", "latency_ms": 412.16516494750977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4041}}}
{"qid": "-7984751231760514910", "question": "who has become the new chairman of sebi", "gold_answers": ["Ajay Tyagi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 107.54036903381348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 219.42496299743652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 98.41370582580566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1332}, "3": {"k": 3, "answer": "Upendra Kumar Sinha", "latency_ms": 277.38118171691895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "Upendra Kumar Sinha", "latency_ms": 209.6724510192871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "Upendra Kumar Sinha", "latency_ms": 140.02394676208496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3285}, "6": {"k": 6, "answer": "Upendra Kumar Sinha", "latency_ms": 141.09086990356445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3925}}}
{"qid": "-3800318726442204745", "question": "how many times has psg won champions league", "gold_answers": ["46"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 187.3612403869629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0", "latency_ms": 117.5391674041748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "0", "latency_ms": 74.71418380737305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1217}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 109.83729362487793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 249.68719482421875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 448.84586334228516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3107}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 308.1498146057129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3705}}}
{"qid": "-642255764943734268", "question": "who played santa in the santa clause movies", "gold_answers": ["Tim Allen"], "shots": {"0": {"k": 0, "answer": "Jim Carrey", "latency_ms": 86.68851852416992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tim Allen", "latency_ms": 104.67362403869629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 589}, "2": {"k": 2, "answer": "Tim Allen", "latency_ms": 240.7529354095459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1213}, "3": {"k": 3, "answer": "Tim Allen", "latency_ms": 156.47244453430176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1843}, "4": {"k": 4, "answer": "Tim Allen", "latency_ms": 233.9174747467041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2522}, "5": {"k": 5, "answer": "Tim Allen", "latency_ms": 198.7607479095459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3167}, "6": {"k": 6, "answer": "Tim Allen", "latency_ms": 227.76484489440918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3798}}}
{"qid": "-8451675676248853811", "question": "how many times have real madrid won the european cup.in paris", "gold_answers": ["twelve"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 231.28294944763184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 344.9537754058838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 305.7694435119629, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 109.03167724609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 411.2277030944824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 189.24498558044434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3160}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 171.39339447021484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3784}}}
{"qid": "-5975200217671466380", "question": "total goals scored by ronaldo in la liga", "gold_answers": ["309"], "shots": {"0": {"k": 0, "answer": "163", "latency_ms": 127.15363502502441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "40", "latency_ms": 59.60226058959961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "40 goals", "latency_ms": 83.79793167114258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "40", "latency_ms": 219.55251693725586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1834}, "4": {"k": 4, "answer": "40", "latency_ms": 246.32906913757324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2443}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 161.4065170288086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3081}, "6": {"k": 6, "answer": "40", "latency_ms": 113.66796493530273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3672}}}
{"qid": "-1975115150327235272", "question": "when was kudzu introduced to the united states", "gold_answers": ["in 1876", "1876"], "shots": {"0": {"k": 0, "answer": "1893", "latency_ms": 307.0979118347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "135 years ago", "latency_ms": 452.6040554046631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "1876", "latency_ms": 95.6106185913086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "1876", "latency_ms": 210.07013320922852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1884}, "4": {"k": 4, "answer": "1876", "latency_ms": 130.72586059570312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2515}, "5": {"k": 5, "answer": "1876", "latency_ms": 277.2409915924072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3160}, "6": {"k": 6, "answer": "1876", "latency_ms": 207.9148292541504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3810}}}
{"qid": "4911813695697896179", "question": "the radiographic term used to describe the dense bone of the socket and septal crest is", "gold_answers": ["the lamina dura", "lamina dura", "alveolar process"], "shots": {"0": {"k": 0, "answer": "alveolar ridge", "latency_ms": 249.44400787353516, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 398.5259532928467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 90.57021141052246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 105.94797134399414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1997}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 110.23688316345215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 217.47589111328125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3284}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 197.3552703857422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3896}}}
{"qid": "3490824095431420580", "question": "where was the tv show friday night lights filmed", "gold_answers": ["Pflugerville", "Austin"], "shots": {"0": {"k": 0, "answer": "Denton, Texas", "latency_ms": 294.7711944580078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 287.3730659484863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 98.53792190551758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 190.23942947387695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1955}, "4": {"k": 4, "answer": "Dillon, Texas", "latency_ms": 261.59024238586426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "in rural Texas, using actual locations rather than stage sets and sound stages", "latency_ms": 317.0897960662842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3248}, "6": {"k": 6, "answer": "in Texas", "latency_ms": 104.78568077087402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3919}}}
{"qid": "-8363239742768997492", "question": "who led an attack that allowed for american victory at yorktown", "gold_answers": ["George Washington", "Comte de Rochambeau"], "shots": {"0": {"k": 0, "answer": "George Washington", "latency_ms": 57.26289749145508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "French and American forces led by George Washington and Comte de Rochambeau", "latency_ms": 392.2848701477051, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 676}, "2": {"k": 2, "answer": "General Charles, Earl Cornwallis", "latency_ms": 235.3060245513916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "General Charles, Earl Cornwallis", "latency_ms": 146.70610427856445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2026}, "4": {"k": 4, "answer": "George Washington and the Comte de Rochambeau", "latency_ms": 448.1990337371826, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2657}, "5": {"k": 5, "answer": "George Washington and the Comte de Rochambeau", "latency_ms": 552.0672798156738, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3312}, "6": {"k": 6, "answer": "George Washington and the Comte de Rochambeau", "latency_ms": 384.94372367858887, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4010}}}
{"qid": "8127283608263713430", "question": "what process causes the continents to drift apart how", "gold_answers": ["Continental drift"], "shots": {"0": {"k": 0, "answer": "plate tectonics", "latency_ms": 251.46102905273438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "continental drift and seafloor spreading", "latency_ms": 183.5932731628418, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "continental drift and seafloor spreading", "latency_ms": 333.66990089416504, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "continental drift", "latency_ms": 74.66769218444824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2054}, "4": {"k": 4, "answer": "continental drift", "latency_ms": 137.5565528869629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2760}, "5": {"k": 5, "answer": "plate tectonics", "latency_ms": 196.5031623840332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3423}, "6": {"k": 6, "answer": "plate tectonics", "latency_ms": 253.97324562072754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4169}}}
{"qid": "-4677464867334464937", "question": "who played in last train from gun hill", "gold_answers": ["Walter Sande", "Brian G. Hutton", "Carolyn Jones", "Ziva Rodann", "Bing Russell", "Val Avery", "Earl Holliman", "Brad Dexter", "Kirk Douglas", "Anthony Quinn"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 162.33015060424805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kirk Douglas, Anthony Quinn, Carolyn Jones, Earl Holliman", "latency_ms": 320.30200958251953, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Kirk Douglas, Anthony Quinn, Carolyn Jones, Earl Holliman", "latency_ms": 483.55984687805176, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Kirk Douglas, Anthony Quinn, Carolyn Jones, Earl Holliman", "latency_ms": 529.6993255615234, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1811}, "4": {"k": 4, "answer": "Kirk Douglas, Anthony Quinn, Carolyn Jones, Earl Holliman", "latency_ms": 641.3350105285645, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2401}, "5": {"k": 5, "answer": "Kirk Douglas, Anthony Quinn, Carolyn Jones, Earl Holliman", "latency_ms": 255.04612922668457, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2992}, "6": {"k": 6, "answer": "Kirk Douglas, Anthony Quinn, Carolyn Jones, Earl Holliman", "latency_ms": 490.3285503387451, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3579}}}
{"qid": "9104579908306893648", "question": "who is the queen of hearts in alice in wonderland", "gold_answers": ["the primary antagonist"], "shots": {"0": {"k": 0, "answer": "Queen of Hearts", "latency_ms": 172.07884788513184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Queen of Hearts", "latency_ms": 151.42083168029785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "Queen of Hearts", "latency_ms": 96.43888473510742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1251}, "3": {"k": 3, "answer": "Queen of Hearts in Alice in Wonderland is a haughty sadist who enjoys decapitating anyone who annoys her.", "latency_ms": 885.2293491363525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "Lewis Carroll", "latency_ms": 89.36023712158203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2536}, "5": {"k": 5, "answer": "Mary Elizabeth Heart", "latency_ms": 115.42201042175293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3199}, "6": {"k": 6, "answer": "Lewis Carroll", "latency_ms": 270.205020904541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3806}}}
{"qid": "658101134800391459", "question": "who invented the first computer game in 1962 and what was the name of the game", "gold_answers": ["Spacewar !", "Wayne Wiitanen", "Steve Russell", "Martin Graetz"], "shots": {"0": {"k": 0, "answer": "Steve Russell, Spacewar!", "latency_ms": 134.53292846679688, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 86.67707443237305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 149.57833290100098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 165.31729698181152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 151.18741989135742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2535}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 314.70441818237305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3162}, "6": {"k": 6, "answer": "Steve Russell, Spacewar!", "latency_ms": 344.3129062652588, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3848}}}
{"qid": "5154394238729460303", "question": "largest state in the us by land mass", "gold_answers": ["Alaska"], "shots": {"0": {"k": 0, "answer": "Alaska", "latency_ms": 157.9136848449707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alaska", "latency_ms": 109.88569259643555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 586}, "2": {"k": 2, "answer": "Alaska", "latency_ms": 159.99150276184082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1244}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 145.59316635131836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Alaska", "latency_ms": 130.6936740875244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2450}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 176.07593536376953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3073}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 348.65880012512207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3702}}}
{"qid": "-6371603500131574271", "question": "who sings somebody's watching me with michael jackson", "gold_answers": ["Jermaine Jackson", "Rockwell"], "shots": {"0": {"k": 0, "answer": "Mariah Carey", "latency_ms": 115.41366577148438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rockwell", "latency_ms": 132.24244117736816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "Rockwell", "latency_ms": 172.49655723571777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Rockwell", "latency_ms": 106.37831687927246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1957}, "4": {"k": 4, "answer": "Rockwell", "latency_ms": 115.73910713195801, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2546}, "5": {"k": 5, "answer": "Jermaine Jackson", "latency_ms": 162.65511512756348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3194}, "6": {"k": 6, "answer": "Rockwell", "latency_ms": 116.26243591308594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3870}}}
{"qid": "-89839634525298434", "question": "who played the mom on what's eating gilbert grape", "gold_answers": ["Darlene Cates"], "shots": {"0": {"k": 0, "answer": "Geraldine Page", "latency_ms": 127.74968147277832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amy Madigan", "latency_ms": 96.18330001831055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 559}, "2": {"k": 2, "answer": "Darlene Cates", "latency_ms": 111.29426956176758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Darlene Cates", "latency_ms": 389.7221088409424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1942}, "4": {"k": 4, "answer": "Darlene Cates", "latency_ms": 150.56109428405762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2577}, "5": {"k": 5, "answer": "Darlene Cates", "latency_ms": 360.08429527282715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3229}, "6": {"k": 6, "answer": "Darlene Cates", "latency_ms": 167.35410690307617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3909}}}
{"qid": "4094570070863238215", "question": "when does the second part of vikings season 4 start", "gold_answers": ["November 30 , 2016"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 589.1196727752686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "November 30, 2016", "latency_ms": 467.8611755371094, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "November 30, 2016", "latency_ms": 428.1797409057617, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "November 30, 2016", "latency_ms": 179.931640625, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1876}, "4": {"k": 4, "answer": "November 30, 2016", "latency_ms": 276.6613960266113, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "November 30, 2016", "latency_ms": 272.4871635437012, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3142}, "6": {"k": 6, "answer": "November 30, 2016", "latency_ms": 467.66066551208496, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3762}}}
{"qid": "-1084748809184043293", "question": "when did the us stop trading with japan", "gold_answers": ["1940", "1939"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 167.02747344970703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 86.69233322143555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 679}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 93.52350234985352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1368}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 196.04086875915527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 409.7144603729248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2717}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 169.73352432250977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3410}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 316.01524353027344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4135}}}
{"qid": "-5869834741419224491", "question": "who gets the golden boot if its a tie", "gold_answers": ["shared"], "shots": {"0": {"k": 0, "answer": "The player with the most goals, based on goal difference if needed.", "latency_ms": 549.0477085113525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ties being broken by", "latency_ms": 79.97274398803711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "ties being broken by assists", "latency_ms": 116.09578132629395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "assists", "latency_ms": 301.6529083251953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "ties being broken by assists", "latency_ms": 458.79554748535156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2460}, "5": {"k": 5, "answer": "assists", "latency_ms": 187.23678588867188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3114}, "6": {"k": 6, "answer": "assists", "latency_ms": 119.9033260345459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3758}}}
{"qid": "6792980250224411482", "question": "who is the minister of local government in zimbabwe", "gold_answers": ["Hon July Moyo"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 363.13819885253906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 307.5699806213379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 89.46895599365234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1314}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 230.4685115814209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1949}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 280.46584129333496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2688}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 180.32264709472656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3399}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 191.08939170837402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4122}}}
{"qid": "4395570541686945657", "question": "who are the dallas cowboys playing on thanksgiving", "gold_answers": ["the Detroit Lions", "Los Angeles Chargers"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 258.4340572357178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington Redskins", "latency_ms": 151.73625946044922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "Washington Redskins", "latency_ms": 190.48285484313965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Washington Redskins", "latency_ms": 256.6211223602295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "Washington Redskins", "latency_ms": 147.89104461669922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2505}, "5": {"k": 5, "answer": "Washington Redskins, Miami Dolphins, Oakland Raiders, Chiefs", "latency_ms": 301.44619941711426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3178}, "6": {"k": 6, "answer": "Washington Redskins (2016), Miami Dolphins (2011)", "latency_ms": 526.3626575469971, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3808}}}
{"qid": "6411144351147088389", "question": "who sang i put a spell on you in hocus pocus", "gold_answers": ["Bette Midler"], "shots": {"0": {"k": 0, "answer": "AT&T", "latency_ms": 164.3662452697754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bette Midler", "latency_ms": 149.4734287261963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "Bette Midler and her Harlettes", "latency_ms": 435.93883514404297, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Bette Midler and her Harlettes", "latency_ms": 513.7271881103516, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1933}, "4": {"k": 4, "answer": "Bette Midler and her Harlettes", "latency_ms": 544.147253036499, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2457}, "5": {"k": 5, "answer": "Bette Midler and her Harlettes", "latency_ms": 202.6362419128418, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3069}, "6": {"k": 6, "answer": "Bette Midler and her Harlettes", "latency_ms": 232.95903205871582, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3710}}}
{"qid": "-6558090229319450246", "question": "what are the roles of international monetary fund", "gold_answers": ["to foster global monetary cooperation", "reduce poverty around the world", "secure financial stability", "foster global monetary cooperation", "facilitate international trade"], "shots": {"0": {"k": 0, "answer": "Monitor economies, provide financial assistance, promote policy reforms, ensure global financial stability.", "latency_ms": 462.76402473449707, "em": 0.0, "f1": 0.26666666666666666, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "guardian to overseer of members' policies; analyzes economic and financial policies; assesses consequences for global economy; guides data dissemination to public", "latency_ms": 558.6423873901367, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 716}, "2": {"k": 2, "answer": "analyses member countries' economic and financial policies, assesses their consequences for global economy, guides data dissemination standards", "latency_ms": 643.8643932342529, "em": 0.0, "f1": 0.1, "containment": 0.0, "context_chars": 1379}, "3": {"k": 3, "answer": "analyzes member countries' economic and financial policies, assesses their impact on global economy, disseminates economic data, oversees member policies", "latency_ms": 758.0156326293945, "em": 0.0, "f1": 0.09090909090909091, "containment": 0.0, "context_chars": 2043}, "4": {"k": 4, "answer": "foster global monetary cooperation, secure financial stability, facilitate international trade, promote high employment and sustainable economic growth, and reduce poverty around the world", "latency_ms": 906.6927433013916, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 2779}, "5": {"k": 5, "answer": "foster global monetary cooperation, secure financial stability, facilitate international trade, promote high employment and sustainable economic growth, and reduce poverty around the world.", "latency_ms": 1268.6645984649658, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 3446}, "6": {"k": 6, "answer": "foster global monetary cooperation, secure financial stability, facilitate international trade, promote high employment and sustainable economic growth, reduce poverty around the world; analyzes appropriateness of member countries' economic and financial policies; assesses consequences of policies for other countries and global economy; disseminates economic and financial data; manages balance of payments difficulties; provides funds for countries in financial difficulty", "latency_ms": 2218.7960147857666, "em": 0.0, "f1": 0.13114754098360656, "containment": 1.0, "context_chars": 4169}}}
{"qid": "-628291178392259442", "question": "when was the first star wars film released", "gold_answers": ["May 25 , 1977", "1977"], "shots": {"0": {"k": 0, "answer": "1977", "latency_ms": 200.46424865722656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1977", "latency_ms": 315.45209884643555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 691}, "2": {"k": 2, "answer": "1977", "latency_ms": 282.6235294342041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1328}, "3": {"k": 3, "answer": "1977", "latency_ms": 350.3537178039551, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "1977", "latency_ms": 349.3692874908447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2603}, "5": {"k": 5, "answer": "1977", "latency_ms": 159.8527431488037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3249}, "6": {"k": 6, "answer": "1977", "latency_ms": 138.06438446044922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3916}}}
{"qid": "9199587263422732891", "question": "who was the bad guy in silence of the lambs", "gold_answers": ["Buffalo Bill"], "shots": {"0": {"k": 0, "answer": "Buffalo Bill", "latency_ms": 63.33661079406738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hannibal Lecter", "latency_ms": 187.1662139892578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "Hannibal Lecter", "latency_ms": 384.6752643585205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Buffalo Bill", "latency_ms": 416.5489673614502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Buffalo Bill", "latency_ms": 94.06661987304688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2643}, "5": {"k": 5, "answer": "Buffalo Bill", "latency_ms": 275.62904357910156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3318}, "6": {"k": 6, "answer": "Buffalo Bill", "latency_ms": 299.6077537536621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3946}}}
{"qid": "-507214070235479571", "question": "epidemiologists attempt to explain the link between health and variables such as", "gold_answers": ["biological agents", "disease conditions in defined populations", "alcohol", "chemicals", "smoking", "stress"], "shots": {"0": {"k": 0, "answer": "socioeconomic status, environment, behavior, genetics, access to healthcare", "latency_ms": 204.85997200012207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "socioeconomic status", "latency_ms": 244.8713779449463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 743}, "2": {"k": 2, "answer": "social factors", "latency_ms": 374.79710578918457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1435}, "3": {"k": 3, "answer": "social, cultural, economic, political and environmental factors", "latency_ms": 549.2231845855713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2154}, "4": {"k": 4, "answer": "socioeconomic status", "latency_ms": 165.1020050048828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2813}, "5": {"k": 5, "answer": "socioeconomic status, environment, policy, and social factors", "latency_ms": 312.4558925628662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3503}, "6": {"k": 6, "answer": "social status, environment, economic inequality, friendship, policies, programmes, interventions", "latency_ms": 607.0523262023926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4151}}}
{"qid": "5954016886103366248", "question": "when was night at the museum 3 filmed", "gold_answers": ["2014", "London , England", "British Columbia , Canada", "January to May 2014", "from January to May 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 195.87016105651855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 87.6474380493164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 278.9623737335205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 190.54341316223145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1904}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 234.21025276184082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2540}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 364.17508125305176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "May 2014", "latency_ms": 292.2399044036865, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3813}}}
{"qid": "4492033271398413517", "question": "what mall did they use in back to the future", "gold_answers": ["Puente Hills Mall"], "shots": {"0": {"k": 0, "answer": "Mall of America", "latency_ms": 358.55937004089355, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Courthouse Mall", "latency_ms": 105.54885864257812, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "Courthouse Mall", "latency_ms": 117.38467216491699, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "Twin Pines Mall", "latency_ms": 211.58123016357422, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1807}, "4": {"k": 4, "answer": "Puente Hills Mall", "latency_ms": 143.42546463012695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2404}, "5": {"k": 5, "answer": "Puente Hills Mall", "latency_ms": 262.662410736084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3022}, "6": {"k": 6, "answer": "Puente Hills Mall", "latency_ms": 194.83661651611328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3608}}}
{"qid": "-3719623571078658627", "question": "what does rt mean on a dodge car", "gold_answers": ["Road / Track"], "shots": {"0": {"k": 0, "answer": "Rear Tow", "latency_ms": 170.2134609222412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 141.1721706390381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 171.48876190185547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "RT means \"Recreation Touring\" on a Dodge car.", "latency_ms": 346.0121154785156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": "RT means \"Recreation Touring\" on a Dodge car.", "latency_ms": 333.6312770843506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2596}, "5": {"k": 5, "answer": "RT means \"Ram Town\" or \"Recreation Touring\" in the context of Dodge minivans, but based on the provided context, it refers to the Chrysler minivan model. Specifically, \"Chrysler minivans (RT)\" indicates the RT trim level. RT stands for \"Recreation Touring.\"", "latency_ms": 1711.5018367767334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3219}, "6": {"k": 6, "answer": "RT means \"Ram Town\" or \"Recreational Touring\" in the context of Dodge minivans, referring to the Chrysler minivan model line. However, based on the provided context, RT specifically refers to the **Chrysler minivans (RT)**. \n\nAnswer: Chrysler minivans (RT)", "latency_ms": 1908.8823795318604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3863}}}
{"qid": "-3436933223479131319", "question": "when did the movie breakfast club come out", "gold_answers": ["February 15 , 1985", "1985"], "shots": {"0": {"k": 0, "answer": "1985", "latency_ms": 128.0040740966797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 253.07631492614746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "1988", "latency_ms": 148.2548713684082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 260.5624198913574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "1985", "latency_ms": 403.23352813720703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2526}, "5": {"k": 5, "answer": "1985", "latency_ms": 413.118839263916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3180}, "6": {"k": 6, "answer": "February 1985", "latency_ms": 399.3077278137207, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3829}}}
{"qid": "-6477588851233520447", "question": "who is the king and queen of the netherlands", "gold_answers": ["Queen Máxima of the Netherlands", "King Willem - Alexander"], "shots": {"0": {"k": 0, "answer": "King Willem-Alexander and Queen Máxima", "latency_ms": 227.08773612976074, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "King Willem-Alexander and Queen Máxima", "latency_ms": 267.2126293182373, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "King Willem-Alexander and Queen Máxima", "latency_ms": 167.30594635009766, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "King Willem-Alexander and Queen Máxima", "latency_ms": 445.6005096435547, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "King Willem-Alexander and Queen Máxima", "latency_ms": 275.9549617767334, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 2557}, "5": {"k": 5, "answer": "King Willem-Alexander and Queen Máxima", "latency_ms": 262.8347873687744, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "King Willem-Alexander and Queen Máxima", "latency_ms": 633.5165500640869, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3727}}}
{"qid": "7281701387754006749", "question": "what written material is included in the talmud", "gold_answers": ["the Gemara", "the Mishnah"], "shots": {"0": {"k": 0, "answer": "Babylonian and Jerusalem Talmuds, Mishnah, Talmudic commentaries", "latency_ms": 888.653039932251, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Torah (Hebrew Bible)", "latency_ms": 340.87109565734863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "Hebrew and Jewish Babylonian Aramaic", "latency_ms": 218.48392486572266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1310}, "3": {"k": 3, "answer": "teachings and opinions of thousands of rabbis, halakha, Jewish ethics, philosophy, customs, history, lore", "latency_ms": 1240.5126094818115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "teachings and opinions of thousands of rabbis, halakha, Jewish ethics, philosophy, customs, history, lore", "latency_ms": 884.8450183868408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "teachings and opinions of thousands of rabbis, halakha, Jewish ethics, philosophy, customs, history, lore", "latency_ms": 627.3140907287598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3343}, "6": {"k": 6, "answer": "teachings and opinions of thousands of rabbis on halakha, Jewish ethics, philosophy, customs, history, lore and other topics", "latency_ms": 1094.6218967437744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3963}}}
{"qid": "2178534208098154067", "question": "what are the value of style guides and style sheet", "gold_answers": ["improve communication"], "shots": {"0": {"k": 0, "answer": "consistency, clarity, efficiency", "latency_ms": 101.06158256530762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ensure consistency, enforce best practice, improve communication", "latency_ms": 229.78806495666504, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "improve communication, ensure consistency, enforce best practice in usage and language composition, visual composition, orthography, typography, and ethics", "latency_ms": 443.8345432281494, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "improve communication, ensure consistency, enforce best practice in usage and language composition, visual composition, orthography, typography, ethics, pedagogy, and compliance", "latency_ms": 1228.2967567443848, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 1971}, "4": {"k": 4, "answer": "improve communication, ensure consistency, enforce best practice in usage and language composition, visual composition, orthography, and typography", "latency_ms": 541.6779518127441, "em": 0.0, "f1": 0.21052631578947367, "containment": 1.0, "context_chars": 2644}, "5": {"k": 5, "answer": "improve communication, ensure consistency, enforce best practice in usage and language composition, visual composition, orthography, and typography", "latency_ms": 853.3473014831543, "em": 0.0, "f1": 0.21052631578947367, "containment": 1.0, "context_chars": 3346}, "6": {"k": 6, "answer": "improve communication, ensure consistency, enforce best practice in usage and language composition, visual composition, orthography, typography, ethics, pedagogy, compliance, and separation of presentation and content", "latency_ms": 1517.31276512146, "em": 0.0, "f1": 0.14814814814814814, "containment": 1.0, "context_chars": 4049}}}
{"qid": "1915885935757407192", "question": "what is the approximate volume of blood in your body", "gold_answers": ["approximately 5 liters"], "shots": {"0": {"k": 0, "answer": "5 liters", "latency_ms": 161.1802577972412, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5 liters", "latency_ms": 143.8896656036377, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "5 liters", "latency_ms": 126.9080638885498, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "5 liters", "latency_ms": 215.8377170562744, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1942}, "4": {"k": 4, "answer": "5 liters", "latency_ms": 105.88645935058594, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2591}, "5": {"k": 5, "answer": "5 liters", "latency_ms": 229.4020652770996, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3308}, "6": {"k": 6, "answer": "5 liters", "latency_ms": 202.9285430908203, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3942}}}
{"qid": "-369514098498013661", "question": "what season does bart bass die in gossip girl", "gold_answers": [")"], "shots": {"0": {"k": 0, "answer": "Season 4", "latency_ms": 154.72817420959473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 182.2664737701416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "sixth season", "latency_ms": 109.24005508422852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "season 6", "latency_ms": 149.0793228149414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1857}, "4": {"k": 4, "answer": "season 6", "latency_ms": 134.63544845581055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "season 6", "latency_ms": 270.8907127380371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "season 6", "latency_ms": 321.63190841674805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3737}}}
{"qid": "-1116288849470511210", "question": "when did france and belgium invade the ruhr", "gold_answers": ["11 January 1923", "1923", "January 1923"], "shots": {"0": {"k": 0, "answer": "1923", "latency_ms": 179.00705337524414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 129.35876846313477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "1921 and 1923", "latency_ms": 396.151065826416, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1203}, "3": {"k": 3, "answer": "1921 and 1923", "latency_ms": 429.0144443511963, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "1921 and 1923", "latency_ms": 436.16175651550293, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2567}, "5": {"k": 5, "answer": "1921 and 1923", "latency_ms": 329.7855854034424, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3191}, "6": {"k": 6, "answer": "1921 and 1923", "latency_ms": 735.809326171875, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3851}}}
{"qid": "1787430967072848088", "question": "what type of novel is goodbye mr chips", "gold_answers": ["Psychological fiction", "novella"], "shots": {"0": {"k": 0, "answer": "novel about education and social change", "latency_ms": 108.85810852050781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "schoolteacher novella", "latency_ms": 129.6710968017578, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "schoolteacher novella", "latency_ms": 297.8537082672119, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "novella", "latency_ms": 330.2021026611328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1908}, "4": {"k": 4, "answer": "sentimental meditation on a teacher's life", "latency_ms": 201.19690895080566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2536}, "5": {"k": 5, "answer": "novella", "latency_ms": 107.9866886138916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3167}, "6": {"k": 6, "answer": "novella", "latency_ms": 221.10652923583984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3801}}}
{"qid": "2105265206768647509", "question": "who won the mens figure skating in 2018 olympics", "gold_answers": ["Javier Fernández", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Hans Christian Andersen", "latency_ms": 92.88859367370605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 155.2886962890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 202.01516151428223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1302}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 209.84745025634766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1985}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 124.45306777954102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 127.70700454711914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3263}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 141.10326766967773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3920}}}
{"qid": "134587584998146088", "question": "when do you get your dress blues in the army", "gold_answers": ["during initial entry training", "when commissioned"], "shots": {"0": {"k": 0, "answer": "Upon completion of basic training and assignment to a unit.", "latency_ms": 285.69865226745605, "em": 0.0, "f1": 0.15384615384615383, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "4th-quarter of fiscal year 2010", "latency_ms": 281.51583671569824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "2010", "latency_ms": 136.96670532226562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "4th quarter of fiscal year 2010", "latency_ms": 303.74789237976074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "fourth quarter, FY2014", "latency_ms": 382.5693130493164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2471}, "5": {"k": 5, "answer": "fourth quarter, FY2010", "latency_ms": 412.9824638366699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3099}, "6": {"k": 6, "answer": "4th-quarter of fiscal year 2010", "latency_ms": 430.94563484191895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3730}}}
{"qid": "1450599178139755430", "question": "what happened at the 1939 worlds fair in regards to television", "gold_answers": ["Television demonstrations are held"], "shots": {"0": {"k": 0, "answer": "First television demonstration ever at a world's fair", "latency_ms": 387.9354000091553, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 110.89491844177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 113.86251449584961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "President Roosevelt's speech was broadcast on television during the opening ceremony.", "latency_ms": 357.79476165771484, "em": 0.0, "f1": 0.14285714285714288, "containment": 0.0, "context_chars": 1921}, "4": {"k": 4, "answer": "Television broadcast of President Roosevelt's speech at the opening ceremony on April 30, 1939.", "latency_ms": 835.2761268615723, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "Television sets were demonstrated at the fair, including at the RCA, General Electric, and Westinghouse pavilions; the fair featured the first public television broadcast with President Roosevelt's speech; television sets became available for public purchase; and one set had a transparent case to show internal components.", "latency_ms": 1550.4884719848633, "em": 0.0, "f1": 0.04444444444444444, "containment": 0.0, "context_chars": 3308}, "6": {"k": 6, "answer": "Television sets were used for broadcasts and demonstrations, including the first public television broadcast of President Roosevelt's speech, and television sets became available for public purchase.", "latency_ms": 1222.1720218658447, "em": 0.0, "f1": 0.13793103448275865, "containment": 0.0, "context_chars": 3985}}}
{"qid": "7075559602853408649", "question": "when does buffy tell her friends she was in heaven", "gold_answers": ["Something to Sing About"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 10: \"The Gift\"", "latency_ms": 365.5679225921631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "After Life (Buffy the Vampire Slayer)", "latency_ms": 230.98278045654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "After Life", "latency_ms": 77.15320587158203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1160}, "3": {"k": 3, "answer": "After Life (Buffy the Vampire Slayer)", "latency_ms": 168.78008842468262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1703}, "4": {"k": 4, "answer": "After Life (Buffy the Vampire Slayer)", "latency_ms": 206.7739963531494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2326}, "5": {"k": 5, "answer": "After Life (Buffy the Vampire Slayer)", "latency_ms": 466.7172431945801, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2936}, "6": {"k": 6, "answer": "After Life (Buffy the Vampire Slayer)", "latency_ms": 281.3141345977783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3536}}}
{"qid": "6709331549884586945", "question": "the recipient of first jnanpith award was an author which language", "gold_answers": ["Malayalam"], "shots": {"0": {"k": 0, "answer": "Kannada", "latency_ms": 66.96391105651855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "English", "latency_ms": 96.50444984436035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "English", "latency_ms": 60.72640419006348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1310}, "3": {"k": 3, "answer": "English", "latency_ms": 119.60697174072266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "English", "latency_ms": 187.88528442382812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2610}, "5": {"k": 5, "answer": "English", "latency_ms": 108.33120346069336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "Malayalam", "latency_ms": 137.69054412841797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3951}}}
{"qid": "-5800244801360835363", "question": "criminal minds episode where jj becomes a profiler", "gold_answers": ["The season seven premiere", "season seven premiere"], "shots": {"0": {"k": 0, "answer": "Season 1, Episode 1: \"Pilot\"", "latency_ms": 494.62127685546875, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 89.58005905151367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 199.5866298675537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 114.82071876525879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1844}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 179.31461334228516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2505}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 173.59232902526855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3079}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 181.79774284362793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3655}}}
{"qid": "7361909937331900466", "question": "who has played raoul in phantom of the opera", "gold_answers": ["Steve Barton", "Tim Martin Gleason", "Hadley Fraser"], "shots": {"0": {"k": 0, "answer": "Rufus Jones", "latency_ms": 244.67229843139648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tim Martin Gleason", "latency_ms": 115.98563194274902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Tim Martin Gleason, Brad Little", "latency_ms": 301.39780044555664, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 1198}, "3": {"k": 3, "answer": "Tim Martin Gleason, Brad Little", "latency_ms": 474.9882221221924, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 1814}, "4": {"k": 4, "answer": "Tim Martin Gleason, Brad Little", "latency_ms": 191.58601760864258, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 2419}, "5": {"k": 5, "answer": "Tim Martin Gleason, Brad Little", "latency_ms": 397.17864990234375, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 3027}, "6": {"k": 6, "answer": "Tim Martin Gleason, Brad Little", "latency_ms": 457.34238624572754, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 3699}}}
{"qid": "3130297943294617952", "question": "who discovered that neural communication between cells occurs through chemicals", "gold_answers": ["Charles Sherrington"], "shots": {"0": {"k": 0, "answer": "Camillo Golgi", "latency_ms": 136.68131828308105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 181.75530433654785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 93.62053871154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1375}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 118.64233016967773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2104}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 232.18059539794922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2796}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 165.7276153564453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3500}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 132.0517063140869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4203}}}
{"qid": "-8188854097093895186", "question": "who has the most ncaa basketball tournament appearances", "gold_answers": ["Kentucky"], "shots": {"0": {"k": 0, "answer": "University of Kansas", "latency_ms": 160.86745262145996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tennessee", "latency_ms": 72.42417335510254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "Tennessee", "latency_ms": 167.32478141784668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1406}, "3": {"k": 3, "answer": "Tennessee", "latency_ms": 172.16920852661133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2124}, "4": {"k": 4, "answer": "Tennessee", "latency_ms": 100.16608238220215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2848}, "5": {"k": 5, "answer": "Tennessee", "latency_ms": 311.4657402038574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3533}, "6": {"k": 6, "answer": "Tennessee", "latency_ms": 166.0165786743164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4234}}}
{"qid": "-3197375005297250079", "question": "which condition would most likely require nutrition delivered through tpn", "gold_answers": ["bowel obstruction", "ulcerative colitis", "gastroschisis", "short bowel syndrome", "high - output fistula", "prolonged diarrhea", "very severe Crohn 's disease"], "shots": {"0": {"k": 0, "answer": "Severe malabsorption disorder", "latency_ms": 102.10680961608887, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "bowel obstruction", "latency_ms": 68.26949119567871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 735}, "2": {"k": 2, "answer": "bowel obstruction", "latency_ms": 210.89410781860352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1476}, "3": {"k": 3, "answer": "bowel obstruction", "latency_ms": 87.4471664428711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2188}, "4": {"k": 4, "answer": "bowel obstruction", "latency_ms": 117.2947883605957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2927}, "5": {"k": 5, "answer": "bowel obstruction", "latency_ms": 240.9803867340088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3649}, "6": {"k": 6, "answer": "bowel obstruction", "latency_ms": 312.72387504577637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4277}}}
{"qid": "-1059932910092423631", "question": "today gestalt psychology ideas are part of which branch of psychology", "gold_answers": ["experimental psychology", "Berlin School of experimental psychology"], "shots": {"0": {"k": 0, "answer": "cognitive psychology", "latency_ms": 384.92369651794434, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "cognitive psychology", "latency_ms": 112.87283897399902, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 679}, "2": {"k": 2, "answer": "cognitive psychology", "latency_ms": 261.1877918243408, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Gestalt therapy", "latency_ms": 136.41881942749023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2048}, "4": {"k": 4, "answer": "cognitive psychology", "latency_ms": 97.54705429077148, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2736}, "5": {"k": 5, "answer": "Gestalt therapy", "latency_ms": 178.30443382263184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3423}, "6": {"k": 6, "answer": "cognitive psychology", "latency_ms": 116.47939682006836, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4222}}}
{"qid": "3063199819637642694", "question": "how did long john silver lose his leg in treasure island", "gold_answers": ["in the Royal Navy"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 76.94602012634277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 166.82696342468262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 117.0041561126709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "under \"the immortal Hawke\"", "latency_ms": 162.63389587402344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "under \"the immortal Hawke\"", "latency_ms": 432.74593353271484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2420}, "5": {"k": 5, "answer": "under \"the immortal Hawke\"", "latency_ms": 174.59917068481445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2992}, "6": {"k": 6, "answer": "under \"the immortal Hawke\"", "latency_ms": 287.6930236816406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3580}}}
{"qid": "-1716244375468450999", "question": "who was the first territorial governor of oklahoma", "gold_answers": ["George Washington Steele"], "shots": {"0": {"k": 0, "answer": "William C. O'Neal", "latency_ms": 182.1908950805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "George Washington Steele", "latency_ms": 176.97930335998535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "George Washington Steele", "latency_ms": 235.0611686706543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1388}, "3": {"k": 3, "answer": "George Washington Steele", "latency_ms": 144.09875869750977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2063}, "4": {"k": 4, "answer": "George Washington Steele", "latency_ms": 289.4775867462158, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2737}, "5": {"k": 5, "answer": "George Washington Steele", "latency_ms": 158.08844566345215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3467}, "6": {"k": 6, "answer": "George Washington Steele", "latency_ms": 162.37735748291016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4137}}}
{"qid": "3124572532765125550", "question": "who did the mavericks beat in the finals", "gold_answers": ["Miami Heat"], "shots": {"0": {"k": 0, "answer": "Golden State Warriors", "latency_ms": 150.38061141967773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 82.54718780517578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 69.47135925292969, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 83.15372467041016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1855}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 85.49118041992188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2469}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 136.48033142089844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3069}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 129.18901443481445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3684}}}
{"qid": "-8179137917755764249", "question": "who is the actor that plays sneaky pete", "gold_answers": ["Giovanni Ribisi"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 129.61745262145996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Giovanni Ribisi", "latency_ms": 103.11555862426758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Giovanni Ribisi", "latency_ms": 111.44828796386719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1276}, "3": {"k": 3, "answer": "Giovanni Ribisi", "latency_ms": 289.06702995300293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1872}, "4": {"k": 4, "answer": "Giovanni Ribisi", "latency_ms": 319.0455436706543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2503}, "5": {"k": 5, "answer": "Giovanni Ribisi", "latency_ms": 320.88780403137207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3091}, "6": {"k": 6, "answer": "Giovanni Ribisi", "latency_ms": 185.97865104675293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3722}}}
{"qid": "-488573928094288904", "question": "sequel to a christmas story it runs in the family", "gold_answers": ["My Summer Story"], "shots": {"0": {"k": 0, "answer": "A Christmas Story II", "latency_ms": 294.3387031555176, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "My Summer Story", "latency_ms": 112.66756057739258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "My Summer Story", "latency_ms": 235.8386516571045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1229}, "3": {"k": 3, "answer": "My Summer Story", "latency_ms": 241.3623332977295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1880}, "4": {"k": 4, "answer": "A Christmas Story 2", "latency_ms": 145.3685760498047, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2484}, "5": {"k": 5, "answer": "A Christmas Story 2", "latency_ms": 279.4184684753418, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3080}, "6": {"k": 6, "answer": "My Summer Story", "latency_ms": 139.56356048583984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3727}}}
{"qid": "-4649146182478016322", "question": "when did virgin australia (formerly virgin blue) commence flying in australia", "gold_answers": ["November 1999"], "shots": {"0": {"k": 0, "answer": "2007", "latency_ms": 80.46627044677734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "November 1999", "latency_ms": 223.1309413909912, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "November 1999", "latency_ms": 156.27288818359375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1289}, "3": {"k": 3, "answer": "August 2000", "latency_ms": 132.19547271728516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "August 2000", "latency_ms": 134.78517532348633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2639}, "5": {"k": 5, "answer": "August 2000", "latency_ms": 356.27293586730957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3296}, "6": {"k": 6, "answer": "August 2000", "latency_ms": 160.00819206237793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3977}}}
{"qid": "-7386387080002447998", "question": "a political leader during the roman empire was called", "gold_answers": ["emperors"], "shots": {"0": {"k": 0, "answer": "emperor", "latency_ms": 83.73212814331055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "public cult leader", "latency_ms": 84.60140228271484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "an imperial court leader", "latency_ms": 253.36503982543945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "imperial court", "latency_ms": 83.52088928222656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2017}, "4": {"k": 4, "answer": "an imperial court leader", "latency_ms": 273.12350273132324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2714}, "5": {"k": 5, "answer": "an imperial court leader", "latency_ms": 153.5658836364746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3385}, "6": {"k": 6, "answer": "public cult leader", "latency_ms": 189.29553031921387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3954}}}
{"qid": "6648524536408285205", "question": "what is the first book of percy jackson", "gold_answers": ["The Lightning Thief"], "shots": {"0": {"k": 0, "answer": "The Lightning Thief", "latency_ms": 66.91670417785645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Percy Jackson & the Olympians", "latency_ms": 141.1609649658203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Percy Jackson & the Olympians", "latency_ms": 333.99152755737305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "Percy Jackson and the Olympians", "latency_ms": 188.10510635375977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "The Lightning Thief", "latency_ms": 192.71111488342285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2527}, "5": {"k": 5, "answer": "The Lightning Thief", "latency_ms": 307.06143379211426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3170}, "6": {"k": 6, "answer": "The Lightning Thief", "latency_ms": 234.40313339233398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3799}}}
{"qid": "-8743280518479013381", "question": "who sings the song only in my dreams", "gold_answers": ["Debbie Gibson"], "shots": {"0": {"k": 0, "answer": "Celine Dion", "latency_ms": 166.0315990447998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Weezer", "latency_ms": 270.95913887023926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "Weezer", "latency_ms": 245.93639373779297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1181}, "3": {"k": 3, "answer": "Roy Orbison", "latency_ms": 262.38274574279785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1789}, "4": {"k": 4, "answer": "Weezer", "latency_ms": 102.43463516235352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2371}, "5": {"k": 5, "answer": "Weezer", "latency_ms": 121.50263786315918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2972}, "6": {"k": 6, "answer": "Weezer", "latency_ms": 210.95848083496094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3499}}}
{"qid": "8015709437014232395", "question": "where is the capital city of alabama located", "gold_answers": ["Montgomery"], "shots": {"0": {"k": 0, "answer": "Montgomery", "latency_ms": 163.27428817749023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montgomery, Alabama", "latency_ms": 183.52508544921875, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Montgomery, Alabama", "latency_ms": 121.90508842468262, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "Montgomery, Alabama", "latency_ms": 126.58548355102539, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2007}, "4": {"k": 4, "answer": "Montgomery, Alabama", "latency_ms": 173.21348190307617, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Montgomery, Alabama", "latency_ms": 127.63381004333496, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3292}, "6": {"k": 6, "answer": "Montgomery, Alabama", "latency_ms": 209.76543426513672, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3965}}}
{"qid": "-7741834825578210187", "question": "when was coffee first made into a drink", "gold_answers": ["the 15th century", "15th century"], "shots": {"0": {"k": 0, "answer": "8th century", "latency_ms": 72.24702835083008, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 96.80795669555664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "middle of the 15th century", "latency_ms": 144.9296474456787, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1219}, "3": {"k": 3, "answer": "middle of the 15th century", "latency_ms": 259.7649097442627, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1796}, "4": {"k": 4, "answer": "middle of the 15th century", "latency_ms": 331.28929138183594, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2395}, "5": {"k": 5, "answer": "middle of the 15th century", "latency_ms": 224.7629165649414, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2992}, "6": {"k": 6, "answer": "middle of the 15th century", "latency_ms": 288.6383533477783, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3634}}}
{"qid": "5397736648256223057", "question": "when was the last time vancouver had an earthquake", "gold_answers": ["1946"], "shots": {"0": {"k": 0, "answer": "2023", "latency_ms": 80.53946495056152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 128.4632682800293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 135.13827323913574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 188.83848190307617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 231.20903968811035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2710}, "5": {"k": 5, "answer": "1700", "latency_ms": 235.8837127685547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3391}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 249.18031692504883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4051}}}
{"qid": "-2756184966764635962", "question": "when did tim hortons open in the usa", "gold_answers": ["1981"], "shots": {"0": {"k": 0, "answer": "2005", "latency_ms": 83.97388458251953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Deerfield", "latency_ms": 103.26862335205078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Deerfield", "latency_ms": 98.15716743469238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "2014", "latency_ms": 261.46745681762695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "2014", "latency_ms": 144.96612548828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "Deerfield", "latency_ms": 192.50726699829102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "Deerfield", "latency_ms": 245.8631992340088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3715}}}
{"qid": "6006172994740079617", "question": "who sang the original scooby doo theme song", "gold_answers": ["Larry Marks"], "shots": {"0": {"k": 0, "answer": "Dana Carol", "latency_ms": 67.72685050964355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 94.99025344848633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Roberts", "latency_ms": 117.25783348083496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 111.37628555297852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 191.0989284515381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 254.20451164245605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3269}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 144.99640464782715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3900}}}
{"qid": "-6197052503812142206", "question": "who has won the most superbowls as a player", "gold_answers": ["Tom Brady", "Charles Haley", "Neal Dahlen", "Bill Belichick"], "shots": {"0": {"k": 0, "answer": "Joe Montana", "latency_ms": 74.09930229187012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 111.04393005371094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 99.90143775939941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 151.61657333374023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 273.98061752319336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2660}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 148.60033988952637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3325}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 211.41552925109863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3921}}}
{"qid": "1471601930209559051", "question": "who used to present i'm a celebrity now", "gold_answers": ["Ant & Dec"], "shots": {"0": {"k": 0, "answer": "Dermot O'Leary", "latency_ms": 135.36953926086426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ant & Dec", "latency_ms": 163.30862045288086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Matt Willis, Emma Willis, and Mark Durden-Smith", "latency_ms": 407.4981212615967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Mark Durden-Smith and Tara Palmer-Tomkinson", "latency_ms": 342.03171730041504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "Matt Willis, Emma Willis, and Mark Durden-Smith", "latency_ms": 663.8479232788086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Matt Willis, Emma Willis, and Mark Durden-Smith", "latency_ms": 521.0564136505127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3083}, "6": {"k": 6, "answer": "Matt Willis, Emma Willis, Mark Durden-Smith", "latency_ms": 739.8209571838379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3706}}}
{"qid": "5150934530929664244", "question": "who led the conquest of the incas in south america", "gold_answers": ["conquistador Francisco Pizarro", "Francisco Pizarro"], "shots": {"0": {"k": 0, "answer": "Vasco Núñez de Balboa", "latency_ms": 238.8451099395752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Francisco Pizarro", "latency_ms": 316.6170120239258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "Francisco Pizarro", "latency_ms": 213.9263153076172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1317}, "3": {"k": 3, "answer": "Francisco Pizarro", "latency_ms": 120.72944641113281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2028}, "4": {"k": 4, "answer": "Francisco Pizarro", "latency_ms": 241.3163185119629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2731}, "5": {"k": 5, "answer": "Francisco Pizarro", "latency_ms": 184.814453125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3410}, "6": {"k": 6, "answer": "Francisco Pizarro", "latency_ms": 515.9804821014404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4103}}}
{"qid": "5255969991136559330", "question": "who sings the pokemon theme song season 1", "gold_answers": ["Jason Paige"], "shots": {"0": {"k": 0, "answer": "Yoko Kanno", "latency_ms": 148.77772331237793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jason Paige", "latency_ms": 57.641029357910156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Jason Paige", "latency_ms": 97.29337692260742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1185}, "3": {"k": 3, "answer": "Jason Paige", "latency_ms": 126.40976905822754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1859}, "4": {"k": 4, "answer": "Jason Paige", "latency_ms": 106.70113563537598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2462}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 303.4181594848633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 277.7259349822998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3650}}}
{"qid": "1376719706403766477", "question": "where was the rise of the planet of the apes filmed", "gold_answers": ["San Francisco , California", "Oahu , Hawaii", "Vancouver , British Columbia"], "shots": {"0": {"k": 0, "answer": "California, USA", "latency_ms": 137.76755332946777, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Vancouver, British Columbia; San Francisco, California; Oahu, Hawaii", "latency_ms": 344.20108795166016, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Vancouver, British Columbia; San Francisco, California; Oahu, Hawaii", "latency_ms": 404.07681465148926, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "Vancouver, British Columbia; San Francisco, California; Oahu, Hawaii", "latency_ms": 510.5161666870117, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 1801}, "4": {"k": 4, "answer": "Vancouver, British Columbia; San Francisco, California; Oahu, Hawaii", "latency_ms": 678.9255142211914, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 2378}, "5": {"k": 5, "answer": "Vancouver, British Columbia; San Francisco, California; Oahu, Hawaii", "latency_ms": 487.3642921447754, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 3045}, "6": {"k": 6, "answer": "Vancouver, British Columbia; San Francisco, California; Oahu, Hawaii", "latency_ms": 762.608528137207, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 3646}}}
{"qid": "-8781977407436236434", "question": "where does wild caught sockeye salmon come from", "gold_answers": ["the Northern Pacific Ocean"], "shots": {"0": {"k": 0, "answer": "North Pacific Ocean", "latency_ms": 79.05983924865723, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bristol Bay, Alaska; Kamchatka Peninsula of the Russian Far East, especially Ozernaya River of Kurile Lake", "latency_ms": 785.1972579956055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Bristol Bay, Alaska; Kamchatka Peninsula of the Russian Far East, especially Ozernaya River of Kurile Lake", "latency_ms": 573.6441612243652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Bristol Bay, Alaska; Kamchatka Peninsula of the Russian Far East; Columbia River; Ozernaya River of the Kurile Lake", "latency_ms": 494.31800842285156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1869}, "4": {"k": 4, "answer": "Bristol Bay, Alaska; Kamchatka Peninsula of the Russian Far East; Fraser River and its tributaries", "latency_ms": 575.1438140869141, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "Bristol Bay, Alaska; Kamchatka Peninsula, Russian Far East; Fraser River and its tributaries, Canada; Snake River and Lake Ozette, Washington, USA", "latency_ms": 1387.913465499878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Bristol Bay, Alaska; Kamchatka Peninsula, Russia; Fraser River, Canada; Snake River, USA; Lake Ozette, Washington, USA; northern Hokkaidō, Japan; Bathurst Inlet, Canada; Anadyr River, Siberia; Redfish Lake, Idaho", "latency_ms": 2111.5143299102783, "em": 0.0, "f1": 0.06451612903225806, "containment": 0.0, "context_chars": 3820}}}
{"qid": "5898293246250067104", "question": "what is the latest version of microsoft office 2010", "gold_answers": ["14.0. 7182.5000"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 75.65188407897949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 176.44977569580078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 193.312406539917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 194.75984573364258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 207.2007656097412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2605}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 193.12787055969238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3229}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 271.4552879333496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3831}}}
{"qid": "-4565661977175862394", "question": "who added a press room to the white house", "gold_answers": ["Richard Nixon", "President Richard Nixon"], "shots": {"0": {"k": 0, "answer": "Jacqueline Kennedy", "latency_ms": 217.48924255371094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Theodore Roosevelt", "latency_ms": 288.6850833892822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "Theodore Roosevelt", "latency_ms": 153.0466079711914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Theodore Roosevelt", "latency_ms": 101.1803150177002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1910}, "4": {"k": 4, "answer": "Theodore Roosevelt", "latency_ms": 176.4047145843506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Theodore Roosevelt", "latency_ms": 126.2655258178711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Theodore Roosevelt", "latency_ms": 117.39635467529297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3811}}}
