{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "June 15, 2023", "latency_ms": 3634.5479488372803, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3145.768642425537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "June 22, 2018", "latency_ms": 4343.676567077637, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "June 22, 2018", "latency_ms": 3542.924642562866, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "June 22, 2018", "latency_ms": 3371.509790420532, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2524}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 3536.648750305176, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "June 22, 2018", "latency_ms": 3163.4624004364014, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3802}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Freestyle, Nordic Combined, Ski Jumping, Biathlon.", "latency_ms": 8307.593584060669, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alpine skiing", "latency_ms": 2110.962152481079, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Alpine, Freestyle", "latency_ms": 2481.055736541748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Alpine, Freestyle", "latency_ms": 3335.749626159668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 3462.1338844299316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 3691.4279460906982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "Alpine, Freestyle, Cross-country", "latency_ms": 4116.127490997314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3922}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "Arianwen Parkes-Lockwood", "latency_ms": 3207.2277069091797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Aldo Mignone", "latency_ms": 2642.005443572998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 694}, "2": {"k": 2, "answer": "Aldo Mignone", "latency_ms": 2829.9357891082764, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Aldo Mignone", "latency_ms": 2843.763589859009, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Aldo Mignone", "latency_ms": 2820.3718662261963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2560}, "5": {"k": 5, "answer": "Aldo Mignone", "latency_ms": 3328.9129734039307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3227}, "6": {"k": 6, "answer": "Aldo Mignone", "latency_ms": 2656.3050746917725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3824}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "Bengals, Dolphins, Broncos, Chargers.", "latency_ms": 4419.745683670044, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2571.613550186157, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 551}, "2": {"k": 2, "answer": "Giants, Chargers, and others not specified", "latency_ms": 5296.849727630615, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 1156}, "3": {"k": 3, "answer": "Giants, Chargers, Broncos", "latency_ms": 3132.415771484375, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1711}, "4": {"k": 4, "answer": "Giants, Chargers, Broncos", "latency_ms": 3321.55179977417, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2294}, "5": {"k": 5, "answer": "Chargers, Bengals, Broncos", "latency_ms": 3650.376796722412, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2888}, "6": {"k": 6, "answer": "Chargers, Bengals, Broncos", "latency_ms": 4268.268346786499, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3442}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "December 8, 1985", "latency_ms": 3344.5112705230713, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 December 1985", "latency_ms": 3220.2093601226807, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 727}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 2777.11820602417, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1447}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 2692.706346511841, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2143}, "4": {"k": 4, "answer": "8 December 1985", "latency_ms": 3790.438175201416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2840}, "5": {"k": 5, "answer": "December 8, 1985", "latency_ms": 3069.2481994628906, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 3557}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 2711.8632793426514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4258}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "Spanish Moss", "latency_ms": 808.0604076385498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2807.7728748321533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2709.5937728881836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1381}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2469.721555709839, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2092}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1291.6045188903809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2735}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1928.4882545471191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3346}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2049.9427318573, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3996}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "I-IV", "latency_ms": 1655.6310653686523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canadian Cardiovascular Society", "latency_ms": 2239.471197128296, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 762}, "2": {"k": 2, "answer": "Canadian Cardiovascular Society", "latency_ms": 2136.509418487549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1494}, "3": {"k": 3, "answer": "Canadian Cardiovascular Society", "latency_ms": 1592.031717300415, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2250}, "4": {"k": 4, "answer": "Canadian Cardiovascular Society grading", "latency_ms": 1752.598762512207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2959}, "5": {"k": 5, "answer": "Canadian Cardiovascular Society", "latency_ms": 2137.6843452453613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}, "6": {"k": 6, "answer": "Canadian Cardiovascular Society", "latency_ms": 2983.5145473480225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4342}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Mick Hucknall and Neil Moss", "latency_ms": 3325.4382610321045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1988.7912273406982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2475.8832454681396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2081.5391540527344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2371.722459793091, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2447}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2805.6631088256836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2523.3805179595947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3635}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 1282.2277545928955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 1214.9102687835693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2000.652551651001, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "3", "latency_ms": 1713.4802341461182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "3", "latency_ms": 908.3220958709717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2466}, "5": {"k": 5, "answer": "3", "latency_ms": 1438.7321472167969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "3", "latency_ms": 1488.5430335998535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3661}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "A cake.", "latency_ms": 1397.6373672485352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Biscuit-sized cakes", "latency_ms": 2702.606439590454, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "cake", "latency_ms": 1212.0614051818848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "cake", "latency_ms": 1745.8622455596924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1764}, "4": {"k": 4, "answer": "A cake.", "latency_ms": 1369.4822788238525, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "A cake.", "latency_ms": 2185.8627796173096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3040}, "6": {"k": 6, "answer": "A cake.", "latency_ms": 2399.5139598846436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Seth MacFarlane", "latency_ms": 2225.9998321533203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seth MacFarlane", "latency_ms": 2627.6931762695312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "Seth MacFarlane", "latency_ms": 2396.056890487671, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "Seth MacFarlane", "latency_ms": 2523.7903594970703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 2797.0025539398193, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 2494.6157932281494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3190}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 2466.5422439575195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3857}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "Heroin", "latency_ms": 1777.1399021148682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amphetamines", "latency_ms": 2014.6667957305908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2597.8996753692627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1897.827386856079, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2735.6386184692383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2430.7780265808105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3135}, "6": {"k": 6, "answer": "Diet pills", "latency_ms": 1700.3483772277832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3712}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "15 weeks", "latency_ms": 1025.700569152832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1143.1806087493896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 571}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2369.269609451294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1153}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2171.7967987060547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1779}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2570.302724838257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2373}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2549.3505001068115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2928}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2470.2394008636475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3520}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "Yushan, China", "latency_ms": 1787.6060009002686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Manchester, England", "latency_ms": 1793.945550918579, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "Sheffield, England", "latency_ms": 2552.58846282959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Sheffield, England", "latency_ms": 1750.2655982971191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1900}, "4": {"k": 4, "answer": "Sheffield, England", "latency_ms": 1785.9749794006348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2517}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1918.9999103546143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3197}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2127.835988998413, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3841}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "Thad Luckinbill", "latency_ms": 2285.025119781494, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1586.944818496704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2158.8168144226074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2134.557008743286, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1868}, "4": {"k": 4, "answer": "Thad Luckinbill", "latency_ms": 2896.0399627685547, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Thad Luckinbill", "latency_ms": 2300.835371017456, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2190.997838973999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3746}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 1057.706356048584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2574.80788230896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2168.978452682495, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "1986", "latency_ms": 961.2786769866943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "1986", "latency_ms": 1723.1378555297852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "1986", "latency_ms": 2295.198917388916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3208}, "6": {"k": 6, "answer": "1986", "latency_ms": 2026.5982151031494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3832}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "J-Rock", "latency_ms": 2103.2121181488037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alexz Johnson", "latency_ms": 1853.5127639770508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Alexz Johnson", "latency_ms": 1896.5973854064941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Alexz Johnson", "latency_ms": 2380.554676055908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Alexz Johnson", "latency_ms": 1171.1218357086182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2608}, "5": {"k": 5, "answer": "Alexz Johnson", "latency_ms": 1764.1081809997559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3259}, "6": {"k": 6, "answer": "Alexz Johnson", "latency_ms": 1707.296371459961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3906}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "March 15, 2002", "latency_ms": 2643.998861312866, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 million years ago", "latency_ms": 2448.160171508789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "360 million years ago", "latency_ms": 2149.778127670288, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "360 million years ago", "latency_ms": 2024.139404296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1920}, "4": {"k": 4, "answer": "360 million years ago", "latency_ms": 1668.9820289611816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "March 2002", "latency_ms": 2141.505002975464, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3206}, "6": {"k": 6, "answer": "March 2002", "latency_ms": 2489.112377166748, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3826}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "Master Sergeant", "latency_ms": 1595.9093570709229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Master Sergeant", "latency_ms": 1715.419054031372, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "First Sergeant", "latency_ms": 1166.7284965515137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1345}, "3": {"k": 3, "answer": "First Sergeant", "latency_ms": 1321.2332725524902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1991}, "4": {"k": 4, "answer": "First Sergeant", "latency_ms": 1984.863519668579, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2718}, "5": {"k": 5, "answer": "First Sergeant", "latency_ms": 1227.4465560913086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3336}, "6": {"k": 6, "answer": "First Sergeant", "latency_ms": 1783.8926315307617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4052}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 2699.366569519043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "GNU project", "latency_ms": 984.917163848877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 2347.165822982788, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 1525.916576385498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1999}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 2064.4843578338623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 1376.4636516571045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3296}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 2666.506767272949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3928}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "Manu Bhaker", "latency_ms": 1935.1446628570557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1647.2620964050293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2695.7485675811768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1180}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2201.352834701538, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1777}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2101.652145385742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2314}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2167.1159267425537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2918}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2198.8463401794434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3517}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Ed Roland", "latency_ms": 745.5542087554932, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 1264.7345066070557, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 2006.2098503112793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 1560.7149600982666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1992}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 1539.252519607544, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2678}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 2041.5339469909668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3316}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 1506.7484378814697, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3959}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "I cannot answer", "latency_ms": 2143.2106494903564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cleveland Cavaliers", "latency_ms": 2132.4427127838135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 1078.150749206543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 1517.8415775299072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 2311.7659091949463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2450}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 1210.2751731872559, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3025}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 1018.9917087554932, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3652}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "Guarani (PYG)", "latency_ms": 2754.582643508911, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1811.7296695709229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "100 centésimos = 1 peso", "latency_ms": 3201.7898559570312, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "Guaraní", "latency_ms": 2413.8729572296143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Guaraní", "latency_ms": 1808.3155155181885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2454}, "5": {"k": 5, "answer": "PYG6155", "latency_ms": 1542.271375656128, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "guarani (PYG)", "latency_ms": 2454.2651176452637, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3749}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "Midazolam.", "latency_ms": 2235.218048095703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "It is not specified.", "latency_ms": 2000.978946685791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "Benzodiazepine", "latency_ms": 2690.835952758789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1445}, "3": {"k": 3, "answer": "Benzodiazepine", "latency_ms": 2547.240734100342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2125}, "4": {"k": 4, "answer": "Benzodiazepine", "latency_ms": 2402.3349285125732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2805}, "5": {"k": 5, "answer": "Benzodiazepine", "latency_ms": 2454.0224075317383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3491}, "6": {"k": 6, "answer": "Benzodiazepine", "latency_ms": 1171.635389328003, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4171}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 1998.7742900848389, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "26,000 years", "latency_ms": 1309.359073638916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "26,000 years", "latency_ms": 2071.091413497925, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1207}, "3": {"k": 3, "answer": "25,772 years", "latency_ms": 1452.3382186889648, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "25,772 years", "latency_ms": 1619.3809509277344, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2481}, "5": {"k": 5, "answer": "25,772 years", "latency_ms": 2028.2657146453857, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "25,772 years", "latency_ms": 1917.4036979675293, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3729}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 1634.4261169433594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1922.4205017089844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Texas A&M", "latency_ms": 1119.164228439331, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Texas A&M Aggies", "latency_ms": 2166.780710220337, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1904}, "4": {"k": 4, "answer": "Texas A&M Aggies", "latency_ms": 2433.94136428833, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Texas A&M Aggies", "latency_ms": 1744.9655532836914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Texas A&M", "latency_ms": 1577.3048400878906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3748}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and Non-Renewable.", "latency_ms": 2224.903106689453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable or non-renewable", "latency_ms": 2924.356460571289, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable or non-renewable", "latency_ms": 3487.4825477600098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1447}, "3": {"k": 3, "answer": "renewable or non-renewable", "latency_ms": 3303.2889366149902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2177}, "4": {"k": 4, "answer": "renewable or non-renewable", "latency_ms": 3461.0230922698975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2828}, "5": {"k": 5, "answer": "renewable or non-renewable", "latency_ms": 2886.096715927124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3469}, "6": {"k": 6, "answer": "renewable or non-renewable", "latency_ms": 3630.2080154418945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4200}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "New life and fertility", "latency_ms": 1200.5586624145508, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parental devotion", "latency_ms": 1894.3321704864502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "parental devotion", "latency_ms": 2300.5692958831787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Parental devotion.", "latency_ms": 1828.1259536743164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1810}, "4": {"k": 4, "answer": "Purity", "latency_ms": 1819.6372985839844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2459}, "5": {"k": 5, "answer": "Purity", "latency_ms": 2010.3471279144287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3065}, "6": {"k": 6, "answer": "Purity", "latency_ms": 1864.8927211761475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3706}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Virat Kohli 286 runs", "latency_ms": 3413.6600494384766, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2176.7354011535645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2453.5865783691406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2206.169843673706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2194.974422454834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2441.67160987854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3144}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2227.001428604126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3769}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "the antimicrobial action of metal ions.", "latency_ms": 2877.2549629211426, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals", "latency_ms": 2789.4227504730225, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "biocidal effect of metals", "latency_ms": 1999.8164176940918, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "biocidal effect of metals", "latency_ms": 2728.095293045044, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2081}, "4": {"k": 4, "answer": "biocidal effect of metals", "latency_ms": 2410.197973251343, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2746}, "5": {"k": 5, "answer": "biocidal effect of metals", "latency_ms": 3226.2563705444336, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3407}, "6": {"k": 6, "answer": "biocidal effect of metals", "latency_ms": 2774.0209102630615, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4072}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "Dustin Higgs", "latency_ms": 1942.2926902770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2393.6877250671387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2210.0539207458496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1612.6925945281982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1904}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2168.057680130005, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Walter LaGrand", "latency_ms": 2050.98032951355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3136}, "6": {"k": 6, "answer": "Walter LaGrand", "latency_ms": 2932.9590797424316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the auction.", "latency_ms": 1996.523380279541, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the conclusion of play", "latency_ms": 2451.1497020721436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 550}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 2564.966917037964, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1156}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 2239.1042709350586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1797}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 2844.601631164551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2367}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 2771.271228790283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2949}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 2791.652202606201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3567}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Afghanistan", "latency_ms": 1349.3549823760986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 1358.963966369629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 699}, "2": {"k": 2, "answer": "Afghanistan", "latency_ms": 1816.4663314819336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Afghanistan", "latency_ms": 1580.8603763580322, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2076}, "4": {"k": 4, "answer": "Afghanistan", "latency_ms": 2104.9487590789795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2735}, "5": {"k": 5, "answer": "Afghanistan", "latency_ms": 1391.7326927185059, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3469}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 1854.8035621643066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4195}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "Vasoconstriction, Platelet Plug Formation, Coagulation.", "latency_ms": 4466.004133224487, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1406.2705039978027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2137.5181674957275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1680.610179901123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2159.5823764801025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2607}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1822.6118087768555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3321}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1829.3194770812988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4055}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "Sebastian Hunsinger", "latency_ms": 2183.8982105255127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shawn Roberts", "latency_ms": 1507.1396827697754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "Shawn Roberts", "latency_ms": 2484.6603870391846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1354}, "3": {"k": 3, "answer": "Shawn Roberts", "latency_ms": 1227.9891967773438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2062}, "4": {"k": 4, "answer": "Shawn Roberts", "latency_ms": 2091.6502475738525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2695}, "5": {"k": 5, "answer": "Shawn Roberts", "latency_ms": 1380.5952072143555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3389}, "6": {"k": 6, "answer": "Shirley Henderson", "latency_ms": 1731.5313816070557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4021}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "20 November 1989", "latency_ms": 2585.5014324188232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1984.9355220794678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 1947.1349716186523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1313}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 1926.3935089111328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1931}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 2970.1404571533203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2637}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 2281.7652225494385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3277}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 3493.6766624450684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3945}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "23 June 2016", "latency_ms": 1755.0063133239746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2016", "latency_ms": 1482.6414585113525, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "2016 EU Referendum", "latency_ms": 2487.514019012451, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "2016 EU Referendum", "latency_ms": 2414.5255088806152, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "2016 EU Referendum", "latency_ms": 2957.441806793213, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2581}, "5": {"k": 5, "answer": "June 2016", "latency_ms": 1403.165340423584, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3170}, "6": {"k": 6, "answer": "June 2016", "latency_ms": 1618.8459396362305, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3751}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 2197.974443435669, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1 World Trade Center", "latency_ms": 2197.225332260132, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "1 World Trade Center", "latency_ms": 2428.3909797668457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 1982.9530715942383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 2000.0758171081543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2644}, "5": {"k": 5, "answer": "Burj Khalifa", "latency_ms": 2664.4582748413086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3256}, "6": {"k": 6, "answer": "Burj Khalifa", "latency_ms": 2743.074655532837, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3973}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "Miriam Margolyes", "latency_ms": 2491.243839263916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2718.2390689849854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Miranda Hart", "latency_ms": 1636.927604675293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Miranda Hart", "latency_ms": 2320.7268714904785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "Miranda Hart", "latency_ms": 1826.3065814971924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Miranda Hart", "latency_ms": 1560.3413581848145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3101}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2647.7062702178955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Montesquieu", "latency_ms": 2480.7722568511963, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2198.859214782715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 1910.2821350097656, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 2717.700958251953, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 1927.9048442840576, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2621}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 2944.4265365600586, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3230}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 2353.869915008545, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3906}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Myles Garrett", "latency_ms": 2076.357126235962, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2374.4242191314697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2942.824125289917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Not mentioned", "latency_ms": 1540.6193733215332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2204.775810241699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1518.7888145446777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3116}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2585.2084159851074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3666}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2063 BS", "latency_ms": 2319.1261291503906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2168.0009365081787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3001.990795135498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2592.686414718628, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1980}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2181.570291519165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2558.3624839782715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3332}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2221.0583686828613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3999}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "Captain John Smith", "latency_ms": 1878.9818286895752, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bacon", "latency_ms": 2284.205198287964, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "Bacon", "latency_ms": 1543.574333190918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "Bacon", "latency_ms": 2200.4871368408203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "Bacon's Rebellion", "latency_ms": 2916.2421226501465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2637}, "5": {"k": 5, "answer": "Bacon", "latency_ms": 1303.4331798553467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3295}, "6": {"k": 6, "answer": "Bacon", "latency_ms": 1067.2328472137451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3979}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "Parietal cells", "latency_ms": 2196.6171264648438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stomach", "latency_ms": 1341.233730316162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "Parietal cells", "latency_ms": 2986.555576324463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Parietal cells", "latency_ms": 2099.6665954589844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1803}, "4": {"k": 4, "answer": "Parietal cells", "latency_ms": 1893.0199146270752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2404}, "5": {"k": 5, "answer": "Parietal cells", "latency_ms": 2734.2448234558105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3055}, "6": {"k": 6, "answer": "Parietal cells", "latency_ms": 1877.434492111206, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3670}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "Early morning.", "latency_ms": 1781.2585830688477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "4 a.m.", "latency_ms": 2369.586706161499, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 2401.9782543182373, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "4 a.m.", "latency_ms": 2675.825834274292, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "4 a.m.", "latency_ms": 2004.2898654937744, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2606}, "5": {"k": 5, "answer": "4 a.m.", "latency_ms": 2406.545639038086, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3317}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 2118.2119846343994, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4053}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 1669.3789958953857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Idaho", "latency_ms": 1520.1287269592285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2715.8656120300293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "Idaho", "latency_ms": 2047.9142665863037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1986}, "4": {"k": 4, "answer": "Idaho", "latency_ms": 1759.1149806976318, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2640}, "5": {"k": 5, "answer": "Idaho", "latency_ms": 1753.957748413086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3264}, "6": {"k": 6, "answer": "Idaho", "latency_ms": 1751.5544891357422, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3900}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales.", "latency_ms": 12045.233011245728, "em": 0.0, "f1": 0.43478260869565216, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2908.745050430298, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2701.2453079223633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2696.73228263855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2707.9107761383057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2953.032970428467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3159}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2533.526659011841, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 1347.3589420318604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "modulated", "latency_ms": 1543.766975402832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "modulated", "latency_ms": 1920.886754989624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1171}, "3": {"k": 3, "answer": "modulated", "latency_ms": 2560.8298778533936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1761}, "4": {"k": 4, "answer": "modulate", "latency_ms": 1830.8048248291016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "modulated", "latency_ms": 1565.201997756958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3037}, "6": {"k": 6, "answer": "modulated", "latency_ms": 1832.4215412139893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3649}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Male citizens.", "latency_ms": 1402.1131992340088, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2418.443441390991, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "only a minority of Romans", "latency_ms": 3240.2732372283936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Roman citizens", "latency_ms": 1171.0753440856934, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1994}, "4": {"k": 4, "answer": "Roman citizens", "latency_ms": 2048.8691329956055, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2700}, "5": {"k": 5, "answer": "Roman citizens", "latency_ms": 1537.5115871429443, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3339}, "6": {"k": 6, "answer": "Roman citizens", "latency_ms": 1732.7158451080322, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4014}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1694.1618919372559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "9 April 2019", "latency_ms": 2323.253393173218, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "9 April 2019", "latency_ms": 1514.1983032226562, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "9 April 2019", "latency_ms": 2220.449924468994, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "9 April 2019", "latency_ms": 2244.8651790618896, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2542}, "5": {"k": 5, "answer": "9 April 2019", "latency_ms": 2530.189037322998, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "9 April 2019", "latency_ms": 1981.4410209655762, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3809}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "100 parts of blood", "latency_ms": 1272.4103927612305, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "volume of blood or mass of blood", "latency_ms": 2894.765853881836, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "mass of blood or volume of blood", "latency_ms": 2571.0196495056152, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1234}, "3": {"k": 3, "answer": "volume of blood or mass of blood", "latency_ms": 2840.3143882751465, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1849}, "4": {"k": 4, "answer": "volume of blood or mass of blood", "latency_ms": 3550.67777633667, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2539}, "5": {"k": 5, "answer": "volume of blood or mass of blood", "latency_ms": 2635.3812217712402, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3203}, "6": {"k": 6, "answer": "volume of blood or mass of blood", "latency_ms": 2891.298532485962, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3800}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "Icarus", "latency_ms": 1434.6396923065186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Icarus", "latency_ms": 1282.9508781433105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "Iphigenia", "latency_ms": 2730.067014694214, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "Icarus", "latency_ms": 2645.235538482666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1810}, "4": {"k": 4, "answer": "Icarus", "latency_ms": 2861.543655395508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2393}, "5": {"k": 5, "answer": "Phaethon", "latency_ms": 2072.038412094116, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "Phaethon", "latency_ms": 2131.9174766540527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3630}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "September 16, 1979", "latency_ms": 2273.1869220733643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1979", "latency_ms": 1489.633560180664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "1979", "latency_ms": 1472.719430923462, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "1979", "latency_ms": 1541.2721633911133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "1979", "latency_ms": 1779.4899940490723, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2551}, "5": {"k": 5, "answer": "1979", "latency_ms": 1561.7904663085938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3159}, "6": {"k": 6, "answer": "1979", "latency_ms": 977.6260852813721, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3727}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 am HKT", "latency_ms": 2241.8041229248047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1395.1187133789062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "2 April 1986", "latency_ms": 2002.6705265045166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "2 April 1986", "latency_ms": 1975.1129150390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "2 April 1986", "latency_ms": 2716.8970108032227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2627}, "5": {"k": 5, "answer": "2 April 1986", "latency_ms": 2000.3025531768799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3296}, "6": {"k": 6, "answer": "2 April 1986", "latency_ms": 2079.7674655914307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3927}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "Tiffany Coyne", "latency_ms": 1686.2285137176514, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2392.3306465148926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "Tiffany Coyne", "latency_ms": 1128.0605792999268, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 1843.0800437927246, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 2035.8436107635498, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2449}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 2446.1758136749268, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3031}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 1939.537763595581, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3658}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "Yankees, Braves, Reds, Giants.", "latency_ms": 3228.63507270813, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yankees, Atlanta Braves", "latency_ms": 3312.9312992095947, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Yankees, Braves, Blue Jays", "latency_ms": 3387.852191925049, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Yankees, Braves, Blue Jays", "latency_ms": 3326.7226219177246, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Yankees, Braves, Blue Jays", "latency_ms": 2711.2348079681396, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2437}, "5": {"k": 5, "answer": "Yankees, Braves, Blue Jays", "latency_ms": 2961.312770843506, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3043}, "6": {"k": 6, "answer": "Yankees, Braves, Blue Jays", "latency_ms": 4196.708679199219, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3676}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "2.187 billion dollars", "latency_ms": 1669.410228729248, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$343.4 million", "latency_ms": 2697.357416152954, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "$1.84 billion", "latency_ms": 1930.1342964172363, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "$1.84 billion", "latency_ms": 2194.2455768585205, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "$1.84 billion", "latency_ms": 2714.7843837738037, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "$1.84 billion", "latency_ms": 2082.827091217041, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "$1.84 billion", "latency_ms": 2105.4866313934326, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3794}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "Christmas Eve and Christmas Day.", "latency_ms": 2860.4085445404053, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1961.240291595459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1864.3078804016113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1679.1048049926758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1679.0733337402344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2496}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2114.814281463623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1208.1923484802246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3718}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark and Norway", "latency_ms": 1349.2910861968994, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "his father", "latency_ms": 1830.4431438446045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "his parents", "latency_ms": 1226.271152496338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Denmark", "latency_ms": 1265.3660774230957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1894}, "4": {"k": 4, "answer": "Denmark", "latency_ms": 1709.5704078674316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "Denmark", "latency_ms": 1257.4870586395264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Denmark", "latency_ms": 1535.7623100280762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3739}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "Presépio", "latency_ms": 841.8278694152832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Christmas Tree", "latency_ms": 1036.0980033874512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Christmas Tree", "latency_ms": 1556.2844276428223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Christmas Tree", "latency_ms": 778.3305644989014, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Christmas Tree", "latency_ms": 1498.1586933135986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Christmas Tree", "latency_ms": 1508.4407329559326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Christmas Tree", "latency_ms": 1318.1028366088867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3845}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "Patrick Swayze", "latency_ms": 1919.9161529541016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1637.0105743408203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1860.4390621185303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1911.3802909851074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Swayze", "latency_ms": 1548.2454299926758, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Swayze", "latency_ms": 1576.1394500732422, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3213}, "6": {"k": 6, "answer": "Swayze", "latency_ms": 1553.3061027526855, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3819}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Pittsburgh", "latency_ms": 1376.2829303741455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2022.2742557525635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2150.974988937378, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1749.3367195129395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2928.8547039031982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2589}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2144.188404083252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3214}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2200.040340423584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3876}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1612", "latency_ms": 1544.273853302002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "First Parliament", "latency_ms": 1028.3000469207764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "1854", "latency_ms": 1742.0177459716797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "1854", "latency_ms": 1016.9188976287842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1994}, "4": {"k": 4, "answer": "1854", "latency_ms": 754.7476291656494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "1854", "latency_ms": 1181.9000244140625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3243}, "6": {"k": 6, "answer": "1854", "latency_ms": 1716.5296077728271, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3911}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier Fernández", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Yuzuru Hanyu", "latency_ms": 2064.058542251587, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2073.7876892089844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2119.324207305908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2017.8649425506592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2059}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2146.475315093994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2810}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 2626.375913619995, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3439}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 2772.195816040039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4120}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "Password cracking and recovery.", "latency_ms": 1274.200439453125, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Password recovery", "latency_ms": 2158.942937850952, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "password recovery", "latency_ms": 1809.1144561767578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1391}, "3": {"k": 3, "answer": "password recovery", "latency_ms": 1294.4917678833008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2024}, "4": {"k": 4, "answer": "Password recovery tool", "latency_ms": 1882.4214935302734, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2617}, "5": {"k": 5, "answer": "Password recovery tool", "latency_ms": 1845.5052375793457, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Password recovery tool", "latency_ms": 2338.4363651275635, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3819}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "Eknath Shinde", "latency_ms": 2819.542169570923, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2492.725372314453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "S. M. Krishna", "latency_ms": 2506.999969482422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 3246.8135356903076, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 3503.8013458251953, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2642}, "5": {"k": 5, "answer": "S. M. Krishna, C. Vidyasagar Rao, K. Sankaranarayanan", "latency_ms": 8489.38274383545, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "S. M. Krishna, C. Vidyasagar Rao, K. Sankaranarayanan", "latency_ms": 7455.6989669799805, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3931}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "Channel 15 (KNXV)", "latency_ms": 2985.944986343384, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1426.9521236419678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2848.0536937713623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2171.292543411255, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "15", "latency_ms": 1743.7617778778076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2570}, "5": {"k": 5, "answer": "15", "latency_ms": 1193.7782764434814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "15", "latency_ms": 1724.9867916107178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3897}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Claudia Wells", "latency_ms": 1227.973222732544, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elisabeth Shue", "latency_ms": 1410.4366302490234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Claudia Wells", "latency_ms": 2215.709447860718, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "Claudia Wells", "latency_ms": 2294.839382171631, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1798}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 2629.4915676116943, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2397}, "5": {"k": 5, "answer": "Claudia Wells", "latency_ms": 2641.251564025879, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "Claudia Wells", "latency_ms": 1600.0938415527344, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3631}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 1115.295171737671, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "United Kingdom", "latency_ms": 999.176025390625, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 1597.506046295166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 2155.3969383239746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 1898.6728191375732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 2429.342746734619, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3160}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 2624.5791912078857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3809}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The White House Chef", "latency_ms": 1982.1102619171143, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The White House Executive Chef", "latency_ms": 2015.709638595581, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "The White House Executive Chef", "latency_ms": 3011.845111846924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1369}, "3": {"k": 3, "answer": "White House Executive Chef", "latency_ms": 2042.0737266540527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2045}, "4": {"k": 4, "answer": "White House Executive Chef", "latency_ms": 2357.612133026123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2708}, "5": {"k": 5, "answer": "White House Executive Chef", "latency_ms": 3167.3295497894287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3377}, "6": {"k": 6, "answer": "White House Executive Chef", "latency_ms": 2134.0794563293457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3956}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 2643.4566974639893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2168.100118637085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3252.470016479492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1372.9469776153564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Nagendra Singh", "latency_ms": 2122.9681968688965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "Nagendra Singh", "latency_ms": 1683.2091808319092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3197}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2165.581703186035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "New Zealand", "latency_ms": 1236.494779586792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles, California and Larchmont, New York", "latency_ms": 5197.761058807373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "Virginia countryside", "latency_ms": 1572.718620300293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2093.4271812438965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2359.7793579101562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2610}, "5": {"k": 5, "answer": "British Columbia", "latency_ms": 1552.802562713623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3268}, "6": {"k": 6, "answer": "British Columbia", "latency_ms": 1321.9192028045654, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3895}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1879.6625137329102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3192.2366619110107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2126.420021057129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 4126.894950866699, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1876}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 3299.215793609619, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 3376.2662410736084, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 3824.1841793060303, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3830}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Jodie Sweetin", "latency_ms": 1914.6537780761719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jodie Sweetin", "latency_ms": 2584.773302078247, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 652}, "2": {"k": 2, "answer": "Jodie Sweetin", "latency_ms": 2104.6879291534424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Stephanie", "latency_ms": 1680.849313735962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "Stephanie", "latency_ms": 1866.3721084594727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2526}, "5": {"k": 5, "answer": "Stephanie", "latency_ms": 2221.539258956909, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2436.3455772399902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "Millennium Tower", "latency_ms": 1680.8221340179443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Millennium Tower", "latency_ms": 2100.961208343506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 2139.6002769470215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1361}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 2621.7663288116455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2008}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 2216.702938079834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2703}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 1803.0319213867188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3328}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 2687.638759613037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3988}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 364.2854690551758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 1768.5275077819824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "2015", "latency_ms": 2083.5375785827637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "2015", "latency_ms": 1562.671184539795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1820}, "4": {"k": 4, "answer": "2015", "latency_ms": 2533.5798263549805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2449}, "5": {"k": 5, "answer": "2015", "latency_ms": 1729.5300960540771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3029}, "6": {"k": 6, "answer": "2015", "latency_ms": 2290.950059890747, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3731}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "John Harlan", "latency_ms": 1614.0222549438477, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2171.73171043396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 693}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2599.034547805786, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1845.4976081848145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2254.870653152466, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2663}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2302.7093410491943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3333}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2870.4886436462402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4032}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Tyrann Mathieu", "latency_ms": 2791.926145553589, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1912.9350185394287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 3209.667921066284, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 2923.7523078918457, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 2773.8404273986816, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 2505.9449672698975, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3186}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 3730.7376861572266, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3837}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "44", "latency_ms": 1072.4449157714844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "six", "latency_ms": 1698.864459991455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 705}, "2": {"k": 2, "answer": "six episodes", "latency_ms": 2308.248281478882, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "six episodes", "latency_ms": 2068.7906742095947, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1973}, "4": {"k": 4, "answer": "Six episodes", "latency_ms": 2331.336736679077, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2646}, "5": {"k": 5, "answer": "six episodes", "latency_ms": 2257.0137977600098, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3304}, "6": {"k": 6, "answer": "6 episodes", "latency_ms": 1314.507007598877, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3979}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul Baümer's", "latency_ms": 2275.1846313476562, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "German soldiers'", "latency_ms": 2113.5966777801514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "German soldiers'", "latency_ms": 2286.1342430114746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "German soldiers'", "latency_ms": 2090.703248977661, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "German soldiers'", "latency_ms": 1804.2960166931152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2564}, "5": {"k": 5, "answer": "German soldiers'", "latency_ms": 2621.3061809539795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3204}, "6": {"k": 6, "answer": "German soldiers'", "latency_ms": 2508.836269378662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3844}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris", "latency_ms": 1506.653070449829, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 4338.470220565796, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 683}, "2": {"k": 2, "answer": "Frank Morris, John Anglin, Clarence Anglin", "latency_ms": 4519.8938846588135, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1339}, "3": {"k": 3, "answer": "Frank Morris, John Anglin, Clarence Anglin", "latency_ms": 4809.8719120025635, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 5719.534397125244, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2619}, "5": {"k": 5, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 5689.536809921265, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3224}, "6": {"k": 6, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 5299.237251281738, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3892}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF programs worldwide.", "latency_ms": 1541.6836738586426, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF's global programming", "latency_ms": 3154.689311981201, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "UNICEF's global programming", "latency_ms": 3229.0046215057373, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1417}, "3": {"k": 3, "answer": "UNICEF's global programming", "latency_ms": 3297.0924377441406, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2137}, "4": {"k": 4, "answer": "UNICEF's global programming", "latency_ms": 3337.8539085388184, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2808}, "5": {"k": 5, "answer": "UNICEF's global programming", "latency_ms": 2598.949193954468, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3538}, "6": {"k": 6, "answer": "UNICEF's global programming", "latency_ms": 2756.6256523132324, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4217}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Tablet in her left hand", "latency_ms": 1814.192533493042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2311.772108078003, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1667.654275894165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2599.385976791382, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2663.0654335021973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "Not mentioned", "latency_ms": 1831.3813209533691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2190.3481483459473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3882}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "Milan-Cortina 2026, Sapporo 2030", "latency_ms": 6738.529205322266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2928.3430576324463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "Beijing, China", "latency_ms": 2482.532262802124, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1183}, "3": {"k": 3, "answer": "Beijing, China", "latency_ms": 2913.3291244506836, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1785}, "4": {"k": 4, "answer": "Beijing, China; Ushuaia", "latency_ms": 4379.5623779296875, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2423}, "5": {"k": 5, "answer": "Beijing, China; unknown", "latency_ms": 3771.092653274536, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3062}, "6": {"k": 6, "answer": "Beijing, China; unknown", "latency_ms": 2981.6129207611084, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3712}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "October 22, 1981", "latency_ms": 2836.111545562744, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1997", "latency_ms": 2262.5691890716553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "1997", "latency_ms": 1477.4842262268066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "1997", "latency_ms": 1779.4468402862549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "1997", "latency_ms": 1543.8079833984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "1997", "latency_ms": 1843.9111709594727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "1997", "latency_ms": 1263.7624740600586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3865}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "Stone Gothic arch bridge", "latency_ms": 1718.2540893554688, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2973.012685775757, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "Through-truss, rolling bascule bridges", "latency_ms": 4351.532697677612, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "Through-truss, rolling bascule bridges", "latency_ms": 3042.8335666656494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1970}, "4": {"k": 4, "answer": "Not specified", "latency_ms": 1835.8068466186523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2650}, "5": {"k": 5, "answer": "Not specified", "latency_ms": 984.8272800445557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "Not specified", "latency_ms": 2247.870445251465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3922}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The Autocrat", "latency_ms": 1586.1351490020752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One person", "latency_ms": 1585.1337909698486, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "One person", "latency_ms": 1818.0921077728271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "One person", "latency_ms": 1721.1213111877441, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1987}, "4": {"k": 4, "answer": "One person", "latency_ms": 1207.580804824829, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2671}, "5": {"k": 5, "answer": "One person", "latency_ms": 2007.1587562561035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3321}, "6": {"k": 6, "answer": "One person", "latency_ms": 1038.3119583129883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3955}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "Affluence and suburbanization.", "latency_ms": 3171.2493896484375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2861.9561195373535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2419.489622116089, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "Return to normalcy", "latency_ms": 2168.8151359558105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Return to normalcy", "latency_ms": 2354.747772216797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "Prosperous postwar era", "latency_ms": 4170.0599193573, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "prosperous postwar era", "latency_ms": 3585.2036476135254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3945}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "Counterclockwise", "latency_ms": 1701.817512512207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Along its trajectory", "latency_ms": 1841.6247367858887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "Along the ecliptic", "latency_ms": 2871.286153793335, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1180}, "3": {"k": 3, "answer": "Counterclockwise", "latency_ms": 1924.7281551361084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1748}, "4": {"k": 4, "answer": "Counterclockwise", "latency_ms": 2378.4008026123047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2293}, "5": {"k": 5, "answer": "Counterclockwise", "latency_ms": 1847.1107482910156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2864}, "6": {"k": 6, "answer": "Counterclockwise", "latency_ms": 2151.496648788452, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3478}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Statue of Freedom", "latency_ms": 1476.200819015503, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Dome", "latency_ms": 1276.576042175293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2079.9813270568848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2317.4595832824707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "\"Statue of Freedom\"", "latency_ms": 2950.890064239502, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "\"Statue of Freedom\"", "latency_ms": 3383.0771446228027, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3285}, "6": {"k": 6, "answer": "\"Statue of Freedom\"", "latency_ms": 2900.481700897217, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3928}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "Taoyuan Leopards", "latency_ms": 4396.954536437988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington Wizards", "latency_ms": 940.3002262115479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "Washington Wizards", "latency_ms": 2335.427761077881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Washington Wizards", "latency_ms": 2025.61616897583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "Washington Wizards", "latency_ms": 2057.7399730682373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2501}, "5": {"k": 5, "answer": "Washington Wizards", "latency_ms": 2264.622688293457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3105}, "6": {"k": 6, "answer": "Washington Wizards", "latency_ms": 2303.4656047821045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3777}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "Rey Mysterio", "latency_ms": 3127.837896347046, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2251.268148422241, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2854.391574859619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Rey Mysterio", "latency_ms": 3298.1185913085938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Rey Mysterio", "latency_ms": 3541.1667823791504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2454}, "5": {"k": 5, "answer": "Mysterio", "latency_ms": 2920.2256202697754, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3107}, "6": {"k": 6, "answer": "Mysterio", "latency_ms": 1320.9192752838135, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3708}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 1665.4636859893799, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake of the Ozarks", "latency_ms": 2741.607427597046, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Lake Mead", "latency_ms": 2038.6462211608887, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "Lake Mead", "latency_ms": 1768.3613300323486, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Lake Mead", "latency_ms": 2000.2684593200684, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2387}, "5": {"k": 5, "answer": "Lake Mead", "latency_ms": 1959.5375061035156, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2959}, "6": {"k": 6, "answer": "Lake Mead", "latency_ms": 1544.1949367523193, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3536}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Tagore", "latency_ms": 2370.3174591064453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tagore", "latency_ms": 728.6276817321777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 585}, "2": {"k": 2, "answer": "Tagore", "latency_ms": 1292.5167083740234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tagore", "latency_ms": 1929.3506145477295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1847}, "4": {"k": 4, "answer": "Tagore", "latency_ms": 1760.0183486938477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2483}, "5": {"k": 5, "answer": "Tagore", "latency_ms": 2299.1511821746826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3134}, "6": {"k": 6, "answer": "Tagore", "latency_ms": 1202.815294265747, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3745}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "Geraldine Ferraro", "latency_ms": 3527.879476547241, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "George H. W. Bush", "latency_ms": 2703.0532360076904, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "George H. W. Bush", "latency_ms": 4241.895914077759, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "George H. W. Bush", "latency_ms": 3451.974868774414, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2073}, "4": {"k": 4, "answer": "George H. W. Bush", "latency_ms": 3795.7801818847656, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2776}, "5": {"k": 5, "answer": "George H. W. Bush", "latency_ms": 2971.8353748321533, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3479}, "6": {"k": 6, "answer": "George H. W. Bush", "latency_ms": 3566.020965576172, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 4204}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "American Rock Salt mine, Livingston County, New York", "latency_ms": 3881.129741668701, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners", "latency_ms": 3201.9314765930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners, Groveland", "latency_ms": 4119.26007270813, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Hampton Corners, Groveland", "latency_ms": 3787.4598503112793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "Hampton Corners, Groveland, New York", "latency_ms": 5022.74227142334, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Hampton Corners, Groveland", "latency_ms": 4440.756797790527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Hampton Corners, Groveland, New York", "latency_ms": 5514.488697052002, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3723}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 1875.2925395965576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 1238.9953136444092, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 2087.986946105957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1172}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 1717.4241542816162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1818}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 1258.3682537078857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2449}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 1905.5697917938232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3090}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 2024.0795612335205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3647}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Meghalaya", "latency_ms": 1067.8317546844482, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2467.578887939453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Uttar Dinajpur", "latency_ms": 2538.8545989990234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "Uttar Dinajpur", "latency_ms": 2988.4138107299805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Uttar Dinajpur", "latency_ms": 3118.8206672668457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "Uttar Dinajpur", "latency_ms": 2727.3547649383545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Uttar Dinajpur", "latency_ms": 2046.9865798950195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3733}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Kanpur", "latency_ms": 2641.2980556488037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1710.9401226043701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2298.29740524292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2860.044479370117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1936}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2011.6164684295654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2447.0982551574707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2249.404191970825, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3876}}}
