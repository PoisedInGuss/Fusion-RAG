{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 1622.7619647979736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Molly", "latency_ms": 1811.8195533752441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1939.6274089813232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1189}, "3": {"k": 3, "answer": "Bonnie Wright's mom, Molly, is played by Julie Walters", "latency_ms": 4871.245622634888, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1804}, "4": {"k": 4, "answer": "Bonnie Wright's mom, Molly, is played by Julie Walters", "latency_ms": 6448.412656784058, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "Bonnie Wright's mom is Molly, played by Julie Walters", "latency_ms": 5512.739419937134, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3041}, "6": {"k": 6, "answer": "Bonnie Wright", "latency_ms": 2655.216932296753, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3687}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 1929.192066192627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 2459.5847129821777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 2980.896234512329, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 2737.1249198913574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 2264.0624046325684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2422}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 2207.197427749634, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2994}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 2200.8869647979736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3594}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwestern United States and Mexico", "latency_ms": 2331.7618370056152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 6294.894695281982, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 5874.825000762939, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 5214.302539825439, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1902}, "4": {"k": 4, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 4917.874813079834, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2546}, "5": {"k": 5, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 4593.133449554443, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3213}, "6": {"k": 6, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 4124.550104141235, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3866}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 3957.4756622314453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Karl Seitz", "latency_ms": 1862.1056079864502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Karl Seitz", "latency_ms": 2491.15252494812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Karl Seitz", "latency_ms": 2688.326597213745, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2011}, "4": {"k": 4, "answer": "Dr. Rajendra Prasad", "latency_ms": 3698.4455585479736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2756}, "5": {"k": 5, "answer": "Karl Seitz", "latency_ms": 3010.2992057800293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3455}, "6": {"k": 6, "answer": "Dr. Rajendra Prasad", "latency_ms": 2820.721387863159, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4101}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1921.3902950286865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2949.186325073242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1951.0958194732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2223.4973907470703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1845.7419872283936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2525}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2690.605878829956, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3215}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1908.7474346160889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3827}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "June 22, 2001", "latency_ms": 3638.766050338745, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2001", "latency_ms": 999.556303024292, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "2001", "latency_ms": 2313.9986991882324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "2001", "latency_ms": 1868.8600063323975, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "2001", "latency_ms": 1648.4744548797607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "2001", "latency_ms": 1861.3319396972656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3112}, "6": {"k": 6, "answer": "2001", "latency_ms": 1531.2130451202393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3738}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "March 1, 2018", "latency_ms": 3695.830821990967, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 3907.095432281494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 3437.2410774230957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 3379.941940307617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 3249.1533756256104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2653}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 3400.7489681243896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "September 27, 2017", "latency_ms": 3948.3885765075684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3894}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3.", "latency_ms": 2206.9671154022217, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2703.443765640259, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "Yes/No episode", "latency_ms": 2344.3503379821777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "Yes/No episode", "latency_ms": 3087.3308181762695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1775}, "4": {"k": 4, "answer": "In \"Hell-O\"", "latency_ms": 3246.4122772216797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2338}, "5": {"k": 5, "answer": "In \"The Power of Madonna\"", "latency_ms": 4238.267660140991, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2957}, "6": {"k": 6, "answer": "In \"Hell-O\"", "latency_ms": 2825.6659507751465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3580}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2664.402484893799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2157.6921939849854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2841.7625427246094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2913.874626159668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2776.1893272399902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2450}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2715.9855365753174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3058}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2916.288375854492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3696}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 2103.2443046569824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "the harbor", "latency_ms": 1266.0787105560303, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "the harbor", "latency_ms": 1313.3182525634766, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Havana Harbor", "latency_ms": 1793.2398319244385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1879}, "4": {"k": 4, "answer": "Havana Harbor", "latency_ms": 2554.9120903015137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2451}, "5": {"k": 5, "answer": "Havana Harbor", "latency_ms": 2375.121593475342, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3067}, "6": {"k": 6, "answer": "Havana Harbor", "latency_ms": 2675.563335418701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3641}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 1982.182264328003, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2098.940134048462, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2326.9333839416504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1931.5192699432373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "No specific god mentioned", "latency_ms": 2192.823648452759, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2553}, "5": {"k": 5, "answer": "No specific god mentioned", "latency_ms": 3189.9354457855225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3227}, "6": {"k": 6, "answer": "No specific god mentioned", "latency_ms": 3124.10569190979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3868}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama.", "latency_ms": 4487.117767333984, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costa Rica and Panama and also possibly Belize, Honduras, Guatemala, Nicaragua, and El Salvador", "latency_ms": 7187.277793884277, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 555}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2700.197458267212, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1164}, "3": {"k": 3, "answer": "Costa Rica and Panama and Nicaragua", "latency_ms": 3096.149682998657, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Costa Rica and Panama and Nicaragua", "latency_ms": 3024.212121963501, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2447}, "5": {"k": 5, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 2815.868377685547, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3107}, "6": {"k": 6, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 3721.632242202759, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3740}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence.", "latency_ms": 2041.520595550537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 1523.9434242248535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 704}, "2": {"k": 2, "answer": "A typical sentence", "latency_ms": 2947.092294692993, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1360}, "3": {"k": 3, "answer": "Typical sentence", "latency_ms": 2308.1212043762207, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2042}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 2029.5825004577637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2701}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 1284.1122150421143, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3365}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 2063.735008239746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4053}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and capitalism.", "latency_ms": 2319.4072246551514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 3974.8246669769287, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Nations' wealth", "latency_ms": 2202.3367881774902, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Nations' wealth", "latency_ms": 2100.926399230957, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "The Wealth of Nations", "latency_ms": 2773.9362716674805, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "Nations' wealth", "latency_ms": 3142.977476119995, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3339.7929668426514, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3884}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 2630.8414936065674, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2334.625244140625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "August 28, 2018", "latency_ms": 4026.3619422912598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 3488.0194664001465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 2686.655044555664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2414}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 3258.411407470703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3034}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 3859.184980392456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3625}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere.", "latency_ms": 2662.3892784118652, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 5796.346664428711, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 4687.690258026123, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1341}, "3": {"k": 3, "answer": "Oceania", "latency_ms": 2358.9212894439697, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2029}, "4": {"k": 4, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 5718.472957611084, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2753}, "5": {"k": 5, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 5962.138652801514, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3452}, "6": {"k": 6, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 6512.558221817017, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4028}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Mara Jade", "latency_ms": 1655.2317142486572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Leia", "latency_ms": 1762.9692554473877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Leia", "latency_ms": 2611.6085052490234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "Leia", "latency_ms": 1714.040994644165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "Leia", "latency_ms": 2036.1363887786865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2435}, "5": {"k": 5, "answer": "Mara Jade", "latency_ms": 2290.36808013916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3055}, "6": {"k": 6, "answer": "Mara Jade", "latency_ms": 2736.717462539673, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3620}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 1402.7204513549805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack Barry", "latency_ms": 2037.9226207733154, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Barry Cryer", "latency_ms": 2222.0726013183594, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1167}, "3": {"k": 3, "answer": "Barry Cryer", "latency_ms": 2889.620780944824, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1717}, "4": {"k": 4, "answer": "Barry Cryer", "latency_ms": 3056.9963455200195, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2312}, "5": {"k": 5, "answer": "Barry Cryer", "latency_ms": 2691.875696182251, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2905}, "6": {"k": 6, "answer": "Barry Cryer", "latency_ms": 1817.7642822265625, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3488}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 1571.4726448059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "mitochondria", "latency_ms": 2011.7266178131104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "mitochondria", "latency_ms": 2122.980833053589, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1387}, "3": {"k": 3, "answer": "mitochondria", "latency_ms": 1383.8329315185547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2044}, "4": {"k": 4, "answer": "Mitochondria", "latency_ms": 2122.492551803589, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "Mitochondria", "latency_ms": 2382.444381713867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3429}, "6": {"k": 6, "answer": "Mitochondrion", "latency_ms": 2479.612112045288, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4103}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Intrusion Detection.", "latency_ms": 6900.921106338501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2125.4403591156006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 753}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1911.5922451019287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1483}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2506.979465484619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2186}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2884.196996688843, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2895}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2403.3429622650146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3588}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2671.5216636657715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4332}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 2892.666816711426, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3208.454370498657, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2147.233724594116, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1156}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1889.9974822998047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1740}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1133.0654621124268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2320}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2695.6684589385986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2925}, "6": {"k": 6, "answer": "Dottie West and Kenny Rogers", "latency_ms": 2990.2725219726562, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3512}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 1353.0583381652832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "36 months", "latency_ms": 1296.9167232513428, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 601}, "2": {"k": 2, "answer": "36 months", "latency_ms": 1775.3007411956787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "36 months", "latency_ms": 1992.0847415924072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1765}, "4": {"k": 4, "answer": "Three years old", "latency_ms": 1366.666555404663, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2456}, "5": {"k": 5, "answer": "36 months", "latency_ms": 1809.880018234253, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3064}, "6": {"k": 6, "answer": "36 months", "latency_ms": 1454.5698165893555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3657}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 1764.4932270050049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Three-part", "latency_ms": 1568.9237117767334, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 652}, "2": {"k": 2, "answer": "Three-part", "latency_ms": 2274.684429168701, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Three-part", "latency_ms": 1289.322853088379, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Three-part", "latency_ms": 1988.168478012085, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2532}, "5": {"k": 5, "answer": "Three", "latency_ms": 1180.2589893341064, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3179}, "6": {"k": 6, "answer": "Three-part", "latency_ms": 1425.4660606384277, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3783}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 6728.172540664673, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1921.447992324829, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 8517.32087135315, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 8912.361145019531, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 1957}, "4": {"k": 4, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 9423.004150390625, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 2623}, "5": {"k": 5, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 10215.45433998108, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 9813.22717666626, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 3815}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party.", "latency_ms": 2852.135419845581, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume", "latency_ms": 1523.1058597564697, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2889.2810344696045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1180}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1949.6901035308838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1773}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2622.960329055786, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2402}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2482.9745292663574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3124}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2586.399793624878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3753}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 1142.202377319336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2906.9037437438965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2704.028844833374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2565.544843673706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1875}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2164.271116256714, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2446}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2454.792022705078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3078}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2177.5667667388916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3649}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "Gratitude to Fantine", "latency_ms": 3283.0142974853516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3281.196355819702, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1907.5660705566406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "He pitied her.", "latency_ms": 3857.5499057769775, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2737.114667892456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Fantine's letter authorizing him to take Cosette", "latency_ms": 5370.943546295166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "Fantine's letter authorizing him to take Cosette", "latency_ms": 5265.573740005493, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3717}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, South Korea, Zambia, United States.", "latency_ms": 6062.415838241577, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2599.0447998046875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "Uganda and Rwanda", "latency_ms": 3313.43936920166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1391}, "3": {"k": 3, "answer": "China", "latency_ms": 1468.1966304779053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "China", "latency_ms": 1525.8510112762451, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2779}, "5": {"k": 5, "answer": "China", "latency_ms": 1725.8319854736328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3516}, "6": {"k": 6, "answer": "China, Uganda, Rwanda", "latency_ms": 2992.169141769409, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4217}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and oppression.", "latency_ms": 2460.3893756866455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to consolidate Bantu education", "latency_ms": 3286.574125289917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 714}, "2": {"k": 2, "answer": "to consolidate Bantu education", "latency_ms": 3349.6108055114746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1413}, "3": {"k": 3, "answer": "to consolidate Bantu education", "latency_ms": 3552.2313117980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2090}, "4": {"k": 4, "answer": "to ensure blacks had only enough education to work as unskilled laborers", "latency_ms": 6006.675958633423, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7306.375503540039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "to consolidate Bantu education and implement discriminatory practices uniformly", "latency_ms": 5055.211782455444, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4022}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 2346.444606781006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 3291.3806438446045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 3037.7612113952637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Python", "latency_ms": 1746.3181018829346, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1783}, "4": {"k": 4, "answer": "Python", "latency_ms": 1481.649398803711, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2399}, "5": {"k": 5, "answer": "Python", "latency_ms": 1747.227668762207, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2984}, "6": {"k": 6, "answer": "Python", "latency_ms": 1769.7641849517822, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3596}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 1075.3505229949951, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "dry ice", "latency_ms": 2132.7860355377197, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "dry ice", "latency_ms": 1513.1690502166748, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "Dry ice", "latency_ms": 911.7484092712402, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Dry ice", "latency_ms": 1802.8638362884521, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2481}, "5": {"k": 5, "answer": "Dry ice", "latency_ms": 2601.7982959747314, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "Frost or snow mixed with dust", "latency_ms": 2905.874490737915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3697}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 3200.666904449463, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "End of season 3", "latency_ms": 2668.915033340454, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "In the hospital.", "latency_ms": 2107.8178882598877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "Season 3 finale", "latency_ms": 1632.7521800994873, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1814}, "4": {"k": 4, "answer": "Season 3 finale", "latency_ms": 2428.140878677368, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2378}, "5": {"k": 5, "answer": "Season 3 finale", "latency_ms": 2610.5010509490967, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2940}, "6": {"k": 6, "answer": "Season 3 finale", "latency_ms": 1648.8542556762695, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3519}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "The home team", "latency_ms": 1353.6784648895264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "None", "latency_ms": 2008.2988739013672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "Premier League clubs", "latency_ms": 1908.8811874389648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "the team who were away for the first game", "latency_ms": 3880.737543106079, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1789}, "4": {"k": 4, "answer": "the club drawn first", "latency_ms": 2223.1247425079346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2360}, "5": {"k": 5, "answer": "The club drawn first", "latency_ms": 2164.245367050171, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2964}, "6": {"k": 6, "answer": "the team drawn first", "latency_ms": 2397.9828357696533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3567}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw.", "latency_ms": 2062.0317459106445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2786.562919616699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "Washington, D.C.", "latency_ms": 3340.9106731414795, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Washington", "latency_ms": 885.6539726257324, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Northwest Washington, DC", "latency_ms": 3482.5289249420166, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2653}, "5": {"k": 5, "answer": "Northwest", "latency_ms": 1257.051944732666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3337}, "6": {"k": 6, "answer": "Northwest", "latency_ms": 1450.0603675842285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4073}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 1593.3771133422852, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2930.3629398345947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2164.851188659668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2144.580841064453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1889.580488204956, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2515}, "5": {"k": 5, "answer": "Noahic Covenant", "latency_ms": 2629.5011043548584, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "Noahic Covenant", "latency_ms": 2382.0769786834717, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3812}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 2396.2409496307373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2407.6671600341797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2718.8549041748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1187}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2428.6513328552246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1795}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1944.5362091064453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2366}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2567.192316055298, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2945}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2165.3943061828613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3548}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "Yogi Berra", "latency_ms": 2761.4970207214355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2637.6023292541504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3186.8717670440674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1194}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2193.873882293701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3026.366949081421, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2407}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2339.357376098633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3012}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2621.448516845703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3625}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 1548.5014915466309, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 2561.0339641571045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 1059.915542602539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 2093.3923721313477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 2332.1921825408936, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2529}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 1025.5091190338135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3149}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 2056.1697483062744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3746}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "2nd", "latency_ms": 1473.0744361877441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Second", "latency_ms": 954.7319412231445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "Second", "latency_ms": 1715.8920764923096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Second", "latency_ms": 1991.7106628417969, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1797}, "4": {"k": 4, "answer": "Second", "latency_ms": 1214.1227722167969, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2453}, "5": {"k": 5, "answer": "Second most populated country", "latency_ms": 2737.748622894287, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3117}, "6": {"k": 6, "answer": "Second most populated country", "latency_ms": 2927.5240898132324, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3837}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 2205.0461769104004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mahatma Gandhi", "latency_ms": 1836.4191055297852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 694}, "2": {"k": 2, "answer": "Mahatma Gandhi", "latency_ms": 2625.587224960327, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1402}, "3": {"k": 3, "answer": "Mahatma Gandhi", "latency_ms": 2624.4561672210693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2058}, "4": {"k": 4, "answer": "Mahatma Gandhi", "latency_ms": 3417.123317718506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2732}, "5": {"k": 5, "answer": "Jawaharlal Nehru", "latency_ms": 3607.6252460479736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3454}, "6": {"k": 6, "answer": "Jawaharlal Nehru", "latency_ms": 3819.88525390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4189}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenae Anderson", "latency_ms": 1926.159143447876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3207.7083587646484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3071.178674697876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2840.7790660858154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2976.224899291992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3317.68798828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3331}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2474.3242263793945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3918}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 1283.787488937378, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 1447.6709365844727, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": ".java", "latency_ms": 1192.8045749664307, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": ".java", "latency_ms": 1721.3928699493408, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": ".java", "latency_ms": 1340.8153057098389, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": ".java", "latency_ms": 1461.5657329559326, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3152}, "6": {"k": 6, "answer": ".java", "latency_ms": 1659.3244075775146, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 2303.203582763672, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Poland", "latency_ms": 1245.213270187378, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Poland", "latency_ms": 1813.2827281951904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "Poland", "latency_ms": 1767.53568649292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "Poland", "latency_ms": 1590.162992477417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "Poland", "latency_ms": 2261.860132217407, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3252}, "6": {"k": 6, "answer": "Polish cryptologists", "latency_ms": 2092.604875564575, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3947}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline and counting votes.", "latency_ms": 3880.004644393921, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to offer promotion or threaten demotion", "latency_ms": 3404.146909713745, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "administer the whipping system", "latency_ms": 2239.637851715088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "offer promotion or threaten demotion within the committee system", "latency_ms": 3212.012767791748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1857}, "4": {"k": 4, "answer": "administer the whipping system", "latency_ms": 2499.1977214813232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "ensure party discipline", "latency_ms": 2314.3017292022705, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3058}, "6": {"k": 6, "answer": "ensuring party discipline", "latency_ms": 2557.544469833374, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3708}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 1789.2968654632568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2442.4192905426025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 609}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2450.0892162323, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2433.5384368896484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2775.024175643921, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2657}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2862.3716831207275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3347}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2458.052396774292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3996}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the right but not the obligation to buy foreign currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 2575.1922130584717, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 1453.153133392334, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 1307.666301727295, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 2014.7693157196045, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "FX option", "latency_ms": 1461.7276191711426, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2690}, "5": {"k": 5, "answer": "FX option", "latency_ms": 2011.3341808319092, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3343}, "6": {"k": 6, "answer": "FX option", "latency_ms": 2849.127769470215, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3971}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360 members in 109 constituencies", "latency_ms": 3612.2398376464844, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 2010.573387145996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360", "latency_ms": 1503.7426948547363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1380}, "3": {"k": 3, "answer": "360 members", "latency_ms": 1513.1175518035889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2064}, "4": {"k": 4, "answer": "One", "latency_ms": 2015.1481628417969, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2764}, "5": {"k": 5, "answer": "360 members", "latency_ms": 800.9052276611328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3441}, "6": {"k": 6, "answer": "360 members", "latency_ms": 2009.988784790039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4091}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 2401.155471801758, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 2143.7017917633057, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 2398.3278274536133, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 2410.938501358032, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 2514.653444290161, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2599}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 2674.0167140960693, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3278}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 3446.857690811157, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3919}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gorm"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 2698.3590126037598, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gorm", "latency_ms": 2788.738489151001, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Eydie Gorm", "latency_ms": 4054.448366165161, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1181}, "3": {"k": 3, "answer": "Eydie Gorm", "latency_ms": 2946.683883666992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1757}, "4": {"k": 4, "answer": "Eydie Gorm", "latency_ms": 2823.185443878174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2334}, "5": {"k": 5, "answer": "Eydie Gorm", "latency_ms": 3237.7090454101562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2899}, "6": {"k": 6, "answer": "Eydie Gorm", "latency_ms": 3617.8650856018066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3496}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "Kurian Joseph", "latency_ms": 1716.2120342254639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "H.L. Dattu", "latency_ms": 2978.705883026123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "H.L. Dattu", "latency_ms": 3765.8376693725586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "H.L. Dattu", "latency_ms": 3839.5564556121826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "H.L. Dattu", "latency_ms": 3037.433385848999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2472}, "5": {"k": 5, "answer": "H.L. Dattu", "latency_ms": 3398.688554763794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3151}, "6": {"k": 6, "answer": "H.L. Dattu", "latency_ms": 2744.9729442596436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3784}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "Margaret Court", "latency_ms": 2470.917224884033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2722.691535949707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Nadal", "latency_ms": 1501.4331340789795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Nadal", "latency_ms": 2261.934280395508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Nadal", "latency_ms": 2378.753662109375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2518}, "5": {"k": 5, "answer": "Federer, Nadal, Sampras, Djokovic, Emerson", "latency_ms": 6256.63948059082, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3137}, "6": {"k": 6, "answer": "Roger Federer", "latency_ms": 2580.5652141571045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3711}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 2195.901870727539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 715.0709629058838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 1725.9917259216309, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1238}, "3": {"k": 3, "answer": "1", "latency_ms": 1740.03267288208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1858}, "4": {"k": 4, "answer": "1", "latency_ms": 2013.7848854064941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2433}, "5": {"k": 5, "answer": "1", "latency_ms": 1189.5966529846191, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3032}, "6": {"k": 6, "answer": "1", "latency_ms": 1742.9089546203613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3639}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 606.0426235198975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2010", "latency_ms": 2328.225612640381, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "2010", "latency_ms": 1255.8505535125732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "2010", "latency_ms": 1937.0007514953613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1883}, "4": {"k": 4, "answer": "2010", "latency_ms": 1796.2048053741455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2487}, "5": {"k": 5, "answer": "2010", "latency_ms": 1774.3427753448486, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "2010", "latency_ms": 1810.121774673462, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3791}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 451.42579078674316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2353.133201599121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2886.0082626342773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2216.6223526000977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2489.129066467285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2022.9883193969727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3137}, "6": {"k": 6, "answer": "17", "latency_ms": 1734.0760231018066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3766}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 3288.31148147583, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2211.8427753448486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 3562.073230743408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 2439.4028186798096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 2470.8826541900635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 2738.064765930176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3144}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 3000.248432159424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3795}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 3889.1937732696533, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 2355.024576187134, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3153.36537361145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "Corey, Corey-Jackson, Smithy", "latency_ms": 5106.928110122681, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Corey, Corey-Jackson, Smithy", "latency_ms": 4351.432323455811, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2482}, "5": {"k": 5, "answer": "Corey, Corey-Jackson, Corey-James", "latency_ms": 6363.8715744018555, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3118}, "6": {"k": 6, "answer": "Corey, Corey-Jackson, Corey Jackson, Smithy", "latency_ms": 6618.036270141602, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3750}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 1882.1933269500732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Toby Keith", "latency_ms": 2281.9302082061768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Toby Keith", "latency_ms": 2168.738842010498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Toby Keith", "latency_ms": 2784.464120864868, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Toby Keith", "latency_ms": 2165.048360824585, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2440}, "5": {"k": 5, "answer": "Toby Keith", "latency_ms": 2149.934768676758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3102}, "6": {"k": 6, "answer": "Toby Keith", "latency_ms": 1885.9052658081055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3677}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 1484.013557434082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 1450.4916667938232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "159", "latency_ms": 1189.180612564087, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1239}, "3": {"k": 3, "answer": "159", "latency_ms": 1197.6795196533203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1888}, "4": {"k": 4, "answer": "159", "latency_ms": 2139.169454574585, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2618}, "5": {"k": 5, "answer": "159", "latency_ms": 972.0335006713867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3242}, "6": {"k": 6, "answer": "159", "latency_ms": 1210.8776569366455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3913}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 2199.0413665771484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1900.6397724151611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1834.8913192749023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1118}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2468.6594009399414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1672}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2658.5745811462402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2243}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2892.345428466797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2838}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3091.801643371582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3365}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 1693.3112144470215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2811.2239837646484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2172.5339889526367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3167.5751209259033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2918.4443950653076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2410}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1750.0581741333008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3004}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2152.1975994110107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3590}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 3628.899097442627, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Left hand fourth finger", "latency_ms": 2331.4528465270996, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 1778.2583236694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1137}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 1446.4442729949951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1691}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 1557.8117370605469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2293}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 1756.927490234375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2857}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 1488.5993003845215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3471}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 3243.521213531494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2296.7424392700195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2963.794946670532, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2456.0482501983643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2624.453544616699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2470}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2848.437547683716, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3100}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2490.79966545105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3724}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 2934.8409175872803, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Philip Stone", "latency_ms": 2571.573495864868, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "Philip Stone", "latency_ms": 2552.83260345459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1184}, "3": {"k": 3, "answer": "Bernard Hill", "latency_ms": 2128.254175186157, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "Bernard Hill", "latency_ms": 2061.7012977600098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2403}, "5": {"k": 5, "answer": "Bernard Hill", "latency_ms": 2387.5439167022705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2961}, "6": {"k": 6, "answer": "Bernard Hill", "latency_ms": 1524.050235748291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3543}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2018", "latency_ms": 4738.550662994385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2519.977807998657, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3474.3733406066895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1404}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2128.7660598754883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2021}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2984.081745147705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2622}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2952.7587890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3249}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3024.294853210449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3863}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 781.630277633667, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2371.8926906585693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2307.541608810425, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1305}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2924.5333671569824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1996}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1608.5636615753174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2635}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2637.2265815734863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3260}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2245.826244354248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3875}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 1087.1691703796387, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2079.183578491211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 547}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1969.62571144104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1146}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2178.175687789917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1681}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1861.2804412841797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2299}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2161.963939666748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2944}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2149.4898796081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3588}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living organisms.", "latency_ms": 1966.1602973937988, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "plants, animals, dead plant matter", "latency_ms": 4493.175745010376, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "plants, soils, animals, organisms", "latency_ms": 3959.873676300049, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "plants, soils, animals, dead plant matter", "latency_ms": 3781.440258026123, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "in plants, animals, and soils", "latency_ms": 4244.268417358398, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2577}, "5": {"k": 5, "answer": "in plants, soils, and organisms", "latency_ms": 4447.411298751831, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3284}, "6": {"k": 6, "answer": "in plants, soils, and organisms", "latency_ms": 3864.841938018799, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 4017}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "Vijay Raghavendra", "latency_ms": 3838.1879329681396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2105.715036392212, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1816.155195236206, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1187}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2689.9750232696533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1761}, "4": {"k": 4, "answer": "Chandan Shetty", "latency_ms": 2488.698720932007, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2373}, "5": {"k": 5, "answer": "Chandan Shetty", "latency_ms": 3106.8832874298096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2968}, "6": {"k": 6, "answer": "Chandan Shetty", "latency_ms": 3215.6875133514404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3611}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 3591.9880867004395, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1397.3407745361328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1422.9612350463867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2379.5766830444336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1866}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2424.015998840332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2483.1759929656982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3126}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2070.763349533081, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3744}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 2183.887004852295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2241.196870803833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1606.236457824707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1232}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2251.7411708831787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2418.0748462677, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2515}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3189.363479614258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3048}, "6": {"k": 6, "answer": "Kevin Kline", "latency_ms": 2195.7480907440186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3734}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Canada to Lake Winnipeg.", "latency_ms": 4356.535911560059, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 2262.373685836792, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Rocky Mountains to Lake Winnipeg", "latency_ms": 3371.1841106414795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1383}, "3": {"k": 3, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 3026.0207653045654, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 2767.3795223236084, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2737}, "5": {"k": 5, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 3522.690534591675, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3342}, "6": {"k": 6, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 3275.4712104797363, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4010}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 1762.953281402588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 1836.5278244018555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 649}, "2": {"k": 2, "answer": "Rome", "latency_ms": 1923.4602451324463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Rome", "latency_ms": 1803.8291931152344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1916}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 2270.00093460083, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2547}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 2991.0483360290527, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3180}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 2724.5137691497803, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3842}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "CE Mark or Measure number", "latency_ms": 2923.628091812134, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2761.25168800354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2896.2419033050537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1342.860221862793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1831}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1980.1204204559326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2379}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2638.960838317871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3002}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2673.231601715088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3580}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia, methanol.", "latency_ms": 2828.291177749634, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2604.597568511963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 3980.2122116088867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Hydrogen fluoride, ammonia, methanol, hydrogen sulfide", "latency_ms": 4051.1391162872314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Hydrogen fluoride, ammonia, methanol, hydrogen sulfide", "latency_ms": 6716.397523880005, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "Hydrogen fluoride, ammonia, methanol, hydrogen sulfide", "latency_ms": 5686.208009719849, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 5608.376502990723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Once in a Lifetime", "latency_ms": 2436.2895488739014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "April 1989", "latency_ms": 2717.259645462036, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "1988", "latency_ms": 1523.7481594085693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "1988", "latency_ms": 1880.6369304656982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "1988", "latency_ms": 1982.6362133026123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2433}, "5": {"k": 5, "answer": "1988", "latency_ms": 2022.434949874878, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3031}, "6": {"k": 6, "answer": "1988", "latency_ms": 1238.189935684204, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3624}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 1889.2409801483154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hombre", "latency_ms": 1764.9593353271484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "Hombre", "latency_ms": 1491.1465644836426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Hombre", "latency_ms": 2072.2403526306152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Hombre", "latency_ms": 1232.093095779419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Hombre", "latency_ms": 2036.7732048034668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2974}, "6": {"k": 6, "answer": "Hombre", "latency_ms": 1191.7572021484375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3613}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 2166.921615600586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Five percent", "latency_ms": 1937.1106624603271, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Five percent", "latency_ms": 1293.2744026184082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Five percent", "latency_ms": 2266.185522079468, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1957}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 3037.922143936157, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2567}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 3403.9394855499268, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 3297.128200531006, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3794}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 2044.8668003082275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2930.6387901306152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "1975", "latency_ms": 2403.3451080322266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1178}, "3": {"k": 3, "answer": "1975", "latency_ms": 751.7030239105225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1756}, "4": {"k": 4, "answer": "1975", "latency_ms": 1841.341257095337, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2368}, "5": {"k": 5, "answer": "1975", "latency_ms": 1496.4334964752197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2949}, "6": {"k": 6, "answer": "1975", "latency_ms": 1784.1362953186035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3539}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 2141.2274837493896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lionel Richie", "latency_ms": 2873.676300048828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Lionel Richie", "latency_ms": 2137.3183727264404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Lionel Richie", "latency_ms": 2554.713249206543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 2869.0521717071533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 2680.535078048706, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3239}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 2906.6953659057617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3863}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert, 2nd Baron Baltimore", "latency_ms": 4211.535692214966, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lord Baltimore", "latency_ms": 1662.8952026367188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Lord Baltimore and John Cabot", "latency_ms": 3810.6770515441895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Sir George Calvert", "latency_ms": 3140.8092975616455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "Jesuit settlers from England", "latency_ms": 3591.102123260498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "English Catholics", "latency_ms": 1737.2431755065918, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3293}, "6": {"k": 6, "answer": "English Catholics", "latency_ms": 1796.0193157196045, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3987}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 1746.9391822814941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2705.1472663879395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2587.5332355499268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Gary Player", "latency_ms": 1718.492031097412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1826}, "4": {"k": 4, "answer": "Gary Player", "latency_ms": 1737.9791736602783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2438}, "5": {"k": 5, "answer": "Gary Player", "latency_ms": 1840.101957321167, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3088}, "6": {"k": 6, "answer": "Gary Player", "latency_ms": 1516.9525146484375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3738}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 2392.204761505127, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2409.595012664795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "200 to 500 mg", "latency_ms": 2178.2174110412598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg", "latency_ms": 2912.3730659484863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1878}, "4": {"k": 4, "answer": "200 to 500 mg", "latency_ms": 1654.1619300842285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2503}, "5": {"k": 5, "answer": "200 to 500 mg", "latency_ms": 3178.6162853240967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3147}, "6": {"k": 6, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 4417.454242706299, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3735}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 3432.6930046081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham", "latency_ms": 1697.0136165618896, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 1667.2542095184326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1166}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 1563.1144046783447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1758}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 2313.8492107391357, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2394}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 2065.8886432647705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2939}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 2305.713415145874, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3533}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 2606.312036514282, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canada, Mexico, and the Caribbean.", "latency_ms": 3197.0889568328857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 698}, "2": {"k": 2, "answer": "Canada, Mexico, and the Caribbean, or Chicago.", "latency_ms": 4876.658916473389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1393}, "3": {"k": 3, "answer": "Canada, Mexico, and the Caribbean", "latency_ms": 4376.70373916626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2014}, "4": {"k": 4, "answer": "Canada, Mexico, and the Caribbean.", "latency_ms": 4976.046085357666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2663}, "5": {"k": 5, "answer": "Canada, Mexico, or the Caribbean", "latency_ms": 3491.393804550171, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3306}, "6": {"k": 6, "answer": "Chicago", "latency_ms": 1140.2993202209473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3970}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh, Scotland", "latency_ms": 2688.568592071533, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 1648.5812664031982, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 2587.592601776123, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1379}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 1640.5291557312012, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2052}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 1904.416561126709, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2718}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 1902.4617671966553, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3417}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 3110.6696128845215, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4093}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 1826.1055946350098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2133.1517696380615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 706}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1754.5461654663086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2271.4107036590576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2062}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2147.2339630126953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2736}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2607.6223850250244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3396}, "6": {"k": 6, "answer": "Roman Reigns", "latency_ms": 2224.529027938843, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4082}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 1985.5527877807617, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Boston", "latency_ms": 945.1329708099365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "Boston", "latency_ms": 1521.031141281128, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Southport, North Carolina", "latency_ms": 2180.8879375457764, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Southport, North Carolina.", "latency_ms": 2802.5784492492676, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "Southport, North Carolina.", "latency_ms": 2796.449661254883, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3045}, "6": {"k": 6, "answer": "Southport, North Carolina.", "latency_ms": 3624.680995941162, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3679}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 1814.021348953247, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1989.9766445159912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2303.5693168640137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2947.204113006592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 3022.5558280944824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 4181.523323059082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 3039.5469665527344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3782}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 2587.0158672332764, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 2481.362819671631, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 669}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 2878.0550956726074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 2874.6137619018555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2012}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 1776.625394821167, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2658}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 2647.0675468444824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3374}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 2810.3420734405518, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4111}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 473.53482246398926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 714.4303321838379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "Max", "latency_ms": 1182.0249557495117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Max", "latency_ms": 1478.4040451049805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1967}, "4": {"k": 4, "answer": "Max", "latency_ms": 707.9548835754395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2615}, "5": {"k": 5, "answer": "Max", "latency_ms": 1792.5896644592285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3269}, "6": {"k": 6, "answer": "Max", "latency_ms": 935.8417987823486, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3871}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 2448.3540058135986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1905.613660812378, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2417.226552963257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Amybeth McNulty", "latency_ms": 2089.162588119507, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "Amybeth McNulty", "latency_ms": 1845.6554412841797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2461}, "5": {"k": 5, "answer": "Amybeth McNulty", "latency_ms": 1818.2978630065918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3048}, "6": {"k": 6, "answer": "Amybeth McNulty", "latency_ms": 1929.4898509979248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3664}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "Boxer Rebellion.", "latency_ms": 1793.5011386871338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2182.767391204834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3123.8479614257812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2382.2126388549805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2743.381977081299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2466}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2368.454694747925, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2409.665822982788, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 1664.888620376587, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "self-empowerment", "latency_ms": 3743.074417114258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 2268.129348754883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "self-empowerment", "latency_ms": 2736.8924617767334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "self-empowerment", "latency_ms": 3156.0089588165283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2540}, "5": {"k": 5, "answer": "self-empowerment", "latency_ms": 2692.127227783203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3170}, "6": {"k": 6, "answer": "self-empowerment", "latency_ms": 2980.644941329956, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams' front offices", "latency_ms": 2645.332098007202, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "NFL owners", "latency_ms": 1955.437421798706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "NFL franchises", "latency_ms": 869.1902160644531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "NFL franchises", "latency_ms": 1753.2892227172852, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1828}, "4": {"k": 4, "answer": "NFL franchises", "latency_ms": 2534.58309173584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2427}, "5": {"k": 5, "answer": "NFL franchises", "latency_ms": 1269.4149017333984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3074}, "6": {"k": 6, "answer": "NFL franchises", "latency_ms": 2108.070135116577, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3678}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 2788.909673690796, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1764.0845775604248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Marshall", "latency_ms": 2034.9020957946777, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Marshall", "latency_ms": 2034.9645614624023, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1977}, "4": {"k": 4, "answer": "Marshall", "latency_ms": 2351.7184257507324, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2639}, "5": {"k": 5, "answer": "Marshall", "latency_ms": 1530.1225185394287, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3324}, "6": {"k": 6, "answer": "Marshall", "latency_ms": 2322.772741317749, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3947}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 2388.9729976654053, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 2424.691915512085, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 1944.2648887634277, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 2169.536590576172, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 2360.826015472412, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 2190.049171447754, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 3433.9237213134766, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3821}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "9", "latency_ms": 1238.7514114379883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2193.100929260254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2673.7706661224365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1188}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2675.5592823028564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1788}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2120.6133365631104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2404}, "5": {"k": 5, "answer": "All five ski jumping gold medals.", "latency_ms": 4274.571657180786, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3041}, "6": {"k": 6, "answer": "5", "latency_ms": 1744.5967197418213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3705}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3481.8460941314697, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3448.411703109741, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3785.3593826293945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4915.158748626709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1844}, "4": {"k": 4, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4876.94787979126, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2508}, "5": {"k": 5, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3506.916284561157, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3165}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4226.876735687256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3840}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 1741.3890361785889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "German-speaking world", "latency_ms": 2290.468692779541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 699}, "2": {"k": 2, "answer": "German-speaking world", "latency_ms": 3328.9215564727783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1383}, "3": {"k": 3, "answer": "German-speaking world", "latency_ms": 1574.596643447876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2014}, "4": {"k": 4, "answer": "German-speaking world", "latency_ms": 2113.147258758545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2662}, "5": {"k": 5, "answer": "German-speaking world", "latency_ms": 2379.286527633667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3308}, "6": {"k": 6, "answer": "German-speaking world", "latency_ms": 1072.83616065979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4054}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 2222.968339920044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 2379.4870376586914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 2129.422426223755, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 2606.0893535614014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "post-medieval era", "latency_ms": 2187.208890914917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "Post-medieval era", "latency_ms": 2171.6580390930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3140}, "6": {"k": 6, "answer": "16481651", "latency_ms": 2479.5050621032715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3791}}}
