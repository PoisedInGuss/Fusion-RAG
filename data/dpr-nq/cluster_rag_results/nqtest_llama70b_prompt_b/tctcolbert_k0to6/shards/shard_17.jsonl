{"qid": "-9197932657152136610", "question": "what are the main sources of economic growth in the us currently", "gold_answers": ["pharmaceuticals", "aircraft", "telecommunications", "heavy machinery"], "shots": {"0": {"k": 0, "answer": "Technology, Healthcare, E-commerce.", "latency_ms": 3160.1192951202393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "investment, new products and services", "latency_ms": 2653.7556648254395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "investment, new products and services", "latency_ms": 2740.978240966797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "investment, new products and services", "latency_ms": 3565.4690265655518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "investment, new products and services, labor, capital, efficiency", "latency_ms": 4141.855955123901, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2611}, "5": {"k": 5, "answer": "increases in labour, increase in capital and increase in efficiency", "latency_ms": 4388.263463973999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3381}, "6": {"k": 6, "answer": "increases in labour, increase in capital and increase in efficiency", "latency_ms": 4467.684984207153, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4053}}}
{"qid": "-4566914757117567579", "question": "who played ethel on the doris day show", "gold_answers": ["Carol Worthington"], "shots": {"0": {"k": 0, "answer": "Kay Chandra", "latency_ms": 1252.469778060913, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2428.6088943481445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2003.4403800964355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1867.6910400390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2336.671829223633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3094.4361686706543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3130}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2356.891393661499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3742}}}
{"qid": "212435016090205927", "question": "who played g baby in the movie hardball", "gold_answers": ["DeWayne Warren"], "shots": {"0": {"k": 0, "answer": "Keanu Reeves", "latency_ms": 2903.7039279937744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2531.611680984497, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2518.7668800354004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2660.5124473571777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1807}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2142.486572265625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2426}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2257.4501037597656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3073}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2987.079858779907, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3657}}}
{"qid": "-4190633494852415957", "question": "who played john coffey in the movie the green mile", "gold_answers": ["Michael Clarke Duncan"], "shots": {"0": {"k": 0, "answer": "Michael Clarke Duncan", "latency_ms": 1930.4628372192383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Clarke Duncan", "latency_ms": 1803.7574291229248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Michael Clarke Duncan", "latency_ms": 1847.8474617004395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1227}, "3": {"k": 3, "answer": "Michael Clarke Duncan", "latency_ms": 2355.9019565582275, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1866}, "4": {"k": 4, "answer": "Michael Clarke Duncan", "latency_ms": 1836.160659790039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2532}, "5": {"k": 5, "answer": "Michael Clarke Duncan", "latency_ms": 2352.8404235839844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3151}, "6": {"k": 6, "answer": "Michael Clarke Duncan", "latency_ms": 2083.8449001312256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3791}}}
{"qid": "811267239470530686", "question": "who wrote catch 22 (both names)", "gold_answers": ["American author Joseph Heller", "Joseph Heller .", "Joseph Heller"], "shots": {"0": {"k": 0, "answer": "Joseph Heller", "latency_ms": 1789.5209789276123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Joseph Heller", "latency_ms": 2203.489303588867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 630}, "2": {"k": 2, "answer": "Joseph Heller", "latency_ms": 2033.0779552459717, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Joseph Heller, Tomas Kalnoky", "latency_ms": 4672.699451446533, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Joseph Heller, Tomas Kalnoky", "latency_ms": 3983.3695888519287, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Joseph Heller, Tomas Kalnoky", "latency_ms": 3103.5053730010986, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3200}, "6": {"k": 6, "answer": "Joseph Heller Tomas Kalnoky", "latency_ms": 3707.1807384490967, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3863}}}
{"qid": "-1608179127534867277", "question": "where was the world chess tournament 2017 held", "gold_answers": ["Tbilisi , Georgia", "in Tbilisi , Georgia"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 1477.7896404266357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2640.5513286590576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2674.448251724243, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1384}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1956.324577331543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2066}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2553.8687705993652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2706}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2408.773422241211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3372}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2403.5723209381104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4015}}}
{"qid": "7687115121611301468", "question": "who votes to elect a rajya sabha memmber", "gold_answers": ["state legislatures"], "shots": {"0": {"k": 0, "answer": "Elected members of State Legislative Assembly.", "latency_ms": 3975.29935836792, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "MLAs", "latency_ms": 1494.9862957000732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2190.1981830596924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1160}, "3": {"k": 3, "answer": "MLAs", "latency_ms": 1104.0759086608887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1795}, "4": {"k": 4, "answer": "MLAs", "latency_ms": 1963.7694358825684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2432}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2081.376791000366, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3061}, "6": {"k": 6, "answer": "Elected members of the State Assembly", "latency_ms": 3093.3210849761963, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3695}}}
{"qid": "-5784633834792163973", "question": "when does season 8 of hawaii five o premiere", "gold_answers": ["September 29 , 2017"], "shots": {"0": {"k": 0, "answer": "September 27, 2019", "latency_ms": 3718.930244445801, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 29, 2017", "latency_ms": 3415.7042503356934, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "September 29, 2017", "latency_ms": 3371.368408203125, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "September 29, 2017", "latency_ms": 3410.928249359131, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "September 29, 2017", "latency_ms": 3898.236036300659, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2477}, "5": {"k": 5, "answer": "September 29, 2017", "latency_ms": 3368.1704998016357, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "September 29, 2017", "latency_ms": 3383.260726928711, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3801}}}
{"qid": "-5864397450755103545", "question": "paul walkers cars in fast and furious list", "gold_answers": ["1995 Toyota Supra", "2002 Mitsubishi Lancer OZ Rally", "1995 Dodge Stealth", "1995 Mitsubishi Eclipse"], "shots": {"0": {"k": 0, "answer": "Toyota Supra, Nissan Skyline, Mitsubishi Eclipse, Dodge Charger, BMW M5, Ford F-150.", "latency_ms": 9003.459215164185, "em": 0.0, "f1": 0.26666666666666666, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2880.689859390259, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2657.22918510437, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2611.529588699341, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3195.1403617858887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2438}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2516.5176391601562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3009}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1911.961555480957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3642}}}
{"qid": "-8491157534197669091", "question": "who won the oscar for best actor in 1975", "gold_answers": ["Art Carney"], "shots": {"0": {"k": 0, "answer": "Art Carney", "latency_ms": 2307.210683822632, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2468.273639678955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2675.408124923706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2192.8350925445557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2172.189474105835, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2529}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2369.9793815612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3165}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1905.2984714508057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "-8408640804522114136", "question": "when did the first episode of that 70s show air", "gold_answers": ["August 23 , 1998"], "shots": {"0": {"k": 0, "answer": "August 23, 1998", "latency_ms": 3068.553924560547, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1998", "latency_ms": 1776.6263484954834, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "1998", "latency_ms": 1215.4748439788818, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "1998", "latency_ms": 1954.5819759368896, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "1998", "latency_ms": 2694.9007511138916, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2479}, "5": {"k": 5, "answer": "1998", "latency_ms": 2275.7906913757324, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "1998", "latency_ms": 1528.008222579956, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3672}}}
{"qid": "722920117313579366", "question": "when did the book thief movie come out", "gold_answers": ["November 27 , 2013", "2013"], "shots": {"0": {"k": 0, "answer": "November 8, 2013", "latency_ms": 3771.740198135376, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "November 8, 2013", "latency_ms": 4136.526346206665, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "November 8, 2013", "latency_ms": 4835.956335067749, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "November 8, 2013", "latency_ms": 2663.317918777466, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "November 8, 2013", "latency_ms": 3959.249973297119, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2509}, "5": {"k": 5, "answer": "November 8, 2013", "latency_ms": 3727.8730869293213, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3152}, "6": {"k": 6, "answer": "November 8, 2013", "latency_ms": 3176.1021614074707, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3796}}}
{"qid": "-4427112594024146143", "question": "when did the eagles win the super bowl", "gold_answers": ["2017"], "shots": {"0": {"k": 0, "answer": "February 4, 2018", "latency_ms": 3667.8476333618164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Super Bowl LII", "latency_ms": 2450.730323791504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "2017 season", "latency_ms": 1098.311185836792, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1243}, "3": {"k": 3, "answer": "2018", "latency_ms": 1810.840368270874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1875}, "4": {"k": 4, "answer": "2018", "latency_ms": 1813.41552734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2479}, "5": {"k": 5, "answer": "2018", "latency_ms": 1251.5416145324707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3070}, "6": {"k": 6, "answer": "2018", "latency_ms": 1286.9102954864502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3672}}}
{"qid": "7078422108284431587", "question": "who is the biggest selling female group of all time", "gold_answers": ["Spice Girls"], "shots": {"0": {"k": 0, "answer": "Spice Girls", "latency_ms": 1821.0561275482178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spice Girls", "latency_ms": 2398.240327835083, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Spice Girls", "latency_ms": 2586.630344390869, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Spice Girls", "latency_ms": 1851.078987121582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Spice Girls", "latency_ms": 2429.0695190429688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2555}, "5": {"k": 5, "answer": "Spice Girls", "latency_ms": 2825.8421421051025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3184}, "6": {"k": 6, "answer": "Spice Girls", "latency_ms": 1550.3644943237305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3862}}}
{"qid": "1039102546557940080", "question": "who sang from russia with love james bond", "gold_answers": ["Matt Monro"], "shots": {"0": {"k": 0, "answer": "Matt Monro", "latency_ms": 1867.7241802215576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matt Monro", "latency_ms": 1617.2053813934326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Matt Monro", "latency_ms": 1835.249423980713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1284}, "3": {"k": 3, "answer": "Matt Monro", "latency_ms": 2141.2596702575684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1913}, "4": {"k": 4, "answer": "Matt Monro", "latency_ms": 1551.135778427124, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2534}, "5": {"k": 5, "answer": "Matt Monro", "latency_ms": 2807.9123497009277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3146}, "6": {"k": 6, "answer": "Matt Monro", "latency_ms": 1871.5031147003174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3845}}}
{"qid": "-8507438636601119973", "question": "where is urinary bladder located in human body", "gold_answers": ["on the pelvic floor", "pelvic floor"], "shots": {"0": {"k": 0, "answer": "Pelvic cavity", "latency_ms": 1631.1852931976318, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the base of the pelvis", "latency_ms": 2982.3155403137207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "at the base of the pelvis", "latency_ms": 3330.700397491455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "at the base of the pelvis", "latency_ms": 4138.6730670928955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "at the base of the pelvis", "latency_ms": 3687.9007816314697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2455}, "5": {"k": 5, "answer": "At the base of the pelvis", "latency_ms": 2765.720844268799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3099}, "6": {"k": 6, "answer": "At the base of the pelvis", "latency_ms": 3278.2115936279297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3702}}}
{"qid": "-1996951438961136762", "question": "architectural elements forming rib vaults eg wells cathedral", "gold_answers": ["two to three barrel vaults", "an armature of piped masonry", "barrel vaults"], "shots": {"0": {"k": 0, "answer": "Ribs", "latency_ms": 1807.8317642211914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ribs", "latency_ms": 1973.5467433929443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "Ribs", "latency_ms": 1481.4589023590088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "Ribs", "latency_ms": 1750.3035068511963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Ribs and barrel vaults", "latency_ms": 2874.47452545166, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2530}, "5": {"k": 5, "answer": "Ribs and piped masonry", "latency_ms": 3023.165464401245, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3132}, "6": {"k": 6, "answer": "Piped masonry", "latency_ms": 2706.6285610198975, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3795}}}
{"qid": "-8490085242981497626", "question": "who sang gonna sit right down and write myself a letter", "gold_answers": ["Fats Waller"], "shots": {"0": {"k": 0, "answer": "Alicia Keys", "latency_ms": 2151.1690616607666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fats Waller", "latency_ms": 2190.455675125122, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "Fats Waller", "latency_ms": 2416.930913925171, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Fats Waller", "latency_ms": 2764.4693851470947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Fats Waller", "latency_ms": 1882.4195861816406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Fats Waller", "latency_ms": 2160.400867462158, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3177}, "6": {"k": 6, "answer": "Fats Waller", "latency_ms": 2005.9335231781006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3801}}}
{"qid": "8783361206191889627", "question": "how many rooms is there in buckingham palace", "gold_answers": ["775 rooms", "775"], "shots": {"0": {"k": 0, "answer": "775 rooms", "latency_ms": 1311.659336090088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "775", "latency_ms": 1468.000888824463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "775", "latency_ms": 1208.1952095031738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1222}, "3": {"k": 3, "answer": "775", "latency_ms": 1241.6603565216064, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "775 rooms", "latency_ms": 1562.4818801879883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2433}, "5": {"k": 5, "answer": "775 rooms", "latency_ms": 1022.1211910247803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3044}, "6": {"k": 6, "answer": "775 rooms", "latency_ms": 1544.2380905151367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3650}}}
{"qid": "1172792682698457582", "question": "where did they get the tree for rockefeller center", "gold_answers": ["State College , PA"], "shots": {"0": {"k": 0, "answer": "New York or New Jersey, and various locations over the years.", "latency_ms": 4551.787853240967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 6549.606561660767, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 5234.333515167236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1314}, "3": {"k": 3, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 7705.379247665405, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 6698.462247848511, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2623}, "5": {"k": 5, "answer": "upstate New York and surrounding states, and even Ottawa in Ontario, Canada.", "latency_ms": 7819.554090499878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3301}, "6": {"k": 6, "answer": "upstate New York and surrounding states, and even Ottawa in Ontario, Canada.", "latency_ms": 5958.926439285278, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3990}}}
{"qid": "-8616225749004085214", "question": "who expanded the territory of china during the qing dynasty", "gold_answers": ["Prince Bao", "the Qianlong Emperor", "Qianlong"], "shots": {"0": {"k": 0, "answer": "Emperor Kangxi and the Qianlong Emperor.", "latency_ms": 3823.7874507904053, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Russian Empire", "latency_ms": 2429.729461669922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "The Qing dynasty", "latency_ms": 1374.004602432251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "Qing Empire", "latency_ms": 2335.6552124023438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Nurhaci", "latency_ms": 2461.0724449157715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "Manchu Aisin Gioro clan", "latency_ms": 3599.125385284424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Manchu Aisin Gioro clan", "latency_ms": 3286.92889213562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3831}}}
{"qid": "-4544825586005995775", "question": "what is the second largest country in asia", "gold_answers": ["China"], "shots": {"0": {"k": 0, "answer": "Kazakhstan", "latency_ms": 1588.5648727416992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2615.4685020446777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2666.0053730010986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2138.449192047119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2167.518377304077, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1690.7358169555664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3144}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1589.3986225128174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3827}}}
{"qid": "2851585794686488659", "question": "when was the last episode of vampire diaries aired", "gold_answers": ["March 10 , 2017"], "shots": {"0": {"k": 0, "answer": "March 10, 2017", "latency_ms": 2856.6017150878906, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2152.4951457977295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2179.3124675750732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "March 10, 2017", "latency_ms": 3387.7456188201904, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "March 10, 2017", "latency_ms": 3394.321918487549, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2494}, "5": {"k": 5, "answer": "March 10, 2017", "latency_ms": 3927.5949001312256, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3132}, "6": {"k": 6, "answer": "March 10, 2017", "latency_ms": 2701.047658920288, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3804}}}
{"qid": "636692438616046367", "question": "who played ashley on the young and the restless", "gold_answers": ["Shari Shattuck", "Eileen Davidson", "Brenda Epperson"], "shots": {"0": {"k": 0, "answer": "Eileen Davidson", "latency_ms": 1866.344928741455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eileen Davidson", "latency_ms": 1513.4356021881104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 629}, "2": {"k": 2, "answer": "Eileen Davidson", "latency_ms": 1893.608570098877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Eileen Davidson, Brenda Epperson, Shari Shattuck", "latency_ms": 6507.352352142334, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1868}, "4": {"k": 4, "answer": "Eileen Davidson", "latency_ms": 2081.2182426452637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2498}, "5": {"k": 5, "answer": "Eileen Davidson", "latency_ms": 1963.4788036346436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3082}, "6": {"k": 6, "answer": "Eileen Davidson", "latency_ms": 1874.1326332092285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3692}}}
{"qid": "-2668952310493902320", "question": "who has scored the most points for wales v france", "gold_answers": ["Neil Jenkins"], "shots": {"0": {"k": 0, "answer": "Neil Jenkins", "latency_ms": 1274.0485668182373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2900.449275970459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2642.4856185913086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1159}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2641.725778579712, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1764}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2994.8573112487793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2366}, "5": {"k": 5, "answer": "Barry John", "latency_ms": 2358.6180210113525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2986}, "6": {"k": 6, "answer": "Barry John", "latency_ms": 1602.3547649383545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3526}}}
{"qid": "-551363795407275714", "question": "who is pictured on the 5000 dollar bill", "gold_answers": ["James Madison"], "shots": {"0": {"k": 0, "answer": "James Madison", "latency_ms": 1010.7653141021729, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3300.9769916534424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1631.974220275879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2640.4569149017334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2743.467092514038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2609.067916870117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3199}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2379.328489303589, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3832}}}
{"qid": "-1776638341170409438", "question": "what is the strongest earthquake in the united states", "gold_answers": ["1700 Cascadia earthquake", "1964 Alaska earthquake and tsunami"], "shots": {"0": {"k": 0, "answer": "Great Alaska Earthquake of 1964", "latency_ms": 3358.541488647461, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Magnitude 4.5 aftershock", "latency_ms": 3912.163019180298, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "magnitude 4.5", "latency_ms": 3144.6940898895264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "5.8 magnitude", "latency_ms": 2632.3513984680176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "5.8 magnitude", "latency_ms": 2706.294536590576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "Magnitude 8.5 or higher", "latency_ms": 2794.9867248535156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3171}, "6": {"k": 6, "answer": "Magnitude 8.5 or higher", "latency_ms": 3348.0818271636963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3861}}}
{"qid": "-3417376069582577712", "question": "who wrote the song balls to the wall", "gold_answers": ["Herman Frank", "Peter Baltes", "Stefan Kaufmann", "Wolf Hoffmann", "Udo Dirkschneider", "Deaffy"], "shots": {"0": {"k": 0, "answer": "Accept", "latency_ms": 1704.3111324310303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1918.2229042053223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2620.7833290100098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2457.3891162872314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2082.7908515930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2461}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2396.7175483703613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1426.804542541504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3664}}}
{"qid": "-5788046732019278353", "question": "who talks for belle in beauty and the beast", "gold_answers": ["Julie Nathanson", "Jodi Benson", "Paige O'Hara"], "shots": {"0": {"k": 0, "answer": "Paige O'Hara", "latency_ms": 1737.5080585479736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Paige O'Hara", "latency_ms": 2549.575090408325, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 689}, "2": {"k": 2, "answer": "Paige O'Hara", "latency_ms": 3327.6941776275635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Paige O'Hara", "latency_ms": 1958.6045742034912, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Paige O'Hara", "latency_ms": 2300.0688552856445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2606}, "5": {"k": 5, "answer": "Paige O'Hara", "latency_ms": 1998.5699653625488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3245}, "6": {"k": 6, "answer": "Paige O'Hara", "latency_ms": 3477.0424365997314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3918}}}
{"qid": "-819495145099806596", "question": "what is a coherent set of values and beliefs about public policy called", "gold_answers": ["political ideology", "ideology", "a political ideology"], "shots": {"0": {"k": 0, "answer": "Ideology", "latency_ms": 1224.2655754089355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2380.329132080078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 732}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2191.5650367736816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1466}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2718.400239944458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2200}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2413.759469985962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2914}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1864.4795417785645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3608}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1903.7203788757324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4313}}}
{"qid": "-467801736331608973", "question": "when do liam and annie get together season 3", "gold_answers": ["Holiday Madness"], "shots": {"0": {"k": 0, "answer": "Episode 9.", "latency_ms": 1433.074712753296, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Season three", "latency_ms": 1256.0124397277832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "Season three", "latency_ms": 1757.3764324188232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "Season three", "latency_ms": 1480.4248809814453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1774}, "4": {"k": 4, "answer": "Season three", "latency_ms": 1766.3185596466064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2353}, "5": {"k": 5, "answer": "Season three", "latency_ms": 1498.0380535125732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2923}, "6": {"k": 6, "answer": "Season 3", "latency_ms": 1263.4193897247314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3532}}}
{"qid": "7210975046317501288", "question": "what breed of cat has spots and stripes", "gold_answers": ["tabby"], "shots": {"0": {"k": 0, "answer": "Ocicat", "latency_ms": 1950.0222206115723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2315.915584564209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Leopard cat", "latency_ms": 1558.3298206329346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1176}, "3": {"k": 3, "answer": "Leopard cat", "latency_ms": 1834.5487117767334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1798}, "4": {"k": 4, "answer": "Fishing cat", "latency_ms": 1595.9296226501465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2315}, "5": {"k": 5, "answer": "Fishing cat", "latency_ms": 2079.4382095336914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2919}, "6": {"k": 6, "answer": "Fishing cat", "latency_ms": 1786.271572113037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3515}}}
{"qid": "7817340376558760325", "question": "who voiced simba in the lion king 2", "gold_answers": ["Matthew Broderick"], "shots": {"0": {"k": 0, "answer": "Matthew Broderick", "latency_ms": 2140.392065048218, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2202.0559310913086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3177.323818206787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2857.697010040283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1960.2134227752686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "Matthew Broderick", "latency_ms": 2400.6900787353516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3173}, "6": {"k": 6, "answer": "Matthew Broderick", "latency_ms": 2655.8003425598145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3826}}}
{"qid": "7584034394038581786", "question": "when did the angel of the north get built", "gold_answers": ["1998", "1994"], "shots": {"0": {"k": 0, "answer": "1998", "latency_ms": 1507.601022720337, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3170.8943843841553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 592}, "2": {"k": 2, "answer": "1910", "latency_ms": 2562.661647796631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2925.893783569336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1818}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2143.559455871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2400}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1676.532506942749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2999}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2847.9537963867188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3680}}}
{"qid": "1854394640394891866", "question": "when did mcgee became a regular on ncis", "gold_answers": ["in season two", "season two"], "shots": {"0": {"k": 0, "answer": "Season 2", "latency_ms": 1100.0065803527832, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Season 2", "latency_ms": 1880.509376525879, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2937.530279159546, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "September 28, 2004", "latency_ms": 4447.104215621948, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "September 28, 2004", "latency_ms": 3400.438070297241, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "September 28, 2004", "latency_ms": 3232.6769828796387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3203}, "6": {"k": 6, "answer": "September 28, 2004", "latency_ms": 3088.2577896118164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3815}}}
{"qid": "2247250807557083996", "question": "when was 1 john 5 7 added to the bible", "gold_answers": ["the 9th century"], "shots": {"0": {"k": 0, "answer": "15th century", "latency_ms": 1636.2724304199219, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2679.1908740997314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 547}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1666.6648387908936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1150}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1682.6777458190918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1697}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2426.69677734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2293}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2400.407552719116, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2923}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1847.4273681640625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3513}}}
{"qid": "-2049551589682654986", "question": "when was the latest version of chrome released", "gold_answers": ["2018 - 01 - 22"], "shots": {"0": {"k": 0, "answer": "February 2024", "latency_ms": 2280.8456420898438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "May 25, 2010", "latency_ms": 2547.9114055633545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "May 25, 2010", "latency_ms": 2897.949457168579, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2430.665969848633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2351.95255279541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2692.9829120635986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3118}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2126.4195442199707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "-3534092359651954035", "question": "who is jojo in horton hears a who", "gold_answers": ["Jesse McCartney"], "shots": {"0": {"k": 0, "answer": "Jo-Jo", "latency_ms": 1567.671537399292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1630.9940814971924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "the teenage son of Mayor Ned McDodd", "latency_ms": 3986.0751628875732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1201}, "3": {"k": 3, "answer": "the teenage son of Mayor Ned McDodd", "latency_ms": 4697.849750518799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1781}, "4": {"k": 4, "answer": "the Mayor's teenage son", "latency_ms": 2694.838285446167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2370}, "5": {"k": 5, "answer": "the Mayor's teenage son", "latency_ms": 2452.503204345703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3031}, "6": {"k": 6, "answer": "the Mayor's teenage son", "latency_ms": 2707.062005996704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "6504412384445795967", "question": "the part of the cytoskeleton made from the protein actin is called", "gold_answers": ["Microfilaments", "microfilament"], "shots": {"0": {"k": 0, "answer": "Microfilaments", "latency_ms": 648.6272811889648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "actin cytoskeleton", "latency_ms": 3644.7460651397705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "actin cytoskeleton", "latency_ms": 2957.5443267822266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1339}, "3": {"k": 3, "answer": "microfilament", "latency_ms": 2679.417848587036, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2049}, "4": {"k": 4, "answer": "microfilament", "latency_ms": 1824.143886566162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2644}, "5": {"k": 5, "answer": "microfilaments", "latency_ms": 2121.65904045105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3351}, "6": {"k": 6, "answer": "microfilaments", "latency_ms": 2116.826057434082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4033}}}
{"qid": "95888218441734902", "question": "who plays jack in battle of the sexes", "gold_answers": ["Bill Pullman", "( Bill Pullman"], "shots": {"0": {"k": 0, "answer": "Steve Carell", "latency_ms": 1594.8681831359863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2705.2700519561768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2607.3837280273438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "Robert Harron", "latency_ms": 2336.989641189575, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "Robert Harron", "latency_ms": 2413.5446548461914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "Robert Harron", "latency_ms": 2082.5624465942383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Donald Crisp", "latency_ms": 2439.0475749969482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3787}}}
{"qid": "2482202658787537401", "question": "is a network connection device that can build tables that identify addresses on each network", "gold_answers": ["routing table", "a router"], "shots": {"0": {"k": 0, "answer": "Router", "latency_ms": 1038.0444526672363, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2346.597671508789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2175.032138824463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1360}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2644.6635723114014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2055}, "4": {"k": 4, "answer": "Router", "latency_ms": 932.5993061065674, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2780}, "5": {"k": 5, "answer": "Router", "latency_ms": 1390.4354572296143, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3459}, "6": {"k": 6, "answer": "Router", "latency_ms": 950.8237838745117, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4211}}}
{"qid": "8359496728452221378", "question": "when did the royal proclamation of 1763 end", "gold_answers": ["with the American Revolutionary War", "the American Revolutionary War", "1783"], "shots": {"0": {"k": 0, "answer": "1867", "latency_ms": 1428.1225204467773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2806.67781829834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "1768", "latency_ms": 1473.1206893920898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1387}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2115.459203720093, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2065}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1965.2478694915771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2750}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2299.8368740081787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3400}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2436.351537704468, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4009}}}
{"qid": "-2657014790962135860", "question": "the tenure of the office of the lokayukt of up", "gold_answers": ["8 years", "eight years"], "shots": {"0": {"k": 0, "answer": "8 years", "latency_ms": 1256.1464309692383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2106.1792373657227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "5 years", "latency_ms": 1519.2067623138428, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1820.265293121338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Eight years", "latency_ms": 1781.3899517059326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2620}, "5": {"k": 5, "answer": "Eight years", "latency_ms": 1290.5642986297607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3244}, "6": {"k": 6, "answer": "Eight years", "latency_ms": 1502.9687881469727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3922}}}
{"qid": "1827180983934640653", "question": "when did response to state of the union start", "gold_answers": ["1966", "in 1966"], "shots": {"0": {"k": 0, "answer": "1966", "latency_ms": 2080.9993743896484, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1938.8940334320068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2179.804563522339, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2093.3289527893066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1856}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2454.05650138855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2519}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2673.706531524658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3119}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2350.7611751556396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3752}}}
{"qid": "-8006002028754190814", "question": "who had the most governmental power under the articles of confederation", "gold_answers": ["the states"], "shots": {"0": {"k": 0, "answer": "State legislatures", "latency_ms": 1729.2790412902832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Each state", "latency_ms": 1833.6176872253418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "The states", "latency_ms": 1500.211477279663, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1388}, "3": {"k": 3, "answer": "The states", "latency_ms": 1021.5163230895996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2088}, "4": {"k": 4, "answer": "The states", "latency_ms": 1814.2459392547607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2811}, "5": {"k": 5, "answer": "The states", "latency_ms": 1749.3071556091309, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3483}, "6": {"k": 6, "answer": "The states", "latency_ms": 978.4235954284668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4174}}}
{"qid": "3406509904702130536", "question": "how many hospitals are there in the united states", "gold_answers": ["5,534 registered hospitals", "5,534"], "shots": {"0": {"k": 0, "answer": "5,764", "latency_ms": 1912.4760627746582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2743.32594871521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 749}, "2": {"k": 2, "answer": "5,534", "latency_ms": 2358.039617538452, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1474}, "3": {"k": 3, "answer": "5,534", "latency_ms": 1847.4762439727783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2154}, "4": {"k": 4, "answer": "5,534", "latency_ms": 1865.800380706787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2838}, "5": {"k": 5, "answer": "5,534", "latency_ms": 1806.6976070404053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3584}, "6": {"k": 6, "answer": "5,534", "latency_ms": 1788.060188293457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4298}}}
{"qid": "2435796066046322163", "question": "who donates a christmas tree to trafalgar square", "gold_answers": ["Oslo , Norway"], "shots": {"0": {"k": 0, "answer": "Norway", "latency_ms": 1730.635404586792, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The city of Oslo, Norway", "latency_ms": 3351.139545440674, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "The city of Oslo, Norway", "latency_ms": 3549.999713897705, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "The city of Oslo, Norway", "latency_ms": 2295.1202392578125, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1885}, "4": {"k": 4, "answer": "The city of Oslo, Norway", "latency_ms": 3970.6547260284424, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "The city of Oslo, Norway", "latency_ms": 2948.4026432037354, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3139}, "6": {"k": 6, "answer": "The city of Oslo, Norway", "latency_ms": 2665.8666133880615, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3783}}}
{"qid": "4926415052497472665", "question": "who starred in the movie on golden pond", "gold_answers": ["William Lanteau", "Dabney Coleman", "Henry Fonda", "Doug McKeon", "Jane Fonda", "Christopher Rydell", "Katharine Hepburn"], "shots": {"0": {"k": 0, "answer": "Henry Fonda and Katharine Hepburn", "latency_ms": 5179.747819900513, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Julie Andrews, Christopher Plummer, Glenne Headly", "latency_ms": 5558.679819107056, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Julie Andrews and Christopher Plummer", "latency_ms": 3625.1914501190186, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Henry Fonda, Katharine Hepburn and Jane Fonda", "latency_ms": 6771.736621856689, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Julie Andrews, Christopher Plummer, Katharine Hepburn, Henry Fonda, Jane Fonda", "latency_ms": 8327.501773834229, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2510}, "5": {"k": 5, "answer": "Julie Andrews, Christopher Plummer, Katharine Hepburn, Henry Fonda, Jane Fonda", "latency_ms": 7934.074401855469, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 4009.248733520508, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3737}}}
{"qid": "2142753216627246962", "question": "isdn uses b & d channels. what is d channel use for", "gold_answers": ["carries control and signaling information", "data", "control and signaling information"], "shots": {"0": {"k": 0, "answer": "Signaling", "latency_ms": 1564.5501613616943, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "control and signaling information", "latency_ms": 2427.0801544189453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "control and signaling information", "latency_ms": 2192.356824874878, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1365}, "3": {"k": 3, "answer": "control and signaling information", "latency_ms": 2843.6384201049805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2091}, "4": {"k": 4, "answer": "control and signaling information", "latency_ms": 2190.0265216827393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2696}, "5": {"k": 5, "answer": "control and signaling information", "latency_ms": 1903.3186435699463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3420}, "6": {"k": 6, "answer": "control and signaling information", "latency_ms": 2393.383026123047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4084}}}
{"qid": "1547060614805522730", "question": "what is the rate limiting enzyme of kreb's cycle", "gold_answers": ["Isocitrate dehydrogenase"], "shots": {"0": {"k": 0, "answer": "Isocitrate dehydrogenase", "latency_ms": 3616.7140007019043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2060.75382232666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2378.2474994659424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2397.03631401062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2353.2800674438477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2484}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2350.548028945923, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3130}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1871.6957569122314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3811}}}
{"qid": "8965198420725510475", "question": "when was the taj mahal built and completed", "gold_answers": ["1632 -- 53"], "shots": {"0": {"k": 0, "answer": "1632-1653", "latency_ms": 2763.291835784912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1196", "latency_ms": 1283.4832668304443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "1196", "latency_ms": 1811.9938373565674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1209}, "3": {"k": 3, "answer": "1643", "latency_ms": 1810.194969177246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "1643, 1653", "latency_ms": 3749.349594116211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2492}, "5": {"k": 5, "answer": "1632-1653", "latency_ms": 3074.4450092315674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3122}, "6": {"k": 6, "answer": "1632-1653", "latency_ms": 2996.9534873962402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3787}}}
{"qid": "-6292760252056275316", "question": "which supreme court judge has surved in international court of justice", "gold_answers": ["Dalveer Bhandari"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 1705.0797939300537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2951.2393474578857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3013.7431621551514, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2807.037115097046, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1868}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2442.315101623535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "Dalveer Bhandari", "latency_ms": 2784.849166870117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3133}, "6": {"k": 6, "answer": "Dalveer Bhandari", "latency_ms": 3253.281593322754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3695}}}
{"qid": "8361850218460994084", "question": "who is known as father of green revolution in india", "gold_answers": ["Mankombu Sambasivan Swaminathan"], "shots": {"0": {"k": 0, "answer": "M.S. Swaminathan", "latency_ms": 3108.367681503296, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Norman Borlaug", "latency_ms": 2388.908624649048, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 704}, "2": {"k": 2, "answer": "Norman Borlaug", "latency_ms": 1710.9229564666748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1438}, "3": {"k": 3, "answer": "Norman Borlaug", "latency_ms": 2721.9784259796143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2160}, "4": {"k": 4, "answer": "Norman Borlaug", "latency_ms": 2980.43155670166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2896}, "5": {"k": 5, "answer": "M. S. Swaminathan", "latency_ms": 4094.7341918945312, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3559}, "6": {"k": 6, "answer": "M. S. Swaminathan", "latency_ms": 2963.5934829711914, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4226}}}
{"qid": "-5690645328022945594", "question": "who sing say you won't let go", "gold_answers": ["James Arthur"], "shots": {"0": {"k": 0, "answer": "James Arthur", "latency_ms": 1049.1054058074951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2396.3377475738525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 565}, "2": {"k": 2, "answer": "James Arthur", "latency_ms": 1227.8943061828613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1151}, "3": {"k": 3, "answer": "James Arthur", "latency_ms": 1967.8809642791748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1743}, "4": {"k": 4, "answer": "James Arthur", "latency_ms": 1993.3784008026123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "James Arthur", "latency_ms": 1533.3905220031738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2969}, "6": {"k": 6, "answer": "James Arthur", "latency_ms": 1858.7563037872314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3592}}}
{"qid": "-4292736993227486718", "question": "who monitor the recovery of the location during a disaster", "gold_answers": ["management team"], "shots": {"0": {"k": 0, "answer": "Emergency Management Teams", "latency_ms": 2036.607027053833, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Key personnel", "latency_ms": 2031.0215950012207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 728}, "2": {"k": 2, "answer": "Emergency managers", "latency_ms": 1828.3298015594482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1433}, "3": {"k": 3, "answer": "Emergency managers", "latency_ms": 914.3967628479004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2145}, "4": {"k": 4, "answer": "Emergency managers", "latency_ms": 1224.982738494873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2814}, "5": {"k": 5, "answer": "Emergency managers", "latency_ms": 1497.831106185913, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3536}, "6": {"k": 6, "answer": "Emergency managers", "latency_ms": 975.1942157745361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4304}}}
{"qid": "-4741747756019727470", "question": "where does the synthesis of new dna from existing dna occurs", "gold_answers": ["origins of replication"], "shots": {"0": {"k": 0, "answer": "Replication fork", "latency_ms": 1385.3387832641602, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "origins of replication", "latency_ms": 2081.5439224243164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "origins of replication", "latency_ms": 2163.6431217193604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1305}, "3": {"k": 3, "answer": "In a cell", "latency_ms": 1513.3826732635498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2003}, "4": {"k": 4, "answer": "at specific locations, or origins of replication, in the genome", "latency_ms": 4509.178638458252, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "In a cell", "latency_ms": 2074.7129917144775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3312}, "6": {"k": 6, "answer": "In a cell", "latency_ms": 1333.5144519805908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3974}}}
{"qid": "4268853195499399258", "question": "who sings gimme shelter with mick jagger", "gold_answers": ["Merry Clayton"], "shots": {"0": {"k": 0, "answer": "Merry Clayton", "latency_ms": 1663.5007858276367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Merry Clayton", "latency_ms": 1510.209560394287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "Merry Clayton", "latency_ms": 2066.8654441833496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Merry Clayton", "latency_ms": 1566.6723251342773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1957}, "4": {"k": 4, "answer": "Merry Clayton", "latency_ms": 1867.192029953003, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2614}, "5": {"k": 5, "answer": "Merry Clayton", "latency_ms": 2678.314208984375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "Merry Clayton", "latency_ms": 2189.6653175354004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3850}}}
{"qid": "7172420463912356173", "question": "who does tony end up with on skins", "gold_answers": ["Michelle"], "shots": {"0": {"k": 0, "answer": "Michelle Richardson", "latency_ms": 1400.6454944610596, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1615.4186725616455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2101.330041885376, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1179}, "3": {"k": 3, "answer": "Michelle", "latency_ms": 902.3640155792236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1743}, "4": {"k": 4, "answer": "Michelle", "latency_ms": 1467.9405689239502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2341}, "5": {"k": 5, "answer": "Michelle", "latency_ms": 1621.5038299560547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2966}, "6": {"k": 6, "answer": "Michelle", "latency_ms": 713.7751579284668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3558}}}
{"qid": "-1400292288904470066", "question": "who sings sugar sugar you are my candy girl", "gold_answers": ["the Archies"], "shots": {"0": {"k": 0, "answer": "The Archies", "latency_ms": 1882.4446201324463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2572.964906692505, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 560}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1928.3533096313477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1181}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2421.384334564209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "The Archies", "latency_ms": 2056.0965538024902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2365}, "5": {"k": 5, "answer": "The Archies", "latency_ms": 2116.88494682312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2966}, "6": {"k": 6, "answer": "The Archies", "latency_ms": 1822.8082656860352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3583}}}
{"qid": "-1696720698220253139", "question": "who does tyler end up with in you get me", "gold_answers": ["Ali"], "shots": {"0": {"k": 0, "answer": "Ally", "latency_ms": 1129.7338008880615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Holly", "latency_ms": 1809.8702430725098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "Holly", "latency_ms": 1252.1040439605713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1130}, "3": {"k": 3, "answer": "Holly", "latency_ms": 824.8424530029297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1648}, "4": {"k": 4, "answer": "Holly", "latency_ms": 1539.7746562957764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2213}, "5": {"k": 5, "answer": "Holly", "latency_ms": 1194.3256855010986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2799}, "6": {"k": 6, "answer": "Holly", "latency_ms": 1550.5383014678955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3389}}}
{"qid": "-6797239474199900801", "question": "who won the gold for the men's figure skating", "gold_answers": ["Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Nathan Chen", "latency_ms": 1742.037296295166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Todd Eldredge", "latency_ms": 1935.4920387268066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 702}, "2": {"k": 2, "answer": "Todd Eldredge", "latency_ms": 2247.992515563965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1391}, "3": {"k": 3, "answer": "Todd Eldredge", "latency_ms": 2194.1099166870117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2069}, "4": {"k": 4, "answer": "Todd Eldredge", "latency_ms": 2431.567430496216, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2785}, "5": {"k": 5, "answer": "Todd Eldredge", "latency_ms": 1863.8763427734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3497}, "6": {"k": 6, "answer": "Todd Eldredge", "latency_ms": 2200.8590698242188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4143}}}
{"qid": "-7819569157752445011", "question": "when did the song holiday road come out", "gold_answers": ["1983", "June 24 , 1983"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 952.3677825927734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 24, 1983", "latency_ms": 3920.865058898926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 594}, "2": {"k": 2, "answer": "1983", "latency_ms": 1524.2063999176025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "1983", "latency_ms": 2022.2983360290527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1907}, "4": {"k": 4, "answer": "1983", "latency_ms": 1305.4533004760742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "1983", "latency_ms": 989.5451068878174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3200}, "6": {"k": 6, "answer": "1983", "latency_ms": 2143.674850463867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3775}}}
{"qid": "-8839043176903626071", "question": "when does the mlb season start and finish", "gold_answers": ["October 31 , 2018", "March 29"], "shots": {"0": {"k": 0, "answer": "Late March to Late October", "latency_ms": 2985.764503479004, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 29 to October 1", "latency_ms": 2391.664981842041, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "March 29 to October 1", "latency_ms": 3872.9493618011475, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1260}, "3": {"k": 3, "answer": "March 29 to October 1", "latency_ms": 2900.4735946655273, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1868}, "4": {"k": 4, "answer": "March 29 - October 1", "latency_ms": 3324.251651763916, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2487}, "5": {"k": 5, "answer": "March 29 - October 1", "latency_ms": 3474.0498065948486, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3081}, "6": {"k": 6, "answer": "March 29 - October 1", "latency_ms": 3377.2990703582764, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3724}}}
{"qid": "6356531089429364942", "question": "when did scotland beat england in six nations", "gold_answers": ["8 March 2008", "25 February 2006", "24 February 2018", "2 April 2000"], "shots": {"0": {"k": 0, "answer": "8 February 2020", "latency_ms": 2209.9013328552246, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2598.165988922119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2394.817352294922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "1938, (and another year not specified in the context)", "latency_ms": 6003.777980804443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1973}, "4": {"k": 4, "answer": "1984, 1994 not mentioned, only 1938", "latency_ms": 5782.902240753174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "Since 1938, only in 1994 is not mentioned, but  [3] \"Scotland national rugby union team\": \"a disappointment; losing their first three Five Nations matches. However, the tournament ended on a high when Scotland recorded only their second victory over England at Twickenham since 1938.\"", "latency_ms": 25323.524236679077, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3350}, "6": {"k": 6, "answer": "Since 1938, only in [3]", "latency_ms": 4759.011507034302, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3982}}}
{"qid": "-3382335563294993978", "question": "when did the rational dress society begin to work", "gold_answers": ["1881"], "shots": {"0": {"k": 0, "answer": "1881", "latency_ms": 1835.585594177246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1881", "latency_ms": 762.563943862915, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "1881", "latency_ms": 1632.4338912963867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "1881", "latency_ms": 1620.6741333007812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1976}, "4": {"k": 4, "answer": "1881", "latency_ms": 1841.5415287017822, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2609}, "5": {"k": 5, "answer": "1881", "latency_ms": 1319.988489151001, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3236}, "6": {"k": 6, "answer": "1881", "latency_ms": 1497.5662231445312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3849}}}
{"qid": "-5630827734073464379", "question": "why is the indian ocean the warmest in the world", "gold_answers": ["human induced greenhouse warming"], "shots": {"0": {"k": 0, "answer": "Thermohaline circulation.", "latency_ms": 4311.498403549194, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "human induced greenhouse warming", "latency_ms": 2694.3161487579346, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2420.0446605682373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1337}, "3": {"k": 3, "answer": "Long-term ocean temperature records show a rapid, continuous warming", "latency_ms": 4709.840774536133, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 1996}, "4": {"k": 4, "answer": "Long-term ocean temperature records show a rapid, continuous warming", "latency_ms": 5577.470064163208, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 2580}, "5": {"k": 5, "answer": "Long-term ocean temperature records show a rapid, continuous warming", "latency_ms": 4056.3814640045166, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 3238}, "6": {"k": 6, "answer": "Human induced greenhouse warming", "latency_ms": 2874.89914894104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3834}}}
{"qid": "-3544151584263258729", "question": "where was the film manchester by the sea filmed", "gold_answers": ["Middleton", "Essex", "Gloucester", "Beverly", "Swampscott", "Lynn", "Manchester", "Salem", "Tewksbury"], "shots": {"0": {"k": 0, "answer": "Gloucester, Massachusetts", "latency_ms": 3263.170003890991, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2138.528823852539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2702.2368907928467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1353}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2383.0487728118896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1999}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1897.2995281219482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2677}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2626.41978263855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3272}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2659.724712371826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3959}}}
{"qid": "-5077733789764986167", "question": "consist of the sum of the fixed and variable costs for any given level of production", "gold_answers": ["total cost ( TC )"], "shots": {"0": {"k": 0, "answer": "Total Costs", "latency_ms": 1553.0061721801758, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Total cost", "latency_ms": 2251.6918182373047, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "Total cost", "latency_ms": 2029.6189785003662, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Total cost", "latency_ms": 1523.101806640625, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Total cost", "latency_ms": 1702.2459506988525, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "Total cost", "latency_ms": 1526.0210037231445, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3107}, "6": {"k": 6, "answer": "Total cost", "latency_ms": 1307.3256015777588, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3799}}}
{"qid": "4892187805447493570", "question": "where was thomas and the magic railroad filmed", "gold_answers": ["Toronto , Ontario , Canada", "Isle of Man", "the Isle of Man"], "shots": {"0": {"k": 0, "answer": "Strasburg Rail Road, Pennsylvania, and Pinewood Studios, England.", "latency_ms": 6404.008626937866, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1691.1802291870117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1795.8195209503174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1431.7693710327148, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Strasburg Rail Road", "latency_ms": 1943.1109428405762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "Strasburg Rail Road", "latency_ms": 2166.426658630371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3172}, "6": {"k": 6, "answer": "Strasburg Railroad", "latency_ms": 2365.4446601867676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-7094533216301278566", "question": "who has access to the presidential daily briefing", "gold_answers": ["Secretaries of State", "the President", "Defense", "National Security Advisor"], "shots": {"0": {"k": 0, "answer": "The President, Vice President, and select senior officials.", "latency_ms": 3681.2353134155273, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President and top-level US officials", "latency_ms": 2599.4956493377686, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "The President of the United States and a small number of top-level US officials.", "latency_ms": 6069.5154666900635, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 1419}, "3": {"k": 3, "answer": "The President of the United States and top-level US officials approved by the President", "latency_ms": 5552.012205123901, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 2061}, "4": {"k": 4, "answer": "The President of the United States and a small number of top-level US officials.", "latency_ms": 5473.650217056274, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 2699}, "5": {"k": 5, "answer": "The President of the United States and a small number of top-level US officials approved by the President.", "latency_ms": 7354.79998588562, "em": 0.0, "f1": 0.13333333333333333, "containment": 1.0, "context_chars": 3336}, "6": {"k": 6, "answer": "The President of the United States and a small number of top-level US officials approved by the President.", "latency_ms": 6218.068599700928, "em": 0.0, "f1": 0.13333333333333333, "containment": 1.0, "context_chars": 4011}}}
{"qid": "-243139310037543674", "question": "what tool is available from microsoft as an alternative to the usmt for smaller migrations", "gold_answers": ["Windows Easy Transfer"], "shots": {"0": {"k": 0, "answer": "USMT's smaller alternative is: Easy Transfer.", "latency_ms": 3251.8398761749268, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Files", "latency_ms": 1770.1811790466309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Windows Easy Transfer", "latency_ms": 1284.0111255645752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Windows Easy Transfer", "latency_ms": 1878.718376159668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Windows Easy Transfer", "latency_ms": 1133.5227489471436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2561}, "5": {"k": 5, "answer": "Windows Easy Transfer", "latency_ms": 2003.2765865325928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3253}, "6": {"k": 6, "answer": "Windows Easy Transfer", "latency_ms": 1929.429292678833, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3892}}}
{"qid": "7079282152145474767", "question": "who appoints the chief election commissioner of india", "gold_answers": ["the president", "President of India"], "shots": {"0": {"k": 0, "answer": "The President of India.", "latency_ms": 2701.9593715667725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President", "latency_ms": 1018.4266567230225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "The President", "latency_ms": 1758.5902214050293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1437}, "3": {"k": 3, "answer": "The President", "latency_ms": 1552.3078441619873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2202}, "4": {"k": 4, "answer": "The President", "latency_ms": 1307.5597286224365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2874}, "5": {"k": 5, "answer": "The President", "latency_ms": 1017.6551342010498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3567}, "6": {"k": 6, "answer": "The President", "latency_ms": 1461.3726139068604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4272}}}
{"qid": "6303430169473424975", "question": "glycogen and amylopectin are long chains of which simple sugar(s)", "gold_answers": ["glucose"], "shots": {"0": {"k": 0, "answer": "Glucose", "latency_ms": 2035.797119140625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Glucose", "latency_ms": 1222.6464748382568, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "Glucose", "latency_ms": 1502.9091835021973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Glucose", "latency_ms": 1082.374095916748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Glucose", "latency_ms": 1743.483066558838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2630}, "5": {"k": 5, "answer": "Glucose", "latency_ms": 992.2776222229004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3262}, "6": {"k": 6, "answer": "Glucose", "latency_ms": 1046.2968349456787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3969}}}
{"qid": "-3240666523350424161", "question": "who was the editor of the journal jugantor published in the time of swadeshi movement", "gold_answers": ["Bhupendranath Dutt"], "shots": {"0": {"k": 0, "answer": "Barindra Kumar Ghosh", "latency_ms": 1955.676794052124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Barindra Kumar Ghosh", "latency_ms": 3284.802198410034, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "Barindra Kumar Ghosh", "latency_ms": 3025.49409866333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Barindra Kumar Ghosh", "latency_ms": 3399.7673988342285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2005}, "4": {"k": 4, "answer": "Barindra Kumar Ghosh", "latency_ms": 2625.464677810669, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2661}, "5": {"k": 5, "answer": "Barindra Kumar Ghosh", "latency_ms": 2329.4525146484375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3352}, "6": {"k": 6, "answer": "Barindra Kumar Ghosh", "latency_ms": 2028.1956195831299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3982}}}
{"qid": "1321443496772706078", "question": "when did indoor toilets become common in america", "gold_answers": ["After World War I"], "shots": {"0": {"k": 0, "answer": "Late 19th century.", "latency_ms": 1844.8412418365479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1890s", "latency_ms": 1819.136142730713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "1890s", "latency_ms": 1262.5494003295898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "1890s", "latency_ms": 1327.5642395019531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "1890s", "latency_ms": 1412.987470626831, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2583}, "5": {"k": 5, "answer": "1890s", "latency_ms": 1855.6673526763916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "1890s", "latency_ms": 2294.8291301727295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3830}}}
{"qid": "6019244948248861067", "question": "who wrote were going on a bear hunt", "gold_answers": ["Michael Rosen"], "shots": {"0": {"k": 0, "answer": "Michael Rosen and Helen Oxenbury", "latency_ms": 2725.261926651001, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Rosen", "latency_ms": 1974.3452072143555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "Michael Rosen", "latency_ms": 1826.1878490447998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "Michael Rosen", "latency_ms": 1863.9070987701416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1802}, "4": {"k": 4, "answer": "Michael Rosen", "latency_ms": 1910.6743335723877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2407}, "5": {"k": 5, "answer": "Michael Rosen", "latency_ms": 1276.350498199463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2948}, "6": {"k": 6, "answer": "Michael Rosen", "latency_ms": 1338.7360572814941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3550}}}
{"qid": "8753987902863757141", "question": "what is the revolution period of venus in earth years", "gold_answers": ["0.615 198 yr", "224.7 Earth days"], "shots": {"0": {"k": 0, "answer": "0.61519726", "latency_ms": 1726.9744873046875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1276.4556407928467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "0.615 Earth years", "latency_ms": 3074.5980739593506, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "0.62 years", "latency_ms": 1677.022933959961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "0.62 years", "latency_ms": 1643.1317329406738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2453}, "5": {"k": 5, "answer": "0.615 Earth years", "latency_ms": 2097.0098972320557, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3045}, "6": {"k": 6, "answer": "0.615 Earth years", "latency_ms": 2196.780204772949, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3637}}}
{"qid": "-5904934687784134086", "question": "who has the power to approve or veto legislation constitution", "gold_answers": ["the President"], "shots": {"0": {"k": 0, "answer": "The President", "latency_ms": 1507.5526237487793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President of the United States", "latency_ms": 3632.862329483032, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "The President of the United States", "latency_ms": 3357.8221797943115, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1348}, "3": {"k": 3, "answer": "The President of the United States", "latency_ms": 2941.9031143188477, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2019}, "4": {"k": 4, "answer": "The President of the United States", "latency_ms": 2713.912010192871, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2691}, "5": {"k": 5, "answer": "The President of the United States", "latency_ms": 3307.8083992004395, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3370}, "6": {"k": 6, "answer": "The President of the United States", "latency_ms": 3430.15193939209, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3994}}}
{"qid": "-1910743846708408775", "question": "when was the taming ofthe shrew first performed", "gold_answers": ["prior to June 1592"], "shots": {"0": {"k": 0, "answer": "1590-1594", "latency_ms": 2916.959285736084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2077.6634216308594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 701}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2493.7691688537598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1353}, "3": {"k": 3, "answer": "1768", "latency_ms": 2089.1497135162354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2022}, "4": {"k": 4, "answer": "15901591", "latency_ms": 3014.8375034332275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "15901591", "latency_ms": 2576.504945755005, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2397.3679542541504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3940}}}
{"qid": "6521877788261380307", "question": "who is the first prime minister of france", "gold_answers": ["Michel Debr"], "shots": {"0": {"k": 0, "answer": "Adolphe Thiers", "latency_ms": 2454.3590545654297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2332.5705528259277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2800.4467487335205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1871.6847896575928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2818.824291229248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2627}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1900.3279209136963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3014.345407485962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3944}}}
{"qid": "-3375621376413612480", "question": "list of strict nature reserve in the philippines", "gold_answers": ["Lake Malimanga", "Palawan", "Calavite and FB Harrison", "Olango Island", "Calauit Safari Park", "Lake Buluan"], "shots": {"0": {"k": 0, "answer": "Verde Island Passage, Mayon Volcano, El Nido Managed Resource Protected Area.", "latency_ms": 6473.658561706543, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2441.2992000579834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2238.6233806610107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1430.0682544708252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2476.759433746338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2609}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2296.729564666748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3292}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2155.09295463562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4066}}}
{"qid": "-7848107192827858958", "question": "where do the events in the story take place geographically", "gold_answers": ["Persia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2411.616563796997, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3144.0560817718506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Setting", "latency_ms": 2241.6329383850098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "Setting", "latency_ms": 879.3253898620605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "Setting", "latency_ms": 1684.6299171447754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2421}, "5": {"k": 5, "answer": "the open countryside", "latency_ms": 2309.49068069458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3104}, "6": {"k": 6, "answer": "Poland", "latency_ms": 1730.2892208099365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3756}}}
{"qid": "-5123704261908217758", "question": "how and why were serial novels a phenomenon in the nineteenth century", "gold_answers": ["improved economics of distribution", "the rise of literacy", "technological advances in printing"], "shots": {"0": {"k": 0, "answer": "Penny dreadfuls and Dickens.", "latency_ms": 3089.688301086426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Broad audiences and magazine publication.", "latency_ms": 3761.5132331848145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "Broad audiences and growth of following", "latency_ms": 3963.780164718628, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Broad audiences and growing following.", "latency_ms": 3030.0981998443604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Broad audiences and growing literacy rates.", "latency_ms": 3649.4686603546143, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "Broad audiences and growing following", "latency_ms": 2387.805938720703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Broad audiences and growing following", "latency_ms": 3334.7275257110596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3853}}}
{"qid": "8893432128322519771", "question": "who eliminated costa rica in world cup 2014", "gold_answers": ["Netherlands"], "shots": {"0": {"k": 0, "answer": "Netherlands", "latency_ms": 2090.2302265167236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1643.3289051055908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2372.1961975097656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2463.158369064331, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1784.3306064605713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2841.9766426086426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2388.3676528930664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3768}}}
{"qid": "-1356405650810931451", "question": "how many countries touches the land boundary of india", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "6", "latency_ms": 468.8427448272705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "6", "latency_ms": 1705.176591873169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "6", "latency_ms": 1550.055742263794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1305}, "3": {"k": 3, "answer": "6", "latency_ms": 721.4267253875732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1887}, "4": {"k": 4, "answer": "6", "latency_ms": 1481.1334609985352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "6", "latency_ms": 918.2546138763428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3168}, "6": {"k": 6, "answer": "6", "latency_ms": 937.5333786010742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3793}}}
{"qid": "6447777231012695504", "question": "who was the 11th prime minister of canada", "gold_answers": ["R.B. Bennett", "Arthur Meighen"], "shots": {"0": {"k": 0, "answer": "William Lyon Mackenzie King", "latency_ms": 1755.5780410766602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2702.1777629852295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2193.0038928985596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1332}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2681.7283630371094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2006}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2667.6290035247803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Wilfrid Laurier", "latency_ms": 3050.9793758392334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3344}, "6": {"k": 6, "answer": "Wilfrid Laurier", "latency_ms": 2629.296064376831, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3975}}}
{"qid": "-5935683210985272192", "question": "when did the steel mills closed in youngstown ohio", "gold_answers": ["September 19 , 1977"], "shots": {"0": {"k": 0, "answer": "1977", "latency_ms": 1263.5912895202637, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 19, 1977", "latency_ms": 4627.56872177124, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "1977", "latency_ms": 995.2771663665771, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "September 19, 1977", "latency_ms": 3760.9338760375977, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1958}, "4": {"k": 4, "answer": "September 19, 1977", "latency_ms": 3298.856019973755, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "September 19, 1977", "latency_ms": 3611.518383026123, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "1977", "latency_ms": 1273.5140323638916, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3947}}}
{"qid": "1834961239491311230", "question": "who owns and operates the panama canal today", "gold_answers": ["Panama Canal Authority", "Panama", "Panamanian government"], "shots": {"0": {"k": 0, "answer": "The Panama Canal Authority", "latency_ms": 2686.3434314727783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kansas City Southern and Mi-Jack Products", "latency_ms": 4547.39236831665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "Panama Canal Authority", "latency_ms": 1965.74068069458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Panama Canal Authority", "latency_ms": 2964.6239280700684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1956}, "4": {"k": 4, "answer": "Panama Canal Authority", "latency_ms": 2643.2859897613525, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Panama Canal Authority", "latency_ms": 2919.6605682373047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3277}, "6": {"k": 6, "answer": "Panamanian government", "latency_ms": 3198.1072425842285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3949}}}
{"qid": "-535648230475805474", "question": "where is a simple gear train used in real life", "gold_answers": ["Automobile drivetrains"], "shots": {"0": {"k": 0, "answer": "Bicycle gears", "latency_ms": 1068.2415962219238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2402.0094871520996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2434.680461883545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1224}, "3": {"k": 3, "answer": "Automobile manual transmission", "latency_ms": 2424.0260124206543, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1842}, "4": {"k": 4, "answer": "Automobile manual transmission", "latency_ms": 2365.6041622161865, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Automobile manual transmission", "latency_ms": 2665.0166511535645, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3017}, "6": {"k": 6, "answer": "Automobile manual transmission", "latency_ms": 2397.2644805908203, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3672}}}
{"qid": "8911390210346559626", "question": "who plays the dad in malcom in the middle", "gold_answers": ["Bryan Cranston"], "shots": {"0": {"k": 0, "answer": "Bryan Cranston", "latency_ms": 2212.573766708374, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2398.172378540039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2590.991735458374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2248.5125064849854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1844}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1832.7524662017822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2432}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2430.429458618164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3044}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2693.5925483703613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3645}}}
{"qid": "-8336776482564898273", "question": "who has won the most world series in baseball", "gold_answers": ["the New York Yankees", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "New York Yankees", "latency_ms": 2096.0733890533447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Yankees", "latency_ms": 2013.8795375823975, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 570}, "2": {"k": 2, "answer": "New York Yankees", "latency_ms": 2670.943021774292, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1194}, "3": {"k": 3, "answer": "New York Yankees", "latency_ms": 2110.3739738464355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1811}, "4": {"k": 4, "answer": "New York Yankees", "latency_ms": 2074.453830718994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2418}, "5": {"k": 5, "answer": "New York Yankees", "latency_ms": 1987.9331588745117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2997}, "6": {"k": 6, "answer": "New York Yankees", "latency_ms": 2542.975902557373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3603}}}
{"qid": "-8742089114148260796", "question": "where are the winter olympic games being played", "gold_answers": ["Beijing"], "shots": {"0": {"k": 0, "answer": "Milan-Cortina", "latency_ms": 2944.446563720703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chamonix, France", "latency_ms": 3203.0551433563232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "Chamonix, France.", "latency_ms": 3008.4402561187744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "Chamonix, France.", "latency_ms": 3766.2603855133057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Chamonix, France.", "latency_ms": 3804.7728538513184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "Chamonix, France.", "latency_ms": 3584.9883556365967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3156}, "6": {"k": 6, "answer": "Pyeongchang", "latency_ms": 2401.962995529175, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3843}}}
{"qid": "3864930130255054488", "question": "who made the song falling in love with you", "gold_answers": ["Hugo Peretti", "Elvis Presley", "George David Weiss", "Luigi Creatore"], "shots": {"0": {"k": 0, "answer": "Lauren Christy.", "latency_ms": 2237.2238636016846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Randy Owen, Teddy Gentry and Greg Fowler", "latency_ms": 3865.630865097046, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Randy Owen, Teddy Gentry and Greg Fowler", "latency_ms": 4209.254264831543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Randy Owen, Teddy Gentry and Greg Fowler", "latency_ms": 4203.495979309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "Randy Owen, Teddy Gentry and Greg Fowler", "latency_ms": 5107.277393341064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2400}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1668.595314025879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2958}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2133.8067054748535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3565}}}
{"qid": "8076743617384207713", "question": "where did saudi crown prince go to college", "gold_answers": ["King Saud University"], "shots": {"0": {"k": 0, "answer": "King Saud University", "latency_ms": 1842.9412841796875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2118.5503005981445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 686}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2667.7141189575195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1358}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2123.5058307647705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2019}, "4": {"k": 4, "answer": "Princeton University", "latency_ms": 2129.4636726379395, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2690}, "5": {"k": 5, "answer": "Princeton University", "latency_ms": 1539.9715900421143, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3310}, "6": {"k": 6, "answer": "Princeton University", "latency_ms": 1788.147211074829, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3997}}}
{"qid": "1735766792677422630", "question": "who did the singing in into the woods", "gold_answers": ["the cast", "the cast members"], "shots": {"0": {"k": 0, "answer": "Meryl Streep", "latency_ms": 2626.6956329345703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "All join in", "latency_ms": 2679.5654296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "All join in", "latency_ms": 1606.3039302825928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "All join in", "latency_ms": 1852.7235984802246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1941}, "4": {"k": 4, "answer": "All join in", "latency_ms": 2115.9210205078125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2586}, "5": {"k": 5, "answer": "the ensemble cast", "latency_ms": 1556.8490028381348, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "the ensemble cast", "latency_ms": 1551.408290863037, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3912}}}
{"qid": "5711801828691961426", "question": "who was the viceroy when the simon commission visited india", "gold_answers": ["Lord Irwin"], "shots": {"0": {"k": 0, "answer": "Lord Irwin", "latency_ms": 1416.9855117797852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2070.1632499694824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2388.5481357574463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2186.98787689209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2454.463481903076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2623}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2844.4113731384277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3285}, "6": {"k": 6, "answer": "Lord Irwin", "latency_ms": 2355.67569732666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3936}}}
{"qid": "9001143341771379731", "question": "who in germany signed the treaty of versailles", "gold_answers": ["colonial minister Johannes Bell", "Foreign minister Hermann Mller", "Gustav Bauer"], "shots": {"0": {"k": 0, "answer": "Ulrich Graf von Brockdorff-Rantzau", "latency_ms": 3929.675579071045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2137.362480163574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2624.380111694336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "Germany's new political leadership", "latency_ms": 2361.189603805542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "Germany's new political leadership", "latency_ms": 2457.7372074127197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2485}, "5": {"k": 5, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 3370.3322410583496, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3132}, "6": {"k": 6, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 4146.269083023071, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3794}}}
{"qid": "-4619585332904698754", "question": "who holds the record for most platinum albums", "gold_answers": ["The Beatles", "AC / DC", "Elvis Presley"], "shots": {"0": {"k": 0, "answer": "The Beatles", "latency_ms": 985.7525825500488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elvis Presley", "latency_ms": 2210.576295852661, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Elvis Presley", "latency_ms": 1673.6886501312256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Elvis Presley", "latency_ms": 2199.7909545898438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Elvis Presley", "latency_ms": 2689.314603805542, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Elvis Presley", "latency_ms": 1335.0796699523926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Elvis Presley", "latency_ms": 2624.5861053466797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3859}}}
{"qid": "-720512252272678238", "question": "when did the movie the post begin filming", "gold_answers": ["May 30 , 2017", "May 2017"], "shots": {"0": {"k": 0, "answer": "May 30, 2016", "latency_ms": 2212.44215965271, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2169.22926902771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2422.070264816284, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2714.6878242492676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2256.437301635742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1899.172306060791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1839.1377925872803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3808}}}
{"qid": "-3371798557886238687", "question": "who starred in an officer and a gentleman", "gold_answers": ["Louis Gossett Jr .", "David Keith", "Louis Gossett Jr.", "Richard Gere", "Debra Winger", "Phillip J. Salmon"], "shots": {"0": {"k": 0, "answer": "Richard Gere", "latency_ms": 1850.0785827636719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1817.9330825805664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 5183.836936950684, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 5945.41597366333, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1851}, "4": {"k": 4, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 5857.607126235962, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 5834.115743637085, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3182}, "6": {"k": 6, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 6101.800918579102, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3771}}}
