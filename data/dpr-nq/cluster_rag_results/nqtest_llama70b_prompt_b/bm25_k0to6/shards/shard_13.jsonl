{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 2626.171350479126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2976.5679836273193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2951.4060020446777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1981.9788932800293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2714.627265930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2602}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3278.515338897705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3243}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2992.236375808716, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3875}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 2019.7124481201172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 2616.9064044952393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 2740.7219409942627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 2405.8728218078613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 2837.332010269165, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2533}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 2878.7176609039307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 2364.812135696411, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3853}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwestern United States and Mexico", "latency_ms": 3169.8620319366455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4877.43878364563, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "arid lowland or mountainous shrubland", "latency_ms": 5315.312623977661, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1310}, "3": {"k": 3, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 5080.200672149658, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2042}, "4": {"k": 4, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 5700.756788253784, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 5154.933214187622, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3326}, "6": {"k": 6, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 5448.643207550049, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3971}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 4159.096717834473, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Karl Seitz", "latency_ms": 2671.6206073760986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Karl Seitz", "latency_ms": 2927.0057678222656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1382}, "3": {"k": 3, "answer": "Karl Seitz", "latency_ms": 2982.1226596832275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2096}, "4": {"k": 4, "answer": "Karl Seitz", "latency_ms": 2975.903272628784, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2753}, "5": {"k": 5, "answer": "Karl Seitz", "latency_ms": 3777.836561203003, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3439}, "6": {"k": 6, "answer": "Karl Seitz", "latency_ms": 2679.4121265411377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4065}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2696.8069076538086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "10pm (Eastern)", "latency_ms": 2367.5827980041504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "10pm (Eastern)", "latency_ms": 2501.4472007751465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "10pm (Eastern)", "latency_ms": 3273.422956466675, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "10pm (Eastern)", "latency_ms": 4078.486919403076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "10pm (Eastern)", "latency_ms": 2726.8874645233154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "10pm (Eastern)", "latency_ms": 2528.5234451293945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3889}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "June 22, 2001", "latency_ms": 4079.0460109710693, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2654.5369625091553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 699}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2607.583999633789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1331}, "3": {"k": 3, "answer": "Not in the context.", "latency_ms": 2714.820623397827, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "2001", "latency_ms": 1736.9487285614014, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2593}, "5": {"k": 5, "answer": "2001", "latency_ms": 1491.2340641021729, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3212}, "6": {"k": 6, "answer": "2001", "latency_ms": 1564.1663074493408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3891}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "March 1, 2018", "latency_ms": 2622.375249862671, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 4843.7559604644775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2847.255229949951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1378}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 3498.418092727661, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2043}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2122.962236404419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2682}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2853.773593902588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3345}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2217.4317836761475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3948}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3.", "latency_ms": 2166.882276535034, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2627.3999214172363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Hell-O", "latency_ms": 1754.9383640289307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "May 19, 2009", "latency_ms": 4393.069505691528, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2007}, "4": {"k": 4, "answer": "May 19, 2009", "latency_ms": 3603.2803058624268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2624}, "5": {"k": 5, "answer": "In \"Hell-O\"", "latency_ms": 2789.433240890503, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3187}, "6": {"k": 6, "answer": "In \"Hell-O\"", "latency_ms": 3002.3999214172363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3794}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1463.6061191558838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1944.6728229522705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2431.6513538360596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2190.519332885742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3206.078052520752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2608.8955402374268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2435.0461959838867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3926}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 1094.8448181152344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Havana harbor", "latency_ms": 2685.8675479888916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "Havana harbor", "latency_ms": 1898.9286422729492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Havana harbor", "latency_ms": 2594.0074920654297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Havana harbor", "latency_ms": 2345.8969593048096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2640}, "5": {"k": 5, "answer": "Havana harbor", "latency_ms": 2674.905300140381, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3214}, "6": {"k": 6, "answer": "Havana harbor", "latency_ms": 1388.1208896636963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3838}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 2092.641830444336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2461.663246154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1921.2703704833984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "No specific god mentioned", "latency_ms": 2272.0229625701904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "Lord Vasupujya", "latency_ms": 3329.1547298431396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2502}, "5": {"k": 5, "answer": "Lord Vasupujya", "latency_ms": 3518.059492111206, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Lord Vasupujya", "latency_ms": 3455.5306434631348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3869}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama.", "latency_ms": 4029.8142433166504, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Honduras and Nicaragua", "latency_ms": 3572.521448135376, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 696}, "2": {"k": 2, "answer": "Honduras", "latency_ms": 1813.401222229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Honduras, Nicaragua", "latency_ms": 2809.0877532958984, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1912}, "4": {"k": 4, "answer": "Honduras, Nicaragua, Costa Rica", "latency_ms": 3606.3902378082275, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2478}, "5": {"k": 5, "answer": "Honduras, Nicaragua, Costa Rica, Panama", "latency_ms": 4310.447692871094, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3110}, "6": {"k": 6, "answer": "Honduras, Nicaragua, Costa Rica, Panama", "latency_ms": 4656.963348388672, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3764}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence.", "latency_ms": 1580.1475048065186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 2243.6678409576416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "Complex sentence", "latency_ms": 1536.0310077667236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Complex sentence", "latency_ms": 2320.213556289673, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2008}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 1319.3864822387695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2672}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 1795.3035831451416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3356}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 1812.6599788665771, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4062}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and capitalism.", "latency_ms": 2512.6142501831055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 4540.204763412476, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "what builds nations' wealth", "latency_ms": 3102.3385524749756, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1337}, "3": {"k": 3, "answer": "the nature and causes of the wealth of nations", "latency_ms": 3436.2545013427734, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1989}, "4": {"k": 4, "answer": "The Wealth of Nations", "latency_ms": 2677.340507507324, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2670}, "5": {"k": 5, "answer": "The Wealth of Nations", "latency_ms": 1644.2887783050537, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3356}, "6": {"k": 6, "answer": "The Wealth of Nations", "latency_ms": 2117.729425430298, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3972}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 4431.407928466797, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2244.9638843536377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2809.189796447754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2380.5408477783203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2171.4110374450684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 3341.191291809082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3131}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 4153.69176864624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3757}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere.", "latency_ms": 3129.3716430664062, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Western Australia", "latency_ms": 1472.2330570220947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "Western Australia, Tasmania", "latency_ms": 2253.9572715759277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "South-west corner of Western Australia", "latency_ms": 2862.8737926483154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1998}, "4": {"k": 4, "answer": "South-west corner of Western Australia", "latency_ms": 3262.1097564697266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2721}, "5": {"k": 5, "answer": "South-west corner", "latency_ms": 2370.7499504089355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3450}, "6": {"k": 6, "answer": "South-west corner of Western Australia", "latency_ms": 2819.079875946045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4184}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Mara Jade", "latency_ms": 1808.8719844818115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3344.6168899536133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 534}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2846.8525409698486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1121}, "3": {"k": 3, "answer": "Mara", "latency_ms": 1742.4004077911377, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1751}, "4": {"k": 4, "answer": "Mara", "latency_ms": 1545.0952053070068, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2322}, "5": {"k": 5, "answer": "Mara", "latency_ms": 2073.70662689209, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2967}, "6": {"k": 6, "answer": "Mara", "latency_ms": 2342.4580097198486, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3558}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 1066.9889450073242, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Barry Cryer", "latency_ms": 2700.676202774048, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 548}, "2": {"k": 2, "answer": "Barry Cryer", "latency_ms": 2373.049259185791, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1098}, "3": {"k": 3, "answer": "Barry Cryer", "latency_ms": 3114.4659519195557, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1711}, "4": {"k": 4, "answer": "Barry Cryer", "latency_ms": 2913.543939590454, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2327}, "5": {"k": 5, "answer": "Barry Cryer", "latency_ms": 2745.8159923553467, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2920}, "6": {"k": 6, "answer": "Barry Cryer", "latency_ms": 2464.4038677215576, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3568}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 2577.9120922088623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mitochondrial", "latency_ms": 2382.09867477417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 728}, "2": {"k": 2, "answer": "Chloroplast", "latency_ms": 1857.4986457824707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1438}, "3": {"k": 3, "answer": "Chloroplast", "latency_ms": 1805.4673671722412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2097}, "4": {"k": 4, "answer": "Chloroplast", "latency_ms": 2602.2002696990967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2776}, "5": {"k": 5, "answer": "Chloroplast and mitochondria", "latency_ms": 4078.054904937744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3452}, "6": {"k": 6, "answer": "Chloroplast and mitochondria", "latency_ms": 3184.248924255371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4245}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Intrusion Detection.", "latency_ms": 5765.416860580444, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2419.161558151245, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3194.9944496154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2782.7322483062744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2066}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2927.600622177124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2775}, "5": {"k": 5, "answer": "FLAIM, CANINE, Scrub-PA, Digital Evidence Investigator, Triage-G2", "latency_ms": 7463.398218154907, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3489}, "6": {"k": 6, "answer": "FLAIM, CANINE, Scrub-PA, Digital Evidence Investigator, Triage-G2", "latency_ms": 8800.196647644043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4232}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 2918.938159942627, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1668.1537628173828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1870.906114578247, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2927.7963638305664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2370.838403701782, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3198.497533798218, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3067}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2834.047555923462, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3666}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 1850.5783081054688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Five to seven years", "latency_ms": 3166.893243789673, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "Five to seven years", "latency_ms": 1719.0096378326416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "Five to seven years", "latency_ms": 2319.582462310791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1703}, "4": {"k": 4, "answer": "Two years old", "latency_ms": 1624.9885559082031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2352}, "5": {"k": 5, "answer": "Two years old", "latency_ms": 1622.0614910125732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3015}, "6": {"k": 6, "answer": "five to seven years", "latency_ms": 2335.1457118988037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3700}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 1473.0734825134277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 1515.8195495605469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "3", "latency_ms": 1668.6534881591797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "3", "latency_ms": 1469.9807167053223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "3", "latency_ms": 951.0116577148438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": "3", "latency_ms": 1044.4753170013428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "3", "latency_ms": 1251.9803047180176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3891}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 6083.75358581543, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2873.4164237976074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2130.493402481079, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1331}, "3": {"k": 3, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 9356.945753097534, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 8708.511352539062, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 2604}, "5": {"k": 5, "answer": "Frodo Baggins, Samwise Gamgee, Peregrin Took, Meriadoc Brandybuck", "latency_ms": 8840.262174606323, "em": 0.0, "f1": 0.3076923076923077, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "Elijah Wood", "latency_ms": 2139.594554901123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3863}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party.", "latency_ms": 1977.4351119995117, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume", "latency_ms": 1759.3488693237305, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "Costume.", "latency_ms": 2382.0786476135254, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Costume or disguise.", "latency_ms": 2877.4807453155518, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1952}, "4": {"k": 4, "answer": "party fashion", "latency_ms": 2403.0814170837402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Costume party", "latency_ms": 1897.5956439971924, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3152}, "6": {"k": 6, "answer": "party fashion", "latency_ms": 1206.880807876587, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3774}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 997.4184036254883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One", "latency_ms": 1528.7609100341797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 598}, "2": {"k": 2, "answer": "One", "latency_ms": 1715.684413909912, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1204}, "3": {"k": 3, "answer": "One", "latency_ms": 1185.4054927825928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "One", "latency_ms": 1526.53169631958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2534}, "5": {"k": 5, "answer": "One", "latency_ms": 1657.7606201171875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3184}, "6": {"k": 6, "answer": "One", "latency_ms": 1739.525318145752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3840}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "Gratitude to Fantine", "latency_ms": 2690.41109085083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3369.8570728302, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "Fantine's authorization", "latency_ms": 2625.993251800537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "Fantine's daughter", "latency_ms": 2200.3836631774902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1781}, "4": {"k": 4, "answer": "Fantine's daughter", "latency_ms": 2866.892099380493, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2420}, "5": {"k": 5, "answer": "Fantine's daughter", "latency_ms": 3057.325601577759, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3077}, "6": {"k": 6, "answer": "Fantine's daughter", "latency_ms": 2671.497106552124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3730}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, South Korea, Zambia, United States.", "latency_ms": 4806.050777435303, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Congo River basin Bantu-speaking tribes", "latency_ms": 3496.1588382720947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "Kenya", "latency_ms": 2270.2901363372803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Kenya", "latency_ms": 1530.3184986114502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2000}, "4": {"k": 4, "answer": "Kenya", "latency_ms": 1543.8733100891113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2685}, "5": {"k": 5, "answer": "Kenya", "latency_ms": 2002.3548603057861, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3425}, "6": {"k": 6, "answer": "Kenya", "latency_ms": 951.4141082763672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4082}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and control of black education.", "latency_ms": 4214.52260017395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to consolidate Bantu education", "latency_ms": 2609.5006465911865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "to consolidate Bantu education", "latency_ms": 2997.213363647461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1413}, "3": {"k": 3, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7902.137756347656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7493.995666503906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2764}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 6290.617227554321, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3440}, "6": {"k": 6, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 6531.566619873047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4117}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 1865.6370639801025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 3186.957597732544, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 2798.696517944336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Python", "latency_ms": 851.8695831298828, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1780}, "4": {"k": 4, "answer": "Python", "latency_ms": 1368.6375617980957, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2403}, "5": {"k": 5, "answer": "Python", "latency_ms": 1487.0901107788086, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3028}, "6": {"k": 6, "answer": "Python", "latency_ms": 1729.6473979949951, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3724}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 1019.9534893035889, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2654.5777320861816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 572}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2626.436948776245, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1152}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2237.309694290161, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1799}, "4": {"k": 4, "answer": "Ice", "latency_ms": 1406.6073894500732, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2448}, "5": {"k": 5, "answer": "Ice", "latency_ms": 1179.91304397583, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3108}, "6": {"k": 6, "answer": "Ice", "latency_ms": 1189.1498565673828, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3733}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 3482.534885406494, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Not in season 2.", "latency_ms": 3300.222873687744, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Not on page 200.", "latency_ms": 2285.4292392730713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "The Departed episode", "latency_ms": 2407.9623222351074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1921}, "4": {"k": 4, "answer": "At the end of the third season", "latency_ms": 2671.816349029541, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2605}, "5": {"k": 5, "answer": "At the hospital", "latency_ms": 2076.9424438476562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "The Departed episode", "latency_ms": 1561.4824295043945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3918}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "The home team.", "latency_ms": 2345.2072143554688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ITV", "latency_ms": 1465.3103351593018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "ITV", "latency_ms": 1774.4653224945068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1182}, "3": {"k": 3, "answer": "ITV", "latency_ms": 1782.5417518615723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1748}, "4": {"k": 4, "answer": "ITV", "latency_ms": 983.0484390258789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2331}, "5": {"k": 5, "answer": "ITV", "latency_ms": 1185.441017150879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2905}, "6": {"k": 6, "answer": "ITV", "latency_ms": 1724.6150970458984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3542}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw.", "latency_ms": 1801.473617553711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2639.3892765045166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Washington", "latency_ms": 1390.537977218628, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1298}, "3": {"k": 3, "answer": "Washington", "latency_ms": 1140.6629085540771, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Washington", "latency_ms": 1389.718770980835, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Washington", "latency_ms": 904.9801826477051, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3273}, "6": {"k": 6, "answer": "Washington", "latency_ms": 1444.7238445281982, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3900}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 1146.8679904937744, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2355.1552295684814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2445.8963871002197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Mosaic covenant", "latency_ms": 1943.1710243225098, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1929}, "4": {"k": 4, "answer": "Mosaic covenant", "latency_ms": 1973.7396240234375, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2539}, "5": {"k": 5, "answer": "Mosaic covenant", "latency_ms": 2072.4871158599854, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Mosaic covenant", "latency_ms": 1946.1965560913086, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3869}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 2626.0883808135986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1914.1013622283936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2925.7373809814453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2188.4119510650635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3114.5479679107666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2032.2532653808594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3153.5470485687256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3827}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "Yip Harburg", "latency_ms": 2200.885772705078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2469.715356826782, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2421.0615158081055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2457.9784870147705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2087.536096572876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2960.493326187134, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3128}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3269.061326980591, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3750}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 1830.2834033966064, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 2662.727117538452, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 2139.6231651306152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 1804.4209480285645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1909}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 1530.855417251587, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2587}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 2114.22061920166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3210}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 1307.53755569458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3832}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "Second", "latency_ms": 1777.2789001464844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2469.6693420410156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1930.4378032684326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1317}, "3": {"k": 3, "answer": "Largest population amongst", "latency_ms": 2444.692850112915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "Not mentioned.", "latency_ms": 2877.877712249756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2550.974130630493, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3204}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3233.3016395568848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3800}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 2975.4457473754883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Subhas Chandra Bose", "latency_ms": 3300.779104232788, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Surendranath Banerjee", "latency_ms": 3878.6001205444336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1323}, "3": {"k": 3, "answer": "Surendranath Banerjee", "latency_ms": 4933.599233627319, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1980}, "4": {"k": 4, "answer": "Surendranath Banerjee", "latency_ms": 3748.540163040161, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "Subhas Chandra Bose", "latency_ms": 3252.051591873169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3342}, "6": {"k": 6, "answer": "Surendranath Banerjee", "latency_ms": 3157.6082706451416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4070}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenae Anderson", "latency_ms": 2504.335641860962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2378.406524658203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2205.336332321167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2548.0778217315674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1942}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1643.1121826171875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3176.1908531188965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3166}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2964.177131652832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3777}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 1188.0435943603516, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 1669.0924167633057, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": ".java", "latency_ms": 1535.8262062072754, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": ".java", "latency_ms": 1767.0941352844238, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2009}, "4": {"k": 4, "answer": ".java", "latency_ms": 1502.3465156555176, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2656}, "5": {"k": 5, "answer": ".java", "latency_ms": 1994.6870803833008, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3294}, "6": {"k": 6, "answer": ".java", "latency_ms": 1470.8421230316162, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3891}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 1625.2689361572266, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alan Turing", "latency_ms": 1808.9377880096436, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Alan Turing", "latency_ms": 1444.6954727172852, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Alan Turing", "latency_ms": 897.2830772399902, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1935}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 1481.327772140503, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2563}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 2551.8901348114014, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3219}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 1300.3082275390625, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3849}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline and counting votes.", "latency_ms": 2955.359935760498, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "assistant majority or minority leader", "latency_ms": 2990.6527996063232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "assistant majority or minority leader", "latency_ms": 2653.8033485412598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "assistant majority or minority leader", "latency_ms": 2427.1140098571777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "assistant majority or minority leader", "latency_ms": 2734.2655658721924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "assistant majority or minority leader", "latency_ms": 2692.225217819214, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3277}, "6": {"k": 6, "answer": "assistant majority or minority leader", "latency_ms": 2219.9926376342773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 2045.189380645752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2138.4944915771484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2496.2234497070312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1717.4205780029297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2199.625253677368, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2513}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2390.542984008789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3137}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2113.978385925293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the right but not the obligation to buy foreign currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 1729.5050621032715, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 1615.807294845581, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 1518.017292022705, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 1983.2065105438232, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "FX option", "latency_ms": 1756.0522556304932, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2694}, "5": {"k": 5, "answer": "FX option", "latency_ms": 1490.063190460205, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3386}, "6": {"k": 6, "answer": "FX option", "latency_ms": 2007.6510906219482, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4003}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360 members in 109 constituencies", "latency_ms": 3293.7817573547363, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "One", "latency_ms": 1231.3902378082275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 698}, "2": {"k": 2, "answer": "360 members", "latency_ms": 895.1671123504639, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1421}, "3": {"k": 3, "answer": "360 members", "latency_ms": 2607.7136993408203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2114}, "4": {"k": 4, "answer": "360 members", "latency_ms": 1187.751293182373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2776}, "5": {"k": 5, "answer": "360 members", "latency_ms": 1733.0505847930908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3435}, "6": {"k": 6, "answer": "360 members", "latency_ms": 1267.9121494293213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4134}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 2402.5745391845703, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 2891.5579319000244, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 2086.6239070892334, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 2407.9339504241943, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1939}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 2420.581817626953, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 2089.646577835083, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 2684.8316192626953, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3909}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gorm"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 2666.0404205322266, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack Mac Ferland", "latency_ms": 2614.8998737335205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Eydie Gorm", "latency_ms": 2819.6980953216553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Eydie Gorm", "latency_ms": 3464.3867015838623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1787}, "4": {"k": 4, "answer": "Eydie Gorm", "latency_ms": 3496.835708618164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2388}, "5": {"k": 5, "answer": "Eydie Gorm", "latency_ms": 2650.55513381958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2965}, "6": {"k": 6, "answer": "Eydie Gorm", "latency_ms": 3586.8260860443115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3566}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "Kurian Joseph", "latency_ms": 1611.6058826446533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2641.6118144989014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "Mohan Shantanagoudar", "latency_ms": 3653.6645889282227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Mohan Shantanagoudar", "latency_ms": 4776.57675743103, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "Mohan Shantanagoudar", "latency_ms": 3113.8598918914795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "Mohan Shantanagoudar", "latency_ms": 3998.2826709747314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3042}, "6": {"k": 6, "answer": "Mohan Shantanagoudar", "latency_ms": 4959.298372268677, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3653}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "Margaret Court", "latency_ms": 2128.688097000122, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2208.3425521850586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1995.8152770996094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2620.002508163452, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1773}, "4": {"k": 4, "answer": "Ashley Cooper", "latency_ms": 1927.0110130310059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2388}, "5": {"k": 5, "answer": "Ken Rosewall", "latency_ms": 2073.7736225128174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2967}, "6": {"k": 6, "answer": "Ken Rosewall", "latency_ms": 3148.2763290405273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3554}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 1184.3104362487793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2695.8932876586914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 581}, "2": {"k": 2, "answer": "1", "latency_ms": 1729.9716472625732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1216}, "3": {"k": 3, "answer": "1", "latency_ms": 1750.5152225494385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "1", "latency_ms": 1491.2800788879395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2469}, "5": {"k": 5, "answer": "1", "latency_ms": 1227.067232131958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3062}, "6": {"k": 6, "answer": "1", "latency_ms": 1445.4615116119385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3644}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 1621.5951442718506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2000", "latency_ms": 2351.1672019958496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "2000", "latency_ms": 1613.593339920044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "2002 NBA Finals", "latency_ms": 3236.722707748413, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2014}, "4": {"k": 4, "answer": "2002", "latency_ms": 2070.1205730438232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2636}, "5": {"k": 5, "answer": "2002", "latency_ms": 2108.736515045166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3319}, "6": {"k": 6, "answer": "2002", "latency_ms": 1760.1795196533203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4003}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 1797.9788780212402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2395.644187927246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3119.013547897339, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Not stated", "latency_ms": 1705.599308013916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "1", "latency_ms": 1638.2520198822021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "1", "latency_ms": 1408.294916152954, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3165}, "6": {"k": 6, "answer": "17", "latency_ms": 1664.3941402435303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3830}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 2777.4457931518555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 2556.7328929901123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 3349.6625423431396, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 2765.6145095825195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 2127.29549407959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2566}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 2977.9415130615234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3217}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 1977.9736995697021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3848}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 3750.1096725463867, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 2267.2131061553955, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 571}, "2": {"k": 2, "answer": "Corey, Cory", "latency_ms": 2362.640619277954, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1134}, "3": {"k": 3, "answer": "Corey, Cory", "latency_ms": 2523.047924041748, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1819}, "4": {"k": 4, "answer": "Corey, Cory", "latency_ms": 2150.763750076294, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2507}, "5": {"k": 5, "answer": "Corey, Cory", "latency_ms": 2463.54079246521, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3130}, "6": {"k": 6, "answer": "Corey, Cory", "latency_ms": 2640.944004058838, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3715}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 1860.8152866363525, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2752.610445022583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "Elvis Presley", "latency_ms": 2790.1978492736816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "Elvis Presley", "latency_ms": 2574.8846530914307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1854}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3431.5083026885986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2451}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1837.1145725250244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3085}, "6": {"k": 6, "answer": "Elvis Presley", "latency_ms": 2889.820098876953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 1390.692949295044, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "60", "latency_ms": 2534.9411964416504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "60th", "latency_ms": 1516.113042831421, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2852.3685932159424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2640.7933235168457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2726.3734340667725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2473.329782485962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3816}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 2410.764217376709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2357.2826385498047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 561}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2639.8892402648926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2094.4082736968994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1785}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2599.067211151123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2381}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2229.353666305542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2981}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2921.924114227295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3562}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 2882.3981285095215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wilt Chamberlain and Adrian Dantley", "latency_ms": 4866.876840591431, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Wilt Chamberlain", "latency_ms": 2617.203950881958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "Wilt Chamberlain", "latency_ms": 3237.6952171325684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "Wilt Chamberlain", "latency_ms": 2737.4961376190186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2545}, "5": {"k": 5, "answer": "Wilt Chamberlain", "latency_ms": 2833.7833881378174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "Wilt Chamberlain", "latency_ms": 2388.6940479278564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3742}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 3280.078411102295, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2020.0097560882568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "Fourth finger", "latency_ms": 1897.2833156585693, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "Fourth finger", "latency_ms": 1520.1237201690674, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1920}, "4": {"k": 4, "answer": "4th finger", "latency_ms": 2266.3440704345703, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2455}, "5": {"k": 5, "answer": "4th finger", "latency_ms": 2352.9553413391113, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3057}, "6": {"k": 6, "answer": "4th finger", "latency_ms": 2094.0446853637695, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3711}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 3045.5358028411865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1655.5216312408447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2909.9979400634766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2410.3167057037354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1956}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3009.887456893921, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2653}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2708.6188793182373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3443.8376426696777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3918}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 2431.9422245025635, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bernard Mayes", "latency_ms": 2127.763032913208, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Bernard Mayes", "latency_ms": 2157.7746868133545, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "Bernard Mayes", "latency_ms": 3175.8081912994385, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Bernard Mayes", "latency_ms": 2922.3155975341797, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2557}, "5": {"k": 5, "answer": "Bernard Mayes", "latency_ms": 3446.9666481018066, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3191}, "6": {"k": 6, "answer": "Bernard Mayes", "latency_ms": 3180.1719665527344, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3789}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2019", "latency_ms": 3546.476125717163, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2373.7566471099854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 3784.247636795044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 3920.45521736145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 3848.048448562622, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2404}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 3327.814817428589, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3055}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 4015.5415534973145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3689}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 1418.6840057373047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2902.7724266052246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 539}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2215.3255939483643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2463.6402130126953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1847}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2438.6260509490967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2489}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2364.6748065948486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3141}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2109.1389656066895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3751}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 2116.889238357544, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2422.3198890686035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1866.1932945251465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1794.9130535125732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Claire Holt", "latency_ms": 1983.8793277740479, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Claire Holt", "latency_ms": 2065.3483867645264, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3108}, "6": {"k": 6, "answer": "Claire Holt", "latency_ms": 2601.817846298218, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3747}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living organisms.", "latency_ms": 2928.4632205963135, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in wood or soil", "latency_ms": 2671.168565750122, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 705}, "2": {"k": 2, "answer": "in wood or soil", "latency_ms": 2437.925100326538, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1425}, "3": {"k": 3, "answer": "wood, soil", "latency_ms": 1862.107276916504, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2048}, "4": {"k": 4, "answer": "in wood or soil", "latency_ms": 3467.8399562835693, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2759}, "5": {"k": 5, "answer": "in wood or soil", "latency_ms": 2862.6859188079834, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3428}, "6": {"k": 6, "answer": "in wood or soil", "latency_ms": 3718.837261199951, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 4095}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "Vijay Raghavendra", "latency_ms": 3193.4144496917725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shruti", "latency_ms": 1584.5954418182373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Chandan Shetty", "latency_ms": 3155.0731658935547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Shruthi", "latency_ms": 2759.211540222168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1824}, "4": {"k": 4, "answer": "Shruthi", "latency_ms": 3212.143659591675, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2427}, "5": {"k": 5, "answer": "Shruthi", "latency_ms": 2228.590488433838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3070}, "6": {"k": 6, "answer": "Season 1: Not specified, Season 2: Akul Balaji, Season 3: Shruthi, Season 4: Not specified, Season 5: Chandan Shetty", "latency_ms": 16818.33291053772, "em": 0.0, "f1": 0.19047619047619052, "containment": 1.0, "context_chars": 3713}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, Utah, and Mexico.", "latency_ms": 4302.155017852783, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3071.157217025757, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2220.7443714141846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2581.17413520813, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3094.6929454803467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2365.1349544525146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3124}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2909.200668334961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3728}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 2087.5723361968994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2285.4814529418945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2155.9813022613525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2361.5801334381104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3328.235149383545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2654.897928237915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3028}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2333.514451980591, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3621}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Canada to Lake Winnipeg.", "latency_ms": 4466.644763946533, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 2881.6521167755127, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2313.1558895111084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2086.545467376709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2966.1705493927, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2557}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2901.5417098999023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2547.447443008423, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 1801.3269901275635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 2063.1229877471924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome", "latency_ms": 1772.4316120147705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Rome", "latency_ms": 2558.335542678833, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1954}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 2905.017375946045, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2583}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 2943.275213241577, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3146}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 2561.2480640411377, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3862}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "CE Mark or Measure number", "latency_ms": 2449.4099617004395, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3292.269468307495, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3135.772466659546, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1280}, "3": {"k": 3, "answer": "the manufacturing company or site", "latency_ms": 2815.167188644409, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1927}, "4": {"k": 4, "answer": "the manufacturing company or site", "latency_ms": 3511.199712753296, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2500}, "5": {"k": 5, "answer": "the manufacturing company or site", "latency_ms": 3036.105155944824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "the manufacturing company or site", "latency_ms": 3524.264097213745, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3770}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia, methanol.", "latency_ms": 3234.6839904785156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "solute molecules", "latency_ms": 2011.8982791900635, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Hydrogen sulfide", "latency_ms": 2574.9716758728027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1356}, "3": {"k": 3, "answer": "Hydrogen sulfide, hydrogen fluoride, ammonia, methanol", "latency_ms": 6242.92778968811, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2025}, "4": {"k": 4, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 3577.756404876709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2625}, "5": {"k": 5, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 3310.584306716919, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol, hydrogen sulfide", "latency_ms": 5418.14398765564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3829}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Once in a Lifetime", "latency_ms": 2149.7154235839844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 956.8445682525635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "1988", "latency_ms": 1572.8914737701416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "1988", "latency_ms": 1515.6221389770508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1824}, "4": {"k": 4, "answer": "1988", "latency_ms": 2326.601028442383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2427}, "5": {"k": 5, "answer": "1988", "latency_ms": 766.3097381591797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3038}, "6": {"k": 6, "answer": "1988", "latency_ms": 2331.8090438842773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3645}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 2063.497543334961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2457.0252895355225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Truco", "latency_ms": 1519.6757316589355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Manille", "latency_ms": 1274.2459774017334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1857}, "4": {"k": 4, "answer": "Manille", "latency_ms": 2074.0888118743896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "Manille", "latency_ms": 1529.2418003082275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3061}, "6": {"k": 6, "answer": "Manille", "latency_ms": 2313.509225845337, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3685}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 2677.9894828796387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Five percent", "latency_ms": 1947.4225044250488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "5%", "latency_ms": 1292.3345565795898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1317}, "3": {"k": 3, "answer": "Five percent", "latency_ms": 1503.5505294799805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2022}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 3354.621410369873, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2632}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 2557.4376583099365, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3257}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 3005.053997039795, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3904}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 2083.8165283203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2819.2431926727295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "1975", "latency_ms": 2293.9205169677734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1200}, "3": {"k": 3, "answer": "1975", "latency_ms": 1729.2439937591553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1854}, "4": {"k": 4, "answer": "1975", "latency_ms": 1537.872076034546, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2458}, "5": {"k": 5, "answer": "1971", "latency_ms": 2254.2850971221924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3128}, "6": {"k": 6, "answer": "1975", "latency_ms": 769.8526382446289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3740}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 1174.9587059020996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2338.825464248657, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2130.3563117980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2711.270570755005, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1844}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2079.7488689422607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2518}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2424.207925796509, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3151}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2190.8204555511475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert, 2nd Baron Baltimore", "latency_ms": 3919.00897026062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "William Stone", "latency_ms": 2279.4535160064697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "William Stone", "latency_ms": 2294.5005893707275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "William Stone", "latency_ms": 1255.51438331604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1956}, "4": {"k": 4, "answer": "William Stone", "latency_ms": 2107.694387435913, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "Leonard Calvert", "latency_ms": 2226.6173362731934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3324}, "6": {"k": 6, "answer": "Leonard Calvert", "latency_ms": 2408.5917472839355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4035}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 1541.7802333831787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2464.913845062256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2364.143133163452, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2695.8391666412354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Tiger Woods", "latency_ms": 1535.0894927978516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "Tiger Woods", "latency_ms": 2561.1109733581543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3172}, "6": {"k": 6, "answer": "Tiger Woods", "latency_ms": 3114.1793727874756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3842}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 2441.5225982666016, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "high amounts", "latency_ms": 1778.0182361602783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 688}, "2": {"k": 2, "answer": "high amounts", "latency_ms": 1900.4075527191162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "high amounts", "latency_ms": 1477.5817394256592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "high amounts", "latency_ms": 2037.9986763000488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2642}, "5": {"k": 5, "answer": "high amounts", "latency_ms": 848.1602668762207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "high amounts", "latency_ms": 2815.7804012298584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3888}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 2849.858522415161, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sunderland", "latency_ms": 2792.6502227783203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 558}, "2": {"k": 2, "answer": "West Ham", "latency_ms": 2647.9618549346924, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1138}, "3": {"k": 3, "answer": "West Ham", "latency_ms": 1730.5245399475098, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1730}, "4": {"k": 4, "answer": "West Ham", "latency_ms": 1261.4555358886719, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2340}, "5": {"k": 5, "answer": "West Ham", "latency_ms": 970.4775810241699, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2982}, "6": {"k": 6, "answer": "Sunderland", "latency_ms": 1578.949213027954, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3574}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 1888.0524635314941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2564.676284790039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1669.9259281158447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1343}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2547.283887863159, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2066}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2556.522846221924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2742}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2219.9339866638184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3426}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2631.634473800659, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4160}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh, Scotland", "latency_ms": 1726.0661125183105, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh", "latency_ms": 1034.03902053833, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "Edinburgh", "latency_ms": 1674.3049621582031, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1356}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 2626.324415206909, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 2425.365447998047, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 2015.9368515014648, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3359}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 2906.2557220458984, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3999}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 1327.307939529419, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2881.7379474639893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3211.859703063965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3201.085329055786, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2030}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2457.388401031494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2707}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1992.8181171417236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3338}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3080.5275440216064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3952}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 2711.3471031188965, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haven", "latency_ms": 2172.8503704071045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Southport, North Carolina.", "latency_ms": 3239.9163246154785, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Southport, North Carolina.", "latency_ms": 3197.925329208374, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1902}, "4": {"k": 4, "answer": "Southport, North Carolina.", "latency_ms": 3233.703851699829, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2499}, "5": {"k": 5, "answer": "Southport, North Carolina.", "latency_ms": 3211.1616134643555, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "Southport, North Carolina.", "latency_ms": 3546.682596206665, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 2316.8060779571533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2505.415916442871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 705}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2698.972225189209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2140.827178955078, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1990}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2923.2099056243896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2599}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2161.2048149108887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2981.9931983947754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3932}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 1907.2885513305664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hoover", "latency_ms": 1804.0263652801514, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 703}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 2077.364921569824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1440}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 1747.8582859039307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2145}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 2568.129539489746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2887}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 1547.475814819336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3615}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 2545.301675796509, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4337}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 861.6337776184082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 1682.6777458190918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "Max", "latency_ms": 1384.626865386963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1244}, "3": {"k": 3, "answer": "Max", "latency_ms": 1469.672679901123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Max", "latency_ms": 1455.34348487854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2519}, "5": {"k": 5, "answer": "Max", "latency_ms": 1447.5903511047363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "Max", "latency_ms": 1149.5699882507324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3742}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 2049.273729324341, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Megan Follows", "latency_ms": 2045.3789234161377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2570.3213214874268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2829.1144371032715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1914}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2848.036289215088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2514}, "5": {"k": 5, "answer": "Megan Follows", "latency_ms": 2401.606321334839, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3160}, "6": {"k": 6, "answer": "Megan Follows", "latency_ms": 2834.174633026123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3869}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "Boxer Rebellion.", "latency_ms": 2693.8397884368896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Navy committed to ocean-going battleships", "latency_ms": 4141.868114471436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "Navy expansion", "latency_ms": 2532.4270725250244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Navy expansion", "latency_ms": 2268.7346935272217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1880}, "4": {"k": 4, "answer": "Navy expansion and stagnation", "latency_ms": 3300.537586212158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "Navy expansion and industrial heritage", "latency_ms": 3265.3987407684326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "Navy expansion and industrial heritage.", "latency_ms": 3010.6043815612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3848}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 2110.4588508605957, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Brisbane Roar's theme song", "latency_ms": 3052.41060256958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "Brisbane Roar's theme song", "latency_ms": 4280.8167934417725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1370}, "3": {"k": 3, "answer": "Brisbane Roar's theme song", "latency_ms": 3555.196523666382, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2041}, "4": {"k": 4, "answer": "self-empowerment", "latency_ms": 3127.7670860290527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2654}, "5": {"k": 5, "answer": "self-empowerment", "latency_ms": 2826.611280441284, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3272}, "6": {"k": 6, "answer": "self-empowerment", "latency_ms": 1784.569263458252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3854}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams' front offices", "latency_ms": 2953.1266689300537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the team", "latency_ms": 1961.7226123809814, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "National Football League teams", "latency_ms": 2916.254758834839, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "National Football League teams", "latency_ms": 2827.019691467285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "National Football League teams", "latency_ms": 2156.095504760742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2508}, "5": {"k": 5, "answer": "National Football League teams", "latency_ms": 3418.0002212524414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3118}, "6": {"k": 6, "answer": "National Football League teams", "latency_ms": 1467.7760601043701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3730}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 2642.559766769409, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "one of the sailors", "latency_ms": 3139.542579650879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "one of the sailors", "latency_ms": 2600.0518798828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "sailors", "latency_ms": 2575.650215148926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Sailors, including one named Brownsville", "latency_ms": 3803.600549697876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2562}, "5": {"k": 5, "answer": "Sailors, including one named Brownsville", "latency_ms": 3916.205644607544, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3148}, "6": {"k": 6, "answer": "James W. Marshall", "latency_ms": 2671.0262298583984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3813}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 1848.4973907470703, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 2079.7622203826904, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 1865.3266429901123, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 2588.5910987854004, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1879}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 1882.2970390319824, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 2293.2214736938477, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 2922.443151473999, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "9", "latency_ms": 216.1421775817871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2386.615753173828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2593.1825637817383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2337.087392807007, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1812.8554821014404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2612}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2429.60786819458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3340}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1678.1470775604248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3938}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3182.182550430298, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ken Hill", "latency_ms": 1773.9295959472656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 669}, "2": {"k": 2, "answer": "Ken Hill", "latency_ms": 1257.9514980316162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "Ken Hill, Charles Hart, Richard Stilgoe", "latency_ms": 5451.41863822937, "em": 0.0, "f1": 0.7272727272727272, "containment": 1.0, "context_chars": 2023}, "4": {"k": 4, "answer": "Ken Hill, Charles Hart, Richard Stilgoe", "latency_ms": 5137.366771697998, "em": 0.0, "f1": 0.7272727272727272, "containment": 1.0, "context_chars": 2687}, "5": {"k": 5, "answer": "Ken Hill, Charles Hart, Richard Stilgoe", "latency_ms": 5824.085712432861, "em": 0.0, "f1": 0.7272727272727272, "containment": 1.0, "context_chars": 3303}, "6": {"k": 6, "answer": "Ken Hill, Charles Hart", "latency_ms": 3079.7603130340576, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3962}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 1569.317102432251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central Germany", "latency_ms": 1740.8390045166016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Central Germany", "latency_ms": 2013.56840133667, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1357}, "3": {"k": 3, "answer": "Central Germany", "latency_ms": 2200.634002685547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Central Germany", "latency_ms": 2218.0116176605225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2757}, "5": {"k": 5, "answer": "European", "latency_ms": 1406.8596363067627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3406}, "6": {"k": 6, "answer": "Central European", "latency_ms": 2288.156270980835, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4051}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 1787.7147197723389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 2630.4116249084473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 2914.5290851593018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 1685.502290725708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "post-medieval era", "latency_ms": 2378.0126571655273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "16481651", "latency_ms": 3021.0554599761963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3260}, "6": {"k": 6, "answer": "16481651", "latency_ms": 2968.259811401367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
