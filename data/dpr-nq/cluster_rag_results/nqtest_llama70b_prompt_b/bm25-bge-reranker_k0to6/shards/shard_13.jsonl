{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 1833.3191871643066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2441.739320755005, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2981.7938804626465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2133.923292160034, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1956}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1379.8792362213135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2588}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2437.9513263702393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2099.1029739379883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3824}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 1892.0586109161377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 1942.7344799041748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 2193.678379058838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 2871.091604232788, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 1993.4463500976562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2597}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 2331.165075302124, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3219}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 2759.5901489257812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3892}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwestern United States and Mexico", "latency_ms": 3556.8058490753174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4908.736944198608, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4876.4283657073975, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 4345.372676849365, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 3894.9568271636963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 4376.779794692993, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 4345.419883728027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3932}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 2725.567579269409, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dr. Rajendra Prasad", "latency_ms": 3070.5788135528564, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 743}, "2": {"k": 2, "answer": "Dr. Rajendra Prasad", "latency_ms": 2763.232707977295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1429}, "3": {"k": 3, "answer": "Dr. Rajendra Prasad", "latency_ms": 2992.5179481506348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2125}, "4": {"k": 4, "answer": "Dr. Rajendra Prasad", "latency_ms": 3521.9790935516357, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2814}, "5": {"k": 5, "answer": "Dr. Rajendra Prasad", "latency_ms": 2952.317476272583, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3509}, "6": {"k": 6, "answer": "Dr. Rajendra Prasad", "latency_ms": 3219.7694778442383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4207}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1987.6432418823242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2415.2889251708984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2746.6235160827637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1998.3570575714111, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2004.467487335205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2691.993474960327, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3179}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1773.1750011444092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3861}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "June 22, 2001", "latency_ms": 4145.833969116211, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2001", "latency_ms": 1575.5243301391602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "2001", "latency_ms": 1760.3809833526611, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "2001", "latency_ms": 2006.7615509033203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1878}, "4": {"k": 4, "answer": "2001", "latency_ms": 1329.7882080078125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2536}, "5": {"k": 5, "answer": "June 22, 2001", "latency_ms": 3737.9465103149414, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3180}, "6": {"k": 6, "answer": "June 22, 2001", "latency_ms": 4677.44517326355, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3795}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "March 1, 2018", "latency_ms": 3502.466917037964, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 3628.7879943847656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 3163.9091968536377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 4184.56244468689, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 4232.992649078369, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2705}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 3976.436138153076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3344}, "6": {"k": 6, "answer": "September 27, 2017", "latency_ms": 4277.843713760376, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4040}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3.", "latency_ms": 2504.2481422424316, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "February 14, 2013", "latency_ms": 3996.2921142578125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "February 14, 2013", "latency_ms": 3213.6807441711426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "February 14, 2013", "latency_ms": 4146.162748336792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "February 14, 2013", "latency_ms": 3838.1714820861816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2648}, "5": {"k": 5, "answer": "February 14, 2013", "latency_ms": 4229.328870773315, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3314}, "6": {"k": 6, "answer": "February 14, 2013", "latency_ms": 4464.7181034088135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3975}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2643.644332885742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2433.804512023926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3013.7553215026855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3254.8115253448486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2185.316562652588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2961.893320083618, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3115}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2209.9227905273438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3815}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 1620.5484867095947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Havana harbor, Cuba", "latency_ms": 3048.8412380218506, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "Havana harbor, Cuba", "latency_ms": 2273.853063583374, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Havana harbor, Cuba", "latency_ms": 2629.3017864227295, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1910}, "4": {"k": 4, "answer": "Havana harbor, Cuba", "latency_ms": 2755.364418029785, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2533}, "5": {"k": 5, "answer": "Havana Harbor, Cuba", "latency_ms": 3471.1267948150635, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3164}, "6": {"k": 6, "answer": "Havana Harbor, Cuba", "latency_ms": 3244.443416595459, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3769}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 2618.2026863098145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1720.0756072998047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "No specific god mentioned", "latency_ms": 3219.6907997131348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1280}, "3": {"k": 3, "answer": "Lord Vasupujya", "latency_ms": 3856.853485107422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1942}, "4": {"k": 4, "answer": "None mentioned", "latency_ms": 1821.7499256134033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Lord Vishnu and Lord Shiva and Lord Vasupujya", "latency_ms": 5279.171943664551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "Lord Vishnu and Lord Shiva and Lord Ganesha", "latency_ms": 5611.072301864624, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3870}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama.", "latency_ms": 3648.5447883605957, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costa Rica, Nicaragua, Panama, Belize, Honduras, Guatemala, El Salvador", "latency_ms": 5887.892961502075, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Costa Rica, Panama", "latency_ms": 2934.3626499176025, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1294}, "3": {"k": 3, "answer": "Costa Rica, Panama", "latency_ms": 2475.698709487915, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1901}, "4": {"k": 4, "answer": "Costa Rica, Panama", "latency_ms": 2489.1254901885986, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2494}, "5": {"k": 5, "answer": "Panama, Costa Rica, Nicaragua", "latency_ms": 3926.0592460632324, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Panama, Nicaragua, Costa Rica", "latency_ms": 3722.031354904175, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3823}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence.", "latency_ms": 1133.6007118225098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 1303.710699081421, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Complex sentence", "latency_ms": 1834.5425128936768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1350}, "3": {"k": 3, "answer": "Complex sentence", "latency_ms": 1484.5974445343018, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2037}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 1253.5288333892822, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2743}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 1775.312900543213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3425}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 1365.920066833496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4084}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and capitalism.", "latency_ms": 3286.8807315826416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 4160.597801208496, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3619.663953781128, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3819.303512573242, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 2000}, "4": {"k": 4, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 4556.574106216431, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 2681}, "5": {"k": 5, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3421.166181564331, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3408}, "6": {"k": 6, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 4376.747369766235, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 4069}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 3351.3898849487305, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 10, 2017", "latency_ms": 3688.4689331054688, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "October 10, 2017", "latency_ms": 3614.661455154419, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 3334.887742996216, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 3715.9483432769775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2494}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 3837.6924991607666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3109}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 4616.550922393799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere.", "latency_ms": 3787.3575687408447, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northern Territory", "latency_ms": 2034.8126888275146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "Northern Territory", "latency_ms": 1440.5455589294434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Asia outside of Russia", "latency_ms": 2620.422840118408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1907}, "4": {"k": 4, "answer": "Asia outside of Russia", "latency_ms": 2437.1085166931152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "Southern part of the Northern Territory", "latency_ms": 3615.78106880188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3248}, "6": {"k": 6, "answer": "Southern part of the Northern Territory", "latency_ms": 3895.2691555023193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3956}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Mara Jade", "latency_ms": 2142.2605514526367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2082.350492477417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "Leia", "latency_ms": 1506.9007873535156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "Leia", "latency_ms": 2043.4575080871582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1785}, "4": {"k": 4, "answer": "Leia", "latency_ms": 2338.4718894958496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2382}, "5": {"k": 5, "answer": "Leia, Callista", "latency_ms": 3322.5808143615723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2994}, "6": {"k": 6, "answer": "Callista", "latency_ms": 1741.560459136963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3614}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 1353.3341884613037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Allen Ludden", "latency_ms": 1797.900676727295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "Allen Ludden", "latency_ms": 1801.973581314087, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Barry Cryer", "latency_ms": 2346.112012863159, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "Jack Barry", "latency_ms": 1985.8646392822266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2471}, "5": {"k": 5, "answer": "Barry Cryer", "latency_ms": 3121.3183403015137, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3021}, "6": {"k": 6, "answer": "Barry Cryer", "latency_ms": 3255.3508281707764, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3654}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 2391.0303115844727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mitochondrion", "latency_ms": 2665.036678314209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 707}, "2": {"k": 2, "answer": "Mitochondrion and Chloroplast", "latency_ms": 3104.6361923217773, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1366}, "3": {"k": 3, "answer": "Mitochondrion and Chloroplast", "latency_ms": 5110.23736000061, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2064}, "4": {"k": 4, "answer": "Mitochondria and Chloroplasts", "latency_ms": 4010.6441974639893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2715}, "5": {"k": 5, "answer": "Mitochondria and Chloroplasts", "latency_ms": 5120.715141296387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3391}, "6": {"k": 6, "answer": "Mitochondria and Chloroplasts", "latency_ms": 3750.2551078796387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4070}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Intrusion Detection.", "latency_ms": 8572.967767715454, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3111.5670204162598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2472.32723236084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1380}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1925.9459972381592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2097}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3165.8456325531006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2806}, "5": {"k": 5, "answer": "Veriato, Armitage, Metasploit, Spector Pro, Centrify", "latency_ms": 7774.242639541626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3562}, "6": {"k": 6, "answer": "Armitage, Veriato, Metasploit, Spector Pro, Centrato", "latency_ms": 7245.656967163086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4251}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 2854.098320007324, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3585.4732990264893, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 590}, "2": {"k": 2, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3505.943775177002, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Dottie West and Kenny Rogers", "latency_ms": 3654.961109161377, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Dottie West and Kenny Rogers", "latency_ms": 3307.7094554901123, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "Dottie West and Kenny Rogers", "latency_ms": 3157.888412475586, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3082}, "6": {"k": 6, "answer": "Dottie West", "latency_ms": 2541.496515274048, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3663}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 2391.1328315734863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Two years of age", "latency_ms": 3190.0477409362793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 581}, "2": {"k": 2, "answer": "36 months", "latency_ms": 1502.4349689483643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1200}, "3": {"k": 3, "answer": "36 months old", "latency_ms": 2603.1455993652344, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "36 months old", "latency_ms": 1512.5811100006104, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2526}, "5": {"k": 5, "answer": "36 months old", "latency_ms": 3125.077724456787, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3129}, "6": {"k": 6, "answer": "36 months", "latency_ms": 2067.7666664123535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3836}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 1467.8034782409668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Three-part", "latency_ms": 1485.1365089416504, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Three-part", "latency_ms": 1774.0724086761475, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Three", "latency_ms": 936.6321563720703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Three", "latency_ms": 2283.3592891693115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2599}, "5": {"k": 5, "answer": "3", "latency_ms": 925.3742694854736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3264}, "6": {"k": 6, "answer": "Three", "latency_ms": 1540.8108234405518, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3904}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 6381.117582321167, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elijah Wood", "latency_ms": 2105.66782951355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "Elijah Wood", "latency_ms": 2383.239507675171, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1258}, "3": {"k": 3, "answer": "Elijah Wood", "latency_ms": 1771.195411682129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1919}, "4": {"k": 4, "answer": "Elijah Wood", "latency_ms": 1959.3698978424072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Elijah Wood", "latency_ms": 2380.722761154175, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3233}, "6": {"k": 6, "answer": "Elijah Wood", "latency_ms": 2600.3477573394775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3862}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party.", "latency_ms": 2585.5019092559814, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume party", "latency_ms": 2077.946662902832, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "Fancy dress party", "latency_ms": 3187.2096061706543, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Fancy dress party", "latency_ms": 3222.9573726654053, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1971}, "4": {"k": 4, "answer": "Fancy dress party", "latency_ms": 2908.7960720062256, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2647}, "5": {"k": 5, "answer": "Fancy dress party", "latency_ms": 2467.8986072540283, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3310}, "6": {"k": 6, "answer": "Fancy dress party", "latency_ms": 2933.9752197265625, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3940}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 937.835693359375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3019.2275047302246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1993.1416511535645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2571.946620941162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2649.006128311157, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "1", "latency_ms": 1201.1899948120117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3225}, "6": {"k": 6, "answer": "1", "latency_ms": 1712.4309539794922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3912}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "Gratitude to Fantine", "latency_ms": 2752.1629333496094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fantine's debts", "latency_ms": 2404.1147232055664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "Fantine's debts", "latency_ms": 1680.3734302520752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Because she was Fantine's daughter", "latency_ms": 4390.142917633057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Because she was Fantine's daughter", "latency_ms": 3212.348461151123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Because she was Fantine's daughter", "latency_ms": 5453.735589981079, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "Because she was Fantine's daughter", "latency_ms": 4009.1137886047363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3701}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, South Korea, Zambia, United States.", "latency_ms": 5285.990238189697, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenya", "latency_ms": 2290.8239364624023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 688}, "2": {"k": 2, "answer": "Kenya", "latency_ms": 2244.0176010131836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1382}, "3": {"k": 3, "answer": "Kenya and India", "latency_ms": 2726.086378097534, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Kenya, India", "latency_ms": 3487.9305362701416, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2788}, "5": {"k": 5, "answer": "Kenya, India, Norway, Russia", "latency_ms": 4365.762233734131, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3489}, "6": {"k": 6, "answer": "Kenya, India, Norway, Russia", "latency_ms": 4057.2853088378906, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 4162}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and oppression.", "latency_ms": 3026.9265174865723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 8056.4868450164795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7248.8977909088135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7898.654222488403, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7571.66600227356, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7050.725221633911, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7870.445966720581, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4130}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 2636.5957260131836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 3022.1774578094482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 2795.4092025756836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Indian python", "latency_ms": 1545.9215641021729, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1830}, "4": {"k": 4, "answer": "Indian python", "latency_ms": 2060.030460357666, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "Indian python", "latency_ms": 1958.7595462799072, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3040}, "6": {"k": 6, "answer": "Indian python", "latency_ms": 2338.719367980957, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3650}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 2323.7483501434326, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "water-ice", "latency_ms": 2499.990224838257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "water-ice", "latency_ms": 1788.4480953216553, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1200}, "3": {"k": 3, "answer": "water-ice", "latency_ms": 1888.1161212921143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1776}, "4": {"k": 4, "answer": "water-ice", "latency_ms": 2269.83904838562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2423}, "5": {"k": 5, "answer": "water-ice", "latency_ms": 2174.8363971710205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2996}, "6": {"k": 6, "answer": "water-ice", "latency_ms": 2791.2704944610596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3644}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 4325.262546539307, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Season four premiere", "latency_ms": 2154.5445919036865, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 594}, "2": {"k": 2, "answer": "Season four premiere", "latency_ms": 2663.1815433502197, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1217}, "3": {"k": 3, "answer": "Season 3 finale", "latency_ms": 2395.787000656128, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1818}, "4": {"k": 4, "answer": "Season 3 finale", "latency_ms": 3097.716808319092, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2382}, "5": {"k": 5, "answer": "Season 3 finale", "latency_ms": 2006.9208145141602, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2999}, "6": {"k": 6, "answer": "Season 3 finale", "latency_ms": 2330.838441848755, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3599}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "The home team", "latency_ms": 1586.1365795135498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2402.6565551757812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 589}, "2": {"k": 2, "answer": "BBC", "latency_ms": 404.91747856140137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1172}, "3": {"k": 3, "answer": "BBC", "latency_ms": 2042.7579879760742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1768}, "4": {"k": 4, "answer": "BBC", "latency_ms": 646.6836929321289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2392}, "5": {"k": 5, "answer": "BBC", "latency_ms": 1976.3374328613281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2976}, "6": {"k": 6, "answer": "BBC", "latency_ms": 1425.896167755127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3568}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw.", "latency_ms": 1709.9990844726562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northwest", "latency_ms": 2211.4431858062744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "Northwest Washington", "latency_ms": 1747.5318908691406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Northwest", "latency_ms": 2269.798994064331, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1995}, "4": {"k": 4, "answer": "Northwest Washington, DC.", "latency_ms": 4071.851968765259, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2687}, "5": {"k": 5, "answer": "Northwest", "latency_ms": 1269.0811157226562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3299}, "6": {"k": 6, "answer": "Northwest", "latency_ms": 1768.531084060669, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 1691.1365985870361, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Covenant of Works", "latency_ms": 2165.9507751464844, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "Noahic", "latency_ms": 2071.2828636169434, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Covenant of Works", "latency_ms": 3074.3868350982666, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Covenant of Works", "latency_ms": 3145.908832550049, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2423}, "5": {"k": 5, "answer": "Covenant of Works", "latency_ms": 2088.2508754730225, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "Covenant of Works", "latency_ms": 2158.581018447876, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3733}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 2647.491931915283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2336.5325927734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2862.6503944396973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2144.3891525268555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1807}, "4": {"k": 4, "answer": "Jack Jones", "latency_ms": 2049.990653991699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2394}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2446.9103813171387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2969}, "6": {"k": 6, "answer": "Jack Jones", "latency_ms": 1745.7633018493652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3572}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "Yip Harburg", "latency_ms": 2832.9341411590576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ray Henderson", "latency_ms": 1354.0284633636475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "Ray Henderson", "latency_ms": 2565.7331943511963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Ray Henderson", "latency_ms": 1507.6372623443604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Ray Henderson", "latency_ms": 2584.3703746795654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "Ray Henderson", "latency_ms": 2534.1238975524902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Ray Henderson", "latency_ms": 1571.9566345214844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3732}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 2323.6489295959473, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 1761.7135047912598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 1540.5735969543457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 2236.102342605591, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 1703.4215927124023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2529}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 1683.3789348602295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3176}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 1902.7936458587646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3789}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "Second", "latency_ms": 1209.9475860595703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2953.4356594085693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2914.4458770751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2475.268602371216, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3210.7093334198, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2482.593536376953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3079}, "6": {"k": 6, "answer": "11th largest", "latency_ms": 2107.2990894317627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3698}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 1844.301700592041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mahatma Gandhi", "latency_ms": 2338.0651473999023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 706}, "2": {"k": 2, "answer": "Mahatma Gandhi", "latency_ms": 2674.602746963501, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1429}, "3": {"k": 3, "answer": "Sonia Gandhi", "latency_ms": 1032.0377349853516, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2103}, "4": {"k": 4, "answer": "Sonia Gandhi", "latency_ms": 2587.3193740844727, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2799}, "5": {"k": 5, "answer": "Mahatma Gandhi", "latency_ms": 2245.3408241271973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3509}, "6": {"k": 6, "answer": "Jawaharlal Nehru", "latency_ms": 2488.790512084961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4184}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenae Anderson", "latency_ms": 1770.7901000976562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "La Toya Jackson", "latency_ms": 2427.4797439575195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1791.5048599243164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1263}, "3": {"k": 3, "answer": "Bobby Flay", "latency_ms": 2458.164930343628, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "Bobby Flay", "latency_ms": 1326.6701698303223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Bobby Flay", "latency_ms": 2245.8791732788086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3086}, "6": {"k": 6, "answer": "Bobby Flay", "latency_ms": 2627.361536026001, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3703}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 1261.3134384155273, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 1538.8209819793701, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": ".java", "latency_ms": 1464.9994373321533, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": ".java", "latency_ms": 1512.0272636413574, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": ".java", "latency_ms": 989.243745803833, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": ".java", "latency_ms": 1505.3253173828125, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": ".java", "latency_ms": 1200.7811069488525, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 1068.6378479003906, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alan Turing", "latency_ms": 2061.4027976989746, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Alan Turing", "latency_ms": 2067.7099227905273, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1289}, "3": {"k": 3, "answer": "Alan Turing", "latency_ms": 2102.3077964782715, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 1019.2620754241943, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2530}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 2278.735876083374, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3124}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 2034.8880290985107, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3756}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline and counting votes.", "latency_ms": 3409.9626541137695, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ensure party members adhere to party policies", "latency_ms": 3573.2879638671875, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "ensure members adhere to party policies", "latency_ms": 3515.4733657836914, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "to ensure members adhere to party policies", "latency_ms": 3436.544179916382, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "to ensure members adhere to party policies", "latency_ms": 4840.649604797363, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "to ensure members adhere to party policies", "latency_ms": 3919.271469116211, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "to gather votes on major issues", "latency_ms": 2544.0711975097656, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 3850}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 1061.7847442626953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2099.090337753296, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2168.7941551208496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2703.5679817199707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2129.951000213623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2513.7197971343994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3311}, "6": {"k": 6, "answer": "1973", "latency_ms": 1812.6213550567627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3866}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the right but not the obligation to buy foreign currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 754.204273223877, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 1474.846601486206, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 1007.6310634613037, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 1379.8117637634277, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "FX option", "latency_ms": 2300.283432006836, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2700}, "5": {"k": 5, "answer": "FX option", "latency_ms": 1728.5354137420654, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3357}, "6": {"k": 6, "answer": "Call option", "latency_ms": 1587.054967880249, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4005}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 2069.9856281280518, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 1318.2871341705322, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360", "latency_ms": 1280.6663513183594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1376}, "3": {"k": 3, "answer": "360", "latency_ms": 1488.590955734253, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2070}, "4": {"k": 4, "answer": "360 members", "latency_ms": 1262.4683380126953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2700}, "5": {"k": 5, "answer": "360 members", "latency_ms": 1325.3417015075684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3342}, "6": {"k": 6, "answer": "360", "latency_ms": 1733.2053184509277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3995}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 1955.7404518127441, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 2689.4233226776123, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 2419.6581840515137, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 2983.9367866516113, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 3181.529998779297, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 2425.598382949829, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3183}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 2459.2342376708984, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3835}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gorm"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 3426.1324405670166, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eydie Gorm", "latency_ms": 2336.9128704071045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 580}, "2": {"k": 2, "answer": "Eydie Gorm", "latency_ms": 3321.1162090301514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1156}, "3": {"k": 3, "answer": "Eydie Gorm", "latency_ms": 3400.3357887268066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1757}, "4": {"k": 4, "answer": "Eydie Gorm", "latency_ms": 3635.3988647460938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2334}, "5": {"k": 5, "answer": "Eydie Gorm", "latency_ms": 2747.8792667388916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2965}, "6": {"k": 6, "answer": "Eydie Gorm", "latency_ms": 2216.63498878479, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3515}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "Kurian Joseph", "latency_ms": 2181.3316345214844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jasti Chelameswar", "latency_ms": 3035.240888595581, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Jasti Chelameswar", "latency_ms": 2551.323890686035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Jasti Chelameswar", "latency_ms": 4184.960603713989, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "Jasti Chelameswar", "latency_ms": 2814.371347427368, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2481}, "5": {"k": 5, "answer": "Jasti Chelameswar", "latency_ms": 2554.5220375061035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3093}, "6": {"k": 6, "answer": "Jasti Chelameswar", "latency_ms": 2347.1596240997314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3657}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "Margaret Court", "latency_ms": 1061.328649520874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roger Federer", "latency_ms": 2755.025625228882, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 635}, "2": {"k": 2, "answer": "Roger Federer", "latency_ms": 1816.7202472686768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Roger Federer", "latency_ms": 2130.7754516601562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1790}, "4": {"k": 4, "answer": "Roger Federer", "latency_ms": 1787.2347831726074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2362}, "5": {"k": 5, "answer": "Roger Federer", "latency_ms": 2563.053846359253, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3023}, "6": {"k": 6, "answer": "Margaret Court", "latency_ms": 1325.9446620941162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3597}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 904.8545360565186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Once", "latency_ms": 1995.7923889160156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "1", "latency_ms": 934.4727993011475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1221}, "3": {"k": 3, "answer": "Once", "latency_ms": 2053.3969402313232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1834}, "4": {"k": 4, "answer": "1", "latency_ms": 979.3603420257568, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2444}, "5": {"k": 5, "answer": "1", "latency_ms": 1471.7512130737305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3051}, "6": {"k": 6, "answer": "1", "latency_ms": 1706.7852020263672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3682}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 1336.3959789276123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2016", "latency_ms": 1531.665325164795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "2002", "latency_ms": 1620.0411319732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "2010", "latency_ms": 2176.302194595337, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1938}, "4": {"k": 4, "answer": "2010", "latency_ms": 1810.441493988037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2619}, "5": {"k": 5, "answer": "2010", "latency_ms": 1459.7084522247314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "2016", "latency_ms": 1682.7569007873535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3855}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 1674.1557121276855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2438.600778579712, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "Not stated.", "latency_ms": 2311.1939430236816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "37", "latency_ms": 924.246072769165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "37", "latency_ms": 1515.178918838501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "37", "latency_ms": 838.0081653594971, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "37", "latency_ms": 1449.9778747558594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3896}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 2662.9912853240967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 3009.397029876709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 2929.981231689453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 2825.7241249084473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1815}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 2981.9185733795166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 3539.1573905944824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3082}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 2985.5411052703857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3712}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 4991.219282150269, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 2399.723768234253, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 587}, "2": {"k": 2, "answer": "Corey, Cory", "latency_ms": 2403.7303924560547, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1188}, "3": {"k": 3, "answer": "Corey, Cory", "latency_ms": 2873.6934661865234, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Corey, Cory", "latency_ms": 2130.070209503174, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2481}, "5": {"k": 5, "answer": "Corey, Cory", "latency_ms": 2617.574691772461, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3134}, "6": {"k": 6, "answer": "Corey, Cory, Gowdy, Goudy", "latency_ms": 5547.756195068359, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3755}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 2582.9577445983887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2005.1043033599854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 662}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2406.3925743103027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1374}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1842.7259922027588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2002}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3411.017417907715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2669}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2855.28826713562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3298}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3158.1106185913086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3901}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 461.84754371643066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 1463.024377822876, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "159", "latency_ms": 1445.6348419189453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "159", "latency_ms": 1733.8201999664307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "159", "latency_ms": 655.8151245117188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2732}, "5": {"k": 5, "answer": "159", "latency_ms": 1997.9522228240967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3379}, "6": {"k": 6, "answer": "159", "latency_ms": 1191.0791397094727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4038}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 2109.678268432617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Egan", "latency_ms": 2008.7494850158691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 581}, "2": {"k": 2, "answer": "Egan", "latency_ms": 2028.993844985962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Egan", "latency_ms": 1748.7068176269531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "Egan", "latency_ms": 1515.1917934417725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "Egan", "latency_ms": 1802.3931980133057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3081}, "6": {"k": 6, "answer": "Egan", "latency_ms": 1235.3558540344238, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3737}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 2364.8581504821777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pete Maravich", "latency_ms": 1902.6014804840088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Pete Maravich", "latency_ms": 2961.0090255737305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Pete Maravich", "latency_ms": 1648.2677459716797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2538.431167602539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2537}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2611.5238666534424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3150}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2372.666358947754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 2355.50594329834, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Right hand", "latency_ms": 1423.8035678863525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 1695.1813697814941, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1154}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 1526.1001586914062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1756}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 861.8271350860596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2378}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 2000.5943775177002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2972}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 1234.9097728729248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3526}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 4034.7719192504883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Donald Duck", "latency_ms": 1199.5184421539307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Donald Duck", "latency_ms": 2274.0278244018555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Donald Duck", "latency_ms": 2051.563501358032, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Donald Duck", "latency_ms": 525.5939960479736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Donald Duck", "latency_ms": 2495.443344116211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3205}, "6": {"k": 6, "answer": "Donald Duck", "latency_ms": 1561.763048171997, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3857}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 1635.1730823516846, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2400.325298309326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "Bernard Mayes", "latency_ms": 3170.0172424316406, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "Bernard Mayes", "latency_ms": 2963.2654190063477, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1910}, "4": {"k": 4, "answer": "Bernard Hill", "latency_ms": 2048.767566680908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2563}, "5": {"k": 5, "answer": "Bernard Mayes", "latency_ms": 2037.3733043670654, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "Bernard Mayes", "latency_ms": 2908.9229106903076, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3875}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2018", "latency_ms": 2550.309181213379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2018", "latency_ms": 3082.4809074401855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 3664.2796993255615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1217}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 3830.758810043335, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1847}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 2594.0115451812744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2443}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 3476.0029315948486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 3688.985824584961, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 1225.7027626037598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2392.9357528686523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2109.8179817199707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1188}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2064.519166946411, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2732.8672409057617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2500}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1895.7786560058594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3096}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1652.846097946167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3706}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 1665.7755374908447, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Claire Holt", "latency_ms": 1784.3284606933594, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Claire Holt", "latency_ms": 2640.80548286438, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "Claire Holt", "latency_ms": 2094.6695804595947, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1799}, "4": {"k": 4, "answer": "Claire Holt", "latency_ms": 1598.6361503601074, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2435}, "5": {"k": 5, "answer": "Claire Holt", "latency_ms": 1583.341121673584, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3006}, "6": {"k": 6, "answer": "Claire Holt", "latency_ms": 2087.9616737365723, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3646}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living organisms.", "latency_ms": 2892.833471298218, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in the biosphere", "latency_ms": 2438.581943511963, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 700}, "2": {"k": 2, "answer": "in all land-living organisms, soils, and plants", "latency_ms": 5938.6045932769775, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 1350}, "3": {"k": 3, "answer": "in all land-living organisms", "latency_ms": 3596.5826511383057, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "in all land-living organisms and soils", "latency_ms": 5615.549325942993, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2601}, "5": {"k": 5, "answer": "in all land-living organisms, soils, and plants", "latency_ms": 6374.581813812256, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 3308}, "6": {"k": 6, "answer": "in all land-living organisms, soils, and plants", "latency_ms": 4931.042432785034, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 3961}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "Vijay Raghavendra", "latency_ms": 3369.9238300323486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Akul Balaji", "latency_ms": 2743.9403533935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Akul Balaji", "latency_ms": 2667.4656867980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "Season 2: Akul Balaji, Season 4: Pratham, Season 5: Chandan Shetty", "latency_ms": 8417.364358901978, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Akul Balaji", "latency_ms": 2067.5089359283447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Akul Balaji", "latency_ms": 1687.9050731658936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Akul Balaji", "latency_ms": 1767.2548294067383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3797}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 3827.820062637329, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kanab, Utah", "latency_ms": 3197.272777557373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "Kanab, Utah, Lake Powell", "latency_ms": 4237.417221069336, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Kanab, Utah, Lake Powell, Page, Arizona", "latency_ms": 5515.429258346558, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1929}, "4": {"k": 4, "answer": "Utah, Arizona, Wyoming, Oroville, California, Lake Powell, Kanab, Page", "latency_ms": 8269.360303878784, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 2574}, "5": {"k": 5, "answer": "Utah, Arizona, Wyoming, Oroville, California, Lake Powell, Page, Arizona, Kanab, Utah", "latency_ms": 10575.472116470337, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 3201}, "6": {"k": 6, "answer": "Utah, Arizona, Wyoming, Oroville, California, Lake Powell, Page, Arizona, Kanab, Utah", "latency_ms": 10985.812902450562, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 3819}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 1639.1515731811523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kevin Kline", "latency_ms": 2184.9732398986816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Kevin Kline", "latency_ms": 1703.1302452087402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1323}, "3": {"k": 3, "answer": "Kevin Kline", "latency_ms": 2616.6882514953613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1957}, "4": {"k": 4, "answer": "Kevin Kline", "latency_ms": 2344.2978858947754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "Kevin Kline", "latency_ms": 2149.026870727539, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3241}, "6": {"k": 6, "answer": "Kevin Kline", "latency_ms": 3175.1177310943604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3908}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Canada to Lake Winnipeg.", "latency_ms": 4815.296173095703, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 2230.059862136841, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 708}, "2": {"k": 2, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 3013.4096145629883, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1438}, "3": {"k": 3, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 2479.7732830047607, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2136}, "4": {"k": 4, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 3188.7283325195312, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2791}, "5": {"k": 5, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 2806.2028884887695, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3435}, "6": {"k": 6, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 2749.7525215148926, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4040}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 1792.9856777191162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 2026.7863273620605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome, Italy", "latency_ms": 2132.8389644622803, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Rome, Italy", "latency_ms": 3050.091028213501, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 2695.5056190490723, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 2967.3616886138916, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3108}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 1695.4450607299805, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3743}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "CE Mark or Measure number", "latency_ms": 2512.657403945923, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "manufacturing company or site", "latency_ms": 2741.96457862854, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "the manufacturing company or site", "latency_ms": 3560.4300498962402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1255}, "3": {"k": 3, "answer": "manufacturing company or site", "latency_ms": 2700.6993293762207, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "the manufacturing company or site", "latency_ms": 3466.3612842559814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2406}, "5": {"k": 5, "answer": "the manufacturing company or site", "latency_ms": 3162.600517272949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2980}, "6": {"k": 6, "answer": "the manufacturing company or site", "latency_ms": 2054.793357849121, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3601}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia, methanol.", "latency_ms": 3683.3136081695557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 4579.250812530518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 5483.017444610596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1340}, "3": {"k": 3, "answer": "Hydrogen fluoride, ammonia, methanol, DNA, proteins", "latency_ms": 5847.83935546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1986}, "4": {"k": 4, "answer": "hydrogen fluoride, ammonia, methanol, DNA, proteins", "latency_ms": 5544.782876968384, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2596}, "5": {"k": 5, "answer": "hydrogen fluoride, ammonia, methanol, DNA, proteins", "latency_ms": 5126.293182373047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol, DNA, proteins", "latency_ms": 4831.329584121704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3885}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Once in a Lifetime", "latency_ms": 1491.5845394134521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 1628.8011074066162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "1988", "latency_ms": 1212.7947807312012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1196}, "3": {"k": 3, "answer": "1988", "latency_ms": 1724.0784168243408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1799}, "4": {"k": 4, "answer": "1988", "latency_ms": 1563.8411045074463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2390}, "5": {"k": 5, "answer": "1988", "latency_ms": 2043.1544780731201, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3000}, "6": {"k": 6, "answer": "1988", "latency_ms": 1013.5207176208496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3619}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 1857.3741912841797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Manille", "latency_ms": 1219.7740077972412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Manille", "latency_ms": 501.43933296203613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Manille", "latency_ms": 2552.0288944244385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1792}, "4": {"k": 4, "answer": "Manille", "latency_ms": 1804.1210174560547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2373}, "5": {"k": 5, "answer": "Manille", "latency_ms": 999.176025390625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2944}, "6": {"k": 6, "answer": "Manille", "latency_ms": 1860.7690334320068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3530}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 2427.2756576538086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Five percent", "latency_ms": 1006.8724155426025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "2% to 16%", "latency_ms": 2179.6820163726807, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "2% to 16%", "latency_ms": 3313.9989376068115, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1845}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 3734.68017578125, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2458}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 3817.7859783172607, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3087}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 3573.643922805786, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3775}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 1885.4262828826904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1975", "latency_ms": 2544.344663619995, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "1975", "latency_ms": 2573.6043453216553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1185}, "3": {"k": 3, "answer": "1975", "latency_ms": 2476.1178493499756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1763}, "4": {"k": 4, "answer": "1975", "latency_ms": 2339.789628982544, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2388}, "5": {"k": 5, "answer": "1975", "latency_ms": 1564.5391941070557, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3008}, "6": {"k": 6, "answer": "1975", "latency_ms": 1764.1079425811768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3593}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 2411.2486839294434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2982.435464859009, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Lionel Richie", "latency_ms": 1693.3465003967285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1199}, "3": {"k": 3, "answer": "Lionel Richie", "latency_ms": 3181.94842338562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1806}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 2674.9484539031982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2421}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 2318.202257156372, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3068}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 2127.516746520996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3662}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert, 2nd Baron Baltimore", "latency_ms": 4495.142459869385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "George Calvert", "latency_ms": 2137.4542713165283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "George Calvert", "latency_ms": 1832.9112529754639, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Cecil Calvert", "latency_ms": 2559.661388397217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Cecil Calvert", "latency_ms": 3144.0224647521973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2629}, "5": {"k": 5, "answer": "Cecil Calvert", "latency_ms": 3294.2347526550293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3323}, "6": {"k": 6, "answer": "Cecil Calvert and his brother Leonard Calvert", "latency_ms": 4468.5351848602295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3953}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 2284.5239639282227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiger Woods", "latency_ms": 2314.5923614501953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Jack Nicklaus", "latency_ms": 2226.5870571136475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Jack Nicklaus", "latency_ms": 2391.209363937378, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "Jack Nicklaus", "latency_ms": 2580.397129058838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Jack Nicklaus", "latency_ms": 2549.7210025787354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3115}, "6": {"k": 6, "answer": "Jack Nicklaus", "latency_ms": 2623.2669353485107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3719}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 2904.8471450805664, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3260.4308128356934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "200 to 500 mg", "latency_ms": 2537.2679233551025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg", "latency_ms": 2448.288679122925, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1889}, "4": {"k": 4, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 5801.354885101318, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 5992.110252380371, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 5380.3863525390625, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3897}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 3263.409376144409, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham United", "latency_ms": 2346.864938735962, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 586}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 2097.9814529418945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 2086.871385574341, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1805}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 1774.7831344604492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2397}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 2360.5878353118896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2916}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 2371.1609840393066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3533}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 2368.354320526123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Paris and Spain", "latency_ms": 2115.4446601867676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "a friend's house or a nearby park", "latency_ms": 3474.6522903442383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "a friend's house or a nearby park", "latency_ms": 4134.847402572632, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "a friend's house or a nearby park", "latency_ms": 3170.039415359497, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "a friend's house or a nearby park", "latency_ms": 4187.477111816406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3259}, "6": {"k": 6, "answer": "a friend's house or a nearby park", "latency_ms": 4001.465082168579, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh, Scotland", "latency_ms": 3094.3498611450195, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 2989.0058040618896, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 2640.1829719543457, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1372}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 2956.0389518737793, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2068}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 2372.3058700561523, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 2528.733968734741, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3333}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 2062.66450881958, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3984}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 2669.0595149993896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1700.9241580963135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2255.9781074523926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Roman Reigns", "latency_ms": 1505.5716037750244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Bray Wyatt", "latency_ms": 2632.4639320373535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2609}, "5": {"k": 5, "answer": "Bray Wyatt", "latency_ms": 2120.373010635376, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3226}, "6": {"k": 6, "answer": "Bray Wyatt", "latency_ms": 1614.9139404296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3897}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 2220.4670906066895, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Southport, North Carolina", "latency_ms": 2943.4964656829834, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Southport, North Carolina.", "latency_ms": 3778.1574726104736, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Southport, North Carolina.", "latency_ms": 2306.86354637146, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Southport, North Carolina.", "latency_ms": 3029.280424118042, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Southport, North Carolina.", "latency_ms": 3490.1113510131836, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Southport, North Carolina.", "latency_ms": 2822.5061893463135, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3759}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 1589.5562171936035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2213.533878326416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "Sylvia F. Porter", "latency_ms": 2333.4925174713135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Sylvia F. Porter", "latency_ms": 2580.389976501465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 2848.973512649536, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 2960.676431655884, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3171}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 3051.332950592041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3846}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 1670.954942703247, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 2111.4132404327393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 714}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 2312.8902912139893, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1414}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 2469.5279598236084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2151}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 2923.6764907836914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2897}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 1793.6489582061768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3534}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 2088.5696411132812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4176}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 981.5199375152588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 1415.942668914795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "Max", "latency_ms": 1270.7419395446777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1247}, "3": {"k": 3, "answer": "Max", "latency_ms": 1429.7311305999756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Max", "latency_ms": 1490.9629821777344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2452}, "5": {"k": 5, "answer": "Max", "latency_ms": 1436.0253810882568, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Max", "latency_ms": 1479.5079231262207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3796}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 2291.7263507843018, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2903.207540512085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2203.7501335144043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2164.0403270721436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "Megan Follows", "latency_ms": 1893.5377597808838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Megan Follows", "latency_ms": 2651.8332958221436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Megan Follows", "latency_ms": 2436.1464977264404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3790}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "Boxer Rebellion.", "latency_ms": 1727.9915809631348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Women starting to serve in limited military roles.", "latency_ms": 4653.503656387329, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "World War was not, but Exposition Universelle and Paris 1900 chess tournament were.", "latency_ms": 7064.600229263306, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "World Exposition", "latency_ms": 1823.3110904693604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "World Exposition", "latency_ms": 2431.7543506622314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "World Exposition, Paris 1900 chess tournament, Women starting to serve in military roles.", "latency_ms": 6237.555980682373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3271}, "6": {"k": 6, "answer": "Exposition Universelle", "latency_ms": 2702.29172706604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3863}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 1349.7810363769531, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Brisbane Roar's theme song", "latency_ms": 3430.7610988616943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 670}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 2964.118480682373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Empowerment", "latency_ms": 1335.1428508758545, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Empowerment", "latency_ms": 2095.506429672241, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2587}, "5": {"k": 5, "answer": "Empowerment", "latency_ms": 2113.4955883026123, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3280}, "6": {"k": 6, "answer": "Empowerment", "latency_ms": 2384.1519355773926, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3951}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams' front offices", "latency_ms": 2046.5281009674072, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "National Football League franchises", "latency_ms": 2562.8859996795654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "National Football League franchises", "latency_ms": 2151.6454219818115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "National Football League franchises", "latency_ms": 3210.399389266968, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "National Football League franchises", "latency_ms": 2359.328031539917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2513}, "5": {"k": 5, "answer": "National Football League franchises", "latency_ms": 2354.529857635498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "National Football League franchises", "latency_ms": 2132.683515548706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3722}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 1795.4833507537842, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Marshall", "latency_ms": 962.9144668579102, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "James Marshall", "latency_ms": 2074.950695037842, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "James Marshall", "latency_ms": 1491.7631149291992, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": "James Marshall", "latency_ms": 1269.7925567626953, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2546}, "5": {"k": 5, "answer": "James Marshall", "latency_ms": 2283.4434509277344, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3220}, "6": {"k": 6, "answer": "James Marshall", "latency_ms": 1924.6647357940674, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3781}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 2199.6541023254395, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 2386.1358165740967, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 2457.597494125366, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 1926.422357559204, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 2704.193592071533, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2505}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 2239.1629219055176, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3136}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 2359.611988067627, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "9", "latency_ms": 1139.3225193023682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2340.4011726379395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1877.211332321167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2953.976631164551, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2648.2889652252197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2489}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1666.1975383758545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3139}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2968.9440727233887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3745}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3790.126323699951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart", "latency_ms": 2488.105535507202, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4557.092189788818, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1227}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4737.6861572265625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1863}, "4": {"k": 4, "answer": "Charles Hart", "latency_ms": 1795.0499057769775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2497}, "5": {"k": 5, "answer": "Charles Hart", "latency_ms": 1561.577558517456, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3161}, "6": {"k": 6, "answer": "Charles Hart", "latency_ms": 2035.1693630218506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3836}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 2332.6096534729004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northern Europe and Central European", "latency_ms": 2405.7838916778564, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "Northern Europe and Central European", "latency_ms": 3276.378631591797, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Northern Europe and Central European cultures.", "latency_ms": 3729.4511795043945, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "Northern Europe and Central European cultures.", "latency_ms": 2841.283082962036, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Northern Europe and Central European cultures.", "latency_ms": 3238.4324073791504, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3406}, "6": {"k": 6, "answer": "Northern Europe and Central Europe", "latency_ms": 3268.6023712158203, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4098}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 2467.7395820617676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 1379.7760009765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 2491.2350177764893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 2167.980670928955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "16481651", "latency_ms": 2675.4462718963623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2648}, "5": {"k": 5, "answer": "16481651", "latency_ms": 2466.186285018921, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3409}, "6": {"k": 6, "answer": "16481651", "latency_ms": 3317.4076080322266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4087}}}
