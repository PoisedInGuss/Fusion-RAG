{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "June 15, 2023", "latency_ms": 3108.196496963501, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 22, 2018", "latency_ms": 3470.0653553009033, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "June 22, 2018", "latency_ms": 2327.7060985565186, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "June 22, 2018", "latency_ms": 2873.1231689453125, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "June 22, 2018", "latency_ms": 3430.344581604004, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 3231.8966388702393, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3106}, "6": {"k": 6, "answer": "June 22, 2018", "latency_ms": 2376.4922618865967, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3761}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Freestyle, Nordic Combined, Ski Jumping, Biathlon.", "latency_ms": 6325.008869171143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Freestyle skiing", "latency_ms": 1863.257884979248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Freestyle, Cross-country", "latency_ms": 2119.774341583252, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1487}, "3": {"k": 3, "answer": "Freestyle, Cross-country", "latency_ms": 2198.15731048584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2139}, "4": {"k": 4, "answer": "Freestyle, Cross-country, Alpine", "latency_ms": 2811.2010955810547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2771}, "5": {"k": 5, "answer": "Alpine, Freestyle, Cross-country", "latency_ms": 3739.570379257202, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3533}, "6": {"k": 6, "answer": "Alpine, Freestyle, Cross-country", "latency_ms": 3710.049629211426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4196}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "Arianwen Parkes-Lockwood", "latency_ms": 3069.5602893829346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Aldo Mignone", "latency_ms": 2786.8411540985107, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Aldo Mignone", "latency_ms": 2183.8784217834473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Aldo Mignone", "latency_ms": 2220.9901809692383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Aldo Mignone", "latency_ms": 2998.6088275909424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Aldo Mignone", "latency_ms": 2569.8485374450684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3064}, "6": {"k": 6, "answer": "Aldo Mignone", "latency_ms": 3437.4008178710938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3684}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "Bengals, Dolphins, Broncos, Chargers.", "latency_ms": 4330.187082290649, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Denver Broncos", "latency_ms": 1252.0818710327148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 661}, "2": {"k": 2, "answer": "Broncos, Bengals", "latency_ms": 2128.103017807007, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Broncos, Bengals, Chargers", "latency_ms": 3245.8462715148926, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "Broncos, Bengals, Chargers", "latency_ms": 2558.7985515594482, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Broncos, Bengals, Chargers, Dolphins", "latency_ms": 2711.793899536133, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3162}, "6": {"k": 6, "answer": "Bengals, Broncos, Dolphins, Chargers", "latency_ms": 4563.639402389526, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3790}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "December 8, 1985", "latency_ms": 3254.823684692383, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 December 1985", "latency_ms": 2787.7140045166016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 727}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 2535.8707904815674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1444}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 2753.225564956665, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2083}, "4": {"k": 4, "answer": "December 8, 1985", "latency_ms": 3373.4734058380127, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 2891}, "5": {"k": 5, "answer": "December 8, 1985", "latency_ms": 3615.201473236084, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 3592}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 2523.8518714904785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4298}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "Spanish Moss", "latency_ms": 1266.4644718170166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ivory-billed woodpecker", "latency_ms": 3950.8469104766846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "Spanish moss", "latency_ms": 1844.916820526123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Spanish moss", "latency_ms": 1562.3435974121094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Spanish moss", "latency_ms": 1622.6060390472412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2605}, "5": {"k": 5, "answer": "Spanish moss", "latency_ms": 2020.430088043213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3206}, "6": {"k": 6, "answer": "Spanish moss", "latency_ms": 1592.9536819458008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3839}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "I-IV", "latency_ms": 1650.9368419647217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Class II or III", "latency_ms": 2909.783363342285, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 730}, "2": {"k": 2, "answer": "Canadian Cardiovascular Society", "latency_ms": 2366.929292678833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1494}, "3": {"k": 3, "answer": "Canadian Cardiovascular Society", "latency_ms": 2909.2772006988525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2250}, "4": {"k": 4, "answer": "Canadian Cardiovascular Society", "latency_ms": 2695.418357849121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2897}, "5": {"k": 5, "answer": "Canadian Cardiovascular Society grading", "latency_ms": 2523.1869220733643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3686}, "6": {"k": 6, "answer": "Canadian Cardiovascular Society grading", "latency_ms": 2784.956693649292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4395}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Mick Hucknall and Neil Moss", "latency_ms": 3269.4923877716064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2578.8135528564453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2138.4832859039307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1158}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3053.4632205963135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1820.9335803985596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2462}, "5": {"k": 5, "answer": "Eurythmics", "latency_ms": 3055.9566020965576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3079}, "6": {"k": 6, "answer": "Eurythmics", "latency_ms": 3116.426944732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3723}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 686.9714260101318, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 1534.6345901489258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "three", "latency_ms": 1278.9688110351562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1230}, "3": {"k": 3, "answer": "3", "latency_ms": 661.6129875183105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "three", "latency_ms": 2219.0444469451904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2507}, "5": {"k": 5, "answer": "three", "latency_ms": 1232.7241897583008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3130}, "6": {"k": 6, "answer": "3", "latency_ms": 1178.485631942749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3814}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "A cake.", "latency_ms": 2257.139205932617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Biscuit-sized cakes", "latency_ms": 3025.3477096557617, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "biscuit-sized cakes", "latency_ms": 1590.8491611480713, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "cake", "latency_ms": 2003.1564235687256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1764}, "4": {"k": 4, "answer": "A cake.", "latency_ms": 1350.8031368255615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "A cake.", "latency_ms": 2097.8646278381348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3040}, "6": {"k": 6, "answer": "A cake.", "latency_ms": 1866.5838241577148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Seth MacFarlane", "latency_ms": 2748.1086254119873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seth MacFarlane", "latency_ms": 2492.7005767822266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "Seth MacFarlane", "latency_ms": 2505.976676940918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Seth MacFarlane", "latency_ms": 2654.25181388855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 2725.900888442993, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2554}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 2453.4406661987305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3178}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 3174.764394760132, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3812}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "Heroin", "latency_ms": 1290.477991104126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amphetamines", "latency_ms": 1977.3778915405273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Amphetamines", "latency_ms": 1876.2733936309814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1289}, "3": {"k": 3, "answer": "Amphetamines", "latency_ms": 2452.5177478790283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1866}, "4": {"k": 4, "answer": "Amphetamines", "latency_ms": 2410.789728164673, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2506}, "5": {"k": 5, "answer": "Amphetamines", "latency_ms": 1558.2380294799805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3114}, "6": {"k": 6, "answer": "Amphetamines", "latency_ms": 2394.8898315429688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3719}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "15 weeks", "latency_ms": 1783.874273300171, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a week", "latency_ms": 2026.2794494628906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 566}, "2": {"k": 2, "answer": "1 week", "latency_ms": 975.0533103942871, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1169}, "3": {"k": 3, "answer": "1 week", "latency_ms": 2054.3901920318604, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1781}, "4": {"k": 4, "answer": "1 week", "latency_ms": 1448.7652778625488, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2400}, "5": {"k": 5, "answer": "1 week", "latency_ms": 1825.0079154968262, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2973}, "6": {"k": 6, "answer": "1 week", "latency_ms": 1818.441390991211, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3528}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "Yushan, China", "latency_ms": 2483.74080657959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sheffield, England", "latency_ms": 2382.826089859009, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Yushan, China", "latency_ms": 3237.1346950531006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "Yushan, China.", "latency_ms": 3607.1434020996094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Yushan, China.", "latency_ms": 3647.8044986724854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "Yushan, China", "latency_ms": 3723.466396331787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3143}, "6": {"k": 6, "answer": "Yushan, China.", "latency_ms": 3064.5408630371094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3752}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "Thad Luckinbill", "latency_ms": 3199.918270111084, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3177.4704456329346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2750.900983810425, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2421.032428741455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1971.1883068084717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2623}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2959.8097801208496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2170.222759246826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3906}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 967.6990509033203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1983", "latency_ms": 2061.366319656372, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "1983", "latency_ms": 1544.2008972167969, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1308}, "3": {"k": 3, "answer": "1983", "latency_ms": 1726.7274856567383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1922}, "4": {"k": 4, "answer": "1983", "latency_ms": 1057.279109954834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2597}, "5": {"k": 5, "answer": "1983", "latency_ms": 1855.316400527954, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3254}, "6": {"k": 6, "answer": "1983", "latency_ms": 1045.51362991333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3893}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "J-Rock", "latency_ms": 1193.7940120697021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alexz Johnson", "latency_ms": 1593.7581062316895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Alexz Johnson", "latency_ms": 1086.210012435913, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Alexz Johnson", "latency_ms": 2118.124485015869, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Alexz Johnson", "latency_ms": 1601.1688709259033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Alexz Johnson", "latency_ms": 1615.7255172729492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3289}, "6": {"k": 6, "answer": "Alexz Johnson", "latency_ms": 1360.1453304290771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3936}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "March 15, 2002", "latency_ms": 2233.926773071289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2002", "latency_ms": 2609.715223312378, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 629}, "2": {"k": 2, "answer": "March 15, 2002", "latency_ms": 2586.203098297119, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "March 15, 2002", "latency_ms": 3642.8558826446533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "March 15, 2002", "latency_ms": 2777.888059616089, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2557}, "5": {"k": 5, "answer": "March 15, 2002", "latency_ms": 2625.3905296325684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "March 15, 2002", "latency_ms": 2632.0419311523438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3847}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "Master Sergeant", "latency_ms": 1095.4573154449463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Master sergeant", "latency_ms": 1252.1934509277344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 718}, "2": {"k": 2, "answer": "Master sergeant", "latency_ms": 1541.555404663086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Master Sergeant", "latency_ms": 1297.2898483276367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1858}, "4": {"k": 4, "answer": "Master Sergeant", "latency_ms": 2551.950454711914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Master Sergeant", "latency_ms": 1789.4830703735352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3052}, "6": {"k": 6, "answer": "Master Sergeant", "latency_ms": 2054.1956424713135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3721}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 2040.7905578613281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Richard Stallman", "latency_ms": 1290.0190353393555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 697}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 1306.4405918121338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1378}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 2043.6947345733643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2056}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 1256.0474872589111, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2701}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 2129.4963359832764, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3340}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 2119.2901134490967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3970}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "Manu Bhaker", "latency_ms": 1902.7085304260254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1621.0074424743652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1851.208209991455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1423.311710357666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1981.0876846313477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Heena Sidhu", "latency_ms": 1364.8655414581299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3058}, "6": {"k": 6, "answer": "Heena Sidhu", "latency_ms": 2448.1279850006104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3706}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Ed Roland", "latency_ms": 1063.842535018921, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 992.6893711090088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 1433.7632656097412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 1006.1647891998291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 1277.7292728424072, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2582}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 1191.6377544403076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3242}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 1298.2807159423828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3880}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "Retired", "latency_ms": 812.9727840423584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miami Heat", "latency_ms": 1474.839210510254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 631}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 950.0010013580322, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 1462.4927043914795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1849}, "4": {"k": 4, "answer": "Chicago Bulls", "latency_ms": 1741.9745922088623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 1286.1380577087402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3059}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 1063.6210441589355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3656}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "Guarani (PYG)", "latency_ms": 2707.1375846862793, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Guarani (PYG)", "latency_ms": 3193.8459873199463, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "PYG", "latency_ms": 1801.0263442993164, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "PYG", "latency_ms": 1184.4391822814941, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "PYG", "latency_ms": 1558.873176574707, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 2431}, "5": {"k": 5, "answer": "PYG", "latency_ms": 1330.8241367340088, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3069}, "6": {"k": 6, "answer": "PYG", "latency_ms": 1260.0960731506348, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3701}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "Midazolam.", "latency_ms": 2292.7160263061523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Benzodiazepines", "latency_ms": 1867.2502040863037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 678}, "2": {"k": 2, "answer": "Midazolam", "latency_ms": 1394.93989944458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1362}, "3": {"k": 3, "answer": "Midazolam", "latency_ms": 2429.751396179199, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2076}, "4": {"k": 4, "answer": "Midazolam", "latency_ms": 2674.386501312256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2758}, "5": {"k": 5, "answer": "Midazolam", "latency_ms": 1387.5372409820557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3473}, "6": {"k": 6, "answer": "Midazolam", "latency_ms": 2631.917715072632, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4153}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 1656.7440032958984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "25,772 years", "latency_ms": 1535.1755619049072, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "25,772 years", "latency_ms": 2412.2278690338135, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1302}, "3": {"k": 3, "answer": "25,772 years", "latency_ms": 1851.9632816314697, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "25,772 years", "latency_ms": 1874.9258518218994, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "25,772 years", "latency_ms": 2049.335479736328, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3183}, "6": {"k": 6, "answer": "25,772 years", "latency_ms": 2233.8554859161377, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3864}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 1072.5040435791016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Texas A&M Aggies", "latency_ms": 2235.98313331604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Texas A&M Aggies", "latency_ms": 2517.8017616271973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Texas A&M Aggies", "latency_ms": 1983.304500579834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Texas A&M Aggies", "latency_ms": 2215.9836292266846, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2541}, "5": {"k": 5, "answer": "Texas A&M Aggies", "latency_ms": 1276.862621307373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3161}, "6": {"k": 6, "answer": "Texas A&M Aggies", "latency_ms": 2205.557346343994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3878}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and Non-Renewable.", "latency_ms": 4611.302614212036, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable or non-renewable", "latency_ms": 3364.4943237304688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable or non-renewable", "latency_ms": 2182.3480129241943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1428}, "3": {"k": 3, "answer": "renewable or non-renewable", "latency_ms": 2960.77299118042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2178}, "4": {"k": 4, "answer": "renewable or non-renewable", "latency_ms": 3431.879758834839, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2910}, "5": {"k": 5, "answer": "renewable or non-renewable", "latency_ms": 3175.795793533325, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3588}, "6": {"k": 6, "answer": "renewable or non-renewable", "latency_ms": 3145.486831665039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4288}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "New life and fertility", "latency_ms": 1925.8041381835938, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parental devotion", "latency_ms": 1309.4494342803955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Parental devotion", "latency_ms": 1892.399549484253, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Parental devotion and filial values", "latency_ms": 2051.154613494873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "Purity", "latency_ms": 1312.1767044067383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2504}, "5": {"k": 5, "answer": "Purity", "latency_ms": 1559.2193603515625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3139}, "6": {"k": 6, "answer": "Purity", "latency_ms": 1270.486831665039, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Virat Kohli 286 runs", "latency_ms": 2980.801582336426, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2155.165910720825, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2423.203468322754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2223.1974601745605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1887}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1896.4817523956299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2370.1374530792236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1152.7776718139648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3703}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "the antimicrobial action of metal ions.", "latency_ms": 3335.468530654907, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals", "latency_ms": 2497.074604034424, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "biocidal effect of metals", "latency_ms": 2687.4351501464844, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "biocidal effect of metals", "latency_ms": 2657.874345779419, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2103}, "4": {"k": 4, "answer": "biocidal effect of metals", "latency_ms": 2299.1230487823486, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2841}, "5": {"k": 5, "answer": "biocidal effect of metals", "latency_ms": 2596.3141918182373, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3568}, "6": {"k": 6, "answer": "biocidal effect of metals", "latency_ms": 2731.433391571045, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4258}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "Dustin Higgs", "latency_ms": 1232.1054935455322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Coburn", "latency_ms": 2255.622625350952, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "James Coburn", "latency_ms": 1885.7612609863281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1294}, "3": {"k": 3, "answer": "James Coburn", "latency_ms": 2104.2072772979736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "Billy Bailey", "latency_ms": 1279.9067497253418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2719.604015350342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2400.1874923706055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the auction.", "latency_ms": 3054.2221069335938, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the conclusion of play", "latency_ms": 2262.467622756958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 550}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 2221.1344242095947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1122}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 2594.1672325134277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1728}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 3150.6989002227783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2310}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 2429.3363094329834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2926}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 2198.993444442749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3511}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Afghanistan", "latency_ms": 2117.442846298218, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 1466.6368961334229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 694}, "2": {"k": 2, "answer": "Afghanistan", "latency_ms": 1603.473424911499, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Afghanistan", "latency_ms": 1815.83833694458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2124}, "4": {"k": 4, "answer": "Afghanistan", "latency_ms": 1642.5867080688477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2785}, "5": {"k": 5, "answer": "Afghanistan", "latency_ms": 1042.8977012634277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3509}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 1729.292631149292, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4243}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "Vasoconstriction, Platelet Plug Formation, Coagulation.", "latency_ms": 4423.2306480407715, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 5641.006946563721, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2371.567726135254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 4115.894556045532, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2082}, "4": {"k": 4, "answer": "primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 6008.905649185181, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2807}, "5": {"k": 5, "answer": "primary hemostasis, secondary hemostasis, and fibrin cross-linking", "latency_ms": 6151.31950378418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3521}, "6": {"k": 6, "answer": "primary hemostasis, secondary hemostasis, and fibrin cross-linking", "latency_ms": 5598.2983112335205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4173}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "Sebastian Hunsinger", "latency_ms": 2699.578285217285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shawn Roberts", "latency_ms": 2133.732318878174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "Sebastian HÃ¼lk", "latency_ms": 2467.1669006347656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1374}, "3": {"k": 3, "answer": "Sebastian Hedges Thomas", "latency_ms": 2760.895252227783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2068}, "4": {"k": 4, "answer": "Presley Smith", "latency_ms": 1469.7597026824951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2768}, "5": {"k": 5, "answer": "Presley Smith", "latency_ms": 2150.8498191833496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3398}, "6": {"k": 6, "answer": "Presley Smith", "latency_ms": 1817.6114559173584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4044}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "20 November 1989", "latency_ms": 2570.448160171509, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "20 November 1989", "latency_ms": 3494.4541454315186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 2482.733726501465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 3245.6510066986084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1890}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 3296.888589859009, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2551}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 1978.4917831420898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 2437.9305839538574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3861}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "23 June 2016", "latency_ms": 1979.1259765625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "23 June 2016", "latency_ms": 2451.5578746795654, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "23 June 2016", "latency_ms": 2418.9579486846924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1348}, "3": {"k": 3, "answer": "23 June 2016", "latency_ms": 2605.8313846588135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2020}, "4": {"k": 4, "answer": "23 June 2016", "latency_ms": 2778.4717082977295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2685}, "5": {"k": 5, "answer": "23 June 2016", "latency_ms": 2946.063756942749, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3299}, "6": {"k": 6, "answer": "23 June 2016", "latency_ms": 2980.177879333496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3971}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 1941.342830657959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Burj Khalifa", "latency_ms": 1893.7745094299316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 679}, "2": {"k": 2, "answer": "Burj Khalifa", "latency_ms": 2876.389503479004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1360}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 1912.1663570404053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 3175.5530834198, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2612}, "5": {"k": 5, "answer": "Burj Khalifa", "latency_ms": 2178.042411804199, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3253}, "6": {"k": 6, "answer": "Burj Khalifa", "latency_ms": 2110.668420791626, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3944}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "Miriam Margolyes", "latency_ms": 2681.5290451049805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miranda Hart's mother is played by  Marcia Warren", "latency_ms": 5700.287103652954, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "Miranda Hart's character's mother is played by  Linda Bassett", "latency_ms": 6426.898956298828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Miranda Hart's mother is played by  Cherie Lunghi but Chummy's mother is played by:  Miranda Richardson", "latency_ms": 9758.88729095459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Miranda Hart's mother is played by  Cherie Lunghi", "latency_ms": 5549.641370773315, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Miranda Hart's mother is played by  Cherie Lunghi", "latency_ms": 4681.138515472412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3101}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2670.396089553833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3767}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Montesquieu", "latency_ms": 1298.248529434204, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montesquieu", "latency_ms": 2640.6757831573486, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 2183.537244796753, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 3675.797700881958, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2009}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 2686.581611633301, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2690}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 2941.3373470306396, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3328}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 1929.0854930877686, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3955}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Myles Garrett", "latency_ms": 1813.0366802215576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sam Bradford", "latency_ms": 1267.322301864624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2192.854642868042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Myles Garrett", "latency_ms": 2054.3313026428223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Myles Garrett", "latency_ms": 2306.8201541900635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2507}, "5": {"k": 5, "answer": "Myles Garrett", "latency_ms": 1594.630241394043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3083}, "6": {"k": 6, "answer": "Myles Garrett", "latency_ms": 2371.380567550659, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3743}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2063 BS", "latency_ms": 1879.345417022705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2672.4205017089844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2627.563238143921, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2769.883871078491, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1651.172161102295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2646}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2925.3764152526855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3358}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2869.462728500366, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4016}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "Captain John Smith", "latency_ms": 2515.991687774658, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Smith", "latency_ms": 2321.742296218872, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "John Smith", "latency_ms": 2031.4593315124512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "John Smith", "latency_ms": 1805.4139614105225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1951}, "4": {"k": 4, "answer": "John Smith", "latency_ms": 2030.2114486694336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2627}, "5": {"k": 5, "answer": "John Smith", "latency_ms": 1869.7164058685303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3237}, "6": {"k": 6, "answer": "John Smith", "latency_ms": 1780.168056488037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3921}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "Parietal cells", "latency_ms": 1697.3164081573486, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parietal cells", "latency_ms": 2370.8620071411133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 625}, "2": {"k": 2, "answer": "Parietal cells", "latency_ms": 2381.9401264190674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Parietal cells", "latency_ms": 2655.850887298584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1878}, "4": {"k": 4, "answer": "Parietal cells", "latency_ms": 2661.5025997161865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2588}, "5": {"k": 5, "answer": "Parietal cells", "latency_ms": 2754.263162612915, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3257}, "6": {"k": 6, "answer": "Parietal cells", "latency_ms": 2666.3310527801514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3912}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "Early morning.", "latency_ms": 1092.4663543701172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Two hours before waking up", "latency_ms": 2152.01473236084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 709}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 2431.3130378723145, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1372}, "3": {"k": 3, "answer": "4 a.m.", "latency_ms": 2085.9832763671875, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2012}, "4": {"k": 4, "answer": "4 a.m.", "latency_ms": 3436.3315105438232, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2676}, "5": {"k": 5, "answer": "4 a.m.", "latency_ms": 1929.6844005584717, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3360}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 2170.961618423462, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4081}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 1297.8835105895996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Idaho", "latency_ms": 1466.0978317260742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 613}, "2": {"k": 2, "answer": "Idaho", "latency_ms": 2534.402847290039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Idaho", "latency_ms": 1789.794921875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Idaho", "latency_ms": 997.1373081207275, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2603}, "5": {"k": 5, "answer": "Idaho", "latency_ms": 2315.690279006958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3262}, "6": {"k": 6, "answer": "Idaho", "latency_ms": 1779.6390056610107, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales.", "latency_ms": 8615.153074264526, "em": 0.0, "f1": 0.43478260869565216, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2656.498432159424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2934.0274333953857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1915.0238037109375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1969}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2265.2974128723145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "Pirates of the Caribbean: The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales", "latency_ms": 10699.023485183716, "em": 0.0, "f1": 0.3846153846153846, "containment": 1.0, "context_chars": 3306}, "6": {"k": 6, "answer": "1. The Curse of the Black Pearl \n2. At World's End \n3. Dead Men Tell No Tales", "latency_ms": 9318.87698173523, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3991}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 1295.7420349121094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "progressed", "latency_ms": 2018.127679824829, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 691}, "2": {"k": 2, "answer": "modulated", "latency_ms": 1785.7122421264648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1303}, "3": {"k": 3, "answer": "modulated", "latency_ms": 2290.73429107666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "modulated", "latency_ms": 2089.9858474731445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2556}, "5": {"k": 5, "answer": "modulated", "latency_ms": 1524.6326923370361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3201}, "6": {"k": 6, "answer": "modulated", "latency_ms": 2069.101095199585, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3846}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Male citizens.", "latency_ms": 1797.5423336029053, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "all full Roman citizens", "latency_ms": 2368.1576251983643, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 637}, "2": {"k": 2, "answer": "full Roman citizens", "latency_ms": 2006.4716339111328, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1296}, "3": {"k": 3, "answer": "full Roman citizens", "latency_ms": 2397.0537185668945, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1941}, "4": {"k": 4, "answer": "full Roman citizens, excluding women, slaves, and originally those outside Rome", "latency_ms": 5762.364625930786, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Adult male citizens", "latency_ms": 2367.492198944092, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3278}, "6": {"k": 6, "answer": "Adult male citizens", "latency_ms": 2361.645221710205, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3977}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2409.794807434082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "9 April 2019", "latency_ms": 2584.824323654175, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "9 April 2019", "latency_ms": 2293.43843460083, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "9 April 2019", "latency_ms": 3040.20357131958, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1925}, "4": {"k": 4, "answer": "9 April 2019", "latency_ms": 2820.96529006958, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2611}, "5": {"k": 5, "answer": "9 April 2019", "latency_ms": 2758.457899093628, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3253}, "6": {"k": 6, "answer": "9 April 2019", "latency_ms": 1755.1069259643555, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3894}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "100 parts of blood", "latency_ms": 2459.5680236816406, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "volume of blood or mass of blood", "latency_ms": 3645.087480545044, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "volume of blood or mass of blood", "latency_ms": 3461.81058883667, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1302}, "3": {"k": 3, "answer": "volume of blood or mass of blood", "latency_ms": 3560.4233741760254, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "volume of blood or mass of blood", "latency_ms": 3314.337968826294, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2563}, "5": {"k": 5, "answer": "volume of blood or mass of blood", "latency_ms": 3177.696704864502, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3260}, "6": {"k": 6, "answer": "volume of blood or mass of blood", "latency_ms": 4656.203031539917, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3981}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "Icarus", "latency_ms": 1920.2625751495361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Icarus", "latency_ms": 1248.8536834716797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 587}, "2": {"k": 2, "answer": "Icarus", "latency_ms": 1855.4861545562744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "Icarus", "latency_ms": 2403.921604156494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Icarus", "latency_ms": 2578.923225402832, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2411}, "5": {"k": 5, "answer": "Icarus", "latency_ms": 1600.8341312408447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3008}, "6": {"k": 6, "answer": "Icarus", "latency_ms": 1644.8218822479248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3645}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "September 16, 1979", "latency_ms": 3112.5502586364746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 16, 1979", "latency_ms": 3994.450330734253, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "September 16, 1979", "latency_ms": 2888.0667686462402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "September 16, 1979", "latency_ms": 3254.948854446411, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1782}, "4": {"k": 4, "answer": "September 16, 1979", "latency_ms": 2468.600034713745, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2363}, "5": {"k": 5, "answer": "September 16, 1979", "latency_ms": 2816.4148330688477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2958}, "6": {"k": 6, "answer": "September 16, 1979", "latency_ms": 3530.6496620178223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3587}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 am HKT", "latency_ms": 3271.6739177703857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2 April 1986", "latency_ms": 2492.783784866333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "2 April 1986", "latency_ms": 2912.013053894043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1296}, "3": {"k": 3, "answer": "2 April 1986", "latency_ms": 2525.0017642974854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1916}, "4": {"k": 4, "answer": "2 April 1986", "latency_ms": 3810.6160163879395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2588}, "5": {"k": 5, "answer": "2 April 1986", "latency_ms": 3483.0970764160156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "2 April 1986", "latency_ms": 3996.7076778411865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3825}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "Tiffany Coyne", "latency_ms": 3237.3569011688232, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiffany Coyne", "latency_ms": 2525.1169204711914, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "Tiffany Coyne", "latency_ms": 2251.596212387085, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1160}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 2852.829933166504, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1744}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 2974.0540981292725, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2372}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 2678.5123348236084, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2986}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 3242.9163455963135, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3619}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "Yankees, Braves, Reds, Giants.", "latency_ms": 4201.667070388794, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5692.577123641968, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 6125.659942626953, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5904.319047927856, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1853}, "4": {"k": 4, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 6481.092929840088, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 6216.716289520264, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3099}, "6": {"k": 6, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 7149.731874465942, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3813}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "2.187 billion dollars", "latency_ms": 3243.427515029907, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$1.84 billion", "latency_ms": 2921.751022338867, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "$1.84 billion", "latency_ms": 2960.6425762176514, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "$1.84 billion", "latency_ms": 2067.444086074829, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "$1.84 billion", "latency_ms": 2975.1522541046143, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "$1.84 billion", "latency_ms": 3305.360794067383, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3247}, "6": {"k": 6, "answer": "$1.84 billion", "latency_ms": 3200.261116027832, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3890}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "Christmas Eve and Christmas Day.", "latency_ms": 3229.977607727051, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Christmas season of 1997", "latency_ms": 3233.4461212158203, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 649}, "2": {"k": 2, "answer": "Christmas season of 1997", "latency_ms": 2108.8523864746094, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1304}, "3": {"k": 3, "answer": "Christmas season of 1997", "latency_ms": 3786.673069000244, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Christmas season of 1997", "latency_ms": 4124.090909957886, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2519}, "5": {"k": 5, "answer": "Christmas season of 1997", "latency_ms": 3171.935796737671, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3152}, "6": {"k": 6, "answer": "1946", "latency_ms": 1366.1291599273682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark and Norway", "latency_ms": 1896.125078201294, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2966.5048122406006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Norway and Denmark", "latency_ms": 2094.789981842041, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2785.80379486084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1976.9504070281982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2559}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2671.4000701904297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "Denmark", "latency_ms": 1113.2655143737793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3813}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "PresÃ©pio", "latency_ms": 1505.4993629455566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Christmas tree", "latency_ms": 1740.5426502227783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "Christmas Tree", "latency_ms": 1246.497392654419, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Christmas Tree", "latency_ms": 1571.150779724121, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Christmas Tree", "latency_ms": 1574.6018886566162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Christmas Tree", "latency_ms": 1246.2799549102783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3193}, "6": {"k": 6, "answer": "Christmas Tree", "latency_ms": 1484.565258026123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3790}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "Patrick Swayze", "latency_ms": 1460.3307247161865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Swayze", "latency_ms": 2048.1414794921875, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Swayze", "latency_ms": 1537.8787517547607, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Swayze", "latency_ms": 1661.7004871368408, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Swayze", "latency_ms": 2010.9024047851562, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Swayze", "latency_ms": 2321.969985961914, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Swayze", "latency_ms": 2136.927843093872, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3767}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Pittsburgh", "latency_ms": 2202.7883529663086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1792.9325103759766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 744}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1651.8373489379883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1438}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1903.9299488067627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2130}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2893.508195877075, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2735}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2357.9800128936768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3461}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3220.4947471618652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4132}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1612", "latency_ms": 1048.9912033081055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "17th Century", "latency_ms": 1770.6799507141113, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "17th Century", "latency_ms": 1801.5151023864746, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1314}, "3": {"k": 3, "answer": "17th Century", "latency_ms": 1565.3905868530273, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2009}, "4": {"k": 4, "answer": "17th Century", "latency_ms": 1704.6740055084229, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2706}, "5": {"k": 5, "answer": "1624", "latency_ms": 2345.796823501587, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3428}, "6": {"k": 6, "answer": "17th Century", "latency_ms": 2637.8421783447266, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4096}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier FernÃ¡ndez", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Yuzuru Hanyu", "latency_ms": 4610.432386398315, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yuzuru Hanyu", "latency_ms": 3401.6826152801514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Yuzuru Hanyu", "latency_ms": 2903.0895233154297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Yuzuru Hanyu", "latency_ms": 3401.143789291382, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Yuzuru Hanyu", "latency_ms": 4020.1101303100586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2607}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 4201.564073562622, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3275}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 3231.6200733184814, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3956}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "Password recovery and cracking.", "latency_ms": 2948.983669281006, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Password recovery", "latency_ms": 2591.322422027588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "Password recovery", "latency_ms": 2056.8578243255615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1391}, "3": {"k": 3, "answer": "Password recovery", "latency_ms": 1768.7761783599854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Password recovery", "latency_ms": 1799.2656230926514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2714}, "5": {"k": 5, "answer": "Password recovery", "latency_ms": 1747.8258609771729, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3379}, "6": {"k": 6, "answer": "Password recovery tool", "latency_ms": 2387.5389099121094, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3964}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "Eknath Shinde", "latency_ms": 2502.2361278533936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "C. Vidyasagar Rao", "latency_ms": 4503.489017486572, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "C. Vidyasagar Rao", "latency_ms": 2992.1810626983643, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 4397.164821624756, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2058}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 4666.5496826171875, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2686}, "5": {"k": 5, "answer": "C. Vidyasagar Rao", "latency_ms": 4368.186712265015, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3326}, "6": {"k": 6, "answer": "C. Vidyasagar Rao", "latency_ms": 3699.1379261016846, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3955}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "Channel 15 (KNXV)", "latency_ms": 4376.317262649536, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "15", "latency_ms": 1452.345609664917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 682}, "2": {"k": 2, "answer": "15", "latency_ms": 1992.347240447998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "15", "latency_ms": 975.820779800415, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1884}, "4": {"k": 4, "answer": "15", "latency_ms": 2038.0818843841553, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2486}, "5": {"k": 5, "answer": "15", "latency_ms": 694.8912143707275, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3118}, "6": {"k": 6, "answer": "15", "latency_ms": 2244.617223739624, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3738}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Claudia Wells", "latency_ms": 1679.7895431518555, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Claudia Wells", "latency_ms": 2919.5735454559326, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Claudia Wells", "latency_ms": 3064.13197517395, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1207}, "3": {"k": 3, "answer": "Claudia Wells", "latency_ms": 2659.7611904144287, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 2304.652452468872, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2477}, "5": {"k": 5, "answer": "Claudia Wells", "latency_ms": 2150.6316661834717, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "Claudia Wells", "latency_ms": 2853.693962097168, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3693}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 1214.3824100494385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "London, United Kingdom", "latency_ms": 2455.5482864379883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 2774.9993801116943, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 1874.9983310699463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1913}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 2686.9914531707764, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2585}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 2450.1311779022217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 1709.765911102295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3847}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The White House Chef", "latency_ms": 2408.8969230651855, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The White House Executive Chef", "latency_ms": 3064.331293106079, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "The White House Executive Chef", "latency_ms": 2759.8934173583984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "The White House Executive Chef", "latency_ms": 3522.585868835449, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2038}, "4": {"k": 4, "answer": "The White House Executive Chef", "latency_ms": 3271.9240188598633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2650}, "5": {"k": 5, "answer": "The White House Executive Chef", "latency_ms": 1550.668478012085, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3311}, "6": {"k": 6, "answer": "The White House Executive Chef", "latency_ms": 3200.515031814575, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3974}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 2109.616756439209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2159.8265171051025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2786.9396209716797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "B. N. Rao", "latency_ms": 3280.8094024658203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1818}, "4": {"k": 4, "answer": "B. N. Rao", "latency_ms": 3208.3470821380615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "B. N. Rao", "latency_ms": 3245.0382709503174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3111}, "6": {"k": 6, "answer": "B. N. Rao", "latency_ms": 2481.891393661499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "New Zealand", "latency_ms": 2117.788314819336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "British Columbia", "latency_ms": 1771.2838649749756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "British Columbia", "latency_ms": 2339.3073081970215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "British Columbia", "latency_ms": 2316.22052192688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1960}, "4": {"k": 4, "answer": "British Columbia", "latency_ms": 1275.9296894073486, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "British Columbia", "latency_ms": 1763.9148235321045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3229}, "6": {"k": 6, "answer": "British Columbia", "latency_ms": 1543.738603591919, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3910}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2953.230142593384, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 11, 2018", "latency_ms": 3569.8235034942627, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "October 11, 2018", "latency_ms": 4053.9333820343018, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 3325.0718116760254, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 3182.464122772217, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 3702.038526535034, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3267}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 4151.044607162476, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3912}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Jodie Sweetin", "latency_ms": 2642.289400100708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2282.501220703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2645.479679107666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1215}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2427.16121673584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2406.200170516968, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2661.524534225464, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3179}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2959.073305130005, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3852}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "Millennium Tower", "latency_ms": 2406.6529273986816, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Millennium Tower", "latency_ms": 2787.3082160949707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 2401.6764163970947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 2435.72735786438, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 2201.716661453247, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2661}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 2094.4859981536865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3357}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 3277.2953510284424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4043}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 539.6170616149902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 1541.992425918579, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "2015", "latency_ms": 2314.861059188843, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2525.7582664489746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "2015", "latency_ms": 1019.4871425628662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2535}, "5": {"k": 5, "answer": "2015", "latency_ms": 2049.2608547210693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "2015", "latency_ms": 2160.895586013794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3807}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "John Harlan", "latency_ms": 1324.9845504760742, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Marshall Harlan", "latency_ms": 2693.3255195617676, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Harlan", "latency_ms": 1254.3320655822754, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1390}, "3": {"k": 3, "answer": "Harlan", "latency_ms": 1981.1046123504639, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2069}, "4": {"k": 4, "answer": "John Marshall Harlan", "latency_ms": 2890.0740146636963, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2750}, "5": {"k": 5, "answer": "John Marshall Harlan", "latency_ms": 1956.4156532287598, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3453}, "6": {"k": 6, "answer": "John Marshall Harlan", "latency_ms": 3273.6005783081055, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4112}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Tyrann Mathieu", "latency_ms": 1904.146432876587, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tyrann Mathieu", "latency_ms": 2295.876979827881, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 3649.291515350342, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 2721.623659133911, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 2921.647548675537, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2568}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 2971.6272354125977, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3181}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 2698.639392852783, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3816}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "44", "latency_ms": 555.9053421020508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Six", "latency_ms": 1938.558578491211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "six", "latency_ms": 693.5973167419434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Six episodes", "latency_ms": 1509.5033645629883, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2042}, "4": {"k": 4, "answer": "Six episodes", "latency_ms": 2058.7615966796875, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2715}, "5": {"k": 5, "answer": "Six episodes", "latency_ms": 2185.8677864074707, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3373}, "6": {"k": 6, "answer": "6 episodes", "latency_ms": 2061.4826679229736, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4016}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul BaÃ¼mer's", "latency_ms": 3136.2593173980713, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "German", "latency_ms": 684.0798854827881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "German perspective", "latency_ms": 2067.878007888794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "German perspective", "latency_ms": 2033.278226852417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "German perspective", "latency_ms": 1794.870138168335, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "German perspective", "latency_ms": 2004.5349597930908, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "German perspective", "latency_ms": 1974.8456478118896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3798}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris", "latency_ms": 1550.4963397979736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 5807.629585266113, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Frank Morris, John Anglin, and Clarence Anglin.", "latency_ms": 5042.477369308472, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1347}, "3": {"k": 3, "answer": "Frank Morris, John Anglin, Clarence Anglin, John Paul Scott", "latency_ms": 5778.975963592529, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1986}, "4": {"k": 4, "answer": "Frank Morris, John Anglin, Clarence Anglin, John Paul Scott", "latency_ms": 6758.208513259888, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Frank Morris, John Anglin, Clarence Anglin, John Paul Scott", "latency_ms": 6199.108839035034, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3244}, "6": {"k": 6, "answer": "Frank Morris, John Anglin, Clarence Anglin, John Paul Scott", "latency_ms": 5565.237045288086, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3898}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF programs worldwide.", "latency_ms": 3562.5672340393066, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF's global programming", "latency_ms": 3783.2577228546143, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "UNICEF's global programming", "latency_ms": 2530.423402786255, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1350}, "3": {"k": 3, "answer": "UNICEF's global programming", "latency_ms": 3823.871850967407, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2070}, "4": {"k": 4, "answer": "UNICEF's global programming", "latency_ms": 2802.243709564209, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2800}, "5": {"k": 5, "answer": "UNICEF's global programming", "latency_ms": 3645.0252532958984, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3488}, "6": {"k": 6, "answer": "UNICEF's global programming", "latency_ms": 2395.299196243286, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4114}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Tablet in her left hand", "latency_ms": 2586.2765312194824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the base", "latency_ms": 2041.5735244750977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "at the base", "latency_ms": 1859.276533126831, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1313}, "3": {"k": 3, "answer": "at the base", "latency_ms": 1853.907585144043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "at the base", "latency_ms": 2984.220027923584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2578}, "5": {"k": 5, "answer": "at the base", "latency_ms": 2299.607038497925, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "at the base", "latency_ms": 2162.095308303833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3899}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "Milan-Cortina 2026, Sapporo 2030", "latency_ms": 6098.557949066162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1599.3256568908691, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Pyeongchang and Beijing", "latency_ms": 3282.7858924865723, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Beijing, China and unknown", "latency_ms": 3008.962392807007, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1823}, "4": {"k": 4, "answer": "Beijing, China and unknown", "latency_ms": 2762.6383304595947, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Pyeongchang and Beijing", "latency_ms": 3651.763439178467, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3180}, "6": {"k": 6, "answer": "Beijing, China and unknown", "latency_ms": 2657.1805477142334, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3852}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "October 22, 1981", "latency_ms": 4372.469663619995, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2197.0558166503906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "1997", "latency_ms": 1559.908151626587, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1291}, "3": {"k": 3, "answer": "1997", "latency_ms": 1787.8146171569824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "1997", "latency_ms": 1520.9577083587646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "1997", "latency_ms": 1576.6394138336182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3262}, "6": {"k": 6, "answer": "1997", "latency_ms": 1570.0178146362305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3859}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "Stone Gothic arch bridge", "latency_ms": 2222.7962017059326, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rolling bascule bridge", "latency_ms": 3218.2204723358154, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Rolling bascule bridge", "latency_ms": 3233.4518432617188, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1379}, "3": {"k": 3, "answer": "Rolling bascule bridge", "latency_ms": 3859.588861465454, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2038}, "4": {"k": 4, "answer": "Stone Bridge", "latency_ms": 1587.794303894043, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2671}, "5": {"k": 5, "answer": "Stone Bridge", "latency_ms": 1776.2808799743652, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3308}, "6": {"k": 6, "answer": "Stone Bridge", "latency_ms": 1510.66255569458, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3975}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The Autocrat", "latency_ms": 2421.3078022003174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One person", "latency_ms": 1744.3323135375977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "One person", "latency_ms": 2054.8558235168457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1345}, "3": {"k": 3, "answer": "One person", "latency_ms": 1816.3678646087646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2018}, "4": {"k": 4, "answer": "One person", "latency_ms": 1776.7677307128906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2672}, "5": {"k": 5, "answer": "One person", "latency_ms": 2313.260793685913, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3336}, "6": {"k": 6, "answer": "One person", "latency_ms": 1797.6536750793457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4005}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "Affluence and suburbanization.", "latency_ms": 3852.3287773132324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Economic expansion", "latency_ms": 2338.9718532562256, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 726}, "2": {"k": 2, "answer": "Pride in new-found affluence", "latency_ms": 4363.758325576782, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1399}, "3": {"k": 3, "answer": "other-directedness", "latency_ms": 2536.2868309020996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2115}, "4": {"k": 4, "answer": "other-directedness", "latency_ms": 1805.4513931274414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2743}, "5": {"k": 5, "answer": "other-directedness", "latency_ms": 1761.9259357452393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3483}, "6": {"k": 6, "answer": "other-directedness", "latency_ms": 1120.6395626068115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4192}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "Counterclockwise", "latency_ms": 2365.354537963867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Counterclockwise", "latency_ms": 2888.6237144470215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "Counterclockwise", "latency_ms": 2349.70760345459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "Counterclockwise", "latency_ms": 2174.517869949341, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1770}, "4": {"k": 4, "answer": "Counterclockwise", "latency_ms": 2723.8945960998535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2344}, "5": {"k": 5, "answer": "Counterclockwise", "latency_ms": 2219.414234161377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3019}, "6": {"k": 6, "answer": "Counterclockwise", "latency_ms": 1443.6018466949463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3590}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Statue of Freedom", "latency_ms": 2382.32421875, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "an outdoor walkway", "latency_ms": 1890.817642211914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Statue of Freedom", "latency_ms": 2922.2536087036133, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1177}, "3": {"k": 3, "answer": "Statue of Freedom", "latency_ms": 1913.015365600586, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "Statue of Freedom", "latency_ms": 1879.256010055542, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2367}, "5": {"k": 5, "answer": "Statue of Freedom", "latency_ms": 3291.9578552246094, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3022}, "6": {"k": 6, "answer": "Statue of Freedom", "latency_ms": 1675.2290725708008, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3682}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "Taoyuan Leopards", "latency_ms": 2016.7944431304932, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wizards", "latency_ms": 2100.1086235046387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "Washington Wizards", "latency_ms": 1400.6528854370117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Washington Wizards", "latency_ms": 1861.8855476379395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Washington Wizards", "latency_ms": 1990.9212589263916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2454}, "5": {"k": 5, "answer": "Washington Wizards", "latency_ms": 1540.822982788086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3113}, "6": {"k": 6, "answer": "Washington Wizards", "latency_ms": 1521.850347518921, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3773}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "Rey Mysterio", "latency_ms": 2000.960350036621, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chris Benoit", "latency_ms": 1483.1352233886719, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "Daniel Bryan", "latency_ms": 1673.7420558929443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Rey Mysterio", "latency_ms": 2910.3736877441406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Daniel Bryan", "latency_ms": 800.0175952911377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2491}, "5": {"k": 5, "answer": "Rey Mysterio", "latency_ms": 2962.369441986084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Daniel Bryan", "latency_ms": 2080.967903137207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3729}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 1328.0227184295654, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake of the Ozarks", "latency_ms": 1798.87056350708, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Lake Oahe", "latency_ms": 2531.4106941223145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Lake Oahe", "latency_ms": 2381.1240196228027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1810}, "4": {"k": 4, "answer": "Lake Oahe", "latency_ms": 1911.2064838409424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2438}, "5": {"k": 5, "answer": "Lake Oahe", "latency_ms": 2422.274112701416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3122}, "6": {"k": 6, "answer": "Lake Oahe", "latency_ms": 1865.1819229125977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3705}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Tagore", "latency_ms": 1527.761459350586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tagore", "latency_ms": 1581.3541412353516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 585}, "2": {"k": 2, "answer": "Tagore", "latency_ms": 824.8419761657715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tagore", "latency_ms": 1462.0957374572754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "Tagore", "latency_ms": 1304.7168254852295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Tagore", "latency_ms": 1836.8644714355469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3134}, "6": {"k": 6, "answer": "Tagore", "latency_ms": 1789.7584438323975, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3767}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "Geraldine Ferraro", "latency_ms": 1553.034782409668, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "George H.W. Bush and Geraldine Ferraro", "latency_ms": 4866.598606109619, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 737}, "2": {"k": 2, "answer": "Geraldine Ferraro", "latency_ms": 2235.200881958008, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1452}, "3": {"k": 3, "answer": "Geraldine Ferraro and George H.W. Bush", "latency_ms": 5235.099792480469, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2141}, "4": {"k": 4, "answer": "Geraldine Ferraro", "latency_ms": 3149.9345302581787, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2825}, "5": {"k": 5, "answer": "Geraldine Ferraro and George H.W. Bush", "latency_ms": 5636.111736297607, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3549}, "6": {"k": 6, "answer": "Geraldine Ferraro and George H.W. Bush", "latency_ms": 6349.398136138916, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4311}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "American Rock Salt mine, Livingston County, New York", "latency_ms": 3937.215566635132, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Groveland", "latency_ms": 3832.494020462036, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners, Groveland", "latency_ms": 4302.041530609131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1263}, "3": {"k": 3, "answer": "Hampton Corners", "latency_ms": 2586.8146419525146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Hampton Corners, Groveland, New York", "latency_ms": 5440.2360916137695, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "Hampton Corners", "latency_ms": 2307.8372478485107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Goderich, Ontario", "latency_ms": 3024.885654449463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3842}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 2347.7859497070312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 1220.285415649414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 2596.508264541626, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 2324.083089828491, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 2042.0770645141602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2469}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 2524.0652561187744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3106}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 1238.1138801574707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3673}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Meghalaya", "latency_ms": 1958.5294723510742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Meghalaya", "latency_ms": 2082.4544429779053, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Meghalaya", "latency_ms": 1429.081916809082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Meghalaya", "latency_ms": 2625.3738403320312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1953}, "4": {"k": 4, "answer": "Meghalaya", "latency_ms": 2878.5266876220703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2522}, "5": {"k": 5, "answer": "Meghalaya", "latency_ms": 2624.7153282165527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3167}, "6": {"k": 6, "answer": "Meghalaya", "latency_ms": 1775.9203910827637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3848}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Kanpur", "latency_ms": 1520.3440189361572, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kanpur", "latency_ms": 2903.550148010254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Kanpur", "latency_ms": 2137.763738632202, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "Kanpur", "latency_ms": 1566.9293403625488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1824}, "4": {"k": 4, "answer": "Kanpur", "latency_ms": 2080.096483230591, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2472}, "5": {"k": 5, "answer": "Kanpur", "latency_ms": 2707.772731781006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3053}, "6": {"k": 6, "answer": "Kanpur", "latency_ms": 1891.000747680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
