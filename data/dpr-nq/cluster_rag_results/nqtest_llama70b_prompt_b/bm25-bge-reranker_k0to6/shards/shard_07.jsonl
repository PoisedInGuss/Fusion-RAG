{"qid": "5306300389470118812", "question": "what was the religion in persia before islam", "gold_answers": ["the Zoroastrian religion", "Zoroastrian"], "shots": {"0": {"k": 0, "answer": "Zoroastrianism", "latency_ms": 2238.896369934082, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Zoroastrianism", "latency_ms": 2574.4338035583496, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "Zoroastrianism", "latency_ms": 2936.082363128662, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1284}, "3": {"k": 3, "answer": "Zoroastrianism", "latency_ms": 3300.757646560669, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1994}, "4": {"k": 4, "answer": "Zoroastrianism", "latency_ms": 3006.8023204803467, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2653}, "5": {"k": 5, "answer": "Zoroastrianism", "latency_ms": 3078.2313346862793, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3338}, "6": {"k": 6, "answer": "Zoroastrianism", "latency_ms": 1936.0589981079102, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3993}}}
{"qid": "4492088526674104172", "question": "why does kerosene oil rise up in the wick of lantern", "gold_answers": ["capillary action"], "shots": {"0": {"k": 0, "answer": "Capillary action.", "latency_ms": 2764.888048171997, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Capillary action", "latency_ms": 2442.192316055298, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 586}, "2": {"k": 2, "answer": "Capillary action", "latency_ms": 2140.770196914673, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1171}, "3": {"k": 3, "answer": "Capillary action", "latency_ms": 1904.7439098358154, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1826}, "4": {"k": 4, "answer": "Capillary action", "latency_ms": 1606.2726974487305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2501}, "5": {"k": 5, "answer": "Capillary action", "latency_ms": 2344.129800796509, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3109}, "6": {"k": 6, "answer": "Capillary action", "latency_ms": 2615.1669025421143, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3728}}}
{"qid": "-4373262132142058334", "question": "mention the chemical change that proinsulin undergo to be able to act as mature insulin", "gold_answers": ["post translational modification"], "shots": {"0": {"k": 0, "answer": "Proteolytic cleavage.", "latency_ms": 3609.787940979004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cleavage of C-peptide", "latency_ms": 3210.490942001343, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Proteolysis", "latency_ms": 2102.6413440704346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1357}, "3": {"k": 3, "answer": "Proteolysis", "latency_ms": 2416.935682296753, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2047}, "4": {"k": 4, "answer": "Proteolysis", "latency_ms": 2418.1976318359375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2596}, "5": {"k": 5, "answer": "Proteolysis", "latency_ms": 1677.121877670288, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3229}, "6": {"k": 6, "answer": "Proteolysis", "latency_ms": 2470.950126647949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3933}}}
{"qid": "-5298560410953979569", "question": "where does the sweetness of fruit come from", "gold_answers": ["Fructose , or fruit sugar", "Fructose"], "shots": {"0": {"k": 0, "answer": "Fructose", "latency_ms": 1043.7812805175781, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "the pulp tissue surrounding the seeds", "latency_ms": 3375.253677368164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 681}, "2": {"k": 2, "answer": "the pulp tissue surrounding the seeds", "latency_ms": 3121.764898300171, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1344}, "3": {"k": 3, "answer": "the pulp tissue surrounding the seeds", "latency_ms": 3577.9991149902344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2023}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1943.8505172729492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2661}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1894.3274021148682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3319}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1440.7753944396973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3981}}}
{"qid": "4344648368832551136", "question": "an object that moves around an external axis is said to be", "gold_answers": ["orbit", "revolution or orbital revolution"], "shots": {"0": {"k": 0, "answer": "rotating", "latency_ms": 1322.2649097442627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "revolving", "latency_ms": 1709.8405361175537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "revolving", "latency_ms": 1808.223009109497, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "in a revolution or orbital revolution", "latency_ms": 2696.985960006714, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 1844}, "4": {"k": 4, "answer": "in a revolution or orbital revolution", "latency_ms": 4055.4375648498535, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 2601}, "5": {"k": 5, "answer": "revolving", "latency_ms": 1252.4685859680176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3230}, "6": {"k": 6, "answer": "in revolution or orbital revolution", "latency_ms": 3307.5497150421143, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 3842}}}
{"qid": "-724426540432437711", "question": "what was the name of the plant on little shop of horrors", "gold_answers": ["Audrey II"], "shots": {"0": {"k": 0, "answer": "Audrey II", "latency_ms": 1882.1916580200195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Audrey II", "latency_ms": 1876.1000633239746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 589}, "2": {"k": 2, "answer": "Audrey II", "latency_ms": 1853.7254333496094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Audrey II", "latency_ms": 1792.6719188690186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1834}, "4": {"k": 4, "answer": "Audrey II", "latency_ms": 2162.2231006622314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2495}, "5": {"k": 5, "answer": "Audrey II", "latency_ms": 1846.487283706665, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Audrey II", "latency_ms": 2496.7775344848633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3810}}}
{"qid": "-5541610970112826260", "question": "who signed the declaration of independence for maryland", "gold_answers": ["Samuel Chase", "Charles Carroll of Carrollton", "Thomas Stone", "William Paca"], "shots": {"0": {"k": 0, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll.", "latency_ms": 5180.402755737305, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 7892.087936401367, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 704}, "2": {"k": 2, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 5870.29242515564, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 1389}, "3": {"k": 3, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 5648.008584976196, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 2076}, "4": {"k": 4, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 6006.465196609497, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 2793}, "5": {"k": 5, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 6588.12689781189, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 3456}, "6": {"k": 6, "answer": "Samuel Chase, William Paca, Thomas Stone, Charles Carroll of Carrollton", "latency_ms": 5945.417165756226, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4130}}}
{"qid": "-86997217831791339", "question": "when does wonder woman come out on blue ray", "gold_answers": ["September 19 , 2017"], "shots": {"0": {"k": 0, "answer": "August 29, 2017", "latency_ms": 3713.0050659179688, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 19, 2017", "latency_ms": 3440.22274017334, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 606}, "2": {"k": 2, "answer": "September 19, 2017", "latency_ms": 4102.394819259644, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "September 19, 2017", "latency_ms": 4246.747732162476, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "September 19, 2017", "latency_ms": 4121.136426925659, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2545}, "5": {"k": 5, "answer": "September 19, 2017", "latency_ms": 3848.515272140503, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3182}, "6": {"k": 6, "answer": "September 19, 2017", "latency_ms": 4118.569612503052, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3797}}}
{"qid": "-8062812506672279762", "question": "what nba team did derrick rose play for", "gold_answers": ["New York Knicks", "Minnesota Timberwolves", "Chicago Bulls", "Cleveland Cavaliers"], "shots": {"0": {"k": 0, "answer": "Chicago Bulls, Cleveland Cavaliers, New York Knicks, Minnesota Timberwolves, Detroit Pistons.", "latency_ms": 7171.050310134888, "em": 0.0, "f1": 0.42857142857142855, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Chicago Bulls, Minnesota Timberwolves", "latency_ms": 3948.500156402588, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 630}, "2": {"k": 2, "answer": "Chicago Bulls, Minnesota Timberwolves", "latency_ms": 3657.9365730285645, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Chicago Bulls, Minnesota Timberwolves, New York Knicks", "latency_ms": 5704.487085342407, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Chicago Bulls, Minnesota Timberwolves, New York Knicks", "latency_ms": 6517.433404922485, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2520}, "5": {"k": 5, "answer": "Chicago Bulls, Minnesota Timberwolves, New York Knicks, Cleveland Cavaliers", "latency_ms": 6260.913133621216, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3128}, "6": {"k": 6, "answer": "Chicago Bulls, Minnesota Timberwolves, New York Knicks, Cleveland Cavaliers", "latency_ms": 7108.25252532959, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3755}}}
{"qid": "7933002036740390435", "question": "where did the term liberal arts come from", "gold_answers": ["the Roman Empire"], "shots": {"0": {"k": 0, "answer": "Ancient Rome", "latency_ms": 1255.4030418395996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roman Empire", "latency_ms": 2331.312656402588, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Roman Empire", "latency_ms": 1805.6366443634033, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Roman Empire", "latency_ms": 976.9937992095947, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2019}, "4": {"k": 4, "answer": "Roman Empire", "latency_ms": 2061.349630355835, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2662}, "5": {"k": 5, "answer": "Roman Empire", "latency_ms": 1775.3849029541016, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3353}, "6": {"k": 6, "answer": "Roman Empire", "latency_ms": 1784.8610877990723, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4087}}}
{"qid": "-2991400700385487821", "question": "who heads the executive department of west virginia government", "gold_answers": ["the Governor of West Virginia", "the governor of West Virginia", "Jim Justice"], "shots": {"0": {"k": 0, "answer": "The Governor", "latency_ms": 1547.1875667572021, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The governor", "latency_ms": 2000.4873275756836, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "The Governor of West Virginia", "latency_ms": 2306.7800998687744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "The Governor of West Virginia", "latency_ms": 2509.721517562866, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1949}, "4": {"k": 4, "answer": "The Governor of West Virginia", "latency_ms": 2786.041736602783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2592}, "5": {"k": 5, "answer": "The Governor of West Virginia", "latency_ms": 2975.2840995788574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3210}, "6": {"k": 6, "answer": "The Governor of West Virginia", "latency_ms": 3498.7714290618896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3842}}}
{"qid": "-9186689755642837558", "question": "how long is the bridge between new brunswick and prince edward island", "gold_answers": ["12.9 - kilometre"], "shots": {"0": {"k": 0, "answer": "13 kilometers", "latency_ms": 1268.2621479034424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2191.5481090545654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 686}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1682.6019287109375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1345}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2145.671606063843, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1933}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2765.6736373901367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2602}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2707.345485687256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3289}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2613.666296005249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3950}}}
{"qid": "8029901619424338449", "question": "when did the uk and us become allies", "gold_answers": ["1940", "Since 1940"], "shots": {"0": {"k": 0, "answer": "1778, then 1814, and fully in 1941", "latency_ms": 5049.35884475708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2650.1715183258057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "After the end of the Second World War in 1945", "latency_ms": 4209.696292877197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2440.9921169281006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2411.4060401916504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2695}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2392.141580581665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3393}, "6": {"k": 6, "answer": "After the end of the Second World War in 1945", "latency_ms": 4634.965896606445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4073}}}
{"qid": "4828649525820722736", "question": "who sang the theme song for the man with the golden gun", "gold_answers": ["Lulu"], "shots": {"0": {"k": 0, "answer": "Lulu", "latency_ms": 1113.1906509399414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lulu", "latency_ms": 1525.9356498718262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Lulu", "latency_ms": 1232.370138168335, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Lulu", "latency_ms": 1526.155948638916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1895}, "4": {"k": 4, "answer": "Lulu", "latency_ms": 1299.4062900543213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2545}, "5": {"k": 5, "answer": "Lulu", "latency_ms": 1632.4782371520996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3150}, "6": {"k": 6, "answer": "Lulu", "latency_ms": 1495.1403141021729, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3805}}}
{"qid": "-7924663090486742985", "question": "american horror story freak show girl kidnapped by clown", "gold_answers": ["Bonnie Lipton"], "shots": {"0": {"k": 0, "answer": "Pennywise is not correct, the answer is: Twisty.", "latency_ms": 4393.049478530884, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2145.606756210327, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "Suzi", "latency_ms": 1318.0022239685059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Dot Tattler", "latency_ms": 1845.2751636505127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Dot Tattler", "latency_ms": 2242.790699005127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2679}, "5": {"k": 5, "answer": "Dot Tattler", "latency_ms": 3162.815809249878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3314}, "6": {"k": 6, "answer": "Bette and Dot Tattler", "latency_ms": 2402.662515640259, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3973}}}
{"qid": "-360675773049242516", "question": "the probability of making a type i error when retaining ho at the .05 level of significance is", "gold_answers": ["5 %"], "shots": {"0": {"k": 0, "answer": "0.05", "latency_ms": 2191.433906555176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0.05", "latency_ms": 1318.9117908477783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "0.05", "latency_ms": 2037.3353958129883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1210}, "3": {"k": 3, "answer": "0.05", "latency_ms": 2333.2290649414062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "0.05", "latency_ms": 1765.916347503662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2430}, "5": {"k": 5, "answer": "0.05", "latency_ms": 1333.2040309906006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3069}, "6": {"k": 6, "answer": "0.05", "latency_ms": 1626.0712146759033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3699}}}
{"qid": "5819386267283467034", "question": "what year did the us hockey team won the olympics", "gold_answers": ["1960", "1980", "1960 and 1980"], "shots": {"0": {"k": 0, "answer": "1980", "latency_ms": 998.9306926727295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1980", "latency_ms": 1184.6771240234375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 595}, "2": {"k": 2, "answer": "1980", "latency_ms": 1712.0604515075684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1226}, "3": {"k": 3, "answer": "1960, 1980", "latency_ms": 1766.0648822784424, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1887}, "4": {"k": 4, "answer": "1960, 1980", "latency_ms": 3056.9746494293213, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2551}, "5": {"k": 5, "answer": "1960, 1980", "latency_ms": 2284.707546234131, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "1960, 1980", "latency_ms": 2398.735284805298, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3772}}}
{"qid": "3916394566028297311", "question": "who wrote it's a long long way to pasadena", "gold_answers": ["Harry Vanda", "John Young", "David Hemmings", "George Young"], "shots": {"0": {"k": 0, "answer": "Albert Von Tilzer and Edgar Leslie", "latency_ms": 3084.2370986938477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2198.5795497894287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1426.79762840271, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2168.999195098877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3197.114944458008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1896.012783050537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3208}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2174.6089458465576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3853}}}
{"qid": "-2432292250757146771", "question": "who wrote the song i hate you i love you", "gold_answers": ["Angel Benitez", "Olivia O'Brien", "Garrett Nash"], "shots": {"0": {"k": 0, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3143.7602043151855, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3578.078031539917, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 572}, "2": {"k": 2, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3324.3229389190674, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1147}, "3": {"k": 3, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3367.5341606140137, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1770}, "4": {"k": 4, "answer": "Gnash", "latency_ms": 1625.32639503479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2383}, "5": {"k": 5, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3763.301372528076, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3025}, "6": {"k": 6, "answer": "Gnash", "latency_ms": 2351.978063583374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3609}}}
{"qid": "2393389448844632496", "question": "what is loihi and where does it originate from", "gold_answers": ["from the Hawaii hotspot"], "shots": {"0": {"k": 0, "answer": "Loihi, Hawaii, USA", "latency_ms": 3246.790647506714, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hawaiian word lōʻihi means \"long\"", "latency_ms": 5757.4591636657715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "Hawaiian seamount", "latency_ms": 2194.265127182007, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1392}, "3": {"k": 3, "answer": "Hawaiian seamount", "latency_ms": 2997.1909523010254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2064}, "4": {"k": 4, "answer": "Hawaiian seamount", "latency_ms": 2564.8317337036133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2856}, "5": {"k": 5, "answer": "Hawaiian seamount", "latency_ms": 2924.4542121887207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3536}, "6": {"k": 6, "answer": "Hawaiian seamount", "latency_ms": 2457.988739013672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4190}}}
{"qid": "-6677440871585683891", "question": "who rebuilt the temple after the babylonian captivity", "gold_answers": ["Herod"], "shots": {"0": {"k": 0, "answer": "Zerubbabel", "latency_ms": 1930.0782680511475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Jews", "latency_ms": 1794.3754196166992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "The Jews", "latency_ms": 2183.1600666046143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "The Jews", "latency_ms": 1532.8426361083984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "King Solomon", "latency_ms": 1764.7581100463867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2564}, "5": {"k": 5, "answer": "King Solomon", "latency_ms": 1049.2660999298096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3215}, "6": {"k": 6, "answer": "King Solomon", "latency_ms": 1217.1363830566406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3884}}}
{"qid": "-6750750235985613277", "question": "who was executed for being an american spy during the revolutionary war", "gold_answers": ["Nathan Hale"], "shots": {"0": {"k": 0, "answer": "Nathan Hale", "latency_ms": 1797.3930835723877, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nathan Hale", "latency_ms": 2098.2117652893066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 591}, "2": {"k": 2, "answer": "Nathan Hale", "latency_ms": 1541.4540767669678, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1210}, "3": {"k": 3, "answer": "Nathan Hale", "latency_ms": 1563.4701251983643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1867}, "4": {"k": 4, "answer": "Nathan Hale", "latency_ms": 1541.7377948760986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2511}, "5": {"k": 5, "answer": "Nathan Hale", "latency_ms": 1749.7689723968506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3106}, "6": {"k": 6, "answer": "Nathan Hale", "latency_ms": 1634.8958015441895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3845}}}
{"qid": "8770209312170080158", "question": "who sang the song suddenly with olivia newton john", "gold_answers": ["Cliff Richard"], "shots": {"0": {"k": 0, "answer": "Cliff Richard", "latency_ms": 1403.6340713500977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cliff Richard", "latency_ms": 2340.6786918640137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "Cliff Richard", "latency_ms": 1895.7114219665527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1270}, "3": {"k": 3, "answer": "Cliff Richard", "latency_ms": 2339.4181728363037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Cliff Richard", "latency_ms": 2082.9343795776367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2509}, "5": {"k": 5, "answer": "Cliff Richard", "latency_ms": 2158.426284790039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3169}, "6": {"k": 6, "answer": "Cliff Richard", "latency_ms": 2102.6787757873535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3834}}}
{"qid": "-180549795106449014", "question": "who is command sergeant major of the army", "gold_answers": ["Daniel A. Dailey"], "shots": {"0": {"k": 0, "answer": "Michael A. Grinston", "latency_ms": 2488.3785247802734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Daniel A. Dailey", "latency_ms": 2846.4784622192383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 566}, "2": {"k": 2, "answer": "Daniel A. Dailey", "latency_ms": 2094.5746898651123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Daniel A. Dailey", "latency_ms": 2818.41778755188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1783}, "4": {"k": 4, "answer": "Daniel A. Dailey", "latency_ms": 2539.26944732666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2489}, "5": {"k": 5, "answer": "Daniel A. Dailey", "latency_ms": 2437.3319149017334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3128}, "6": {"k": 6, "answer": "Daniel A. Dailey", "latency_ms": 2478.360414505005, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3752}}}
{"qid": "7815138213728640354", "question": "who sings the original windmills of your mind", "gold_answers": ["Noel Harrison"], "shots": {"0": {"k": 0, "answer": "Noel Harrison", "latency_ms": 1332.3845863342285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noel Harrison", "latency_ms": 2122.7829456329346, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 679}, "2": {"k": 2, "answer": "Noel Harrison", "latency_ms": 1353.1756401062012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1284}, "3": {"k": 3, "answer": "Noel Harrison", "latency_ms": 2393.660306930542, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1952}, "4": {"k": 4, "answer": "Noel Harrison", "latency_ms": 2182.5151443481445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2604}, "5": {"k": 5, "answer": "Noel Harrison", "latency_ms": 1748.1002807617188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3266}, "6": {"k": 6, "answer": "Noel Harrison", "latency_ms": 1041.0208702087402, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3886}}}
{"qid": "2098168902147822379", "question": "where will the next summer and winter olympics be held", "gold_answers": ["Beijing", "Tokyo"], "shots": {"0": {"k": 0, "answer": "Paris 2024 and Milan-Cortina 2026.", "latency_ms": 6068.825483322144, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tokyo", "latency_ms": 1199.8908519744873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 596}, "2": {"k": 2, "answer": "Tokyo, Beijing", "latency_ms": 2449.8584270477295, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1221}, "3": {"k": 3, "answer": "Tokyo, Beijing", "latency_ms": 2129.6277046203613, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1841}, "4": {"k": 4, "answer": "Tokyo, Beijing", "latency_ms": 2165.0171279907227, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2458}, "5": {"k": 5, "answer": "Tokyo and Beijing", "latency_ms": 2068.488359451294, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3050}, "6": {"k": 6, "answer": "Tokyo and Beijing", "latency_ms": 2156.947135925293, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3730}}}
{"qid": "-1458476052377668874", "question": "when did ole miss beat alabama in football", "gold_answers": ["September 19 , 2015", "October 3 , 1970", "October 27 , 1894", "October 13 , 2001", "October 5 , 1968", "October 4 , 2014", "September 11 , 1976", "October 8 , 1988", "October 18 , 2003", "November 5 , 1910"], "shots": {"0": {"k": 0, "answer": "October 10, 2014", "latency_ms": 3086.087226867676, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 1531.076192855835, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "1988, 1998", "latency_ms": 3185.1260662078857, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1216}, "3": {"k": 3, "answer": "1988, 2015", "latency_ms": 2204.155206680298, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1903}, "4": {"k": 4, "answer": "1988, 2016", "latency_ms": 2844.7747230529785, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "1988, 2015", "latency_ms": 2846.287965774536, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "1988, 2015", "latency_ms": 3557.4657917022705, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3835}}}
{"qid": "-6861734002351236912", "question": "who sang the song how far is heaven", "gold_answers": ["Los Lonely Boys"], "shots": {"0": {"k": 0, "answer": "Los Lonely Boys", "latency_ms": 1369.2772388458252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2846.959114074707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2719.515323638916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1200}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2508.650064468384, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1816}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2433.5193634033203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2405}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2971.7774391174316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2994}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2678.3647537231445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3635}}}
{"qid": "-1722216190521937227", "question": "where are the organ mountains in new mexico", "gold_answers": ["southern New Mexico"], "shots": {"0": {"k": 0, "answer": "Las Cruces", "latency_ms": 2443.2551860809326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "southern New Mexico", "latency_ms": 2170.3665256500244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "southern New Mexico", "latency_ms": 2441.8647289276123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1263}, "3": {"k": 3, "answer": "southern New Mexico", "latency_ms": 1453.134298324585, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1982}, "4": {"k": 4, "answer": "southern New Mexico", "latency_ms": 2136.852741241455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2574}, "5": {"k": 5, "answer": "southern New Mexico", "latency_ms": 3164.7019386291504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3171}, "6": {"k": 6, "answer": "southern New Mexico", "latency_ms": 1890.1643753051758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3788}}}
{"qid": "-2717119588239727064", "question": "where are the 10 plagues found in the bible", "gold_answers": ["Book of Exodus", "Exodus"], "shots": {"0": {"k": 0, "answer": "Exodus 7-12", "latency_ms": 3246.1204528808594, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2465.528726577759, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 570}, "2": {"k": 2, "answer": "Hebrew Bible", "latency_ms": 1285.3505611419678, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Hebrew Bible", "latency_ms": 1369.635820388794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1787}, "4": {"k": 4, "answer": "Hebrew Bible", "latency_ms": 1701.462984085083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2399}, "5": {"k": 5, "answer": "Hebrew Bible, Exodus", "latency_ms": 3460.6590270996094, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2949}, "6": {"k": 6, "answer": "Hebrew Bible, Exodus", "latency_ms": 2974.071741104126, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3524}}}
{"qid": "2988284357714596500", "question": "where are red blood cells made in adults", "gold_answers": ["in the bone marrow"], "shots": {"0": {"k": 0, "answer": "Bone marrow", "latency_ms": 1282.7033996582031, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "red bone marrow", "latency_ms": 1654.6833515167236, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "the red bone marrow", "latency_ms": 1400.3891944885254, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "the red bone marrow", "latency_ms": 1813.8587474822998, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1911}, "4": {"k": 4, "answer": "red bone marrow", "latency_ms": 1617.0954704284668, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2504}, "5": {"k": 5, "answer": "red bone marrow", "latency_ms": 1732.1405410766602, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3148}, "6": {"k": 6, "answer": "red bone marrow", "latency_ms": 2333.0986499786377, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3838}}}
{"qid": "-4616596799374362422", "question": "who was the pinkerton detective agency's first female detective", "gold_answers": ["Kate Warne"], "shots": {"0": {"k": 0, "answer": "Kate Warne", "latency_ms": 858.2251071929932, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kate Warne", "latency_ms": 2087.6009464263916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Kate Warne", "latency_ms": 2041.2571430206299, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1235}, "3": {"k": 3, "answer": "Kate Warne", "latency_ms": 1913.254976272583, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Kate Warne", "latency_ms": 1270.0166702270508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2591}, "5": {"k": 5, "answer": "Kate Warne", "latency_ms": 2652.6834964752197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Kate Warne", "latency_ms": 1825.4578113555908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3841}}}
{"qid": "-3650291155113659146", "question": "how many episodes are there in modern family", "gold_answers": ["232", "201"], "shots": {"0": {"k": 0, "answer": "250 episodes", "latency_ms": 763.392448425293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "24", "latency_ms": 1680.2136898040771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "24 episodes", "latency_ms": 1177.5870323181152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "24 episodes", "latency_ms": 1732.7580451965332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "24 episodes", "latency_ms": 1497.4982738494873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2464}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1625.2620220184326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3088}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2647.4664211273193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3716}}}
{"qid": "3381924381590631417", "question": "who built the first temple for god in jerusalem", "gold_answers": ["Solomon"], "shots": {"0": {"k": 0, "answer": "King Solomon", "latency_ms": 1539.1924381256104, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "King Solomon", "latency_ms": 1837.6073837280273, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "King Solomon", "latency_ms": 1973.6204147338867, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1296}, "3": {"k": 3, "answer": "King Solomon", "latency_ms": 1048.8030910491943, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "King Solomon", "latency_ms": 1340.8091068267822, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2602}, "5": {"k": 5, "answer": "King Solomon", "latency_ms": 1186.5425109863281, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3237}, "6": {"k": 6, "answer": "King Solomon", "latency_ms": 1776.637077331543, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3797}}}
{"qid": "-154783694579651082", "question": "what is a dropped pin on google maps for", "gold_answers": ["marks locations", "marks locations in Google Maps"], "shots": {"0": {"k": 0, "answer": "Saving a location.", "latency_ms": 1933.9380264282227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "marking locations", "latency_ms": 2584.08784866333, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "marking locations", "latency_ms": 2423.9675998687744, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "to mark locations", "latency_ms": 2075.808525085449, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "to mark locations", "latency_ms": 2173.748016357422, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "marking locations", "latency_ms": 1556.1714172363281, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3211}, "6": {"k": 6, "answer": "to mark a location", "latency_ms": 2648.826837539673, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "6915606477668963399", "question": "what do the 3 dots mean in math", "gold_answers": ["the therefore sign", "therefore sign"], "shots": {"0": {"k": 0, "answer": "Ellipsis", "latency_ms": 1254.7485828399658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2348.9582538604736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2039.289951324463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Therefore", "latency_ms": 1798.15673828125, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "Therefore sign", "latency_ms": 1218.583583831787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Therefore", "latency_ms": 1258.744478225708, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3172}, "6": {"k": 6, "answer": "Therefore", "latency_ms": 990.6861782073975, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3844}}}
{"qid": "-8366545547296627039", "question": "who wrote the song photograph by ringo starr", "gold_answers": ["Richard Starkey", "George Harrison", "Ringo Starr"], "shots": {"0": {"k": 0, "answer": "Ringo Starr and George Harrison.", "latency_ms": 3264.7364139556885, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ringo Starr and George Harrison", "latency_ms": 2790.952205657959, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Ringo Starr and George Harrison", "latency_ms": 2960.6242179870605, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Ringo Starr and George Harrison", "latency_ms": 3405.3614139556885, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1985}, "4": {"k": 4, "answer": "Ringo Starr and George Harrison", "latency_ms": 2755.4423809051514, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2629}, "5": {"k": 5, "answer": "Ringo Starr and George Harrison", "latency_ms": 3552.5903701782227, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3357}, "6": {"k": 6, "answer": "Ringo Starr and George Harrison", "latency_ms": 4066.715955734253, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4036}}}
{"qid": "-5004457603684974952", "question": "who is playing the halftime show at super bowl 2016", "gold_answers": ["Beyoncé", "Coldplay", "Bruno Mars"], "shots": {"0": {"k": 0, "answer": "Coldplay", "latency_ms": 1589.423418045044, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 3249.0334510803223, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 634}, "2": {"k": 2, "answer": "Coldplay, Beyoncé and Bruno Mars", "latency_ms": 4754.535913467407, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Coldplay", "latency_ms": 1489.3200397491455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1958}, "4": {"k": 4, "answer": "Coldplay", "latency_ms": 1613.8195991516113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2618}, "5": {"k": 5, "answer": "Coldplay", "latency_ms": 2032.951831817627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3252}, "6": {"k": 6, "answer": "Coldplay, Beyoncé, and Bruno Mars", "latency_ms": 5099.668502807617, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3885}}}
{"qid": "7420920477821898435", "question": "to aru kagaku no railgun s episode 3", "gold_answers": ["Project Radio Noise"], "shots": {"0": {"k": 0, "answer": "Ability and Power", "latency_ms": 1954.69331741333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1905.7888984680176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2695.1382160186768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2278.265953063965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2567.7831172943115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2457}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2459.2392444610596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3012}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2728.908061981201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "7478795216476346339", "question": "who won the 2017 sports personality of the year", "gold_answers": ["Mo Farah"], "shots": {"0": {"k": 0, "answer": "Mo Farah", "latency_ms": 2163.224220275879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2499.159574508667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2441.784381866455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Geraint Thomas", "latency_ms": 1819.9267387390137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Geraint Thomas", "latency_ms": 1830.885410308838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "Geraint Thomas", "latency_ms": 1571.990966796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Geraint Thomas", "latency_ms": 2576.7195224761963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3848}}}
{"qid": "7217222058435937287", "question": "where was the world economic forum held this year", "gold_answers": ["Davos"], "shots": {"0": {"k": 0, "answer": "Davos, Switzerland", "latency_ms": 2072.5176334381104, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dubai", "latency_ms": 1497.2388744354248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 689}, "2": {"k": 2, "answer": "Dubai", "latency_ms": 1802.5894165039062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1362}, "3": {"k": 3, "answer": "Davos-Klosters", "latency_ms": 3348.9134311676025, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1989}, "4": {"k": 4, "answer": "Davos-Klosters", "latency_ms": 2599.8005867004395, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2674}, "5": {"k": 5, "answer": "Davos-Klosters", "latency_ms": 3898.7908363342285, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3305}, "6": {"k": 6, "answer": "Davos", "latency_ms": 1571.7599391937256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3945}}}
{"qid": "-143054837169120955", "question": "where are the giant redwoods located in california", "gold_answers": ["the coast of northern California", "Del Norte County", "Humboldt County"], "shots": {"0": {"k": 0, "answer": "Northern California.", "latency_ms": 2368.9095973968506, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Humboldt County", "latency_ms": 2168.5879230499268, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 719}, "2": {"k": 2, "answer": "Humboldt County, Northern California, and Fresno County", "latency_ms": 5373.703956604004, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1331}, "3": {"k": 3, "answer": "Humboldt County", "latency_ms": 1689.1989707946777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1969}, "4": {"k": 4, "answer": "Humboldt County, Northern California, Sierra Nevada", "latency_ms": 5063.441276550293, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2604}, "5": {"k": 5, "answer": "Humboldt County, Northern California, Sierra Nevada", "latency_ms": 5839.092969894409, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3249}, "6": {"k": 6, "answer": "Humboldt County, Northern California, Sierra Nevada", "latency_ms": 3841.615676879883, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3886}}}
{"qid": "4892429640540595424", "question": "who has made the most premier league appearances", "gold_answers": ["Gareth Barry"], "shots": {"0": {"k": 0, "answer": "Gareth Barry", "latency_ms": 1376.6436576843262, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gareth Barry", "latency_ms": 2558.6867332458496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Gareth Barry", "latency_ms": 1634.1817378997803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Gareth Barry", "latency_ms": 2121.998071670532, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1841}, "4": {"k": 4, "answer": "Gareth Barry", "latency_ms": 1257.9941749572754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2429}, "5": {"k": 5, "answer": "Gareth Barry", "latency_ms": 2373.4514713287354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3049}, "6": {"k": 6, "answer": "Gareth Barry", "latency_ms": 2094.230890274048, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3636}}}
{"qid": "5533906981191706877", "question": "who was the first chief minister of west bengal", "gold_answers": ["Prafulla Chandra Ghosh"], "shots": {"0": {"k": 0, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3750.5154609680176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Prafulla Chandra Ghosh", "latency_ms": 4081.451416015625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Prafulla Chandra Ghosh", "latency_ms": 4534.584283828735, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1408}, "3": {"k": 3, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3882.917881011963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2054}, "4": {"k": 4, "answer": "Prafulla Chandra Ghosh", "latency_ms": 4619.14587020874, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2740}, "5": {"k": 5, "answer": "Prafulla Chandra Ghosh", "latency_ms": 4027.3420810699463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3469}, "6": {"k": 6, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3672.701120376587, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4135}}}
{"qid": "8823076125131408628", "question": "who sings got my mind set on you", "gold_answers": ["George Harrison", "James Ray"], "shots": {"0": {"k": 0, "answer": "George Harrison", "latency_ms": 1658.7238311767578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2122.67804145813, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2383.1353187561035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1648.2312679290771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2362.983465194702, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2452}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2493.4751987457275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2125.8459091186523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3640}}}
{"qid": "9168660859139861094", "question": "two main types of research methods used in psychology", "gold_answers": ["Correlational research", "Descriptive research", "quantitative data", "Quantitative psychological research", "qualitative", "quantitative", "Qualitative psychological research", "Experimental research", "qualitative data"], "shots": {"0": {"k": 0, "answer": "Qualitative and Quantitative.", "latency_ms": 2375.1542568206787, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Qualitative or quantitative", "latency_ms": 1743.2441711425781, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 735}, "2": {"k": 2, "answer": "Qualitative or quantitative", "latency_ms": 2189.1770362854004, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1482}, "3": {"k": 3, "answer": "Qualitative or quantitative", "latency_ms": 2389.3978595733643, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2285}, "4": {"k": 4, "answer": "Qualitative or quantitative", "latency_ms": 2979.5212745666504, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3089}, "5": {"k": 5, "answer": "Qualitative or quantitative", "latency_ms": 2726.6197204589844, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3898}, "6": {"k": 6, "answer": "Qualitative or quantitative", "latency_ms": 1670.3088283538818, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4640}}}
{"qid": "-7073063191952855764", "question": "who plays peter in what we do in the shadows", "gold_answers": ["Ben Fransham"], "shots": {"0": {"k": 0, "answer": "Kayvan Novak", "latency_ms": 2745.0110912323, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1936.9690418243408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2227.755069732666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2707.6101303100586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1911}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2757.601022720337, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2183.389186859131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1898.7977504730225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3859}}}
{"qid": "7901746249864619718", "question": "when does the 14th season of grey's anatomy come out", "gold_answers": ["September 28 , 2017"], "shots": {"0": {"k": 0, "answer": "September 28, 2017", "latency_ms": 3407.9482555389404, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 28, 2017", "latency_ms": 2318.483591079712, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 28, 2017", "latency_ms": 3329.124927520752, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1402}, "3": {"k": 3, "answer": "September 28, 2017", "latency_ms": 2975.240468978882, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 28, 2017", "latency_ms": 2632.279872894287, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2678}, "5": {"k": 5, "answer": "September 28, 2017", "latency_ms": 3598.5326766967773, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3366}, "6": {"k": 6, "answer": "September 28, 2017", "latency_ms": 3562.1705055236816, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3962}}}
{"qid": "-896127746191949637", "question": "when was the first hunger games book published", "gold_answers": ["September 14 , 2008", "2008"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 544.7225570678711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 14, 2008", "latency_ms": 3640.0835514068604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "September 14, 2008", "latency_ms": 3115.6246662139893, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1342}, "3": {"k": 3, "answer": "September 14, 2008", "latency_ms": 2773.7951278686523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1941}, "4": {"k": 4, "answer": "September 14, 2008", "latency_ms": 3854.53200340271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2593}, "5": {"k": 5, "answer": "September 14, 2008", "latency_ms": 4127.158164978027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3243}, "6": {"k": 6, "answer": "September 14, 2008", "latency_ms": 3403.0306339263916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3914}}}
{"qid": "8044909700499569711", "question": "how much is the united states in debt to china", "gold_answers": ["$1.06 trillion", "1,200.5"], "shots": {"0": {"k": 0, "answer": "$1.08 trillion", "latency_ms": 2283.646583557129, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$1.16 trillion", "latency_ms": 2400.545835494995, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "$1.18 trillion", "latency_ms": 2542.246103286743, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "$1.18 trillion", "latency_ms": 3042.523145675659, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "$1.18 trillion", "latency_ms": 2505.789279937744, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "$1.18 trillion", "latency_ms": 3552.3946285247803, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3223}, "6": {"k": 6, "answer": "$1.18 trillion", "latency_ms": 2055.6130409240723, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3867}}}
{"qid": "-3123234845590594961", "question": "where did the race in grease take place", "gold_answers": ["Thunder Road"], "shots": {"0": {"k": 0, "answer": "The Thunder Road race track", "latency_ms": 1712.683916091919, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles River", "latency_ms": 2094.416618347168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Los Angeles River", "latency_ms": 1758.0502033233643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Los Angeles River", "latency_ms": 1678.584098815918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1794}, "4": {"k": 4, "answer": "Los Angeles River", "latency_ms": 1258.056879043579, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2388}, "5": {"k": 5, "answer": "Los Angeles River", "latency_ms": 2609.467029571533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3082}, "6": {"k": 6, "answer": "Los Angeles River", "latency_ms": 1843.736171722412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3721}}}
{"qid": "4326992806019599297", "question": "what is the maximum data rate for the 802.11a standard select one", "gold_answers": ["54 Mbit / s"], "shots": {"0": {"k": 0, "answer": "54 Mbps", "latency_ms": 1326.2500762939453, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "54 Mbit/s", "latency_ms": 1919.5940494537354, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "54 Mbit/s", "latency_ms": 2014.559268951416, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "54 Mbit/s", "latency_ms": 2169.090986251831, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1900}, "4": {"k": 4, "answer": "54 Mbit/s", "latency_ms": 1633.110523223877, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2593}, "5": {"k": 5, "answer": "54 Mbit/s", "latency_ms": 1819.8647499084473, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3293}, "6": {"k": 6, "answer": "54 Mbit/s", "latency_ms": 2970.0212478637695, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3862}}}
{"qid": "6144099837933283715", "question": "a good that can be used in place of another good", "gold_answers": ["A substitute good", "substitute good"], "shots": {"0": {"k": 0, "answer": "Substitute", "latency_ms": 1563.0474090576172, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Substitute", "latency_ms": 1497.8036880493164, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Substitute", "latency_ms": 1760.1194381713867, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Substitute", "latency_ms": 1783.4091186523438, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "Substitute", "latency_ms": 1490.5648231506348, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Substitute", "latency_ms": 2051.236629486084, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "Pickling salt", "latency_ms": 2544.7404384613037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3602}}}
{"qid": "-4621948696356225060", "question": "where in the bible can i find the lord's prayer", "gold_answers": ["the Gospel of Luke", "the Gospel of Matthew"], "shots": {"0": {"k": 0, "answer": "Matthew 6:9-13, Luke 11:2-4", "latency_ms": 5352.956533432007, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matthew 6:9", "latency_ms": 1994.854211807251, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 544}, "2": {"k": 2, "answer": "Matthew 6:9", "latency_ms": 2737.7102375030518, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1103}, "3": {"k": 3, "answer": "Matthew 6:9-13", "latency_ms": 3653.0168056488037, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1684}, "4": {"k": 4, "answer": "Matthew 6", "latency_ms": 2139.5983695983887, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2322}, "5": {"k": 5, "answer": "Matthew 6:9-13", "latency_ms": 2697.3812580108643, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2876}, "6": {"k": 6, "answer": "Matthew 6:9-13", "latency_ms": 3102.1978855133057, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3448}}}
{"qid": "6941993254369956277", "question": "when was the last time nebraska voted democrat", "gold_answers": ["1964"], "shots": {"0": {"k": 0, "answer": "1964", "latency_ms": 1070.521593093872, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Before 1860", "latency_ms": 2672.6198196411133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "2006", "latency_ms": 2245.9182739257812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "2006", "latency_ms": 1771.3313102722168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2007}, "4": {"k": 4, "answer": "2008", "latency_ms": 1269.0043449401855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2672}, "5": {"k": 5, "answer": "1964", "latency_ms": 1286.2052917480469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3323}, "6": {"k": 6, "answer": "1964", "latency_ms": 2301.3134002685547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3946}}}
{"qid": "-8955197065025093046", "question": "who become the ceo of it wipro company in 2016", "gold_answers": ["Abid Ali Neemuchwala"], "shots": {"0": {"k": 0, "answer": "Abidali Neemuchwala", "latency_ms": 3443.1488513946533, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Abidali Neemuchwala", "latency_ms": 3457.195043563843, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "Abidali Neemuchwala", "latency_ms": 3599.539041519165, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "Abidali Neemuchwala", "latency_ms": 3890.7885551452637, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "Abidali Neemuchwala", "latency_ms": 3396.829843521118, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Abidali Neemuchwala", "latency_ms": 3104.2447090148926, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3301}, "6": {"k": 6, "answer": "Abidali Neemuchwala", "latency_ms": 2906.3241481781006, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3908}}}
{"qid": "-3010425579521817304", "question": "who does eric end up with in gossip girl", "gold_answers": ["Jenny"], "shots": {"0": {"k": 0, "answer": "Vanessa, then ultimately Serena", "latency_ms": 2561.594009399414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2972.1322059631348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2180.799961090088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1247}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2436.8906021118164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1903}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2159.6827507019043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2515}, "5": {"k": 5, "answer": "Jenny", "latency_ms": 1818.838119506836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3100}, "6": {"k": 6, "answer": "Jenny", "latency_ms": 2281.870126724243, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3737}}}
{"qid": "7264112453286983469", "question": "who plays unis in she's the man", "gold_answers": ["Emily Perkins"], "shots": {"0": {"k": 0, "answer": "Amanda Bynes", "latency_ms": 2263.258934020996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1834.0046405792236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1695.6408023834229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3312.0639324188232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1938.4260177612305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2663.987636566162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1747.5829124450684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3761}}}
{"qid": "2627695648792729859", "question": "who played booster in jingle all the way", "gold_answers": ["Curtis Armstrong"], "shots": {"0": {"k": 0, "answer": "Eric Lloyd", "latency_ms": 2066.2856101989746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1874.1860389709473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2299.588680267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3010.4997158050537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "Phil Hartman", "latency_ms": 2522.6571559906006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2568}, "5": {"k": 5, "answer": "Phil Hartman", "latency_ms": 1621.795892715454, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3257}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3743.936777114868, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3938}}}
{"qid": "-9169976182548289414", "question": "who is recognized as the founder of islam", "gold_answers": ["the Islamic prophet Muhammad", "Muhammad"], "shots": {"0": {"k": 0, "answer": "Muhammad", "latency_ms": 1137.9079818725586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Muhammad", "latency_ms": 1749.6774196624756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 636}, "2": {"k": 2, "answer": "Muhammad", "latency_ms": 1186.7499351501465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Muhammad", "latency_ms": 2244.027614593506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Muhammad", "latency_ms": 1833.6212635040283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2549}, "5": {"k": 5, "answer": "Muhammad", "latency_ms": 1816.4787292480469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Muhammad", "latency_ms": 2047.598123550415, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3842}}}
{"qid": "-6696747560626271522", "question": "who plays emma in air bud world pup", "gold_answers": ["Brittany Paige Bouck"], "shots": {"0": {"k": 0, "answer": "Brittany Paige Bouck", "latency_ms": 2465.1639461517334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2843.007802963257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "Chantal Strand", "latency_ms": 1693.6025619506836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Chantal Strand", "latency_ms": 1817.1889781951904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1924}, "4": {"k": 4, "answer": "Chantal Strand", "latency_ms": 2180.532217025757, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "Chantal Strand", "latency_ms": 1676.368236541748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Tammy", "latency_ms": 2028.6378860473633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3872}}}
{"qid": "5871681964137793716", "question": "how old was sasuke when his clan died", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "7 years old", "latency_ms": 785.2823734283447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seven", "latency_ms": 1949.7098922729492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Seven", "latency_ms": 1191.8511390686035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1258}, "3": {"k": 3, "answer": "Seven", "latency_ms": 1001.6851425170898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Seven", "latency_ms": 728.3062934875488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2479}, "5": {"k": 5, "answer": "Seven", "latency_ms": 1791.3236618041992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3114}, "6": {"k": 6, "answer": "Seven", "latency_ms": 620.7473278045654, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3692}}}
{"qid": "8552176802923865025", "question": "where do some of the natural air pollutants come from", "gold_answers": ["wildfires", "Dust", "Vegetation", "Carbon dioxide", "Volcanic activity"], "shots": {"0": {"k": 0, "answer": "Volcanic eruptions.", "latency_ms": 2768.3632373809814, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "volcanic eruption", "latency_ms": 2446.0244178771973, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Volcanic eruptions, forest fires", "latency_ms": 3930.6445121765137, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1408}, "3": {"k": 3, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity.", "latency_ms": 8927.402257919312, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 2128}, "4": {"k": 4, "answer": "forest fires, volcanic eruptions, wind erosion, pollen dispersal, evaporation of organic compounds, and natural radioactivity.", "latency_ms": 9338.046312332153, "em": 0.0, "f1": 0.1176470588235294, "containment": 0.0, "context_chars": 2745}, "5": {"k": 5, "answer": "Volcanic eruptions, forest fires, wind erosion, pollen dispersal.", "latency_ms": 6786.6151332855225, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 3349}, "6": {"k": 6, "answer": "Volcanic eruptions, forest fires, wind erosion, pollen dispersal.", "latency_ms": 7166.463851928711, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 4024}}}
{"qid": "-2630525064809360052", "question": "who is the pastor of new birth missionary baptist church now", "gold_answers": ["Stephen A. Davis"], "shots": {"0": {"k": 0, "answer": "Jamal Harrison Bryant", "latency_ms": 1811.8772506713867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jamal Bryant", "latency_ms": 2067.718744277954, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Jamal Bryant", "latency_ms": 2112.614870071411, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1353}, "3": {"k": 3, "answer": "Jamal Bryant", "latency_ms": 2347.571611404419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2018}, "4": {"k": 4, "answer": "Jamal Bryant", "latency_ms": 1846.7686176300049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2639}, "5": {"k": 5, "answer": "Jamal Bryant", "latency_ms": 1938.2920265197754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3276}, "6": {"k": 6, "answer": "Jamal Bryant", "latency_ms": 1674.4797229766846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3907}}}
{"qid": "6434931911289860123", "question": "who is doing 2018 super bowl half time show", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "Justin Timberlake", "latency_ms": 1402.726650238037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Timberlake", "latency_ms": 1926.7683029174805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "Justin Timberlake", "latency_ms": 2433.654546737671, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1291}, "3": {"k": 3, "answer": "Justin Timberlake", "latency_ms": 1819.9009895324707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Justin Timberlake", "latency_ms": 2078.1493186950684, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Justin Timberlake", "latency_ms": 1700.3788948059082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3237}, "6": {"k": 6, "answer": "Justin Timberlake", "latency_ms": 2397.458791732788, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3890}}}
{"qid": "8869318258439148973", "question": "who is playing the halftime show for the superbowl", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "Rihanna", "latency_ms": 793.4238910675049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Janet Jackson and Justin Timberlake", "latency_ms": 2557.1563243865967, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "Katy Perry", "latency_ms": 1625.1225471496582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "Lady Gaga", "latency_ms": 2243.7989711761475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1998}, "4": {"k": 4, "answer": "Maroon 5", "latency_ms": 1976.8061637878418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2630}, "5": {"k": 5, "answer": "Maroon 5", "latency_ms": 2935.4403018951416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "Maroon 5", "latency_ms": 1383.1298351287842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3891}}}
{"qid": "-8359866474144720253", "question": "who hosted they think it's all over", "gold_answers": ["Des Lynam", "Lee Mack", "comedian Nick Hancock", "Nick Hancock"], "shots": {"0": {"k": 0, "answer": "Nick Hancock", "latency_ms": 1834.0766429901123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2098.316431045532, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2327.2438049316406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2420.2165603637695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1969.7401523590088, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2554}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2198.744535446167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3179}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2859.43603515625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3852}}}
{"qid": "-1206653570097564556", "question": "where does the movie proof of life take place", "gold_answers": ["The Republic of Tecala"], "shots": {"0": {"k": 0, "answer": "South America", "latency_ms": 1825.3943920135498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Republic of Tecala", "latency_ms": 2680.1364421844482, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "The Republic of Tecala", "latency_ms": 3428.1420707702637, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1226}, "3": {"k": 3, "answer": "The Republic of Tecala", "latency_ms": 2362.3855113983154, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "The Republic of Tecala", "latency_ms": 3007.36665725708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2524}, "5": {"k": 5, "answer": "The Republic of Tecala", "latency_ms": 3191.1396980285645, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3122}, "6": {"k": 6, "answer": "The Republic of Tecala, a fictional South American country.", "latency_ms": 3608.449935913086, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3719}}}
{"qid": "6144521615402262404", "question": "where does us highway 1 start and end", "gold_answers": ["Fort Kent , Maine", "to Key West , Florida", "Key West , Florida"], "shots": {"0": {"k": 0, "answer": "Fort Kent, Maine to Key West, Florida", "latency_ms": 4152.857065200806, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2133.5206031799316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2658.4551334381104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2933.682441711426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2472.360849380493, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2453}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2414.449691772461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3049}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2753.4148693084717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}}}
{"qid": "-8631190913794477985", "question": "who scored the most points in a single game in the nba", "gold_answers": ["Wilt Chamberlain"], "shots": {"0": {"k": 0, "answer": "Wilt Chamberlain, 100 points", "latency_ms": 3756.8626403808594, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wilt Chamberlain", "latency_ms": 2201.1303901672363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "Wilt Chamberlain", "latency_ms": 2914.3404960632324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1317}, "3": {"k": 3, "answer": "Wilt Chamberlain", "latency_ms": 2878.631830215454, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1984}, "4": {"k": 4, "answer": "Wilt Chamberlain", "latency_ms": 1465.2884006500244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2637}, "5": {"k": 5, "answer": "Wilt Chamberlain", "latency_ms": 2146.101713180542, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3239}, "6": {"k": 6, "answer": "Wilt Chamberlain", "latency_ms": 2708.9028358459473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3889}}}
{"qid": "199896377614951764", "question": "where is natural gas found in the us", "gold_answers": ["Texas", "Pennsylvania", "Colorado", "New Mexico", "West Virginia", "Arkansas", "Wyoming", "Louisiana"], "shots": {"0": {"k": 0, "answer": "Texas, Oklahoma, Louisiana, Alaska, and Pennsylvania.", "latency_ms": 5159.4078540802, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pennsylvania, West Virginia, Ohio, and New York.", "latency_ms": 4707.415342330933, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "Pennsylvania, West Virginia, Ohio, New York, Kansas", "latency_ms": 5991.182565689087, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 1238}, "3": {"k": 3, "answer": "Pennsylvania, West Virginia, Ohio, New York, Kansas, Louisiana, Texas, California, Alaska", "latency_ms": 7440.202474594116, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Pennsylvania, West Virginia, Ohio, New York, Louisiana, Texas, California, Alaska, Kansas", "latency_ms": 7291.333198547363, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 2546}, "5": {"k": 5, "answer": "Pennsylvania, West Virginia, Ohio, New York, Louisiana, Texas, California, Alaska, Kansas", "latency_ms": 7988.053798675537, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 3157}, "6": {"k": 6, "answer": "Louisiana, Texas, California, Alaska, Pennsylvania, West Virginia, Ohio, New York, Kansas, Indiana", "latency_ms": 8129.237174987793, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 3764}}}
{"qid": "8986775680996674901", "question": "when were the first general elections held in independent india", "gold_answers": ["1951 -- 52"], "shots": {"0": {"k": 0, "answer": "1951-52", "latency_ms": 2148.763418197632, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "January 1952", "latency_ms": 1910.1097583770752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "January 1952", "latency_ms": 2192.2621726989746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "January 1952", "latency_ms": 1910.128116607666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1939}, "4": {"k": 4, "answer": "25 October 1951 and 27 March 1952", "latency_ms": 5268.797874450684, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2587}, "5": {"k": 5, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 4786.351442337036, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 3250}, "6": {"k": 6, "answer": "25 October 1951 and 27 March 1952", "latency_ms": 4477.174997329712, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 3915}}}
{"qid": "700604097171850168", "question": "what was the tower of london originally used for", "gold_answers": ["as a royal residence", "a royal residence"], "shots": {"0": {"k": 0, "answer": "Royal Palace and Fortress", "latency_ms": 2157.9556465148926, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Norman Conquest of England", "latency_ms": 3739.6862506866455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 568}, "2": {"k": 2, "answer": "Timber fortification", "latency_ms": 1646.5063095092773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "as a castle", "latency_ms": 1218.0767059326172, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1842}, "4": {"k": 4, "answer": "as a timber fortification and castle", "latency_ms": 3516.0892009735107, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2453}, "5": {"k": 5, "answer": "as a timber fortification and castle", "latency_ms": 3240.6907081604004, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3076}, "6": {"k": 6, "answer": "incidental role of holding prisoners and as a castle", "latency_ms": 4105.78179359436, "em": 0.0, "f1": 0.18181818181818182, "containment": 0.0, "context_chars": 3660}}}
{"qid": "6745303307988470742", "question": "what type of fuel goes in a zippo", "gold_answers": ["butane", "lighter fluid"], "shots": {"0": {"k": 0, "answer": "Lighter fluid", "latency_ms": 1586.2376689910889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 6642.006397247314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 5659.511566162109, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "light petroleum distillate or naphtha", "latency_ms": 3733.4489822387695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1841}, "4": {"k": 4, "answer": "light petroleum distillate or naphtha", "latency_ms": 3515.549421310425, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 4521.14200592041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3158}, "6": {"k": 6, "answer": "naphtha or butane", "latency_ms": 3351.893663406372, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3845}}}
{"qid": "-2060506905455252030", "question": "first jnanpith award was an autor of which language", "gold_answers": ["Malayalam"], "shots": {"0": {"k": 0, "answer": "Gujarati", "latency_ms": 1234.0216636657715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Malayalam", "latency_ms": 1849.6625423431396, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 669}, "2": {"k": 2, "answer": "Malayalam", "latency_ms": 2168.8098907470703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1345}, "3": {"k": 3, "answer": "Malayalam", "latency_ms": 1860.9416484832764, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1993}, "4": {"k": 4, "answer": "Malayalam", "latency_ms": 1090.090274810791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2689}, "5": {"k": 5, "answer": "Malayalam", "latency_ms": 1592.9601192474365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3352}, "6": {"k": 6, "answer": "Malayalam", "latency_ms": 1618.9663410186768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4011}}}
{"qid": "4738663028303377024", "question": "who played the mad hatter in the batman tv show", "gold_answers": ["Roddy McDowall", "David Wayne", "Benedict Samuel"], "shots": {"0": {"k": 0, "answer": "David Wayne", "latency_ms": 1287.3351573944092, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Benedict Samuel", "latency_ms": 1977.6651859283447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 636}, "2": {"k": 2, "answer": "Benedict Samuel", "latency_ms": 1682.032585144043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Benedict Samuel", "latency_ms": 2437.4542236328125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1900}, "4": {"k": 4, "answer": "David Wayne", "latency_ms": 1786.5345478057861, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2541}, "5": {"k": 5, "answer": "Benedict Samuel", "latency_ms": 1456.566333770752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3215}, "6": {"k": 6, "answer": "David Wayne", "latency_ms": 1538.2392406463623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3870}}}
{"qid": "-1650946015201779846", "question": "how many cracker barrels in the united states", "gold_answers": ["639", "more than 600"], "shots": {"0": {"k": 0, "answer": "664", "latency_ms": 513.9579772949219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "645 stores in 44 states", "latency_ms": 2939.281702041626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "645 stores in 44 states", "latency_ms": 3511.441707611084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1257}, "3": {"k": 3, "answer": "645 stores in 44 states", "latency_ms": 3799.776315689087, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1941}, "4": {"k": 4, "answer": "645 stores in 44 states", "latency_ms": 2815.2108192443848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2608}, "5": {"k": 5, "answer": "645 stores in 44 states", "latency_ms": 3277.066707611084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3233}, "6": {"k": 6, "answer": "645 stores in 44 states", "latency_ms": 2797.220230102539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3850}}}
{"qid": "-3422350952909582054", "question": "in photosynthesis the carbon in co2 is initially fixed to what molecule", "gold_answers": ["3 - phosphoglycerate"], "shots": {"0": {"k": 0, "answer": "RuBP (Ribulose-1,5-Bisphosphate)", "latency_ms": 4612.120866775513, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 4211.4362716674805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 712}, "2": {"k": 2, "answer": "ribulose 1,5-bisphosphate", "latency_ms": 4689.380645751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1441}, "3": {"k": 3, "answer": "Ribulose 1,5-bisphosphate", "latency_ms": 4084.2859745025635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2110}, "4": {"k": 4, "answer": "Ribulose 1,5-bisphosphate", "latency_ms": 4543.572664260864, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2820}, "5": {"k": 5, "answer": "Ribulose 1,5-bisphosphate", "latency_ms": 5327.865123748779, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3515}, "6": {"k": 6, "answer": "Ribulose 1,5-bisphosphate", "latency_ms": 4635.16902923584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4316}}}
{"qid": "-2704708103393811482", "question": "who voices randy in f is for family", "gold_answers": ["T.J. Miller"], "shots": {"0": {"k": 0, "answer": "Bill Burr", "latency_ms": 538.8989448547363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parker", "latency_ms": 1464.43772315979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "Bill Burr", "latency_ms": 1799.647569656372, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "Bill Burr", "latency_ms": 1022.3519802093506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "Bill Burr", "latency_ms": 2113.926649093628, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2522}, "5": {"k": 5, "answer": "Bill Burr", "latency_ms": 1502.4511814117432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3151}, "6": {"k": 6, "answer": "Bill Burr", "latency_ms": 1477.574110031128, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3804}}}
{"qid": "5482012214308896475", "question": "how many countries does cadbury sell its products", "gold_answers": ["more than 50", "more than 50 countries worldwide"], "shots": {"0": {"k": 0, "answer": "160 countries", "latency_ms": 1873.4869956970215, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "more than 50 countries", "latency_ms": 2320.512533187866, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 706}, "2": {"k": 2, "answer": "more than 50 countries", "latency_ms": 2248.9521503448486, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 1405}, "3": {"k": 3, "answer": "50", "latency_ms": 1700.2885341644287, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2039}, "4": {"k": 4, "answer": "more than 50 countries", "latency_ms": 2725.999593734741, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 2743}, "5": {"k": 5, "answer": "more than 50 countries", "latency_ms": 3257.272243499756, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 3397}, "6": {"k": 6, "answer": "more than 50 countries", "latency_ms": 2584.8774909973145, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 4010}}}
{"qid": "-5737509619250561344", "question": "ethiopia flight 961 crashes in to the sea", "gold_answers": ["23 November 1996"], "shots": {"0": {"k": 0, "answer": "November 23, 1996", "latency_ms": 2760.7874870300293, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indian Ocean", "latency_ms": 1250.8749961853027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Indian Ocean", "latency_ms": 1262.415885925293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Indian Ocean", "latency_ms": 2815.0057792663574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Indian Ocean", "latency_ms": 1236.860990524292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2507}, "5": {"k": 5, "answer": "Indian Ocean", "latency_ms": 1559.6489906311035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "Indian Ocean", "latency_ms": 2083.15372467041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3779}}}
{"qid": "-7175456993713717070", "question": "what does istj mean in a personality test", "gold_answers": ["Extroverted Thinking ( Te )", "Extroverted Intuition ( Ne )", "Introverted Feeling ( Fi )", "Introverted Sensing ( Si )"], "shots": {"0": {"k": 0, "answer": "Introverted, Sensing, Thinking, Judging.", "latency_ms": 4021.735191345215, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 3584.6121311187744, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 724}, "2": {"k": 2, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 2754.1117668151855, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4043.271780014038, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2085}, "4": {"k": 4, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4631.546258926392, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2713}, "5": {"k": 5, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4566.578388214111, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3424}, "6": {"k": 6, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4049.48091506958, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4140}}}
{"qid": "4437170343606050664", "question": "who does the voice of ash in sing", "gold_answers": ["Scarlett Johansson"], "shots": {"0": {"k": 0, "answer": "Scarlett Johansson", "latency_ms": 2326.4381885528564, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Veronica Taylor", "latency_ms": 1534.8341464996338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "Veronica Taylor", "latency_ms": 2028.8736820220947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2328.430652618408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "Rica Matsumoto", "latency_ms": 2582.207679748535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2484}, "5": {"k": 5, "answer": "Rica Matsumoto", "latency_ms": 2511.495351791382, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3133}, "6": {"k": 6, "answer": "Rica Matsumoto", "latency_ms": 2463.352680206299, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3720}}}
{"qid": "-8773010039077552394", "question": "who scored the most points in their nba career", "gold_answers": ["Kareem Abdul - Jabbar"], "shots": {"0": {"k": 0, "answer": "LeBron James", "latency_ms": 1844.7120189666748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Jordan", "latency_ms": 1257.610559463501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Kareem Abdul-Jabbar", "latency_ms": 3589.5986557006836, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "Kareem Abdul-Jabbar", "latency_ms": 2068.0863857269287, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "Kareem Abdul-Jabbar", "latency_ms": 3140.284776687622, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2437}, "5": {"k": 5, "answer": "Kareem Abdul-Jabbar", "latency_ms": 3218.3890342712402, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3014}, "6": {"k": 6, "answer": "Kareem Abdul-Jabbar", "latency_ms": 3329.5609951019287, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3668}}}
{"qid": "-3278224144622911032", "question": "with a land area of 54 314 square miles where does wisconsin rank among the 50 states", "gold_answers": ["25"], "shots": {"0": {"k": 0, "answer": "23rd", "latency_ms": 1075.3974914550781, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1677.196979522705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2062.612295150757, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1190}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2905.405282974243, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1760}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2420.456886291504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2347}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2418.588876724243, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2958}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2342.893600463867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3557}}}
{"qid": "-3466298422174960041", "question": "who plays charles on have and have nots", "gold_answers": ["Nick Sager", "Nick Sagar"], "shots": {"0": {"k": 0, "answer": "Renée Lawless", "latency_ms": 1673.1390953063965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1905.073642730713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Peter Parros", "latency_ms": 1793.5223579406738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Peter Parros", "latency_ms": 1805.2115440368652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Peter Parros", "latency_ms": 2111.746072769165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Peter Parros", "latency_ms": 1433.211088180542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Peter Parros", "latency_ms": 1587.0780944824219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3753}}}
{"qid": "1803248910342766083", "question": "who wrote the book my country my life", "gold_answers": ["L.K. Advani"], "shots": {"0": {"k": 0, "answer": "L.K. Advani", "latency_ms": 2453.2289505004883, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "L. K. Advani", "latency_ms": 2737.154245376587, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "L. K. Advani", "latency_ms": 3063.3723735809326, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1158}, "3": {"k": 3, "answer": "L. K. Advani", "latency_ms": 2338.25421333313, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1789}, "4": {"k": 4, "answer": "L. K. Advani", "latency_ms": 3037.2183322906494, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2455}, "5": {"k": 5, "answer": "L. K. Advani", "latency_ms": 2432.703733444214, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3098}, "6": {"k": 6, "answer": "L. K. Advani", "latency_ms": 2781.158685684204, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3679}}}
{"qid": "-1176280233636154422", "question": "when did the east india company take control of india", "gold_answers": ["1757", "1799", "1612", "in 1757"], "shots": {"0": {"k": 0, "answer": "1757", "latency_ms": 1709.5167636871338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1757", "latency_ms": 1524.634599685669, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "1757", "latency_ms": 1760.0042819976807, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1349}, "3": {"k": 3, "answer": "1757", "latency_ms": 1528.7399291992188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1967}, "4": {"k": 4, "answer": "By 1818", "latency_ms": 1154.6134948730469, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2622}, "5": {"k": 5, "answer": "By 1818", "latency_ms": 3002.2988319396973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3285}, "6": {"k": 6, "answer": "By 1818", "latency_ms": 2096.5428352355957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3920}}}
{"qid": "5911119091653953181", "question": "where does the water come from to fill lake eyre", "gold_answers": ["Warburton River"], "shots": {"0": {"k": 0, "answer": "Cooper Creek and Diamantina River", "latency_ms": 3470.15118598938, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the west, the Channel Country of Queensland", "latency_ms": 3755.772113800049, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "the west, the Channel Country of Queensland", "latency_ms": 3157.5913429260254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1179}, "3": {"k": 3, "answer": "the west, the Channel Country of Queensland", "latency_ms": 2239.74609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1776}, "4": {"k": 4, "answer": "the west, the Channel Country of Queensland", "latency_ms": 3428.2641410827637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2407}, "5": {"k": 5, "answer": "the west, the Channel Country of Queensland", "latency_ms": 3548.229217529297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3028}, "6": {"k": 6, "answer": "the west, the Channel Country of Queensland", "latency_ms": 3125.804901123047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3610}}}
{"qid": "5557104327881436095", "question": "who is the founder of google and when was it founded", "gold_answers": ["1998", "Sergey Brin", "Larry Page and Sergey Brin", "Larry Page"], "shots": {"0": {"k": 0, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 3905.1830768585205, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Larry Page and Sergey Brin, September 1998", "latency_ms": 4223.713636398315, "em": 0.0, "f1": 0.8333333333333333, "containment": 1.0, "context_chars": 680}, "2": {"k": 2, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 4427.382230758667, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 1358}, "3": {"k": 3, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 4094.9320793151855, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 2002}, "4": {"k": 4, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 5028.893947601318, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 2648}, "5": {"k": 5, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 4292.392253875732, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 5538.956880569458, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 3946}}}
{"qid": "-1333328812971005142", "question": "who did the dominican republic gain its independence from", "gold_answers": ["Haiti"], "shots": {"0": {"k": 0, "answer": "Haiti", "latency_ms": 1299.0119457244873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haiti", "latency_ms": 2249.248504638672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 635}, "2": {"k": 2, "answer": "Haiti", "latency_ms": 1768.8472270965576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Haiti", "latency_ms": 1882.228136062622, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2010}, "4": {"k": 4, "answer": "Haiti", "latency_ms": 2090.1572704315186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2696}, "5": {"k": 5, "answer": "Haiti", "latency_ms": 2074.0270614624023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3404}, "6": {"k": 6, "answer": "Haiti", "latency_ms": 2085.7105255126953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4073}}}
{"qid": "1122605495295045742", "question": "how did early humans make use of stones during the prehistoric period", "gold_answers": ["start fires", "hunt", "bury their dead"], "shots": {"0": {"k": 0, "answer": "Tool making.", "latency_ms": 1120.708703994751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 5307.328701019287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 7006.8910121917725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 5728.555202484131, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 7051.282167434692, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 5509.267091751099, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3211}, "6": {"k": 6, "answer": "to make implements with an edge, a point, or a percussion surface.", "latency_ms": 6459.0163230896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3865}}}
{"qid": "7402184777947527945", "question": "who wrote the text for jeanie with the light brown hair", "gold_answers": ["Stephen Foster"], "shots": {"0": {"k": 0, "answer": "Maud Irving", "latency_ms": 2145.73335647583, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stephen Foster", "latency_ms": 1570.1160430908203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Stephen Foster", "latency_ms": 1784.172534942627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Stephen Foster", "latency_ms": 1512.5489234924316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Stephen Foster", "latency_ms": 1033.2255363464355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2522}, "5": {"k": 5, "answer": "Stephen Foster", "latency_ms": 1811.9657039642334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Stephen Foster", "latency_ms": 2095.752954483032, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3844}}}
{"qid": "1656745334095178455", "question": "the basic steps of rational decision making include defining goals and", "gold_answers": ["Implementation of plans / policies"], "shots": {"0": {"k": 0, "answer": "identifying alternatives", "latency_ms": 1793.351650238037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "problem definition", "latency_ms": 1998.3723163604736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 774}, "2": {"k": 2, "answer": "problem definition", "latency_ms": 1777.5609493255615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1428}, "3": {"k": 3, "answer": "problem definition", "latency_ms": 1526.7610549926758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2194}, "4": {"k": 4, "answer": "problem definition", "latency_ms": 1295.4354286193848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2912}, "5": {"k": 5, "answer": "problem definition", "latency_ms": 2575.432062149048, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3568}, "6": {"k": 6, "answer": "problem definition", "latency_ms": 810.0688457489014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4256}}}
{"qid": "-216657635823030751", "question": "when was the design period known as art deco", "gold_answers": ["1910 -- 1939"], "shots": {"0": {"k": 0, "answer": "1920-1940", "latency_ms": 2313.7266635894775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "just before World War I", "latency_ms": 3432.1906566619873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "just before World War I", "latency_ms": 2905.5566787719727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1362}, "3": {"k": 3, "answer": "1920s through the 1930s", "latency_ms": 3986.0265254974365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2065}, "4": {"k": 4, "answer": "1910 to 1940", "latency_ms": 3194.493532180786, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2695}, "5": {"k": 5, "answer": "1920s through the 1930s", "latency_ms": 4482.848644256592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3358}, "6": {"k": 6, "answer": "1920s through the 1930s", "latency_ms": 3677.5596141815186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4026}}}
{"qid": "250542332339248886", "question": "where does the bob and tom show broadcast from", "gold_answers": ["WFBQ in Indianapolis , Indiana", "Indianapolis , Indiana"], "shots": {"0": {"k": 0, "answer": "Indianapolis, Indiana", "latency_ms": 976.9775867462158, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indianapolis, Indiana", "latency_ms": 2459.4781398773193, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 4681.335687637329, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 4206.208944320679, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 3522.280216217041, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2510}, "5": {"k": 5, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 3309.553861618042, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3150}, "6": {"k": 6, "answer": "WFBQ's studios in Indianapolis, Indiana", "latency_ms": 4494.818925857544, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3764}}}
{"qid": "7610758795954724809", "question": "star wars the clone wars season 3 episode 1", "gold_answers": ["Clone Cadets"], "shots": {"0": {"k": 0, "answer": "Clone Cadets", "latency_ms": 1844.9738025665283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nightsisters", "latency_ms": 2160.9108448028564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1910.7904434204102, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2127.7472972869873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1944}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2715.5888080596924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2619}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2976.1152267456055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3244}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2152.8632640838623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3929}}}
{"qid": "2997223939033016160", "question": "what part of brain is responsible for complex thinking", "gold_answers": ["the frontal lobe"], "shots": {"0": {"k": 0, "answer": "Prefrontal cortex", "latency_ms": 2566.8842792510986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cerebral cortex", "latency_ms": 2392.2016620635986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "Cerebral cortex", "latency_ms": 2694.890022277832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1350}, "3": {"k": 3, "answer": "Cerebral cortex", "latency_ms": 2499.0758895874023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2063}, "4": {"k": 4, "answer": "Cerebral cortex", "latency_ms": 2185.7571601867676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2760}, "5": {"k": 5, "answer": "Cerebral cortex", "latency_ms": 2980.095624923706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3464}, "6": {"k": 6, "answer": "Cerebral cortex", "latency_ms": 2389.8239135742188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4139}}}
{"qid": "2680196226239522881", "question": "who won the champions league final in 2016", "gold_answers": ["Real Madrid"], "shots": {"0": {"k": 0, "answer": "Real Madrid", "latency_ms": 1525.623083114624, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Real Madrid", "latency_ms": 1298.9094257354736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Real Madrid", "latency_ms": 2062.9944801330566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Real Madrid", "latency_ms": 1756.0303211212158, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1884}, "4": {"k": 4, "answer": "Real Madrid", "latency_ms": 1545.9187030792236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2504}, "5": {"k": 5, "answer": "Real Madrid", "latency_ms": 1531.2912464141846, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3170}, "6": {"k": 6, "answer": "Real Madrid", "latency_ms": 1791.2979125976562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3796}}}
{"qid": "-8458006812258546025", "question": "who has the most gold medals in the winter olympics of all time", "gold_answers": ["Norway"], "shots": {"0": {"k": 0, "answer": "Marit Bjoergen", "latency_ms": 2666.7373180389404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Norway", "latency_ms": 2246.166706085205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 605}, "2": {"k": 2, "answer": "Norway", "latency_ms": 984.5230579376221, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1210}, "3": {"k": 3, "answer": "Norway", "latency_ms": 1722.9819297790527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Norway", "latency_ms": 1962.669849395752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2397}, "5": {"k": 5, "answer": "Norway", "latency_ms": 1308.7878227233887, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3110}, "6": {"k": 6, "answer": "Norway", "latency_ms": 1486.8817329406738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3716}}}
