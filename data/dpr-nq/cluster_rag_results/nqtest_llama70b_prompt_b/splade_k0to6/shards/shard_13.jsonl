{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 1132.134199142456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3242.265462875366, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "Helen McCrory", "latency_ms": 3337.9063606262207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1323}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2667.379856109619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Geraldine Somerville", "latency_ms": 3220.982789993286, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Geraldine Somerville", "latency_ms": 2241.3601875305176, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3219}, "6": {"k": 6, "answer": "Ellie Darcey-Alden", "latency_ms": 3845.414161682129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 2321.8905925750732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 2194.122552871704, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 3152.7390480041504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 2958.6477279663086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1950}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 2939.4967555999756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 2728.421926498413, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 1903.4674167633057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3798}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwestern United States and Mexico", "latency_ms": 2041.4628982543945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4813.890695571899, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4861.290454864502, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 4174.068450927734, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 3851.456880569458, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2622}, "5": {"k": 5, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 5378.8957595825195, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3248}, "6": {"k": 6, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 5488.933086395264, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3854}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 2856.1713695526123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rajendra Prasad", "latency_ms": 2811.5382194519043, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Rajendra Prasad", "latency_ms": 3257.049083709717, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 3445.4116821289062, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2083}, "4": {"k": 4, "answer": "Rajendra Prasad", "latency_ms": 3796.398162841797, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2757}, "5": {"k": 5, "answer": "Rajendra Prasad", "latency_ms": 2973.560333251953, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3383}, "6": {"k": 6, "answer": "Rajendra Prasad", "latency_ms": 3313.7218952178955, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4045}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2796.3857650756836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 6, 2011", "latency_ms": 3270.1451778411865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 689}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3017.7371501922607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1347}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2707.376718521118, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1942}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2807.0240020751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2778.838872909546, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3240}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2875.699758529663, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3895}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "June 22, 2001", "latency_ms": 2380.1448345184326, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2191.800594329834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2594.9878692626953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "June 22, 2001", "latency_ms": 3864.9816513061523, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1935}, "4": {"k": 4, "answer": "June 22, 2001", "latency_ms": 3042.893886566162, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2565}, "5": {"k": 5, "answer": "June 22, 2001", "latency_ms": 3693.0835247039795, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3152}, "6": {"k": 6, "answer": "June 22, 2001", "latency_ms": 2923.7873554229736, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3769}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "March 1, 2018", "latency_ms": 2758.0108642578125, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 3772.4435329437256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 3352.858304977417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 3604.7024726867676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 3838.3734226226807, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2739}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 4504.695177078247, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3435}, "6": {"k": 6, "answer": "September 27, 2017", "latency_ms": 4174.889087677002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4141}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3.", "latency_ms": 1991.4376735687256, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sectionals episode", "latency_ms": 2495.4800605773926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Sectionals", "latency_ms": 2089.4832611083984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Sectionals", "latency_ms": 1214.3089771270752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Sectionals", "latency_ms": 2219.4433212280273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2469}, "5": {"k": 5, "answer": "In \"Sectionals\"", "latency_ms": 2890.0766372680664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "Sectionals", "latency_ms": 1767.7562236785889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3705}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2124.3982315063477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2350.677967071533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2599.5843410491943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2444.3798065185547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2875.507354736328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1905.8897495269775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2745.274543762207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3828}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 2368.029832839966, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "the harbor", "latency_ms": 1763.7851238250732, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Havana Harbor, Cuba", "latency_ms": 3001.9752979278564, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Havana Harbor, Cuba", "latency_ms": 2471.3528156280518, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Havana Harbor, Cuba", "latency_ms": 3039.56937789917, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2573}, "5": {"k": 5, "answer": "Havana Harbor, Cuba", "latency_ms": 3011.8422508239746, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3200}, "6": {"k": 6, "answer": "Havana Harbor, Cuba", "latency_ms": 2768.120527267456, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3877}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 1758.7804794311523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2650.6245136260986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2355.2725315093994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Lord Vishnu", "latency_ms": 2286.9412899017334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Lord Vishnu", "latency_ms": 2279.838800430298, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2600}, "5": {"k": 5, "answer": "Lord Vishnu", "latency_ms": 2601.9234657287598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3168}, "6": {"k": 6, "answer": "Lord Vishnu", "latency_ms": 2055.5551052093506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3811}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama.", "latency_ms": 3031.970977783203, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "All of them", "latency_ms": 2344.503879547119, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Costa Rica, Nicaragua, Panama, Honduras, Guatemala, El Salvador, Belize", "latency_ms": 8858.073711395264, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1322}, "3": {"k": 3, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 3676.454782485962, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2021}, "4": {"k": 4, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 3802.8149604797363, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2696}, "5": {"k": 5, "answer": "Costa Rica, Nicaragua, Panama, Guatemala, Honduras, El Salvador, Belize", "latency_ms": 7933.274745941162, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3355}, "6": {"k": 6, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 4135.408639907837, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3983}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence.", "latency_ms": 2595.5452919006348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 1010.3859901428223, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Complex sentence", "latency_ms": 2000.4785060882568, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Complex sentence", "latency_ms": 1047.2588539123535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2006}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 1418.2987213134766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 1554.0499687194824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3361}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 1479.6085357666016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4087}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and capitalism.", "latency_ms": 1664.3280982971191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 4571.77209854126, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "the Nature and Causes of the Wealth of Nations", "latency_ms": 4681.540966033936, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "the Nature and Causes of the Wealth of Nations", "latency_ms": 4288.9227867126465, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "the Nature and Causes of the Wealth of Nations", "latency_ms": 3851.120948791504, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "the nature and causes of the wealth of nations", "latency_ms": 4955.1849365234375, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "the nature and causes of the wealth of nations", "latency_ms": 4386.60454750061, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3738}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 4412.72759437561, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "August 28, 2018", "latency_ms": 2175.2755641937256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "August 28, 2018", "latency_ms": 4337.385177612305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 4138.644218444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1868}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 3973.294496536255, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 3106.2264442443848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3172}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 3336.2860679626465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3841}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere.", "latency_ms": 3288.5544300079346, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 5595.241069793701, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 6265.45524597168, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1341}, "3": {"k": 3, "answer": "Oceania", "latency_ms": 1437.4258518218994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2010}, "4": {"k": 4, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 6105.804920196533, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2698}, "5": {"k": 5, "answer": "Oceania", "latency_ms": 1998.9314079284668, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3338}, "6": {"k": 6, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 5879.577159881592, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4067}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Mara Jade", "latency_ms": 1329.6127319335938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2205.2390575408936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1864.2957210540771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "Mara Jade", "latency_ms": 2071.9175338745117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1813}, "4": {"k": 4, "answer": "a woman at Luke's Jedi Academy", "latency_ms": 3931.7245483398438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2349}, "5": {"k": 5, "answer": "her", "latency_ms": 946.1872577667236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2920}, "6": {"k": 6, "answer": "Mara Jade", "latency_ms": 1833.4314823150635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3554}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 1297.8432178497314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack Barry", "latency_ms": 1734.0543270111084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Jack Barry", "latency_ms": 2062.0322227478027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1196}, "3": {"k": 3, "answer": "Allen Ludden", "latency_ms": 2370.2139854431152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Jack Barry", "latency_ms": 1253.2343864440918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2405}, "5": {"k": 5, "answer": "Allen Ludden", "latency_ms": 2710.354804992676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2988}, "6": {"k": 6, "answer": "Barry Cryer", "latency_ms": 3044.278621673584, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3583}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 1678.9586544036865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mitochondria", "latency_ms": 2089.6918773651123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "Mitochondria", "latency_ms": 2770.4732418060303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1365}, "3": {"k": 3, "answer": "Mitochondria", "latency_ms": 2842.3361778259277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2024}, "4": {"k": 4, "answer": "Mitochondria, Chloroplasts", "latency_ms": 4354.439735412598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2672}, "5": {"k": 5, "answer": "Mitochondria, Chloroplasts", "latency_ms": 4158.3709716796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3329}, "6": {"k": 6, "answer": "Mitochondria, Chloroplasts", "latency_ms": 3082.456350326538, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4028}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Intrusion Detection.", "latency_ms": 7546.063423156738, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2420.4494953155518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 693}, "2": {"k": 2, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 3798.6202239990234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1402}, "3": {"k": 3, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 3905.515432357788, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2089}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1548.6578941345215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2782}, "5": {"k": 5, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 3783.618211746216, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3506}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2950.894832611084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4159}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3567.307949066162, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2923.4704971313477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 567}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2436.9595050811768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1136}, "3": {"k": 3, "answer": "Dottie West and Kenny Rogers", "latency_ms": 3028.6405086517334, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1721}, "4": {"k": 4, "answer": "Dottie West and Kenny Rogers", "latency_ms": 3598.4549522399902, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2308}, "5": {"k": 5, "answer": "Dottie West and Kenny Rogers", "latency_ms": 2847.9886054992676, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2904}, "6": {"k": 6, "answer": "Dottie West and Kenny Rogers", "latency_ms": 3093.1501388549805, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3499}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 2278.2485485076904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Three years old", "latency_ms": 2588.975191116333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 689}, "2": {"k": 2, "answer": "36 months old", "latency_ms": 1525.5317687988281, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "36 months old", "latency_ms": 2355.5665016174316, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1927}, "4": {"k": 4, "answer": "36 months old", "latency_ms": 1799.2243766784668, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2546}, "5": {"k": 5, "answer": "36 months old", "latency_ms": 1736.107349395752, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3151}, "6": {"k": 6, "answer": "36 months old", "latency_ms": 2300.016164779663, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3851}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 809.3423843383789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 1165.9834384918213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "3", "latency_ms": 2523.223876953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "3", "latency_ms": 705.0933837890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "3", "latency_ms": 2292.274236679077, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Three", "latency_ms": 979.4812202453613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3190}, "6": {"k": 6, "answer": "3", "latency_ms": 1546.2677478790283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3842}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 6536.7724895477295, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2998.9616870880127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "Billy Boyd", "latency_ms": 2812.275171279907, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Billy Boyd", "latency_ms": 2081.6891193389893, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1843}, "4": {"k": 4, "answer": "Billy Boyd", "latency_ms": 1305.330514907837, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Billy Boyd", "latency_ms": 1775.3322124481201, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Elijah Wood, Billy Boyd, Dominic Guard, Simon Chandler, Michael Scholes", "latency_ms": 6473.034858703613, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3783}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party.", "latency_ms": 2173.210620880127, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume party", "latency_ms": 2299.776554107666, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Costume party", "latency_ms": 2422.9393005371094, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1198}, "3": {"k": 3, "answer": "Costume", "latency_ms": 1536.5278720855713, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Costume", "latency_ms": 1540.2705669403076, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2432}, "5": {"k": 5, "answer": "Costume.", "latency_ms": 2082.214593887329, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3067}, "6": {"k": 6, "answer": "Costume", "latency_ms": 2302.6108741760254, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3683}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 1187.1695518493652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One", "latency_ms": 942.3189163208008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 598}, "2": {"k": 2, "answer": "One", "latency_ms": 1831.6125869750977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1204}, "3": {"k": 3, "answer": "One", "latency_ms": 1208.3396911621094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1902}, "4": {"k": 4, "answer": "One", "latency_ms": 1230.2086353302002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2590}, "5": {"k": 5, "answer": "1", "latency_ms": 1698.5843181610107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3247}, "6": {"k": 6, "answer": "1", "latency_ms": 1197.7503299713135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3872}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "Gratitude to Fantine", "latency_ms": 2236.36531829834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2493.285655975342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2383.350133895874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1178}, "3": {"k": 3, "answer": "Fantine signed a note", "latency_ms": 2299.7090816497803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1805}, "4": {"k": 4, "answer": "Fantine's daughter", "latency_ms": 3395.22123336792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2389}, "5": {"k": 5, "answer": "Fantine's daughter", "latency_ms": 3011.3160610198975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2997}, "6": {"k": 6, "answer": "Fantine's request", "latency_ms": 2380.1119327545166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3610}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, South Korea, Zambia, United States.", "latency_ms": 5234.986305236816, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canada", "latency_ms": 1487.4730110168457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 710}, "2": {"k": 2, "answer": "Canada", "latency_ms": 1208.7275981903076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1400}, "3": {"k": 3, "answer": "Canada, China, Belgium, Portugal", "latency_ms": 4545.159101486206, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2096}, "4": {"k": 4, "answer": "Canada, China, Belgium, Portugal", "latency_ms": 4600.534200668335, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2743}, "5": {"k": 5, "answer": "Canada, China, Belgium, Portugal", "latency_ms": 3709.6381187438965, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3428}, "6": {"k": 6, "answer": "Canada, China, Europe, Portugal, Belgium", "latency_ms": 4019.639015197754, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 4109}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and oppression.", "latency_ms": 2739.9981021881104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7265.6090259552, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 5465.311765670776, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7592.208623886108, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 6064.001083374023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 8212.615251541138, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3344}, "6": {"k": 6, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 6427.6769161224365, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4022}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 1839.1082286834717, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 3409.170627593994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 3735.4798316955566, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Huge and powerful snake", "latency_ms": 3540.973424911499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Python", "latency_ms": 1058.8953495025635, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Python", "latency_ms": 1710.923671722412, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3099}, "6": {"k": 6, "answer": "Python", "latency_ms": 1697.2012519836426, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3724}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 2564.8484230041504, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ice", "latency_ms": 2437.4377727508545, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Ice", "latency_ms": 1745.8281517028809, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "water-ice", "latency_ms": 1886.4564895629883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "water-ice", "latency_ms": 2082.2818279266357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "water-ice", "latency_ms": 2052.9892444610596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "water-ice", "latency_ms": 2349.5304584503174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3668}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 4358.556032180786, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Not in season 2.", "latency_ms": 3544.0690517425537, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2314.037799835205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1185}, "3": {"k": 3, "answer": "The Departed episode", "latency_ms": 1871.2763786315918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1808}, "4": {"k": 4, "answer": "The Departed episode", "latency_ms": 2395.0798511505127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2425}, "5": {"k": 5, "answer": "Season 3", "latency_ms": 1633.5322856903076, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2989}, "6": {"k": 6, "answer": "Season 3, episode 22, \"The Departed\"", "latency_ms": 5405.80415725708, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3630}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "The home team", "latency_ms": 1342.3714637756348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3121.342897415161, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3221.8635082244873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2281.8098068237305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2379.3301582336426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2423}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2151.395082473755, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3027}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3385.9939575195312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3655}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw.", "latency_ms": 1409.468650817871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington, D.C.", "latency_ms": 3852.886199951172, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 691}, "2": {"k": 2, "answer": "Washington, D.C.", "latency_ms": 3282.8071117401123, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "LeDroit Park", "latency_ms": 2779.097080230713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2026}, "4": {"k": 4, "answer": "Northwest Washington", "latency_ms": 2858.5174083709717, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2709}, "5": {"k": 5, "answer": "Northwest Washington", "latency_ms": 2129.5251846313477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3449}, "6": {"k": 6, "answer": "Northwest Washington", "latency_ms": 2903.6362171173096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4133}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 1897.9549407958984, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noahic", "latency_ms": 1880.94162940979, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "Noahic", "latency_ms": 2570.2784061431885, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Noahic", "latency_ms": 2301.020383834839, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Noahic", "latency_ms": 2076.498508453369, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2577}, "5": {"k": 5, "answer": "Noahic", "latency_ms": 2534.7847938537598, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "Noahic", "latency_ms": 2239.305019378662, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3870}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 2992.931127548218, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2650.726318359375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2647.841453552246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1154}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2665.100336074829, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2116.1346435546875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2344}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2678.956985473633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2946}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2352.3385524749756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3530}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "Yip Harburg", "latency_ms": 2682.3179721832275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Anna King", "latency_ms": 1791.0735607147217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Anna King", "latency_ms": 2030.116319656372, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "Rudy Valle패e, Anna King, Erma Bombeck", "latency_ms": 5600.613594055176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Rudy Valle패e, Anna King, Erma Bombeck", "latency_ms": 5443.498611450195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2444}, "5": {"k": 5, "answer": "Rudy Valle패e", "latency_ms": 2484.386920928955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3038}, "6": {"k": 6, "answer": "Rudy Valle패e", "latency_ms": 2694.6959495544434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3686}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 2171.7913150787354, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 2068.911552429199, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 1628.014087677002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 2080.2650451660156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 1830.9094905853271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 1808.797836303711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 1988.5189533233643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3801}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "Second", "latency_ms": 1232.4812412261963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "17.5% of the world's population", "latency_ms": 4917.588233947754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "17.5% of the world's population", "latency_ms": 4334.582805633545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1440}, "3": {"k": 3, "answer": "17.5% of the world's population", "latency_ms": 3857.764959335327, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2155}, "4": {"k": 4, "answer": "17.5% of the world's population", "latency_ms": 4294.0404415130615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2822}, "5": {"k": 5, "answer": "17.5% of the world's population", "latency_ms": 5077.334642410278, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3415}, "6": {"k": 6, "answer": "Second most populated country", "latency_ms": 1682.3585033416748, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 4027}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 1822.4854469299316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gandhi", "latency_ms": 2342.395544052124, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 689}, "2": {"k": 2, "answer": "Gandhi", "latency_ms": 2062.166929244995, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "Gandhi", "latency_ms": 2352.118492126465, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2016}, "4": {"k": 4, "answer": "Gandhi", "latency_ms": 1345.1974391937256, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Gandhi", "latency_ms": 2369.4143295288086, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3399}, "6": {"k": 6, "answer": "Pattom A. Thanu Pillai", "latency_ms": 3898.33927154541, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4081}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenae Anderson", "latency_ms": 2438.359260559082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bobby Flay", "latency_ms": 1689.7435188293457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Bobby Flay", "latency_ms": 2167.0100688934326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Bobby Flay", "latency_ms": 2445.6050395965576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Bobby Flay", "latency_ms": 1661.0298156738281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "Bobby Flay", "latency_ms": 1707.550287246704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "Bobby Flay", "latency_ms": 1720.9842205047607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 1180.678367614746, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "codice_22", "latency_ms": 2619.415521621704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 687}, "2": {"k": 2, "answer": ".java", "latency_ms": 1139.3253803253174, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": ".java", "latency_ms": 1240.0867938995361, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2009}, "4": {"k": 4, "answer": ".java", "latency_ms": 959.7208499908447, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2651}, "5": {"k": 5, "answer": ".java", "latency_ms": 1001.685380935669, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3316}, "6": {"k": 6, "answer": ".java", "latency_ms": 1220.2460765838623, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3937}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 1543.6546802520752, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alan Turing", "latency_ms": 1974.2484092712402, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Alan Turing", "latency_ms": 1740.4227256774902, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1304}, "3": {"k": 3, "answer": "Alan Turing", "latency_ms": 2200.3064155578613, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 2073.155403137207, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2627}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 1499.861717224121, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3278}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 1534.5818996429443, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3946}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline and counting votes.", "latency_ms": 4227.264165878296, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to offer promotion or threaten demotion", "latency_ms": 4372.858047485352, "em": 0.0, "f1": 0.2, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "bargain for votes", "latency_ms": 2909.2257022857666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1383}, "3": {"k": 3, "answer": "manages their party's legislative program", "latency_ms": 3851.266384124756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "manage their party's legislative program", "latency_ms": 3280.3328037261963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2655}, "5": {"k": 5, "answer": "manage their party's legislative program", "latency_ms": 2832.0188522338867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3318}, "6": {"k": 6, "answer": "manage legislative program", "latency_ms": 2070.6286430358887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3982}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 1523.3473777770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2446.305513381958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 700}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1938.4539127349854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1342}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1820.554256439209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2398.576498031616, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2586}, "5": {"k": 5, "answer": "1973", "latency_ms": 1288.8553142547607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3141}, "6": {"k": 6, "answer": "1973", "latency_ms": 1260.8017921447754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the right but not the obligation to buy foreign currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 1639.8265361785889, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 1479.2616367340088, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 1287.492275238037, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 1762.2857093811035, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "FX option", "latency_ms": 1832.5400352478027, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2666}, "5": {"k": 5, "answer": "FX option", "latency_ms": 1443.941354751587, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3287}, "6": {"k": 6, "answer": "FX option", "latency_ms": 995.7060813903809, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3850}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360 members in 109 constituencies", "latency_ms": 2586.4784717559814, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 1201.429843902588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360 members", "latency_ms": 2086.367130279541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1420}, "3": {"k": 3, "answer": "360", "latency_ms": 670.2971458435059, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2062}, "4": {"k": 4, "answer": "360", "latency_ms": 1240.3502464294434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2717}, "5": {"k": 5, "answer": "360 members", "latency_ms": 1545.2017784118652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3347}, "6": {"k": 6, "answer": "360 members", "latency_ms": 953.3140659332275, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3997}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 2194.1978931427, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 2113.7890815734863, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 2408.0448150634766, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 2706.089973449707, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 2429.9416542053223, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 1683.9649677276611, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 2870.1093196868896, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3856}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gorm칠"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 2212.2936248779297, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eydie Gorm칠", "latency_ms": 3540.365695953369, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 580}, "2": {"k": 2, "answer": "Eydie Gorm칠", "latency_ms": 2388.2498741149902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Eydie Gorm칠", "latency_ms": 2855.8905124664307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1787}, "4": {"k": 4, "answer": "Eydie Gorm칠", "latency_ms": 2163.3174419403076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2404}, "5": {"k": 5, "answer": "Eydie Gorm칠", "latency_ms": 2194.629907608032, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3052}, "6": {"k": 6, "answer": "Eydie Gorm칠", "latency_ms": 3237.560749053955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3653}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "Kurian Joseph", "latency_ms": 2402.7013778686523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ashok Bhushan", "latency_ms": 3144.81520652771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 562}, "2": {"k": 2, "answer": "Ashok Bhushan", "latency_ms": 2975.558280944824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Ashok Bhushan", "latency_ms": 2582.6256275177, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1806}, "4": {"k": 4, "answer": "Ashok Bhushan", "latency_ms": 2770.376682281494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2408}, "5": {"k": 5, "answer": "Ashok Bhushan", "latency_ms": 3255.5880546569824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2929}, "6": {"k": 6, "answer": "Ashok Bhushan", "latency_ms": 2816.310405731201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3493}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "Margaret Court", "latency_ms": 1779.7534465789795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Martina Navratilova", "latency_ms": 3210.111141204834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "Martina Navratilova", "latency_ms": 2743.0927753448486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "Martina Navratilova", "latency_ms": 3781.9085121154785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Martina Navratilova", "latency_ms": 2842.3938751220703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Roger Federer", "latency_ms": 2125.380516052246, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3229}, "6": {"k": 6, "answer": "Roger Federer", "latency_ms": 1901.9908905029297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3882}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 1237.5445365905762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 1471.4674949645996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 1678.3421039581299, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1215}, "3": {"k": 3, "answer": "1", "latency_ms": 1451.1222839355469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "1", "latency_ms": 1439.4612312316895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2459}, "5": {"k": 5, "answer": "1", "latency_ms": 1135.1122856140137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3072}, "6": {"k": 6, "answer": "1", "latency_ms": 1386.51704788208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3655}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 1742.938756942749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1954", "latency_ms": 2128.3369064331055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "2002", "latency_ms": 1501.7266273498535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1273}, "3": {"k": 3, "answer": "2002", "latency_ms": 2077.988862991333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "2000", "latency_ms": 2325.4306316375732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2479}, "5": {"k": 5, "answer": "2000", "latency_ms": 1535.0673198699951, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "2002", "latency_ms": 1471.1034297943115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3746}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 1453.4802436828613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "7", "latency_ms": 951.9577026367188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "2", "latency_ms": 1454.0722370147705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "2", "latency_ms": 1488.2378578186035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "5", "latency_ms": 1517.7080631256104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2621}, "5": {"k": 5, "answer": "17", "latency_ms": 1467.0970439910889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3284}, "6": {"k": 6, "answer": "2", "latency_ms": 731.5468788146973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3886}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 2186.685562133789, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 2447.596549987793, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 3417.912244796753, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 2135.730981826782, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1872}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 2937.6723766326904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2545}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 2541.6300296783447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3218}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 3042.5949096679688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3855}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 3975.2092361450195, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 2445.2853202819824, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2144.0305709838867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Corey, Cory", "latency_ms": 2827.9874324798584, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1916}, "4": {"k": 4, "answer": "Corey, Cory", "latency_ms": 1833.9431285858154, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Corey, Cory", "latency_ms": 2176.853656768799, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3106}, "6": {"k": 6, "answer": "Corey, Cory", "latency_ms": 2289.743423461914, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3691}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 1410.883903503418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Toby Keith", "latency_ms": 1345.7012176513672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Toby Keith", "latency_ms": 2132.4803829193115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Toby Keith", "latency_ms": 2610.698461532593, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Toby Keith", "latency_ms": 1856.9307327270508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2491}, "5": {"k": 5, "answer": "Toby Keith", "latency_ms": 2146.9485759735107, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3102}, "6": {"k": 6, "answer": "Toby Keith", "latency_ms": 1769.120454788208, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3737}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 722.2867012023926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 original counties", "latency_ms": 2851.6087532043457, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "159", "latency_ms": 966.3312435150146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1301}, "3": {"k": 3, "answer": "159", "latency_ms": 1776.2982845306396, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1933}, "4": {"k": 4, "answer": "159", "latency_ms": 1459.193468093872, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2557}, "5": {"k": 5, "answer": "159", "latency_ms": 1202.9147148132324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3247}, "6": {"k": 6, "answer": "159", "latency_ms": 899.4259834289551, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3920}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 2477.853298187256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2920.240879058838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "Matt Flinders", "latency_ms": 2144.484758377075, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Johnny Curtis", "latency_ms": 1582.484483718872, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "Matt Flinders", "latency_ms": 2284.7256660461426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2443}, "5": {"k": 5, "answer": "Matt Flinders", "latency_ms": 2326.3235092163086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3057}, "6": {"k": 6, "answer": "Matt Flinders", "latency_ms": 1821.3670253753662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3640}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 1324.7761726379395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2634.4799995422363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3138.4408473968506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1177}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2685.383081436157, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1755}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3409.5795154571533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2346}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2045.2971458435059, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2998}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2719.560384750366, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3631}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 2416.8686866760254, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Right hand", "latency_ms": 1762.0460987091064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 2102.013349533081, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1154}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 1725.3913879394531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1718}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 1819.502353668213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2320}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 2865.4589653015137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2914}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 1446.7403888702393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3468}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 3680.5028915405273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Donald Duck", "latency_ms": 1547.5108623504639, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Donald Duck", "latency_ms": 1183.2191944122314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1293}, "3": {"k": 3, "answer": "Donald Duck", "latency_ms": 2245.448350906372, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1945}, "4": {"k": 4, "answer": "Donald Duck", "latency_ms": 1748.7683296203613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Donald Duck", "latency_ms": 1458.4414958953857, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3192}, "6": {"k": 6, "answer": "Donald Duck", "latency_ms": 2273.946523666382, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3800}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 1843.8761234283447, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bernard Hill", "latency_ms": 2079.7603130340576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 590}, "2": {"k": 2, "answer": "Bernard Hill", "latency_ms": 2659.825325012207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1178}, "3": {"k": 3, "answer": "Bernard Hill", "latency_ms": 1592.4363136291504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1824}, "4": {"k": 4, "answer": "Bernard Hill", "latency_ms": 2324.610471725464, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2422}, "5": {"k": 5, "answer": "Bernard Hill", "latency_ms": 1645.4246044158936, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3028}, "6": {"k": 6, "answer": "Bernard Hill", "latency_ms": 2356.2586307525635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3691}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2019", "latency_ms": 3864.2470836639404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2018", "latency_ms": 4112.0054721832275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 4073.9870071411133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1191}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 3505.8999061584473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1787}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 4450.910806655884, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2404}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 3814.8396015167236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3055}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 3642.6401138305664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3697}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 1624.415636062622, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles", "latency_ms": 2421.3082790374756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Los Angeles", "latency_ms": 1030.9619903564453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Los Angeles", "latency_ms": 2007.1325302124023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Los Angeles", "latency_ms": 1552.26469039917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "Los Angeles", "latency_ms": 1268.9793109893799, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3196}, "6": {"k": 6, "answer": "Los Angeles", "latency_ms": 2277.8823375701904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3800}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 1612.4258041381836, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Claire Holt", "latency_ms": 2065.7787322998047, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Claire Holt", "latency_ms": 2033.8525772094727, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Claire Holt", "latency_ms": 2345.269203186035, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Claire Holt", "latency_ms": 2319.234848022461, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "Claire Holt", "latency_ms": 1551.2402057647705, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3110}, "6": {"k": 6, "answer": "Claire Holt", "latency_ms": 2365.473508834839, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3753}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living organisms.", "latency_ms": 2903.2039642333984, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in the biosphere", "latency_ms": 3192.793369293213, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 700}, "2": {"k": 2, "answer": "the deepest parts of the ocean, and high in the atmosphere, soil and subsurface.", "latency_ms": 6714.454889297485, "em": 0.0, "f1": 0.16666666666666669, "containment": 1.0, "context_chars": 1325}, "3": {"k": 3, "answer": "in all water bodies, soil, and subsurface, and in forests", "latency_ms": 7220.113277435303, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 2010}, "4": {"k": 4, "answer": "the deepest parts of the ocean, and at least high in the atmosphere", "latency_ms": 6038.217306137085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2664}, "5": {"k": 5, "answer": "the deepest parts of the ocean, and at least high in the atmosphere", "latency_ms": 6288.6643409729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3314}, "6": {"k": 6, "answer": "in all land-living organisms, soils, and dead plant matter", "latency_ms": 7124.094724655151, "em": 0.0, "f1": 0.16666666666666663, "containment": 1.0, "context_chars": 3937}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "Vijay Raghavendra", "latency_ms": 4331.413507461548, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Vijay Raghavendra", "latency_ms": 3431.1928749084473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "Vijay Raghavendra", "latency_ms": 3575.960874557495, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Vijay Raghavendra", "latency_ms": 4813.470363616943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Vijay Raghavendra", "latency_ms": 3741.364002227783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "Vijay Raghavendra", "latency_ms": 3373.3115196228027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Vijay Raghavendra", "latency_ms": 3390.672445297241, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3852}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 2545.8104610443115, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kanab, Utah", "latency_ms": 2678.8547039031982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "Kanab, Utah, Lake Powell", "latency_ms": 4054.3136596679688, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Kanab, Utah, Lake Powell", "latency_ms": 3518.0442333221436, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Kanab, Utah, Lake Powell", "latency_ms": 4260.59103012085, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2523}, "5": {"k": 5, "answer": "Kanab, Utah, Lake Powell", "latency_ms": 3929.788827896118, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3150}, "6": {"k": 6, "answer": "Lake Powell, Utah, Kanab", "latency_ms": 2582.946300506592, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3775}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 1681.147575378418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roy Dotrice", "latency_ms": 1875.3013610839844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Henry Garrett", "latency_ms": 1779.0319919586182, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Roy Dotrice", "latency_ms": 2559.037923812866, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2681.3762187957764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2721.3919162750244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3212}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2518.5441970825195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3858}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Canada to Lake Winnipeg.", "latency_ms": 3817.612648010254, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Saskatchewan Glacier to Rocky Mountain House", "latency_ms": 4136.233329772949, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Rocky Mountains to Lake Winnipeg", "latency_ms": 2992.5389289855957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "Rocky Mountains to Lake Winnipeg", "latency_ms": 4025.622844696045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "Alberta to Lake Winnipeg", "latency_ms": 2527.4879932403564, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2624}, "5": {"k": 5, "answer": "Alberta to Lake Winnipeg", "latency_ms": 2517.066717147827, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3354}, "6": {"k": 6, "answer": "Alberta to Lake Winnipeg", "latency_ms": 2582.932233810425, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4071}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 1116.1651611328125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 1316.2102699279785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome", "latency_ms": 1237.903356552124, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Rome, Italy", "latency_ms": 1641.0937309265137, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 3222.1639156341553, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2547}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 1631.5994262695312, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 2437.549591064453, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3722}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "CE Mark or Measure number", "latency_ms": 2124.563694000244, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "batch code", "latency_ms": 1479.8808097839355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "manufacturing company or site", "latency_ms": 2805.093288421631, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "manufacturing company or site", "latency_ms": 2749.790906906128, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1967}, "4": {"k": 4, "answer": "the manufacturing company or site", "latency_ms": 2670.320987701416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2574}, "5": {"k": 5, "answer": "the manufacturing company or site", "latency_ms": 3169.7521209716797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3214}, "6": {"k": 6, "answer": "the manufacturing company or site", "latency_ms": 2485.9213829040527, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3855}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia, methanol.", "latency_ms": 3256.1798095703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 4630.9494972229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 3952.9073238372803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1352}, "3": {"k": 3, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 3992.61736869812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1952}, "4": {"k": 4, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 4750.869512557983, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 4504.4105052948, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 4310.672760009766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3766}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Once in a Lifetime", "latency_ms": 2158.1969261169434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 1508.8942050933838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "1988", "latency_ms": 1821.8059539794922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1199}, "3": {"k": 3, "answer": "1988", "latency_ms": 1195.5273151397705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1815}, "4": {"k": 4, "answer": "1988", "latency_ms": 2227.877140045166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2417}, "5": {"k": 5, "answer": "1988", "latency_ms": 1986.4797592163086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3047}, "6": {"k": 6, "answer": "1988", "latency_ms": 1818.0766105651855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3682}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 623.2001781463623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tute", "latency_ms": 1827.5370597839355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "Manille", "latency_ms": 1071.6767311096191, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1164}, "3": {"k": 3, "answer": "Manille", "latency_ms": 2051.4121055603027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1799}, "4": {"k": 4, "answer": "Manille", "latency_ms": 1802.1912574768066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2447}, "5": {"k": 5, "answer": "Manille", "latency_ms": 1501.0604858398438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "Manille", "latency_ms": 1426.8324375152588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3654}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 2483.3083152770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2746.9258308410645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1675.8179664611816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "5%", "latency_ms": 2022.5539207458496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "5%", "latency_ms": 1145.747423171997, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "5%", "latency_ms": 2076.660394668579, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3166}, "6": {"k": 6, "answer": "5%", "latency_ms": 1509.063482284546, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3791}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 1058.4120750427246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1975", "latency_ms": 1506.8888664245605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "1975", "latency_ms": 1540.4751300811768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "1975", "latency_ms": 1711.3652229309082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1934}, "4": {"k": 4, "answer": "1975", "latency_ms": 1595.613718032837, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2604}, "5": {"k": 5, "answer": "1975", "latency_ms": 876.3446807861328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3272}, "6": {"k": 6, "answer": "1975", "latency_ms": 2062.6060962677, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3882}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 2631.6823959350586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lionel Richie", "latency_ms": 2424.408197402954, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Lionel Richie", "latency_ms": 1883.878231048584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Lionel Richie", "latency_ms": 2640.7902240753174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 2211.928606033325, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2625}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 2183.067798614502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3233}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 2970.256805419922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3841}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert, 2nd Baron Baltimore", "latency_ms": 4397.936820983887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cecil Calvert and Catholic settlers", "latency_ms": 3125.5204677581787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Catholics", "latency_ms": 2561.1398220062256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1330}, "3": {"k": 3, "answer": "Cecil Calvert", "latency_ms": 3063.971996307373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2020}, "4": {"k": 4, "answer": "Cecil Calvert", "latency_ms": 3312.3764991760254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2671}, "5": {"k": 5, "answer": "Cecil Calvert", "latency_ms": 2853.228807449341, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3378}, "6": {"k": 6, "answer": "Cecil Calvert", "latency_ms": 2758.8038444519043, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4011}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player and Fred Couples and Gary Player and  Augusta native  and Arnold Palmer", "latency_ms": 8219.450235366821, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gary Player", "latency_ms": 2578.0131816864014, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 630}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2994.1678047180176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2648.914098739624, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2958.6269855499268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2475}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2154.1056632995605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3139}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3219.460964202881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3728}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 1897.216796875, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "200 to 500 mg", "latency_ms": 3213.6945724487305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 4623.382091522217, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg", "latency_ms": 3569.263696670532, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1930}, "4": {"k": 4, "answer": "200 to 500 mg", "latency_ms": 2997.786283493042, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2549}, "5": {"k": 5, "answer": "200 to 500 mg", "latency_ms": 3543.067693710327, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3248}, "6": {"k": 6, "answer": "200 to 500 mg", "latency_ms": 2025.543451309204, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3949}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 2609.3297004699707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham", "latency_ms": 1510.0488662719727, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 2061.657667160034, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1097}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 1858.5548400878906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1685}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 1854.0446758270264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2245}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 2091.8631553649902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2837}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 1895.6706523895264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3479}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 2027.069091796875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canada", "latency_ms": 926.8679618835449, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "Canada", "latency_ms": 1986.431360244751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "Canada", "latency_ms": 916.1481857299805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2012}, "4": {"k": 4, "answer": "Canada", "latency_ms": 1498.8245964050293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Canada", "latency_ms": 965.3811454772949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3367}, "6": {"k": 6, "answer": "Canada", "latency_ms": 1615.5576705932617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4000}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh, Scotland", "latency_ms": 2123.9795684814453, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 2683.6822032928467, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 2468.313455581665, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1337}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 2245.131492614746, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2015}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 3688.582420349121, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2687}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 3164.268970489502, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3365}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 2485.7048988342285, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4050}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 2221.116781234741, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2259.5150470733643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2733.7653636932373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1316}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2933.2048892974854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1963}, "4": {"k": 4, "answer": "I cannot answer", "latency_ms": 1380.2664279937744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2680.479049682617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3222}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3230.2143573760986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3921}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 2977.2729873657227, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Southport, North Carolina", "latency_ms": 2271.188497543335, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Southport, North Carolina", "latency_ms": 2483.757495880127, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1232}, "3": {"k": 3, "answer": "Southport, North Carolina", "latency_ms": 2707.9122066497803, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "Southport, North Carolina.", "latency_ms": 3627.4406909942627, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2456}, "5": {"k": 5, "answer": "Southport, North Carolina.", "latency_ms": 4362.3621463775635, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3102}, "6": {"k": 6, "answer": "Southport, North Carolina.", "latency_ms": 3434.9024295806885, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3707}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 1449.9356746673584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2686.4771842956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 705}, "2": {"k": 2, "answer": "Sylvia F. Porter", "latency_ms": 4892.1263217926025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Sylvia F. Porter", "latency_ms": 3038.609027862549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 2689.2833709716797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2561}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 4175.458669662476, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 3552.3972511291504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3904}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 2109.201431274414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 2960.4098796844482, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 1473.0193614959717, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 2405.0936698913574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2050}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 2059.570550918579, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2696}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 2134.5036029815674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3371}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 2443.13907623291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4055}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 886.9333267211914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 1695.2311992645264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 602}, "2": {"k": 2, "answer": "Max", "latency_ms": 1304.2068481445312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Max", "latency_ms": 666.9363975524902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1831}, "4": {"k": 4, "answer": "Max", "latency_ms": 1237.6587390899658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2452}, "5": {"k": 5, "answer": "Max", "latency_ms": 1203.0532360076904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Max", "latency_ms": 704.2474746704102, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3787}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 2723.3645915985107, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amybeth McNulty", "latency_ms": 2342.3688411712646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 677}, "2": {"k": 2, "answer": "Amybeth McNulty", "latency_ms": 2706.3379287719727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Amybeth McNulty", "latency_ms": 1425.5921840667725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Amybeth McNulty", "latency_ms": 2173.987627029419, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2563}, "5": {"k": 5, "answer": "Amybeth McNulty", "latency_ms": 2198.108434677124, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3243}, "6": {"k": 6, "answer": "Amybeth McNulty", "latency_ms": 2458.9719772338867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3818}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "Boxer Rebellion.", "latency_ms": 2517.011880874634, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "World's Fair, Rapid Transit Tunnel, Eight Nation Alliance, inventions, and laws.", "latency_ms": 8928.688049316406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "World's Fair, Rapid Transit Tunnel, Eight Nation Alliance invasion, Browning Pistol invention, Nobel Prize invention.", "latency_ms": 10047.711610794067, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "World's Fair, Rapid Transit Tunnel, Eight Nation Alliance invasion, and others.", "latency_ms": 7252.894878387451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1894}, "4": {"k": 4, "answer": "World's Fair, Rapid Transit Tunnel, Eight Nation Alliance invasion, Nobel Prize invention.", "latency_ms": 6736.9444370269775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2616}, "5": {"k": 5, "answer": "World's Fair, Rapid Transit Tunnel, Eight Nation Alliance invasion, Browning Pistol invention, Nobel Prize invention.", "latency_ms": 8470.208406448364, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3330}, "6": {"k": 6, "answer": "World's Fair, Rapid Transit Tunnel, Eight Nation Alliance invasion, Browning Pistol invention, Nobel Prize invention.", "latency_ms": 8961.019515991211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3996}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 1909.301519393921, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "self-empowerment", "latency_ms": 2358.487844467163, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 2965.2411937713623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "self-empowerment", "latency_ms": 3380.917549133301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "self-empowerment", "latency_ms": 2501.720666885376, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2472}, "5": {"k": 5, "answer": "Empowerment", "latency_ms": 2336.0307216644287, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3094}, "6": {"k": 6, "answer": "Empowerment", "latency_ms": 1857.9885959625244, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3769}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams' front offices", "latency_ms": 2867.8808212280273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Teams", "latency_ms": 1479.426622390747, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "Teams", "latency_ms": 914.9057865142822, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Teams", "latency_ms": 2648.747682571411, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "NFL franchises", "latency_ms": 977.053165435791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2469}, "5": {"k": 5, "answer": "NFL teams", "latency_ms": 1964.390754699707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "NFL teams", "latency_ms": 1408.6062908172607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3722}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 1701.1840343475342, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3286.619186401367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "James W. Marshall", "latency_ms": 2458.6822986602783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1270}, "3": {"k": 3, "answer": "James W. Marshall", "latency_ms": 2327.009677886963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "James W. Marshall", "latency_ms": 2412.837505340576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2582}, "5": {"k": 5, "answer": "James W. Marshall", "latency_ms": 2454.071044921875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "James W. Marshall", "latency_ms": 2713.8519287109375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3901}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 2417.7322387695312, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 2600.2910137176514, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 2414.958953857422, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 2458.5046768188477, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 2765.129566192627, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 2173.2852458953857, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 2906.1200618743896, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3801}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "9", "latency_ms": 1508.5101127624512, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1947.3423957824707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2673.4468936920166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1238}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2419.649124145508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1872}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2533.283472061157, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1991.9869899749756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2224.229574203491, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3671}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4269.0184116363525, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 2490.807294845581, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3510.3132724761963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3875.9758472442627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4273.940086364746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2596}, "5": {"k": 5, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4007.9147815704346, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3287}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4500.2992153167725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3918}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 1086.6119861602783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central German cultural region", "latency_ms": 3231.684684753418, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Central Germany", "latency_ms": 1783.1027507781982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Central Germany", "latency_ms": 1517.7557468414307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1946}, "4": {"k": 4, "answer": "Central Germany", "latency_ms": 1771.8889713287354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Central Germany", "latency_ms": 2082.160234451294, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3288}, "6": {"k": 6, "answer": "Central Europe", "latency_ms": 2020.9720134735107, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3974}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 2145.491600036621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "16481651", "latency_ms": 2746.9162940979004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "16481651", "latency_ms": 2977.0705699920654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "16481651", "latency_ms": 3086.5113735198975, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1979}, "4": {"k": 4, "answer": "16481651", "latency_ms": 2805.7000637054443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2632}, "5": {"k": 5, "answer": "16481651", "latency_ms": 2847.416877746582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "16481651", "latency_ms": 3286.8359088897705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3966}}}
