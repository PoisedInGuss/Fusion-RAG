{"qid": "-9197932657152136610", "question": "what are the main sources of economic growth in the us currently", "gold_answers": ["pharmaceuticals", "aircraft", "telecommunications", "heavy machinery"], "shots": {"0": {"k": 0, "answer": "Technology, Healthcare, E-commerce, Finance.", "latency_ms": 3191.6587352752686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "investment, new products and services", "latency_ms": 2900.881767272949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "New products and services, investment", "latency_ms": 2783.243417739868, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "New products and services, investment.", "latency_ms": 2810.9793663024902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "investment, new products and services", "latency_ms": 3032.7930450439453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2470}, "5": {"k": 5, "answer": "investment, new products and services", "latency_ms": 3011.1401081085205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "investment, new products and services", "latency_ms": 3065.1471614837646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3837}}}
{"qid": "-4566914757117567579", "question": "who played ethel on the doris day show", "gold_answers": ["Carol Worthington"], "shots": {"0": {"k": 0, "answer": "Kay Chandra", "latency_ms": 1895.576000213623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2932.798147201538, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2466.815948486328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Doris Hare", "latency_ms": 1884.9005699157715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "Doris Hare", "latency_ms": 2600.019931793213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2488}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2086.8959426879883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3146}, "6": {"k": 6, "answer": "Aggie Thompson", "latency_ms": 1859.1814041137695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3845}}}
{"qid": "212435016090205927", "question": "who played g baby in the movie hardball", "gold_answers": ["DeWayne Warren"], "shots": {"0": {"k": 0, "answer": "Keanu Reeves", "latency_ms": 2450.361490249634, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "DeWayne Warren", "latency_ms": 1609.9612712860107, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 644}, "2": {"k": 2, "answer": "DeWayne Warren", "latency_ms": 2228.468418121338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "DeWayne Warren", "latency_ms": 1914.8526191711426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1853}, "4": {"k": 4, "answer": "DeWayne Warren", "latency_ms": 1956.3019275665283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2462}, "5": {"k": 5, "answer": "DeWayne Warren", "latency_ms": 2586.0579013824463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3170}, "6": {"k": 6, "answer": "DeWayne Warren", "latency_ms": 2493.5364723205566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3761}}}
{"qid": "-4190633494852415957", "question": "who played john coffey in the movie the green mile", "gold_answers": ["Michael Clarke Duncan"], "shots": {"0": {"k": 0, "answer": "Michael Clarke Duncan", "latency_ms": 2641.784191131592, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Michael Clarke Duncan", "latency_ms": 2225.489377975464, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "Michael Clarke Duncan", "latency_ms": 1416.4729118347168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1296}, "3": {"k": 3, "answer": "Michael Clarke Duncan", "latency_ms": 2037.7726554870605, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Michael Clarke Duncan", "latency_ms": 2022.3510265350342, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2561}, "5": {"k": 5, "answer": "Michael Clarke Duncan", "latency_ms": 1985.1093292236328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3181}, "6": {"k": 6, "answer": "Michael Clarke Duncan", "latency_ms": 2100.625991821289, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3849}}}
{"qid": "811267239470530686", "question": "who wrote catch 22 (both names)", "gold_answers": ["American author Joseph Heller", "Joseph Heller .", "Joseph Heller"], "shots": {"0": {"k": 0, "answer": "Joseph Heller", "latency_ms": 1534.1744422912598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Joseph Heller", "latency_ms": 1828.0324935913086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 578}, "2": {"k": 2, "answer": "Joseph Heller", "latency_ms": 1035.2857112884521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1203}, "3": {"k": 3, "answer": "Joseph Heller", "latency_ms": 1772.3181247711182, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Joseph Heller", "latency_ms": 1066.5185451507568, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2468}, "5": {"k": 5, "answer": "Joseph Heller", "latency_ms": 1532.4840545654297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3084}, "6": {"k": 6, "answer": "Joseph Heller", "latency_ms": 1764.228343963623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3748}}}
{"qid": "-1608179127534867277", "question": "where was the world chess tournament 2017 held", "gold_answers": ["Tbilisi , Georgia", "in Tbilisi , Georgia"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 481.3804626464844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tbilisi, Georgia", "latency_ms": 2188.169479370117, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "Tbilisi, Georgia", "latency_ms": 2789.9982929229736, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Tbilisi, Georgia", "latency_ms": 2786.923885345459, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1910}, "4": {"k": 4, "answer": "Tbilisi, Georgia", "latency_ms": 2247.3630905151367, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2552}, "5": {"k": 5, "answer": "Tbilisi, Georgia", "latency_ms": 2254.354238510132, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3202}, "6": {"k": 6, "answer": "Tbilisi, Georgia", "latency_ms": 1681.5705299377441, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3861}}}
{"qid": "7687115121611301468", "question": "who votes to elect a rajya sabha memmber", "gold_answers": ["state legislatures"], "shots": {"0": {"k": 0, "answer": "Elected members of State Legislative Assembly.", "latency_ms": 3582.6961994171143, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elected members of the State Assembly", "latency_ms": 2583.8444232940674, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "Elected members of the State Assembly", "latency_ms": 3172.6696491241455, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "Elected members of the State Assembly", "latency_ms": 2552.3152351379395, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1926}, "4": {"k": 4, "answer": "Elected members of the State Assembly", "latency_ms": 2942.326068878174, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2551}, "5": {"k": 5, "answer": "Elected members of the State Assembly", "latency_ms": 3435.4488849639893, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": "Elected members of the State Assembly", "latency_ms": 3491.8646812438965, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3828}}}
{"qid": "-5784633834792163973", "question": "when does season 8 of hawaii five o premiere", "gold_answers": ["September 29 , 2017"], "shots": {"0": {"k": 0, "answer": "September 27, 2019", "latency_ms": 1625.6449222564697, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 29, 2017", "latency_ms": 3633.8953971862793, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 613}, "2": {"k": 2, "answer": "September 29, 2017", "latency_ms": 3601.3615131378174, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "September 29, 2017", "latency_ms": 3300.255298614502, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "September 29, 2017", "latency_ms": 2851.8433570861816, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2477}, "5": {"k": 5, "answer": "September 29, 2017", "latency_ms": 2685.136556625366, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "September 29, 2017", "latency_ms": 2670.222759246826, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3785}}}
{"qid": "-5864397450755103545", "question": "paul walkers cars in fast and furious list", "gold_answers": ["1995 Toyota Supra", "2002 Mitsubishi Lancer OZ Rally", "1995 Dodge Stealth", "1995 Mitsubishi Eclipse"], "shots": {"0": {"k": 0, "answer": "Toyota Supra, Nissan Skyline, Mitsubishi Eclipse, Dodge Charger, BMW M5, Ford Lightning Rod.", "latency_ms": 7212.480545043945, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3233.9961528778076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Mitsubishi Lancer Evolution VII", "latency_ms": 3395.3909873962402, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2333.3868980407715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1820}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2721.7235565185547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Mitsubishi Lancer Evolution, Ford Gran Torino Sport", "latency_ms": 4630.694389343262, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3141}, "6": {"k": 6, "answer": "Mitsubishi Lancer Evolution, Ford Gran Torino Sport", "latency_ms": 5486.100435256958, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3840}}}
{"qid": "-8491157534197669091", "question": "who won the oscar for best actor in 1975", "gold_answers": ["Art Carney"], "shots": {"0": {"k": 0, "answer": "Art Carney", "latency_ms": 1094.0361022949219, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2416.2912368774414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2615.0851249694824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1802.046537399292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1939}, "4": {"k": 4, "answer": "Art Carney", "latency_ms": 1604.2959690093994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2529}, "5": {"k": 5, "answer": "Art Carney", "latency_ms": 1738.5518550872803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3165}, "6": {"k": 6, "answer": "Art Carney", "latency_ms": 1620.753288269043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3800}}}
{"qid": "-8408640804522114136", "question": "when did the first episode of that 70s show air", "gold_answers": ["August 23 , 1998"], "shots": {"0": {"k": 0, "answer": "August 23, 1998", "latency_ms": 3115.3087615966797, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "August 23, 1998", "latency_ms": 2836.4295959472656, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "August 23, 1998", "latency_ms": 3333.9571952819824, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1253}, "3": {"k": 3, "answer": "August 23, 1998", "latency_ms": 3732.733726501465, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "August 23, 1998", "latency_ms": 3083.399772644043, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2469}, "5": {"k": 5, "answer": "August 23, 1998", "latency_ms": 3513.2553577423096, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3041}, "6": {"k": 6, "answer": "August 23, 1998", "latency_ms": 2866.7049407958984, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3641}}}
{"qid": "722920117313579366", "question": "when did the book thief movie come out", "gold_answers": ["November 27 , 2013", "2013"], "shots": {"0": {"k": 0, "answer": "November 8, 2013", "latency_ms": 2808.173656463623, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 11, 2014", "latency_ms": 3927.543878555298, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "November 8, 2013", "latency_ms": 3053.178548812866, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1270}, "3": {"k": 3, "answer": "November 8, 2013", "latency_ms": 3975.0828742980957, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1883}, "4": {"k": 4, "answer": "November 8, 2013", "latency_ms": 2814.833879470825, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2522}, "5": {"k": 5, "answer": "November 8, 2013", "latency_ms": 2546.5095043182373, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3191}, "6": {"k": 6, "answer": "November 8, 2013", "latency_ms": 2919.853925704956, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3819}}}
{"qid": "-4427112594024146143", "question": "when did the eagles win the super bowl", "gold_answers": ["2017"], "shots": {"0": {"k": 0, "answer": "February 4, 2018", "latency_ms": 2692.93475151062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2448.4901428222656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Super Bowl LII", "latency_ms": 2424.8507022857666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "Super Bowl LII", "latency_ms": 2516.103506088257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Super Bowl LII", "latency_ms": 2441.946506500244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2557}, "5": {"k": 5, "answer": "Super Bowl LII", "latency_ms": 1390.998363494873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3148}, "6": {"k": 6, "answer": "Super Bowl LII", "latency_ms": 1867.1398162841797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3734}}}
{"qid": "7078422108284431587", "question": "who is the biggest selling female group of all time", "gold_answers": ["Spice Girls"], "shots": {"0": {"k": 0, "answer": "Spice Girls", "latency_ms": 1352.0982265472412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spice Girls", "latency_ms": 2303.823947906494, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 676}, "2": {"k": 2, "answer": "Spice Girls", "latency_ms": 2140.9711837768555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1352}, "3": {"k": 3, "answer": "Spice Girls", "latency_ms": 1792.5469875335693, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1961}, "4": {"k": 4, "answer": "Spice Girls", "latency_ms": 2392.437696456909, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2601}, "5": {"k": 5, "answer": "Spice Girls", "latency_ms": 1823.7638473510742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3183}, "6": {"k": 6, "answer": "Spice Girls", "latency_ms": 1916.4183139801025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3843}}}
{"qid": "1039102546557940080", "question": "who sang from russia with love james bond", "gold_answers": ["Matt Monro"], "shots": {"0": {"k": 0, "answer": "Matt Monro", "latency_ms": 1602.6525497436523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matt Monro", "latency_ms": 1779.1950702667236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "Matt Monro", "latency_ms": 2059.450149536133, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1196}, "3": {"k": 3, "answer": "Matt Monro", "latency_ms": 1800.6203174591064, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1817}, "4": {"k": 4, "answer": "Matt Monro", "latency_ms": 1981.543779373169, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Matt Monro", "latency_ms": 2324.934482574463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Matt Monro", "latency_ms": 1629.1139125823975, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3775}}}
{"qid": "-8507438636601119973", "question": "where is urinary bladder located in human body", "gold_answers": ["on the pelvic floor", "pelvic floor"], "shots": {"0": {"k": 0, "answer": "Pelvic cavity", "latency_ms": 2355.468273162842, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "at the base of the pelvis", "latency_ms": 2609.6205711364746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "at the base of the pelvis", "latency_ms": 3321.0818767547607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1184}, "3": {"k": 3, "answer": "at the base of the pelvis", "latency_ms": 4028.7132263183594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1907}, "4": {"k": 4, "answer": "At the base of the pelvis", "latency_ms": 3645.076274871826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2536}, "5": {"k": 5, "answer": "At the base of the pelvis", "latency_ms": 3387.7108097076416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "At the base of the pelvis", "latency_ms": 3793.565273284912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3809}}}
{"qid": "-1996951438961136762", "question": "architectural elements forming rib vaults eg wells cathedral", "gold_answers": ["two to three barrel vaults", "an armature of piped masonry", "barrel vaults"], "shots": {"0": {"k": 0, "answer": "Ribs", "latency_ms": 1485.6889247894287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ribs in a net-like form", "latency_ms": 3886.8284225463867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 571}, "2": {"k": 2, "answer": "Ribs in a net-like form", "latency_ms": 3470.3524112701416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Ribs in a net-like form", "latency_ms": 3340.974807739258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "ribs in a net-like form", "latency_ms": 2699.5849609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2569}, "5": {"k": 5, "answer": "Lierne ribs", "latency_ms": 1894.0553665161133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "ribs", "latency_ms": 1433.3217144012451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3800}}}
{"qid": "-8490085242981497626", "question": "who sang gonna sit right down and write myself a letter", "gold_answers": ["Fats Waller"], "shots": {"0": {"k": 0, "answer": "Alicia Keys", "latency_ms": 2058.964729309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fats Waller", "latency_ms": 3751.7850399017334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "Fats Waller", "latency_ms": 2114.6066188812256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Fats Waller, Billy Williams, Frank Sinatra, Bing Crosby, The Boswell Sisters, Connee Boswell, Nat King Cole, Scatman Crothers", "latency_ms": 11063.334703445435, "em": 0.0, "f1": 0.21052631578947367, "containment": 1.0, "context_chars": 1904}, "4": {"k": 4, "answer": "Fats Waller, Billy Williams, Frank Sinatra, Bing Crosby, The Boswell Sisters, Connee Boswell, Nat King Cole, Scatman Crothers, Gregory Isaacs, Barry Manilow, Dean Martin, Anne Murray, Willie Nelson, Linda Scott, Shakin' Stevens, Al Bowlly, Sarah Vaughan, Charlie Gracie, Bill Haley, Fabian", "latency_ms": 25484.03000831604, "em": 0.0, "f1": 0.09523809523809523, "containment": 1.0, "context_chars": 2568}, "5": {"k": 5, "answer": "Fats Waller, Billy Williams, Frank Sinatra, Bing Crosby, Nat King Cole, Dean Martin, Anne Murray, Willie Nelson, Linda Scott, Shakin' Stevens, Al Bowlly, Sarah Vaughan, Charlie Gracie, Bill Haley, Fabian.", "latency_ms": 20927.321195602417, "em": 0.0, "f1": 0.125, "containment": 1.0, "context_chars": 3157}, "6": {"k": 6, "answer": "Fats Waller, Billy Williams, Frank Sinatra, Bing Crosby, The Boswell Sisters, Connee Boswell, Nat King Cole, Scatman Crothers, Gregory Isaacs, Barry Manilow, Dean Martin, Anne Murray, Willie Nelson, Linda Scott, Shakin' Stevens, Al Bowlly, Sarah Vaughan, Charlie Gracie, Bill Haley, Fabian, Big Joe Turner", "latency_ms": 28706.8989276886, "em": 0.0, "f1": 0.08888888888888888, "containment": 1.0, "context_chars": 3769}}}
{"qid": "8783361206191889627", "question": "how many rooms is there in buckingham palace", "gold_answers": ["775 rooms", "775"], "shots": {"0": {"k": 0, "answer": "775", "latency_ms": 1278.5272598266602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "775", "latency_ms": 1190.3588771820068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "775", "latency_ms": 922.4770069122314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1197}, "3": {"k": 3, "answer": "775", "latency_ms": 1220.324993133545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1863}, "4": {"k": 4, "answer": "775", "latency_ms": 681.3225746154785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2490}, "5": {"k": 5, "answer": "775", "latency_ms": 1476.33957862854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3070}, "6": {"k": 6, "answer": "775", "latency_ms": 668.9069271087646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3640}}}
{"qid": "1172792682698457582", "question": "where did they get the tree for rockefeller center", "gold_answers": ["State College , PA"], "shots": {"0": {"k": 0, "answer": "New York or New Jersey, and various locations over the years", "latency_ms": 5094.778299331665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1704.7815322875977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2196.7947483062744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1365}, "3": {"k": 3, "answer": "Killingworth, Connecticut", "latency_ms": 2671.6928482055664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "upstate New York and surrounding states", "latency_ms": 3861.421585083008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2695}, "5": {"k": 5, "answer": "upstate New York and surrounding states", "latency_ms": 3382.009267807007, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3344}, "6": {"k": 6, "answer": "upstate New York and surrounding states, and Ottawa in Ontario, Canada.", "latency_ms": 6168.378591537476, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3962}}}
{"qid": "-8616225749004085214", "question": "who expanded the territory of china during the qing dynasty", "gold_answers": ["Prince Bao", "the Qianlong Emperor", "Qianlong"], "shots": {"0": {"k": 0, "answer": "Emperor Kangxi and the Qianlong Emperor.", "latency_ms": 4363.945960998535, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Qing China", "latency_ms": 1297.806739807129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "Qianlong Emperor", "latency_ms": 2412.872076034546, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Qianlong Emperor", "latency_ms": 2725.5797386169434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1935}, "4": {"k": 4, "answer": "Qianlong Emperor", "latency_ms": 2502.1884441375732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Qianlong Emperor", "latency_ms": 1730.3166389465332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3235}, "6": {"k": 6, "answer": "Qianlong Emperor", "latency_ms": 1858.4346771240234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3889}}}
{"qid": "-4544825586005995775", "question": "what is the second largest country in asia", "gold_answers": ["China"], "shots": {"0": {"k": 0, "answer": "Kazakhstan", "latency_ms": 2019.2689895629883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Japan", "latency_ms": 1168.992042541504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2696.0854530334473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "India", "latency_ms": 1178.8725852966309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1933}, "4": {"k": 4, "answer": "India", "latency_ms": 880.6149959564209, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2498}, "5": {"k": 5, "answer": "India", "latency_ms": 1266.5057182312012, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3190}, "6": {"k": 6, "answer": "India", "latency_ms": 770.4856395721436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3766}}}
{"qid": "2851585794686488659", "question": "when was the last episode of vampire diaries aired", "gold_answers": ["March 10 , 2017"], "shots": {"0": {"k": 0, "answer": "March 10, 2017", "latency_ms": 3069.9801445007324, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 10, 2017", "latency_ms": 3547.7445125579834, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "March 10, 2017", "latency_ms": 3978.391408920288, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "March 10, 2017", "latency_ms": 2918.2212352752686, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "March 10, 2017", "latency_ms": 2676.4936447143555, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2464}, "5": {"k": 5, "answer": "March 10, 2017", "latency_ms": 4390.117406845093, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3094}, "6": {"k": 6, "answer": "March 10, 2017", "latency_ms": 3795.0046062469482, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3683}}}
{"qid": "636692438616046367", "question": "who played ashley on the young and the restless", "gold_answers": ["Shari Shattuck", "Eileen Davidson", "Brenda Epperson"], "shots": {"0": {"k": 0, "answer": "Eileen Davidson", "latency_ms": 1470.6792831420898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Brenda Epperson", "latency_ms": 3033.7319374084473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "Brenda Epperson", "latency_ms": 2403.2530784606934, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Eileen Davidson, Brenda Epperson", "latency_ms": 3725.821018218994, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1870}, "4": {"k": 4, "answer": "Eileen Davidson, Brenda Epperson, Shari Shattuck", "latency_ms": 4702.396392822266, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2501}, "5": {"k": 5, "answer": "Eileen Davidson, Brenda Epperson, Shari Shattuck", "latency_ms": 5815.791368484497, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3110}, "6": {"k": 6, "answer": "Eileen Davidson, Brenda Epperson, Shari Shattuck", "latency_ms": 6744.772911071777, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3690}}}
{"qid": "-2668952310493902320", "question": "who has scored the most points for wales v france", "gold_answers": ["Neil Jenkins"], "shots": {"0": {"k": 0, "answer": "Neil Jenkins", "latency_ms": 1752.9551982879639, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2732.3484420776367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1682.5876235961914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2648.575782775879, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2196.8860626220703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2453}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2443.401098251343, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3037}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1914.776086807251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3657}}}
{"qid": "-551363795407275714", "question": "who is pictured on the 5000 dollar bill", "gold_answers": ["James Madison"], "shots": {"0": {"k": 0, "answer": "James Madison", "latency_ms": 1564.0809535980225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2161.4766120910645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1631.5603256225586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2107.1617603302, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1871}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2711.576461791992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2518}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2159.6665382385254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3115}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2402.67276763916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "-1776638341170409438", "question": "what is the strongest earthquake in the united states", "gold_answers": ["1700 Cascadia earthquake", "1964 Alaska earthquake and tsunami"], "shots": {"0": {"k": 0, "answer": "Great Alaska Earthquake of 1964", "latency_ms": 2928.9920330047607, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5.8 magnitude", "latency_ms": 1690.9875869750977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "5.8 magnitude", "latency_ms": 2659.114360809326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1307}, "3": {"k": 3, "answer": "5.8 magnitude", "latency_ms": 1612.3476028442383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1967}, "4": {"k": 4, "answer": "5.8", "latency_ms": 2329.8792839050293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2641}, "5": {"k": 5, "answer": "5.8", "latency_ms": 1343.9664840698242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3297}, "6": {"k": 6, "answer": "5.8", "latency_ms": 1603.0330657958984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3948}}}
{"qid": "-3417376069582577712", "question": "who wrote the song balls to the wall", "gold_answers": ["Herman Frank", "Peter Baltes", "Stefan Kaufmann", "Wolf Hoffmann", "Udo Dirkschneider", "Deaffy"], "shots": {"0": {"k": 0, "answer": "Accept", "latency_ms": 1191.382646560669, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2210.8728885650635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1911.8692874908447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1171}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1649.7068405151367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1761}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2316.3230419158936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2358}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2418.403148651123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2969}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2701.9011974334717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3565}}}
{"qid": "-5788046732019278353", "question": "who talks for belle in beauty and the beast", "gold_answers": ["Julie Nathanson", "Jodi Benson", "Paige O'Hara"], "shots": {"0": {"k": 0, "answer": "Paige O'Hara", "latency_ms": 2233.2427501678467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Emma Watson", "latency_ms": 1525.7446765899658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Emma Watson", "latency_ms": 1552.2456169128418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Paige O'Hara", "latency_ms": 2050.7049560546875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Paige O'Hara", "latency_ms": 3175.966739654541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2563}, "5": {"k": 5, "answer": "Paige O'Hara", "latency_ms": 2137.223958969116, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3190}, "6": {"k": 6, "answer": "Paige O'Hara", "latency_ms": 3137.1757984161377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3865}}}
{"qid": "-819495145099806596", "question": "what is a coherent set of values and beliefs about public policy called", "gold_answers": ["political ideology", "ideology", "a political ideology"], "shots": {"0": {"k": 0, "answer": "Ideology", "latency_ms": 1109.8136901855469, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Group of Five", "latency_ms": 2126.2898445129395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "Group of Five", "latency_ms": 2046.856164932251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1444}, "3": {"k": 3, "answer": "Group of Five", "latency_ms": 1337.7881050109863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2165}, "4": {"k": 4, "answer": "Public policy doctrine", "latency_ms": 1517.1031951904297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2861}, "5": {"k": 5, "answer": "Group of Five", "latency_ms": 1760.0464820861816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3587}, "6": {"k": 6, "answer": "Public policy doctrine", "latency_ms": 2116.3206100463867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4270}}}
{"qid": "-467801736331608973", "question": "when do liam and annie get together season 3", "gold_answers": ["Holiday Madness"], "shots": {"0": {"k": 0, "answer": "Episode 9.", "latency_ms": 2171.2286472320557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2178.619861602783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2560.4329109191895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2361.787796020508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2473.4699726104736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2453}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2679.877996444702, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3063}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1860.0308895111084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3659}}}
{"qid": "7210975046317501288", "question": "what breed of cat has spots and stripes", "gold_answers": ["tabby"], "shots": {"0": {"k": 0, "answer": "Ocicat", "latency_ms": 2663.4089946746826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Turkish Van", "latency_ms": 2343.128442764282, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 561}, "2": {"k": 2, "answer": "Abyssinian tabby", "latency_ms": 3105.2534580230713, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Australian Mist", "latency_ms": 1716.9156074523926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Bengal", "latency_ms": 2074.936628341675, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2520}, "5": {"k": 5, "answer": "Bengal", "latency_ms": 1848.357915878296, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3078}, "6": {"k": 6, "answer": "Bengal", "latency_ms": 2413.3408069610596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3729}}}
{"qid": "7817340376558760325", "question": "who voiced simba in the lion king 2", "gold_answers": ["Matthew Broderick"], "shots": {"0": {"k": 0, "answer": "Matthew Broderick", "latency_ms": 2388.4613513946533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2984.4467639923096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2223.7534523010254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "Matthew Broderick", "latency_ms": 1865.8735752105713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1877}, "4": {"k": 4, "answer": "Matthew Broderick", "latency_ms": 2626.432180404663, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Matthew Broderick", "latency_ms": 3268.6026096343994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3123}, "6": {"k": 6, "answer": "Matthew Broderick", "latency_ms": 2709.00821685791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3717}}}
{"qid": "7584034394038581786", "question": "when did the angel of the north get built", "gold_answers": ["1998", "1994"], "shots": {"0": {"k": 0, "answer": "1998", "latency_ms": 1316.5252208709717, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2962.1710777282715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "1998", "latency_ms": 2071.1140632629395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "1998", "latency_ms": 1580.4100036621094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1855}, "4": {"k": 4, "answer": "1998", "latency_ms": 1476.5138626098633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "1998", "latency_ms": 2024.9052047729492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3141}, "6": {"k": 6, "answer": "1998", "latency_ms": 2352.149724960327, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3692}}}
{"qid": "1854394640394891866", "question": "when did mcgee became a regular on ncis", "gold_answers": ["in season two", "season two"], "shots": {"0": {"k": 0, "answer": "Season 2", "latency_ms": 1332.615613937378, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3691.694498062134, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "Season two", "latency_ms": 1495.276689529419, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Season two", "latency_ms": 2106.268882751465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1932}, "4": {"k": 4, "answer": "Season two", "latency_ms": 1476.097822189331, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2565}, "5": {"k": 5, "answer": "Season two", "latency_ms": 1538.1972789764404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3215}, "6": {"k": 6, "answer": "Season two", "latency_ms": 1492.9461479187012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3808}}}
{"qid": "2247250807557083996", "question": "when was 1 john 5 7 added to the bible", "gold_answers": ["the 9th century"], "shots": {"0": {"k": 0, "answer": "15th century", "latency_ms": 1824.1827487945557, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "9th century", "latency_ms": 2127.432346343994, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "5th century", "latency_ms": 2155.829429626465, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "1520", "latency_ms": 1991.6949272155762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1779}, "4": {"k": 4, "answer": "Fifth century", "latency_ms": 2163.3193492889404, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "Fifth century", "latency_ms": 1296.9253063201904, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2962}, "6": {"k": 6, "answer": "Fifth century", "latency_ms": 2662.315845489502, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3550}}}
{"qid": "-2049551589682654986", "question": "when was the latest version of chrome released", "gold_answers": ["2018 - 01 - 22"], "shots": {"0": {"k": 0, "answer": "February 2024", "latency_ms": 1388.427734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "26 March 2013", "latency_ms": 3002.460718154907, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 717}, "2": {"k": 2, "answer": "26 March 2013", "latency_ms": 3165.5097007751465, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "20 May 2014", "latency_ms": 2806.929349899292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2050}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2818.647861480713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2752}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2210.427761077881, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3374}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2526.6573429107666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4053}}}
{"qid": "-3534092359651954035", "question": "who is jojo in horton hears a who", "gold_answers": ["Jesse McCartney"], "shots": {"0": {"k": 0, "answer": "Jo-Jo", "latency_ms": 1829.6077251434326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2991.0430908203125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2465.578317642212, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1211}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2187.9992485046387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1784}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2606.738567352295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2299}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2383.303642272949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2963}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2199.3162631988525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3598}}}
{"qid": "6504412384445795967", "question": "the part of the cytoskeleton made from the protein actin is called", "gold_answers": ["Microfilaments", "microfilament"], "shots": {"0": {"k": 0, "answer": "Microfilaments", "latency_ms": 1630.5396556854248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Microfilaments", "latency_ms": 2287.0049476623535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 676}, "2": {"k": 2, "answer": "Microfilaments", "latency_ms": 2369.7850704193115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1384}, "3": {"k": 3, "answer": "Microfilaments", "latency_ms": 2339.3232822418213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2058}, "4": {"k": 4, "answer": "Microfilaments", "latency_ms": 1386.2593173980713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2666}, "5": {"k": 5, "answer": "Microfilaments", "latency_ms": 2170.374631881714, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3331}, "6": {"k": 6, "answer": "Microfilaments", "latency_ms": 1596.228837966919, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3962}}}
{"qid": "95888218441734902", "question": "who plays jack in battle of the sexes", "gold_answers": ["Bill Pullman", "( Bill Pullman"], "shots": {"0": {"k": 0, "answer": "Steve Carell", "latency_ms": 2053.1744956970215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Steve Carell", "latency_ms": 2140.6238079071045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 660}, "2": {"k": 2, "answer": "Bill Pullman", "latency_ms": 1070.197343826294, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "Bill Pullman", "latency_ms": 2073.1794834136963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Bill Pullman", "latency_ms": 2100.412368774414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Bill Pullman", "latency_ms": 3132.188558578491, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3176}, "6": {"k": 6, "answer": "Bill Pullman", "latency_ms": 2174.0219593048096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3807}}}
{"qid": "2482202658787537401", "question": "is a network connection device that can build tables that identify addresses on each network", "gold_answers": ["routing table", "a router"], "shots": {"0": {"k": 0, "answer": "Router", "latency_ms": 1069.6356296539307, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1910.2709293365479, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Nmap", "latency_ms": 1746.0529804229736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "Nmap", "latency_ms": 1416.4762496948242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Nmap", "latency_ms": 1588.1690979003906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2622}, "5": {"k": 5, "answer": "Router", "latency_ms": 901.2165069580078, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3338}, "6": {"k": 6, "answer": "Nmap", "latency_ms": 1783.8592529296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4033}}}
{"qid": "8359496728452221378", "question": "when did the royal proclamation of 1763 end", "gold_answers": ["with the American Revolutionary War", "the American Revolutionary War", "1783"], "shots": {"0": {"k": 0, "answer": "1867", "latency_ms": 2380.4731369018555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3110.8758449554443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3694.3600177764893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1358}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2458.575487136841, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2019}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2455.8839797973633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2693}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2197.511911392212, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3321}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1540.1349067687988, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4022}}}
{"qid": "-2657014790962135860", "question": "the tenure of the office of the lokayukt of up", "gold_answers": ["8 years", "eight years"], "shots": {"0": {"k": 0, "answer": "8 years", "latency_ms": 1497.47896194458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eight years", "latency_ms": 1961.9591236114502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Eight years", "latency_ms": 1983.0429553985596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1335}, "3": {"k": 3, "answer": "Eight years", "latency_ms": 1762.502908706665, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1991}, "4": {"k": 4, "answer": "Eight years", "latency_ms": 1844.7587490081787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2653}, "5": {"k": 5, "answer": "Eight years", "latency_ms": 1779.4809341430664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3321}, "6": {"k": 6, "answer": "Eight years", "latency_ms": 2006.7267417907715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3945}}}
{"qid": "1827180983934640653", "question": "when did response to state of the union start", "gold_answers": ["1966", "in 1966"], "shots": {"0": {"k": 0, "answer": "1966", "latency_ms": 1106.386423110962, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1970", "latency_ms": 1792.506217956543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "1966", "latency_ms": 2163.69366645813, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1389}, "3": {"k": 3, "answer": "1966", "latency_ms": 1780.9460163116455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2071}, "4": {"k": 4, "answer": "1966", "latency_ms": 1493.382215499878, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2709}, "5": {"k": 5, "answer": "1966", "latency_ms": 2013.4239196777344, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3343}, "6": {"k": 6, "answer": "1966", "latency_ms": 2397.177219390869, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3957}}}
{"qid": "-8006002028754190814", "question": "who had the most governmental power under the articles of confederation", "gold_answers": ["the states"], "shots": {"0": {"k": 0, "answer": "State legislatures", "latency_ms": 1566.8182373046875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The States", "latency_ms": 1616.4865493774414, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 718}, "2": {"k": 2, "answer": "Congress of the Confederation", "latency_ms": 3483.189105987549, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1416}, "3": {"k": 3, "answer": "Congress of the Confederation", "latency_ms": 2739.327907562256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2102}, "4": {"k": 4, "answer": "Congress of the Confederation", "latency_ms": 3065.0908946990967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2814}, "5": {"k": 5, "answer": "The States", "latency_ms": 1964.9648666381836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3519}, "6": {"k": 6, "answer": "The States", "latency_ms": 2024.86252784729, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4213}}}
{"qid": "3406509904702130536", "question": "how many hospitals are there in the united states", "gold_answers": ["5,534 registered hospitals", "5,534"], "shots": {"0": {"k": 0, "answer": "5,764", "latency_ms": 1628.298044204712, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "5,534", "latency_ms": 2078.30810546875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 723}, "2": {"k": 2, "answer": "5,534", "latency_ms": 2705.4121494293213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1403}, "3": {"k": 3, "answer": "5,534", "latency_ms": 1508.0294609069824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2056}, "4": {"k": 4, "answer": "5,534", "latency_ms": 1774.6198177337646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2801}, "5": {"k": 5, "answer": "5,534", "latency_ms": 1509.6027851104736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3466}, "6": {"k": 6, "answer": "5,534", "latency_ms": 2330.7042121887207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4135}}}
{"qid": "2435796066046322163", "question": "who donates a christmas tree to trafalgar square", "gold_answers": ["Oslo , Norway"], "shots": {"0": {"k": 0, "answer": "Norway", "latency_ms": 1184.1459274291992, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The city of Oslo, Norway", "latency_ms": 3229.1524410247803, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "The city of Oslo, Norway", "latency_ms": 2988.825798034668, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "The city of Oslo, Norway", "latency_ms": 2511.058568954468, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "The city of Oslo, Norway", "latency_ms": 2597.2325801849365, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2545}, "5": {"k": 5, "answer": "The city of Oslo, Norway", "latency_ms": 2551.9535541534424, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3158}, "6": {"k": 6, "answer": "The city of Oslo, Norway", "latency_ms": 2740.358352661133, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3801}}}
{"qid": "4926415052497472665", "question": "who starred in the movie on golden pond", "gold_answers": ["William Lanteau", "Dabney Coleman", "Henry Fonda", "Doug McKeon", "Jane Fonda", "Christopher Rydell", "Katharine Hepburn"], "shots": {"0": {"k": 0, "answer": "Henry Fonda and Katharine Hepburn", "latency_ms": 3731.6393852233887, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 4292.000532150269, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 3181.3902854919434, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 4438.719749450684, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 3629.49800491333, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 3090.841054916382, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Katharine Hepburn and Henry Fonda", "latency_ms": 4260.672092437744, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3732}}}
{"qid": "2142753216627246962", "question": "isdn uses b & d channels. what is d channel use for", "gold_answers": ["carries control and signaling information", "data", "control and signaling information"], "shots": {"0": {"k": 0, "answer": "Signaling", "latency_ms": 1518.1405544281006, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "signaling and control", "latency_ms": 2233.210802078247, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "signaling and control", "latency_ms": 2255.687952041626, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 1338}, "3": {"k": 3, "answer": "signaling and control", "latency_ms": 2177.2677898406982, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 1946}, "4": {"k": 4, "answer": "signaling and control", "latency_ms": 2107.03182220459, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 2589}, "5": {"k": 5, "answer": "signaling and control", "latency_ms": 3146.747827529907, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3211}, "6": {"k": 6, "answer": "signaling and control", "latency_ms": 1910.5966091156006, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3816}}}
{"qid": "1547060614805522730", "question": "what is the rate limiting enzyme of kreb's cycle", "gold_answers": ["Isocitrate dehydrogenase"], "shots": {"0": {"k": 0, "answer": "Isocitrate dehydrogenase", "latency_ms": 3800.842761993408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2356.656312942505, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 679}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2411.024332046509, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1323}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2533.918857574463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2014}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1809.7755908966064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2660}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1411.9737148284912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3372}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1744.051456451416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4062}}}
{"qid": "8965198420725510475", "question": "when was the taj mahal built and completed", "gold_answers": ["1632 -- 53"], "shots": {"0": {"k": 0, "answer": "1632-1653", "latency_ms": 2465.1143550872803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1632-1648 AD", "latency_ms": 3314.551591873169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "1632-1653", "latency_ms": 2749.4735717773438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "1632-1653", "latency_ms": 2769.195556640625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "1632-1653", "latency_ms": 2483.2119941711426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2429}, "5": {"k": 5, "answer": "1632-1653", "latency_ms": 2126.323461532593, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3001}, "6": {"k": 6, "answer": "1632-1653", "latency_ms": 2923.6810207366943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3642}}}
{"qid": "-6292760252056275316", "question": "which supreme court judge has surved in international court of justice", "gold_answers": ["Dalveer Bhandari"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 2156.6097736358643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justice Dalveer Bhandari", "latency_ms": 2830.6949138641357, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 633}, "2": {"k": 2, "answer": "Justice Dalveer Bhandari", "latency_ms": 3646.273612976074, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1272}, "3": {"k": 3, "answer": "Justice Dalveer Bhandari", "latency_ms": 3579.176187515259, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1975}, "4": {"k": 4, "answer": "Dalveer Bhandari", "latency_ms": 3033.759593963623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2545}, "5": {"k": 5, "answer": "Dalveer Bhandari", "latency_ms": 2647.994041442871, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3181}, "6": {"k": 6, "answer": "Dalveer Bhandari", "latency_ms": 3269.24991607666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3824}}}
{"qid": "8361850218460994084", "question": "who is known as father of green revolution in india", "gold_answers": ["Mankombu Sambasivan Swaminathan"], "shots": {"0": {"k": 0, "answer": "M.S. Swaminathan", "latency_ms": 3073.7993717193604, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "M. S. Swaminathan", "latency_ms": 3912.8799438476562, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "M. S. Swaminathan", "latency_ms": 3916.1150455474854, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "M. S. Swaminathan", "latency_ms": 5535.222768783569, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2034}, "4": {"k": 4, "answer": "M. S. Swaminathan", "latency_ms": 3520.3192234039307, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2713}, "5": {"k": 5, "answer": "M. S. Swaminathan", "latency_ms": 4088.1576538085938, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3347}, "6": {"k": 6, "answer": "M. S. Swaminathan", "latency_ms": 4055.299997329712, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4068}}}
{"qid": "-5690645328022945594", "question": "who sing say you won't let go", "gold_answers": ["James Arthur"], "shots": {"0": {"k": 0, "answer": "James Arthur", "latency_ms": 1267.2719955444336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Arthur", "latency_ms": 2055.283308029175, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "James Arthur", "latency_ms": 1495.6419467926025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1112}, "3": {"k": 3, "answer": "James Arthur", "latency_ms": 1308.5908889770508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1704}, "4": {"k": 4, "answer": "James Arthur", "latency_ms": 1785.2001190185547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2308}, "5": {"k": 5, "answer": "James Arthur", "latency_ms": 1226.792335510254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2957}, "6": {"k": 6, "answer": "James Arthur", "latency_ms": 1808.5358142852783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3576}}}
{"qid": "-4292736993227486718", "question": "who monitor the recovery of the location during a disaster", "gold_answers": ["management team"], "shots": {"0": {"k": 0, "answer": "Emergency Management Teams", "latency_ms": 1337.9676342010498, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "A planning group", "latency_ms": 2613.1205558776855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 766}, "2": {"k": 2, "answer": "The management team", "latency_ms": 2808.7568283081055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1522}, "3": {"k": 3, "answer": "The management team", "latency_ms": 1794.896125793457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2184}, "4": {"k": 4, "answer": "The management team", "latency_ms": 1561.6087913513184, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2866}, "5": {"k": 5, "answer": "The management team", "latency_ms": 2112.9024028778076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3576}, "6": {"k": 6, "answer": "The management team", "latency_ms": 1846.4810848236084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4274}}}
{"qid": "-4741747756019727470", "question": "where does the synthesis of new dna from existing dna occurs", "gold_answers": ["origins of replication"], "shots": {"0": {"k": 0, "answer": "Replication fork", "latency_ms": 1605.454444885254, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in vivo", "latency_ms": 1497.8868961334229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "in a cell", "latency_ms": 1779.0427207946777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1372}, "3": {"k": 3, "answer": "in vivo", "latency_ms": 2843.066930770874, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2003}, "4": {"k": 4, "answer": "in a cell", "latency_ms": 2385.04695892334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2652}, "5": {"k": 5, "answer": "in vivo", "latency_ms": 2337.676525115967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3314}, "6": {"k": 6, "answer": "in vivo", "latency_ms": 1807.9078197479248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3961}}}
{"qid": "4268853195499399258", "question": "who sings gimme shelter with mick jagger", "gold_answers": ["Merry Clayton"], "shots": {"0": {"k": 0, "answer": "Meredith Hunter and Keith Richards and also guest vocalist Merry Clayton", "latency_ms": 5740.34857749939, "em": 0.0, "f1": 0.3076923076923077, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Merry Clayton", "latency_ms": 1204.69069480896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "Merry Clayton", "latency_ms": 2368.053674697876, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1302}, "3": {"k": 3, "answer": "Merry Clayton", "latency_ms": 1356.3456535339355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1912}, "4": {"k": 4, "answer": "Merry Clayton", "latency_ms": 2599.9834537506104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2588}, "5": {"k": 5, "answer": "Merry Clayton", "latency_ms": 2101.5384197235107, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3292}, "6": {"k": 6, "answer": "Merry Clayton", "latency_ms": 1813.8532638549805, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3939}}}
{"qid": "7172420463912356173", "question": "who does tony end up with on skins", "gold_answers": ["Michelle"], "shots": {"0": {"k": 0, "answer": "Michelle Richardson", "latency_ms": 962.6953601837158, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2209.052562713623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 574}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1648.198127746582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2112.496852874756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1770}, "4": {"k": 4, "answer": "No one", "latency_ms": 1478.4977436065674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2381}, "5": {"k": 5, "answer": "No one consistently", "latency_ms": 1629.5173168182373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2966}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2167.3896312713623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3556}}}
{"qid": "-1400292288904470066", "question": "who sings sugar sugar you are my candy girl", "gold_answers": ["the Archies"], "shots": {"0": {"k": 0, "answer": "The Archies", "latency_ms": 1522.707223892212, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The Four Seasons", "latency_ms": 2633.2032680511475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 581}, "2": {"k": 2, "answer": "The Four Seasons", "latency_ms": 1767.7831649780273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "The Archies", "latency_ms": 1661.7226600646973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "The Four Seasons", "latency_ms": 2078.596353530884, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2453}, "5": {"k": 5, "answer": "The Four Seasons", "latency_ms": 1859.5514297485352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3052}, "6": {"k": 6, "answer": "The Four Seasons", "latency_ms": 2119.602918624878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3737}}}
{"qid": "-1696720698220253139", "question": "who does tyler end up with in you get me", "gold_answers": ["Ali"], "shots": {"0": {"k": 0, "answer": "Ally", "latency_ms": 1789.4556522369385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1951.7483711242676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2686.1965656280518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2383.779287338257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1833}, "4": {"k": 4, "answer": "Ali", "latency_ms": 1213.23823928833, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2435}, "5": {"k": 5, "answer": "Ali", "latency_ms": 1701.1213302612305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3031}, "6": {"k": 6, "answer": "Ali", "latency_ms": 1268.3019638061523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3614}}}
{"qid": "-6797239474199900801", "question": "who won the gold for the men's figure skating", "gold_answers": ["Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Nathan Chen", "latency_ms": 1558.2823753356934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yuzuru Hanyu", "latency_ms": 3548.898458480835, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Yuzuru Hanyu", "latency_ms": 3244.652271270752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Yuzuru Hanyu", "latency_ms": 3080.244302749634, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1879}, "4": {"k": 4, "answer": "Yuzuru Hanyu", "latency_ms": 3575.6657123565674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2569}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 3130.6707859039307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3257}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 3356.8785190582275, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3944}}}
{"qid": "-7819569157752445011", "question": "when did the song holiday road come out", "gold_answers": ["1983", "June 24 , 1983"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 950.3777027130127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1983", "latency_ms": 1793.5900688171387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 655}, "2": {"k": 2, "answer": "1983", "latency_ms": 2618.0953979492188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "1983", "latency_ms": 1498.0747699737549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1907}, "4": {"k": 4, "answer": "1983", "latency_ms": 1573.9045143127441, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2610}, "5": {"k": 5, "answer": "1983", "latency_ms": 1750.1542568206787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3244}, "6": {"k": 6, "answer": "1983", "latency_ms": 1278.6107063293457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3930}}}
{"qid": "-8839043176903626071", "question": "when does the mlb season start and finish", "gold_answers": ["October 31 , 2018", "March 29"], "shots": {"0": {"k": 0, "answer": "Late March to Late October", "latency_ms": 2861.541748046875, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 20 to September 29", "latency_ms": 3573.883056640625, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "March 20 to September 29", "latency_ms": 3929.476022720337, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "March 20 to September 29", "latency_ms": 3147.416353225708, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "March 20 to September 29", "latency_ms": 3296.704053878784, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "March 20 to September 29", "latency_ms": 3448.208808898926, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "March 20 to September 29", "latency_ms": 3088.346004486084, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3695}}}
{"qid": "6356531089429364942", "question": "when did scotland beat england in six nations", "gold_answers": ["8 March 2008", "25 February 2006", "24 February 2018", "2 April 2000"], "shots": {"0": {"k": 0, "answer": "8 February 2020", "latency_ms": 3017.371892929077, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2010", "latency_ms": 2009.3026161193848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "2010", "latency_ms": 2021.5702056884766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1243}, "3": {"k": 3, "answer": "2010", "latency_ms": 1797.1630096435547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "2010", "latency_ms": 2367.93851852417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2520}, "5": {"k": 5, "answer": "2010", "latency_ms": 1954.6117782592773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "2010", "latency_ms": 1523.651123046875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3781}}}
{"qid": "-3382335563294993978", "question": "when did the rational dress society begin to work", "gold_answers": ["1881"], "shots": {"0": {"k": 0, "answer": "1881", "latency_ms": 1515.4149532318115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1881", "latency_ms": 1730.2093505859375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "1881", "latency_ms": 1509.48166847229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1326}, "3": {"k": 3, "answer": "1881", "latency_ms": 1696.7799663543701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1927}, "4": {"k": 4, "answer": "1881", "latency_ms": 1880.8231353759766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2581}, "5": {"k": 5, "answer": "1881", "latency_ms": 2056.8535327911377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3194}, "6": {"k": 6, "answer": "1881", "latency_ms": 1517.4634456634521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3827}}}
{"qid": "-5630827734073464379", "question": "why is the indian ocean the warmest in the world", "gold_answers": ["human induced greenhouse warming"], "shots": {"0": {"k": 0, "answer": "Thermohaline circulation.", "latency_ms": 3493.0191040039062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "human induced greenhouse warming", "latency_ms": 1880.831003189087, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 650}, "2": {"k": 2, "answer": "human induced greenhouse warming", "latency_ms": 2716.230869293213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Long-term ocean temperature records show a rapid, continuous warming", "latency_ms": 4344.781875610352, "em": 0.0, "f1": 0.16666666666666663, "containment": 0.0, "context_chars": 1929}, "4": {"k": 4, "answer": "human induced greenhouse warming", "latency_ms": 2113.28387260437, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2646}, "5": {"k": 5, "answer": "human induced greenhouse warming", "latency_ms": 1125.4377365112305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3257}, "6": {"k": 6, "answer": "Human induced greenhouse warming", "latency_ms": 2413.8548374176025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3876}}}
{"qid": "-3544151584263258729", "question": "where was the film manchester by the sea filmed", "gold_answers": ["Middleton", "Essex", "Gloucester", "Beverly", "Swampscott", "Lynn", "Manchester", "Salem", "Tewksbury"], "shots": {"0": {"k": 0, "answer": "Gloucester, Massachusetts", "latency_ms": 2791.217088699341, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 11547.229766845703, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 697}, "2": {"k": 2, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, Salem", "latency_ms": 9451.879978179932, "em": 0.0, "f1": 0.2, "containment": 1.0, "context_chars": 1334}, "3": {"k": 3, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem.", "latency_ms": 10926.236629486084, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 2006}, "4": {"k": 4, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem.", "latency_ms": 11671.289443969727, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 2685}, "5": {"k": 5, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem.", "latency_ms": 12327.410221099854, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 3359}, "6": {"k": 6, "answer": "Manchester-by-the-Sea, Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem.", "latency_ms": 13403.430700302124, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 4024}}}
{"qid": "-5077733789764986167", "question": "consist of the sum of the fixed and variable costs for any given level of production", "gold_answers": ["total cost ( TC )"], "shots": {"0": {"k": 0, "answer": "Total Costs", "latency_ms": 859.569787979126, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Y = a + bX", "latency_ms": 3187.2267723083496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 519}, "2": {"k": 2, "answer": "Total cost", "latency_ms": 1147.7572917938232, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1165}, "3": {"k": 3, "answer": "Total cost", "latency_ms": 2261.693000793457, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1766}, "4": {"k": 4, "answer": "Total cost", "latency_ms": 1257.5883865356445, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2331}, "5": {"k": 5, "answer": "Total cost", "latency_ms": 1705.029010772705, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2994}, "6": {"k": 6, "answer": "Total cost", "latency_ms": 1740.1955127716064, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3690}}}
{"qid": "4892187805447493570", "question": "where was thomas and the magic railroad filmed", "gold_answers": ["Toronto , Ontario , Canada", "Isle of Man", "the Isle of Man"], "shots": {"0": {"k": 0, "answer": "Strasburg Rail Road, Lancaster County, Pennsylvania, and Pinewood Studios, England.", "latency_ms": 6784.680604934692, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Strasburg, Pennsylvania, Toronto, Ontario, and the Isle of Man.", "latency_ms": 5319.636583328247, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 661}, "2": {"k": 2, "answer": "Strasburg, Pennsylvania, Toronto, Ontario, Canada, and the Isle of Man.", "latency_ms": 8754.42361831665, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1304}, "3": {"k": 3, "answer": "Strasburg, Pennsylvania, Toronto, Ontario, Canada, and the Isle of Man.", "latency_ms": 6396.1427211761475, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Strasburg, Pennsylvania, Toronto, Ontario, Canada, and the Isle of Man.", "latency_ms": 6489.607095718384, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2555}, "5": {"k": 5, "answer": "Strasburg, Pennsylvania, Toronto, Ontario, Canada, and the Isle of Man.", "latency_ms": 5325.902462005615, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3190}, "6": {"k": 6, "answer": "Strasburg, Pennsylvania, Toronto, Ontario, Canada, and the Isle of Man.", "latency_ms": 6350.157976150513, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3818}}}
{"qid": "-7094533216301278566", "question": "who has access to the presidential daily briefing", "gold_answers": ["Secretaries of State", "the President", "Defense", "National Security Advisor"], "shots": {"0": {"k": 0, "answer": "The President, Vice President, and select senior officials.", "latency_ms": 5026.240348815918, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President and top-level US officials", "latency_ms": 2266.761541366577, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "The President of the United States and top-level US officials", "latency_ms": 4584.169626235962, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1334}, "3": {"k": 3, "answer": "The President and top-level US officials approved by the President", "latency_ms": 3047.0495223999023, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2009}, "4": {"k": 4, "answer": "The President and a small number of top-level US officials", "latency_ms": 4128.334522247314, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2676}, "5": {"k": 5, "answer": "The President and a small number of top-level US officials", "latency_ms": 3818.9167976379395, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3380}, "6": {"k": 6, "answer": "The President and a small number of top-level US officials", "latency_ms": 4157.75728225708, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4107}}}
{"qid": "-243139310037543674", "question": "what tool is available from microsoft as an alternative to the usmt for smaller migrations", "gold_answers": ["Windows Easy Transfer"], "shots": {"0": {"k": 0, "answer": "USMT's smaller alternative is: Easy Transfer.", "latency_ms": 3751.357316970825, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Windows Easy Transfer", "latency_ms": 2407.102346420288, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 685}, "2": {"k": 2, "answer": "Windows Easy Transfer", "latency_ms": 2065.152406692505, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1344}, "3": {"k": 3, "answer": "Windows Easy Transfer", "latency_ms": 2330.111503601074, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2036}, "4": {"k": 4, "answer": "Windows Easy Transfer", "latency_ms": 1133.6376667022705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2675}, "5": {"k": 5, "answer": "Windows Easy Transfer", "latency_ms": 2012.1030807495117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3288}, "6": {"k": 6, "answer": "Windows Easy Transfer", "latency_ms": 2137.2721195220947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3943}}}
{"qid": "7079282152145474767", "question": "who appoints the chief election commissioner of india", "gold_answers": ["the president", "President of India"], "shots": {"0": {"k": 0, "answer": "The President of India", "latency_ms": 1939.0954971313477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President", "latency_ms": 1977.705478668213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "The President", "latency_ms": 1020.561933517456, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1437}, "3": {"k": 3, "answer": "The President", "latency_ms": 2012.1843814849854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2144}, "4": {"k": 4, "answer": "The President", "latency_ms": 1515.779972076416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2767}, "5": {"k": 5, "answer": "The President", "latency_ms": 1256.730556488037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3437}, "6": {"k": 6, "answer": "The President", "latency_ms": 1243.8092231750488, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4142}}}
{"qid": "6303430169473424975", "question": "glycogen and amylopectin are long chains of which simple sugar(s)", "gold_answers": ["glucose"], "shots": {"0": {"k": 0, "answer": "Glucose", "latency_ms": 1723.5054969787598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Glucose", "latency_ms": 994.8508739471436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "Glucose", "latency_ms": 1274.5606899261475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1340}, "3": {"k": 3, "answer": "Glucose", "latency_ms": 1260.282278060913, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Glucose", "latency_ms": 1036.330223083496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2683}, "5": {"k": 5, "answer": "Glucose", "latency_ms": 2003.1118392944336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3364}, "6": {"k": 6, "answer": "Glucose units", "latency_ms": 2105.9021949768066, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4019}}}
{"qid": "-3240666523350424161", "question": "who was the editor of the journal jugantor published in the time of swadeshi movement", "gold_answers": ["Bhupendranath Dutt"], "shots": {"0": {"k": 0, "answer": "Barindra Kumar Ghosh", "latency_ms": 2849.5116233825684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1447.7663040161133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2232.8717708587646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "Abhinash Bhattacharya, Barindra, Bhupendranath Dutt and Debabrata Basu.", "latency_ms": 9283.979415893555, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1910}, "4": {"k": 4, "answer": "Abhinash Bhattacharya, Barindra, Bhupendranath Dutt and Debabrata Basu.", "latency_ms": 8206.54010772705, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2549}, "5": {"k": 5, "answer": "Abhinash Bhattacharya, Barindra, Bhupendranath Dutt and Debabrata Basu.", "latency_ms": 9767.897129058838, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Abhinash Bhattacharya, Barindra, Bhupendranath Dutt and Debabrata Basu.", "latency_ms": 9251.990556716919, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3957}}}
{"qid": "1321443496772706078", "question": "when did indoor toilets become common in america", "gold_answers": ["After World War I"], "shots": {"0": {"k": 0, "answer": "Late 19th century.", "latency_ms": 2489.03489112854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1890s", "latency_ms": 1249.3057250976562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "1890s", "latency_ms": 2081.0704231262207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1315}, "3": {"k": 3, "answer": "1890s", "latency_ms": 1355.1955223083496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": "1890s", "latency_ms": 1138.1406784057617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2560}, "5": {"k": 5, "answer": "1890s", "latency_ms": 2041.7983531951904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "1890s", "latency_ms": 1217.773675918579, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3837}}}
{"qid": "6019244948248861067", "question": "who wrote were going on a bear hunt", "gold_answers": ["Michael Rosen"], "shots": {"0": {"k": 0, "answer": "Michael Rosen and Helen Oxenbury", "latency_ms": 1620.1391220092773, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rosen", "latency_ms": 1230.2947044372559, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "Michael Rosen", "latency_ms": 1825.9074687957764, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1222}, "3": {"k": 3, "answer": "Michael Rosen", "latency_ms": 1560.2834224700928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1819}, "4": {"k": 4, "answer": "Michael Rosen", "latency_ms": 777.9867649078369, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Michael Rosen", "latency_ms": 1544.3062782287598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3072}, "6": {"k": 6, "answer": "Michael Rosen", "latency_ms": 1545.8598136901855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3704}}}
{"qid": "8753987902863757141", "question": "what is the revolution period of venus in earth years", "gold_answers": ["0.615 198 yr", "224.7 Earth days"], "shots": {"0": {"k": 0, "answer": "0.61519726", "latency_ms": 1993.0782318115234, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2378.3040046691895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "0.615 Earth years", "latency_ms": 2389.2009258270264, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "0.62", "latency_ms": 1632.2951316833496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1806}, "4": {"k": 4, "answer": "0.62", "latency_ms": 2082.340955734253, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2465}, "5": {"k": 5, "answer": "0.615 Earth years", "latency_ms": 2197.361469268799, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3078}, "6": {"k": 6, "answer": "0.615 Earth years", "latency_ms": 2931.5717220306396, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3694}}}
{"qid": "-5904934687784134086", "question": "who has the power to approve or veto legislation constitution", "gold_answers": ["the President"], "shots": {"0": {"k": 0, "answer": "The President", "latency_ms": 1760.735273361206, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "The President of the United States", "latency_ms": 3213.0672931671143, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "The President of the United States", "latency_ms": 2355.369806289673, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "The President", "latency_ms": 1278.8314819335938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1884}, "4": {"k": 4, "answer": "The President", "latency_ms": 2030.1477909088135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2591}, "5": {"k": 5, "answer": "The President", "latency_ms": 1534.2371463775635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3259}, "6": {"k": 6, "answer": "The President", "latency_ms": 2051.1934757232666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3937}}}
{"qid": "-1910743846708408775", "question": "when was the taming ofthe shrew first performed", "gold_answers": ["prior to June 1592"], "shots": {"0": {"k": 0, "answer": "1593-1594", "latency_ms": 2529.660701751709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "11 of June 1594", "latency_ms": 3680.509090423584, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "11 June 1594", "latency_ms": 2020.9755897521973, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1310}, "3": {"k": 3, "answer": "11 June 1594", "latency_ms": 2524.9152183532715, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "11 June 1594", "latency_ms": 3303.5547733306885, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "11 June 1594", "latency_ms": 2627.347707748413, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "11 June 1594", "latency_ms": 2503.586769104004, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3881}}}
{"qid": "6521877788261380307", "question": "who is the first prime minister of france", "gold_answers": ["Michel Debr"], "shots": {"0": {"k": 0, "answer": "Adolphe Thiers", "latency_ms": 2475.6860733032227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2914.679527282715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 653}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1914.5314693450928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1324}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2116.750717163086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1973}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2498.544692993164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2622}, "5": {"k": 5, "answer": "Jacques-Charles Dupont de l'Eure", "latency_ms": 4634.41276550293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3272}, "6": {"k": 6, "answer": "Jacques-Charles Dupont de l'Eure", "latency_ms": 5258.814096450806, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3977}}}
{"qid": "-3375621376413612480", "question": "list of strict nature reserve in the philippines", "gold_answers": ["Lake Malimanga", "Palawan", "Calavite and FB Harrison", "Olango Island", "Calauit Safari Park", "Lake Buluan"], "shots": {"0": {"k": 0, "answer": "Verde Island Passage, Mayon Volcano, El Nido Managed Resource Protected Area.", "latency_ms": 7479.072332382202, "em": 0.0, "f1": 0.15384615384615385, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2350.1226902008057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 717}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2376.908540725708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1393}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1807.6794147491455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2026}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2315.840482711792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2695}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2092.0634269714355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3376}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2196.117162704468, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4095}}}
{"qid": "-7848107192827858958", "question": "where do the events in the story take place geographically", "gold_answers": ["Persia"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1879.1906833648682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Saint-Domingue, Paris, Neuilly, Alexandria, Jerusalem", "latency_ms": 4939.126968383789, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "Saint-Domingue, Paris, Neuilly, Alexandria, Jerusalem, Lazulis Island.", "latency_ms": 7391.719341278076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Saint-Domingue, Paris, Neuilly, Alexandria, Jerusalem, Lazulis Island, Spearpoint, Mars, Earth.", "latency_ms": 9481.415271759033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1847}, "4": {"k": 4, "answer": "Saint-Domingue, Paris, Neuilly, Alexandria, Jerusalem, Lazulis Island, Spearpoint, Mars, Oldorando, Campannlat, Avernus, Helliconia.", "latency_ms": 16505.516052246094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "Saint-Domingue, Paris, Neuilly, Alexandria, Jerusalem, Lazulis Island, Spearpoint, Oldorando, Campannlat, Avernus, Helliconia, Elantris, Arelon.", "latency_ms": 19998.323440551758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3077}, "6": {"k": 6, "answer": "Multiple locations", "latency_ms": 1540.783166885376, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3730}}}
{"qid": "-5123704261908217758", "question": "how and why were serial novels a phenomenon in the nineteenth century", "gold_answers": ["improved economics of distribution", "the rise of literacy", "technological advances in printing"], "shots": {"0": {"k": 0, "answer": "Penny dreadfuls and Dickens.", "latency_ms": 3695.6794261932373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rise of literacy, technological advances, and improved distribution economics.", "latency_ms": 7003.602981567383, "em": 0.0, "f1": 0.6153846153846153, "containment": 0.0, "context_chars": 749}, "2": {"k": 2, "answer": "rise of literacy, technological advances in printing, and improved economics of distribution.", "latency_ms": 7891.266107559204, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1432}, "3": {"k": 3, "answer": "Rise of literacy, technological advances in printing, and improved economics of distribution.", "latency_ms": 6232.463836669922, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2101}, "4": {"k": 4, "answer": "Rise of literacy, technological advances in printing, and improved economics of distribution.", "latency_ms": 6466.310977935791, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2781}, "5": {"k": 5, "answer": "Rise of literacy, technological advances in printing, and improved economics of distribution.", "latency_ms": 5889.541387557983, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3437}, "6": {"k": 6, "answer": "Rise of literacy, technological advances, and improved economics of distribution.", "latency_ms": 6038.304567337036, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4102}}}
{"qid": "8893432128322519771", "question": "who eliminated costa rica in world cup 2014", "gold_answers": ["Netherlands"], "shots": {"0": {"k": 0, "answer": "Netherlands", "latency_ms": 1065.676212310791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2915.2328968048096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Netherlands", "latency_ms": 2283.377170562744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1217}, "3": {"k": 3, "answer": "Netherlands", "latency_ms": 1501.6560554504395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Netherlands", "latency_ms": 1317.331314086914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2507}, "5": {"k": 5, "answer": "Netherlands", "latency_ms": 2051.4557361602783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3143}, "6": {"k": 6, "answer": "Netherlands", "latency_ms": 2234.1275215148926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3760}}}
{"qid": "-1356405650810931451", "question": "how many countries touches the land boundary of india", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "6", "latency_ms": 1218.9185619354248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "6", "latency_ms": 2008.4517002105713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "6", "latency_ms": 1016.1991119384766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "6", "latency_ms": 2089.4038677215576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "6", "latency_ms": 1163.1717681884766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "6", "latency_ms": 1495.3374862670898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "6", "latency_ms": 1735.419511795044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3799}}}
{"qid": "6447777231012695504", "question": "who was the 11th prime minister of canada", "gold_answers": ["R.B. Bennett", "Arthur Meighen"], "shots": {"0": {"k": 0, "answer": "William Lyon Mackenzie King", "latency_ms": 3762.6614570617676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sir Wilfrid Laurier", "latency_ms": 3076.907157897949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "Sir Wilfrid Laurier", "latency_ms": 4015.075206756592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1339}, "3": {"k": 3, "answer": "Richard Bedford Bennett", "latency_ms": 1893.200159072876, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "R. B. Bennett", "latency_ms": 3017.357110977173, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "R. B. Bennett", "latency_ms": 3519.699811935425, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3245}, "6": {"k": 6, "answer": "R. B. Bennett", "latency_ms": 4040.1933193206787, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3902}}}
{"qid": "-5935683210985272192", "question": "when did the steel mills closed in youngstown ohio", "gold_answers": ["September 19 , 1977"], "shots": {"0": {"k": 0, "answer": "1977", "latency_ms": 1053.682565689087, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 19, 1977", "latency_ms": 3633.5272789001465, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "September 19, 1977", "latency_ms": 3316.356420516968, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1347}, "3": {"k": 3, "answer": "September 19, 1977", "latency_ms": 3788.005590438843, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1990}, "4": {"k": 4, "answer": "September 19, 1977", "latency_ms": 3320.7294940948486, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2664}, "5": {"k": 5, "answer": "September 19, 1977", "latency_ms": 2895.275831222534, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3364}, "6": {"k": 6, "answer": "September 19, 1977", "latency_ms": 3728.835344314575, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4053}}}
{"qid": "1834961239491311230", "question": "who owns and operates the panama canal today", "gold_answers": ["Panama Canal Authority", "Panama", "Panamanian government"], "shots": {"0": {"k": 0, "answer": "The Panama Canal Authority", "latency_ms": 1733.49928855896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Panama Canal Authority", "latency_ms": 2817.64817237854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "Panama Canal Authority", "latency_ms": 2379.0621757507324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1293}, "3": {"k": 3, "answer": "Panama Canal Authority", "latency_ms": 2715.418577194214, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Panama Canal Authority", "latency_ms": 1927.539348602295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2636}, "5": {"k": 5, "answer": "Panama Canal Authority", "latency_ms": 1906.0096740722656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3308}, "6": {"k": 6, "answer": "Panama Canal Authority", "latency_ms": 2226.0777950286865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4002}}}
{"qid": "-535648230475805474", "question": "where is a simple gear train used in real life", "gold_answers": ["Automobile drivetrains"], "shots": {"0": {"k": 0, "answer": "Bicycle gears", "latency_ms": 1594.7625637054443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2114.590644836426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "automobile manual transmission", "latency_ms": 2198.2176303863525, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Automobile manual transmission", "latency_ms": 2140.8541202545166, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1842}, "4": {"k": 4, "answer": "Automobile manual transmission", "latency_ms": 2637.5489234924316, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2430}, "5": {"k": 5, "answer": "Automobile manual transmission", "latency_ms": 2429.546594619751, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2985}, "6": {"k": 6, "answer": "Automobile manual transmission", "latency_ms": 2159.6245765686035, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3567}}}
{"qid": "8911390210346559626", "question": "who plays the dad in malcom in the middle", "gold_answers": ["Bryan Cranston"], "shots": {"0": {"k": 0, "answer": "Bryan Cranston", "latency_ms": 1651.5588760375977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2344.1312313079834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2314.9147033691406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "Bryan Cranston", "latency_ms": 2084.308862686157, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1840}, "4": {"k": 4, "answer": "Bryan Cranston", "latency_ms": 3016.439437866211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Bryan Cranston", "latency_ms": 1990.8068180084229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3072}, "6": {"k": 6, "answer": "Bryan Cranston", "latency_ms": 2387.2783184051514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3690}}}
{"qid": "-8336776482564898273", "question": "who has won the most world series in baseball", "gold_answers": ["the New York Yankees", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "New York Yankees", "latency_ms": 1217.0491218566895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Yankees", "latency_ms": 2910.905122756958, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "New York Yankees", "latency_ms": 2340.8050537109375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1217}, "3": {"k": 3, "answer": "New York Yankees", "latency_ms": 2394.3166732788086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1810}, "4": {"k": 4, "answer": "New York Yankees", "latency_ms": 2690.006732940674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2389}, "5": {"k": 5, "answer": "New York Yankees", "latency_ms": 1576.8074989318848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2982}, "6": {"k": 6, "answer": "New York Yankees", "latency_ms": 2606.4677238464355, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3554}}}
{"qid": "-8742089114148260796", "question": "where are the winter olympic games being played", "gold_answers": ["Beijing"], "shots": {"0": {"k": 0, "answer": "Milan-Cortina", "latency_ms": 2047.1556186676025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pyeongchang", "latency_ms": 3221.397638320923, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "Beijing and Gangneung", "latency_ms": 3172.7006435394287, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1236}, "3": {"k": 3, "answer": "Beijing, China", "latency_ms": 2681.9379329681396, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Beijing and Gangneung", "latency_ms": 3043.562889099121, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2499}, "5": {"k": 5, "answer": "Beijing and Gangneung", "latency_ms": 3392.230987548828, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3124}, "6": {"k": 6, "answer": "Beijing, China", "latency_ms": 1943.3860778808594, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3768}}}
{"qid": "3864930130255054488", "question": "who made the song falling in love with you", "gold_answers": ["Hugo Peretti", "Elvis Presley", "George David Weiss", "Luigi Creatore"], "shots": {"0": {"k": 0, "answer": "Lauren Christy.", "latency_ms": 2818.228244781494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rodgers", "latency_ms": 1313.2719993591309, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 598}, "2": {"k": 2, "answer": "Rodgers", "latency_ms": 1770.81298828125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "Richard Rodgers", "latency_ms": 1290.9700870513916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Carole Bayer Sager and David Foster", "latency_ms": 4205.10196685791, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 2522}, "5": {"k": 5, "answer": "Carole Bayer Sager and David Foster", "latency_ms": 3755.9502124786377, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 3130}, "6": {"k": 6, "answer": "Carole Bayer Sager and David Foster", "latency_ms": 3360.877275466919, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 3736}}}
{"qid": "8076743617384207713", "question": "where did saudi crown prince go to college", "gold_answers": ["King Saud University"], "shots": {"0": {"k": 0, "answer": "King Saud University", "latency_ms": 1368.9615726470947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "King Faisal Air College", "latency_ms": 2350.292205810547, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1813.4410381317139, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1236}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2994.723081588745, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1900}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2624.0789890289307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Georgetown University", "latency_ms": 1909.9345207214355, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3236}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2163.6579036712646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3935}}}
{"qid": "1735766792677422630", "question": "who did the singing in into the woods", "gold_answers": ["the cast", "the cast members"], "shots": {"0": {"k": 0, "answer": "Meryl Streep", "latency_ms": 2324.0275382995605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Meryl Streep, Emily Blunt, James Corden, Anna Kendrick, Chris Pine, Johnny Depp, Daniel Huttlestone, Lilla Crawford, MacKenzie Mauzy, Tracey Ullman, Christine Baranski, Tammy Blanchard, Lucy Punch", "latency_ms": 24352.458953857422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 692}, "2": {"k": 2, "answer": "Meryl Streep, Emily Blunt, James Corden, Anna Kendrick, Chris Pine, Johnny Depp, Daniel Huttlestone, Lilla Crawford, MacKenzie Mauzy, Tracey Ullman, Christine Baranski, Tammy Blanchard, Lucy Punch", "latency_ms": 24658.583641052246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1405}, "3": {"k": 3, "answer": "Meryl Streep, Emily Blunt, James Corden, Anna Kendrick, Chris Pine, Johnny Depp, Daniel Huttlestone, Lilla Crawford, MacKenzie Mauzy, Tracey Ullman, Christine Baranski, Tammy Blanchard, and Lucy Punch.", "latency_ms": 25564.302682876587, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2076}, "4": {"k": 4, "answer": "Meryl Streep, Emily Blunt, James Corden, Anna Kendrick, Chris Pine, Johnny Depp", "latency_ms": 10075.090169906616, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2713}, "5": {"k": 5, "answer": "The ensemble cast including Meryl Streep, Emily Blunt, James Corden, Anna Kendrick, Chris Pine, Johnny Depp, Daniel Huttlestone, Lilla Crawford, MacKenzie Mauzy, Tracey Ullman, Christine Baranski, Tammy Blanchard, and Lucy Punch.", "latency_ms": 26367.72108078003, "em": 0.0, "f1": 0.06451612903225806, "containment": 0.0, "context_chars": 3400}, "6": {"k": 6, "answer": "the ensemble cast", "latency_ms": 2765.740156173706, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 4082}}}
{"qid": "5711801828691961426", "question": "who was the viceroy when the simon commission visited india", "gold_answers": ["Lord Irwin"], "shots": {"0": {"k": 0, "answer": "Lord Irwin", "latency_ms": 2210.446834564209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2361.6886138916016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "Lord Irwin", "latency_ms": 2132.8701972961426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1321}, "3": {"k": 3, "answer": "Lord Irwin", "latency_ms": 2537.6944541931152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1984}, "4": {"k": 4, "answer": "Lord Irwin", "latency_ms": 2035.6464385986328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2635}, "5": {"k": 5, "answer": "Lord Irwin", "latency_ms": 1978.0540466308594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3297}, "6": {"k": 6, "answer": "Lord Irwin", "latency_ms": 1573.8754272460938, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3982}}}
{"qid": "9001143341771379731", "question": "who in germany signed the treaty of versailles", "gold_answers": ["colonial minister Johannes Bell", "Foreign minister Hermann Mller", "Gustav Bauer"], "shots": {"0": {"k": 0, "answer": "Ulrich Graf von Brockdorff-Rantzau", "latency_ms": 5363.394498825073, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Germany's new political leadership", "latency_ms": 3209.8965644836426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Germany's new political leadership", "latency_ms": 2926.530361175537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 3552.9942512512207, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 1903}, "4": {"k": 4, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 2925.5528450012207, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 2591}, "5": {"k": 5, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 3517.4577236175537, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3263}, "6": {"k": 6, "answer": "Hermann Mller and Johannes Bell", "latency_ms": 3117.1350479125977, "em": 0.0, "f1": 0.4444444444444445, "containment": 0.0, "context_chars": 3934}}}
{"qid": "-4619585332904698754", "question": "who holds the record for most platinum albums", "gold_answers": ["The Beatles", "AC / DC", "Elvis Presley"], "shots": {"0": {"k": 0, "answer": "The Beatles", "latency_ms": 1977.7634143829346, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elvis Presley", "latency_ms": 2093.761205673218, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Elvis Presley", "latency_ms": 2657.3495864868164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1273}, "3": {"k": 3, "answer": "Elvis Presley", "latency_ms": 2477.75936126709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1889}, "4": {"k": 4, "answer": "Elvis Presley", "latency_ms": 3173.1510162353516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2489}, "5": {"k": 5, "answer": "Elvis Presley", "latency_ms": 2967.3352241516113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3108}, "6": {"k": 6, "answer": "Elvis Presley", "latency_ms": 2172.436237335205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3773}}}
{"qid": "-720512252272678238", "question": "when did the movie the post begin filming", "gold_answers": ["May 30 , 2017", "May 2017"], "shots": {"0": {"k": 0, "answer": "May 30, 2016", "latency_ms": 3923.461675643921, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "May 2017", "latency_ms": 2950.4125118255615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "May 2017", "latency_ms": 2782.3290824890137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1300}, "3": {"k": 3, "answer": "May 30, 2017", "latency_ms": 4137.4077796936035, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "May 30, 2017", "latency_ms": 3047.645092010498, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2630}, "5": {"k": 5, "answer": "May 30, 2017", "latency_ms": 3006.5786838531494, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3270}, "6": {"k": 6, "answer": "May 30, 2017", "latency_ms": 4219.651222229004, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3909}}}
{"qid": "-3371798557886238687", "question": "who starred in an officer and a gentleman", "gold_answers": ["Louis Gossett Jr .", "David Keith", "Louis Gossett Jr.", "Richard Gere", "Debra Winger", "Phillip J. Salmon"], "shots": {"0": {"k": 0, "answer": "Richard Gere", "latency_ms": 2086.58504486084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 6186.5575313568115, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 643}, "2": {"k": 2, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 7692.588567733765, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 7023.124217987061, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 1920}, "4": {"k": 4, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 7540.40789604187, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 2559}, "5": {"k": 5, "answer": "Richard Gere, Debra Winger, Louis Gossett Jr.", "latency_ms": 7424.209833145142, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3188}, "6": {"k": 6, "answer": "Richard Gere, Debra Winger, and Louis Gossett Jr.", "latency_ms": 7544.183015823364, "em": 0.0, "f1": 0.5454545454545454, "containment": 1.0, "context_chars": 3839}}}
