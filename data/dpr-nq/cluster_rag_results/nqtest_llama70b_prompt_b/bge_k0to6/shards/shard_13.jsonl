{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 3174.0171909332275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Julie Walters", "latency_ms": 1642.0519351959229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Geraldine Somerville", "latency_ms": 3723.797559738159, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Geraldine Somerville", "latency_ms": 2701.777696609497, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "Geraldine Somerville", "latency_ms": 2826.246738433838, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2504}, "5": {"k": 5, "answer": "Geraldine Somerville", "latency_ms": 2967.411756515503, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Geraldine Somerville", "latency_ms": 3228.3475399017334, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3801}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 1470.6151485443115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 2478.5313606262207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 2379.373788833618, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 2984.4231605529785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 1893.286943435669, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 1460.0520133972168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 2807.114601135254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3838}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwestern United States and Mexico", "latency_ms": 3279.1197299957275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4643.4125900268555, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 4467.683553695679, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1328}, "3": {"k": 3, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 4334.980726242065, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1977}, "4": {"k": 4, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 4370.262145996094, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2622}, "5": {"k": 5, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 3357.6276302337646, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3354}, "6": {"k": 6, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 4447.203159332275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3968}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 3227.077007293701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dr. Rajendra Prasad", "latency_ms": 3144.1195011138916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 743}, "2": {"k": 2, "answer": "Dr. Rajendra Prasad", "latency_ms": 3034.7211360931396, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1429}, "3": {"k": 3, "answer": "Dr. Rajendra Prasad", "latency_ms": 4189.709186553955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2127}, "4": {"k": 4, "answer": "Dr. Rajendra Prasad", "latency_ms": 3859.954595565796, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2802}, "5": {"k": 5, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 4201.653242111206, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3473}, "6": {"k": 6, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 4183.659315109253, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4153}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2936.78879737854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2635.7345581054688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 665}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2845.1433181762695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1302}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2435.5485439300537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1907}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2114.718437194824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2219.6104526519775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2640.6984329223633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3720}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "June 22, 2001", "latency_ms": 3131.3772201538086, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 22, 2001", "latency_ms": 3164.46852684021, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 672}, "2": {"k": 2, "answer": "June 22, 2001", "latency_ms": 3267.4412727355957, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1304}, "3": {"k": 3, "answer": "June 22, 2001", "latency_ms": 2657.864570617676, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1934}, "4": {"k": 4, "answer": "June 22, 2001", "latency_ms": 3697.6161003112793, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2592}, "5": {"k": 5, "answer": "June 22, 2001", "latency_ms": 3393.9902782440186, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3216}, "6": {"k": 6, "answer": "June 22, 2001", "latency_ms": 3790.271759033203, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3847}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "March 1, 2018", "latency_ms": 1859.6851825714111, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 3845.5870151519775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 2611.2139225006104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 3116.0826683044434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2052}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 3342.3218727111816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2724}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 3384.965181350708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3353}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2952.6400566101074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4035}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3.", "latency_ms": 1976.9225120544434, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2572.9739665985107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 562}, "2": {"k": 2, "answer": "Sectionals", "latency_ms": 1275.1052379608154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1194}, "3": {"k": 3, "answer": "after Sectionals", "latency_ms": 1880.9432983398438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1811}, "4": {"k": 4, "answer": "after Sectionals", "latency_ms": 2601.130485534668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "After sectionals", "latency_ms": 2078.124523162842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3082}, "6": {"k": 6, "answer": "After the mid-season finale episode \"Sectionals\"", "latency_ms": 4388.216972351074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3671}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2079.1704654693604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1863.6417388916016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2215.622663497925, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2640.0318145751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2409.1949462890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2409}, "5": {"k": 5, "answer": "Early 2019", "latency_ms": 2603.0004024505615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3046}, "6": {"k": 6, "answer": "Early 2019", "latency_ms": 2665.396213531494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 1892.2624588012695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Havana Harbor", "latency_ms": 2638.5152339935303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 594}, "2": {"k": 2, "answer": "Havana, Cuba", "latency_ms": 2462.264060974121, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "Havana, Cuba", "latency_ms": 2722.935438156128, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1877}, "4": {"k": 4, "answer": "Havana, Cuba", "latency_ms": 1665.5633449554443, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2459}, "5": {"k": 5, "answer": "Havana Harbor, Cuba", "latency_ms": 2627.90584564209, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3093}, "6": {"k": 6, "answer": "Havana Harbor, Cuba", "latency_ms": 2901.223659515381, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3717}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 1327.948808670044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2953.69815826416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2648.8497257232666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "No specific god mentioned", "latency_ms": 1667.4344539642334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1935}, "4": {"k": 4, "answer": "No specific god mentioned", "latency_ms": 2955.925703048706, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "None", "latency_ms": 1016.7908668518066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3171}, "6": {"k": 6, "answer": "Jains and Hindus", "latency_ms": 2701.4787197113037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3800}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama.", "latency_ms": 5170.006513595581, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Honduras", "latency_ms": 1955.5020332336426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Honduras, Guatemala", "latency_ms": 3534.9693298339844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Honduras, Guatemala", "latency_ms": 2997.359275817871, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1958}, "4": {"k": 4, "answer": "Honduras, Guatemala", "latency_ms": 3300.72283744812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2618}, "5": {"k": 5, "answer": "Honduras, Guatemala, Nicaragua, El Salvador, Costa Rica, Panama", "latency_ms": 7417.834758758545, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3282}, "6": {"k": 6, "answer": "Honduras, Guatemala, Nicaragua, Costa Rica, El Salvador, Panama", "latency_ms": 6486.4654541015625, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3948}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence.", "latency_ms": 1322.2572803497314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 1719.3453311920166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 708}, "2": {"k": 2, "answer": "Complex sentence", "latency_ms": 1247.6913928985596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1372}, "3": {"k": 3, "answer": "Complex sentence", "latency_ms": 2825.7577419281006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2028}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 1152.660608291626, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2776}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 1742.2411441802979, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3435}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 1270.254373550415, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4059}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and capitalism.", "latency_ms": 2536.6313457489014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 3936.0153675079346, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3931.2500953674316, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3743.501663208008, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1998}, "4": {"k": 4, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 4018.084764480591, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 2664}, "5": {"k": 5, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 3092.385768890381, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3334}, "6": {"k": 6, "answer": "the nature and causes of the wealth of nations", "latency_ms": 4024.364709854126, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3953}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 2889.415979385376, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 10, 2017", "latency_ms": 4412.853479385376, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "October 10, 2017", "latency_ms": 2920.238256454468, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 3859.999895095825, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 4485.905170440674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "October 10, 2017", "latency_ms": 3860.1882457733154, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3156}, "6": {"k": 6, "answer": "October 10, 2017", "latency_ms": 3919.828176498413, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3780}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere.", "latency_ms": 3955.972909927368, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 6552.767038345337, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 640}, "2": {"k": 2, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 6532.869338989258, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 1341}, "3": {"k": 3, "answer": "Oceania", "latency_ms": 2640.784502029419, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1985}, "4": {"k": 4, "answer": "Oceania", "latency_ms": 2283.559799194336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2644}, "5": {"k": 5, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 6583.620071411133, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3332}, "6": {"k": 6, "answer": "Oceania, between the Indian Ocean and the South Pacific Ocean.", "latency_ms": 7085.492372512817, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4057}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Mara Jade", "latency_ms": 2674.2541790008545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Camie, Nakari Kelen, Mara Jade", "latency_ms": 5929.908037185669, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Camie, Nakari Kelen, Mara Jade", "latency_ms": 4806.595087051392, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1219}, "3": {"k": 3, "answer": "Camie, Nakari Kelen, Mara Jade", "latency_ms": 5517.319440841675, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Camie, Nakari Kelen, Mara Jade, Leia", "latency_ms": 6142.433166503906, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2450}, "5": {"k": 5, "answer": "Camie, Nakari Kelen, Mara Jade", "latency_ms": 4884.81593132019, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3080}, "6": {"k": 6, "answer": "Camie, Nakari Kelen, Mara Jade", "latency_ms": 5159.03377532959, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3675}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 1238.1088733673096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack Barry", "latency_ms": 2330.864906311035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Jack Barry", "latency_ms": 1794.041633605957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Jack Barry", "latency_ms": 1537.451982498169, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1822}, "4": {"k": 4, "answer": "Jack Barry", "latency_ms": 2243.722677230835, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2461}, "5": {"k": 5, "answer": "Jack Barry", "latency_ms": 1781.3494205474854, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3091}, "6": {"k": 6, "answer": "Jack Barry", "latency_ms": 1717.693567276001, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3641}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 1875.1893043518066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mitochondrion", "latency_ms": 3055.2945137023926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 707}, "2": {"k": 2, "answer": "Mitochondria", "latency_ms": 1638.1025314331055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "Mitochondria", "latency_ms": 2570.9431171417236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2072}, "4": {"k": 4, "answer": "Mitochondria", "latency_ms": 2564.67604637146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2713}, "5": {"k": 5, "answer": "Mitochondria and Chloroplasts", "latency_ms": 3652.367115020752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3372}, "6": {"k": 6, "answer": "Mitochondria and Chloroplasts", "latency_ms": 4107.132196426392, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4069}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Intrusion Detection.", "latency_ms": 6144.009590148926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Background checks, keystroke tracking, photo ID, thumb print, cameras", "latency_ms": 7157.586336135864, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 771}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2568.068504333496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1464}, "3": {"k": 3, "answer": "Background checks, keystroke tracking, photo ID, thumb print, cameras", "latency_ms": 6596.5611934661865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2173}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2896.876573562622, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2897}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2644.5045471191406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3580}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2464.10870552063, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4298}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3160.310745239258, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dottie West and Kenny Rogers", "latency_ms": 2757.46488571167, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 583}, "2": {"k": 2, "answer": "Dottie West and Kenny Rogers", "latency_ms": 3874.2549419403076, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1170}, "3": {"k": 3, "answer": "Dottie West and Kenny Rogers", "latency_ms": 3452.1026611328125, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1840}, "4": {"k": 4, "answer": "Dottie West and Kenny Rogers", "latency_ms": 3012.624502182007, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2442}, "5": {"k": 5, "answer": "Dottie West and Kenny Rogers", "latency_ms": 2951.014518737793, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3118}, "6": {"k": 6, "answer": "Dottie West and Kenny Rogers", "latency_ms": 3245.659112930298, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3729}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 1337.6765251159668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "36 months", "latency_ms": 1944.4913864135742, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 601}, "2": {"k": 2, "answer": "36 months", "latency_ms": 2033.475399017334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1220}, "3": {"k": 3, "answer": "36 months", "latency_ms": 1722.7554321289062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1855}, "4": {"k": 4, "answer": "36 months old", "latency_ms": 2317.596197128296, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2438}, "5": {"k": 5, "answer": "36 months", "latency_ms": 2286.726951599121, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3138}, "6": {"k": 6, "answer": "36 months", "latency_ms": 1721.8043804168701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3823}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 1752.3820400238037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1681.469440460205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2668.333053588867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3003.33571434021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2755.8910846710205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2472}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2242.908477783203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3068}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2765.6445503234863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3699}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 6723.488569259644, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elijah Wood", "latency_ms": 1347.8248119354248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2618.06058883667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1302}, "3": {"k": 3, "answer": "Elijah Wood", "latency_ms": 2170.433282852173, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1968}, "4": {"k": 4, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan", "latency_ms": 5453.786373138428, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2622}, "5": {"k": 5, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan", "latency_ms": 6400.9881019592285, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan", "latency_ms": 5403.779029846191, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3902}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party.", "latency_ms": 2482.269048690796, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume", "latency_ms": 1490.8628463745117, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2919.0258979797363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1171}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2669.9516773223877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1793}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2727.135419845581, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2524.2137908935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3038}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2148.235321044922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3692}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 734.6737384796143, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2894.2975997924805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2170.872449874878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2146.693468093872, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2009}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3066.9291019439697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2627}, "5": {"k": 5, "answer": "1", "latency_ms": 915.8508777618408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3253}, "6": {"k": 6, "answer": "1", "latency_ms": 2054.6531677246094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3866}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "Gratitude to Fantine", "latency_ms": 2204.946756362915, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "To protect her", "latency_ms": 1668.2627201080322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "He promised Fantine", "latency_ms": 2521.045446395874, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "He promised Fantine", "latency_ms": 1226.0029315948486, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "He promised Fantine", "latency_ms": 2450.648784637451, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "He promised Fantine", "latency_ms": 1411.789894104004, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "He promised Fantine", "latency_ms": 3480.0078868865967, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3723}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, South Korea, Zambia, United States.", "latency_ms": 4202.570915222168, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenya", "latency_ms": 1411.0498428344727, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 692}, "2": {"k": 2, "answer": "Kenya, China", "latency_ms": 2125.910520553589, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1395}, "3": {"k": 3, "answer": "Kenya, China", "latency_ms": 2530.1454067230225, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2096}, "4": {"k": 4, "answer": "Kenya, China, India", "latency_ms": 3035.2320671081543, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2807}, "5": {"k": 5, "answer": "Kenya, China, India", "latency_ms": 3229.3801307678223, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3497}, "6": {"k": 6, "answer": "Kenya, China, India", "latency_ms": 3245.258331298828, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4317}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and oppression.", "latency_ms": 2097.8190898895264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Enforcing racially separated educational facilities", "latency_ms": 3598.0851650238037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 675}, "2": {"k": 2, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7989.797115325928, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1289}, "3": {"k": 3, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7602.68759727478, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2005}, "4": {"k": 4, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 8322.073221206665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2681}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7137.426137924194, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3380}, "6": {"k": 6, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7794.733047485352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4082}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 1911.947250366211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 3058.8409900665283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 2492.629289627075, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Huge and powerful snake", "latency_ms": 2620.3970909118652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1759}, "4": {"k": 4, "answer": "Huge and powerful snake", "latency_ms": 3078.810214996338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2455}, "5": {"k": 5, "answer": "Huge and powerful snake", "latency_ms": 2596.7957973480225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3029}, "6": {"k": 6, "answer": "Cobra", "latency_ms": 982.3031425476074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3615}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 2236.879348754883, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "water ice covered with layers of dust and sand", "latency_ms": 4477.994441986084, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 598}, "2": {"k": 2, "answer": "water ice covered with layers of dust and sand", "latency_ms": 4073.67205619812, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1207}, "3": {"k": 3, "answer": "Water ice and dry ice", "latency_ms": 2740.6270503997803, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1833}, "4": {"k": 4, "answer": "ice-coated dust grains", "latency_ms": 1566.1039352416992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "ice-coated dust grains", "latency_ms": 3315.199375152588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "ice-coated dust grains", "latency_ms": 3149.2254734039307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3756}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 3947.7765560150146, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Fourth season", "latency_ms": 1232.269287109375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 577}, "2": {"k": 2, "answer": "Fourth season", "latency_ms": 2059.1607093811035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1178}, "3": {"k": 3, "answer": "Season three", "latency_ms": 1804.6448230743408, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1770}, "4": {"k": 4, "answer": "Season 3 finale", "latency_ms": 1695.7495212554932, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2349}, "5": {"k": 5, "answer": "Season 3 finale", "latency_ms": 2660.733461380005, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2949}, "6": {"k": 6, "answer": "Season 3 finale", "latency_ms": 2157.972574234009, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3537}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "The home team", "latency_ms": 1640.8796310424805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dennis Wise and Dion Dublin", "latency_ms": 2750.9419918060303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 574}, "2": {"k": 2, "answer": "Dennis Wise and Dion Dublin", "latency_ms": 3508.7571144104004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "Dennis Wise and Dion Dublin", "latency_ms": 3913.675308227539, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1751}, "4": {"k": 4, "answer": "Dennis Wise and Dion Dublin", "latency_ms": 3409.313678741455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2352}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2543.8756942749023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2948}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2183.3865642547607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3521}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw.", "latency_ms": 1527.8785228729248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington, D.C.", "latency_ms": 3415.87233543396, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 691}, "2": {"k": 2, "answer": "Northwest quadrant", "latency_ms": 2379.9774646759033, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1348}, "3": {"k": 3, "answer": "Northwest quadrant", "latency_ms": 2872.9851245880127, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2005}, "4": {"k": 4, "answer": "Northwest quadrant", "latency_ms": 2642.364263534546, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2689}, "5": {"k": 5, "answer": "Northwest quadrant", "latency_ms": 2602.1673679351807, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3339}, "6": {"k": 6, "answer": "Northwest", "latency_ms": 1563.0073547363281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4052}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 2314.5182132720947, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noahic", "latency_ms": 1838.2313251495361, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "Noahic", "latency_ms": 2671.782970428467, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1320}, "3": {"k": 3, "answer": "Noahic", "latency_ms": 1839.583396911621, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1958}, "4": {"k": 4, "answer": "Noahic", "latency_ms": 2558.199405670166, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2569}, "5": {"k": 5, "answer": "Noahic", "latency_ms": 1872.3742961883545, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3125}, "6": {"k": 6, "answer": "Noahic", "latency_ms": 1885.0409984588623, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3745}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 1628.1483173370361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3526.762008666992, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2434.5808029174805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1224}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3193.531274795532, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1952.6259899139404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1771.6484069824219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3035}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1871.0975646972656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3665}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "Yip Harburg", "latency_ms": 2422.032356262207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2087.7532958984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2728.463649749756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2152.3303985595703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2605.767250061035, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2548}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2199.974298477173, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3197}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2905.9102535247803, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3992}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 2129.6515464782715, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 1949.1593837738037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 642}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 1496.9468116760254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 1798.666000366211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 1502.722978591919, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Lee County", "latency_ms": 1845.360517501831, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Lee County", "latency_ms": 1549.5784282684326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3848}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "Second", "latency_ms": 1255.9993267059326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Second", "latency_ms": 1455.923318862915, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "Second", "latency_ms": 1982.384443283081, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Second most populated country", "latency_ms": 2912.5897884368896, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Second most populated country", "latency_ms": 2994.9495792388916, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2567}, "5": {"k": 5, "answer": "Second", "latency_ms": 1290.1678085327148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "Second", "latency_ms": 1004.9500465393066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3937}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 2258.854389190674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jawaharlal Nehru", "latency_ms": 3094.2492485046387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 699}, "2": {"k": 2, "answer": "Jawaharlal Nehru", "latency_ms": 3637.2501850128174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1390}, "3": {"k": 3, "answer": "Mahatma Gandhi", "latency_ms": 2673.7329959869385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2064}, "4": {"k": 4, "answer": "Mahatma Gandhi", "latency_ms": 2715.0471210479736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2740}, "5": {"k": 5, "answer": "Mahatma Gandhi", "latency_ms": 2383.6162090301514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3415}, "6": {"k": 6, "answer": "Mahatma Gandhi", "latency_ms": 2675.96697807312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4088}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenae Anderson", "latency_ms": 2016.4048671722412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2066.5674209594727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Bobby Flay", "latency_ms": 2455.6891918182373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Bobby Flay", "latency_ms": 3030.402183532715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "Bobby Flay", "latency_ms": 3214.022636413574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2492}, "5": {"k": 5, "answer": "Bobby Flay", "latency_ms": 3395.9851264953613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3115}, "6": {"k": 6, "answer": "Bobby Flay", "latency_ms": 2041.1784648895264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3743}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 578.6418914794922, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": ".java", "latency_ms": 2010.9226703643799, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": ".java", "latency_ms": 900.5162715911865, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "codice_22", "latency_ms": 2670.5360412597656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1995}, "4": {"k": 4, "answer": "codice_22", "latency_ms": 3497.915744781494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2610}, "5": {"k": 5, "answer": "codice_22", "latency_ms": 2107.3529720306396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3229}, "6": {"k": 6, "answer": "codice_22", "latency_ms": 2349.337100982666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3927}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 2110.8999252319336, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alan Turing", "latency_ms": 1751.2428760528564, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "Alan Turing", "latency_ms": 2129.429340362549, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1373}, "3": {"k": 3, "answer": "Alan Turing", "latency_ms": 1536.8690490722656, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2108}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 1522.8488445281982, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2817}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 2054.2101860046387, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3508}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 2335.3230953216553, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4209}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline and counting votes.", "latency_ms": 3367.2406673431396, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "manages their party's legislative program", "latency_ms": 4128.023862838745, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 669}, "2": {"k": 2, "answer": "manages their party's legislative program on the House floor", "latency_ms": 6279.049634933472, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1281}, "3": {"k": 3, "answer": "manages their party's legislative program", "latency_ms": 2614.1421794891357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1915}, "4": {"k": 4, "answer": "manages party's legislative program", "latency_ms": 2886.9235515594482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2634}, "5": {"k": 5, "answer": "manages party's legislative program", "latency_ms": 3475.8875370025635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3348}, "6": {"k": 6, "answer": "manage party's legislative program", "latency_ms": 2765.230178833008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3982}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 1302.02317237854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1974", "latency_ms": 1771.4931964874268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 679}, "2": {"k": 2, "answer": "1974", "latency_ms": 1027.1587371826172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "2001", "latency_ms": 1305.3719997406006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1902}, "4": {"k": 4, "answer": "1989", "latency_ms": 1851.2258529663086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2484}, "5": {"k": 5, "answer": "1989", "latency_ms": 1278.5849571228027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "2001", "latency_ms": 2121.2947368621826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3796}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the right but not the obligation to buy foreign currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 1295.5191135406494, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 2017.6596641540527, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 2310.603380203247, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 1328.2690048217773, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1972}, "4": {"k": 4, "answer": "FX option", "latency_ms": 2028.5449028015137, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2662}, "5": {"k": 5, "answer": "FX option", "latency_ms": 2075.21390914917, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3311}, "6": {"k": 6, "answer": "FX option", "latency_ms": 1580.7421207427979, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3874}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360", "latency_ms": 743.5703277587891, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 1819.1728591918945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360", "latency_ms": 860.1062297821045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1352}, "3": {"k": 3, "answer": "360", "latency_ms": 1722.3927974700928, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2011}, "4": {"k": 4, "answer": "360", "latency_ms": 1224.6248722076416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2756}, "5": {"k": 5, "answer": "360", "latency_ms": 1732.9127788543701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3450}, "6": {"k": 6, "answer": "360", "latency_ms": 1213.6008739471436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4146}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 1862.813949584961, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 2442.2807693481445, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 2074.263572692871, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 2210.320234298706, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 2409.3432426452637, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 2981.4271926879883, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 1406.9905281066895, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3850}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gorm"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 2242.401123046875, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eydie Gorm", "latency_ms": 2221.0533618927, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 580}, "2": {"k": 2, "answer": "Eydie Gorm", "latency_ms": 2360.734701156616, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1157}, "3": {"k": 3, "answer": "Eydie Gorm", "latency_ms": 2698.800563812256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1758}, "4": {"k": 4, "answer": "Eydie Gorm", "latency_ms": 2632.5409412384033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2359}, "5": {"k": 5, "answer": "Eydie Gorm", "latency_ms": 2845.202684402466, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2935}, "6": {"k": 6, "answer": "Eydie Gorm", "latency_ms": 2359.421491622925, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3552}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "Kurian Joseph", "latency_ms": 2671.205997467041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2247.7195262908936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2422.4307537078857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Mohan Shantanagoudar", "latency_ms": 3917.0944690704346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "Mohan Shantanagoudar", "latency_ms": 3436.727285385132, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2518}, "5": {"k": 5, "answer": "Mohan Shantanagoudar", "latency_ms": 3945.880889892578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3139}, "6": {"k": 6, "answer": "Mohan Shantanagoudar", "latency_ms": 5235.766649246216, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3742}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "Margaret Court", "latency_ms": 1462.5518321990967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Margaret Court", "latency_ms": 1413.3541584014893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 669}, "2": {"k": 2, "answer": "Roger Federer", "latency_ms": 2650.5982875823975, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Roger Federer", "latency_ms": 2702.2552490234375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Roger Federer", "latency_ms": 1815.2379989624023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2483}, "5": {"k": 5, "answer": "Roger Federer", "latency_ms": 1755.5649280548096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3057}, "6": {"k": 6, "answer": "Roger Federer", "latency_ms": 1872.5576400756836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3631}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 1519.7744369506836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 924.921989440918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 2294.4087982177734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1228}, "3": {"k": 3, "answer": "1", "latency_ms": 438.89451026916504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1864}, "4": {"k": 4, "answer": "1", "latency_ms": 1741.5049076080322, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2479}, "5": {"k": 5, "answer": "1", "latency_ms": 965.6906127929688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3092}, "6": {"k": 6, "answer": "1", "latency_ms": 1626.9903182983398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3691}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 1279.0496349334717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2009", "latency_ms": 1798.1324195861816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "2009", "latency_ms": 2059.5641136169434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1235}, "3": {"k": 3, "answer": "2009", "latency_ms": 1592.9632186889648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1890}, "4": {"k": 4, "answer": "2009 and 2010", "latency_ms": 3125.7121562957764, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2589}, "5": {"k": 5, "answer": "2010", "latency_ms": 1545.386552810669, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3187}, "6": {"k": 6, "answer": "2010", "latency_ms": 1976.426124572754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3839}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 1509.3460083007812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "At least 1", "latency_ms": 1961.6165161132812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "17", "latency_ms": 1471.142292022705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "37", "latency_ms": 1186.70654296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1988}, "4": {"k": 4, "answer": "17", "latency_ms": 1453.066110610962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2594}, "5": {"k": 5, "answer": "37", "latency_ms": 974.9555587768555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "37", "latency_ms": 2039.0405654907227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3916}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 1851.5448570251465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 2791.0518646240234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 2466.6895866394043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 2330.1753997802734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1914}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 2014.5518779754639, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2556}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 2566.9379234313965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3207}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 2431.605339050293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3838}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 5108.611583709717, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2763.591527938843, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1670.7217693328857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3175.053596496582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1991}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2459.763526916504, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2659}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2754.1797161102295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1899.3043899536133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3926}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 2368.0429458618164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Toby Keith", "latency_ms": 2368.284225463867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "Toby Keith", "latency_ms": 2676.7656803131104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Toby Keith", "latency_ms": 2055.861234664917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Toby Keith", "latency_ms": 2417.3293113708496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2402}, "5": {"k": 5, "answer": "Toby Keith", "latency_ms": 1851.7911434173584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3013}, "6": {"k": 6, "answer": "Toby Keith", "latency_ms": 2360.274314880371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3633}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 1205.9104442596436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 1527.6353359222412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "159", "latency_ms": 974.1349220275879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "159", "latency_ms": 1809.5746040344238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "159", "latency_ms": 974.2605686187744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2626}, "5": {"k": 5, "answer": "159", "latency_ms": 1489.9234771728516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3316}, "6": {"k": 6, "answer": "159", "latency_ms": 947.8795528411865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3989}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 2235.2635860443115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Matt Flinders", "latency_ms": 1889.251470565796, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "Matt Flinders", "latency_ms": 1907.0513248443604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1298}, "3": {"k": 3, "answer": "Matt Flinders", "latency_ms": 2387.803792953491, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Matt Flinders", "latency_ms": 2351.987361907959, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2562}, "5": {"k": 5, "answer": "Matt Flinders", "latency_ms": 1388.854742050171, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Matt Flinders", "latency_ms": 1925.743818283081, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3869}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 1153.3215045928955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2216.944456100464, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 602}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2283.339500427246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2112.8227710723877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1836}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1651.71480178833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2437}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2363.445281982422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3035}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2710.5469703674316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3687}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 1355.947494506836, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Right hand", "latency_ms": 1173.6741065979004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 1793.4441566467285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1137}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 1538.5653972625732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1739}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 1429.8739433288574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2303}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 1503.8502216339111, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2897}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 1934.1933727264404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3533}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 2219.480514526367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2401.5231132507324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2104.8476696014404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2315.6609535217285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1914}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2888.0934715270996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2551}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2570.103406906128, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3185}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2006.7574977874756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3821}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 2697.676181793213, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bernard Hill", "latency_ms": 1671.3838577270508, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 644}, "2": {"k": 2, "answer": "Bernard Hill", "latency_ms": 1535.8517169952393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "Bernard Hill", "latency_ms": 1333.5990905761719, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Bernard Hill", "latency_ms": 2414.799451828003, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "Bernard Hill", "latency_ms": 2143.1543827056885, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3233}, "6": {"k": 6, "answer": "Bernard Hill", "latency_ms": 2661.9696617126465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3821}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2019", "latency_ms": 3211.26127243042, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2018", "latency_ms": 3420.6717014312744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 3142.106771469116, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 3153.477668762207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 3399.1730213165283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2483}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 4165.401935577393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3113}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 2672.2166538238525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3704}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 1858.7391376495361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles", "latency_ms": 986.0849380493164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Los Angeles", "latency_ms": 1558.0425262451172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Los Angeles", "latency_ms": 1974.9267101287842, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1855}, "4": {"k": 4, "answer": "Los Angeles", "latency_ms": 1794.7955131530762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2487}, "5": {"k": 5, "answer": "Los Angeles", "latency_ms": 1544.3439483642578, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3086}, "6": {"k": 6, "answer": "Los Angeles", "latency_ms": 2304.7194480895996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3708}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 2153.9013385772705, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indiana Evans", "latency_ms": 1519.9658870697021, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2136.993646621704, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1251}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2342.7858352661133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1891}, "4": {"k": 4, "answer": "Indiana Evans", "latency_ms": 1901.5533924102783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "Indiana Evans", "latency_ms": 1759.6631050109863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "Indiana Evans", "latency_ms": 1551.7089366912842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3844}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living organisms.", "latency_ms": 2158.079147338867, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in plants, soils, and organisms", "latency_ms": 4073.578357696533, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 648}, "2": {"k": 2, "answer": "in plants, soils, and organisms", "latency_ms": 3603.426218032837, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "in plants, soils, and organisms", "latency_ms": 3696.500062942505, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "in all land-living organisms, soils, plants, and forests", "latency_ms": 6147.980690002441, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2652}, "5": {"k": 5, "answer": "in all land-living organisms, soils, plants, and forests", "latency_ms": 6050.560235977173, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3295}, "6": {"k": 6, "answer": "in all land-living organisms, soils, plants, and animals", "latency_ms": 5627.6609897613525, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3862}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "Vijay Raghavendra", "latency_ms": 3381.242036819458, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pratham", "latency_ms": 1553.478717803955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "Pratham", "latency_ms": 2907.7417850494385, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Pratham", "latency_ms": 1508.2859992980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Pratham", "latency_ms": 1504.1322708129883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2496}, "5": {"k": 5, "answer": "Pratham", "latency_ms": 1292.0258045196533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "Pratham", "latency_ms": 2031.5570831298828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3776}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 2922.100782394409, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake Powell", "latency_ms": 1568.7768459320068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "Lake Powell, Kanab, Utah", "latency_ms": 4257.589340209961, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Lake Powell, Kanab, Utah", "latency_ms": 3064.6207332611084, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1892}, "4": {"k": 4, "answer": "Lake Powell, Kanab, Utah, and Clay County", "latency_ms": 4679.30793762207, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Lake Powell, Kanab, Utah, and Clay County", "latency_ms": 5475.7678508758545, "em": 0.0, "f1": 0.4444444444444445, "containment": 1.0, "context_chars": 3110}, "6": {"k": 6, "answer": "Lake Powell, Kanab, Utah, Jackson County, Clay County", "latency_ms": 5051.115989685059, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3828}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 1597.2621440887451, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Stevens", "latency_ms": 1232.7215671539307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Henry Garrett", "latency_ms": 1823.1558799743652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1288}, "3": {"k": 3, "answer": "Kevin Kline", "latency_ms": 1097.7721214294434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1983}, "4": {"k": 4, "answer": "Kevin Kline", "latency_ms": 2191.786527633667, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2621}, "5": {"k": 5, "answer": "Dan Stevens", "latency_ms": 1521.6588973999023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3282}, "6": {"k": 6, "answer": "Dan Stevens", "latency_ms": 1261.397361755371, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3897}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Canada to Lake Winnipeg.", "latency_ms": 4076.003313064575, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 2540.3366088867188, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 728}, "2": {"k": 2, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 2226.3524532318115, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1438}, "3": {"k": 3, "answer": "central Saskatchewan to Lake Winnipeg", "latency_ms": 2732.7165603637695, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "Rocky Mountains to Lake Winnipeg", "latency_ms": 2078.3348083496094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2761}, "5": {"k": 5, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 3070.894956588745, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3459}, "6": {"k": 6, "answer": "Central Saskatchewan to Lake Winnipeg", "latency_ms": 2925.5008697509766, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4060}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 1236.2895011901855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 1789.1952991485596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome", "latency_ms": 1559.7999095916748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Rome", "latency_ms": 1768.28932762146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1843}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 1608.1972122192383, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2487}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 2132.7219009399414, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3102}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 2088.395357131958, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3764}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "CE Mark or Measure number", "latency_ms": 2271.469831466675, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "batch code", "latency_ms": 1523.4990119934082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "year mark", "latency_ms": 1283.6849689483643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "batch code", "latency_ms": 2351.9866466522217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1801}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2436.039924621582, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2364}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2725.3293991088867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2987}, "6": {"k": 6, "answer": "Year mark", "latency_ms": 1025.2313613891602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3608}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia, methanol.", "latency_ms": 3741.130828857422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "associated liquids", "latency_ms": 1801.6221523284912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 671}, "2": {"k": 2, "answer": "Ice", "latency_ms": 933.5215091705322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 4387.322425842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 3292.7610874176025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 4106.03666305542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3216}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 3882.760763168335, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3820}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Once in a Lifetime", "latency_ms": 2189.7430419921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2589.4689559936523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2093.7552452087402, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1142}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1680.955171585083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1702}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2424.069404602051, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2287}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2132.4219703674316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2933}, "6": {"k": 6, "answer": "The Little Match Girl", "latency_ms": 1665.4667854309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3494}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 1247.035264968872, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hombre", "latency_ms": 1214.059829711914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Hombre", "latency_ms": 2298.40350151062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1234}, "3": {"k": 3, "answer": "Rook", "latency_ms": 1319.6427822113037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "Rook", "latency_ms": 1205.6550979614258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2413}, "5": {"k": 5, "answer": "Rook", "latency_ms": 1267.0347690582275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3036}, "6": {"k": 6, "answer": "Rook", "latency_ms": 2075.392723083496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3612}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 2422.024965286255, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2223.661184310913, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 610}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3065.7901763916016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1183}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1990.2894496917725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1769}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2403.4268856048584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2354}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2425.3876209259033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3009}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2266.711473464966, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3543}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 2074.1536617279053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1975", "latency_ms": 1566.5371417999268, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 610}, "2": {"k": 2, "answer": "1975", "latency_ms": 1791.898250579834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "1975", "latency_ms": 1776.7078876495361, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "1975", "latency_ms": 2003.7624835968018, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2515}, "5": {"k": 5, "answer": "1975", "latency_ms": 1808.763027191162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3108}, "6": {"k": 6, "answer": "1975", "latency_ms": 1006.2317848205566, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3852}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 2176.318407058716, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lionel Richie", "latency_ms": 2633.1212520599365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Lionel Richie", "latency_ms": 1820.373773574829, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1273}, "3": {"k": 3, "answer": "Lionel Richie", "latency_ms": 2635.812997817993, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1840}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 2409.5373153686523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2426}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 2678.5800457000732, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3005}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 2400.237798690796, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3636}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert, 2nd Baron Baltimore", "latency_ms": 5586.005687713623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cecil Calvert and Catholic settlers", "latency_ms": 3630.614757537842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Cecil Calvert and Catholic settlers", "latency_ms": 3780.1454067230225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1297}, "3": {"k": 3, "answer": "Cecil Calvert", "latency_ms": 2484.2846393585205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "Cecil Calvert", "latency_ms": 2405.864953994751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Cecil Calvert", "latency_ms": 2738.4257316589355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3218}, "6": {"k": 6, "answer": "Cecil Calvert and Lord Baltimore", "latency_ms": 4039.2422676086426, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3871}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player", "latency_ms": 1029.7482013702393, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1848.1009006500244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2680.39870262146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Gary Player", "latency_ms": 1251.5578269958496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1875}, "4": {"k": 4, "answer": "Gary Player", "latency_ms": 1284.853458404541, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Gary Player", "latency_ms": 1288.773536682129, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3077}, "6": {"k": 6, "answer": "Gary Player", "latency_ms": 2094.202756881714, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3827}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 2171.529769897461, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "200 to 500 mg", "latency_ms": 2464.130640029907, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "200 to 500 mg", "latency_ms": 3560.2824687957764, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1269}, "3": {"k": 3, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 4829.869747161865, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1889}, "4": {"k": 4, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 5325.4711627960205, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2607}, "5": {"k": 5, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 6875.312328338623, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3226}, "6": {"k": 6, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 5140.149116516113, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3886}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 2543.9305305480957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham", "latency_ms": 2293.971300125122, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 578}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 2996.7057704925537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1166}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 2802.225112915039, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1758}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 1884.0744495391846, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2394}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 2918.8220500946045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2966}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 1867.4254417419434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3562}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 2072.0372200012207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Beer parlours", "latency_ms": 1816.554307937622, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Beer parlours", "latency_ms": 2376.8224716186523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Canada, Mexico, and the Caribbean.", "latency_ms": 4745.610475540161, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2067}, "4": {"k": 4, "answer": "nearby township of Lorneville", "latency_ms": 3277.5039672851562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2683}, "5": {"k": 5, "answer": "Canada, Mexico, or the Caribbean.", "latency_ms": 3458.209753036499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3335}, "6": {"k": 6, "answer": "nearby township of Lorneville or the town of Winton", "latency_ms": 5450.098514556885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3983}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh, Scotland", "latency_ms": 1877.9587745666504, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 2701.838970184326, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 2989.941120147705, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1372}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 1622.3797798156738, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2057}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 2755.418062210083, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2733}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 2968.059301376343, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3406}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 3275.2349376678467, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4109}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 1891.8814659118652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2462.735891342163, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 706}, "2": {"k": 2, "answer": "Roman Reigns", "latency_ms": 1631.5560340881348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1413}, "3": {"k": 3, "answer": "Roman Reigns", "latency_ms": 2369.037389755249, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2090}, "4": {"k": 4, "answer": "AJ Styles", "latency_ms": 2279.329538345337, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2692}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2737.041711807251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3360}, "6": {"k": 6, "answer": "AJ Styles and Bray Wyatt", "latency_ms": 2494.3902492523193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4007}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 2486.259698867798, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Southport", "latency_ms": 1963.4029865264893, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 560}, "2": {"k": 2, "answer": "Southport", "latency_ms": 1703.6397457122803, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1144}, "3": {"k": 3, "answer": "Southport", "latency_ms": 1350.6648540496826, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1780}, "4": {"k": 4, "answer": "Southport", "latency_ms": 1695.5859661102295, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2343}, "5": {"k": 5, "answer": "Southport, North Carolina", "latency_ms": 2309.7918033599854, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2939}, "6": {"k": 6, "answer": "Southport, North Carolina", "latency_ms": 2926.5077114105225, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3573}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 1578.7038803100586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2438.335657119751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 705}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2707.5977325439453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1366}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2650.362014770508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1971}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1489.8056983947754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2609}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 2551.7520904541016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 2313.321352005005, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3831}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 1648.7252712249756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 1918.6561107635498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 714}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 2432.20591545105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1460}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 1616.6882514953613, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2166}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 1321.4774131774902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2903}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 1834.8331451416016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3650}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 1683.2301616668701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4386}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 939.4869804382324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 1391.0937309265137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 600}, "2": {"k": 2, "answer": "Max", "latency_ms": 978.8286685943604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1163}, "3": {"k": 3, "answer": "Max", "latency_ms": 1164.250135421753, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1791}, "4": {"k": 4, "answer": "Max", "latency_ms": 913.2592678070068, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2426}, "5": {"k": 5, "answer": "Max", "latency_ms": 1488.9028072357178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3027}, "6": {"k": 6, "answer": "Max", "latency_ms": 1197.049617767334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3671}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 2701.29656791687, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amybeth McNulty", "latency_ms": 2232.205629348755, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 649}, "2": {"k": 2, "answer": "Amybeth McNulty", "latency_ms": 2507.1280002593994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Amybeth McNulty", "latency_ms": 3135.2739334106445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "Amybeth McNulty", "latency_ms": 3287.658929824829, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "Amybeth McNulty", "latency_ms": 2134.479761123657, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Amybeth McNulty", "latency_ms": 1905.7786464691162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3786}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "Boxer Rebellion.", "latency_ms": 1946.2380409240723, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2487.394332885742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 651}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2668.2565212249756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "The 1900s decade began.", "latency_ms": 3541.156530380249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "The start of the 1900s decade.", "latency_ms": 3540.593385696411, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2565}, "5": {"k": 5, "answer": "The 1900s decade began.", "latency_ms": 4208.514928817749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3252}, "6": {"k": 6, "answer": "The 1900s decade began.", "latency_ms": 3637.7153396606445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3846}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 1724.8799800872803, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "self-empowerment", "latency_ms": 1596.4627265930176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "self-empowerment", "latency_ms": 2913.6881828308105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "self-empowerment", "latency_ms": 2748.7943172454834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "self-empowerment", "latency_ms": 3175.0965118408203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2629}, "5": {"k": 5, "answer": "self-empowerment", "latency_ms": 2408.454656600952, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3212}, "6": {"k": 6, "answer": "Empowerment", "latency_ms": 1612.0052337646484, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3834}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams' front offices", "latency_ms": 2893.7466144561768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "each team", "latency_ms": 2048.758029937744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "each team", "latency_ms": 967.2853946685791, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1247}, "3": {"k": 3, "answer": "each team", "latency_ms": 1215.1141166687012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1836}, "4": {"k": 4, "answer": "each team", "latency_ms": 1216.212511062622, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2476}, "5": {"k": 5, "answer": "each team", "latency_ms": 1788.1934642791748, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3063}, "6": {"k": 6, "answer": "The teams", "latency_ms": 1943.406343460083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3664}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 1885.7009410858154, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1884.8292827606201, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "James W. Marshall", "latency_ms": 2113.8107776641846, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "James W. Marshall", "latency_ms": 2160.865068435669, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1895}, "4": {"k": 4, "answer": "James W. Marshall", "latency_ms": 2103.062868118286, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2573}, "5": {"k": 5, "answer": "James W. Marshall", "latency_ms": 1461.7676734924316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3200}, "6": {"k": 6, "answer": "James W. Marshall", "latency_ms": 1882.5948238372803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3846}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 1759.246587753296, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 1833.5068225860596, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 2388.2851600646973, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 1679.6863079071045, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 2170.3128814697266, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 1309.6342086791992, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 2255.1581859588623, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "9", "latency_ms": 445.38235664367676, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1735.5270385742188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1548.5968589782715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "5", "latency_ms": 1266.5276527404785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "All five ski jumping gold medals.", "latency_ms": 2612.3292446136475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2511}, "5": {"k": 5, "answer": "5", "latency_ms": 1161.3805294036865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3150}, "6": {"k": 6, "answer": "5", "latency_ms": 911.322832107544, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3814}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 2447.556495666504, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 2972.8827476501465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 617}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 2103.8575172424316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1253}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 2629.7125816345215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3590.714931488037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 2839.059829711914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 2809.6539974212646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3850}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 1340.487003326416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central Germany", "latency_ms": 1491.9652938842773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Central Germany", "latency_ms": 1787.6172065734863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1374}, "3": {"k": 3, "answer": "Central Germany", "latency_ms": 1814.0721321105957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2020}, "4": {"k": 4, "answer": "German-speaking world", "latency_ms": 1858.088731765747, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "Central European cultures", "latency_ms": 2090.406656265259, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3349}, "6": {"k": 6, "answer": "European", "latency_ms": 409.26384925842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4031}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 1699.9669075012207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 2435.930013656616, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 2687.081813812256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 2970.158100128174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1978}, "4": {"k": 4, "answer": "16481651", "latency_ms": 2737.9398345947266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2661}, "5": {"k": 5, "answer": "16481651", "latency_ms": 3359.287977218628, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3339}, "6": {"k": 6, "answer": "16481651", "latency_ms": 2883.56876373291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3964}}}
