{"qid": "5306300389470118812", "question": "what was the religion in persia before islam", "gold_answers": ["the Zoroastrian religion", "Zoroastrian"], "shots": {"0": {"k": 0, "answer": "Zoroastrianism", "latency_ms": 1737.4439239501953, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Zoroastrianism", "latency_ms": 2696.3276863098145, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "Zoroastrianism", "latency_ms": 1978.47580909729, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 1396}, "3": {"k": 3, "answer": "Zoroastrianism", "latency_ms": 3524.5697498321533, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2068}, "4": {"k": 4, "answer": "Zoroastrianism", "latency_ms": 2757.481813430786, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 2746}, "5": {"k": 5, "answer": "Zoroastrianism", "latency_ms": 2247.4353313446045, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 3482}, "6": {"k": 6, "answer": "Zoroastrianism", "latency_ms": 2823.8213062286377, "em": 0.0, "f1": 0.0, "containment": 1.0, "context_chars": 4192}}}
{"qid": "4492088526674104172", "question": "why does kerosene oil rise up in the wick of lantern", "gold_answers": ["capillary action"], "shots": {"0": {"k": 0, "answer": "Capillary action.", "latency_ms": 1888.4658813476562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Capillary action", "latency_ms": 2635.2362632751465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "Capillary action", "latency_ms": 1550.8928298950195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1208}, "3": {"k": 3, "answer": "Capillary action", "latency_ms": 2390.8798694610596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1785}, "4": {"k": 4, "answer": "Capillary action", "latency_ms": 1949.5630264282227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2402}, "5": {"k": 5, "answer": "Capillary action", "latency_ms": 1209.0070247650146, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3021}, "6": {"k": 6, "answer": "Capillary action", "latency_ms": 1867.6989078521729, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3676}}}
{"qid": "-4373262132142058334", "question": "mention the chemical change that proinsulin undergo to be able to act as mature insulin", "gold_answers": ["post translational modification"], "shots": {"0": {"k": 0, "answer": "Proteolytic cleavage.", "latency_ms": 3339.3962383270264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cleavage of C-peptide", "latency_ms": 4413.5730266571045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Cleavage of C-peptide.", "latency_ms": 3968.7294960021973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "Cleavage of C-peptide", "latency_ms": 2270.4880237579346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1967}, "4": {"k": 4, "answer": "Cleavage of C-peptide", "latency_ms": 2923.907518386841, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "Cleavage of C-peptide", "latency_ms": 2656.2821865081787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "Cleavage of C-peptide", "latency_ms": 3114.272117614746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3834}}}
{"qid": "-5298560410953979569", "question": "where does the sweetness of fruit come from", "gold_answers": ["Fructose , or fruit sugar", "Fructose"], "shots": {"0": {"k": 0, "answer": "Fructose", "latency_ms": 1311.253547668457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3099.590539932251, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 654}, "2": {"k": 2, "answer": "Sucrose", "latency_ms": 1253.1037330627441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "photosynthesis", "latency_ms": 2499.422550201416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1959}, "4": {"k": 4, "answer": "photosynthesis", "latency_ms": 966.7580127716064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2636}, "5": {"k": 5, "answer": "photosynthesis", "latency_ms": 1505.6650638580322, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3332}, "6": {"k": 6, "answer": "photosynthesis", "latency_ms": 1380.0015449523926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4020}}}
{"qid": "4344648368832551136", "question": "an object that moves around an external axis is said to be", "gold_answers": ["orbit", "revolution or orbital revolution"], "shots": {"0": {"k": 0, "answer": "rotating", "latency_ms": 1039.4635200500488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "revolving", "latency_ms": 1786.3497734069824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "revolving", "latency_ms": 1176.9630908966064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1186}, "3": {"k": 3, "answer": "revolving", "latency_ms": 2261.638641357422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1758}, "4": {"k": 4, "answer": "revolving", "latency_ms": 1273.1506824493408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2325}, "5": {"k": 5, "answer": "revolving", "latency_ms": 1174.7422218322754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2938}, "6": {"k": 6, "answer": "revolving", "latency_ms": 2144.275903701782, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3603}}}
{"qid": "-724426540432437711", "question": "what was the name of the plant on little shop of horrors", "gold_answers": ["Audrey II"], "shots": {"0": {"k": 0, "answer": "Audrey II", "latency_ms": 1968.3117866516113, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Audrey II", "latency_ms": 836.400032043457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Audrey II", "latency_ms": 2201.1802196502686, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1243}, "3": {"k": 3, "answer": "Audrey II", "latency_ms": 1545.3524589538574, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1896}, "4": {"k": 4, "answer": "Audrey II", "latency_ms": 1561.0971450805664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2594}, "5": {"k": 5, "answer": "Audrey II", "latency_ms": 2386.0809803009033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Audrey II", "latency_ms": 1767.3883438110352, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3852}}}
{"qid": "-5541610970112826260", "question": "who signed the declaration of independence for maryland", "gold_answers": ["Samuel Chase", "Charles Carroll of Carrollton", "Thomas Stone", "William Paca"], "shots": {"0": {"k": 0, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll.", "latency_ms": 5177.807569503784, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 6646.52156829834, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 704}, "2": {"k": 2, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 5989.921092987061, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 1294}, "3": {"k": 3, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 7555.420160293579, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 1948}, "4": {"k": 4, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 6416.7540073394775, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 2568}, "5": {"k": 5, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 6962.852239608765, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 3240}, "6": {"k": 6, "answer": "Samuel Chase, William Paca, Thomas Stone, and Charles Carroll of Carrollton", "latency_ms": 6387.946367263794, "em": 0.0, "f1": 0.5333333333333333, "containment": 1.0, "context_chars": 3921}}}
{"qid": "-86997217831791339", "question": "when does wonder woman come out on blue ray", "gold_answers": ["September 19 , 2017"], "shots": {"0": {"k": 0, "answer": "August 29, 2017", "latency_ms": 3336.3077640533447, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1890.6452655792236, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "September 19, 2017", "latency_ms": 2890.6099796295166, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1194}, "3": {"k": 3, "answer": "September 19, 2017", "latency_ms": 2818.650007247925, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1848}, "4": {"k": 4, "answer": "September 19, 2017", "latency_ms": 3045.631170272827, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2521}, "5": {"k": 5, "answer": "September 19, 2017", "latency_ms": 3785.2861881256104, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "September 19, 2017", "latency_ms": 3641.3168907165527, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3825}}}
{"qid": "-8062812506672279762", "question": "what nba team did derrick rose play for", "gold_answers": ["New York Knicks", "Minnesota Timberwolves", "Chicago Bulls", "Cleveland Cavaliers"], "shots": {"0": {"k": 0, "answer": "Chicago Bulls, Cleveland Cavaliers, Minnesota Timberwolves, Detroit Pistons, New York Knicks.", "latency_ms": 6890.741586685181, "em": 0.0, "f1": 0.42857142857142855, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York (implied, not directly stated, however other teams are mentioned that he played against)", "latency_ms": 7235.555171966553, "em": 0.0, "f1": 0.2222222222222222, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "New York Knicks, Cleveland Cavaliers, Oklahoma City Thunder, Washington Wizards, Boston Celtics, Chicago, Portland Trail Blazers, New Orleans Pelicans", "latency_ms": 8545.030355453491, "em": 0.0, "f1": 0.2727272727272727, "containment": 1.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Washington Wizards, Oklahoma City Thunder, New Orleans Pelicans, Boston Celtics, Portland Trail Blazers, New York Knicks, Cleveland Cavaliers, Orlando Magic, Utah Jazz, Sacramento Kings, Minnesota Timberwolves", "latency_ms": 12085.927248001099, "em": 0.0, "f1": 0.20689655172413793, "containment": 1.0, "context_chars": 1766}, "4": {"k": 4, "answer": "New York Knicks, Cleveland Cavaliers, Minnesota Timberwolves, Boston Celtics, Chicago Bulls, Utah Jazz, Oklahoma City Thunder, Washington Wizards, Sacramento Kings, Orlando Magic", "latency_ms": 9967.08083152771, "em": 0.0, "f1": 0.24000000000000005, "containment": 1.0, "context_chars": 2344}, "5": {"k": 5, "answer": "New York Knicks, Cleveland Cavaliers, Minnesota Timberwolves, Chicago Bulls, Utah Jazz", "latency_ms": 5955.727100372314, "em": 0.0, "f1": 0.42857142857142855, "containment": 1.0, "context_chars": 2919}, "6": {"k": 6, "answer": "New York Knicks, Cleveland Cavaliers, Minnesota Timberwolves, Chicago Bulls, Utah Jazz", "latency_ms": 5207.744598388672, "em": 0.0, "f1": 0.42857142857142855, "containment": 1.0, "context_chars": 3483}}}
{"qid": "7933002036740390435", "question": "where did the term liberal arts come from", "gold_answers": ["the Roman Empire"], "shots": {"0": {"k": 0, "answer": "Ancient Rome", "latency_ms": 1392.9853439331055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roman Empire", "latency_ms": 1520.620584487915, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Roman Empire", "latency_ms": 1715.437412261963, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Roman Empire", "latency_ms": 1014.4650936126709, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Roman Empire", "latency_ms": 1204.9319744110107, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2579}, "5": {"k": 5, "answer": "Roman Empire", "latency_ms": 2223.0584621429443, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3228}, "6": {"k": 6, "answer": "Roman Empire", "latency_ms": 1414.4132137298584, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3962}}}
{"qid": "-2991400700385487821", "question": "who heads the executive department of west virginia government", "gold_answers": ["the Governor of West Virginia", "the governor of West Virginia", "Jim Justice"], "shots": {"0": {"k": 0, "answer": "The Governor", "latency_ms": 1330.9781551361084, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The governor", "latency_ms": 2024.996280670166, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "The governor", "latency_ms": 1745.1202869415283, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "The governor", "latency_ms": 751.2083053588867, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2017}, "4": {"k": 4, "answer": "The governor", "latency_ms": 1778.9099216461182, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2661}, "5": {"k": 5, "answer": "The governor", "latency_ms": 1062.4499320983887, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3312}, "6": {"k": 6, "answer": "The governor", "latency_ms": 1296.6744899749756, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3955}}}
{"qid": "-9186689755642837558", "question": "how long is the bridge between new brunswick and prince edward island", "gold_answers": ["12.9 - kilometre"], "shots": {"0": {"k": 0, "answer": "13 kilometers", "latency_ms": 892.3158645629883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2381.7572593688965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 733}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2218.010663986206, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1421}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2404.5135974884033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2090}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1925.417184829712, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2777}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2433.1953525543213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3368}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1675.8625507354736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4029}}}
{"qid": "8029901619424338449", "question": "when did the uk and us become allies", "gold_answers": ["1940", "Since 1940"], "shots": {"0": {"k": 0, "answer": "1778, then 1814, and fully in 1941", "latency_ms": 6493.448495864868, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1958", "latency_ms": 1539.4749641418457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 690}, "2": {"k": 2, "answer": "1958", "latency_ms": 1819.9641704559326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1380}, "3": {"k": 3, "answer": "1958", "latency_ms": 1894.6139812469482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "1958", "latency_ms": 770.5302238464355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2733}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2180.922269821167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3379}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2111.4606857299805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3989}}}
{"qid": "4828649525820722736", "question": "who sang the theme song for the man with the golden gun", "gold_answers": ["Lulu"], "shots": {"0": {"k": 0, "answer": "Lulu", "latency_ms": 569.7288513183594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lulu", "latency_ms": 2065.2294158935547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 641}, "2": {"k": 2, "answer": "Lulu", "latency_ms": 1413.968563079834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1225}, "3": {"k": 3, "answer": "Lulu", "latency_ms": 1069.617748260498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1791}, "4": {"k": 4, "answer": "Lulu", "latency_ms": 2115.325450897217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2446}, "5": {"k": 5, "answer": "Lulu", "latency_ms": 1811.4371299743652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3096}, "6": {"k": 6, "answer": "Lulu", "latency_ms": 1995.3742027282715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3703}}}
{"qid": "-7924663090486742985", "question": "american horror story freak show girl kidnapped by clown", "gold_answers": ["Bonnie Lipton"], "shots": {"0": {"k": 0, "answer": "Pennywise is not correct, the answer is: Twisty.", "latency_ms": 5906.343936920166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Twisty", "latency_ms": 1228.0280590057373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "Dot Tattler", "latency_ms": 2609.407663345337, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Dot Tattler", "latency_ms": 2922.7914810180664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2001}, "4": {"k": 4, "answer": "Dot Tattler", "latency_ms": 1942.5055980682373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2555}, "5": {"k": 5, "answer": "Dot Tattler", "latency_ms": 2943.2621002197266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3231}, "6": {"k": 6, "answer": "Dot Tattler", "latency_ms": 1808.457612991333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3915}}}
{"qid": "-360675773049242516", "question": "the probability of making a type i error when retaining ho at the .05 level of significance is", "gold_answers": ["5 %"], "shots": {"0": {"k": 0, "answer": "0.05", "latency_ms": 2314.397096633911, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "0.05", "latency_ms": 1815.0310516357422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 575}, "2": {"k": 2, "answer": "0%", "latency_ms": 1931.8604469299316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1167}, "3": {"k": 3, "answer": "0.05", "latency_ms": 2356.4794063568115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1759}, "4": {"k": 4, "answer": "0.05", "latency_ms": 1563.530683517456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2325}, "5": {"k": 5, "answer": "0.05", "latency_ms": 1929.7127723693848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2960}, "6": {"k": 6, "answer": "0.05", "latency_ms": 1974.9455451965332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3634}}}
{"qid": "5819386267283467034", "question": "what year did the us hockey team won the olympics", "gold_answers": ["1960", "1980", "1960 and 1980"], "shots": {"0": {"k": 0, "answer": "1980", "latency_ms": 1191.2496089935303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1960, 1980", "latency_ms": 3553.2584190368652, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 659}, "2": {"k": 2, "answer": "1960, 1980", "latency_ms": 2799.7195720672607, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1310}, "3": {"k": 3, "answer": "1960, 1980", "latency_ms": 1776.2959003448486, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1913}, "4": {"k": 4, "answer": "1960, 1980", "latency_ms": 3104.947328567505, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2510}, "5": {"k": 5, "answer": "1960, 1980", "latency_ms": 3688.1461143493652, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3113}, "6": {"k": 6, "answer": "1960, 1980", "latency_ms": 2687.446355819702, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3724}}}
{"qid": "3916394566028297311", "question": "who wrote it's a long long way to pasadena", "gold_answers": ["Harry Vanda", "John Young", "David Hemmings", "George Young"], "shots": {"0": {"k": 0, "answer": "Albert Von Tilzer and Edgar Leslie", "latency_ms": 3732.332229614258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1435.7669353485107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1954.336166381836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1264}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1652.057409286499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1902}, "4": {"k": 4, "answer": "Harry Vanda and George Young and David Hemmings", "latency_ms": 4883.378982543945, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2159.717559814453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2940.959930419922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3739}}}
{"qid": "-2432292250757146771", "question": "who wrote the song i hate you i love you", "gold_answers": ["Angel Benitez", "Olivia O'Brien", "Garrett Nash"], "shots": {"0": {"k": 0, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3132.0080757141113, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2978.4440994262695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "Gnash", "latency_ms": 2129.606246948242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "Gnash", "latency_ms": 2111.112594604492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1831}, "4": {"k": 4, "answer": "Gnash", "latency_ms": 1413.7067794799805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2494}, "5": {"k": 5, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3922.562599182129, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3069}, "6": {"k": 6, "answer": "Gnash and Olivia O'Brien", "latency_ms": 3936.0907077789307, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3643}}}
{"qid": "2393389448844632496", "question": "what is loihi and where does it originate from", "gold_answers": ["from the Hawaii hotspot"], "shots": {"0": {"k": 0, "answer": "Loihi, Hawaii, USA", "latency_ms": 3445.2738761901855, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2980.527639389038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2128.164768218994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1185}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2400.8824825286865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1793}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2710.2625370025635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2440}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2965.53897857666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3027}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1630.2709579467773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3592}}}
{"qid": "-6677440871585683891", "question": "who rebuilt the temple after the babylonian captivity", "gold_answers": ["Herod"], "shots": {"0": {"k": 0, "answer": "Zerubbabel", "latency_ms": 2499.9990463256836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The exiles", "latency_ms": 1906.1329364776611, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "Haggai and Zechariah", "latency_ms": 3574.6524333953857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1201}, "3": {"k": 3, "answer": "Haggai and Zechariah", "latency_ms": 3750.7307529449463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1820}, "4": {"k": 4, "answer": "Haggai and Zechariah", "latency_ms": 3344.3338871002197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2408}, "5": {"k": 5, "answer": "Haggai and Zechariah", "latency_ms": 3190.486431121826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3104}, "6": {"k": 6, "answer": "Haggai and Zechariah", "latency_ms": 3787.0357036590576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3710}}}
{"qid": "-6750750235985613277", "question": "who was executed for being an american spy during the revolutionary war", "gold_answers": ["Nathan Hale"], "shots": {"0": {"k": 0, "answer": "Nathan Hale", "latency_ms": 1804.6479225158691, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Nathan Hale", "latency_ms": 1583.4577083587646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 593}, "2": {"k": 2, "answer": "Nathan Hale", "latency_ms": 2602.4327278137207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1157}, "3": {"k": 3, "answer": "Nathan Hale", "latency_ms": 2326.178789138794, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1739}, "4": {"k": 4, "answer": "Nathan Hale", "latency_ms": 2188.364028930664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2384}, "5": {"k": 5, "answer": "Nathan Hale", "latency_ms": 2051.311731338501, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3008}, "6": {"k": 6, "answer": "Nathan Hale", "latency_ms": 1543.4718132019043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3594}}}
{"qid": "8770209312170080158", "question": "who sang the song suddenly with olivia newton john", "gold_answers": ["Cliff Richard"], "shots": {"0": {"k": 0, "answer": "Cliff Richard", "latency_ms": 1855.3118705749512, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cliff Richard", "latency_ms": 2070.3134536743164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "Cliff Richard", "latency_ms": 1883.6934566497803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1198}, "3": {"k": 3, "answer": "Cliff Richard", "latency_ms": 1876.7166137695312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Cliff Richard", "latency_ms": 1551.5022277832031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2402}, "5": {"k": 5, "answer": "Cliff Richard", "latency_ms": 1333.603858947754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3014}, "6": {"k": 6, "answer": "Cliff Richard", "latency_ms": 1826.82204246521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3672}}}
{"qid": "-180549795106449014", "question": "who is command sergeant major of the army", "gold_answers": ["Daniel A. Dailey"], "shots": {"0": {"k": 0, "answer": "Michael A. Grinston", "latency_ms": 2261.195659637451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1878.2129287719727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2278.7084579467773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2603.147029876709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1901.8385410308838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2453}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1976.2282371520996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3123}, "6": {"k": 6, "answer": "Kenneth Preston", "latency_ms": 2077.364921569824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3732}}}
{"qid": "7815138213728640354", "question": "who sings the original windmills of your mind", "gold_answers": ["Noel Harrison"], "shots": {"0": {"k": 0, "answer": "Noel Harrison", "latency_ms": 2375.5009174346924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1946.5041160583496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "No singer mentioned", "latency_ms": 1623.8315105438232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "No information", "latency_ms": 2317.049026489258, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Noel Harrison", "latency_ms": 1859.1842651367188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2525}, "5": {"k": 5, "answer": "Noel Harrison", "latency_ms": 2223.472833633423, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3206}, "6": {"k": 6, "answer": "Noel Harrison", "latency_ms": 1295.140266418457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3812}}}
{"qid": "2098168902147822379", "question": "where will the next summer and winter olympics be held", "gold_answers": ["Beijing", "Tokyo"], "shots": {"0": {"k": 0, "answer": "Paris 2024 and Milan-Cortina 2026.", "latency_ms": 6515.38872718811, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Beijing", "latency_ms": 2286.2634658813477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 623}, "2": {"k": 2, "answer": "Beijing, Tokyo, Paris, Los Angeles", "latency_ms": 3461.811304092407, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Tokyo, Beijing, Paris, Los Angeles", "latency_ms": 3532.0894718170166, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1863}, "4": {"k": 4, "answer": "Tokyo, Beijing, Paris, Los Angeles", "latency_ms": 3869.0640926361084, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 2534}, "5": {"k": 5, "answer": "Tokyo, Beijing, Paris, Los Angeles", "latency_ms": 3393.3987617492676, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3135}, "6": {"k": 6, "answer": "Tokyo, Beijing, Paris, Los Angeles", "latency_ms": 4222.543954849243, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3784}}}
{"qid": "-1458476052377668874", "question": "when did ole miss beat alabama in football", "gold_answers": ["September 19 , 2015", "October 3 , 1970", "October 27 , 1894", "October 13 , 2001", "October 5 , 1968", "October 4 , 2014", "September 11 , 1976", "October 8 , 1988", "October 18 , 2003", "November 5 , 1910"], "shots": {"0": {"k": 0, "answer": "October 10, 2014", "latency_ms": 3417.3595905303955, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2312.2100830078125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "1988", "latency_ms": 1775.9478092193604, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1246}, "3": {"k": 3, "answer": "1988", "latency_ms": 1830.9507369995117, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "1988, 2015", "latency_ms": 4073.845386505127, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2482}, "5": {"k": 5, "answer": "1988", "latency_ms": 2789.250612258911, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "1988, 2014", "latency_ms": 3663.748025894165, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3801}}}
{"qid": "-6861734002351236912", "question": "who sang the song how far is heaven", "gold_answers": ["Los Lonely Boys"], "shots": {"0": {"k": 0, "answer": "Los Lonely Boys", "latency_ms": 1870.8760738372803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2647.9272842407227, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3011.014938354492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "Carol Sue", "latency_ms": 1681.6742420196533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "Carol Sue", "latency_ms": 1183.4917068481445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Carol Sue", "latency_ms": 1739.2938137054443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3114}, "6": {"k": 6, "answer": "Carol Sue", "latency_ms": 2555.6328296661377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3725}}}
{"qid": "-1722216190521937227", "question": "where are the organ mountains in new mexico", "gold_answers": ["southern New Mexico"], "shots": {"0": {"k": 0, "answer": "Las Cruces", "latency_ms": 2014.2302513122559, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "southern New Mexico", "latency_ms": 1797.257900238037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "southern New Mexico", "latency_ms": 2383.4681510925293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1325}, "3": {"k": 3, "answer": "southern New Mexico", "latency_ms": 1725.1806259155273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1986}, "4": {"k": 4, "answer": "southern New Mexico", "latency_ms": 2881.2239170074463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2643}, "5": {"k": 5, "answer": "southern New Mexico", "latency_ms": 2632.004737854004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3283}, "6": {"k": 6, "answer": "southern New Mexico", "latency_ms": 2661.6666316986084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3880}}}
{"qid": "-2717119588239727064", "question": "where are the 10 plagues found in the bible", "gold_answers": ["Book of Exodus", "Exodus"], "shots": {"0": {"k": 0, "answer": "Exodus 7-12", "latency_ms": 2327.5222778320312, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Book of Exodus", "latency_ms": 2624.279260635376, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Book of Exodus", "latency_ms": 2625.5664825439453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Book of Exodus", "latency_ms": 1794.2874431610107, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1887}, "4": {"k": 4, "answer": "Book of Exodus", "latency_ms": 2080.737352371216, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2506}, "5": {"k": 5, "answer": "Book of Exodus", "latency_ms": 1871.2899684906006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3129}, "6": {"k": 6, "answer": "Book of Exodus", "latency_ms": 2902.0044803619385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3701}}}
{"qid": "2988284357714596500", "question": "where are red blood cells made in adults", "gold_answers": ["in the bone marrow"], "shots": {"0": {"k": 0, "answer": "Bone marrow", "latency_ms": 546.6933250427246, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "red bone marrow", "latency_ms": 2090.3961658477783, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "the red bone marrow", "latency_ms": 2704.446792602539, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "the red bone marrow", "latency_ms": 2745.7282543182373, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1895}, "4": {"k": 4, "answer": "the red bone marrow", "latency_ms": 2713.6006355285645, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2607}, "5": {"k": 5, "answer": "red bone marrow", "latency_ms": 2097.7375507354736, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "the red bone marrow", "latency_ms": 2889.1193866729736, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3840}}}
{"qid": "-4616596799374362422", "question": "who was the pinkerton detective agency's first female detective", "gold_answers": ["Kate Warne"], "shots": {"0": {"k": 0, "answer": "Kate Warne", "latency_ms": 858.0615520477295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kate Warne", "latency_ms": 2787.2848510742188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Kate Warne", "latency_ms": 2143.505573272705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1235}, "3": {"k": 3, "answer": "Kate Warne", "latency_ms": 2366.2896156311035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Kate Warne", "latency_ms": 2218.6925411224365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2539}, "5": {"k": 5, "answer": "Kate Warne", "latency_ms": 1788.5677814483643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3222}, "6": {"k": 6, "answer": "Kate Warne", "latency_ms": 2713.5019302368164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3862}}}
{"qid": "-3650291155113659146", "question": "how many episodes are there in modern family", "gold_answers": ["232", "201"], "shots": {"0": {"k": 0, "answer": "250 episodes", "latency_ms": 1602.1480560302734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "24", "latency_ms": 1236.3760471343994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "24 episodes", "latency_ms": 1779.6425819396973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "24 episodes", "latency_ms": 2059.4465732574463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1855}, "4": {"k": 4, "answer": "24 episodes", "latency_ms": 1745.5062866210938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2500}, "5": {"k": 5, "answer": "24 episodes", "latency_ms": 2087.2349739074707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3178}, "6": {"k": 6, "answer": "24 episodes", "latency_ms": 2290.0643348693848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3805}}}
{"qid": "3381924381590631417", "question": "who built the first temple for god in jerusalem", "gold_answers": ["Solomon"], "shots": {"0": {"k": 0, "answer": "King Solomon", "latency_ms": 1321.2685585021973, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "King Solomon", "latency_ms": 1993.9196109771729, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 661}, "2": {"k": 2, "answer": "King Solomon", "latency_ms": 1772.8023529052734, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1251}, "3": {"k": 3, "answer": "Solomon", "latency_ms": 1817.209005355835, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "King Solomon", "latency_ms": 2244.554042816162, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2508}, "5": {"k": 5, "answer": "King Solomon", "latency_ms": 1815.9980773925781, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3145}, "6": {"k": 6, "answer": "King Solomon", "latency_ms": 2287.6904010772705, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3790}}}
{"qid": "-154783694579651082", "question": "what is a dropped pin on google maps for", "gold_answers": ["marks locations", "marks locations in Google Maps"], "shots": {"0": {"k": 0, "answer": "Saving a location.", "latency_ms": 2502.3558139801025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "marking locations", "latency_ms": 2774.1429805755615, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "to mark a point on a map", "latency_ms": 4403.871536254883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "to mark a point on a map", "latency_ms": 2829.9717903137207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1851}, "4": {"k": 4, "answer": "to mark a point on a map", "latency_ms": 3800.01163482666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "to mark a point on a map", "latency_ms": 3558.6628913879395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3138}, "6": {"k": 6, "answer": "to mark a point on a map", "latency_ms": 3679.034471511841, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3772}}}
{"qid": "6915606477668963399", "question": "what do the 3 dots mean in math", "gold_answers": ["the therefore sign", "therefore sign"], "shots": {"0": {"k": 0, "answer": "Ellipsis", "latency_ms": 2032.846212387085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2674.7782230377197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "Infinitely repeating set of numbers", "latency_ms": 2571.483850479126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Ellipsis", "latency_ms": 1394.4189548492432, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "Ellipsis", "latency_ms": 2546.8239784240723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2407}, "5": {"k": 5, "answer": "Ellipsis", "latency_ms": 1772.322177886963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2985}, "6": {"k": 6, "answer": "Ellipsis", "latency_ms": 2028.4953117370605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3645}}}
{"qid": "-8366545547296627039", "question": "who wrote the song photograph by ringo starr", "gold_answers": ["Richard Starkey", "George Harrison", "Ringo Starr"], "shots": {"0": {"k": 0, "answer": "Ringo Starr and George Harrison.", "latency_ms": 4172.021389007568, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ringo Starr and George Harrison", "latency_ms": 3205.1918506622314, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "Ringo Starr and George Harrison", "latency_ms": 3229.517698287964, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Ringo Starr and George Harrison", "latency_ms": 3753.000259399414, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1968}, "4": {"k": 4, "answer": "Ringo Starr and George Harrison", "latency_ms": 3556.779623031616, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2578}, "5": {"k": 5, "answer": "Ringo Starr and George Harrison", "latency_ms": 3556.8342208862305, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3302}, "6": {"k": 6, "answer": "Ringo Starr and George Harrison", "latency_ms": 2736.99951171875, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3958}}}
{"qid": "-5004457603684974952", "question": "who is playing the halftime show at super bowl 2016", "gold_answers": ["Beyonc√©", "Coldplay", "Bruno Mars"], "shots": {"0": {"k": 0, "answer": "Coldplay", "latency_ms": 1144.0045833587646, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2884.658098220825, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Coldplay", "latency_ms": 1223.7303256988525, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "Coldplay", "latency_ms": 1990.6086921691895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Coldplay", "latency_ms": 1972.1615314483643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2581}, "5": {"k": 5, "answer": "Coldplay", "latency_ms": 1245.6457614898682, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3225}, "6": {"k": 6, "answer": "Coldplay", "latency_ms": 1570.3606605529785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3862}}}
{"qid": "7420920477821898435", "question": "to aru kagaku no railgun s episode 3", "gold_answers": ["Project Radio Noise"], "shots": {"0": {"k": 0, "answer": "Ability and Power", "latency_ms": 1534.6782207489014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2716.188907623291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 545}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2171.919345855713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1150}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3147.426128387451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1753}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2496.9282150268555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2389}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2444.6473121643066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3011}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2682.3318004608154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3631}}}
{"qid": "7478795216476346339", "question": "who won the 2017 sports personality of the year", "gold_answers": ["Mo Farah"], "shots": {"0": {"k": 0, "answer": "Mo Farah", "latency_ms": 1607.0728302001953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2662.400484085083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2491.0402297973633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2912.468194961548, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1960}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2458.9037895202637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2618}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1997.1768856048584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3278}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2075.6618976593018, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3913}}}
{"qid": "7217222058435937287", "question": "where was the world economic forum held this year", "gold_answers": ["Davos"], "shots": {"0": {"k": 0, "answer": "Davos, Switzerland.", "latency_ms": 2452.313184738159, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Davos", "latency_ms": 1875.6017684936523, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 671}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2718.0066108703613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1571.380853652954, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1997}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1859.0278625488281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2673}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1645.7371711730957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3277}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2013.2546424865723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3957}}}
{"qid": "-143054837169120955", "question": "where are the giant redwoods located in california", "gold_answers": ["the coast of northern California", "Del Norte County", "Humboldt County"], "shots": {"0": {"k": 0, "answer": "Northern California.", "latency_ms": 1333.7316513061523, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "western Sierra Nevada", "latency_ms": 1765.7177448272705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 586}, "2": {"k": 2, "answer": "Sierra Nevada", "latency_ms": 2074.979066848755, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "Western Sierra Nevada", "latency_ms": 1773.2269763946533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1869}, "4": {"k": 4, "answer": "San Francisco Bay", "latency_ms": 2045.853614807129, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Western Sierra Nevada, California", "latency_ms": 1999.1481304168701, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3252}, "6": {"k": 6, "answer": "Western Sierra Nevada, California", "latency_ms": 2750.0176429748535, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3893}}}
{"qid": "4892429640540595424", "question": "who has made the most premier league appearances", "gold_answers": ["Gareth Barry"], "shots": {"0": {"k": 0, "answer": "Gareth Barry", "latency_ms": 1547.996997833252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2851.7463207244873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Steven Gerrard", "latency_ms": 2063.9781951904297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Steven Gerrard", "latency_ms": 1767.84086227417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "Steven Gerrard", "latency_ms": 1790.7273769378662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2591}, "5": {"k": 5, "answer": "Steven Gerrard", "latency_ms": 1809.4136714935303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3245}, "6": {"k": 6, "answer": "Steven Gerrard", "latency_ms": 2313.508987426758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3899}}}
{"qid": "5533906981191706877", "question": "who was the first chief minister of west bengal", "gold_answers": ["Prafulla Chandra Ghosh"], "shots": {"0": {"k": 0, "answer": "Prafulla Chandra Ghosh", "latency_ms": 2685.9517097473145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Prafulla Chandra Ghosh", "latency_ms": 4481.621265411377, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Prafulla Chandra Ghosh", "latency_ms": 4496.989727020264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1347}, "3": {"k": 3, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3350.9013652801514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1993}, "4": {"k": 4, "answer": "Prafulla Chandra Ghosh", "latency_ms": 2980.7255268096924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2708}, "5": {"k": 5, "answer": "Prafulla Chandra Ghosh", "latency_ms": 3686.680316925049, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3304}, "6": {"k": 6, "answer": "Prafulla Chandra Ghosh", "latency_ms": 5186.036109924316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3964}}}
{"qid": "8823076125131408628", "question": "who sings got my mind set on you", "gold_answers": ["George Harrison", "James Ray"], "shots": {"0": {"k": 0, "answer": "George Harrison", "latency_ms": 2365.274667739868, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Ray and George Harrison", "latency_ms": 2413.816213607788, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 541}, "2": {"k": 2, "answer": "James Ray and George Harrison", "latency_ms": 3455.9326171875, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1183}, "3": {"k": 3, "answer": "James Ray, George Harrison", "latency_ms": 3712.9058837890625, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1740}, "4": {"k": 4, "answer": "James Ray, George Harrison", "latency_ms": 3194.9517726898193, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2301}, "5": {"k": 5, "answer": "James Ray, George Harrison", "latency_ms": 2693.619966506958, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2861}, "6": {"k": 6, "answer": "James Ray, George Harrison", "latency_ms": 2460.0179195404053, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3406}}}
{"qid": "9168660859139861094", "question": "two main types of research methods used in psychology", "gold_answers": ["Correlational research", "Descriptive research", "quantitative data", "Quantitative psychological research", "qualitative", "quantitative", "Qualitative psychological research", "Experimental research", "qualitative data"], "shots": {"0": {"k": 0, "answer": "Qualitative and Quantitative.", "latency_ms": 3194.491147994995, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Experimental Methods", "latency_ms": 2013.6301517486572, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 822}, "2": {"k": 2, "answer": "Qualitative and Quantitative", "latency_ms": 3439.6045207977295, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1631}, "3": {"k": 3, "answer": "Qualitative and Quantitative", "latency_ms": 2911.63969039917, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2337}, "4": {"k": 4, "answer": "Qualitative or quantitative", "latency_ms": 1657.8292846679688, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3074}, "5": {"k": 5, "answer": "Qualitative or quantitative", "latency_ms": 2205.470561981201, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3821}, "6": {"k": 6, "answer": "Qualitative or quantitative", "latency_ms": 2364.945411682129, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4624}}}
{"qid": "-7073063191952855764", "question": "who plays peter in what we do in the shadows", "gold_answers": ["Ben Fransham"], "shots": {"0": {"k": 0, "answer": "Kayvan Novak", "latency_ms": 2432.636499404907, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2713.332176208496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 637}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2968.6942100524902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1223}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2985.9626293182373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1881}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1696.4921951293945, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2480}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2404.024124145508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2887.4049186706543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3743}}}
{"qid": "7901746249864619718", "question": "when does the 14th season of grey's anatomy come out", "gold_answers": ["September 28 , 2017"], "shots": {"0": {"k": 0, "answer": "September 28, 2017", "latency_ms": 3116.9936656951904, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 28, 2017", "latency_ms": 3431.8294525146484, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 28, 2017", "latency_ms": 3067.8155422210693, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1327}, "3": {"k": 3, "answer": "September 28, 2017", "latency_ms": 2621.2151050567627, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 28, 2017", "latency_ms": 4069.17142868042, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2678}, "5": {"k": 5, "answer": "September 28, 2017", "latency_ms": 3236.9942665100098, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3346}, "6": {"k": 6, "answer": "September 28, 2017", "latency_ms": 2840.157985687256, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3933}}}
{"qid": "-896127746191949637", "question": "when was the first hunger games book published", "gold_answers": ["September 14 , 2008", "2008"], "shots": {"0": {"k": 0, "answer": "2008", "latency_ms": 1780.5516719818115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 14, 2008", "latency_ms": 3282.271146774292, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "September 14, 2008", "latency_ms": 2946.251630783081, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1322}, "3": {"k": 3, "answer": "September 14, 2008", "latency_ms": 3119.3928718566895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1939}, "4": {"k": 4, "answer": "September 14, 2008", "latency_ms": 3793.280839920044, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2563}, "5": {"k": 5, "answer": "September 14, 2008", "latency_ms": 3175.203561782837, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3225}, "6": {"k": 6, "answer": "September 14, 2008", "latency_ms": 4694.608926773071, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3854}}}
{"qid": "8044909700499569711", "question": "how much is the united states in debt to china", "gold_answers": ["$1.06 trillion", "1,200.5"], "shots": {"0": {"k": 0, "answer": "$1.08 trillion", "latency_ms": 1564.7680759429932, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$1.16 trillion", "latency_ms": 2822.5455284118652, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "$1.16 trillion", "latency_ms": 3338.3655548095703, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "$1.16 trillion", "latency_ms": 2544.21067237854, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "$1.16 trillion", "latency_ms": 2798.4883785247803, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2582}, "5": {"k": 5, "answer": "$1.18 trillion", "latency_ms": 2974.924087524414, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3235}, "6": {"k": 6, "answer": "$1.18 trillion", "latency_ms": 3243.67356300354, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3867}}}
{"qid": "-3123234845590594961", "question": "where did the race in grease take place", "gold_answers": ["Thunder Road"], "shots": {"0": {"k": 0, "answer": "The Thunder Road race track", "latency_ms": 2243.215799331665, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Los Angeles River", "latency_ms": 2311.4020824432373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Los Angeles River", "latency_ms": 1333.141803741455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "Los Angeles River", "latency_ms": 2059.9329471588135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1824}, "4": {"k": 4, "answer": "Los Angeles River", "latency_ms": 2258.883476257324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2445}, "5": {"k": 5, "answer": "Los Angeles River", "latency_ms": 1844.3667888641357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3143}, "6": {"k": 6, "answer": "Los Angeles River", "latency_ms": 1567.967176437378, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3762}}}
{"qid": "4326992806019599297", "question": "what is the maximum data rate for the 802.11a standard select one", "gold_answers": ["54 Mbit / s"], "shots": {"0": {"k": 0, "answer": "54 Mbps", "latency_ms": 2023.2558250427246, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "54 Mbit/s", "latency_ms": 1525.040864944458, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 628}, "2": {"k": 2, "answer": "54 Mbit/s", "latency_ms": 2391.404628753662, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "54 Mbit/s", "latency_ms": 2417.5853729248047, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1950}, "4": {"k": 4, "answer": "54 Mbit/s", "latency_ms": 1882.3215961456299, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2612}, "5": {"k": 5, "answer": "54 Mbit/s", "latency_ms": 2409.6498489379883, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3234}, "6": {"k": 6, "answer": "54 Mbit/s", "latency_ms": 2733.7286472320557, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3856}}}
{"qid": "6144099837933283715", "question": "a good that can be used in place of another good", "gold_answers": ["A substitute good", "substitute good"], "shots": {"0": {"k": 0, "answer": "Substitute", "latency_ms": 2085.130453109741, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Substitute good", "latency_ms": 1834.0771198272705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 558}, "2": {"k": 2, "answer": "Substitute good", "latency_ms": 2043.8077449798584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1155}, "3": {"k": 3, "answer": "Substitute good", "latency_ms": 1768.3255672454834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1734}, "4": {"k": 4, "answer": "Substitute good", "latency_ms": 1830.5344581604004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2319}, "5": {"k": 5, "answer": "Substitute good", "latency_ms": 2080.0621509552, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2925}, "6": {"k": 6, "answer": "Substitute good", "latency_ms": 1791.2859916687012, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3488}}}
{"qid": "-4621948696356225060", "question": "where in the bible can i find the lord's prayer", "gold_answers": ["the Gospel of Luke", "the Gospel of Matthew"], "shots": {"0": {"k": 0, "answer": "Matthew 6:9-13, Luke 11:2-4", "latency_ms": 6183.473110198975, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Gospel of Matthew and Gospel of Luke", "latency_ms": 3166.7628288269043, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "Gospel of Matthew and Gospel of Luke", "latency_ms": 4007.5228214263916, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Gospel of Matthew and Gospel of Luke", "latency_ms": 3357.5267791748047, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Gospel of Matthew and Luke", "latency_ms": 2654.84356880188, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "Gospel of Matthew and Luke", "latency_ms": 2371.1650371551514, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 3166}, "6": {"k": 6, "answer": "Gospel of Matthew and Luke", "latency_ms": 2627.453565597534, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 3854}}}
{"qid": "6941993254369956277", "question": "when was the last time nebraska voted democrat", "gold_answers": ["1964"], "shots": {"0": {"k": 0, "answer": "1964", "latency_ms": 1459.6061706542969, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2066.483736038208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 704}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2281.5890312194824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1415}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2367.1743869781494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2030}, "4": {"k": 4, "answer": "1936", "latency_ms": 2025.7110595703125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2724}, "5": {"k": 5, "answer": "1936", "latency_ms": 510.6039047241211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3450}, "6": {"k": 6, "answer": "1936", "latency_ms": 2249.0146160125732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4148}}}
{"qid": "-8955197065025093046", "question": "who become the ceo of it wipro company in 2016", "gold_answers": ["Abid Ali Neemuchwala"], "shots": {"0": {"k": 0, "answer": "Abidali Neemuchwala", "latency_ms": 3451.8496990203857, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Abidali Neemuchwala", "latency_ms": 4604.508876800537, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Abidali Neemuchwala", "latency_ms": 3796.436548233032, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1363}, "3": {"k": 3, "answer": "Abidali Neemuchwala", "latency_ms": 3508.175849914551, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1991}, "4": {"k": 4, "answer": "Abidali Neemuchwala", "latency_ms": 4390.663623809814, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2672}, "5": {"k": 5, "answer": "Abidali Neemuchwala", "latency_ms": 3770.653009414673, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3266}, "6": {"k": 6, "answer": "Abidali Neemuchwala", "latency_ms": 3909.4250202178955, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3932}}}
{"qid": "-3010425579521817304", "question": "who does eric end up with in gossip girl", "gold_answers": ["Jenny"], "shots": {"0": {"k": 0, "answer": "Vanessa, then ultimately Serena", "latency_ms": 3189.4025802612305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2967.0283794403076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2703.296184539795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1198}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2490.339756011963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1856}, "4": {"k": 4, "answer": "Damien", "latency_ms": 1684.7867965698242, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2421}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2603.8267612457275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2996}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3255.6960582733154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3619}}}
{"qid": "7264112453286983469", "question": "who plays unis in she's the man", "gold_answers": ["Emily Perkins"], "shots": {"0": {"k": 0, "answer": "Amanda Bynes", "latency_ms": 2608.745813369751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amanda Bynes", "latency_ms": 3017.0912742614746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 611}, "2": {"k": 2, "answer": "Amanda Bynes", "latency_ms": 2879.4448375701904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1226}, "3": {"k": 3, "answer": "Amanda Bynes", "latency_ms": 2938.5204315185547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Amanda Bynes", "latency_ms": 2631.0253143310547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2505.3322315216064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3167}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2160.1667404174805, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3791}}}
{"qid": "2627695648792729859", "question": "who played booster in jingle all the way", "gold_answers": ["Curtis Armstrong"], "shots": {"0": {"k": 0, "answer": "Eric Lloyd", "latency_ms": 1462.479829788208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2810.9638690948486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2593.3234691619873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1329}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2620.1350688934326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2446.211576461792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2520}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2155.1172733306885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3209}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2311.2423419952393, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3890}}}
{"qid": "-9169976182548289414", "question": "who is recognized as the founder of islam", "gold_answers": ["the Islamic prophet Muhammad", "Muhammad"], "shots": {"0": {"k": 0, "answer": "Muhammad", "latency_ms": 1015.1944160461426, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Muhammad", "latency_ms": 1720.4198837280273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 606}, "2": {"k": 2, "answer": "Muhammad", "latency_ms": 1751.3902187347412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Muhammad", "latency_ms": 1862.6892566680908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1839}, "4": {"k": 4, "answer": "Muhammad", "latency_ms": 1763.2484436035156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2416}, "5": {"k": 5, "answer": "Muhammad", "latency_ms": 2045.3312397003174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3074}, "6": {"k": 6, "answer": "Muhammad", "latency_ms": 1488.7733459472656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3627}}}
{"qid": "-6696747560626271522", "question": "who plays emma in air bud world pup", "gold_answers": ["Brittany Paige Bouck"], "shots": {"0": {"k": 0, "answer": "Brittany Paige Bouck", "latency_ms": 2549.5901107788086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1856.6155433654785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2680.0858974456787, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2373.9469051361084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2474.9343395233154, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2574}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1673.6621856689453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3201}, "6": {"k": 6, "answer": "Chantal Strand", "latency_ms": 2979.732036590576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3800}}}
{"qid": "5871681964137793716", "question": "how old was sasuke when his clan died", "gold_answers": ["seven"], "shots": {"0": {"k": 0, "answer": "7 years old", "latency_ms": 722.836971282959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2662.6527309417725, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3137.1734142303467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2388.50474357605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3197.8535652160645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1942.584753036499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3056}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1997.0345497131348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3674}}}
{"qid": "8552176802923865025", "question": "where do some of the natural air pollutants come from", "gold_answers": ["wildfires", "Dust", "Vegetation", "Carbon dioxide", "Volcanic activity"], "shots": {"0": {"k": 0, "answer": "Volcanic eruptions.", "latency_ms": 2849.170684814453, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "sea spray, volcanic ash, and meteoroids", "latency_ms": 4202.6917934417725, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 683}, "2": {"k": 2, "answer": "sea spray, volcanic ash, and meteoroids", "latency_ms": 5200.111389160156, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "Sea spray, volcanic ash, and meteoroids.", "latency_ms": 4586.904048919678, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 2089}, "4": {"k": 4, "answer": "sea spray, volcanic ash, dust, pollen and spores", "latency_ms": 5059.89670753479, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2789}, "5": {"k": 5, "answer": "sea spray, volcanic ash, dust, pollen and spores, and meteoroids.", "latency_ms": 6806.114673614502, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 3467}, "6": {"k": 6, "answer": "sea spray, volcanic ash, dust, pollen and spores", "latency_ms": 6333.09006690979, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 4184}}}
{"qid": "-2630525064809360052", "question": "who is the pastor of new birth missionary baptist church now", "gold_answers": ["Stephen A. Davis"], "shots": {"0": {"k": 0, "answer": "Jamal Harrison Bryant", "latency_ms": 2226.3290882110596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pastor Bryant", "latency_ms": 1594.0544605255127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "Jamal Bryant", "latency_ms": 1800.6629943847656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1353}, "3": {"k": 3, "answer": "Jamal Bryant", "latency_ms": 2075.6490230560303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2018}, "4": {"k": 4, "answer": "Jamal Bryant", "latency_ms": 1720.76416015625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2655}, "5": {"k": 5, "answer": "Jamal Bryant", "latency_ms": 1287.7581119537354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3328}, "6": {"k": 6, "answer": "Jamal Bryant", "latency_ms": 1852.1475791931152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3991}}}
{"qid": "6434931911289860123", "question": "who is doing 2018 super bowl half time show", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "Justin Timberlake", "latency_ms": 1825.9615898132324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Timberlake", "latency_ms": 1842.5352573394775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "Justin Timberlake", "latency_ms": 1897.7041244506836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1298}, "3": {"k": 3, "answer": "Justin Timberlake", "latency_ms": 2306.0178756713867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1921}, "4": {"k": 4, "answer": "Justin Timberlake", "latency_ms": 1576.3158798217773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2525}, "5": {"k": 5, "answer": "Justin Timberlake", "latency_ms": 1607.9087257385254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3123}, "6": {"k": 6, "answer": "Justin Timberlake", "latency_ms": 2112.1039390563965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3739}}}
{"qid": "8869318258439148973", "question": "who is playing the halftime show for the superbowl", "gold_answers": ["Justin Timberlake"], "shots": {"0": {"k": 0, "answer": "Rihanna", "latency_ms": 1852.3259162902832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Justin Timberlake", "latency_ms": 2443.570137023926, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 658}, "2": {"k": 2, "answer": "Justin Timberlake", "latency_ms": 2351.552724838257, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "Maroon 5", "latency_ms": 2325.629949569702, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1943}, "4": {"k": 4, "answer": "Justin Timberlake", "latency_ms": 1320.6367492675781, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2587}, "5": {"k": 5, "answer": "Justin Timberlake", "latency_ms": 1899.2564678192139, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3213}, "6": {"k": 6, "answer": "Justin Timberlake", "latency_ms": 2100.118398666382, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3847}}}
{"qid": "-8359866474144720253", "question": "who hosted they think it's all over", "gold_answers": ["Des Lynam", "Lee Mack", "comedian Nick Hancock", "Nick Hancock"], "shots": {"0": {"k": 0, "answer": "Nick Hancock", "latency_ms": 770.888090133667, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Des Lynam", "latency_ms": 2077.3377418518066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Nick Hancock", "latency_ms": 1019.3533897399902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Nick Hancock, Lee Mack", "latency_ms": 2031.9085121154785, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1941}, "4": {"k": 4, "answer": "Nick Hancock, Lee Mack", "latency_ms": 2768.413782119751, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2580}, "5": {"k": 5, "answer": "Nick Hancock", "latency_ms": 1691.3328170776367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3198}, "6": {"k": 6, "answer": "Nick Hancock, Lee Mack", "latency_ms": 2197.885036468506, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3840}}}
{"qid": "-1206653570097564556", "question": "where does the movie proof of life take place", "gold_answers": ["The Republic of Tecala"], "shots": {"0": {"k": 0, "answer": "South America", "latency_ms": 1494.9965476989746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tecala", "latency_ms": 1906.8880081176758, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "The Republic of Tecala", "latency_ms": 2175.1086711883545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Tecala", "latency_ms": 1739.8557662963867, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "The Republic of Tecala", "latency_ms": 2692.7878856658936, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2507}, "5": {"k": 5, "answer": "Tecala, a fictional South American country", "latency_ms": 3188.8644695281982, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3105}, "6": {"k": 6, "answer": "Tecala, a fictional South American country", "latency_ms": 2685.955047607422, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3756}}}
{"qid": "6144521615402262404", "question": "where does us highway 1 start and end", "gold_answers": ["Fort Kent , Maine", "to Key West , Florida", "Key West , Florida"], "shots": {"0": {"k": 0, "answer": "Fort Kent, Maine to Key West, Florida", "latency_ms": 4305.62686920166, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Key West, Florida to Fort Kent, Maine", "latency_ms": 3409.221887588501, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Key West, Florida to Fort Kent, Maine", "latency_ms": 4478.4095287323, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Key West, Florida to Fort Kent, Maine", "latency_ms": 4491.805076599121, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "Key West, Florida to Fort Kent, Maine", "latency_ms": 4481.247425079346, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 2478}, "5": {"k": 5, "answer": "Key West, Florida to Fort Kent, Maine", "latency_ms": 4007.7009201049805, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Key West, Florida to Fort Kent, Maine", "latency_ms": 4114.405632019043, "em": 0.0, "f1": 0.7272727272727273, "containment": 0.0, "context_chars": 3736}}}
{"qid": "-8631190913794477985", "question": "who scored the most points in a single game in the nba", "gold_answers": ["Wilt Chamberlain"], "shots": {"0": {"k": 0, "answer": "Wilt Chamberlain, 100 points", "latency_ms": 2671.7653274536133, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Wilt Chamberlain", "latency_ms": 2208.510637283325, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "Wilt Chamberlain", "latency_ms": 2734.3170642852783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Wilt Chamberlain", "latency_ms": 2416.278839111328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1844}, "4": {"k": 4, "answer": "Wilt Chamberlain", "latency_ms": 2489.0382289886475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2476}, "5": {"k": 5, "answer": "Wilt Chamberlain", "latency_ms": 2154.6218395233154, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3127}, "6": {"k": 6, "answer": "Wilt Chamberlain", "latency_ms": 2410.243272781372, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3734}}}
{"qid": "199896377614951764", "question": "where is natural gas found in the us", "gold_answers": ["Texas", "Pennsylvania", "Colorado", "New Mexico", "West Virginia", "Arkansas", "Wyoming", "Louisiana"], "shots": {"0": {"k": 0, "answer": "Texas, Oklahoma, Louisiana, Alaska, and Pennsylvania.", "latency_ms": 6121.604204177856, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pennsylvania", "latency_ms": 2072.019577026367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Pennsylvania", "latency_ms": 1818.2015419006348, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Texas, Pennsylvania, Louisiana", "latency_ms": 3333.946466445923, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1972}, "4": {"k": 4, "answer": "Texas, Pennsylvania, Louisiana, Michigan", "latency_ms": 3807.7492713928223, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2588}, "5": {"k": 5, "answer": "Texas, Pennsylvania, Louisiana", "latency_ms": 2472.282886505127, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3279}, "6": {"k": 6, "answer": "Texas, Pennsylvania, Louisiana", "latency_ms": 3447.315216064453, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3926}}}
{"qid": "8986775680996674901", "question": "when were the first general elections held in independent india", "gold_answers": ["1951 -- 52"], "shots": {"0": {"k": 0, "answer": "1951-52", "latency_ms": 2352.1478176116943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 5775.049209594727, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 4061.342477798462, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 5492.318153381348, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 1974}, "4": {"k": 4, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 5435.338735580444, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2660}, "5": {"k": 5, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 5000.9026527404785, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 3335}, "6": {"k": 6, "answer": "25 October 1951 and 21 February 1952", "latency_ms": 5502.268314361572, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 4052}}}
{"qid": "700604097171850168", "question": "what was the tower of london originally used for", "gold_answers": ["as a royal residence", "a royal residence"], "shots": {"0": {"k": 0, "answer": "Royal Palace and Fortress", "latency_ms": 2475.1596450805664, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Royal residence", "latency_ms": 2106.8942546844482, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "royal residence", "latency_ms": 1347.3150730133057, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "royal residence", "latency_ms": 2077.643394470215, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "royal residence", "latency_ms": 2038.9678478240967, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "royal residence", "latency_ms": 2312.9565715789795, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3153}, "6": {"k": 6, "answer": "royal residence", "latency_ms": 1807.1942329406738, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3775}}}
{"qid": "6745303307988470742", "question": "what type of fuel goes in a zippo", "gold_answers": ["butane", "lighter fluid"], "shots": {"0": {"k": 0, "answer": "Lighter fluid", "latency_ms": 1816.5998458862305, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 5946.006536483765, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 5572.41153717041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1227}, "3": {"k": 3, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 4861.014842987061, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1804}, "4": {"k": 4, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 5081.250429153442, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2397}, "5": {"k": 5, "answer": "Light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 5928.332805633545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3053}, "6": {"k": 6, "answer": "light petroleum distillate or synthetic isoparaffinic hydrocarbon", "latency_ms": 5590.652227401733, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3645}}}
{"qid": "-2060506905455252030", "question": "first jnanpith award was an autor of which language", "gold_answers": ["Malayalam"], "shots": {"0": {"k": 0, "answer": "Gujarati", "latency_ms": 1675.3323078155518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Malayalam", "latency_ms": 1841.4666652679443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 669}, "2": {"k": 2, "answer": "Malayalam", "latency_ms": 1479.6278476715088, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1332}, "3": {"k": 3, "answer": "Malayalam", "latency_ms": 1651.951551437378, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1980}, "4": {"k": 4, "answer": "Malayalam", "latency_ms": 2140.377998352051, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2644}, "5": {"k": 5, "answer": "Malayalam", "latency_ms": 1112.8125190734863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3321}, "6": {"k": 6, "answer": "Malayalam", "latency_ms": 2048.6671924591064, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3961}}}
{"qid": "4738663028303377024", "question": "who played the mad hatter in the batman tv show", "gold_answers": ["Roddy McDowall", "David Wayne", "Benedict Samuel"], "shots": {"0": {"k": 0, "answer": "David Wayne", "latency_ms": 1267.1728134155273, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1877.0277500152588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2243.574619293213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1250}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2236.9701862335205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1858.5259914398193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2562}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1989.4988536834717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2234.560251235962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3887}}}
{"qid": "-1650946015201779846", "question": "how many cracker barrels in the united states", "gold_answers": ["639", "more than 600"], "shots": {"0": {"k": 0, "answer": "664 locations", "latency_ms": 1340.7142162322998, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "314", "latency_ms": 682.3141574859619, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "645 stores in 44 states", "latency_ms": 3578.9568424224854, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1280}, "3": {"k": 3, "answer": "645 stores in 44 states", "latency_ms": 2854.740619659424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "645 stores in 44 states", "latency_ms": 3170.550584793091, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2581}, "5": {"k": 5, "answer": "645 stores in 44 states", "latency_ms": 3644.972801208496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3236}, "6": {"k": 6, "answer": "645 stores in 44 states", "latency_ms": 2853.8918495178223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3882}}}
{"qid": "-3422350952909582054", "question": "in photosynthesis the carbon in co2 is initially fixed to what molecule", "gold_answers": ["3 - phosphoglycerate"], "shots": {"0": {"k": 0, "answer": "RuBP (Ribulose-1,5-Bisphosphate)", "latency_ms": 5047.7423667907715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 5378.81326675415, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 712}, "2": {"k": 2, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 4783.849716186523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1383}, "3": {"k": 3, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 4473.186016082764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2086}, "4": {"k": 4, "answer": "Phosphoenolpyruvate (PEP)", "latency_ms": 5624.414443969727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2731}, "5": {"k": 5, "answer": "Phosphoenolpyruvate (PEP)", "latency_ms": 5302.509784698486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3457}, "6": {"k": 6, "answer": "phosphoenolpyruvate (PEP)", "latency_ms": 5106.233358383179, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4116}}}
{"qid": "-2704708103393811482", "question": "who voices randy in f is for family", "gold_answers": ["T.J. Miller"], "shots": {"0": {"k": 0, "answer": "Bill Burr", "latency_ms": 1544.4097518920898, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1898.7910747528076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Haley Reinhart", "latency_ms": 2968.647003173828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2675.2729415893555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2437.716484069824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2574}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2462.5091552734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2437.0639324188232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3833}}}
{"qid": "5482012214308896475", "question": "how many countries does cadbury sell its products", "gold_answers": ["more than 50", "more than 50 countries worldwide"], "shots": {"0": {"k": 0, "answer": "160 countries", "latency_ms": 1545.9866523742676, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "30", "latency_ms": 899.298906326294, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "More than 50 countries", "latency_ms": 2791.896343231201, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 1360}, "3": {"k": 3, "answer": "More than 50 countries", "latency_ms": 1921.1177825927734, "em": 0.0, "f1": 0.888888888888889, "containment": 1.0, "context_chars": 1983}, "4": {"k": 4, "answer": "50 countries worldwide", "latency_ms": 2799.7047901153564, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 2682}, "5": {"k": 5, "answer": "50 countries worldwide", "latency_ms": 1868.0534362792969, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 3410}, "6": {"k": 6, "answer": "50 countries worldwide", "latency_ms": 1052.558183670044, "em": 0.0, "f1": 0.7499999999999999, "containment": 0.0, "context_chars": 4035}}}
{"qid": "-5737509619250561344", "question": "ethiopia flight 961 crashes in to the sea", "gold_answers": ["23 November 1996"], "shots": {"0": {"k": 0, "answer": "November 23, 1996", "latency_ms": 3959.2864513397217, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indian Ocean", "latency_ms": 2086.1480236053467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Indian Ocean", "latency_ms": 2060.178279876709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "Indian Ocean", "latency_ms": 2036.7720127105713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2016}, "4": {"k": 4, "answer": "Indian Ocean", "latency_ms": 2021.9495296478271, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2677}, "5": {"k": 5, "answer": "Indian Ocean", "latency_ms": 1801.7966747283936, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3382}, "6": {"k": 6, "answer": "Indian Ocean", "latency_ms": 2595.0896739959717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4019}}}
{"qid": "-7175456993713717070", "question": "what does istj mean in a personality test", "gold_answers": ["Extroverted Thinking ( Te )", "Extroverted Intuition ( Ne )", "Introverted Feeling ( Fi )", "Introverted Sensing ( Si )"], "shots": {"0": {"k": 0, "answer": "Introverted, Sensing, Thinking, Judging.", "latency_ms": 5231.2586307525635, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4561.492681503296, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 724}, "2": {"k": 2, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4467.52405166626, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1424}, "3": {"k": 3, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 5399.115562438965, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2085}, "4": {"k": 4, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4177.482604980469, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2796}, "5": {"k": 5, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 3615.0968074798584, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3424}, "6": {"k": 6, "answer": "Introversion, Sensing, Thinking, Judgment", "latency_ms": 4556.100130081177, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4117}}}
{"qid": "4437170343606050664", "question": "who does the voice of ash in sing", "gold_answers": ["Scarlett Johansson"], "shots": {"0": {"k": 0, "answer": "Scarlett Johansson", "latency_ms": 2713.756799697876, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Scarlett Johansson", "latency_ms": 2711.1167907714844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 688}, "2": {"k": 2, "answer": "Scarlett Johansson", "latency_ms": 1495.3725337982178, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1401}, "3": {"k": 3, "answer": "Scarlett Johansson", "latency_ms": 1881.0245990753174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2049}, "4": {"k": 4, "answer": "Scarlett Johansson", "latency_ms": 2398.1361389160156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2716}, "5": {"k": 5, "answer": "Scarlett Johansson", "latency_ms": 2250.1816749572754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3372}, "6": {"k": 6, "answer": "Scarlett Johansson", "latency_ms": 2137.573719024658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4036}}}
{"qid": "-8773010039077552394", "question": "who scored the most points in their nba career", "gold_answers": ["Kareem Abdul - Jabbar"], "shots": {"0": {"k": 0, "answer": "LeBron James", "latency_ms": 2590.2445316314697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2721.8761444091797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2620.8019256591797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1159}, "3": {"k": 3, "answer": "Michael Jordan", "latency_ms": 1738.9159202575684, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1778}, "4": {"k": 4, "answer": "Kareem Abdul-Jabbar", "latency_ms": 3274.832248687744, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2390}, "5": {"k": 5, "answer": "Kareem Abdul-Jabbar", "latency_ms": 3544.53706741333, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3031}, "6": {"k": 6, "answer": "Kareem Abdul-Jabbar", "latency_ms": 3653.5749435424805, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3682}}}
{"qid": "-3278224144622911032", "question": "with a land area of 54 314 square miles where does wisconsin rank among the 50 states", "gold_answers": ["25"], "shots": {"0": {"k": 0, "answer": "23rd", "latency_ms": 1302.7093410491943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "23rd", "latency_ms": 753.7164688110352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "23rd", "latency_ms": 2048.0241775512695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "23rd", "latency_ms": 2025.0921249389648, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1868}, "4": {"k": 4, "answer": "23rd", "latency_ms": 1056.7936897277832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2468}, "5": {"k": 5, "answer": "23rd", "latency_ms": 2084.232807159424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3106}, "6": {"k": 6, "answer": "23rd", "latency_ms": 1328.606128692627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3695}}}
{"qid": "-3466298422174960041", "question": "who plays charles on have and have nots", "gold_answers": ["Nick Sager", "Nick Sagar"], "shots": {"0": {"k": 0, "answer": "Ren√©e Lawless", "latency_ms": 2722.8243350982666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1915.4579639434814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2665.8473014831543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1294}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1929.7459125518799, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2629.936456680298, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2554}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1965.681552886963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3251}, "6": {"k": 6, "answer": "Gavin Houston", "latency_ms": 2134.8602771759033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3895}}}
{"qid": "1803248910342766083", "question": "who wrote the book my country my life", "gold_answers": ["L.K. Advani"], "shots": {"0": {"k": 0, "answer": "L.K. Advani", "latency_ms": 2255.2413940429688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2664.172410964966, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "L. K. Advani", "latency_ms": 3210.601806640625, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1208}, "3": {"k": 3, "answer": "L. K. Advani", "latency_ms": 3509.9875926971436, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1849}, "4": {"k": 4, "answer": "L. K. Advani", "latency_ms": 2568.6004161834717, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2485}, "5": {"k": 5, "answer": "L. K. Advani", "latency_ms": 3379.518985748291, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3149}, "6": {"k": 6, "answer": "L. K. Advani", "latency_ms": 3929.4068813323975, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "-1176280233636154422", "question": "when did the east india company take control of india", "gold_answers": ["1757", "1799", "1612", "in 1757"], "shots": {"0": {"k": 0, "answer": "1757", "latency_ms": 1025.4347324371338, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2985.145092010498, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 642}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3150.43568611145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "By 1818", "latency_ms": 2755.6071281433105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1936}, "4": {"k": 4, "answer": "1757", "latency_ms": 2045.4521179199219, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2585}, "5": {"k": 5, "answer": "1757", "latency_ms": 1091.4034843444824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3255}, "6": {"k": 6, "answer": "1757", "latency_ms": 1541.7566299438477, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3891}}}
{"qid": "5911119091653953181", "question": "where does the water come from to fill lake eyre", "gold_answers": ["Warburton River"], "shots": {"0": {"k": 0, "answer": "Cooper Creek and Diamantina River", "latency_ms": 4466.160297393799, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The north-east part of the Lake Eyre Basin", "latency_ms": 5891.207933425903, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "The north-east part of the Lake Eyre Basin", "latency_ms": 5641.682147979736, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "The north-east part of the Lake Eyre Basin", "latency_ms": 5615.479230880737, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1850}, "4": {"k": 4, "answer": "The north-east part of the Lake Eyre Basin", "latency_ms": 4301.145315170288, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2432}, "5": {"k": 5, "answer": "The north-east part of the Lake Eyre Basin", "latency_ms": 5306.168794631958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3014}, "6": {"k": 6, "answer": "The north-east part of the Lake Eyre Basin", "latency_ms": 5502.605438232422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3635}}}
{"qid": "5557104327881436095", "question": "who is the founder of google and when was it founded", "gold_answers": ["1998", "Sergey Brin", "Larry Page and Sergey Brin", "Larry Page"], "shots": {"0": {"k": 0, "answer": "Larry Page and Sergey Brin, September 4, 1998", "latency_ms": 4902.355194091797, "em": 0.0, "f1": 0.7692307692307694, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3181.4990043640137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 4612.269878387451, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 1340}, "3": {"k": 3, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 5161.430835723877, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 1980}, "4": {"k": 4, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 3671.2570190429688, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 2647}, "5": {"k": 5, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 4159.578084945679, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 3327}, "6": {"k": 6, "answer": "Larry Page and Sergey Brin, 1998", "latency_ms": 4664.11280632019, "em": 0.0, "f1": 0.9090909090909091, "containment": 1.0, "context_chars": 3983}}}
{"qid": "-1333328812971005142", "question": "who did the dominican republic gain its independence from", "gold_answers": ["Haiti"], "shots": {"0": {"k": 0, "answer": "Haiti", "latency_ms": 1568.922758102417, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spain and Haiti", "latency_ms": 1447.5202560424805, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 667}, "2": {"k": 2, "answer": "Haiti and Spain", "latency_ms": 2626.4443397521973, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1304}, "3": {"k": 3, "answer": "Haiti and Spain", "latency_ms": 2516.4437294006348, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1938}, "4": {"k": 4, "answer": "Haiti and Spain", "latency_ms": 2986.806631088257, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2613}, "5": {"k": 5, "answer": "Haiti and Spain", "latency_ms": 2496.1204528808594, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3260}, "6": {"k": 6, "answer": "Haiti and Spain", "latency_ms": 3091.9623374938965, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3974}}}
{"qid": "1122605495295045742", "question": "how did early humans make use of stones during the prehistoric period", "gold_answers": ["start fires", "hunt", "bury their dead"], "shots": {"0": {"k": 0, "answer": "Tool making.", "latency_ms": 1649.4293212890625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Shaped or chipped stones for tools and weapons.", "latency_ms": 3641.2954330444336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "chipping and flaking", "latency_ms": 2425.4367351531982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1258}, "3": {"k": 3, "answer": "Shaped or chipped for tools and weapons.", "latency_ms": 4594.203472137451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1944}, "4": {"k": 4, "answer": "Shaping and chipping.", "latency_ms": 3168.1182384490967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Shaping or chipping stones for tools and weapons.", "latency_ms": 4837.494373321533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3221}, "6": {"k": 6, "answer": "Shaping and chipping stones for tools and weapons.", "latency_ms": 4622.881174087524, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3893}}}
{"qid": "7402184777947527945", "question": "who wrote the text for jeanie with the light brown hair", "gold_answers": ["Stephen Foster"], "shots": {"0": {"k": 0, "answer": "Maud Irving", "latency_ms": 1530.5366516113281, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stephen Foster", "latency_ms": 1534.2047214508057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Stephen Foster", "latency_ms": 1533.5190296173096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Stephen Foster", "latency_ms": 1565.096139907837, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1871}, "4": {"k": 4, "answer": "Stephen Foster", "latency_ms": 2513.77010345459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2488}, "5": {"k": 5, "answer": "Stephen Foster", "latency_ms": 789.9980545043945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3071}, "6": {"k": 6, "answer": "Stephen Foster", "latency_ms": 2088.078737258911, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3686}}}
{"qid": "1656745334095178455", "question": "the basic steps of rational decision making include defining goals and", "gold_answers": ["Implementation of plans / policies"], "shots": {"0": {"k": 0, "answer": "identifying alternatives", "latency_ms": 2033.977746963501, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "problem definition", "latency_ms": 1278.2320976257324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 774}, "2": {"k": 2, "answer": "problem definition", "latency_ms": 1788.3496284484863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1407}, "3": {"k": 3, "answer": "problem definition", "latency_ms": 1414.6528244018555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2061}, "4": {"k": 4, "answer": "problem identification", "latency_ms": 2033.3144664764404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2713}, "5": {"k": 5, "answer": "problem definition", "latency_ms": 2052.8905391693115, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3431}, "6": {"k": 6, "answer": "problem definition", "latency_ms": 1791.8789386749268, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4101}}}
{"qid": "-216657635823030751", "question": "when was the design period known as art deco", "gold_answers": ["1910 -- 1939"], "shots": {"0": {"k": 0, "answer": "1920s-1940s", "latency_ms": 3932.002067565918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "just before World War I", "latency_ms": 3235.700845718384, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 680}, "2": {"k": 2, "answer": "just before World War I", "latency_ms": 2524.5378017425537, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1362}, "3": {"k": 3, "answer": "just before World War I to 1939", "latency_ms": 4291.408061981201, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2013}, "4": {"k": 4, "answer": "just before World War I to 1939", "latency_ms": 5526.143312454224, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 2721}, "5": {"k": 5, "answer": "just before World War I", "latency_ms": 3376.0483264923096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3391}, "6": {"k": 6, "answer": "just before World War I", "latency_ms": 3277.472496032715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4054}}}
{"qid": "250542332339248886", "question": "where does the bob and tom show broadcast from", "gold_answers": ["WFBQ in Indianapolis , Indiana", "Indianapolis , Indiana"], "shots": {"0": {"k": 0, "answer": "Indianapolis, Indiana", "latency_ms": 2092.1366214752197, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Indianapolis, Indiana", "latency_ms": 2446.3839530944824, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Indianapolis, Indiana", "latency_ms": 2105.039596557617, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1237}, "3": {"k": 3, "answer": "Indianapolis, Indiana", "latency_ms": 2122.251033782959, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1867}, "4": {"k": 4, "answer": "Indianapolis, Indiana", "latency_ms": 2429.405450820923, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2495}, "5": {"k": 5, "answer": "Indianapolis, Indiana", "latency_ms": 3023.9317417144775, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3083}, "6": {"k": 6, "answer": "Indianapolis, Indiana", "latency_ms": 2590.00825881958, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3695}}}
{"qid": "7610758795954724809", "question": "star wars the clone wars season 3 episode 1", "gold_answers": ["Clone Cadets"], "shots": {"0": {"k": 0, "answer": "Clone Cadets", "latency_ms": 1402.1210670471191, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Volume Two", "latency_ms": 2315.131664276123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2388.289451599121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1321}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2197.3161697387695, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2972.294569015503, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2574}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2657.20534324646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3224}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2275.6569385528564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3837}}}
{"qid": "2997223939033016160", "question": "what part of brain is responsible for complex thinking", "gold_answers": ["the frontal lobe"], "shots": {"0": {"k": 0, "answer": "Prefrontal cortex", "latency_ms": 1692.2781467437744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Frontal lobe", "latency_ms": 1897.0611095428467, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Parietal lobe", "latency_ms": 3225.52490234375, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1386}, "3": {"k": 3, "answer": "Parietal lobe", "latency_ms": 2933.2189559936523, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2073}, "4": {"k": 4, "answer": "Frontal lobe", "latency_ms": 2682.838201522827, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2747}, "5": {"k": 5, "answer": "Parietal lobe", "latency_ms": 2571.7203617095947, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3443}, "6": {"k": 6, "answer": "Frontal lobe", "latency_ms": 1618.6153888702393, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4141}}}
{"qid": "2680196226239522881", "question": "who won the champions league final in 2016", "gold_answers": ["Real Madrid"], "shots": {"0": {"k": 0, "answer": "Real Madrid", "latency_ms": 792.468786239624, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Real Madrid", "latency_ms": 1749.2716312408447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Real Madrid", "latency_ms": 1537.4438762664795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Real Madrid", "latency_ms": 1540.815830230713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1837}, "4": {"k": 4, "answer": "Real Madrid", "latency_ms": 1286.181926727295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2442}, "5": {"k": 5, "answer": "Real Madrid", "latency_ms": 2053.943395614624, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3058}, "6": {"k": 6, "answer": "Real Madrid", "latency_ms": 1191.7505264282227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "-8458006812258546025", "question": "who has the most gold medals in the winter olympics of all time", "gold_answers": ["Norway"], "shots": {"0": {"k": 0, "answer": "Marit Bjoergen", "latency_ms": 2328.925848007202, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canada", "latency_ms": 1532.6602458953857, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Canada", "latency_ms": 1158.2481861114502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "Norway", "latency_ms": 1575.5853652954102, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Norway", "latency_ms": 1228.8877964019775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2480}, "5": {"k": 5, "answer": "Marit Bj√∏rgen", "latency_ms": 3384.0560913085938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3095}, "6": {"k": 6, "answer": "Marit Bj√∏rgen", "latency_ms": 2598.165273666382, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3750}}}
