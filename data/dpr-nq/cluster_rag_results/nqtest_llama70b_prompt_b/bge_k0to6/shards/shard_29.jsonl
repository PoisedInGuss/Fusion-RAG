{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "June 15, 2023", "latency_ms": 3894.573450088501, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 22, 2018", "latency_ms": 3563.699722290039, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "June 22, 2018", "latency_ms": 3029.750347137451, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "June 22, 2018", "latency_ms": 4449.610948562622, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "June 22, 2018", "latency_ms": 4493.502140045166, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2582}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 3913.9811992645264, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3233}, "6": {"k": 6, "answer": "June 22, 2018", "latency_ms": 3162.3523235321045, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3935}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Freestyle, Nordic Combined, Ski Jumping, Biathlon.", "latency_ms": 7909.353017807007, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alpine skiing", "latency_ms": 2336.1103534698486, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Alpine skiing", "latency_ms": 2284.2702865600586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Alpine skiing", "latency_ms": 1588.939905166626, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "Alpine, Cross-country, Ski-orienteering", "latency_ms": 4699.439287185669, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2604}, "5": {"k": 5, "answer": "Alpine, Cross-country, Ski jumping", "latency_ms": 3179.163932800293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3246}, "6": {"k": 6, "answer": "Alpine, Cross-country, Ski jumping, Freestyle", "latency_ms": 4156.61883354187, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3901}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "Arianwen Parkes-Lockwood", "latency_ms": 3133.037567138672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2897.5095748901367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2220.836877822876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3151.2820720672607, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1949}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2762.603282928467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2572}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2388.6477947235107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3248}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2684.865713119507, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3944}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "Bengals, Dolphins, Broncos, Chargers.", "latency_ms": 4741.760492324829, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Giants", "latency_ms": 2591.1905765533447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 552}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2432.68084526062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1199}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2660.4127883911133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2645.1220512390137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "Miami Dolphins", "latency_ms": 1369.7073459625244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3172}, "6": {"k": 6, "answer": "Miami Dolphins", "latency_ms": 2032.6759815216064, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3776}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "December 8, 1985", "latency_ms": 3345.977544784546, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "8 December 1985", "latency_ms": 3202.0113468170166, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 727}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 2939.6047592163086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1447}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 3248.276472091675, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2144}, "4": {"k": 4, "answer": "8 December 1985", "latency_ms": 3159.874439239502, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2861}, "5": {"k": 5, "answer": "December 8, 1985", "latency_ms": 3106.198787689209, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 3557}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 3195.728063583374, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4315}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "Spanish Moss", "latency_ms": 1474.4749069213867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "moss", "latency_ms": 2070.786237716675, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "moss", "latency_ms": 1706.7646980285645, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1343}, "3": {"k": 3, "answer": "moss", "latency_ms": 1308.7513446807861, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "moss", "latency_ms": 1259.8962783813477, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2635}, "5": {"k": 5, "answer": "moss", "latency_ms": 1771.8510627746582, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3264}, "6": {"k": 6, "answer": "moss", "latency_ms": 1697.0179080963135, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3949}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "I-IV", "latency_ms": 2052.8109073638916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Class II or III", "latency_ms": 2367.7351474761963, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 730}, "2": {"k": 2, "answer": "Canadian Cardiovascular Society", "latency_ms": 2079.8115730285645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1494}, "3": {"k": 3, "answer": "Canadian Cardiovascular Society", "latency_ms": 2574.868679046631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2250}, "4": {"k": 4, "answer": "Canadian Cardiovascular Society grading", "latency_ms": 2698.863744735718, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2959}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1973.383903503418, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3658}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2515.666961669922, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4437}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Mick Hucknall and Neil Moss", "latency_ms": 4108.559608459473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mike Leeson and Peter Vale", "latency_ms": 3893.446922302246, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 583}, "2": {"k": 2, "answer": "Mike Leeson and Peter Vale", "latency_ms": 3032.5253009796143, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1219}, "3": {"k": 3, "answer": "Mike Leeson and Peter Vale", "latency_ms": 2631.6487789154053, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1856}, "4": {"k": 4, "answer": "Mike Leeson and Peter Vale", "latency_ms": 3187.365770339966, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2455}, "5": {"k": 5, "answer": "Mike Leeson and Peter Vale", "latency_ms": 2014.5535469055176, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3060}, "6": {"k": 6, "answer": "Mike Leeson and Peter Vale", "latency_ms": 2848.3731746673584, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3712}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 956.1669826507568, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 920.7015037536621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 641}, "2": {"k": 2, "answer": "3", "latency_ms": 945.5485343933105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1283}, "3": {"k": 3, "answer": "3", "latency_ms": 1449.4407176971436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1882}, "4": {"k": 4, "answer": "3", "latency_ms": 1535.6476306915283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2643}, "5": {"k": 5, "answer": "3", "latency_ms": 1475.0175476074219, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3299}, "6": {"k": 6, "answer": "3", "latency_ms": 958.0371379852295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3927}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "A cake.", "latency_ms": 1287.8215312957764, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Biscuit-sized cakes", "latency_ms": 2513.6287212371826, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "biscuit-sized cakes", "latency_ms": 2354.285717010498, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "A cake.", "latency_ms": 1130.7203769683838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1765}, "4": {"k": 4, "answer": "A cake.", "latency_ms": 2147.7158069610596, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2460}, "5": {"k": 5, "answer": "A cake.", "latency_ms": 1861.8063926696777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3101}, "6": {"k": 6, "answer": "A cake.", "latency_ms": 2076.2076377868652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Seth MacFarlane", "latency_ms": 2292.0875549316406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rachael MacFarlane", "latency_ms": 2639.498710632324, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 675}, "2": {"k": 2, "answer": "Rachael MacFarlane", "latency_ms": 2822.8237628936768, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1399}, "3": {"k": 3, "answer": "Rachael MacFarlane", "latency_ms": 2983.577251434326, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2065}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 3000.07700920105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2738}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 2761.700391769409, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3407}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 2736.072540283203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4062}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "Heroin", "latency_ms": 1724.153995513916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amphetamines", "latency_ms": 2011.7230415344238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Amphetamines", "latency_ms": 2553.175687789917, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1254}, "3": {"k": 3, "answer": "Amphetamines", "latency_ms": 2365.353584289551, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1831}, "4": {"k": 4, "answer": "Amphetamines", "latency_ms": 2254.988431930542, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2445}, "5": {"k": 5, "answer": "Amphetamines", "latency_ms": 2403.278350830078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3085}, "6": {"k": 6, "answer": "Amphetamines", "latency_ms": 2130.5887699127197, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3708}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "15 weeks", "latency_ms": 2091.0608768463135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1941.6179656982422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2897.3593711853027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "364 weeks", "latency_ms": 1544.0373420715332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1800}, "4": {"k": 4, "answer": "1 year", "latency_ms": 2833.378314971924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2412}, "5": {"k": 5, "answer": "1", "latency_ms": 1768.7220573425293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3023}, "6": {"k": 6, "answer": "1 week", "latency_ms": 2627.445936203003, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3656}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "Yushan, China", "latency_ms": 2645.958185195923, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sheffield, England", "latency_ms": 2735.5475425720215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Sheffield, England", "latency_ms": 1906.313180923462, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "Sheffield, England", "latency_ms": 2420.2637672424316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1933}, "4": {"k": 4, "answer": "Sheffield, England", "latency_ms": 2366.0078048706055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2562}, "5": {"k": 5, "answer": "Sheffield, England", "latency_ms": 3065.5317306518555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Yushan, China", "latency_ms": 2816.863775253296, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3836}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "Thad Luckinbill", "latency_ms": 2061.107873916626, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Thad Luckinbill", "latency_ms": 2728.4646034240723, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "Thad Luckinbill", "latency_ms": 3246.7076778411865, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Thad Luckinbill", "latency_ms": 3607.2821617126465, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1898}, "4": {"k": 4, "answer": "Thad Luckinbill", "latency_ms": 3298.4137535095215, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2485}, "5": {"k": 5, "answer": "Thad Luckinbill", "latency_ms": 3220.003128051758, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3103}, "6": {"k": 6, "answer": "Thad Luckinbill", "latency_ms": 2477.7512550354004, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3708}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 1498.7530708312988, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Early 1990s", "latency_ms": 2776.7374515533447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 666}, "2": {"k": 2, "answer": "early 1990s", "latency_ms": 3488.1865978240967, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1359}, "3": {"k": 3, "answer": "1973", "latency_ms": 2313.035488128662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2001}, "4": {"k": 4, "answer": "1983", "latency_ms": 2083.029270172119, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2690}, "5": {"k": 5, "answer": "1983", "latency_ms": 1450.4077434539795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3320}, "6": {"k": 6, "answer": "1983", "latency_ms": 1624.445915222168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3903}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "J-Rock", "latency_ms": 1520.555019378662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jakalope, Damhnait Doyle", "latency_ms": 5190.056085586548, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Jakalope, Damhnait Doyle, Alexz Johnson", "latency_ms": 3685.4870319366455, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Damhnait Doyle", "latency_ms": 3447.1089839935303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Damhnait Doyle", "latency_ms": 2728.7678718566895, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Damhnait Doyle, Jakalope, Alexz Johnson", "latency_ms": 6378.475189208984, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3209}, "6": {"k": 6, "answer": "Damhnait Doyle", "latency_ms": 2476.22013092041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3935}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "March 15, 2002", "latency_ms": 3665.088415145874, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2.6 million years ago", "latency_ms": 4080.826759338379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "360 million years ago", "latency_ms": 2725.311279296875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "360 million years ago", "latency_ms": 2563.258171081543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "2.6 million years ago", "latency_ms": 4129.772186279297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "360 million years ago", "latency_ms": 2384.0551376342773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3192}, "6": {"k": 6, "answer": "360 million years ago", "latency_ms": 2191.004753112793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3871}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "Master Sergeant", "latency_ms": 738.9600276947021, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "8th Engineer Support Battalion", "latency_ms": 2805.943250656128, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 732}, "2": {"k": 2, "answer": "Master Sergeant", "latency_ms": 1166.707992553711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1425}, "3": {"k": 3, "answer": "First Sergeant", "latency_ms": 1784.1362953186035, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2087}, "4": {"k": 4, "answer": "First Sergeant", "latency_ms": 1530.9433937072754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2737}, "5": {"k": 5, "answer": "First Sergeant", "latency_ms": 1234.4741821289062, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3440}, "6": {"k": 6, "answer": "First Sergeant", "latency_ms": 1572.0765590667725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4176}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 1412.7252101898193, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Richard Stallman", "latency_ms": 2376.516819000244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 685}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 2141.052722930908, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1332}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 1857.4202060699463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1981}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 2107.929468154907, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2594}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 2102.091073989868, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3284}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 1401.3149738311768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "Manu Bhaker", "latency_ms": 2949.87154006958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2140.328884124756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2890.504837036133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2626.005172729492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1828}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2158.2858562469482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2433}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2382.671117782593, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3014}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2485.6479167938232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3641}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Ed Roland", "latency_ms": 1201.709270477295, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 1909.139633178711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 1767.0018672943115, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1369}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 1521.8877792358398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 2511.190414428711, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2622}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 1785.1366996765137, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3207}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 1763.8187408447266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3813}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "Retired", "latency_ms": 2023.7922668457031, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miami Heat", "latency_ms": 1846.1096286773682, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 1342.4444198608398, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1310}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 1496.169090270996, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1908}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 1835.14404296875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2505}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 1512.2120380401611, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3072}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 2252.9618740081787, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3682}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "Guarani (PYG)", "latency_ms": 3624.6252059936523, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "PYG", "latency_ms": 1943.8438415527344, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 656}, "2": {"k": 2, "answer": "PYG6155", "latency_ms": 2210.387945175171, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "PYG", "latency_ms": 1801.100492477417, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "PYG", "latency_ms": 1846.5816974639893, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 2392}, "5": {"k": 5, "answer": "PYG", "latency_ms": 1705.165147781372, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3030}, "6": {"k": 6, "answer": "PYG", "latency_ms": 1291.417121887207, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3667}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "Midazolam.", "latency_ms": 3216.0253524780273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Benzodiazepines", "latency_ms": 3255.056381225586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 678}, "2": {"k": 2, "answer": "Benzodiazepines.", "latency_ms": 4160.467863082886, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1397}, "3": {"k": 3, "answer": "Benzodiazepines", "latency_ms": 3483.1929206848145, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2036}, "4": {"k": 4, "answer": "Benzodiazepines", "latency_ms": 3845.7210063934326, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2771}, "5": {"k": 5, "answer": "Benzodiazepines", "latency_ms": 3066.5974617004395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3496}, "6": {"k": 6, "answer": "Benzodiazepines", "latency_ms": 3097.7654457092285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4207}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 1326.0624408721924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "26,000 years", "latency_ms": 1583.5819244384766, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "26,000 years", "latency_ms": 2727.003335952759, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "26,000 years", "latency_ms": 2198.284149169922, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1840}, "4": {"k": 4, "answer": "26,000 years", "latency_ms": 2650.942325592041, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2468}, "5": {"k": 5, "answer": "26,000 years", "latency_ms": 3144.836664199829, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3095}, "6": {"k": 6, "answer": "26,000 years", "latency_ms": 2705.124616622925, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3720}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 1411.6106033325195, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Texas A&M University", "latency_ms": 2377.845287322998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 618}, "2": {"k": 2, "answer": "Texas A&M University", "latency_ms": 2725.8331775665283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Texas A&M University", "latency_ms": 2611.524820327759, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1894}, "4": {"k": 4, "answer": "Texas A&M University", "latency_ms": 3226.5090942382812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2518}, "5": {"k": 5, "answer": "Texas A&M Aggies", "latency_ms": 3032.214641571045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3165}, "6": {"k": 6, "answer": "Texas A&M Aggies", "latency_ms": 3278.764486312866, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3823}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and Non-Renewable.", "latency_ms": 4229.318141937256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable or non-renewable", "latency_ms": 4088.048219680786, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable or non-renewable", "latency_ms": 4350.03399848938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1403}, "3": {"k": 3, "answer": "renewable or non-renewable", "latency_ms": 4239.468812942505, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2201}, "4": {"k": 4, "answer": "renewable or non-renewable", "latency_ms": 5140.72322845459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2932}, "5": {"k": 5, "answer": "renewable or non-renewable", "latency_ms": 4848.617792129517, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3579}, "6": {"k": 6, "answer": "renewable or non-renewable", "latency_ms": 3572.028636932373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4356}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "New life and fertility", "latency_ms": 1721.7774391174316, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parental devotion", "latency_ms": 2296.458959579468, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "parental devotion", "latency_ms": 2043.259859085083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1230}, "3": {"k": 3, "answer": "Purity", "latency_ms": 1821.624994277954, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1879}, "4": {"k": 4, "answer": "parental devotion", "latency_ms": 1829.3030261993408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2522}, "5": {"k": 5, "answer": "parental devotion", "latency_ms": 2404.186487197876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "Parental devotion", "latency_ms": 1722.0380306243896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3795}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Virat Kohli 286 runs", "latency_ms": 2348.3948707580566, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "558", "latency_ms": 1621.9186782836914, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "558 runs", "latency_ms": 1301.2924194335938, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1203}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2475.1040935516357, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1834}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2474.644660949707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2447}, "5": {"k": 5, "answer": "558", "latency_ms": 1240.8430576324463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3084}, "6": {"k": 6, "answer": "558", "latency_ms": 928.678035736084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3681}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "the antimicrobial properties of metals.", "latency_ms": 3209.0041637420654, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals", "latency_ms": 4471.715688705444, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "biocidal effect of metals", "latency_ms": 2702.9380798339844, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "biocidal effect of metals", "latency_ms": 3503.15523147583, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2074}, "4": {"k": 4, "answer": "biocidal effect of metals", "latency_ms": 3269.4618701934814, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2740}, "5": {"k": 5, "answer": "biocidal effect of metals", "latency_ms": 2792.140483856201, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3478}, "6": {"k": 6, "answer": "biocidal effect of metals", "latency_ms": 3333.5041999816895, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4146}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "Dustin Higgs", "latency_ms": 1447.3531246185303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rainey Bethea", "latency_ms": 2213.4737968444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 634}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3213.9739990234375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1263}, "3": {"k": 3, "answer": "Eddie Lee Mays", "latency_ms": 3571.439266204834, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1874}, "4": {"k": 4, "answer": "Rainey Bethea", "latency_ms": 2868.860960006714, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2532}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2672.3315715789795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3156}, "6": {"k": 6, "answer": "Nidal Hasan", "latency_ms": 2162.539482116699, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3776}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the auction.", "latency_ms": 2262.6776695251465, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2618.5238361358643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 2605.8082580566406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1166}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 2726.8502712249756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1736}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 2745.582103729248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2342}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 2403.7389755249023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2924}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 2270.0724601745605, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3618}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Afghanistan", "latency_ms": 1574.9988555908203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 1571.5081691741943, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 699}, "2": {"k": 2, "answer": "Afghanistan", "latency_ms": 2393.7366008758545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1416}, "3": {"k": 3, "answer": "Afghanistan", "latency_ms": 1634.1500282287598, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2145}, "4": {"k": 4, "answer": "Afghanistan", "latency_ms": 1766.2081718444824, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2851}, "5": {"k": 5, "answer": "Afghanistan", "latency_ms": 2435.152053833008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3547}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 2379.871606826782, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4271}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "Vasoconstriction, Platelet Plug Formation, Coagulation.", "latency_ms": 5575.514316558838, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1) vasoconstriction, 2) platelet plug, 3) blood coagulation", "latency_ms": 10359.193563461304, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "Vasoconstriction, platelet plug, coagulation", "latency_ms": 5471.245527267456, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": "Vasoconstriction, platelet plug formation, coagulation", "latency_ms": 5269.931316375732, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1994}, "4": {"k": 4, "answer": "Vasoconstriction, platelet plug formation, blood coagulation", "latency_ms": 6805.972337722778, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2663}, "5": {"k": 5, "answer": "Vasoconstriction, platelet plug formation, coagulation", "latency_ms": 5269.819021224976, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3321}, "6": {"k": 6, "answer": "Vasoconstriction, platelet plug formation, coagulation", "latency_ms": 6597.149133682251, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 4042}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "Sebastian Hunsinger", "latency_ms": 3036.5850925445557, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2126.5735626220703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "Presley Smith", "latency_ms": 2576.4286518096924, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1324}, "3": {"k": 3, "answer": "Shirley Temple did not play Sunny, the answer is not in the provided context for the 2004 film, but for the TV series: Presley Smith", "latency_ms": 13691.311359405518, "em": 0.0, "f1": 0.17391304347826084, "containment": 1.0, "context_chars": 2016}, "4": {"k": 4, "answer": "Shirley Temple did not play Sunny, it was  Kara and Shelby Hoffman in the 2004 film, and Presley Smith in the TV series", "latency_ms": 13418.35641860962, "em": 0.0, "f1": 0.17391304347826084, "containment": 1.0, "context_chars": 2700}, "5": {"k": 5, "answer": "Shirley Temple did not play Sunny, it was  Kara and Shelby Hoffman in the 2004 film, and Presley Smith in the TV series", "latency_ms": 13560.206651687622, "em": 0.0, "f1": 0.17391304347826084, "containment": 1.0, "context_chars": 3306}, "6": {"k": 6, "answer": "Shirley Temple (no), Presley Smith", "latency_ms": 4567.23427772522, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4000}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "20 November 1989", "latency_ms": 2587.240219116211, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "20 November 1989", "latency_ms": 2958.801507949829, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 3017.925262451172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1324}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 2559.681177139282, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2012}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 2438.7478828430176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2594}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 2649.8727798461914, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3212}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 3196.110248565674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3865}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "23 June 2016", "latency_ms": 2334.1245651245117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2016", "latency_ms": 2111.830949783325, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "23 June 2016", "latency_ms": 2539.5052433013916, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1294}, "3": {"k": 3, "answer": "23 June 2016", "latency_ms": 2788.2089614868164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1923}, "4": {"k": 4, "answer": "23 June 2016", "latency_ms": 3012.4197006225586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2504}, "5": {"k": 5, "answer": "23 June 2016", "latency_ms": 2990.199089050293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3099}, "6": {"k": 6, "answer": "23 June 2016", "latency_ms": 3021.2302207946777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3773}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 2951.9262313842773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Burj Khalifa", "latency_ms": 2003.2727718353271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "Burj Khalifa", "latency_ms": 2202.0273208618164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1320}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 1930.2141666412354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2001}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 2973.2067584991455, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2688}, "5": {"k": 5, "answer": "Burj Khalifa", "latency_ms": 2475.5098819732666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3291}, "6": {"k": 6, "answer": "Burj Khalifa", "latency_ms": 3492.5947189331055, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3982}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "Miriam Margolyes", "latency_ms": 2683.2823753356934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Miranda Hart's mother is played by  Cherie Lunghi", "latency_ms": 6196.750164031982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "Miranda Hart", "latency_ms": 2587.4788761138916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "Miranda Hart's mother is played by  Cherie Lunghi", "latency_ms": 7081.74991607666, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1940}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3260.3800296783447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2578}, "5": {"k": 5, "answer": "Miranda Hart's mother is played by  Cherie Lunghi", "latency_ms": 6247.58768081665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3162}, "6": {"k": 6, "answer": "Miranda Hart's mother is played by  Cherie Lunghi", "latency_ms": 6896.84796333313, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3742}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Montesquieu", "latency_ms": 2733.2818508148193, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montesquieu", "latency_ms": 2195.225238800049, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 2973.797559738159, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 2335.9169960021973, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1992}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 2103.099584579468, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2714}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 2547.0261573791504, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3352}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 2671.055555343628, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4054}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Myles Garrett", "latency_ms": 1876.7025470733643, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2450.6568908691406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1985.0354194641113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2349.0097522735596, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1948}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2658.583879470825, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "Not in context.", "latency_ms": 2934.2291355133057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3213}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3223.4015464782715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3758}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2063 BS", "latency_ms": 1640.4120922088623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2900.6431102752686, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 714}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1705.6269645690918, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2704.113721847534, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2124}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2164.2544269561768, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2877}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2681.1721324920654, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3522}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1993.5753345489502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4163}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "Captain John Smith", "latency_ms": 1804.4471740722656, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Smith", "latency_ms": 1768.0206298828125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 623}, "2": {"k": 2, "answer": "John Smith", "latency_ms": 957.2343826293945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1261}, "3": {"k": 3, "answer": "John Smith", "latency_ms": 2196.9263553619385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1923}, "4": {"k": 4, "answer": "John Smith", "latency_ms": 1279.5591354370117, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2569}, "5": {"k": 5, "answer": "John Smith", "latency_ms": 2033.360481262207, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3241}, "6": {"k": 6, "answer": "John Smith", "latency_ms": 1295.412302017212, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3966}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "Parietal cells", "latency_ms": 2161.3991260528564, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parietal cells", "latency_ms": 2731.870412826538, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 625}, "2": {"k": 2, "answer": "Parietal cells", "latency_ms": 2703.840494155884, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Parietal cells", "latency_ms": 2442.7237510681152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1838}, "4": {"k": 4, "answer": "Parietal cells", "latency_ms": 2410.5803966522217, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2495}, "5": {"k": 5, "answer": "Parietal cells", "latency_ms": 2883.746862411499, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3126}, "6": {"k": 6, "answer": "canaliculi", "latency_ms": 2208.6591720581055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3870}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "Early morning.", "latency_ms": 1382.568120956421, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "4 a.m.", "latency_ms": 3142.5254344940186, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 2589.8704528808594, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "4 a.m.", "latency_ms": 2298.4254360198975, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1975}, "4": {"k": 4, "answer": "4 a.m.", "latency_ms": 1661.0400676727295, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2610}, "5": {"k": 5, "answer": "4 a.m.", "latency_ms": 2422.0502376556396, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3264}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 2284.7564220428467, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3895}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 1046.989917755127, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Idaho", "latency_ms": 1495.4700469970703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "Idaho", "latency_ms": 1203.1619548797607, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1332}, "3": {"k": 3, "answer": "Idaho", "latency_ms": 1236.961841583252, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "Idaho", "latency_ms": 2347.8734493255615, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2599}, "5": {"k": 5, "answer": "Idaho", "latency_ms": 1467.7436351776123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3235}, "6": {"k": 6, "answer": "Idaho", "latency_ms": 2072.011709213257, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3903}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales.", "latency_ms": 11131.147623062134, "em": 0.0, "f1": 0.43478260869565216, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1871.9182014465332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2717.1802520751953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3136.819362640381, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2420.9654331207275, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2520}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2640.202522277832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3151}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2838.517904281616, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3775}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 1309.6959590911865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "changed key", "latency_ms": 1540.9507751464844, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2386.742115020752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1429}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2782.7486991882324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2096}, "4": {"k": 4, "answer": "undergone key modulation", "latency_ms": 1862.7493381500244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2741}, "5": {"k": 5, "answer": "undergone key modulations", "latency_ms": 3251.1918544769287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3351}, "6": {"k": 6, "answer": "undergone modulation", "latency_ms": 1659.1110229492188, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3963}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Male citizens.", "latency_ms": 1889.1589641571045, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "the Roman people", "latency_ms": 2247.5616931915283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 672}, "2": {"k": 2, "answer": "full Roman citizens", "latency_ms": 2603.3406257629395, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "adult male citizens", "latency_ms": 2713.3171558380127, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1991}, "4": {"k": 4, "answer": "Adult male citizens", "latency_ms": 576.4105319976807, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2685}, "5": {"k": 5, "answer": "Adult male citizens", "latency_ms": 2541.2707328796387, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3347}, "6": {"k": 6, "answer": "Adult male citizens", "latency_ms": 1853.02734375, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4058}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1742.9695129394531, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "9 April 2019", "latency_ms": 2299.4587421417236, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "9 April 2019", "latency_ms": 3234.8523139953613, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1503}, "3": {"k": 3, "answer": "9 April 2019", "latency_ms": 2578.510046005249, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2163}, "4": {"k": 4, "answer": "9 April 2019", "latency_ms": 3925.2700805664062, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2807}, "5": {"k": 5, "answer": "9 April 2019", "latency_ms": 2087.6216888427734, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3421}, "6": {"k": 6, "answer": "9 April 2019", "latency_ms": 2056.546449661255, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4119}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "100 parts of blood", "latency_ms": 1893.0785655975342, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "volume of blood or mass of blood", "latency_ms": 3031.371831893921, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "volume of blood or mass of blood", "latency_ms": 3597.710371017456, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1302}, "3": {"k": 3, "answer": "volume of blood or mass of blood", "latency_ms": 3947.8371143341064, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "volume of blood or mass of blood", "latency_ms": 3018.1803703308105, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2514}, "5": {"k": 5, "answer": "volume of blood or mass of blood", "latency_ms": 3621.9494342803955, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3172}, "6": {"k": 6, "answer": "volume of blood or mass of blood", "latency_ms": 3532.2721004486084, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3889}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "Icarus", "latency_ms": 2531.0535430908203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Icarus", "latency_ms": 1927.7853965759277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 603}, "2": {"k": 2, "answer": "Icarus", "latency_ms": 2570.430278778076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1200}, "3": {"k": 3, "answer": "Icarus", "latency_ms": 1832.0295810699463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1736}, "4": {"k": 4, "answer": "Phaethon", "latency_ms": 2093.6119556427, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2351}, "5": {"k": 5, "answer": "Icarus", "latency_ms": 2230.0450801849365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2921}, "6": {"k": 6, "answer": "Icarus", "latency_ms": 2298.5897064208984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3539}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "September 16, 1979", "latency_ms": 3101.4816761016846, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 16, 1979", "latency_ms": 3376.368522644043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "September 16, 1979", "latency_ms": 3367.2385215759277, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1195}, "3": {"k": 3, "answer": "September 16, 1979", "latency_ms": 2902.458429336548, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1851}, "4": {"k": 4, "answer": "September 16, 1979", "latency_ms": 3678.4048080444336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "September 16, 1979", "latency_ms": 3209.592342376709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3123}, "6": {"k": 6, "answer": "September 16, 1979", "latency_ms": 3571.6793537139893, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3752}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 am HKT", "latency_ms": 3046.9369888305664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2168.339729309082, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "09:00 am", "latency_ms": 2718.91188621521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "09:00 am", "latency_ms": 3288.4864807128906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1900}, "4": {"k": 4, "answer": "09:00 am", "latency_ms": 2456.392288208008, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2548}, "5": {"k": 5, "answer": "09:00 am", "latency_ms": 2752.6650428771973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "09:00 am", "latency_ms": 2417.090654373169, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3849}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "Tiffany Coyne", "latency_ms": 2190.265417098999, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiffany Coyne", "latency_ms": 1582.4172496795654, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 574}, "2": {"k": 2, "answer": "Tiffany Coyne", "latency_ms": 2418.397903442383, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 2668.987512588501, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 2357.0570945739746, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2398}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 2415.8153533935547, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3025}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 2954.017400741577, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3639}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "Yankees, Braves, Reds, Giants.", "latency_ms": 4696.007490158081, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yankees, Atlanta Braves", "latency_ms": 2966.132879257202, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5697.307109832764, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1250}, "3": {"k": 3, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 6534.846782684326, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1856}, "4": {"k": 4, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 4776.326894760132, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2499}, "5": {"k": 5, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 6282.053470611572, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3075}, "6": {"k": 6, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 4983.976364135742, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3684}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "2.187 billion dollars", "latency_ms": 2516.495704650879, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$343.4 million", "latency_ms": 2139.995813369751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "$1.84 billion", "latency_ms": 2773.393392562866, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "$1.84 billion", "latency_ms": 2936.7690086364746, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1914}, "4": {"k": 4, "answer": "$1.84 billion", "latency_ms": 2930.994749069214, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2507}, "5": {"k": 5, "answer": "$1.843 billion", "latency_ms": 2173.731565475464, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3176}, "6": {"k": 6, "answer": "$2.187 billion", "latency_ms": 2952.4781703948975, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3827}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "Christmas Eve and Christmas Day.", "latency_ms": 2520.3685760498047, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3255.2225589752197, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2225.985527038574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1249}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3047.62601852417, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2345.151424407959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2535}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2240.8201694488525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3177}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2993.042230606079, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3837}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark and Norway", "latency_ms": 1933.4025382995605, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Denmark, Norway and Schleswig-Holstein", "latency_ms": 3148.9179134368896, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "Denmark, Norway and Schleswig-Holstein", "latency_ms": 4485.0263595581055, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1342}, "3": {"k": 3, "answer": "Scandinavia", "latency_ms": 1377.9609203338623, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1993}, "4": {"k": 4, "answer": "Denmark, Norway and Schleswig-Holstein", "latency_ms": 4618.741512298584, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2621}, "5": {"k": 5, "answer": "Denmark, Norway and Schleswig-Holstein", "latency_ms": 3385.161876678467, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 3233}, "6": {"k": 6, "answer": "Scandinavia", "latency_ms": 1981.3456535339355, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3858}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "Prespio", "latency_ms": 1737.738847732544, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Puritina", "latency_ms": 1658.24556350708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Christmas Tree", "latency_ms": 1307.9087734222412, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Christmas Tree", "latency_ms": 1249.3953704833984, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1949}, "4": {"k": 4, "answer": "Christmas Tree", "latency_ms": 1745.0897693634033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2595}, "5": {"k": 5, "answer": "Nativity scene", "latency_ms": 1233.961582183838, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3270}, "6": {"k": 6, "answer": "Puritina", "latency_ms": 2285.414934158325, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3908}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "Patrick Swayze", "latency_ms": 1690.3457641601562, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 3050.3036975860596, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 3047.111749649048, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1249}, "3": {"k": 3, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 4513.9806270599365, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1881}, "4": {"k": 4, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 3920.1557636260986, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2475}, "5": {"k": 5, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 2824.2015838623047, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3098}, "6": {"k": 6, "answer": "Patrick Swayze & Wendy Fraser", "latency_ms": 3103.1765937805176, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3723}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Pittsburgh", "latency_ms": 1447.6447105407715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Pittsburgh", "latency_ms": 2324.765920639038, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 621}, "2": {"k": 2, "answer": "Pittsburgh", "latency_ms": 1878.4401416778564, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1299}, "3": {"k": 3, "answer": "Pittsburgh", "latency_ms": 2607.572078704834, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1910}, "4": {"k": 4, "answer": "Pittsburgh", "latency_ms": 1584.6078395843506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "Pittsburgh", "latency_ms": 1838.1226062774658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Pittsburgh", "latency_ms": 1410.017728805542, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3885}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1612", "latency_ms": 1753.8073062896729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1697.5347995758057, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "1901", "latency_ms": 2001.2567043304443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1319}, "3": {"k": 3, "answer": "1901", "latency_ms": 1553.778886795044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1987}, "4": {"k": 4, "answer": "18th century", "latency_ms": 2113.4438514709473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2651}, "5": {"k": 5, "answer": "18th century", "latency_ms": 2091.912269592285, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3319}, "6": {"k": 6, "answer": "1727", "latency_ms": 2032.4654579162598, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3987}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier Fernndez", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Yuzuru Hanyu", "latency_ms": 2844.3870544433594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yuzuru Hanyu", "latency_ms": 2984.6880435943604, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Yuzuru Hanyu", "latency_ms": 2792.1571731567383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Yuzuru Hanyu", "latency_ms": 3529.430389404297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1940}, "4": {"k": 4, "answer": "Yuzuru Hanyu", "latency_ms": 3266.6797637939453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2588}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 2869.290351867676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3188}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 2809.021234512329, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3798}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "Password cracking and recovery.", "latency_ms": 2592.078685760498, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1638.7314796447754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2712.0206356048584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1385}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2187.183380126953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2023}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1981.4836978912354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2693}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2151.381015777588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3384}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2452.4905681610107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4055}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "Eknath Shinde", "latency_ms": 2250.690221786499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2597.1856117248535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "C. Vidyasagar Rao", "latency_ms": 3626.366138458252, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1299}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 3672.511577606201, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 3720.0570106506348, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2593}, "5": {"k": 5, "answer": "C. Vidyasagar Rao", "latency_ms": 3421.457052230835, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "C. Vidyasagar Rao", "latency_ms": 3023.8184928894043, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3873}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "Channel 15", "latency_ms": 1825.23775100708, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "15", "latency_ms": 1552.7992248535156, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 603}, "2": {"k": 2, "answer": "15", "latency_ms": 1179.567813873291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "15", "latency_ms": 1993.3099746704102, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1959}, "4": {"k": 4, "answer": "15", "latency_ms": 1186.2924098968506, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2713}, "5": {"k": 5, "answer": "15", "latency_ms": 1774.2295265197754, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3390}, "6": {"k": 6, "answer": "15", "latency_ms": 1468.0781364440918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4022}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Claudia Wells", "latency_ms": 2263.659715652466, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Claudia Wells", "latency_ms": 2213.082790374756, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Claudia Wells", "latency_ms": 1938.6284351348877, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1207}, "3": {"k": 3, "answer": "Claudia Wells", "latency_ms": 2663.7656688690186, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1829}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 2620.5239295959473, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2477}, "5": {"k": 5, "answer": "Claudia Wells", "latency_ms": 2668.105363845825, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3062}, "6": {"k": 6, "answer": "Claudia Wells", "latency_ms": 2422.689437866211, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3667}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 1127.223014831543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "London, United Kingdom", "latency_ms": 2115.567684173584, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 1872.3101615905762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1244}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 2497.723340988159, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1891}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 2843.371868133545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2490}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 2160.107135772705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3105}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 2595.862865447998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3741}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The White House Chef", "latency_ms": 2179.1274547576904, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The White House Executive Chef", "latency_ms": 3335.5038166046143, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 686}, "2": {"k": 2, "answer": "The White House Executive Chef", "latency_ms": 3383.863687515259, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1369}, "3": {"k": 3, "answer": "The White House Executive Chef", "latency_ms": 3464.381217956543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2038}, "4": {"k": 4, "answer": "The White House Executive Chef", "latency_ms": 3273.876428604126, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2656}, "5": {"k": 5, "answer": "The White House Executive Chef", "latency_ms": 3518.801689147949, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3325}, "6": {"k": 6, "answer": "The White House Executive Chef", "latency_ms": 4539.416313171387, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3982}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 2899.2819786071777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2803.6582469940186, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2668.7088012695312, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Benegal Narsing Rau", "latency_ms": 3062.1109008789062, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "Benegal Narsing Rau", "latency_ms": 3887.9683017730713, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Benegal Narsing Rau", "latency_ms": 3355.822801589966, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3200}, "6": {"k": 6, "answer": "Benegal Narsing Rau", "latency_ms": 3045.8219051361084, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 3846}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "New Zealand", "latency_ms": 1970.665454864502, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "British Columbia", "latency_ms": 1287.0771884918213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "British Columbia", "latency_ms": 1807.4777126312256, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1301}, "3": {"k": 3, "answer": "British Columbia", "latency_ms": 1730.0360202789307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1986}, "4": {"k": 4, "answer": "British Columbia", "latency_ms": 1033.4486961364746, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2592}, "5": {"k": 5, "answer": "British Columbia, Abbotsford, Vancouver, Langley, Aldergrove", "latency_ms": 6774.7483253479, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3250}, "6": {"k": 6, "answer": "British Columbia, Abbotsford, Vancouver, Langley, Aldergrove", "latency_ms": 5894.081354141235, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3850}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2733.3407402038574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 12, 2017", "latency_ms": 3840.7797813415527, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 661}, "2": {"k": 2, "answer": "October 11, 2018", "latency_ms": 3003.8163661956787, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1322}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 3563.632011413574, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1949}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 3632.8794956207275, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2601}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 4391.700744628906, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3233}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 2829.453706741333, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3869}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Jodie Sweetin", "latency_ms": 1711.2958431243896, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lori Loughlin", "latency_ms": 3814.7287368774414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "Jodie Sweetin", "latency_ms": 2731.74786567688, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1282}, "3": {"k": 3, "answer": "Jodie Sweetin", "latency_ms": 3139.0380859375, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1885}, "4": {"k": 4, "answer": "Jodie Sweetin", "latency_ms": 3061.6939067840576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2513}, "5": {"k": 5, "answer": "Jodie Sweetin", "latency_ms": 2130.0129890441895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3121}, "6": {"k": 6, "answer": "Jodie Sweetin", "latency_ms": 1425.8551597595215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3746}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "Millennium Tower", "latency_ms": 1601.5253067016602, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2146.50559425354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 614}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 2174.7589111328125, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1266}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 2172.551155090332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1867}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 2104.2072772979736, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 2063.4801387786865, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3248}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 1393.6550617218018, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3905}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 1540.93599319458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 981.3432693481445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1941.7297840118408, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1221}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2464.205741882324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "January 11, 2014", "latency_ms": 2859.9374294281006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2525}, "5": {"k": 5, "answer": "January 11, 2014", "latency_ms": 3464.1618728637695, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3161}, "6": {"k": 6, "answer": "January 11, 2014", "latency_ms": 2859.4539165496826, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3787}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "John Harlan", "latency_ms": 1322.934627532959, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2385.021209716797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2463.580369949341, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1307}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2069.366931915283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1624.9184608459473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2559}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2712.7137184143066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3165}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1933.854341506958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3812}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Tyrann Mathieu", "latency_ms": 2456.125259399414, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tyrann Mathieu", "latency_ms": 3271.9688415527344, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 2479.523181915283, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1309}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 2947.7295875549316, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1968}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 2258.9478492736816, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2618}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 2752.746820449829, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3236}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 3609.720230102539, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3928}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "44", "latency_ms": 719.2587852478027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "six", "latency_ms": 1497.2898960113525, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "6", "latency_ms": 1429.4350147247314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1318}, "3": {"k": 3, "answer": "6", "latency_ms": 932.1484565734863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "six episodes", "latency_ms": 1529.6003818511963, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2633}, "5": {"k": 5, "answer": "Six episodes", "latency_ms": 1011.3368034362793, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3306}, "6": {"k": 6, "answer": "6 episodes", "latency_ms": 1558.7351322174072, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3923}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul Bamer's", "latency_ms": 1482.4037551879883, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Remarque's", "latency_ms": 2175.180673599243, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "Remarque's", "latency_ms": 2129.9588680267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Paul's", "latency_ms": 1250.7891654968262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Paul", "latency_ms": 1170.6511974334717, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2492}, "5": {"k": 5, "answer": "Paul's", "latency_ms": 1505.1684379577637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3117}, "6": {"k": 6, "answer": "Paul's", "latency_ms": 1937.1352195739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3670}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris", "latency_ms": 1175.9028434753418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Morris and the Anglins", "latency_ms": 3304.672956466675, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Morris and the Anglins", "latency_ms": 3136.6450786590576, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1175}, "3": {"k": 3, "answer": "Morris and the Anglins", "latency_ms": 3300.631523132324, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "John Paul Scott", "latency_ms": 2380.114793777466, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2497}, "5": {"k": 5, "answer": "John Paul Scott", "latency_ms": 2089.3049240112305, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3121}, "6": {"k": 6, "answer": "John Paul Scott", "latency_ms": 1809.950351715088, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3717}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF programs worldwide.", "latency_ms": 2590.8732414245605, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF", "latency_ms": 2355.9272289276123, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 718}, "2": {"k": 2, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world.", "latency_ms": 7517.597198486328, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1376}, "3": {"k": 3, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world.", "latency_ms": 9082.401514053345, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2106}, "4": {"k": 4, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world", "latency_ms": 7144.113063812256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2800}, "5": {"k": 5, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world", "latency_ms": 7931.517839431763, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3488}, "6": {"k": 6, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world", "latency_ms": 6727.414846420288, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4121}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Tablet in her left hand", "latency_ms": 2887.139320373535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Inside the statue", "latency_ms": 2133.659839630127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Inside the statue", "latency_ms": 2657.1953296661377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "on a tabula ansata", "latency_ms": 3658.649682998657, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "on a tabula ansata", "latency_ms": 3062.4241828918457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2421}, "5": {"k": 5, "answer": "on her tabula ansata", "latency_ms": 4152.7099609375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3013}, "6": {"k": 6, "answer": "on her tabula ansata", "latency_ms": 2667.1555042266846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "Milan-Cortina 2026, Sapporo 2030", "latency_ms": 8015.996694564819, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2598.5329151153564, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "Beijing, China, then unknown", "latency_ms": 4118.715763092041, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1236}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3253.608465194702, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2605.175733566284, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2912.1294021606445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3064}, "6": {"k": 6, "answer": "Beijing, then a city to be selected for 2026", "latency_ms": 8352.783679962158, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3726}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "October 22, 1981", "latency_ms": 2715.6975269317627, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "August 22, 1980", "latency_ms": 3306.3995838165283, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 631}, "2": {"k": 2, "answer": "August 22, 1980", "latency_ms": 3499.289035797119, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "August 22, 1980", "latency_ms": 4089.8709297180176, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1892}, "4": {"k": 4, "answer": "August 22, 1980", "latency_ms": 3400.867223739624, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2519}, "5": {"k": 5, "answer": "August 22, 1980", "latency_ms": 3214.486837387085, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3135}, "6": {"k": 6, "answer": "August 22, 1980", "latency_ms": 3199.740171432495, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3702}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "Stone Gothic arch bridge", "latency_ms": 2366.300582885742, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stone Bridge", "latency_ms": 2025.5937576293945, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 631}, "2": {"k": 2, "answer": "Historic bridge", "latency_ms": 1733.4342002868652, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "Historic Stone Bridge", "latency_ms": 2144.925594329834, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Historic bridge", "latency_ms": 1847.085952758789, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2679}, "5": {"k": 5, "answer": "Historic Stone Bridge", "latency_ms": 2645.3301906585693, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3335}, "6": {"k": 6, "answer": "Historic Stone Bridge", "latency_ms": 2169.3999767303467, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3913}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The Autocrat", "latency_ms": 1625.7355213165283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One person or a small elite.", "latency_ms": 3582.197904586792, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 674}, "2": {"k": 2, "answer": "One person or a small elite.", "latency_ms": 4461.756944656372, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1333}, "3": {"k": 3, "answer": "One person", "latency_ms": 1050.5409240722656, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "One person", "latency_ms": 1496.2375164031982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2632}, "5": {"k": 5, "answer": "One person", "latency_ms": 1944.108009338379, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3298}, "6": {"k": 6, "answer": "One person", "latency_ms": 2058.9118003845215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3952}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "Affluence and suburbanization.", "latency_ms": 4124.650955200195, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Stable jobs", "latency_ms": 2077.1965980529785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "Stable jobs", "latency_ms": 1089.1389846801758, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1368}, "3": {"k": 3, "answer": "Affluence", "latency_ms": 1989.2446994781494, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2077}, "4": {"k": 4, "answer": "Affluence", "latency_ms": 2717.5726890563965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2839}, "5": {"k": 5, "answer": "Affluence", "latency_ms": 2248.257637023926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3538}, "6": {"k": 6, "answer": "Affluence", "latency_ms": 2253.6442279815674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4241}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "Counterclockwise", "latency_ms": 1976.344108581543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Along its trajectory", "latency_ms": 1781.9697856903076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 595}, "2": {"k": 2, "answer": "Eastward", "latency_ms": 1500.9982585906982, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1147}, "3": {"k": 3, "answer": "Eastward", "latency_ms": 1700.3824710845947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1755}, "4": {"k": 4, "answer": "around", "latency_ms": 1201.2896537780762, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2362}, "5": {"k": 5, "answer": "around", "latency_ms": 1005.850076675415, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2993}, "6": {"k": 6, "answer": "around", "latency_ms": 1974.1723537445068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3595}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Statue of Freedom", "latency_ms": 2136.112928390503, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "The dome", "latency_ms": 1808.9354038238525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "Dome", "latency_ms": 1750.9398460388184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1312}, "3": {"k": 3, "answer": "Dome", "latency_ms": 1776.2269973754883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1965}, "4": {"k": 4, "answer": "The dome", "latency_ms": 1757.0321559906006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2548}, "5": {"k": 5, "answer": "The dome", "latency_ms": 1576.6994953155518, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3215}, "6": {"k": 6, "answer": "A bronze eagle", "latency_ms": 1469.1927433013916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3811}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "Taoyuan Leopards", "latency_ms": 3015.148401260376, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2405.388116836548, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "Los Angeles Lakers", "latency_ms": 3156.0490131378174, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1220}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2067.2051906585693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1985.4378700256348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2454}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2603.1973361968994, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3053}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2081.209659576416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3657}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "Rey Mysterio", "latency_ms": 2353.260278701782, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2315.293788909912, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "Rey Mysterio", "latency_ms": 2988.703966140747, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Rey Mysterio", "latency_ms": 2460.4763984680176, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1803}, "4": {"k": 4, "answer": "Rey Mysterio", "latency_ms": 2212.219715118408, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2411}, "5": {"k": 5, "answer": "Rey Mysterio", "latency_ms": 2514.309883117676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3012}, "6": {"k": 6, "answer": "Rey Mysterio", "latency_ms": 2170.718193054199, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3619}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 1636.3096237182617, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake of the Ozarks", "latency_ms": 2927.4415969848633, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Lake of the Ozarks", "latency_ms": 3283.6177349090576, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "Lake Mead", "latency_ms": 2113.009452819824, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "Lake Mead", "latency_ms": 1800.1930713653564, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "Lake Mead", "latency_ms": 1823.713779449463, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3145}, "6": {"k": 6, "answer": "Lake Mead", "latency_ms": 1672.4615097045898, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3752}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Tagore", "latency_ms": 2381.4961910247803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tagore", "latency_ms": 535.3126525878906, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 585}, "2": {"k": 2, "answer": "Tagore", "latency_ms": 2114.7398948669434, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tagore", "latency_ms": 2152.5216102600098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1860}, "4": {"k": 4, "answer": "Tagore", "latency_ms": 1822.6118087768555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2571}, "5": {"k": 5, "answer": "Tagore", "latency_ms": 1508.6946487426758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3232}, "6": {"k": 6, "answer": "Tagore", "latency_ms": 2074.4144916534424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3904}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "Geraldine Ferraro", "latency_ms": 1227.8368473052979, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Geraldine Ferraro", "latency_ms": 2941.4827823638916, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 682}, "2": {"k": 2, "answer": "Geraldine Ferraro", "latency_ms": 2755.122184753418, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1375}, "3": {"k": 3, "answer": "Geraldine Ferraro", "latency_ms": 3045.3884601593018, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2070}, "4": {"k": 4, "answer": "Geraldine Ferraro", "latency_ms": 2174.7758388519287, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2787}, "5": {"k": 5, "answer": "Geraldine Ferraro and George H.W. Bush", "latency_ms": 3940.7105445861816, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3497}, "6": {"k": 6, "answer": "Geraldine Ferraro, George H.W. Bush", "latency_ms": 4955.999374389648, "em": 0.0, "f1": 0.7499999999999999, "containment": 1.0, "context_chars": 4186}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "American Rock Salt mine, Livingston County, New York", "latency_ms": 3791.2113666534424, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Groveland", "latency_ms": 3316.093921661377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners", "latency_ms": 1657.522439956665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Hampton Corners", "latency_ms": 2757.113218307495, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1953}, "4": {"k": 4, "answer": "Hampton Corners", "latency_ms": 2395.71213722229, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2585}, "5": {"k": 5, "answer": "Hampton Corners", "latency_ms": 1957.7808380126953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3201}, "6": {"k": 6, "answer": "Hampton Corners", "latency_ms": 2091.5427207946777, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3790}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 1057.7821731567383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 2000.9257793426514, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 565}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 1772.78733253479, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1164}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 1755.3424835205078, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1754}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 1542.9019927978516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2371}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 2076.1618614196777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2961}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 2042.2651767730713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3623}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Meghalaya", "latency_ms": 1621.4137077331543, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bihar", "latency_ms": 2062.450408935547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 621}, "2": {"k": 2, "answer": "Meghalaya", "latency_ms": 2310.868263244629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Meghalaya", "latency_ms": 2344.4619178771973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1927}, "4": {"k": 4, "answer": "Meghalaya", "latency_ms": 2133.7921619415283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2569}, "5": {"k": 5, "answer": "Meghalaya", "latency_ms": 2373.9173412323, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Meghalaya", "latency_ms": 2126.981496810913, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3870}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Kanpur", "latency_ms": 1849.6618270874023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1944.7693824768066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1447.2553730010986, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2322.2572803497314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1842}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3207.946538925171, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2541}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1874.8128414154053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3196}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2984.2193126678467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3877}}}
