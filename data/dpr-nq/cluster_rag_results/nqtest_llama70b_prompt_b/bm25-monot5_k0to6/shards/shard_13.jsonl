{"qid": "175824256524792922", "question": "who plays harry's mom in harry potter", "gold_answers": ["Geraldine Margaret Agnew - Somerville"], "shots": {"0": {"k": 0, "answer": "Fiona Shaw", "latency_ms": 2402.9924869537354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Molly", "latency_ms": 1277.7273654937744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 607}, "2": {"k": 2, "answer": "Molly", "latency_ms": 2031.6791534423828, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1196}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2818.1252479553223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1813}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3040.6525135040283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2471.3892936706543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3099}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3860.414505004883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3727}}}
{"qid": "-8223571798173928629", "question": "who sang you'll be a woman soon in pulp fiction", "gold_answers": ["Urge Overkill", "rock band Urge Overkill"], "shots": {"0": {"k": 0, "answer": "Urge Overkill", "latency_ms": 2991.8088912963867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Urge Overkill", "latency_ms": 2281.4390659332275, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 653}, "2": {"k": 2, "answer": "Urge Overkill", "latency_ms": 2663.2285118103027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Urge Overkill", "latency_ms": 3022.341728210449, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1950}, "4": {"k": 4, "answer": "Urge Overkill", "latency_ms": 3112.5388145446777, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2572}, "5": {"k": 5, "answer": "Urge Overkill", "latency_ms": 3181.6153526306152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3204}, "6": {"k": 6, "answer": "Urge Overkill", "latency_ms": 2489.5682334899902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3867}}}
{"qid": "-8095180930653230478", "question": "where does a roadrunner live in the desert", "gold_answers": ["arid lowland", "mountainous shrubland"], "shots": {"0": {"k": 0, "answer": "Southwestern United States and Mexico", "latency_ms": 2824.7251510620117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4673.78830909729, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 684}, "2": {"k": 2, "answer": "arid lowland or mountainous shrubland", "latency_ms": 4752.143621444702, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1329}, "3": {"k": 3, "answer": "Arid lowland or mountainous shrubland", "latency_ms": 4402.091503143311, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 3570.6820487976074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2628}, "5": {"k": 5, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 5633.900880813599, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3315}, "6": {"k": 6, "answer": "Southwestern United States, Mexico, and Central America.", "latency_ms": 5025.432109832764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3929}}}
{"qid": "-5489426796364143729", "question": "who was the first president of the constituent assembly", "gold_answers": ["Dr. Rajendra Prasad"], "shots": {"0": {"k": 0, "answer": "Dr. Rajendra Prasad", "latency_ms": 3113.1043434143066, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rajendra Prasad", "latency_ms": 3005.366802215576, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 5014.888763427734, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1441}, "3": {"k": 3, "answer": "Dr. Rajendra Prasad", "latency_ms": 3609.9154949188232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2126}, "4": {"k": 4, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 4183.466672897339, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2764}, "5": {"k": 5, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 4610.405206680298, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3463}, "6": {"k": 6, "answer": "Dr. Sachchidananda Sinha", "latency_ms": 5535.597562789917, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4137}}}
{"qid": "7835345385704208729", "question": "when does the new episode of scorpion come on", "gold_answers": ["January 15 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2365.164279937744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2954.160451889038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "10pm", "latency_ms": 1527.7864933013916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "10pm (Eastern)", "latency_ms": 2801.1701107025146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2428.518772125244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2586}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2630.5863857269287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3277}, "6": {"k": 6, "answer": "September 22, 2014", "latency_ms": 3631.6442489624023, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3883}}}
{"qid": "907238223200158003", "question": "when did first fast and furious come out", "gold_answers": ["2001"], "shots": {"0": {"k": 0, "answer": "June 22, 2001", "latency_ms": 3580.592632293701, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2496.595859527588, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "1955", "latency_ms": 1799.0128993988037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1244}, "3": {"k": 3, "answer": "1955", "latency_ms": 2301.7916679382324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "June 22, 2001", "latency_ms": 3848.8566875457764, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2497}, "5": {"k": 5, "answer": "June 22, 2001", "latency_ms": 4291.968584060669, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3123}, "6": {"k": 6, "answer": "June 22, 2001", "latency_ms": 5205.22141456604, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3781}}}
{"qid": "-6782664238831495856", "question": "when does season 5 of the blacklist resume", "gold_answers": ["January 31 , 2018"], "shots": {"0": {"k": 0, "answer": "March 1, 2018", "latency_ms": 3681.3552379608154, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "September 27, 2017", "latency_ms": 4188.695192337036, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "September 27, 2017", "latency_ms": 3744.7938919067383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1361}, "3": {"k": 3, "answer": "September 27, 2017", "latency_ms": 3034.930944442749, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2033}, "4": {"k": 4, "answer": "September 27, 2017", "latency_ms": 4066.5674209594727, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2739}, "5": {"k": 5, "answer": "September 27, 2017", "latency_ms": 4195.104122161865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3445}, "6": {"k": 6, "answer": "September 27, 2017", "latency_ms": 3867.7313327789307, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4141}}}
{"qid": "3492797766982308854", "question": "when do mr schuester and emma get together", "gold_answers": ["the fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3.", "latency_ms": 1976.696252822876, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hell-O", "latency_ms": 1741.8251037597656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "mid-season finale episode \"Sectionals\"", "latency_ms": 4042.07706451416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "In \"Sectionals\"", "latency_ms": 3341.6974544525146, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1839}, "4": {"k": 4, "answer": "In \"Hell-O\"", "latency_ms": 3740.150213241577, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2430}, "5": {"k": 5, "answer": "In \"Sectionals\"", "latency_ms": 2717.029571533203, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3053}, "6": {"k": 6, "answer": "In Season 4", "latency_ms": 2223.1907844543457, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3691}}}
{"qid": "-2654989306076235475", "question": "when does the next episode of izombie air", "gold_answers": ["May 14 , 2018", "May 7 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2483.7043285369873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2885.2882385253906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 596}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3460.071802139282, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3167.680501937866, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3493.0241107940674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2543}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1521.4405059814453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 3466.8915271759033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3792}}}
{"qid": "3066393401707107613", "question": "where was the u.s.s maine when it exploded in 1898", "gold_answers": ["Havana Harbor"], "shots": {"0": {"k": 0, "answer": "Havana Harbor", "latency_ms": 2050.0452518463135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Havana Harbor, Cuba.", "latency_ms": 3575.178623199463, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 632}, "2": {"k": 2, "answer": "Havana Harbor, Cuba.", "latency_ms": 2804.382085800171, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1256}, "3": {"k": 3, "answer": "Havana Harbor", "latency_ms": 1822.2873210906982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1828}, "4": {"k": 4, "answer": "Havana Harbor", "latency_ms": 2604.888677597046, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2505}, "5": {"k": 5, "answer": "Havana Harbor", "latency_ms": 2088.8102054595947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3132}, "6": {"k": 6, "answer": "Havana Harbor", "latency_ms": 1904.8893451690674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3796}}}
{"qid": "6972056626325669866", "question": "in the honour of which god is anant chaturdashi celebrated", "gold_answers": ["Ganesh"], "shots": {"0": {"k": 0, "answer": "Vishnu", "latency_ms": 2172.131061553955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2569.84281539917, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 639}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2698.1329917907715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1272}, "3": {"k": 3, "answer": "No specific god mentioned", "latency_ms": 2502.042055130005, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1934}, "4": {"k": 4, "answer": "Vishnu", "latency_ms": 2351.5093326568604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2576}, "5": {"k": 5, "answer": "Vishnu", "latency_ms": 1849.9794006347656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3239}, "6": {"k": 6, "answer": "Lord Vishnu", "latency_ms": 2090.160131454468, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3905}}}
{"qid": "6043389452532567502", "question": "which central american nations border the pacific ocean and the caribbean sea", "gold_answers": ["Costa Rica", "Nicaragua"], "shots": {"0": {"k": 0, "answer": "Costa Rica, Nicaragua, Panama.", "latency_ms": 4213.045835494995, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "All of them", "latency_ms": 1347.7599620819092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 658}, "2": {"k": 2, "answer": "Costa Rica, Nicaragua, Panama, Honduras, Guatemala, El Salvador, Belize", "latency_ms": 6545.541286468506, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 1322}, "3": {"k": 3, "answer": "Costa Rica, Nicaragua", "latency_ms": 2934.5145225524902, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2007}, "4": {"k": 4, "answer": "Costa Rica, Nicaragua", "latency_ms": 3219.6638584136963, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2705}, "5": {"k": 5, "answer": "Costa Rica, Nicaragua", "latency_ms": 3262.5434398651123, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3397}, "6": {"k": 6, "answer": "Costa Rica, Nicaragua, Panama", "latency_ms": 4008.161783218384, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4029}}}
{"qid": "2541316470469570888", "question": "what kind of sentence contains an independent clause and a dependent clause", "gold_answers": ["A complex sentence", "complex sentence"], "shots": {"0": {"k": 0, "answer": "Complex sentence.", "latency_ms": 2119.884252548218, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Complex sentence", "latency_ms": 1745.6257343292236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Complex sentence", "latency_ms": 2264.1260623931885, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Complex sentence", "latency_ms": 2054.1515350341797, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1977}, "4": {"k": 4, "answer": "Complex sentence", "latency_ms": 2351.158380508423, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "Complex sentence", "latency_ms": 2179.0554523468018, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3371}, "6": {"k": 6, "answer": "Complex sentence", "latency_ms": 1238.0588054656982, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4067}}}
{"qid": "3239205946903665891", "question": "what was the book wealth of nations about", "gold_answers": ["what builds nations ' wealth"], "shots": {"0": {"k": 0, "answer": "Economics and capitalism.", "latency_ms": 2521.679401397705, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "the nature and causes of the wealth of nations", "latency_ms": 5934.399127960205, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 649}, "2": {"k": 2, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 4070.7693099975586, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1326}, "3": {"k": 3, "answer": "the Nature and Causes of the Wealth of Nations", "latency_ms": 4840.208053588867, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 1917}, "4": {"k": 4, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 4407.593250274658, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 2578}, "5": {"k": 5, "answer": "Nature and Causes of the Wealth of Nations", "latency_ms": 4204.755783081055, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3225}, "6": {"k": 6, "answer": "the nature and causes of the wealth of nations", "latency_ms": 3719.3779945373535, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 3841}}}
{"qid": "-4659426898177460954", "question": "when will the flash season 4 be released", "gold_answers": ["October 10 , 2017"], "shots": {"0": {"k": 0, "answer": "October 10, 2017", "latency_ms": 3303.6279678344727, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 10, 2017", "latency_ms": 3888.6873722076416, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "August 28, 2018", "latency_ms": 3968.971014022827, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1260}, "3": {"k": 3, "answer": "August 28, 2018", "latency_ms": 3989.2327785491943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1852}, "4": {"k": 4, "answer": "August 28, 2018", "latency_ms": 3857.945442199707, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2476}, "5": {"k": 5, "answer": "August 28, 2018", "latency_ms": 4352.818965911865, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "August 28, 2018", "latency_ms": 3728.121280670166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3769}}}
{"qid": "-1204722541964024977", "question": "what is australia's location in the world and region", "gold_answers": ["Oceania"], "shots": {"0": {"k": 0, "answer": "Oceania, Southern Hemisphere.", "latency_ms": 3380.1591396331787, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Australian state of Queensland", "latency_ms": 3067.8629875183105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Western Australia and Queensland", "latency_ms": 3152.801990509033, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1374}, "3": {"k": 3, "answer": "Southwestern most tip of Australia", "latency_ms": 3246.957540512085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2040}, "4": {"k": 4, "answer": "Australian state of Queensland and Western Australia", "latency_ms": 3302.887201309204, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2714}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2388.0298137664795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3367}, "6": {"k": 6, "answer": "Southwest corner of the world", "latency_ms": 3225.2535820007324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4042}}}
{"qid": "-6291722830448463311", "question": "who does luke skywalker fall in love with", "gold_answers": ["Mara Jade"], "shots": {"0": {"k": 0, "answer": "Mara Jade", "latency_ms": 2063.6792182922363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2957.002639770508, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "her", "latency_ms": 1250.9384155273438, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1205}, "3": {"k": 3, "answer": "her", "latency_ms": 1451.3120651245117, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1741}, "4": {"k": 4, "answer": "her", "latency_ms": 893.5585021972656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2312}, "5": {"k": 5, "answer": "her", "latency_ms": 1678.1973838806152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2909}, "6": {"k": 6, "answer": "her", "latency_ms": 1183.9711666107178, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3440}}}
{"qid": "-5631283176059213935", "question": "who was the original host of jokers wild", "gold_answers": ["Jack Barry"], "shots": {"0": {"k": 0, "answer": "Jack Barry", "latency_ms": 1876.5747547149658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jack Barry", "latency_ms": 2042.3524379730225, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Jack Barry", "latency_ms": 2031.5022468566895, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1229}, "3": {"k": 3, "answer": "Allen Ludden", "latency_ms": 2863.8792037963867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1779}, "4": {"k": 4, "answer": "Allen Ludden", "latency_ms": 2629.6188831329346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2424}, "5": {"k": 5, "answer": "Allen Ludden", "latency_ms": 2097.1481800079346, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3017}, "6": {"k": 6, "answer": "Allen Ludden", "latency_ms": 2324.01704788208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3633}}}
{"qid": "5360223163814883105", "question": "which organelle is the site of atp production and storage", "gold_answers": ["mitochondrion"], "shots": {"0": {"k": 0, "answer": "Mitochondria", "latency_ms": 1821.1655616760254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "mitochondria", "latency_ms": 2564.262628555298, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 674}, "2": {"k": 2, "answer": "mitochondria", "latency_ms": 2511.9988918304443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1325}, "3": {"k": 3, "answer": "Mitochondria, Chloroplasts", "latency_ms": 3958.0979347229004, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "Mitochondria and Chloroplasts", "latency_ms": 4401.719331741333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2693}, "5": {"k": 5, "answer": "Mitochondria and Chloroplast", "latency_ms": 3365.9043312072754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3377}, "6": {"k": 6, "answer": "Mitochondria and Chloroplast", "latency_ms": 4401.742935180664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4111}}}
{"qid": "-718217992489656032", "question": "five tools of security management to overcome computer crime", "gold_answers": ["post-evaluation", "operative planning", "implementation", "Pre-evaluation", "strategic planning"], "shots": {"0": {"k": 0, "answer": "Firewall, Encryption, Antivirus, Access Control, Intrusion Detection.", "latency_ms": 5859.756946563721, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2899.5132446289062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 707}, "2": {"k": 2, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 4266.058683395386, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1402}, "3": {"k": 3, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 3889.0950679779053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2091}, "4": {"k": 4, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 4318.8676834106445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2791}, "5": {"k": 5, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 4036.940097808838, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3484}, "6": {"k": 6, "answer": "crime, waste, accidents, errors, unethical practices", "latency_ms": 4082.0229053497314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4220}}}
{"qid": "5584540254904933863", "question": "who sang what are we doing in love", "gold_answers": ["Dottie West", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3405.0915241241455, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3388.533115386963, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 590}, "2": {"k": 2, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3966.130018234253, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3388.485908508301, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 1843}, "4": {"k": 4, "answer": "Kenny Rogers and Dottie West", "latency_ms": 4484.973192214966, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 2464}, "5": {"k": 5, "answer": "Kenny Rogers and Dottie West", "latency_ms": 3697.7529525756836, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3051}, "6": {"k": 6, "answer": "Dottie West and Kenny Rogers", "latency_ms": 4293.47562789917, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 3627}}}
{"qid": "97369777493072047", "question": "at what age are you no longer a toddler", "gold_answers": ["36 months"], "shots": {"0": {"k": 0, "answer": "3 years old", "latency_ms": 1917.3996448516846, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Three years old", "latency_ms": 1785.1989269256592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 689}, "2": {"k": 2, "answer": "36 months old", "latency_ms": 1721.5843200683594, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "36 months old", "latency_ms": 1865.4189109802246, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1911}, "4": {"k": 4, "answer": "36 months old", "latency_ms": 1779.7949314117432, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "36 months old", "latency_ms": 1862.0426654815674, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3077}, "6": {"k": 6, "answer": "36 months", "latency_ms": 2090.298891067505, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3660}}}
{"qid": "3537093784371401720", "question": "how many episodes are there in ordeal by innocence", "gold_answers": ["three", "three part"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 2174.755334854126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "3", "latency_ms": 681.3275814056396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 663}, "2": {"k": 2, "answer": "3", "latency_ms": 1738.0287647247314, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1311}, "3": {"k": 3, "answer": "3", "latency_ms": 1755.542278289795, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Three", "latency_ms": 931.2939643859863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2610}, "5": {"k": 5, "answer": "3", "latency_ms": 1250.0884532928467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3226}, "6": {"k": 6, "answer": "3", "latency_ms": 1692.570686340332, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3842}}}
{"qid": "-2126094349681352450", "question": "who played the hobbits in the lord of the rings", "gold_answers": ["Ian Holm", "Dominic Monaghan", "Elijah Wood as Frodo Baggins", "Sean Astin", "Elijah Wood", "Billy Boyd"], "shots": {"0": {"k": 0, "answer": "Elijah Wood, Sean Astin, Billy Boyd, Dominic Monaghan.", "latency_ms": 4900.841236114502, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Felix Felton", "latency_ms": 2155.0638675689697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "Felix Felton, Ian Holm, Elijah Wood", "latency_ms": 5146.062135696411, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Felix Felton, Paul Daneman, Ian Holm, Elijah Wood", "latency_ms": 6045.348644256592, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1886}, "4": {"k": 4, "answer": "Ian Holm, Elijah Wood", "latency_ms": 2862.9565238952637, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2472}, "5": {"k": 5, "answer": "Ian Holm, Elijah Wood", "latency_ms": 4058.7267875671387, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3146}, "6": {"k": 6, "answer": "Ian Holm, Elijah Wood", "latency_ms": 3434.9451065063477, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3812}}}
{"qid": "-6982991192528081677", "question": "what does fancy dress mean in the uk", "gold_answers": ["costumes", "A costume", "guests dress up in costumes"], "shots": {"0": {"k": 0, "answer": "Costume party.", "latency_ms": 2248.5475540161133, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Costume party", "latency_ms": 2357.6598167419434, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "Costume party", "latency_ms": 1616.8510913848877, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Costume party", "latency_ms": 2154.141664505005, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1861}, "4": {"k": 4, "answer": "Costume party", "latency_ms": 1617.7034378051758, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Costume party", "latency_ms": 2371.629238128662, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3207}, "6": {"k": 6, "answer": "Costume party", "latency_ms": 2602.6127338409424, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3778}}}
{"qid": "-6751220433242447969", "question": "how many seasons of the bastard executioner are there", "gold_answers": ["one season", "one"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 498.33083152770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One", "latency_ms": 1962.6967906951904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "One", "latency_ms": 692.878007888794, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1204}, "3": {"k": 3, "answer": "One", "latency_ms": 2276.1127948760986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1902}, "4": {"k": 4, "answer": "One", "latency_ms": 907.7050685882568, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2527}, "5": {"k": 5, "answer": "One", "latency_ms": 1229.6028137207031, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3159}, "6": {"k": 6, "answer": "One", "latency_ms": 1481.597661972046, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3782}}}
{"qid": "-7607921794902030568", "question": "why did jean valjean take care of cosette", "gold_answers": ["he had promised"], "shots": {"0": {"k": 0, "answer": "Gratitude to Fantine", "latency_ms": 3433.8762760162354, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2695.7767009735107, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Fantine's debts", "latency_ms": 1761.0037326812744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Fantine's debts", "latency_ms": 3021.4290618896484, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1865}, "4": {"k": 4, "answer": "Fantine's debts", "latency_ms": 2717.264413833618, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2503}, "5": {"k": 5, "answer": "Fantine's request", "latency_ms": 2820.659637451172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3130}, "6": {"k": 6, "answer": "Fantine's debts", "latency_ms": 2786.102294921875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3743}}}
{"qid": "-5341729935918652247", "question": "who does the democratic republic of congo trade with", "gold_answers": ["Belgium", "World Bank", "China", "Zambia", "African Development Bank", "SADC", "South Africa", "AU", "WTO", "France", "Kenya", "Zimbabwe", "Group of 77", "IMF"], "shots": {"0": {"k": 0, "answer": "China, Belgium, South Korea, Zambia, United States.", "latency_ms": 5094.599485397339, "em": 0.0, "f1": 0.25, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "India", "latency_ms": 1056.0555458068848, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 709}, "2": {"k": 2, "answer": "India and Kenya", "latency_ms": 1350.9154319763184, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1403}, "3": {"k": 3, "answer": "India and Kenya", "latency_ms": 2544.9929237365723, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2093}, "4": {"k": 4, "answer": "India and Kenya", "latency_ms": 1637.1495723724365, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 2743}, "5": {"k": 5, "answer": "India, Kenya, Russia", "latency_ms": 2658.8075160980225, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3444}, "6": {"k": 6, "answer": "India, Kenya, Russia", "latency_ms": 2677.067518234253, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 4072}}}
{"qid": "5518515944351776633", "question": "what was the purpose of the bantu education act", "gold_answers": ["enforcing racially separated educational facilities"], "shots": {"0": {"k": 0, "answer": "Segregation and oppression.", "latency_ms": 2747.976779937744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 5499.215602874756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 8234.634399414062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7771.196365356445, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2027}, "4": {"k": 4, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 8765.132904052734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2704}, "5": {"k": 5, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 8683.052778244019, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3441}, "6": {"k": 6, "answer": "to ensure blacks would have only just enough education to work as unskilled laborers", "latency_ms": 7727.911949157715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4119}}}
{"qid": "-4271099756149693907", "question": "what type of snake is kaa in jungle book", "gold_answers": ["Indian rock python"], "shots": {"0": {"k": 0, "answer": "Indian Rock Python", "latency_ms": 2075.5105018615723, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Huge and powerful snake", "latency_ms": 2899.4150161743164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 587}, "2": {"k": 2, "answer": "Huge and powerful snake", "latency_ms": 2488.9070987701416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1174}, "3": {"k": 3, "answer": "Huge and powerful snake", "latency_ms": 3434.849500656128, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1759}, "4": {"k": 4, "answer": "Indian python", "latency_ms": 1298.2523441314697, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "Indian python", "latency_ms": 2343.5540199279785, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3021}, "6": {"k": 6, "answer": "Indian python", "latency_ms": 1289.5457744598389, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3717}}}
{"qid": "-6527462410412242988", "question": "what is the snow on mars made of", "gold_answers": ["water ice", "Frozen carbon dioxide"], "shots": {"0": {"k": 0, "answer": "Dry ice", "latency_ms": 1544.0642833709717, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "water-ice", "latency_ms": 2095.954418182373, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 585}, "2": {"k": 2, "answer": "water-ice", "latency_ms": 2628.390073776245, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "water-ice", "latency_ms": 2346.7750549316406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1809}, "4": {"k": 4, "answer": "water-ice", "latency_ms": 2451.793909072876, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2382}, "5": {"k": 5, "answer": "water-ice", "latency_ms": 2168.666362762451, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3042}, "6": {"k": 6, "answer": "water-ice", "latency_ms": 1553.8759231567383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3655}}}
{"qid": "-2155345050664800035", "question": "when does elena turn into a vampire in the tv series", "gold_answers": ["season four", "fourth season"], "shots": {"0": {"k": 0, "answer": "Season 3, Episode 22.", "latency_ms": 3671.2021827697754, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Not in season 2.", "latency_ms": 3501.4102458953857, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "The Departed episode", "latency_ms": 2368.0291175842285, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "The Departed episode", "latency_ms": 2572.5226402282715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "The Departed episode", "latency_ms": 3133.685827255249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2379}, "5": {"k": 5, "answer": "The Departed episode", "latency_ms": 2690.133571624756, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2941}, "6": {"k": 6, "answer": "The Departed episode", "latency_ms": 2621.7308044433594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3525}}}
{"qid": "5491319565508469860", "question": "who gets first pick of fa cup games", "gold_answers": ["the BBC", "BBC"], "shots": {"0": {"k": 0, "answer": "The home team", "latency_ms": 1214.4560813903809, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2393.2859897613525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "ITV", "latency_ms": 1447.8414058685303, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "ITV", "latency_ms": 2031.7823886871338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1838}, "4": {"k": 4, "answer": "ITV", "latency_ms": 2009.7062587738037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2421}, "5": {"k": 5, "answer": "ITV", "latency_ms": 2234.118938446045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2995}, "6": {"k": 6, "answer": "ITV", "latency_ms": 1512.1121406555176, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3592}}}
{"qid": "-816889472900831237", "question": "what part of dc is howard university in", "gold_answers": ["northwest", "northwest Washington", "in northwest Washington"], "shots": {"0": {"k": 0, "answer": "Shaw.", "latency_ms": 2101.500988006592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Northwest", "latency_ms": 2048.2122898101807, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 670}, "2": {"k": 2, "answer": "Northwest Washington, DC", "latency_ms": 2939.620018005371, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Northwest", "latency_ms": 2320.8141326904297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2040}, "4": {"k": 4, "answer": "Northwest Washington, DC", "latency_ms": 2689.9402141571045, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2831}, "5": {"k": 5, "answer": "Northwest Washington, DC", "latency_ms": 2916.820526123047, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 3507}, "6": {"k": 6, "answer": "Northwest Washington, DC", "latency_ms": 3473.9646911621094, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 4217}}}
{"qid": "479254158383415496", "question": "what is the first covenant in the old testament", "gold_answers": ["the Noahic Covenant"], "shots": {"0": {"k": 0, "answer": "Adamic Covenant", "latency_ms": 1849.1530418395996, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Noahic", "latency_ms": 2367.246627807617, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 648}, "2": {"k": 2, "answer": "Noahic", "latency_ms": 2054.5780658721924, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "Noahic", "latency_ms": 1345.1037406921387, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "Noahic", "latency_ms": 1544.6014404296875, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2431}, "5": {"k": 5, "answer": "Noahic", "latency_ms": 2339.393138885498, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3042}, "6": {"k": 6, "answer": "Noahic", "latency_ms": 1533.4405899047852, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3695}}}
{"qid": "-8025421046364238920", "question": "who sings the theme song for living single", "gold_answers": ["Queen Latifah"], "shots": {"0": {"k": 0, "answer": "Queen Latifah", "latency_ms": 2294.268846511841, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1897.3655700683594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 577}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2535.6030464172363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1150}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2090.765953063965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1721}, "4": {"k": 4, "answer": "Jack Jones", "latency_ms": 1757.035732269287, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2354}, "5": {"k": 5, "answer": "a singer", "latency_ms": 1679.2726516723633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2940}, "6": {"k": 6, "answer": "a singer", "latency_ms": 1684.7054958343506, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3560}}}
{"qid": "-2347826883564742884", "question": "who said life is like a bowl of cherries", "gold_answers": ["Lew Brown"], "shots": {"0": {"k": 0, "answer": "Yip Harburg", "latency_ms": 1773.2737064361572, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rudy Vallée", "latency_ms": 2140.2523517608643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 590}, "2": {"k": 2, "answer": "Rudy Vallée", "latency_ms": 3158.22696685791, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "Rudy Vallée", "latency_ms": 2966.054677963257, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1846}, "4": {"k": 4, "answer": "Rudy Vallée", "latency_ms": 3149.8043537139893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2444}, "5": {"k": 5, "answer": "Rudy Vallée", "latency_ms": 2252.6378631591797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3079}, "6": {"k": 6, "answer": "Rudy Vallée", "latency_ms": 3789.576292037964, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3673}}}
{"qid": "2467509477831469982", "question": "where is fort myers located at in florida", "gold_answers": ["Lee County", "the Southwest"], "shots": {"0": {"k": 0, "answer": "Southwest Florida", "latency_ms": 816.2572383880615, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lee County", "latency_ms": 2262.401580810547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 615}, "2": {"k": 2, "answer": "Lee County", "latency_ms": 1797.7759838104248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1259}, "3": {"k": 3, "answer": "Lee County", "latency_ms": 1768.117904663086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1906}, "4": {"k": 4, "answer": "Lee County", "latency_ms": 1818.3619976043701, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2553}, "5": {"k": 5, "answer": "Southwest Florida", "latency_ms": 2859.9281311035156, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3161}, "6": {"k": 6, "answer": "Southwest Florida", "latency_ms": 1675.2007007598877, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3758}}}
{"qid": "4440911260005876349", "question": "state the position of india in terms of population size", "gold_answers": ["second"], "shots": {"0": {"k": 0, "answer": "Second", "latency_ms": 697.368860244751, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "50 million", "latency_ms": 1768.8794136047363, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 713}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2434.64994430542, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1306}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1808.9568614959717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1897}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2434.288740158081, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2516}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2121.920108795166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3143}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2189.1422271728516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3736}}}
{"qid": "3172949410241605868", "question": "who became a leader of the indian national congress", "gold_answers": ["Mahatma Gandhi"], "shots": {"0": {"k": 0, "answer": "Mahatma Gandhi", "latency_ms": 2419.4130897521973, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jawaharlal Nehru", "latency_ms": 3250.406503677368, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 673}, "2": {"k": 2, "answer": "Pattom A. Thanu Pillai", "latency_ms": 3825.988292694092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1355}, "3": {"k": 3, "answer": "Pattom A. Thanu Pillai", "latency_ms": 4087.2416496276855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2058}, "4": {"k": 4, "answer": "Pattom A. Thanu Pillai", "latency_ms": 4085.286855697632, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2766}, "5": {"k": 5, "answer": "Pattom A. Thanu Pillai", "latency_ms": 3720.787525177002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3373}, "6": {"k": 6, "answer": "Pattom A. Thanu Pillai", "latency_ms": 4068.406820297241, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4101}}}
{"qid": "-5136645336730213305", "question": "winner of worst cooks in america season 5", "gold_answers": ["Amber Brauner"], "shots": {"0": {"k": 0, "answer": "Jenae Anderson", "latency_ms": 1670.910358428955, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bobby Flay", "latency_ms": 2227.2095680236816, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "Bobby Flay", "latency_ms": 2323.7640857696533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Bobby Flay", "latency_ms": 2997.194528579712, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Bobby Flay", "latency_ms": 2118.638277053833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2550}, "5": {"k": 5, "answer": "Bobby Flay", "latency_ms": 1979.2301654815674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3158}, "6": {"k": 6, "answer": "Bobby Flay", "latency_ms": 2347.428321838379, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3763}}}
{"qid": "159123015669900402", "question": "what is the filename extension used for all java source files", "gold_answers": [". java"], "shots": {"0": {"k": 0, "answer": ".java", "latency_ms": 1715.0540351867676, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "codice_22", "latency_ms": 2458.8043689727783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 687}, "2": {"k": 2, "answer": ".java", "latency_ms": 1158.3011150360107, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1290}, "3": {"k": 3, "answer": ".java", "latency_ms": 1616.6496276855469, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1928}, "4": {"k": 4, "answer": ".java", "latency_ms": 1682.4672222137451, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": ".java", "latency_ms": 1160.6190204620361, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3195}, "6": {"k": 6, "answer": ".java", "latency_ms": 1403.5940170288086, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3911}}}
{"qid": "6860341019198485637", "question": "who cracked the enigma code in world war 2", "gold_answers": ["Turing"], "shots": {"0": {"k": 0, "answer": "Alan Turing", "latency_ms": 1590.2698040008545, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alan Turing", "latency_ms": 1529.0944576263428, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 654}, "2": {"k": 2, "answer": "Alan Turing", "latency_ms": 2202.0204067230225, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Alan Turing", "latency_ms": 2506.101369857788, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1915}, "4": {"k": 4, "answer": "Alan Turing", "latency_ms": 1757.3258876800537, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2519}, "5": {"k": 5, "answer": "Alan Turing", "latency_ms": 2526.6788005828857, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3187}, "6": {"k": 6, "answer": "Alan Turing", "latency_ms": 1515.8936977386475, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3876}}}
{"qid": "7990281571644070368", "question": "what is the job of the whip in congress", "gold_answers": ["to ensure party discipline"], "shots": {"0": {"k": 0, "answer": "Enforcing party discipline and counting votes.", "latency_ms": 4444.159746170044, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "ensure party members adhere to party policies", "latency_ms": 3153.879404067993, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 632}, "2": {"k": 2, "answer": "ensure members adhere to party policies", "latency_ms": 3041.2588119506836, "em": 0.0, "f1": 0.6, "containment": 0.0, "context_chars": 1293}, "3": {"k": 3, "answer": "to ensure members adhere to party policies", "latency_ms": 4211.281061172485, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 1937}, "4": {"k": 4, "answer": "to ensure members adhere to party policies", "latency_ms": 2860.4397773742676, "em": 0.0, "f1": 0.5454545454545454, "containment": 0.0, "context_chars": 2573}, "5": {"k": 5, "answer": "to make sure that House members vote in line with party leadership", "latency_ms": 5139.526128768921, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3223}, "6": {"k": 6, "answer": "to make sure that House members vote in line with party leadership", "latency_ms": 4591.1760330200195, "em": 0.0, "f1": 0.25, "containment": 0.0, "context_chars": 3947}}}
{"qid": "-3089533754017582743", "question": "when was the last time unc did not make the ncaa tournament", "gold_answers": ["2003"], "shots": {"0": {"k": 0, "answer": "2010", "latency_ms": 530.1482677459717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2284.9032878875732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "1973", "latency_ms": 1529.0124416351318, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1195}, "3": {"k": 3, "answer": "1973", "latency_ms": 1793.1928634643555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "1973", "latency_ms": 2208.9734077453613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "1973", "latency_ms": 1525.9134769439697, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3039}, "6": {"k": 6, "answer": "1993", "latency_ms": 1792.7260398864746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3675}}}
{"qid": "-3530165048900528552", "question": "which foreign currency option is the​ right but not the​ obligation to buy foreign​ currency", "gold_answers": ["foreign exchange option"], "shots": {"0": {"k": 0, "answer": "Call option", "latency_ms": 1819.7851181030273, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "FX option", "latency_ms": 1481.1301231384277, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 676}, "2": {"k": 2, "answer": "FX option", "latency_ms": 1540.4322147369385, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1364}, "3": {"k": 3, "answer": "FX option", "latency_ms": 1528.8739204406738, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "Call option", "latency_ms": 1852.7271747589111, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2702}, "5": {"k": 5, "answer": "Call option", "latency_ms": 1496.788740158081, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3265}, "6": {"k": 6, "answer": "FX option", "latency_ms": 1808.7773323059082, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3910}}}
{"qid": "2795932191977151266", "question": "how many house of representative do we have in nigeria", "gold_answers": ["360", "360 members"], "shots": {"0": {"k": 0, "answer": "360 members in 109 constituencies", "latency_ms": 2906.2771797180176, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "360 members", "latency_ms": 2018.2898044586182, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 721}, "2": {"k": 2, "answer": "360", "latency_ms": 1403.6943912506104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1380}, "3": {"k": 3, "answer": "360", "latency_ms": 1426.069736480713, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2010}, "4": {"k": 4, "answer": "360 members", "latency_ms": 1737.760066986084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2665}, "5": {"k": 5, "answer": "360 members", "latency_ms": 1007.3270797729492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3307}, "6": {"k": 6, "answer": "360", "latency_ms": 1972.8059768676758, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4001}}}
{"qid": "4714895284721516061", "question": "who was the actor who played grizzly adams", "gold_answers": ["`` Dan '' Haggerty"], "shots": {"0": {"k": 0, "answer": "Dan Haggerty", "latency_ms": 2137.474536895752, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Dan Haggerty", "latency_ms": 2270.5087661743164, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 615}, "2": {"k": 2, "answer": "Dan Haggerty", "latency_ms": 2010.1630687713623, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1266}, "3": {"k": 3, "answer": "Dan Haggerty", "latency_ms": 2078.1562328338623, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1918}, "4": {"k": 4, "answer": "Dan Haggerty", "latency_ms": 3475.980281829834, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2559}, "5": {"k": 5, "answer": "Dan Haggerty", "latency_ms": 2786.6358757019043, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3205}, "6": {"k": 6, "answer": "Dan Haggerty", "latency_ms": 2503.615379333496, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3856}}}
{"qid": "-6101054679785992133", "question": "who sings blame it on the bossa nova", "gold_answers": ["Eydie Gormé"], "shots": {"0": {"k": 0, "answer": "Eydie Gorme", "latency_ms": 3127.1800994873047, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Eydie Gormé", "latency_ms": 3221.074104309082, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 580}, "2": {"k": 2, "answer": "Eydie Gormé", "latency_ms": 4348.364353179932, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1211}, "3": {"k": 3, "answer": "Eydie Gormé", "latency_ms": 2757.070302963257, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1787}, "4": {"k": 4, "answer": "Eydie Gormé", "latency_ms": 3023.4155654907227, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2364}, "5": {"k": 5, "answer": "Eydie Gormé", "latency_ms": 2233.5612773895264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2981}, "6": {"k": 6, "answer": "Eydie Gormé", "latency_ms": 3019.5069313049316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3582}}}
{"qid": "1882117704293632224", "question": "who is the supreme court judge was a former chief justice of kerala high court", "gold_answers": ["Konakuppakatil Gopinathan Balakrishnan"], "shots": {"0": {"k": 0, "answer": "Kurian Joseph", "latency_ms": 2387.0203495025635, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "K. K. Usha", "latency_ms": 3282.9277515411377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 519}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2471.228837966919, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1132}, "3": {"k": 3, "answer": "K. K. Usha", "latency_ms": 3077.791452407837, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1756}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2678.36856842041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2317}, "5": {"k": 5, "answer": "Mohan Shantanagoudar", "latency_ms": 3862.3788356781006, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2929}, "6": {"k": 6, "answer": "Mohan Shantanagoudar", "latency_ms": 4272.22204208374, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3493}}}
{"qid": "2524852627963543698", "question": "who has won more grand slam titles in tennis", "gold_answers": ["Roger Federer"], "shots": {"0": {"k": 0, "answer": "Margaret Court", "latency_ms": 2912.121057510376, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Martina Navratilova", "latency_ms": 2316.136121749878, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 636}, "2": {"k": 2, "answer": "Nadal", "latency_ms": 1812.6730918884277, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1214}, "3": {"k": 3, "answer": "Roger Federer", "latency_ms": 1348.803997039795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1851}, "4": {"k": 4, "answer": "Roger Federer", "latency_ms": 2099.87735748291, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2410}, "5": {"k": 5, "answer": "Roger Federer", "latency_ms": 1895.9457874298096, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3008}, "6": {"k": 6, "answer": "Roger Federer", "latency_ms": 3335.623264312744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3594}}}
{"qid": "-6230694167244306035", "question": "how many times has the saints won the super bowl", "gold_answers": ["1"], "shots": {"0": {"k": 0, "answer": "1", "latency_ms": 1276.7252922058105, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1", "latency_ms": 941.5614604949951, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 608}, "2": {"k": 2, "answer": "1", "latency_ms": 1991.673469543457, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1228}, "3": {"k": 3, "answer": "1", "latency_ms": 892.4074172973633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1835}, "4": {"k": 4, "answer": "1", "latency_ms": 1422.5947856903076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2418}, "5": {"k": 5, "answer": "1", "latency_ms": 1710.9830379486084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3054}, "6": {"k": 6, "answer": "1", "latency_ms": 1193.838119506836, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3661}}}
{"qid": "4186485631454362041", "question": "when was the last time the los angeles lakers won a championship", "gold_answers": ["2010", "in 2010"], "shots": {"0": {"k": 0, "answer": "2020", "latency_ms": 922.5919246673584, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2000", "latency_ms": 1818.915605545044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "2000", "latency_ms": 1520.5833911895752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1204}, "3": {"k": 3, "answer": "2000", "latency_ms": 1983.37721824646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1826}, "4": {"k": 4, "answer": "2000", "latency_ms": 2233.1697940826416, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2351}, "5": {"k": 5, "answer": "2000", "latency_ms": 2282.437562942505, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2965}, "6": {"k": 6, "answer": "2000", "latency_ms": 1708.4851264953613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3565}}}
{"qid": "6332740420650663139", "question": "how many gold medals did australia win in the 2000 olympics", "gold_answers": ["16"], "shots": {"0": {"k": 0, "answer": "17", "latency_ms": 668.6639785766602, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2699.9974250793457, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 627}, "2": {"k": 2, "answer": "5", "latency_ms": 1246.9329833984375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "37 is for the US, 5", "latency_ms": 3715.6355381011963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1884}, "4": {"k": 4, "answer": "37", "latency_ms": 765.4471397399902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2527}, "5": {"k": 5, "answer": "37", "latency_ms": 1702.8775215148926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3203}, "6": {"k": 6, "answer": "37", "latency_ms": 922.6477146148682, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3872}}}
{"qid": "-2418032234376469176", "question": "where is the eagle creek fire located in oregon", "gold_answers": ["Cascade Locks", "Columbia River Gorge"], "shots": {"0": {"k": 0, "answer": "Columbia River Gorge", "latency_ms": 3167.597770690918, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Columbia River Gorge", "latency_ms": 2464.830160140991, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 624}, "2": {"k": 2, "answer": "Columbia River Gorge", "latency_ms": 2500.6582736968994, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Columbia River Gorge", "latency_ms": 2283.1461429595947, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1882}, "4": {"k": 4, "answer": "Columbia River Gorge", "latency_ms": 1617.2988414764404, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2512}, "5": {"k": 5, "answer": "Columbia River Gorge", "latency_ms": 2551.219940185547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3163}, "6": {"k": 6, "answer": "Columbia River Gorge", "latency_ms": 2881.44588470459, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3814}}}
{"qid": "-2622854017829301835", "question": "different ways to spell corey for a boy", "gold_answers": ["Kori", "Cory", "Kory", "Coire", "Corrie", "Correy", "Corie", "Corey", "Khouri"], "shots": {"0": {"k": 0, "answer": "Corey, Cory, Korey, Kory", "latency_ms": 4627.651929855347, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Corey, Cory", "latency_ms": 1958.137035369873, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 619}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1615.6573295593262, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1182}, "3": {"k": 3, "answer": "Corey, Cory", "latency_ms": 2952.812671661377, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1783}, "4": {"k": 4, "answer": "Corey, Cory", "latency_ms": 2173.786401748657, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2419}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2226.9179821014404, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3011}, "6": {"k": 6, "answer": "Corey, Cory", "latency_ms": 2410.944700241089, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3596}}}
{"qid": "3480908309420822259", "question": "who sang the song should have been a cowboy", "gold_answers": ["Toby Keith"], "shots": {"0": {"k": 0, "answer": "Toby Keith", "latency_ms": 1728.8157939910889, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1397.8297710418701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2448.481798171997, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1228}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2575.4876136779785, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3145.7550525665283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2415}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2679.7738075256348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3127}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2925.2474308013916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3748}}}
{"qid": "-4198273171611748168", "question": "how many counties does the state of georgia have", "gold_answers": ["159", "159 counties"], "shots": {"0": {"k": 0, "answer": "159", "latency_ms": 1510.984182357788, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "159", "latency_ms": 1022.7928161621094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 622}, "2": {"k": 2, "answer": "159", "latency_ms": 2259.6912384033203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "159", "latency_ms": 1714.2972946166992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1997}, "4": {"k": 4, "answer": "159", "latency_ms": 1408.5299968719482, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2708}, "5": {"k": 5, "answer": "159", "latency_ms": 2222.787857055664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3443}, "6": {"k": 6, "answer": "159", "latency_ms": 1760.5619430541992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4090}}}
{"qid": "2077711785168359308", "question": "who sang picking up pebbles and throwing them into the sea", "gold_answers": ["Matt Flinders"], "shots": {"0": {"k": 0, "answer": "Bobby Vinton", "latency_ms": 2686.68270111084, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Egan", "latency_ms": 1475.210189819336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 581}, "2": {"k": 2, "answer": "Egan", "latency_ms": 1795.3896522521973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1181}, "3": {"k": 3, "answer": "Egan", "latency_ms": 1816.2636756896973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1701}, "4": {"k": 4, "answer": "Egan", "latency_ms": 1574.1610527038574, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2317}, "5": {"k": 5, "answer": "Egan", "latency_ms": 1586.3828659057617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2889}, "6": {"k": 6, "answer": "Egan", "latency_ms": 2032.1733951568604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3427}}}
{"qid": "9062886943819260445", "question": "who made the most free throws in nba history", "gold_answers": ["Karl Malone"], "shots": {"0": {"k": 0, "answer": "Karl Malone", "latency_ms": 2084.8240852355957, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2895.7252502441406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 591}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1854.1338443756104, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1219}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2126.7449855804443, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1805}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2453.974962234497, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2383}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1769.2172527313232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2948}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2682.9633712768555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3548}}}
{"qid": "1278533364941960992", "question": "which is the ring finger for male in india", "gold_answers": ["the left ring finger", "left ring finger"], "shots": {"0": {"k": 0, "answer": "Anamika finger", "latency_ms": 1695.0013637542725, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Right hand", "latency_ms": 1775.651216506958, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 583}, "2": {"k": 2, "answer": "Right hand", "latency_ms": 1935.2757930755615, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1137}, "3": {"k": 3, "answer": "Right hand", "latency_ms": 1793.1933403015137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1701}, "4": {"k": 4, "answer": "Right hand", "latency_ms": 1854.0503978729248, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2255}, "5": {"k": 5, "answer": "Right hand", "latency_ms": 1625.723123550415, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2857}, "6": {"k": 6, "answer": "Right hand", "latency_ms": 1439.422607421875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3451}}}
{"qid": "-8788207958970648395", "question": "what disney cartoon character's middle name is fauntleroy", "gold_answers": ["Donald Fauntleroy Duck", "Donald Duck"], "shots": {"0": {"k": 0, "answer": "Donald Fauntleroy Duck", "latency_ms": 2831.700563430786, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Donald Duck", "latency_ms": 2243.2005405426025, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 647}, "2": {"k": 2, "answer": "Donald Duck", "latency_ms": 1771.4142799377441, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1293}, "3": {"k": 3, "answer": "Donald Duck", "latency_ms": 1347.4674224853516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1945}, "4": {"k": 4, "answer": "Donald Duck", "latency_ms": 2880.793571472168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2597}, "5": {"k": 5, "answer": "Donald Duck", "latency_ms": 1252.9022693634033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3236}, "6": {"k": 6, "answer": "Donald Duck", "latency_ms": 2028.4671783447266, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3851}}}
{"qid": "-4323000711881657078", "question": "who played king theoden in lord of the rings", "gold_answers": ["Bernard Hill"], "shots": {"0": {"k": 0, "answer": "Bernard Mayes", "latency_ms": 2845.3876972198486, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bernard Mayes", "latency_ms": 3179.1322231292725, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "Bernard Mayes", "latency_ms": 2704.7793865203857, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1206}, "3": {"k": 3, "answer": "Bernard Mayes", "latency_ms": 2972.0427989959717, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Bernard Mayes", "latency_ms": 2775.2017974853516, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2470}, "5": {"k": 5, "answer": "Bernard Mayes", "latency_ms": 2388.91339302063, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "Bernard Mayes", "latency_ms": 3172.9822158813477, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3679}}}
{"qid": "-2664158830468622213", "question": "dark parables return of the salt princess release date", "gold_answers": ["September 2017"], "shots": {"0": {"k": 0, "answer": "March 22, 2018", "latency_ms": 4016.735792160034, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2018", "latency_ms": 4067.6326751708984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 573}, "2": {"k": 2, "answer": "March 15, 2018", "latency_ms": 4414.610862731934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1169}, "3": {"k": 3, "answer": "March 15, 2018", "latency_ms": 3320.2664852142334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "March 15, 2018", "latency_ms": 4124.450206756592, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2404}, "5": {"k": 5, "answer": "March 15, 2018", "latency_ms": 4324.1143226623535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3055}, "6": {"k": 6, "answer": "March 15, 2018", "latency_ms": 2860.7630729675293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3661}}}
{"qid": "9078092620239351027", "question": "where was the movie 500 days of summer filmed", "gold_answers": ["Los Angeles"], "shots": {"0": {"k": 0, "answer": "Los Angeles", "latency_ms": 2320.8961486816406, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2417.2348976135254, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2709.777355194092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1270}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2165.4481887817383, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1909}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2744.5263862609863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2600}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2052.7377128601074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1612.367868423462, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3825}}}
{"qid": "4747795168824294053", "question": "who played emma in h2o just add water", "gold_answers": ["Claire Rhiannon Holt"], "shots": {"0": {"k": 0, "answer": "Claire Holt", "latency_ms": 1899.275541305542, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Claire Holt", "latency_ms": 1793.0879592895508, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 618}, "2": {"k": 2, "answer": "Claire Holt", "latency_ms": 2136.4543437957764, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "Claire Holt", "latency_ms": 2144.644260406494, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1835}, "4": {"k": 4, "answer": "Claire Holt", "latency_ms": 2587.946891784668, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2471}, "5": {"k": 5, "answer": "Claire Holt", "latency_ms": 2281.172752380371, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3111}, "6": {"k": 6, "answer": "Claire Holt", "latency_ms": 2676.305055618286, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3750}}}
{"qid": "-1368633715963532113", "question": "where can carbon be found in the biosphere", "gold_answers": ["other living organisms", "plants", "soil", "The terrestrial biosphere"], "shots": {"0": {"k": 0, "answer": "All living organisms.", "latency_ms": 2870.2497482299805, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "in wood or soil", "latency_ms": 2753.486394882202, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 705}, "2": {"k": 2, "answer": "in wood or soil", "latency_ms": 2329.4713497161865, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 1407}, "3": {"k": 3, "answer": "in wood, soil, plants, and animals' digestive tracts", "latency_ms": 5569.331169128418, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 2057}, "4": {"k": 4, "answer": "in wood, soil, plants, and animals", "latency_ms": 4125.9870529174805, "em": 0.0, "f1": 0.2857142857142857, "containment": 1.0, "context_chars": 2742}, "5": {"k": 5, "answer": "in all land-living organisms, soils, and water bodies", "latency_ms": 6000.180244445801, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 3462}, "6": {"k": 6, "answer": "in all land-living organisms, soils, and water bodies", "latency_ms": 4776.586294174194, "em": 0.0, "f1": 0.18181818181818182, "containment": 1.0, "context_chars": 4116}}}
{"qid": "-1173252802989599019", "question": "who is the winner of bigg boss kannada season", "gold_answers": ["rapper Chandan Shetty", "Chandan Shetty"], "shots": {"0": {"k": 0, "answer": "Vijay Raghavendra", "latency_ms": 3245.56827545166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Akul Balaji", "latency_ms": 2917.125463485718, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "Akul Balaji", "latency_ms": 2436.0921382904053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1324}, "3": {"k": 3, "answer": "Akul Balaji", "latency_ms": 2212.3794555664062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "Akul Balaji", "latency_ms": 2115.154266357422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "Akul Balaji", "latency_ms": 2338.017225265503, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Akul Balaji", "latency_ms": 2680.485486984253, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3817}}}
{"qid": "-8950878510839541193", "question": "where was the outlaw of josey wales filmed", "gold_answers": ["Utah", "Arizona", "Kanab , Utah", "Lake Powell", "Wyoming", "Oroville , California"], "shots": {"0": {"k": 0, "answer": "Arizona, California, and Utah", "latency_ms": 2333.3778381347656, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jackson County", "latency_ms": 1773.031234741211, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 616}, "2": {"k": 2, "answer": "Clay County", "latency_ms": 1338.6166095733643, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Kanab, Utah", "latency_ms": 2292.030096054077, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1863}, "4": {"k": 4, "answer": "Kanab, Utah", "latency_ms": 1709.155559539795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2490}, "5": {"k": 5, "answer": "Kanab, Utah, and neighboring Clay County.", "latency_ms": 4926.869630813599, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3115}, "6": {"k": 6, "answer": "Kanab, Utah", "latency_ms": 2674.506664276123, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3730}}}
{"qid": "445108246725869963", "question": "who plays the dad in the new beauty and the beast", "gold_answers": ["Kevin Kline"], "shots": {"0": {"k": 0, "answer": "Kevin Kline", "latency_ms": 2129.788398742676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jesper Klein", "latency_ms": 1655.9340953826904, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2386.972188949585, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1335}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 3183.0897331237793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1932}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2823.897123336792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2963.693141937256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3255}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2347.8610515594482, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3896}}}
{"qid": "-5745040113272333526", "question": "where does the saskatchewan river start and end", "gold_answers": ["the Hudson Bay", "central Saskatchewan", "Saskatchewan River Forks , Saskatchewan", "Saskatchewan Glacier , Alberta"], "shots": {"0": {"k": 0, "answer": "Saskatchewan, Canada to Lake Winnipeg.", "latency_ms": 4292.431592941284, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Saskatchewan Glacier to Rocky Mountain House", "latency_ms": 5228.427410125732, "em": 0.0, "f1": 0.4444444444444444, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 2591.287851333618, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 1300}, "3": {"k": 3, "answer": "at the confluence of its two main tributaries, Hudson Bay", "latency_ms": 6908.912658691406, "em": 0.0, "f1": 0.3636363636363636, "containment": 0.0, "context_chars": 1964}, "4": {"k": 4, "answer": "Canadian Rockies to Lake Winnipeg", "latency_ms": 1970.2355861663818, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2674}, "5": {"k": 5, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 2989.7446632385254, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 3279}, "6": {"k": 6, "answer": "Canadian Rockies to Hudson Bay", "latency_ms": 3032.08589553833, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 4009}}}
{"qid": "2370076891269438265", "question": "where are the spanish steps located in italy", "gold_answers": ["Rome"], "shots": {"0": {"k": 0, "answer": "Rome", "latency_ms": 786.405086517334, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rome", "latency_ms": 2011.7084980010986, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 611}, "2": {"k": 2, "answer": "Rome", "latency_ms": 971.6100692749023, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1242}, "3": {"k": 3, "answer": "Rome, Italy", "latency_ms": 2390.9614086151123, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1816}, "4": {"k": 4, "answer": "Rome, Italy", "latency_ms": 1942.7568912506104, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2417}, "5": {"k": 5, "answer": "Rome, Italy", "latency_ms": 2251.3842582702637, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3068}, "6": {"k": 6, "answer": "Rome, Italy", "latency_ms": 2135.4057788848877, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3755}}}
{"qid": "-1701212376306091221", "question": "what does the m number mean on a pint glass", "gold_answers": ["imperial fluid ounces", "the manufacturing company or site"], "shots": {"0": {"k": 0, "answer": "CE Mark or Measure number", "latency_ms": 2758.3940029144287, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "batch code", "latency_ms": 1793.0431365966797, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "manufacturing company or site", "latency_ms": 2141.3567066192627, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1255}, "3": {"k": 3, "answer": "manufacturing company or site", "latency_ms": 1706.4073085784912, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "the manufacturing company or site", "latency_ms": 2387.4475955963135, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2500}, "5": {"k": 5, "answer": "the manufacturing company or site", "latency_ms": 2828.6077976226807, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3089}, "6": {"k": 6, "answer": "the manufacturing company or site", "latency_ms": 2698.998212814331, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3710}}}
{"qid": "3631867991857999976", "question": "other than water what else has hydrogen bonds", "gold_answers": ["inorganic molecules such as water"], "shots": {"0": {"k": 0, "answer": "Ammonia, methanol.", "latency_ms": 2872.504949569702, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hydrogen fluoride, ammonia, methanol", "latency_ms": 3678.9791584014893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "hydrogen fluoride, ammonia and methanol", "latency_ms": 4201.609373092651, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 3861.1671924591064, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "Hydrogen fluoride, ammonia, methanol", "latency_ms": 4430.2051067352295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "Hydrogen fluoride, ammonia, methanol, DNA, proteins", "latency_ms": 6220.345258712769, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3212}, "6": {"k": 6, "answer": "Hydrogen fluoride, ammonia, methanol, DNA, proteins", "latency_ms": 5351.87292098999, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3812}}}
{"qid": "-1665528830781573810", "question": "when boy meets girl waiting for a star to fall", "gold_answers": ["1988"], "shots": {"0": {"k": 0, "answer": "Once in a Lifetime", "latency_ms": 1856.3880920410156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1988", "latency_ms": 1815.3438568115234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 584}, "2": {"k": 2, "answer": "1988", "latency_ms": 1483.8860034942627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1173}, "3": {"k": 3, "answer": "1988", "latency_ms": 1500.4291534423828, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1785}, "4": {"k": 4, "answer": "1988", "latency_ms": 2052.922487258911, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2409}, "5": {"k": 5, "answer": "1988", "latency_ms": 1933.9869022369385, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3012}, "6": {"k": 6, "answer": "1988", "latency_ms": 2130.356550216675, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3628}}}
{"qid": "4289442278067074619", "question": "trick taking card game name derived from spanish for man", "gold_answers": ["Skat"], "shots": {"0": {"k": 0, "answer": "Hombre", "latency_ms": 1208.8184356689453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tute", "latency_ms": 1830.1432132720947, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 569}, "2": {"k": 2, "answer": "Truco", "latency_ms": 1813.7376308441162, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1168}, "3": {"k": 3, "answer": "Manille", "latency_ms": 1306.039810180664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1763}, "4": {"k": 4, "answer": "Manille", "latency_ms": 2039.7486686706543, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2363}, "5": {"k": 5, "answer": "Manille", "latency_ms": 1270.2381610870361, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2949}, "6": {"k": 6, "answer": "Manille", "latency_ms": 1843.1615829467773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3609}}}
{"qid": "-7311149600272472027", "question": "what percentage of the population is naturally blonde", "gold_answers": ["2 %"], "shots": {"0": {"k": 0, "answer": "2-6%", "latency_ms": 1747.00927734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2207.1361541748047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 604}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2836.3757133483887, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1222}, "3": {"k": 3, "answer": "5%", "latency_ms": 1271.0371017456055, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1853}, "4": {"k": 4, "answer": "2% to 16%", "latency_ms": 3277.1246433258057, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "2% to 16%", "latency_ms": 3381.3111782073975, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3092}, "6": {"k": 6, "answer": "2% to 16%", "latency_ms": 3332.165479660034, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3724}}}
{"qid": "7110705857253017304", "question": "when was the last time miss texas won miss america", "gold_answers": ["1975"], "shots": {"0": {"k": 0, "answer": "1971", "latency_ms": 1310.7280731201172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2712.209939956665, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 608}, "2": {"k": 2, "answer": "1970", "latency_ms": 1980.8650016784668, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1278}, "3": {"k": 3, "answer": "1971", "latency_ms": 1776.9432067871094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1906}, "4": {"k": 4, "answer": "1971", "latency_ms": 1954.6561241149902, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2510}, "5": {"k": 5, "answer": "1971", "latency_ms": 1677.9708862304688, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3133}, "6": {"k": 6, "answer": "1971", "latency_ms": 1510.5607509613037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3692}}}
{"qid": "-3653614166480549899", "question": "who sang first line of we are the world", "gold_answers": ["Billy Joel", "Stevie Wonder", "Lionel Richie", "James Ingram", "Tina Turner", "Paul Simon", "Kenny Rogers"], "shots": {"0": {"k": 0, "answer": "Lionel Richie", "latency_ms": 2991.633653640747, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2722.609758377075, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 605}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2941.378593444824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1252}, "3": {"k": 3, "answer": "Lionel Richie", "latency_ms": 2617.638349533081, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1848}, "4": {"k": 4, "answer": "Lionel Richie", "latency_ms": 2424.015998840332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2467}, "5": {"k": 5, "answer": "Lionel Richie", "latency_ms": 2700.8609771728516, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3062}, "6": {"k": 6, "answer": "Lionel Richie", "latency_ms": 2989.326000213623, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3679}}}
{"qid": "-6284503594240226071", "question": "who formed and first came to the colony of maryland", "gold_answers": ["the English"], "shots": {"0": {"k": 0, "answer": "Cecil Calvert, 2nd Baron Baltimore", "latency_ms": 3874.7191429138184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Cecil Calvert and Catholic settlers", "latency_ms": 4882.143497467041, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Cecil Calvert", "latency_ms": 2145.48921585083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1336}, "3": {"k": 3, "answer": "Cecil Calvert and Lord Baltimore's first settlers, including Leonard Calvert.", "latency_ms": 7326.121091842651, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1966}, "4": {"k": 4, "answer": "Cecil Calvert", "latency_ms": 2153.0213356018066, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2617}, "5": {"k": 5, "answer": "Cecil Calvert and Leonard Calvert", "latency_ms": 5044.323921203613, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3294}, "6": {"k": 6, "answer": "Cecil Calvert and his brother Leonard Calvert", "latency_ms": 4741.6651248931885, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3952}}}
{"qid": "6948592513354589991", "question": "who has played in the most masters tournaments", "gold_answers": ["Gary Player"], "shots": {"0": {"k": 0, "answer": "Gary Player and Fred Couples and Gary Player and  Miguel Angel Jimenez and  Bernhard Langer", "latency_ms": 7410.70032119751, "em": 0.0, "f1": 0.2352941176470588, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tiger Woods", "latency_ms": 1848.095178604126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 619}, "2": {"k": 2, "answer": "Tiger Woods", "latency_ms": 1384.2308521270752, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Tiger Woods", "latency_ms": 2376.774787902832, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1923}, "4": {"k": 4, "answer": "Tiger Woods", "latency_ms": 1821.9048976898193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Tiger Woods", "latency_ms": 2392.6658630371094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3188}, "6": {"k": 6, "answer": "Tiger Woods", "latency_ms": 1880.0756931304932, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3848}}}
{"qid": "3311962143974666464", "question": "how much venom can a king cobra produce", "gold_answers": ["200 to 500 mg", "420 mg", "up to 7 ml"], "shots": {"0": {"k": 0, "answer": "400-600 mg", "latency_ms": 1897.7315425872803, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "200 to 500 mg", "latency_ms": 3490.7734394073486, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 620}, "2": {"k": 2, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 5632.926464080811, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "200 to 500 mg", "latency_ms": 2530.6854248046875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1930}, "4": {"k": 4, "answer": "200 to 500 mg", "latency_ms": 2999.8066425323486, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 5392.081499099731, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3228}, "6": {"k": 6, "answer": "200 to 500 mg up to 7 ml", "latency_ms": 5332.098484039307, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3816}}}
{"qid": "4829683075369336935", "question": "last team to win fa cup outside top flight", "gold_answers": ["Arsenal", "West Ham United"], "shots": {"0": {"k": 0, "answer": "Wimbledon (1988)", "latency_ms": 2730.682373046875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "West Ham United", "latency_ms": 2638.1242275238037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 586}, "2": {"k": 2, "answer": "West Ham United", "latency_ms": 2296.9799041748047, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1105}, "3": {"k": 3, "answer": "West Ham United", "latency_ms": 1794.7664260864258, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1685}, "4": {"k": 4, "answer": "West Ham United", "latency_ms": 3138.881206512451, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2245}, "5": {"k": 5, "answer": "West Ham United", "latency_ms": 1722.4211692810059, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2887}, "6": {"k": 6, "answer": "West Ham United", "latency_ms": 2371.612787246704, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3467}}}
{"qid": "947113025953164512", "question": "where did you go to drink during prohibition", "gold_answers": ["Speakeasies"], "shots": {"0": {"k": 0, "answer": "Speakeasy", "latency_ms": 2215.2953147888184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "hotel beverage rooms", "latency_ms": 2017.0972347259521, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 685}, "2": {"k": 2, "answer": "Windsor", "latency_ms": 1856.586217880249, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1369}, "3": {"k": 3, "answer": "Windsor", "latency_ms": 2604.340076446533, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1993}, "4": {"k": 4, "answer": "Windsor", "latency_ms": 2396.1358070373535, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2668}, "5": {"k": 5, "answer": "Windsor", "latency_ms": 2861.814260482788, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3361}, "6": {"k": 6, "answer": "Windsor", "latency_ms": 2425.6832599639893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4082}}}
{"qid": "2162587275527723755", "question": "where does the edinburgh fringe festival take place", "gold_answers": ["in Edinburgh , Scotland"], "shots": {"0": {"k": 0, "answer": "Edinburgh, Scotland", "latency_ms": 2442.2898292541504, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edinburgh, Scotland", "latency_ms": 2332.242488861084, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 694}, "2": {"k": 2, "answer": "Edinburgh, Scotland", "latency_ms": 2408.0591201782227, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1379}, "3": {"k": 3, "answer": "Edinburgh, Scotland", "latency_ms": 3133.045196533203, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2057}, "4": {"k": 4, "answer": "Edinburgh, Scotland", "latency_ms": 2605.445384979248, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2730}, "5": {"k": 5, "answer": "Edinburgh, Scotland", "latency_ms": 1855.3521633148193, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3428}, "6": {"k": 6, "answer": "Edinburgh, Scotland", "latency_ms": 2691.0452842712402, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 4106}}}
{"qid": "1875157261182375834", "question": "who won the wwe championship elimination chamber 2018", "gold_answers": ["Roman Reigns"], "shots": {"0": {"k": 0, "answer": "Roman Reigns", "latency_ms": 2161.0891819000244, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alexa Bliss", "latency_ms": 2066.9708251953125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2481.234550476074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1262}, "3": {"k": 3, "answer": "Alexa Bliss", "latency_ms": 2383.117198944092, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1889}, "4": {"k": 4, "answer": "Roman Reigns", "latency_ms": 1264.9281024932861, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2596}, "5": {"k": 5, "answer": "Roman Reigns", "latency_ms": 2351.184129714966, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3264}, "6": {"k": 6, "answer": "Roman Reigns", "latency_ms": 2608.4187030792236, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3881}}}
{"qid": "8926902974073457645", "question": "where does safe haven take place in the book", "gold_answers": ["Southport , North Carolina"], "shots": {"0": {"k": 0, "answer": "Southport, North Carolina", "latency_ms": 3186.555862426758, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Southport, North Carolina", "latency_ms": 3226.419687271118, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "Southport, North Carolina.", "latency_ms": 3460.153341293335, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Southport, North Carolina.", "latency_ms": 3105.4604053497314, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "Southport, North Carolina", "latency_ms": 3739.7329807281494, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2425}, "5": {"k": 5, "answer": "Southport, North Carolina.", "latency_ms": 3044.914484024048, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3028}, "6": {"k": 6, "answer": "Southport, North Carolina.", "latency_ms": 3636.2318992614746, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3649}}}
{"qid": "8445703091969850957", "question": "who came up with the term baby boomer", "gold_answers": ["The Washington Post"], "shots": {"0": {"k": 0, "answer": "Landon Jones", "latency_ms": 2486.471176147461, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2454.111099243164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 705}, "2": {"k": 2, "answer": "Sylvia F. Porter", "latency_ms": 3037.7116203308105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1318}, "3": {"k": 3, "answer": "Sylvia F. Porter", "latency_ms": 3275.3825187683105, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1984}, "4": {"k": 4, "answer": "Sylvia F. Porter", "latency_ms": 3047.8031635284424, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2645}, "5": {"k": 5, "answer": "Sylvia F. Porter", "latency_ms": 3992.4561977386475, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3327}, "6": {"k": 6, "answer": "Sylvia F. Porter", "latency_ms": 3015.8097743988037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3932}}}
{"qid": "-2961860751699827965", "question": "who was elected president of the united states in 1928", "gold_answers": ["Herbert Hoover"], "shots": {"0": {"k": 0, "answer": "Herbert Hoover", "latency_ms": 1832.2663307189941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Herbert Hoover", "latency_ms": 2068.436622619629, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 735}, "2": {"k": 2, "answer": "Herbert Hoover", "latency_ms": 2625.9078979492188, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1441}, "3": {"k": 3, "answer": "Herbert Hoover", "latency_ms": 2086.818218231201, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2187}, "4": {"k": 4, "answer": "Herbert Hoover", "latency_ms": 2568.5033798217773, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2881}, "5": {"k": 5, "answer": "Herbert Hoover", "latency_ms": 1635.0102424621582, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3642}, "6": {"k": 6, "answer": "Herbert Hoover", "latency_ms": 1358.1676483154297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4403}}}
{"qid": "-3997272399784107764", "question": "dogs name in the grinch who stole christmas", "gold_answers": ["Max"], "shots": {"0": {"k": 0, "answer": "Max", "latency_ms": 1027.91428565979, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Max", "latency_ms": 875.1201629638672, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "Max", "latency_ms": 1470.9153175354004, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1271}, "3": {"k": 3, "answer": "Max", "latency_ms": 1711.374044418335, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1872}, "4": {"k": 4, "answer": "Max", "latency_ms": 1199.112892150879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2493}, "5": {"k": 5, "answer": "Max", "latency_ms": 1544.9888706207275, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3097}, "6": {"k": 6, "answer": "Max", "latency_ms": 1493.7496185302734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3716}}}
{"qid": "119543419987074002", "question": "who played anne in anne with an e", "gold_answers": ["Amybeth McNulty"], "shots": {"0": {"k": 0, "answer": "Amybeth McNulty", "latency_ms": 1989.2246723175049, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2374.797582626343, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 655}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1843.6076641082764, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2585.301160812378, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1935}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2379.696846008301, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2534}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2627.286911010742, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3156}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2385.234594345093, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3815}}}
{"qid": "4362450141225960365", "question": "what was going on in the world in 1900", "gold_answers": ["Boxer Rebellion", "U.S. population exceeds 75 million", "Galveston hurricane"], "shots": {"0": {"k": 0, "answer": "Boxer Rebellion.", "latency_ms": 3132.2896480560303, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1900 Summer Olympics", "latency_ms": 2904.2434692382812, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "1900 Summer Olympics", "latency_ms": 3417.3638820648193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "Summer Olympics in Paris", "latency_ms": 1658.881664276123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1930}, "4": {"k": 4, "answer": "Summer Olympics in Paris", "latency_ms": 2197.309970855713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2635}, "5": {"k": 5, "answer": "Summer Olympics in Paris", "latency_ms": 3489.940881729126, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3326}, "6": {"k": 6, "answer": "Summer Olympics", "latency_ms": 1553.558588027954, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4010}}}
{"qid": "-599106694350296477", "question": "theme of the song roar by katy perry", "gold_answers": ["standing up for oneself", "self - empowerment"], "shots": {"0": {"k": 0, "answer": "Empowerment", "latency_ms": 2164.435386657715, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Empowerment", "latency_ms": 1652.3840427398682, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Empowerment", "latency_ms": 2441.8859481811523, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Empowerment", "latency_ms": 1860.901117324829, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1905}, "4": {"k": 4, "answer": "Empowerment", "latency_ms": 2319.159984588623, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2487}, "5": {"k": 5, "answer": "Empowerment", "latency_ms": 1344.592571258545, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3112}, "6": {"k": 6, "answer": "Empowerment", "latency_ms": 1830.2631378173828, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3787}}}
{"qid": "6341281025332348318", "question": "who picks the players in the nfl draft", "gold_answers": ["each team"], "shots": {"0": {"k": 0, "answer": "NFL teams' front offices", "latency_ms": 2715.2934074401855, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "National Football League teams", "latency_ms": 2434.3953132629395, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "National Football League teams", "latency_ms": 1917.9675579071045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1229}, "3": {"k": 3, "answer": "National Football League teams", "latency_ms": 1997.9121685028076, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1863}, "4": {"k": 4, "answer": "National Football League teams", "latency_ms": 2158.919334411621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2451}, "5": {"k": 5, "answer": "National Football League teams", "latency_ms": 2539.8738384246826, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3069}, "6": {"k": 6, "answer": "National Football League teams", "latency_ms": 2132.3938369750977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3686}}}
{"qid": "1656636013570720778", "question": "who discovered gold in the sierra nevada of california", "gold_answers": ["James W. Marshall"], "shots": {"0": {"k": 0, "answer": "James W. Marshall", "latency_ms": 2659.752368927002, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1967.9508209228516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1628.4496784210205, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1305}, "3": {"k": 3, "answer": "James Marshall", "latency_ms": 1301.8317222595215, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1961}, "4": {"k": 4, "answer": "James Marshall", "latency_ms": 1817.88969039917, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2617}, "5": {"k": 5, "answer": "James Marshall", "latency_ms": 1779.8621654510498, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3191}, "6": {"k": 6, "answer": "James Marshall", "latency_ms": 2244.71116065979, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3743}}}
{"qid": "6797662554091549033", "question": "which mirror is used in vehicles for rear view", "gold_answers": ["rear - view mirror"], "shots": {"0": {"k": 0, "answer": "Convex Mirror", "latency_ms": 2120.9397315979004, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rear-view mirror", "latency_ms": 2943.2101249694824, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "Rear-view mirror", "latency_ms": 2759.754180908203, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1233}, "3": {"k": 3, "answer": "Rear-view mirror", "latency_ms": 1678.194284439087, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1859}, "4": {"k": 4, "answer": "Rear-view mirror", "latency_ms": 1697.868824005127, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2523}, "5": {"k": 5, "answer": "Rear-view mirror", "latency_ms": 2896.456003189087, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3154}, "6": {"k": 6, "answer": "Rear-view mirror", "latency_ms": 2163.965940475464, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3800}}}
{"qid": "7788386234127027369", "question": "how many medals did austria win in the 2011 alpine skiing world championships", "gold_answers": ["8"], "shots": {"0": {"k": 0, "answer": "9", "latency_ms": 1458.937644958496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2494.856834411621, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 579}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2996.0501194000244, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1158}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1985.3465557098389, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1756}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2156.719207763672, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2372}, "5": {"k": 5, "answer": "All five ski jumping gold medals.", "latency_ms": 3485.7616424560547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3035}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1537.6529693603516, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3689}}}
{"qid": "647605647914971565", "question": "who wrote lyrics for phantom of the opera", "gold_answers": ["Richard Stilgoe", "Charles Hart and Richard Stilgoe", "Charles Hart"], "shots": {"0": {"k": 0, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3437.0272159576416, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Charles Hart", "latency_ms": 1563.035488128662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 662}, "2": {"k": 2, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3675.5027770996094, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1281}, "3": {"k": 3, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 3583.0249786376953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1952}, "4": {"k": 4, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4053.394556045532, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2631}, "5": {"k": 5, "answer": "Charles Hart", "latency_ms": 1230.0541400909424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3306}, "6": {"k": 6, "answer": "Charles Hart and Richard Stilgoe", "latency_ms": 4150.389909744263, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3997}}}
{"qid": "-7980433566693172177", "question": "what culture region is germany a part of", "gold_answers": ["Central Germany"], "shots": {"0": {"k": 0, "answer": "Western Europe", "latency_ms": 1259.6843242645264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Central Germany", "latency_ms": 2002.0685195922852, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 646}, "2": {"k": 2, "answer": "Central Germany", "latency_ms": 1510.5180740356445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1292}, "3": {"k": 3, "answer": "Central Germany", "latency_ms": 1558.3624839782715, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2003}, "4": {"k": 4, "answer": "Central Germany", "latency_ms": 828.0911445617676, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2657}, "5": {"k": 5, "answer": "Central Germany", "latency_ms": 2199.6586322784424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3288}, "6": {"k": 6, "answer": "Central Germany", "latency_ms": 1395.977258682251, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4016}}}
{"qid": "6268706985209815767", "question": "mount and blade with fire and sword time period", "gold_answers": ["1648 - 51"], "shots": {"0": {"k": 0, "answer": "17th century", "latency_ms": 2008.2483291625977, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "post-medieval era", "latency_ms": 2889.902114868164, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 659}, "2": {"k": 2, "answer": "post-medieval era", "latency_ms": 1958.899736404419, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "post-medieval era", "latency_ms": 2619.736909866333, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1954}, "4": {"k": 4, "answer": "1648–1651", "latency_ms": 2512.49361038208, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2631}, "5": {"k": 5, "answer": "1648–1651", "latency_ms": 3266.331911087036, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3309}, "6": {"k": 6, "answer": "1648–1651", "latency_ms": 3267.564296722412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3902}}}
