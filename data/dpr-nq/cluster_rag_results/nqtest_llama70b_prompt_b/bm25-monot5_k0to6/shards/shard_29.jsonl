{"qid": "3012568508229512715", "question": "when does like cage season 2 come out", "gold_answers": ["June 22 , 2018"], "shots": {"0": {"k": 0, "answer": "June 15, 2023", "latency_ms": 3322.5812911987305, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "June 22, 2018", "latency_ms": 3358.565330505371, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "June 22, 2018", "latency_ms": 4418.75696182251, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1267}, "3": {"k": 3, "answer": "June 22, 2018", "latency_ms": 3050.7805347442627, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1922}, "4": {"k": 4, "answer": "June 22, 2018", "latency_ms": 3869.3699836730957, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2531}, "5": {"k": 5, "answer": "June 22, 2018", "latency_ms": 3570.12939453125, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3170}, "6": {"k": 6, "answer": "June 22, 2018", "latency_ms": 3568.1943893432617, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3788}}}
{"qid": "839669511198247322", "question": "types of skiing in the winter olympics 2018", "gold_answers": ["Super-G", "Slalom -- ( SC )", "Downhill", "Giant slalom", "Slalom"], "shots": {"0": {"k": 0, "answer": "Alpine, Cross-Country, Freestyle, Nordic Combined, Ski Jumping, Biathlon.", "latency_ms": 8032.181978225708, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Alpine skiing", "latency_ms": 1813.4703636169434, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 630}, "2": {"k": 2, "answer": "Alpine skiing", "latency_ms": 1637.5904083251953, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Alpine, Freestyle", "latency_ms": 2457.034111022949, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1888}, "4": {"k": 4, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 3085.394859313965, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2564}, "5": {"k": 5, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 3649.2795944213867, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3223}, "6": {"k": 6, "answer": "Alpine skiing, Freestyle skiing", "latency_ms": 3048.8879680633545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3886}}}
{"qid": "-5881961149303861412", "question": "who played gino in a place to call home", "gold_answers": ["Aldo Mignone"], "shots": {"0": {"k": 0, "answer": "Arianwen Parkes-Lockwood", "latency_ms": 3029.402732849121, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Aldo Mignone", "latency_ms": 3305.2449226379395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 694}, "2": {"k": 2, "answer": "Aldo Mignone", "latency_ms": 3621.567964553833, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1367}, "3": {"k": 3, "answer": "Aldo Mignone", "latency_ms": 4290.0872230529785, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1897}, "4": {"k": 4, "answer": "Aldo Mignone", "latency_ms": 3088.5369777679443, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2564}, "5": {"k": 5, "answer": "Aldo Mignone", "latency_ms": 3295.91965675354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3137}, "6": {"k": 6, "answer": "Aldo Mignone", "latency_ms": 2531.280279159546, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3789}}}
{"qid": "-9077495306870424234", "question": "who did the 49ers beat in the super bowls", "gold_answers": ["San Diego Chargers", "Miami Dolphins", "Denver Broncos", "Cincinnati Bengals"], "shots": {"0": {"k": 0, "answer": "Bengals, Dolphins, Broncos, Chargers.", "latency_ms": 4309.514999389648, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Bengals", "latency_ms": 2534.2512130737305, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 620}, "2": {"k": 2, "answer": "Bengals, Dolphins", "latency_ms": 2742.4731254577637, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1269}, "3": {"k": 3, "answer": "Bengals, Dolphins", "latency_ms": 2824.8836994171143, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1860}, "4": {"k": 4, "answer": "Miami Dolphins, Bengals", "latency_ms": 2676.0318279266357, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2414}, "5": {"k": 5, "answer": "Miami Dolphins, Denver Broncos", "latency_ms": 3208.8751792907715, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3042}, "6": {"k": 6, "answer": "Miami Dolphins, Denver Broncos", "latency_ms": 2796.449661254883, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3660}}}
{"qid": "-5623229691925051533", "question": "when was the south asian association for regional co-operation (saarc) formed", "gold_answers": ["December 1985", "8 December 1985"], "shots": {"0": {"k": 0, "answer": "December 8, 1985", "latency_ms": 3120.687484741211, "em": 0.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 3443.5875415802, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 695}, "2": {"k": 2, "answer": "8 December 1985", "latency_ms": 3094.5823192596436, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1424}, "3": {"k": 3, "answer": "8 December 1985", "latency_ms": 4051.931858062744, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2144}, "4": {"k": 4, "answer": "8 December 1985", "latency_ms": 3262.6161575317383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2845}, "5": {"k": 5, "answer": "8 December 1985", "latency_ms": 3329.3442726135254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3484}, "6": {"k": 6, "answer": "8 December 1985", "latency_ms": 2025.9919166564941, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4210}}}
{"qid": "8707879945343660137", "question": "what hangs from the trees in the bayou", "gold_answers": ["Spanish moss"], "shots": {"0": {"k": 0, "answer": "Spanish Moss", "latency_ms": 1784.3189239501953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Spanish moss", "latency_ms": 1449.6145248413086, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 651}, "2": {"k": 2, "answer": "Spanish moss", "latency_ms": 1787.7388000488281, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1295}, "3": {"k": 3, "answer": "Spanish moss", "latency_ms": 1730.8604717254639, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1939}, "4": {"k": 4, "answer": "Spanish moss", "latency_ms": 1764.591932296753, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2570}, "5": {"k": 5, "answer": "Spanish moss", "latency_ms": 2074.918508529663, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3309}, "6": {"k": 6, "answer": "Spanish moss", "latency_ms": 2099.552869796753, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3987}}}
{"qid": "-731256923033768782", "question": "new york heart association functional classification of angina", "gold_answers": ["II"], "shots": {"0": {"k": 0, "answer": "I-IV", "latency_ms": 1650.256872177124, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Canadian Cardiovascular Society", "latency_ms": 1872.6043701171875, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 762}, "2": {"k": 2, "answer": "Canadian Cardiovascular Society", "latency_ms": 1846.3175296783447, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1494}, "3": {"k": 3, "answer": "Canadian Cardiovascular Society", "latency_ms": 2393.2857513427734, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2250}, "4": {"k": 4, "answer": "Canadian Cardiovascular Society grading", "latency_ms": 2156.5234661102295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2959}, "5": {"k": 5, "answer": "Canadian Cardiovascular Society", "latency_ms": 2874.50909614563, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3606}, "6": {"k": 6, "answer": "Canadian Cardiovascular Society grading", "latency_ms": 2498.905897140503, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4395}}}
{"qid": "-5350413673278085389", "question": "who wrote the song would i lie to you", "gold_answers": ["Mike Leeson", "Peter Vale"], "shots": {"0": {"k": 0, "answer": "Mick Hucknall and Neil Moss", "latency_ms": 3731.7492961883545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2400.919198989868, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 623}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3449.8212337493896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1872.0805644989014, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1840}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2657.8235626220703, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2442}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 1763.0558013916016, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3052}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1626.7974376678467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3708}}}
{"qid": "-6190173184813176768", "question": "number of films in lord of the rings", "gold_answers": ["three"], "shots": {"0": {"k": 0, "answer": "3", "latency_ms": 718.1940078735352, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1875.5395412445068, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 597}, "2": {"k": 2, "answer": "3", "latency_ms": 856.3036918640137, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1231}, "3": {"k": 3, "answer": "3", "latency_ms": 1135.8675956726074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1837}, "4": {"k": 4, "answer": "3", "latency_ms": 1199.8345851898193, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2442}, "5": {"k": 5, "answer": "3", "latency_ms": 1151.7958641052246, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3038}, "6": {"k": 6, "answer": "3", "latency_ms": 2226.9492149353027, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3691}}}
{"qid": "8239463385147663167", "question": "is jaffa cakes a biscuit or a cake", "gold_answers": ["cakes", "Cake", "biscuit - sized cakes"], "shots": {"0": {"k": 0, "answer": "A cake.", "latency_ms": 1356.4200401306152, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Biscuit-sized cakes", "latency_ms": 3002.347707748413, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 604}, "2": {"k": 2, "answer": "cake", "latency_ms": 962.3899459838867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1184}, "3": {"k": 3, "answer": "cake", "latency_ms": 1497.985601425171, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1764}, "4": {"k": 4, "answer": "A cake", "latency_ms": 766.6692733764648, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2345}, "5": {"k": 5, "answer": "A cake", "latency_ms": 2016.1011219024658, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2986}, "6": {"k": 6, "answer": "A cake.", "latency_ms": 1081.3546180725098, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3681}}}
{"qid": "756385103791298508", "question": "who does the voice of stewie family guy", "gold_answers": ["Seth MacFarlane"], "shots": {"0": {"k": 0, "answer": "Seth MacFarlane", "latency_ms": 1466.2144184112549, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Seth MacFarlane", "latency_ms": 2422.8034019470215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "Seth MacFarlane", "latency_ms": 1696.1572170257568, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1285}, "3": {"k": 3, "answer": "Seth MacFarlane", "latency_ms": 2931.9231510162354, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1926}, "4": {"k": 4, "answer": "Seth MacFarlane", "latency_ms": 2710.832118988037, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2550}, "5": {"k": 5, "answer": "Seth MacFarlane", "latency_ms": 2973.9561080932617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3184}, "6": {"k": 6, "answer": "Seth MacFarlane", "latency_ms": 2365.5483722686768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3850}}}
{"qid": "7355457342276623885", "question": "what drug does the mom use in requiem for a dream", "gold_answers": ["weight - loss amphetamines", "amphetamines"], "shots": {"0": {"k": 0, "answer": "Heroin", "latency_ms": 1285.9244346618652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Amphetamines", "latency_ms": 2604.154586791992, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 609}, "2": {"k": 2, "answer": "Amphetamines", "latency_ms": 2872.666597366333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1186}, "3": {"k": 3, "answer": "Amphetamines", "latency_ms": 2368.87264251709, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1794}, "4": {"k": 4, "answer": "Amphetamines", "latency_ms": 1866.5847778320312, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2436}, "5": {"k": 5, "answer": "Amphetamines", "latency_ms": 2404.200553894043, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3116}, "6": {"k": 6, "answer": "Amphetamines", "latency_ms": 2057.0623874664307, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3735}}}
{"qid": "-251770629620567718", "question": "how long was dark side of the moon number 1", "gold_answers": ["42 : 49", "a week"], "shots": {"0": {"k": 0, "answer": "15 weeks", "latency_ms": 1215.252161026001, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2570.406436920166, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 601}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2657.560110092163, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1213}, "3": {"k": 3, "answer": "Not stated", "latency_ms": 2308.546543121338, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1786}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1340.0368690490723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2390}, "5": {"k": 5, "answer": "only a week", "latency_ms": 1849.9770164489746, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2958}, "6": {"k": 6, "answer": "1 week", "latency_ms": 2305.818796157837, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3577}}}
{"qid": "3227997019205769806", "question": "where is the snooker world open currently held", "gold_answers": ["Hainan International Exhibition Center", "Haikou"], "shots": {"0": {"k": 0, "answer": "Yushan, China", "latency_ms": 2683.4213733673096, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Haikou", "latency_ms": 2144.7994709014893, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 573}, "2": {"k": 2, "answer": "Yushan, China", "latency_ms": 2580.265760421753, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1202}, "3": {"k": 3, "answer": "Yushan, China.", "latency_ms": 2864.706039428711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1817}, "4": {"k": 4, "answer": "Yushan, China", "latency_ms": 2760.8611583709717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2434}, "5": {"k": 5, "answer": "Yushan, China", "latency_ms": 2810.1627826690674, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3038}, "6": {"k": 6, "answer": "Yushan, China", "latency_ms": 2831.393003463745, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3680}}}
{"qid": "8499576329103738172", "question": "who is the actor that plays jt on the young and the restless", "gold_answers": ["Thaddeus Rowe Luckinbill"], "shots": {"0": {"k": 0, "answer": "Thad Luckinbill", "latency_ms": 2002.0363330841064, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1946.8834400177002, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 588}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2647.6237773895264, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1259}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2199.007511138916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1862}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2760.5957984924316, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2463}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2344.2351818084717, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3098}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2641.1867141723633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3758}}}
{"qid": "4230593664190705298", "question": "when was the first commercial cell phone released", "gold_answers": ["1983", "1973"], "shots": {"0": {"k": 0, "answer": "1983", "latency_ms": 1040.2495861053467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "1983", "latency_ms": 1455.5463790893555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "1986", "latency_ms": 1372.9808330535889, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "1973", "latency_ms": 2252.216339111328, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1853}, "4": {"k": 4, "answer": "1986", "latency_ms": 2089.3712043762207, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2528}, "5": {"k": 5, "answer": "1973", "latency_ms": 1322.6675987243652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3124}, "6": {"k": 6, "answer": "1973", "latency_ms": 1776.5684127807617, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3769}}}
{"qid": "2241516377343726249", "question": "who sings the theme song for degrassi the next generation", "gold_answers": ["The Degrassi Junior Strings", "Jakalope"], "shots": {"0": {"k": 0, "answer": "J-Rock", "latency_ms": 1841.4826393127441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Jakalope, Damhnait Doyle", "latency_ms": 3456.268072128296, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Jakalope, Damhnait Doyle, Alexz Johnson", "latency_ms": 5773.746013641357, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "Damhnait Doyle", "latency_ms": 2640.910863876343, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "Damhnait Doyle", "latency_ms": 2300.0926971435547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2598}, "5": {"k": 5, "answer": "Damhnait Doyle, Jakalope, Alexz Johnson", "latency_ms": 4216.499328613281, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3268}, "6": {"k": 6, "answer": "Damhnait Doyle, Jakalope, Alexz Johnson", "latency_ms": 5136.563539505005, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3879}}}
{"qid": "8179100082271836759", "question": "when did the first ice age come out", "gold_answers": ["March 15 , 2002", "2002"], "shots": {"0": {"k": 0, "answer": "March 15, 2002", "latency_ms": 2766.517162322998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "March 15, 2002", "latency_ms": 3542.556047439575, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 629}, "2": {"k": 2, "answer": "March 15, 2002", "latency_ms": 3513.2386684417725, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1257}, "3": {"k": 3, "answer": "March 15, 2002", "latency_ms": 3665.138006210327, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1822}, "4": {"k": 4, "answer": "March 15, 2002", "latency_ms": 3024.9640941619873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2449}, "5": {"k": 5, "answer": "June 1995", "latency_ms": 2468.8563346862793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3091}, "6": {"k": 6, "answer": "March 15, 2002", "latency_ms": 5204.463958740234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3707}}}
{"qid": "-1946900884888632776", "question": "what is a e8 in the marine corps", "gold_answers": ["Master sergeant", "First sergeant"], "shots": {"0": {"k": 0, "answer": "Master Sergeant", "latency_ms": 1532.6733589172363, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Master Sergeant", "latency_ms": 2024.9927043914795, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 616}, "2": {"k": 2, "answer": "Master Sergeant", "latency_ms": 2522.810935974121, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1336}, "3": {"k": 3, "answer": "Master Sergeant", "latency_ms": 2051.5053272247314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1912}, "4": {"k": 4, "answer": "Master Sergeant", "latency_ms": 1605.8785915374756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2484}, "5": {"k": 5, "answer": "Master Sergeant", "latency_ms": 2106.3833236694336, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3052}, "6": {"k": 6, "answer": "First Sergeant", "latency_ms": 1817.9571628570557, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "8538836642175821278", "question": "who is given credit for the gnu initiative", "gold_answers": ["Richard Stallman"], "shots": {"0": {"k": 0, "answer": "Richard Stallman", "latency_ms": 2136.6734504699707, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "GNU project", "latency_ms": 1476.0041236877441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "Richard Stallman", "latency_ms": 2644.1643238067627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1316}, "3": {"k": 3, "answer": "Richard Stallman", "latency_ms": 2106.8756580352783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1973}, "4": {"k": 4, "answer": "Richard Stallman", "latency_ms": 2680.3228855133057, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2584}, "5": {"k": 5, "answer": "Richard Stallman", "latency_ms": 2389.378309249878, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3249}, "6": {"k": 6, "answer": "Richard Stallman", "latency_ms": 1366.8982982635498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3886}}}
{"qid": "-170392909557030937", "question": "who won the 10m air pistol gold medal at commonwealth shooting championship in brisbane australia", "gold_answers": ["Shahzar Rizvi"], "shots": {"0": {"k": 0, "answer": "Manu Bhaker", "latency_ms": 2668.935775756836, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Heena Sidhu", "latency_ms": 2459.6810340881348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 580}, "2": {"k": 2, "answer": "Heena Sidhu", "latency_ms": 2071.2192058563232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1164}, "3": {"k": 3, "answer": "Heena Sidhu", "latency_ms": 2379.4803619384766, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1777}, "4": {"k": 4, "answer": "Heena Sidhu", "latency_ms": 2295.6290245056152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2408}, "5": {"k": 5, "answer": "Heena Sidhu", "latency_ms": 2671.2400913238525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3018}, "6": {"k": 6, "answer": "Heena Sidhu", "latency_ms": 1978.891134262085, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3627}}}
{"qid": "-7137073055537137289", "question": "who is the lead singer of collective soul", "gold_answers": ["Ed Roland"], "shots": {"0": {"k": 0, "answer": "Ed Roland", "latency_ms": 1031.3889980316162, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ed Roland", "latency_ms": 1987.6797199249268, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Ed Roland", "latency_ms": 1992.0611381530762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1278}, "3": {"k": 3, "answer": "Ed Roland", "latency_ms": 1775.5134105682373, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1916}, "4": {"k": 4, "answer": "Ed Roland", "latency_ms": 1784.562349319458, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2592}, "5": {"k": 5, "answer": "Ed Roland", "latency_ms": 1797.273874282837, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3220}, "6": {"k": 6, "answer": "Ed Roland", "latency_ms": 1783.1590175628662, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3849}}}
{"qid": "7198381700174721586", "question": "who does dwyane wade play for right now", "gold_answers": ["the Miami Heat", "Miami Heat"], "shots": {"0": {"k": 0, "answer": "Retired", "latency_ms": 1251.4476776123047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2570.319414138794, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 609}, "2": {"k": 2, "answer": "Miami Heat", "latency_ms": 2263.22603225708, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1231}, "3": {"k": 3, "answer": "Miami Heat", "latency_ms": 2249.6700286865234, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1864}, "4": {"k": 4, "answer": "Miami Heat", "latency_ms": 1250.0009536743164, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2461}, "5": {"k": 5, "answer": "Miami Heat", "latency_ms": 1990.4217720031738, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3047}, "6": {"k": 6, "answer": "Miami Heat", "latency_ms": 1802.2520542144775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3643}}}
{"qid": "-4036207256798544363", "question": "what is the value of the currency in paraguay", "gold_answers": ["126 PYG to 1 USD"], "shots": {"0": {"k": 0, "answer": "Guarani (PYG)", "latency_ms": 3274.294853210449, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "100 cent√©simos = 1 peso", "latency_ms": 4462.303638458252, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 567}, "2": {"k": 2, "answer": "PYG6155", "latency_ms": 1399.0564346313477, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1225}, "3": {"k": 3, "answer": "PYG", "latency_ms": 2082.7863216400146, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 1794}, "4": {"k": 4, "answer": "PYG", "latency_ms": 2046.9727516174316, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 2431}, "5": {"k": 5, "answer": "PYG", "latency_ms": 1523.0093002319336, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3097}, "6": {"k": 6, "answer": "PYG", "latency_ms": 2241.6162490844727, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 3735}}}
{"qid": "222526478564019881", "question": "a drug that might be used in surgery for its amnesic properties is", "gold_answers": ["benzodiazepines", "Benzodiazepines"], "shots": {"0": {"k": 0, "answer": "Midazolam.", "latency_ms": 2479.2213439941406, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "It is not specified.", "latency_ms": 2639.955520629883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "It is ideal for short appointments and simple procedures.", "latency_ms": 4140.235900878906, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1425}, "3": {"k": 3, "answer": "Midazolam", "latency_ms": 2583.686113357544, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2151}, "4": {"k": 4, "answer": "Midazolam", "latency_ms": 3030.543804168701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2889}, "5": {"k": 5, "answer": "Midazolam", "latency_ms": 3207.2811126708984, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3573}, "6": {"k": 6, "answer": "Midazolam", "latency_ms": 2254.497289657593, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4219}}}
{"qid": "-9216522514171777028", "question": "a single period of precession of earth's axis is completed in about", "gold_answers": ["26,000 years", "approximately 26,000 years"], "shots": {"0": {"k": 0, "answer": "26,000 years", "latency_ms": 2530.918598175049, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "26,000 years", "latency_ms": 2176.952362060547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 626}, "2": {"k": 2, "answer": "26,000 years", "latency_ms": 2363.9843463897705, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1262}, "3": {"k": 3, "answer": "26,000 years", "latency_ms": 2540.311813354492, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1900}, "4": {"k": 4, "answer": "25,772 years", "latency_ms": 2681.809902191162, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2566}, "5": {"k": 5, "answer": "25,772 years", "latency_ms": 1941.028356552124, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3147}, "6": {"k": 6, "answer": "25,772 years", "latency_ms": 2202.549695968628, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3775}}}
{"qid": "8838750614698973059", "question": "who did johnny manziel play college football for", "gold_answers": ["Texas A&M University", "Texas A&M Aggies", "Texas A&M"], "shots": {"0": {"k": 0, "answer": "Texas A&M", "latency_ms": 1356.6009998321533, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Texas A&M Aggies", "latency_ms": 2656.9032669067383, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 645}, "2": {"k": 2, "answer": "Texas A&M Aggies", "latency_ms": 2493.342399597168, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1310}, "3": {"k": 3, "answer": "Texas A&M Aggies", "latency_ms": 2513.867139816284, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Texas A&M Aggies", "latency_ms": 2183.382749557495, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2554}, "5": {"k": 5, "answer": "Texas A&M Aggies", "latency_ms": 1734.6436977386475, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3174}, "6": {"k": 6, "answer": "Texas A&M Aggies", "latency_ms": 2921.607732772827, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3810}}}
{"qid": "7579233308152571691", "question": "natural resources can be divided into what two categories", "gold_answers": ["Biotic", "Abiotic"], "shots": {"0": {"k": 0, "answer": "Renewable and Non-Renewable.", "latency_ms": 5105.923652648926, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "renewable or non-renewable", "latency_ms": 3481.147050857544, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 697}, "2": {"k": 2, "answer": "renewable or non-renewable", "latency_ms": 3605.771541595459, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1428}, "3": {"k": 3, "answer": "renewable or non-renewable", "latency_ms": 3442.0957565307617, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2178}, "4": {"k": 4, "answer": "renewable or non-renewable", "latency_ms": 4898.7836837768555, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2876}, "5": {"k": 5, "answer": "renewable or non-renewable", "latency_ms": 3933.839797973633, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3636}, "6": {"k": 6, "answer": "renewable or non-renewable", "latency_ms": 3388.5409832000732, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4314}}}
{"qid": "1106103350744797710", "question": "what is the white stork a symbol for in western culture", "gold_answers": ["bringing babies to new parents"], "shots": {"0": {"k": 0, "answer": "New life and fertility", "latency_ms": 2171.621561050415, "em": 0.0, "f1": 0.22222222222222224, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1758.0175399780273, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 603}, "2": {"k": 2, "answer": "Parental devotion", "latency_ms": 2631.1094760894775, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1245}, "3": {"k": 3, "answer": "Parental devotion", "latency_ms": 2643.3510780334473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1883}, "4": {"k": 4, "answer": "parental devotion", "latency_ms": 2884.5772743225098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2473}, "5": {"k": 5, "answer": "Parental devotion", "latency_ms": 2435.258626937866, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3081}, "6": {"k": 6, "answer": "parental devotion", "latency_ms": 2685.0624084472656, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3727}}}
{"qid": "-8361853086037854880", "question": "india south africa test series 2018 highest runs", "gold_answers": ["AB de Villiers", "286"], "shots": {"0": {"k": 0, "answer": "Virat Kohli 286 runs", "latency_ms": 3748.828172683716, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "558", "latency_ms": 1513.3018493652344, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 584}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2423.19917678833, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1197}, "3": {"k": 3, "answer": "558", "latency_ms": 1212.6705646514893, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1765}, "4": {"k": 4, "answer": "558", "latency_ms": 1416.46146774292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2384}, "5": {"k": 5, "answer": "558", "latency_ms": 1773.2622623443604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3033}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2723.3023643493652, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3677}}}
{"qid": "-5202207990213031495", "question": "the oligodynamic effect is a phenomenon that describes", "gold_answers": ["a biocidal effect of metals"], "shots": {"0": {"k": 0, "answer": "the antimicrobial properties of metals.", "latency_ms": 4109.209775924683, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "biocidal effect of metals", "latency_ms": 3805.936574935913, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 715}, "2": {"k": 2, "answer": "biocidal effect of metals", "latency_ms": 4074.7339725494385, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1412}, "3": {"k": 3, "answer": "biocidal effect of metals", "latency_ms": 3531.146764755249, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2074}, "4": {"k": 4, "answer": "biocidal effect of metals", "latency_ms": 3400.707244873047, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2765}, "5": {"k": 5, "answer": "biocidal effect of metals", "latency_ms": 3326.6079425811768, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3503}, "6": {"k": 6, "answer": "biocidal effect of metals", "latency_ms": 3943.089485168457, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 4193}}}
{"qid": "6391370451004919214", "question": "who was last person to be executed in us", "gold_answers": ["Ruben Cardenas Ramirez"], "shots": {"0": {"k": 0, "answer": "Dustin Higgs", "latency_ms": 1963.7279510498047, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "James Coburn", "latency_ms": 1883.3494186401367, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "James Coburn", "latency_ms": 2604.6457290649414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1265}, "3": {"k": 3, "answer": "Ronald Wolfe", "latency_ms": 2825.3512382507324, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1893}, "4": {"k": 4, "answer": "James Coburn", "latency_ms": 2178.145170211792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2549}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2869.9793815612793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3187}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2709.2316150665283, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3818}}}
{"qid": "-8069963735453146166", "question": "when do you declare honors in contract bridge", "gold_answers": ["any time after the auction"], "shots": {"0": {"k": 0, "answer": "After the auction.", "latency_ms": 2192.4490928649902, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "when they hold two \"touching honors\"", "latency_ms": 5720.291614532471, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 580}, "2": {"k": 2, "answer": "at the conclusion of play", "latency_ms": 3028.66530418396, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1132}, "3": {"k": 3, "answer": "at the conclusion of play", "latency_ms": 3068.427324295044, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1704}, "4": {"k": 4, "answer": "at the conclusion of play", "latency_ms": 3274.8773097991943, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2308}, "5": {"k": 5, "answer": "at the conclusion of play", "latency_ms": 3247.1251487731934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2924}, "6": {"k": 6, "answer": "at the conclusion of play", "latency_ms": 3358.6082458496094, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3509}}}
{"qid": "-2154502691082554319", "question": "which country is the last member of saarc", "gold_answers": ["Afghanistan"], "shots": {"0": {"k": 0, "answer": "Afghanistan", "latency_ms": 2362.4467849731445, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Afghanistan", "latency_ms": 1674.3543148040771, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 699}, "2": {"k": 2, "answer": "Afghanistan", "latency_ms": 2401.2393951416016, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1373}, "3": {"k": 3, "answer": "Afghanistan", "latency_ms": 1548.2933521270752, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2069}, "4": {"k": 4, "answer": "Afghanistan", "latency_ms": 2331.2509059906006, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2775}, "5": {"k": 5, "answer": "Afghanistan", "latency_ms": 2362.2846603393555, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3420}, "6": {"k": 6, "answer": "Afghanistan", "latency_ms": 2149.7719287872314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4149}}}
{"qid": "-8498955431733322253", "question": "describe the three phases of the normal blood clotting process", "gold_answers": ["blood coagulation", "vasoconstriction ,"], "shots": {"0": {"k": 0, "answer": "Vasoconstriction, Platelet Plug Formation, Coagulation.", "latency_ms": 6143.942356109619, "em": 0.0, "f1": 0.33333333333333337, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 5665.353775024414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2460.8869552612305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1337}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2938.964605331421, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1995}, "4": {"k": 4, "answer": "Primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 6078.5276889801025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2689}, "5": {"k": 5, "answer": "primary hemostasis, secondary hemostasis, final common pathway", "latency_ms": 5860.263824462891, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3414}, "6": {"k": 6, "answer": "primary hemostasis, secondary hemostasis, and fibrin cross-linking", "latency_ms": 6741.980314254761, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4135}}}
{"qid": "7392498509104714323", "question": "who played sonny in lemony snicket's a series of unfortunate events", "gold_answers": ["Presley Smith"], "shots": {"0": {"k": 0, "answer": "Sebastian Hunsinger", "latency_ms": 3395.5578804016113, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Presley Smith", "latency_ms": 2316.2665367126465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 698}, "2": {"k": 2, "answer": "Presley Smith", "latency_ms": 2095.076560974121, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1362}, "3": {"k": 3, "answer": "Shirley Temple did not play, Presley Smith played Sunny", "latency_ms": 5814.121961593628, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 2054}, "4": {"k": 4, "answer": "Presley Smith", "latency_ms": 2913.77854347229, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2684}, "5": {"k": 5, "answer": "Presley Smith", "latency_ms": 2893.876791000366, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3368}, "6": {"k": 6, "answer": "Shirley Temple (no), Presley Smith", "latency_ms": 5363.214492797852, "em": 0.0, "f1": 0.5714285714285715, "containment": 1.0, "context_chars": 4050}}}
{"qid": "2911493370352980057", "question": "when was united nations convention on the rights of the child created", "gold_answers": ["20 November 1989"], "shots": {"0": {"k": 0, "answer": "20 November 1989", "latency_ms": 2524.573564529419, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "20 November 1989", "latency_ms": 3485.1720333099365, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 664}, "2": {"k": 2, "answer": "20 November 1989", "latency_ms": 2698.95601272583, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1309}, "3": {"k": 3, "answer": "20 November 1989", "latency_ms": 3405.5747985839844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1976}, "4": {"k": 4, "answer": "20 November 1989", "latency_ms": 2935.4259967803955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2607}, "5": {"k": 5, "answer": "20 November 1989", "latency_ms": 1770.5998420715332, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3202}, "6": {"k": 6, "answer": "20 November 1989", "latency_ms": 2778.021812438965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3869}}}
{"qid": "2495228512593253768", "question": "when did we decide to leave the eu", "gold_answers": ["23 June 2016"], "shots": {"0": {"k": 0, "answer": "23 June 2016", "latency_ms": 3048.2633113861084, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "13 April 2016", "latency_ms": 3239.448308944702, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "23 June 2016", "latency_ms": 3231.294631958008, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1236}, "3": {"k": 3, "answer": "23 June 2016", "latency_ms": 2554.7306537628174, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1830}, "4": {"k": 4, "answer": "23 June 2016", "latency_ms": 3502.823829650879, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2502}, "5": {"k": 5, "answer": "23 June 2016", "latency_ms": 2518.242835998535, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3128}, "6": {"k": 6, "answer": "23 June 2016", "latency_ms": 2711.7390632629395, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3808}}}
{"qid": "95636137517606056", "question": "tallest building in the world of all time", "gold_answers": ["Burj Khalifa"], "shots": {"0": {"k": 0, "answer": "Burj Khalifa", "latency_ms": 2899.010419845581, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Burj Khalifa", "latency_ms": 2474.4913578033447, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 679}, "2": {"k": 2, "answer": "Burj Khalifa", "latency_ms": 2920.135736465454, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1360}, "3": {"k": 3, "answer": "Burj Khalifa", "latency_ms": 2449.101209640503, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2001}, "4": {"k": 4, "answer": "Burj Khalifa", "latency_ms": 2499.3369579315186, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2688}, "5": {"k": 5, "answer": "Burj Khalifa", "latency_ms": 1861.3049983978271, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3291}, "6": {"k": 6, "answer": "Burj Khalifa", "latency_ms": 2635.4401111602783, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3982}}}
{"qid": "-4020097033891103749", "question": "who plays chummy's mother in call the midwife", "gold_answers": ["Cheryl Campbell"], "shots": {"0": {"k": 0, "answer": "Miriam Margolyes", "latency_ms": 1981.9188117980957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2516.5679454803467, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 664}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2967.7376747131348, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1324}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2480.398178100586, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1951}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1964.231014251709, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2592}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3094.359874725342, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3247}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 1885.390043258667, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3827}}}
{"qid": "-7690316790133138931", "question": "who created separation of powers and checks and balances", "gold_answers": ["Montesquieu in the Enlightenment"], "shots": {"0": {"k": 0, "answer": "Montesquieu", "latency_ms": 2698.580741882324, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Montesquieu", "latency_ms": 2072.9732513427734, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 647}, "2": {"k": 2, "answer": "Montesquieu", "latency_ms": 3171.724796295166, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1348}, "3": {"k": 3, "answer": "Montesquieu", "latency_ms": 2879.9986839294434, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2070}, "4": {"k": 4, "answer": "Montesquieu", "latency_ms": 2317.6989555358887, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2751}, "5": {"k": 5, "answer": "Montesquieu", "latency_ms": 1920.8238124847412, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3389}, "6": {"k": 6, "answer": "Montesquieu", "latency_ms": 2136.758804321289, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4037}}}
{"qid": "914815550191007566", "question": "who was the nfl first draft pick 2017", "gold_answers": ["Myles Garrett"], "shots": {"0": {"k": 0, "answer": "Myles Garrett", "latency_ms": 1601.9906997680664, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Myles Garrett", "latency_ms": 2086.3394737243652, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Myles Garrett", "latency_ms": 2791.193723678589, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1260}, "3": {"k": 3, "answer": "Myles Garrett", "latency_ms": 1562.408447265625, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1843}, "4": {"k": 4, "answer": "Myles Garrett", "latency_ms": 2795.8459854125977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2484}, "5": {"k": 5, "answer": "Myles Garrett", "latency_ms": 2050.6110191345215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3060}, "6": {"k": 6, "answer": "Myles Garrett", "latency_ms": 1573.0865001678467, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3662}}}
{"qid": "972568347460262100", "question": "when was nepal declared a secular state in bs", "gold_answers": ["January 15 , 2007"], "shots": {"0": {"k": 0, "answer": "2063 BS", "latency_ms": 2099.97820854187, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "2063 BS", "latency_ms": 1160.78519821167, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 751}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2925.2192974090576, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1409}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2673.966884613037, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2054}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 3364.042282104492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2763}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2466.5932655334473, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3408}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2247.169256210327, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4120}}}
{"qid": "-4845827823184041115", "question": "who took control of jamestown and made new rules that made everyone work", "gold_answers": ["John Smith"], "shots": {"0": {"k": 0, "answer": "Captain John Smith", "latency_ms": 2125.739336013794, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sir Thomas Gates", "latency_ms": 2893.9003944396973, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "Sir Thomas Gates", "latency_ms": 2309.718370437622, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1296}, "3": {"k": 3, "answer": "John Smith", "latency_ms": 1984.619379043579, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1946}, "4": {"k": 4, "answer": "John Smith", "latency_ms": 1793.5469150543213, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2579}, "5": {"k": 5, "answer": "John Smith", "latency_ms": 2027.5702476501465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3229}, "6": {"k": 6, "answer": "John Smith", "latency_ms": 1520.479679107666, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3861}}}
{"qid": "7592863385884727299", "question": "the site of secretion of h+ and cl-", "gold_answers": ["Parietal cells"], "shots": {"0": {"k": 0, "answer": "Parietal cells", "latency_ms": 2029.181957244873, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Parietal cells", "latency_ms": 2825.0763416290283, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 625}, "2": {"k": 2, "answer": "Parietal cells", "latency_ms": 2106.1224937438965, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1212}, "3": {"k": 3, "answer": "Parietal cells", "latency_ms": 2100.162982940674, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1803}, "4": {"k": 4, "answer": "Parietal cells", "latency_ms": 1576.7638683319092, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2404}, "5": {"k": 5, "answer": "Parietal cells", "latency_ms": 1894.0417766571045, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3019}, "6": {"k": 6, "answer": "Parietal cells", "latency_ms": 2996.1915016174316, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3729}}}
{"qid": "-217684522847197793", "question": "when does body temperature tend to be lowest", "gold_answers": ["11 p.m. to 3 a.m."], "shots": {"0": {"k": 0, "answer": "Early morning.", "latency_ms": 2365.607261657715, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "second half of the sleep cycle", "latency_ms": 3178.516626358032, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 638}, "2": {"k": 2, "answer": "4 a.m.", "latency_ms": 2215.809106826782, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 1301}, "3": {"k": 3, "answer": "4 a.m.", "latency_ms": 2175.4486560821533, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2022}, "4": {"k": 4, "answer": "4 a.m.", "latency_ms": 2253.959894180298, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 2686}, "5": {"k": 5, "answer": "4 a.m.", "latency_ms": 2353.977680206299, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3364}, "6": {"k": 6, "answer": "4 a.m.", "latency_ms": 1816.5595531463623, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4038}}}
{"qid": "3926678456788602613", "question": "what us state forms the western boundary of montana", "gold_answers": ["Idaho"], "shots": {"0": {"k": 0, "answer": "Idaho", "latency_ms": 1263.7815475463867, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Idaho", "latency_ms": 2292.4036979675293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 673}, "2": {"k": 2, "answer": "Idaho", "latency_ms": 2058.3012104034424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "Idaho", "latency_ms": 1729.957103729248, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2028}, "4": {"k": 4, "answer": "Idaho", "latency_ms": 1279.8092365264893, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2730}, "5": {"k": 5, "answer": "Idaho", "latency_ms": 1245.276927947998, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3391}, "6": {"k": 6, "answer": "Idaho", "latency_ms": 2303.699493408203, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4015}}}
{"qid": "-444951262186580688", "question": "what is the pirates of the caribbean in order", "gold_answers": ["At World 's End", "Dead Men Tell No Tales", "Dead Man 's Chest", "On Stranger Tides"], "shots": {"0": {"k": 0, "answer": "The Curse of the Black Pearl, Dead Man's Chest, At World's End, On Stranger Tides, Dead Men Tell No Tales.", "latency_ms": 10796.551942825317, "em": 0.0, "f1": 0.43478260869565216, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2156.1312675476074, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 640}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2144.735336303711, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1282}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2383.7811946868896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1958}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2742.565631866455, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2626}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2350.1975536346436, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3272}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2727.458953857422, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3934}}}
{"qid": "-822810697742332337", "question": "if a piece of music is perceived to have changed key then we say the piece has", "gold_answers": ["transposed", "transposition"], "shots": {"0": {"k": 0, "answer": "modulated", "latency_ms": 1612.0150089263916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "undergone a modulation", "latency_ms": 2125.255346298218, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "undergone a modulation", "latency_ms": 2085.448980331421, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1328}, "3": {"k": 3, "answer": "modulated", "latency_ms": 1537.5969409942627, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1973}, "4": {"k": 4, "answer": "modulated", "latency_ms": 1186.3107681274414, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2558}, "5": {"k": 5, "answer": "modulated", "latency_ms": 2031.1815738677979, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3189}, "6": {"k": 6, "answer": "modulated", "latency_ms": 1244.8608875274658, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3779}}}
{"qid": "-4663296615598634791", "question": "who was allowed to vote in the roman republic", "gold_answers": ["unknown", "citizens"], "shots": {"0": {"k": 0, "answer": "Male citizens.", "latency_ms": 2016.6192054748535, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Roman citizens, patricians and plebeians.", "latency_ms": 4685.154438018799, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 668}, "2": {"k": 2, "answer": "Roman citizens, patricians and plebeians.", "latency_ms": 5318.049669265747, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 1307}, "3": {"k": 3, "answer": "Roman citizens", "latency_ms": 1491.0459518432617, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2006}, "4": {"k": 4, "answer": "Roman citizens", "latency_ms": 1557.1019649505615, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2595}, "5": {"k": 5, "answer": "Roman citizens, patricians and plebeians.", "latency_ms": 5201.901435852051, "em": 0.0, "f1": 0.33333333333333337, "containment": 1.0, "context_chars": 3237}, "6": {"k": 6, "answer": "Roman citizens, patricians and plebeians, adult male citizens.", "latency_ms": 7032.535552978516, "em": 0.0, "f1": 0.2222222222222222, "containment": 1.0, "context_chars": 3917}}}
{"qid": "3695813920971622504", "question": "when does the next warrior book come out", "gold_answers": ["April 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 1973.442554473877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "9 April 2019", "latency_ms": 2921.8828678131104, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 635}, "2": {"k": 2, "answer": "9 April 2019", "latency_ms": 3156.9666862487793, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1277}, "3": {"k": 3, "answer": "9 April 2019", "latency_ms": 3773.261308670044, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1901}, "4": {"k": 4, "answer": "9 April 2019", "latency_ms": 2566.0717487335205, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "9 April 2019", "latency_ms": 2467.5824642181396, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "9 April 2019", "latency_ms": 3545.42875289917, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3810}}}
{"qid": "8533079479108336590", "question": "blood alcohol concentration means the parts of alcohol in the blood in relation to what", "gold_answers": ["volume of blood", "ethanol"], "shots": {"0": {"k": 0, "answer": "100 parts of blood", "latency_ms": 2664.6296977996826, "em": 0.0, "f1": 0.5714285714285715, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "volume of blood or mass of blood", "latency_ms": 5189.114570617676, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "volume of blood or mass of blood", "latency_ms": 3734.222650527954, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "volume of blood or mass of blood", "latency_ms": 4060.9419345855713, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 1899}, "4": {"k": 4, "answer": "volume of blood or mass of blood", "latency_ms": 4321.723461151123, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 2596}, "5": {"k": 5, "answer": "volume of blood or mass of blood", "latency_ms": 3731.8477630615234, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3239}, "6": {"k": 6, "answer": "volume of blood or mass of blood", "latency_ms": 3278.140068054199, "em": 0.0, "f1": 0.6, "containment": 1.0, "context_chars": 3854}}}
{"qid": "-1531676396763282931", "question": "which greek god flew too close to the sun", "gold_answers": ["Icarus"], "shots": {"0": {"k": 0, "answer": "Icarus", "latency_ms": 1127.3510456085205, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Icarus", "latency_ms": 2300.192356109619, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 612}, "2": {"k": 2, "answer": "Icarus", "latency_ms": 1820.0726509094238, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1240}, "3": {"k": 3, "answer": "Icarus", "latency_ms": 2323.737144470215, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1812}, "4": {"k": 4, "answer": "Icarus", "latency_ms": 2275.0117778778076, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2409}, "5": {"k": 5, "answer": "Icarus", "latency_ms": 1609.2934608459473, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3006}, "6": {"k": 6, "answer": "Icarus", "latency_ms": 2165.876865386963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3643}}}
{"qid": "-3682350378604306871", "question": "when did the song rapper's delight come out", "gold_answers": ["September 16 , 1979", "1979"], "shots": {"0": {"k": 0, "answer": "September 16, 1979", "latency_ms": 2717.3588275909424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "January 1980", "latency_ms": 1637.3939514160156, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "1979", "latency_ms": 1750.8270740509033, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1146}, "3": {"k": 3, "answer": "1979", "latency_ms": 1490.4980659484863, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1802}, "4": {"k": 4, "answer": "1979", "latency_ms": 2052.2220134735107, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2419}, "5": {"k": 5, "answer": "September 16, 1979", "latency_ms": 3118.894577026367, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3041}, "6": {"k": 6, "answer": "1979", "latency_ms": 1511.0316276550293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3688}}}
{"qid": "-3646291394492263644", "question": "when does the stock market open in hong kong", "gold_answers": ["09 : 15"], "shots": {"0": {"k": 0, "answer": "9:30 am HKT", "latency_ms": 3728.792905807495, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 1675.6339073181152, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "2 April 1986", "latency_ms": 1951.230764389038, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1275}, "3": {"k": 3, "answer": "2 April 1986", "latency_ms": 3165.816068649292, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1919}, "4": {"k": 4, "answer": "2 April 1986", "latency_ms": 3377.838134765625, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2591}, "5": {"k": 5, "answer": "2 April 1986", "latency_ms": 2629.401206970215, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3229}, "6": {"k": 6, "answer": "2 April 1986", "latency_ms": 2287.8592014312744, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3869}}}
{"qid": "9187994979510737197", "question": "who's the model on let's make a deal", "gold_answers": ["Tiffany Adams Coyne"], "shots": {"0": {"k": 0, "answer": "Tiffany Coyne", "latency_ms": 1608.6254119873047, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Carol Merrill", "latency_ms": 1660.773754119873, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 625}, "2": {"k": 2, "answer": "Carol Merrill", "latency_ms": 1467.6833152770996, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1239}, "3": {"k": 3, "answer": "Tiffany Coyne", "latency_ms": 2355.18479347229, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1823}, "4": {"k": 4, "answer": "Tiffany Coyne", "latency_ms": 2712.606906890869, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2417}, "5": {"k": 5, "answer": "Tiffany Coyne", "latency_ms": 2397.5470066070557, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2993}, "6": {"k": 6, "answer": "Tiffany Coyne", "latency_ms": 1932.4352741241455, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3637}}}
{"qid": "5078709962400196312", "question": "what mlb teams did deion sanders play for", "gold_answers": ["San Francisco Giants", "Cincinnati Reds", "Atlanta Braves", "New York Yankees"], "shots": {"0": {"k": 0, "answer": "Yankees, Braves, Reds, Giants.", "latency_ms": 3809.4959259033203, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5175.494909286499, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5538.4767055511475, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1269}, "3": {"k": 3, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 4891.307353973389, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 1845}, "4": {"k": 4, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5413.28763961792, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 2456}, "5": {"k": 5, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5553.536653518677, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3065}, "6": {"k": 6, "answer": "New York Yankees, Atlanta Braves, Cincinnati Reds, San Francisco Giants", "latency_ms": 5574.7129917144775, "em": 0.0, "f1": 0.4615384615384615, "containment": 1.0, "context_chars": 3708}}}
{"qid": "-4910305402988079742", "question": "how much money did the film titanic make", "gold_answers": ["$2.18 billion", "$2.187 billion"], "shots": {"0": {"k": 0, "answer": "2.187 billion dollars", "latency_ms": 3508.2848072052, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "$343.4 million", "latency_ms": 2612.6463413238525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 624}, "2": {"k": 2, "answer": "$2 billion", "latency_ms": 2628.4890174865723, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1286}, "3": {"k": 3, "answer": "$1.84 billion", "latency_ms": 3038.1925106048584, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 1938}, "4": {"k": 4, "answer": "$1.84 billion", "latency_ms": 2856.0328483581543, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2581}, "5": {"k": 5, "answer": "$2 billion", "latency_ms": 1901.5541076660156, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3208}, "6": {"k": 6, "answer": "$1.84 billion", "latency_ms": 2968.9722061157227, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3819}}}
{"qid": "1636956235349274030", "question": "when does it's a wonderful life comes on", "gold_answers": ["Christmas season"], "shots": {"0": {"k": 0, "answer": "Christmas Eve and Christmas Day.", "latency_ms": 2575.5112171173096, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2355.815887451172, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 593}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2758.183002471924, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1218}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2455.057382583618, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2613.020420074463, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2474}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2721.9152450561523, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3135}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2431.060552597046, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3768}}}
{"qid": "5608421991404219229", "question": "where does the last name hansen come from", "gold_answers": ["the Faroe Islands", "Norway", "Denmark", "Scandinavian"], "shots": {"0": {"k": 0, "answer": "Denmark and Norway", "latency_ms": 2318.6819553375244, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2659.353494644165, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2714.62345123291, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1241}, "3": {"k": 3, "answer": "Norway", "latency_ms": 2800.5638122558594, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1862}, "4": {"k": 4, "answer": "Norway", "latency_ms": 1509.0198516845703, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2457}, "5": {"k": 5, "answer": "Norway", "latency_ms": 2656.911611557007, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3037}, "6": {"k": 6, "answer": "Denmark and Norway", "latency_ms": 3099.090814590454, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 3655}}}
{"qid": "2577140274301537828", "question": "what is the symbol for christmas in brazil", "gold_answers": ["Nativity scene", "Christmas Tree"], "shots": {"0": {"k": 0, "answer": "Pres√©pio", "latency_ms": 2211.91143989563, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Puritina", "latency_ms": 1872.0812797546387, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "Puritina", "latency_ms": 2260.451316833496, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1274}, "3": {"k": 3, "answer": "Puritina", "latency_ms": 2684.4170093536377, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1912}, "4": {"k": 4, "answer": "Christmas Tree", "latency_ms": 2320.777654647827, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2541}, "5": {"k": 5, "answer": "Christmas Tree", "latency_ms": 2066.9851303100586, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3193}, "6": {"k": 6, "answer": "Puritina", "latency_ms": 2594.1126346588135, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3913}}}
{"qid": "-6762654750812139940", "question": "who sings she's like the wind lyrics", "gold_answers": ["Wendy Fraser", "Patrick Swayze"], "shots": {"0": {"k": 0, "answer": "Patrick Swayze", "latency_ms": 1818.3355331420898, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Swayze", "latency_ms": 2908.3995819091797, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Swayze", "latency_ms": 2133.9855194091797, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1268}, "3": {"k": 3, "answer": "Swayze", "latency_ms": 1568.5865879058838, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1913}, "4": {"k": 4, "answer": "Swayze", "latency_ms": 2080.0986289978027, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "Swayze", "latency_ms": 2702.6004791259766, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3163}, "6": {"k": 6, "answer": "Swayze", "latency_ms": 1895.7693576812744, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3730}}}
{"qid": "-3640066593401557276", "question": "where does the this is us family live", "gold_answers": ["Pittsburgh"], "shots": {"0": {"k": 0, "answer": "Pittsburgh", "latency_ms": 1617.0120239257812, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Sweden, US, 60 countries", "latency_ms": 2908.381462097168, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 629}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2956.7642211914062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1256}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2715.221405029297, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1927}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 1562.5293254852295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2605}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2181.7991733551025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3294}, "6": {"k": 6, "answer": "I cannot answer.", "latency_ms": 2571.5432167053223, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3902}}}
{"qid": "-4546405080702371934", "question": "when was the term prime minister first used", "gold_answers": ["18th century", "1624"], "shots": {"0": {"k": 0, "answer": "1612", "latency_ms": 1030.2674770355225, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2442.2595500946045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 657}, "2": {"k": 2, "answer": "after 1901", "latency_ms": 2552.950859069824, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1354}, "3": {"k": 3, "answer": "after 1901", "latency_ms": 2424.609422683716, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2022}, "4": {"k": 4, "answer": "after 1901", "latency_ms": 2140.045642852783, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2674}, "5": {"k": 5, "answer": "1901", "latency_ms": 1803.7524223327637, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3396}, "6": {"k": 6, "answer": "1905", "latency_ms": 1087.254524230957, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4057}}}
{"qid": "3653635084331615973", "question": "who won the mens single ice skating 2018", "gold_answers": ["Javier Fern√°ndez", "Shoma Uno", "Yuzuru Hanyu"], "shots": {"0": {"k": 0, "answer": "Yuzuru Hanyu", "latency_ms": 2800.018310546875, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Yuzuru Hanyu", "latency_ms": 4648.519277572632, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 627}, "2": {"k": 2, "answer": "Yuzuru Hanyu", "latency_ms": 3317.483425140381, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1279}, "3": {"k": 3, "answer": "Yuzuru Hanyu", "latency_ms": 2178.917169570923, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1904}, "4": {"k": 4, "answer": "Yuzuru Hanyu", "latency_ms": 3079.8511505126953, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2468}, "5": {"k": 5, "answer": "Yuzuru Hanyu", "latency_ms": 2553.947925567627, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3119}, "6": {"k": 6, "answer": "Yuzuru Hanyu", "latency_ms": 3432.9185485839844, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3756}}}
{"qid": "-8943432852681116531", "question": "what is cain and abel software used for", "gold_answers": ["password recovery"], "shots": {"0": {"k": 0, "answer": "Password cracking and recovery.", "latency_ms": 3568.613052368164, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Password recovery", "latency_ms": 1306.434154510498, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 695}, "2": {"k": 2, "answer": "Password recovery tool", "latency_ms": 2123.4772205352783, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 1391}, "3": {"k": 3, "answer": "Password recovery", "latency_ms": 1995.284080505371, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2034}, "4": {"k": 4, "answer": "Password recovery tool", "latency_ms": 2341.655731201172, "em": 0.0, "f1": 0.8, "containment": 1.0, "context_chars": 2619}, "5": {"k": 5, "answer": "Password recovery", "latency_ms": 1514.5962238311768, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3261}, "6": {"k": 6, "answer": "Password recovery", "latency_ms": 1571.6631412506104, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3840}}}
{"qid": "3562729819386821776", "question": "what is the name of governor of maharashtra", "gold_answers": ["Chennamaneni Vidyasagar Rao"], "shots": {"0": {"k": 0, "answer": "Eknath Shinde", "latency_ms": 2030.2982330322266, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "C. Vidyasagar Rao", "latency_ms": 3600.9674072265625, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 668}, "2": {"k": 2, "answer": "C. Vidyasagar Rao", "latency_ms": 4037.98770904541, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1308}, "3": {"k": 3, "answer": "C. Vidyasagar Rao", "latency_ms": 3930.856227874756, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "C. Vidyasagar Rao", "latency_ms": 3783.8642597198486, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2588}, "5": {"k": 5, "answer": "C. Vidyasagar Rao", "latency_ms": 3551.147937774658, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3242}, "6": {"k": 6, "answer": "C. Vidyasagar Rao", "latency_ms": 2812.633275985718, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3899}}}
{"qid": "-2040762149245803825", "question": "what channel is abc on in phoenix arizona", "gold_answers": ["15"], "shots": {"0": {"k": 0, "answer": "Channel 15 (KNXV)", "latency_ms": 3410.914421081543, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "15", "latency_ms": 1497.1411228179932, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 682}, "2": {"k": 2, "answer": "15", "latency_ms": 1197.2131729125977, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1287}, "3": {"k": 3, "answer": "15", "latency_ms": 1755.3985118865967, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1919}, "4": {"k": 4, "answer": "15", "latency_ms": 901.3383388519287, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2565}, "5": {"k": 5, "answer": "15", "latency_ms": 1462.414026260376, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3252}, "6": {"k": 6, "answer": "15", "latency_ms": 1166.0246849060059, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3933}}}
{"qid": "-1378070576053000718", "question": "who played jennifer in back to the future", "gold_answers": ["Claudia Grace Wells"], "shots": {"0": {"k": 0, "answer": "Claudia Wells", "latency_ms": 1987.6670837402344, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Elisabeth Shue", "latency_ms": 2947.9470252990723, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 582}, "2": {"k": 2, "answer": "Claudia Wells", "latency_ms": 2174.191474914551, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "Claudia Wells", "latency_ms": 2173.6900806427, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1777}, "4": {"k": 4, "answer": "Claudia Wells", "latency_ms": 3227.9531955718994, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2408}, "5": {"k": 5, "answer": "Claudia Wells", "latency_ms": 2436.3996982574463, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3007}, "6": {"k": 6, "answer": "Claudia Wells", "latency_ms": 2256.0908794403076, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3629}}}
{"qid": "-8946826352712324685", "question": "where was the summer olympics held in 2012", "gold_answers": ["London", "London , United Kingdom"], "shots": {"0": {"k": 0, "answer": "London", "latency_ms": 969.202995300293, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "London, United Kingdom", "latency_ms": 2382.585048675537, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 639}, "2": {"k": 2, "answer": "London, United Kingdom", "latency_ms": 2652.4574756622314, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1286}, "3": {"k": 3, "answer": "London, United Kingdom", "latency_ms": 2686.2008571624756, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1955}, "4": {"k": 4, "answer": "London, United Kingdom", "latency_ms": 3006.5271854400635, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2581}, "5": {"k": 5, "answer": "London, United Kingdom", "latency_ms": 2194.709062576294, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3235}, "6": {"k": 6, "answer": "London, United Kingdom", "latency_ms": 1878.7634372711182, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3909}}}
{"qid": "-5578685052965147220", "question": "who cooks for the president of the united states", "gold_answers": ["Cristeta Comerford", "The White House Executive Chef", "White House Executive Chef"], "shots": {"0": {"k": 0, "answer": "The White House Chef", "latency_ms": 2933.0148696899414, "em": 0.0, "f1": 0.8571428571428571, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Executive Chef", "latency_ms": 1812.523365020752, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 667}, "2": {"k": 2, "answer": "White House Executive Chef", "latency_ms": 2376.58429145813, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1355}, "3": {"k": 3, "answer": "White House Executive Chef", "latency_ms": 3046.764373779297, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1967}, "4": {"k": 4, "answer": "White House Executive Chef", "latency_ms": 1950.056552886963, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2558}, "5": {"k": 5, "answer": "White House Executive Chef", "latency_ms": 1854.825735092163, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3150}, "6": {"k": 6, "answer": "White House Executive Chef", "latency_ms": 2452.634334564209, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3783}}}
{"qid": "-7323892214876884658", "question": "who was the first indian to be appointed as a judge in the international court of justice", "gold_answers": ["Sir Benegal Narsing Rau"], "shots": {"0": {"k": 0, "answer": "Nagendra Singh", "latency_ms": 2407.9344272613525, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2477.445363998413, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 633}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2951.6820907592773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1248}, "3": {"k": 3, "answer": "Nagendra Singh", "latency_ms": 2948.0247497558594, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1821}, "4": {"k": 4, "answer": "B. N. Rao", "latency_ms": 3507.5807571411133, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2391}, "5": {"k": 5, "answer": "B. N. Rao", "latency_ms": 2840.1405811309814, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3019}, "6": {"k": 6, "answer": "B. N. Rao", "latency_ms": 2775.6173610687256, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3672}}}
{"qid": "-7530191989994326613", "question": "where was the film coming home for christmas filmed", "gold_answers": ["British Columbia"], "shots": {"0": {"k": 0, "answer": "New Zealand", "latency_ms": 1249.6180534362793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "British Columbia", "latency_ms": 2770.134210586548, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 656}, "2": {"k": 2, "answer": "British Columbia", "latency_ms": 1187.0779991149902, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1305}, "3": {"k": 3, "answer": "British Columbia", "latency_ms": 2103.5892963409424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1960}, "4": {"k": 4, "answer": "British Columbia", "latency_ms": 1538.2332801818848, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2605}, "5": {"k": 5, "answer": "British Columbia", "latency_ms": 2007.138967514038, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3252}, "6": {"k": 6, "answer": "British Columbia", "latency_ms": 2040.3330326080322, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3932}}}
{"qid": "1036801998292429298", "question": "when do the new episodes of supernatural start", "gold_answers": ["May 10 , 2018"], "shots": {"0": {"k": 0, "answer": "I cannot answer.", "latency_ms": 2382.503032684326, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "October 11, 2018", "latency_ms": 3839.2488956451416, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 650}, "2": {"k": 2, "answer": "October 11, 2018", "latency_ms": 3082.1619033813477, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1295}, "3": {"k": 3, "answer": "October 11, 2018", "latency_ms": 4253.209352493286, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 1945}, "4": {"k": 4, "answer": "October 11, 2018", "latency_ms": 3811.8934631347656, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 2654}, "5": {"k": 5, "answer": "October 11, 2018", "latency_ms": 4575.453996658325, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 3378}, "6": {"k": 6, "answer": "October 11, 2018", "latency_ms": 3690.8671855926514, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 4032}}}
{"qid": "-7296166998534064378", "question": "who played the middle sister on full house", "gold_answers": ["Jodie Sweetin"], "shots": {"0": {"k": 0, "answer": "Jodie Sweetin", "latency_ms": 2192.233085632324, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2392.7524089813232, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 612}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 2480.147123336792, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1271}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2226.724147796631, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1858}, "4": {"k": 4, "answer": "Stephanie", "latency_ms": 2113.372802734375, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2512}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 2340.131998062134, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3155}, "6": {"k": 6, "answer": "Stephanie", "latency_ms": 1805.6495189666748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3754}}}
{"qid": "-4173722566701480014", "question": "a 58-story skyscraper in san francisco is tilting and sinking", "gold_answers": ["Millennium Tower"], "shots": {"0": {"k": 0, "answer": "Millennium Tower", "latency_ms": 2166.811227798462, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Millennium Tower", "latency_ms": 2177.0541667938232, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 693}, "2": {"k": 2, "answer": "Millennium Tower", "latency_ms": 1781.3794612884521, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1345}, "3": {"k": 3, "answer": "Millennium Tower", "latency_ms": 2418.1113243103027, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2031}, "4": {"k": 4, "answer": "Millennium Tower", "latency_ms": 2324.4190216064453, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2688}, "5": {"k": 5, "answer": "Millennium Tower", "latency_ms": 2335.432291030884, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3347}, "6": {"k": 6, "answer": "Millennium Tower", "latency_ms": 1963.733196258545, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4043}}}
{"qid": "8741253661372783389", "question": "when was the first season of when calls the heart", "gold_answers": ["2014", "January 11 , 2014"], "shots": {"0": {"k": 0, "answer": "2014", "latency_ms": 763.8950347900391, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "2015", "latency_ms": 2023.4739780426025, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 626}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1161.4844799041748, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1254}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2324.0582942962646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1819}, "4": {"k": 4, "answer": "2015", "latency_ms": 1781.5430164337158, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2429}, "5": {"k": 5, "answer": "2015", "latency_ms": 1278.2905101776123, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3080}, "6": {"k": 6, "answer": "2015", "latency_ms": 1796.2279319763184, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3703}}}
{"qid": "-2244798821441304446", "question": "who said one man's vulgarity is another's lyric", "gold_answers": ["Justice Harlan"], "shots": {"0": {"k": 0, "answer": "John Harlan", "latency_ms": 1159.9290370941162, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "John Marshall Harlan", "latency_ms": 2799.480676651001, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 696}, "2": {"k": 2, "answer": "John Marshall Harlan", "latency_ms": 1754.9378871917725, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1377}, "3": {"k": 3, "answer": "John Marshall Harlan", "latency_ms": 2653.601884841919, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2080}, "4": {"k": 4, "answer": "John Marshall Harlan", "latency_ms": 2593.3961868286133, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2774}, "5": {"k": 5, "answer": "John Marshall Harlan", "latency_ms": 2105.6363582611084, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3453}, "6": {"k": 6, "answer": "John Marshall Harlan", "latency_ms": 2380.7263374328613, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 4030}}}
{"qid": "4764100575661627990", "question": "what football player is called the honey badger", "gold_answers": ["Tyrann Devine Mathieu"], "shots": {"0": {"k": 0, "answer": "Tyrann Mathieu", "latency_ms": 2252.377510070801, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tyrann Mathieu", "latency_ms": 2519.6635723114014, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 622}, "2": {"k": 2, "answer": "Tyrann Mathieu", "latency_ms": 1927.7575016021729, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1261}, "3": {"k": 3, "answer": "Tyrann Mathieu", "latency_ms": 2778.2223224639893, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 1931}, "4": {"k": 4, "answer": "Tyrann Mathieu", "latency_ms": 2272.972822189331, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 2544}, "5": {"k": 5, "answer": "Tyrann Mathieu", "latency_ms": 2278.9883613586426, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3232}, "6": {"k": 6, "answer": "Tyrann Mathieu", "latency_ms": 2924.7732162475586, "em": 0.0, "f1": 0.8, "containment": 0.0, "context_chars": 3869}}}
{"qid": "-2273381713182307888", "question": "how many episodes of the killing on netflix", "gold_answers": ["six", "6"], "shots": {"0": {"k": 0, "answer": "44", "latency_ms": 660.5823040008545, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Six", "latency_ms": 1177.056074142456, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 660}, "2": {"k": 2, "answer": "6", "latency_ms": 1743.1223392486572, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1318}, "3": {"k": 3, "answer": "6", "latency_ms": 1188.3752346038818, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1991}, "4": {"k": 4, "answer": "Six episodes", "latency_ms": 1583.1654071807861, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2698}, "5": {"k": 5, "answer": "Six episodes", "latency_ms": 1126.9776821136475, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3373}, "6": {"k": 6, "answer": "6 episodes", "latency_ms": 521.1141109466553, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4022}}}
{"qid": "7214445857680379083", "question": "from whose perspective is the story of all quiet on the western front told", "gold_answers": ["Paul Baumer"], "shots": {"0": {"k": 0, "answer": "Paul Ba√ºmer's", "latency_ms": 2493.1366443634033, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "a German infantryman", "latency_ms": 2885.5433464050293, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 643}, "2": {"k": 2, "answer": "a German infantryman", "latency_ms": 2940.5899047851562, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1284}, "3": {"k": 3, "answer": "a German infantryman", "latency_ms": 1881.2634944915771, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1966}, "4": {"k": 4, "answer": "a German infantryman", "latency_ms": 1920.8760261535645, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2575}, "5": {"k": 5, "answer": "German infantryman", "latency_ms": 1357.2986125946045, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3180}, "6": {"k": 6, "answer": "German infantryman", "latency_ms": 2147.5391387939453, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3798}}}
{"qid": "4905519627710399354", "question": "who was the person who escaped from alcatraz", "gold_answers": ["John Anglin", "Clarence Anglin", "Frank Morris"], "shots": {"0": {"k": 0, "answer": "Frank Morris", "latency_ms": 1457.5018882751465, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Henri Young", "latency_ms": 1617.5565719604492, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 644}, "2": {"k": 2, "answer": "Frank Morris, John Anglin, Clarence Anglin", "latency_ms": 5892.298460006714, "em": 0.0, "f1": 0.5, "containment": 1.0, "context_chars": 1308}, "3": {"k": 3, "answer": "John Paul Scott", "latency_ms": 1582.1843147277832, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1947}, "4": {"k": 4, "answer": "John Paul Scott", "latency_ms": 1776.5913009643555, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 2632}, "5": {"k": 5, "answer": "Frank Morris, John Anglin, Clarence Anglin, John Paul Scott", "latency_ms": 5626.0082721710205, "em": 0.0, "f1": 0.3636363636363636, "containment": 1.0, "context_chars": 3307}, "6": {"k": 6, "answer": "John Paul Scott", "latency_ms": 1828.6712169647217, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 3933}}}
{"qid": "-5199162398326752157", "question": "where does trick or treat for unicef money go", "gold_answers": ["UNICEF 's global programing"], "shots": {"0": {"k": 0, "answer": "UNICEF programs worldwide.", "latency_ms": 3324.3846893310547, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "UNICEF", "latency_ms": 2086.0860347747803, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 718}, "2": {"k": 2, "answer": "UNICEF", "latency_ms": 1636.4481449127197, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 1448}, "3": {"k": 3, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world", "latency_ms": 6727.86808013916, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2106}, "4": {"k": 4, "answer": "to deliver lifesaving packets of therapeutic food to severely malnourished children around the world", "latency_ms": 6236.870527267456, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2795}, "5": {"k": 5, "answer": "UNICEF's global programming", "latency_ms": 2761.155128479004, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 3489}, "6": {"k": 6, "answer": "UNICEF's global programming", "latency_ms": 2595.2212810516357, "em": 0.0, "f1": 0.28571428571428575, "containment": 0.0, "context_chars": 4214}}}
{"qid": "9200381329776083757", "question": "where is the inscription on the statue of liberty", "gold_answers": ["The New Colossus"], "shots": {"0": {"k": 0, "answer": "Tablet in her left hand", "latency_ms": 1797.1515655517578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Edge of the coin", "latency_ms": 1401.99875831604, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 646}, "2": {"k": 2, "answer": "Edge of the coin", "latency_ms": 2098.3214378356934, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1334}, "3": {"k": 3, "answer": "Edge of the coin", "latency_ms": 1616.318702697754, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1956}, "4": {"k": 4, "answer": "Not mentioned", "latency_ms": 1526.1704921722412, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2548}, "5": {"k": 5, "answer": "Not mentioned", "latency_ms": 1256.638765335083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3226}, "6": {"k": 6, "answer": "Not mentioned", "latency_ms": 2047.4202632904053, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3876}}}
{"qid": "9179702110514757818", "question": "where are the next two winter olympics going to be held", "gold_answers": ["Beijing", "TBD"], "shots": {"0": {"k": 0, "answer": "Milan-Cortina 2026, Sapporo 2030", "latency_ms": 5715.749263763428, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2368.344783782959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 600}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 1643.9766883850098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1193}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 1904.1128158569336, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1832}, "4": {"k": 4, "answer": "Beijing, China and unknown", "latency_ms": 2933.922529220581, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 2439}, "5": {"k": 5, "answer": "Beijing, China; Abu Dhabi is incorrect as Abu Dhabi is for Special Olympics, the next Winter Olympics after Beijing is not specified.", "latency_ms": 9966.581106185913, "em": 0.0, "f1": 0.0909090909090909, "containment": 1.0, "context_chars": 3031}, "6": {"k": 6, "answer": "Beijing, China; Abu Dhabi is incorrect as Abu Dhabi is for Special Olympics, the next Winter Olympics after Beijing is not specified. \n Beijing, China", "latency_ms": 12451.937913894653, "em": 0.0, "f1": 0.08333333333333331, "containment": 1.0, "context_chars": 3641}}}
{"qid": "-5410471527866417159", "question": "when did i'm coming out come out", "gold_answers": ["August 22 , 1980"], "shots": {"0": {"k": 0, "answer": "October 22, 1981", "latency_ms": 3563.6303424835205, "em": 0.0, "f1": 0.33333333333333326, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "1997", "latency_ms": 2042.1922206878662, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 645}, "2": {"k": 2, "answer": "1997", "latency_ms": 1502.0673274993896, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1242}, "3": {"k": 3, "answer": "1997", "latency_ms": 1559.0436458587646, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1802}, "4": {"k": 4, "answer": "1997", "latency_ms": 1779.4215679168701, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2441}, "5": {"k": 5, "answer": "1997", "latency_ms": 1007.037878036499, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3040}, "6": {"k": 6, "answer": "1997", "latency_ms": 1790.7934188842773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3694}}}
{"qid": "-3621585537083644585", "question": "what type of bridge is the charles bridge", "gold_answers": ["bow bridge", "a bow bridge", "Stone"], "shots": {"0": {"k": 0, "answer": "Stone Gothic arch bridge", "latency_ms": 2423.444986343384, "em": 0.0, "f1": 0.4, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Rolling bascule bridge", "latency_ms": 3067.0228004455566, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 678}, "2": {"k": 2, "answer": "Stone Bridge", "latency_ms": 1768.7137126922607, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1311}, "3": {"k": 3, "answer": "Stone Bridge", "latency_ms": 1837.6762866973877, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1978}, "4": {"k": 4, "answer": "Historic bridge", "latency_ms": 2127.950668334961, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 2615}, "5": {"k": 5, "answer": "Historic bridge", "latency_ms": 1853.1742095947266, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 3316}, "6": {"k": 6, "answer": "Historic bridge", "latency_ms": 2419.438362121582, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 4009}}}
{"qid": "-6934435686987287378", "question": "who makes the important government decisions in an autocracy", "gold_answers": ["one person"], "shots": {"0": {"k": 0, "answer": "The Autocrat", "latency_ms": 1897.639513015747, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "One person", "latency_ms": 1780.7276248931885, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 657}, "2": {"k": 2, "answer": "One person", "latency_ms": 1540.513038635254, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1323}, "3": {"k": 3, "answer": "One person", "latency_ms": 1986.3719940185547, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1987}, "4": {"k": 4, "answer": "One person", "latency_ms": 831.049919128418, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2722}, "5": {"k": 5, "answer": "One person", "latency_ms": 1063.1840229034424, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3364}, "6": {"k": 6, "answer": "One person", "latency_ms": 1823.9390850067139, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 4034}}}
{"qid": "-7488727646515698670", "question": "what was the main characteristic of post-world war ii american society", "gold_answers": ["strong economic growth"], "shots": {"0": {"k": 0, "answer": "Affluence and suburbanization.", "latency_ms": 3888.1053924560547, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Economic expansion", "latency_ms": 2349.271059036255, "em": 0.0, "f1": 0.4, "containment": 0.0, "context_chars": 726}, "2": {"k": 2, "answer": "other-directedness", "latency_ms": 2108.6621284484863, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1442}, "3": {"k": 3, "answer": "other-directedness", "latency_ms": 2167.592763900757, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2050}, "4": {"k": 4, "answer": "other-directedness", "latency_ms": 2151.5190601348877, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2759}, "5": {"k": 5, "answer": "Consumer culture", "latency_ms": 795.5942153930664, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3484}, "6": {"k": 6, "answer": "Consumer culture", "latency_ms": 2538.817882537842, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 4112}}}
{"qid": "5760101138584878549", "question": "which way does the earth orbit the sun", "gold_answers": ["counter clockwise direction", "counter clockwise"], "shots": {"0": {"k": 0, "answer": "Counterclockwise", "latency_ms": 2636.194944381714, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Counterclockwise", "latency_ms": 3230.32283782959, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 566}, "2": {"k": 2, "answer": "Counterclockwise", "latency_ms": 2442.4407482147217, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1163}, "3": {"k": 3, "answer": "Counterclockwise", "latency_ms": 1991.5990829467773, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1737}, "4": {"k": 4, "answer": "Counterclockwise", "latency_ms": 1879.441499710083, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2359}, "5": {"k": 5, "answer": "Counterclockwise", "latency_ms": 2644.789695739746, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2966}, "6": {"k": 6, "answer": "Counterclockwise", "latency_ms": 2364.797592163086, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3511}}}
{"qid": "-7003244893871973796", "question": "what is on top of us capitol building", "gold_answers": ["The Statue of Freedom"], "shots": {"0": {"k": 0, "answer": "Statue of Freedom", "latency_ms": 2428.0378818511963, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Statue of Freedom", "latency_ms": 2148.052453994751, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 555}, "2": {"k": 2, "answer": "Statue of Freedom", "latency_ms": 1962.8386497497559, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1177}, "3": {"k": 3, "answer": "Statue of Freedom", "latency_ms": 2651.984453201294, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 1791}, "4": {"k": 4, "answer": "Statue of Freedom", "latency_ms": 2430.760383605957, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 2446}, "5": {"k": 5, "answer": "Statue of Freedom", "latency_ms": 2219.4390296936035, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3022}, "6": {"k": 6, "answer": "Statue of Freedom", "latency_ms": 2359.019994735718, "em": 1.0, "f1": 1.0, "containment": 0.0, "context_chars": 3682}}}
{"qid": "-3587434056219625939", "question": "who did dwight howard play for last year", "gold_answers": ["Charlotte Hornets", "Atlanta Hawks"], "shots": {"0": {"k": 0, "answer": "Taoyuan Leopards", "latency_ms": 2547.727346420288, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Washington Wizards", "latency_ms": 1026.6633033752441, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 684}, "2": {"k": 2, "answer": "Washington Wizards", "latency_ms": 2073.8203525543213, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1276}, "3": {"k": 3, "answer": "Washington Wizards", "latency_ms": 1812.304973602295, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1873}, "4": {"k": 4, "answer": "Washington Wizards", "latency_ms": 1266.704797744751, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2490}, "5": {"k": 5, "answer": "Washington Wizards", "latency_ms": 2315.3679370880127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3050}, "6": {"k": 6, "answer": "Washington Wizards", "latency_ms": 2085.7319831848145, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3644}}}
{"qid": "-6209397953683103736", "question": "who lasted the longest in the royal rumble", "gold_answers": ["Rey Mysterio"], "shots": {"0": {"k": 0, "answer": "Rey Mysterio", "latency_ms": 1771.9480991363525, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Mysterio", "latency_ms": 1612.351655960083, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 599}, "2": {"k": 2, "answer": "Rey Mysterio", "latency_ms": 2935.8839988708496, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1191}, "3": {"k": 3, "answer": "Mysterio", "latency_ms": 2367.8596019744873, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 1801}, "4": {"k": 4, "answer": "Mysterio", "latency_ms": 1632.2393417358398, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 2426}, "5": {"k": 5, "answer": "Mysterio", "latency_ms": 2343.322515487671, "em": 0.0, "f1": 0.6666666666666665, "containment": 0.0, "context_chars": 3027}, "6": {"k": 6, "answer": "Rey Mysterio", "latency_ms": 2825.641870498657, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3689}}}
{"qid": "-5424723408850352324", "question": "what is the largest man made lake in the us", "gold_answers": ["Lake Oahe"], "shots": {"0": {"k": 0, "answer": "Lake Mead", "latency_ms": 1613.8896942138672, "em": 0.0, "f1": 0.5, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Lake Oahe", "latency_ms": 2437.0620250701904, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 601}, "2": {"k": 2, "answer": "Lake Oahe", "latency_ms": 2610.1884841918945, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1223}, "3": {"k": 3, "answer": "Lake Oahe", "latency_ms": 2252.753496170044, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1818}, "4": {"k": 4, "answer": "Lake Oahe", "latency_ms": 2167.513608932495, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2428}, "5": {"k": 5, "answer": "Lake Oahe", "latency_ms": 2605.299711227417, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3093}, "6": {"k": 6, "answer": "Lake Oahe", "latency_ms": 1888.5011672973633, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3723}}}
{"qid": "7225785319983716635", "question": "gabbar is back is a remake of which telugu movie", "gold_answers": ["Tagore"], "shots": {"0": {"k": 0, "answer": "Tagore", "latency_ms": 908.4455966949463, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Tagore", "latency_ms": 1801.6314506530762, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 585}, "2": {"k": 2, "answer": "Tagore", "latency_ms": 1402.357578277588, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1209}, "3": {"k": 3, "answer": "Tagore", "latency_ms": 1792.5288677215576, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1860}, "4": {"k": 4, "answer": "Tagore", "latency_ms": 1768.9220905303955, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2481}, "5": {"k": 5, "answer": "Tagore", "latency_ms": 2078.71675491333, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3167}, "6": {"k": 6, "answer": "Tagore", "latency_ms": 1254.5430660247803, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3819}}}
{"qid": "8466196474705624263", "question": "who was running as vice president in 1984", "gold_answers": ["Ferraro", "Vice President George H.W. Bush", "Congresswoman Ferraro", "George H.W. Bush"], "shots": {"0": {"k": 0, "answer": "George H.W. Bush", "latency_ms": 2781.0893058776855, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Geraldine Ferraro", "latency_ms": 2470.153570175171, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 682}, "2": {"k": 2, "answer": "Geraldine Ferraro", "latency_ms": 2263.7946605682373, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 1348}, "3": {"k": 3, "answer": "Geraldine Ferraro", "latency_ms": 2243.746519088745, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2037}, "4": {"k": 4, "answer": "Geraldine Ferraro", "latency_ms": 3644.853353500366, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 2752}, "5": {"k": 5, "answer": "Geraldine Ferraro", "latency_ms": 2657.12833404541, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 3448}, "6": {"k": 6, "answer": "Geraldine Ferraro", "latency_ms": 3458.8518142700195, "em": 0.0, "f1": 0.6666666666666665, "containment": 1.0, "context_chars": 4123}}}
{"qid": "7711594393122809900", "question": "where is the largest salt mine in the us", "gold_answers": ["Central New York", "Western New York"], "shots": {"0": {"k": 0, "answer": "American Rock Salt mine, Livingston County, New York", "latency_ms": 4759.694814682007, "em": 0.0, "f1": 0.36363636363636365, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Hampton Corners, Groveland", "latency_ms": 3927.79803276062, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 617}, "2": {"k": 2, "answer": "Hampton Corners", "latency_ms": 2725.700855255127, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1346}, "3": {"k": 3, "answer": "Hampton Corners", "latency_ms": 2104.421377182007, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1963}, "4": {"k": 4, "answer": "Goderich, Ontario", "latency_ms": 2701.007843017578, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2570}, "5": {"k": 5, "answer": "Hampton Corners", "latency_ms": 2154.2305946350098, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3178}, "6": {"k": 6, "answer": "Goderich, Ontario", "latency_ms": 2990.173101425171, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3804}}}
{"qid": "-7011448454774306489", "question": "who took the first steps on the moon in 1969", "gold_answers": ["Neil Armstrong"], "shots": {"0": {"k": 0, "answer": "Neil Armstrong", "latency_ms": 1578.909158706665, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "Neil Armstrong", "latency_ms": 1708.5368633270264, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 588}, "2": {"k": 2, "answer": "Neil Armstrong", "latency_ms": 2083.750009536743, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1200}, "3": {"k": 3, "answer": "Neil Armstrong", "latency_ms": 1510.6792449951172, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 1757}, "4": {"k": 4, "answer": "Neil Armstrong", "latency_ms": 1557.2576522827148, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2377}, "5": {"k": 5, "answer": "Neil Armstrong", "latency_ms": 1142.5533294677734, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 2997}, "6": {"k": 6, "answer": "Neil Armstrong", "latency_ms": 1208.0137729644775, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 3659}}}
{"qid": "3125559316824073534", "question": "state with highest population growth rate in india 2011", "gold_answers": ["Dadra and Nagar Haveli", "Meghalaya"], "shots": {"0": {"k": 0, "answer": "Meghalaya", "latency_ms": 1890.023946762085, "em": 1.0, "f1": 1.0, "containment": 1.0, "context_chars": 0}, "1": {"k": 1, "answer": "I cannot answer.", "latency_ms": 2719.68674659729, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 652}, "2": {"k": 2, "answer": "I cannot answer.", "latency_ms": 3100.6622314453125, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1294}, "3": {"k": 3, "answer": "I cannot answer.", "latency_ms": 2998.807430267334, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1962}, "4": {"k": 4, "answer": "I cannot answer.", "latency_ms": 2435.2521896362305, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2613}, "5": {"k": 5, "answer": "I cannot answer.", "latency_ms": 3211.6987705230713, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3264}, "6": {"k": 6, "answer": "Uttar Dinajpur", "latency_ms": 3033.5137844085693, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3911}}}
{"qid": "400438603377436284", "question": "which city is called the manchester of north india", "gold_answers": ["Ahmedabad"], "shots": {"0": {"k": 0, "answer": "Kanpur", "latency_ms": 2814.8787021636963, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 0}, "1": {"k": 1, "answer": "Ludhiana", "latency_ms": 1836.4100456237793, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 565}, "2": {"k": 2, "answer": "Ludhiana", "latency_ms": 3137.4330520629883, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1192}, "3": {"k": 3, "answer": "Kanpur", "latency_ms": 1600.219964981079, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 1831}, "4": {"k": 4, "answer": "Kanpur", "latency_ms": 1647.9840278625488, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 2412}, "5": {"k": 5, "answer": "Ludhiana", "latency_ms": 2719.458818435669, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3109}, "6": {"k": 6, "answer": "Kanpur", "latency_ms": 2205.019235610962, "em": 0.0, "f1": 0.0, "containment": 0.0, "context_chars": 3702}}}
